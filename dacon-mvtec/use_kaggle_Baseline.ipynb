{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install timm","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:07:59.678126Z","iopub.execute_input":"2022-04-12T03:07:59.678399Z","iopub.status.idle":"2022-04-12T03:08:09.639569Z","shell.execute_reply.started":"2022-04-12T03:07:59.678375Z","shell.execute_reply":"2022-04-12T03:08:09.638697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nfrom glob import glob\nimport pandas as pd\nimport numpy as np \nfrom tqdm import tqdm\nimport cv2\n\nimport os\nimport timm\nimport random\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom sklearn.metrics import f1_score, accuracy_score\nimport time\n\n\ndevice = torch.device('cuda')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-12T03:08:09.643116Z","iopub.execute_input":"2022-04-12T03:08:09.643351Z","iopub.status.idle":"2022-04-12T03:08:13.06076Z","shell.execute_reply.started":"2022-04-12T03:08:09.643325Z","shell.execute_reply":"2022-04-12T03:08:13.059843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_y = pd.read_csv(\"../input/dacon-cv-data/open/train_df.csv\")\ntest_df = pd.read_csv(\"../input/dacon-cv-data/open/test_df.csv\")\ntrain_labels = train_y[\"label\"]\n\nlabel_unique = sorted(np.unique(train_labels))\nlabel_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n\ntrain_labels = [label_unique[k] for k in train_labels]","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:08:13.062666Z","iopub.execute_input":"2022-04-12T03:08:13.062917Z","iopub.status.idle":"2022-04-12T03:08:13.140444Z","shell.execute_reply.started":"2022-04-12T03:08:13.06289Z","shell.execute_reply":"2022-04-12T03:08:13.139762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    IMAGE_SIZE = 380\n    MEAN_NORMAL = [0.485, 0.456, 0.406]\n    STD_NORMAL = [0.229, 0.224, 0.225]\n\n    pre_trained_model = 'efficientnet_b3'\n    DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:08:13.142589Z","iopub.execute_input":"2022-04-12T03:08:13.14287Z","iopub.status.idle":"2022-04-12T03:08:13.197256Z","shell.execute_reply.started":"2022-04-12T03:08:13.142835Z","shell.execute_reply":"2022-04-12T03:08:13.19631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\ndef train_transform():\n    return A.Compose([\n        A.Resize(config.IMAGE_SIZE, config.IMAGE_SIZE),\n        A.HueSaturationValue(p = 0.8),\n        A.Normalize(mean= config.MEAN_NORMAL,\n                    std = config.STD_NORMAL),\n        ToTensorV2(p = 1),\n    ])\n\n\ndef test_transform():\n    return A.Compose([\n        A.Resize(config.IMAGE_SIZE, config.IMAGE_SIZE),\n        A.Normalize(mean = config.MEAN_NORMAL,\n                    std = config.STD_NORMAL),\n        ToTensorV2(p = 1),\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:08:13.198932Z","iopub.execute_input":"2022-04-12T03:08:13.199526Z","iopub.status.idle":"2022-04-12T03:08:14.070458Z","shell.execute_reply.started":"2022-04-12T03:08:13.199489Z","shell.execute_reply":"2022-04-12T03:08:14.06967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, dataframe, root_dir, labels, transforms = None):\n        self.dataframe = dataframe\n        self.root_dir = root_dir\n        self.transforms = transforms\n        self.labels = labels\n    \n    def __len__(self):\n        return len(self.dataframe)\n    \n    def get_img(self, path):\n        img_bgr = cv2.imread(path)\n        img_rgb = img_bgr[:, :, ::-1]\n        return img_rgb\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        img_name = os.path.join(self.root_dir,\n                                self.dataframe.iloc[idx, 1])\n        image = self.get_img(img_name)\n        if self.transforms:\n            image = self.transforms(image = image)['image']\n        \n        labels = self.labels[idx]\n            \n        return image, labels","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:08:14.072769Z","iopub.execute_input":"2022-04-12T03:08:14.073205Z","iopub.status.idle":"2022-04-12T03:08:14.082234Z","shell.execute_reply.started":"2022-04-12T03:08:14.073167Z","shell.execute_reply":"2022-04-12T03:08:14.081321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:08:14.084746Z","iopub.execute_input":"2022-04-12T03:08:14.085339Z","iopub.status.idle":"2022-04-12T03:08:14.095463Z","shell.execute_reply.started":"2022-04-12T03:08:14.085284Z","shell.execute_reply":"2022-04-12T03:08:14.094647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nepochs = 50\n\n# Train\ntrain_dataset = CustomDataset(dataframe = train_y, root_dir = '../input/dacon-cv-data/open/train/train', labels = np.array(train_labels), transforms = train_transform())\ntrain_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n\n# Test\ntest_dataset = CustomDataset(dataframe = test_df, root_dir = '../input/dacon-cv-data/open/test/test', labels = np.array([\"tmp\"]*len(test_df)), transforms = test_transform())\ntest_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:08:14.098403Z","iopub.execute_input":"2022-04-12T03:08:14.098611Z","iopub.status.idle":"2022-04-12T03:08:14.108031Z","shell.execute_reply.started":"2022-04-12T03:08:14.098586Z","shell.execute_reply":"2022-04-12T03:08:14.107076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def score_function(real, pred):\n    score = f1_score(real, pred, average=\"macro\")\n    return score\n\ncount = 1\nfor _ in range(5):\n    model = Network().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n    scaler = torch.cuda.amp.GradScaler() \n    best=0\n    for epoch in range(epochs):    \n        start=time.time()\n        train_loss = 0\n        train_pred=[]\n        train_y=[]\n        model.train()\n        for batch in (train_loader):\n            optimizer.zero_grad()\n            x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n            y = torch.tensor(batch[1], dtype=torch.long, device=device)\n            with torch.cuda.amp.autocast():\n                pred = model(x)\n            loss = criterion(pred, y)\n\n\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n\n            train_loss += loss.item()/len(train_loader)\n            train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n            train_y += y.detach().cpu().numpy().tolist()\n\n\n        train_f1 = score_function(train_y, train_pred)\n\n        TIME = time.time() - start\n        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n    torch.save(model.state_dict(),f'torch_model_effic4_state_dict_{count}.pth' )\n    count += 1","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:08:25.21561Z","iopub.execute_input":"2022-04-12T03:08:25.216428Z","iopub.status.idle":"2022-04-12T07:04:49.524732Z","shell.execute_reply.started":"2022-04-12T03:08:25.216375Z","shell.execute_reply":"2022-04-12T07:04:49.523664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Network().to(device)\nmodel.load_state_dict(torch.load('./torch_model_effic4_state_dict_1.pth'))\nf_pred = []\n\nwith torch.no_grad():\n    for batch in (test_loader):\n        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n        with torch.cuda.amp.autocast():\n            pred = model(x)\n        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())","metadata":{"execution":{"iopub.status.busy":"2022-04-12T07:05:07.042122Z","iopub.execute_input":"2022-04-12T07:05:07.042363Z","iopub.status.idle":"2022-04-12T07:07:07.954406Z","shell.execute_reply.started":"2022-04-12T07:05:07.042337Z","shell.execute_reply":"2022-04-12T07:07:07.953677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_decoder = {val:key for key, val in label_unique.items()}\nf_result = [label_decoder[result] for result in f_pred]\nsubmission = pd.read_csv(\"../input/dacon-cv-data/open/sample_submission.csv\")\nsubmission[\"label\"] = f_result\nsubmission.to_csv(\"submit.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T07:07:07.955967Z","iopub.execute_input":"2022-04-12T07:07:07.956199Z","iopub.status.idle":"2022-04-12T07:07:07.982407Z","shell.execute_reply.started":"2022-04-12T07:07:07.956166Z","shell.execute_reply":"2022-04-12T07:07:07.981802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}