{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Data Science Solution(KOR Ver)\n- This is written in Korean with reference to this link\n    - link : https://www.kaggle.com/startupsci/titanic-data-science-solutions/notebook\n\n**제가 NoteBook을 작성하게 된 계기는 처음 Kaggle에 접하시거나, DataScience가 무엇인지 한번 쯤 간단하게 접해보고 싶은 사람을 위해 작성하였습니다. 또한 Kaggle에 한글로 번역된 자료가 많이 없기에 작성한것도 있습니다. 처음 번역하여 NoteBook을 작성하였는데 오타 및 수정이 필요한 부분이 있을 수 있습니다. 발견하신 분들은 commit 남겨주시면 수정하도록 하겠습니다. 또한 좋게 봐주시는 분들이 있으면 추가적으로 매주 1회 정도 competition 한가지를 번역하여 정리해서 올릴려고 합니다. 이상 긴글 읽어주셔서 감사합니다.**\n","metadata":{}},{"cell_type":"markdown","source":"## 목차\n- 훈련, 테스트 데이터에 대한 습득(Acquire training and testing data)\n- 데이터 준비 및 다루기(Wrangle, prepare, cleanse the data)\n- 데이터 탐험, 패턴, 분석하기(Analyze, identify patterns, and explore the data.)\n- 모델 생성 및 문제 해결 및 예측(Model, predict and solve the problem.)\n- 문제 해결 단계와 최종 Solution, 시각화 (Visualize, report, and present the problem solving steps and final solution.)\n- 결과 제출(Supply or submit the results.)\n","metadata":{}},{"cell_type":"code","source":"# 데이터 분석 및 다루기(data analysis and wrangling)\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# 데이터 시각화(visualization)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# 머신러닝(machine learning)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:45.948946Z","iopub.execute_input":"2021-12-14T11:16:45.949777Z","iopub.status.idle":"2021-12-14T11:16:45.958157Z","shell.execute_reply.started":"2021-12-14T11:16:45.949741Z","shell.execute_reply":"2021-12-14T11:16:45.957339Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 가져오기\n- Pandas 패키지를 이용하여 dataset을 불러오겠습니다.\n    - Train, Test 데이터를 DataFrame 형태로 변환후, 데이터셋을 결합하여, 동시에 작업을 수행하겠습니다.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/titanic/train.csv')\ntest_df = pd.read_csv('../input/titanic/test.csv')\ncombine = [train_df , test_df]","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:46.921134Z","iopub.execute_input":"2021-12-14T11:16:46.921447Z","iopub.status.idle":"2021-12-14T11:16:46.940041Z","shell.execute_reply.started":"2021-12-14T11:16:46.921413Z","shell.execute_reply":"2021-12-14T11:16:46.939159Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"## 어떠한 컬럼이 범주형 데이터인가?\n- 범주형 데이터 내에 명목,순서,비율,간격 기반의 범주형 데이터가 존재합니까?\n- 이러한 데이터들은 시각화에 도움을 주는 그래프를 선택하는 매우 도움이 됩니다.\n    - **Nominal : Survived, Sex, Embarked** \n    - **Ordinal : Pclass**   \n\n## 어떠한 컬럼이 수치형 데이터인가?\n- 수치형 데이터 내에 이산,연속,시계열에 기반인 데이터가 존재합니까?\n- 이러한 데이터들은 시각화에 도움을 주는 그래프를 선택하는 매우 도움이 됩니다.\n    - **Continous : Age, Fare** \n    - **Discete: SibSp, Parch**\n\n추가로 데이터의 특징에 대한 설명은 아래 Link를 참고하기 바랍니다.\n- link : https://blog.naver.com/qkrdnjsrl0628/222595486903","metadata":{}},{"cell_type":"code","source":"train_df.columns.values","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:47.911120Z","iopub.execute_input":"2021-12-14T11:16:47.911650Z","iopub.status.idle":"2021-12-14T11:16:47.917317Z","shell.execute_reply.started":"2021-12-14T11:16:47.911607Z","shell.execute_reply":"2021-12-14T11:16:47.916622Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"**Data에 대한 상세한 설명은 Titanic-data에 설명이 명시되어 있으니 확인해주시기 바랍니다.**","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:48.435100Z","iopub.execute_input":"2021-12-14T11:16:48.435531Z","iopub.status.idle":"2021-12-14T11:16:48.449577Z","shell.execute_reply.started":"2021-12-14T11:16:48.435488Z","shell.execute_reply":"2021-12-14T11:16:48.448980Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"## 데이터 타입이 혼용된 컬럼은 어떤 것이 있습니까?\n- Ticket 데이터는 알파벳과 수치형데이터가 섞여 있으며, Cabin 데이터 또한 알파벳과 숫자 데이터가 섞여 있다.\n\n## 어떤 컬럼이 누락되어있거나 NULL 값을 가지고 있습니까?\n- 대규모 데이터에서는 다루기가 매우 어렵습니다. 하지만 몇가지 샘플을 확인하면 어떤 컬럼을 수정해야 하는지 바로 알 수 있다.\n\n- Name 데이터에는 대체 이름, 짧은 이름에 사용되는 따옴표를 포함하여 이름을 설명하는데 여러가지 방법이 있으므로, 오류나 오타가 포함되어 있을 수 있다.","metadata":{}},{"cell_type":"code","source":"train_df.tail()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:48.584862Z","iopub.execute_input":"2021-12-14T11:16:48.585394Z","iopub.status.idle":"2021-12-14T11:16:48.601678Z","shell.execute_reply.started":"2021-12-14T11:16:48.585359Z","shell.execute_reply":"2021-12-14T11:16:48.600642Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"## <strong>어떤 데이터가 누락 및 NUL을 포함하고 있습니까?</strong>\n- NULL값 및 누락 데이터는 수정될 필요가 있습니다.\n- 훈련 데이터 내에서는 Cabin > Age > Embarked 순으로 NULL 값 데이터가 존재합니다.\n- 테스트 데이터 내에는 Cabin > Age 순으로 NULl 값 데이터가 존재합니다.\n\n## <strong>데이터 타입의 개수가 어떻게 되나요?</strong>\n- 훈련 데이터에는 7개의 데이터들이 정수형 또는 실수형으로 이루어져 있으며, 테스트 데이터는 6개의 정수형 또는 실수형으로 이루어져 있다.\n- 5개의 데이터 타입은 object이다.","metadata":{}},{"cell_type":"code","source":"train_df.info()\nprint('_'*40)\ntest_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:48.960156Z","iopub.execute_input":"2021-12-14T11:16:48.960591Z","iopub.status.idle":"2021-12-14T11:16:48.981706Z","shell.execute_reply.started":"2021-12-14T11:16:48.960555Z","shell.execute_reply":"2021-12-14T11:16:48.980933Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"## <strong>수치형 데이터의 분포가 어떻게 되나요?</strong>\n- <strong>수치형 데이터의 분포를 파악하는 것은 인사이트 를 얻는 것과 훈련데이터가 어떤 문제의 영역에 어떻게 직면하는 아는데 도움을 준다.<strong>\n    <br></br>\n    - 총 표본 데이터는 891개이다.\n    - 생존 데이터의 범주는 0, 1로 이루어져 있음을 알 수 있다.\n    - 생존을 나타내는 데이터가 38%임을 알 수 있다.\n    - 75% 이상이 부모 또는 자녀들과 여행을 가지 않았음을 알 수 있다.\n    - 승객의 30%정도는 형재 자매 및 배우자와 함께 타고 있음을 알 수 있다.\n    - 요금을 512달러까지 지불하는 승객들도 존재합니다.\n    - 65 - 80세 사이의 나이 많은 어르신분들이 대략 1%존재한다는 것을 알 수 있습니다.","metadata":{}},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:49.187267Z","iopub.execute_input":"2021-12-14T11:16:49.188224Z","iopub.status.idle":"2021-12-14T11:16:49.220731Z","shell.execute_reply.started":"2021-12-14T11:16:49.188173Z","shell.execute_reply":"2021-12-14T11:16:49.219701Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"## <strong>범주형 데이터는 어떻게 분포되어 있습니까?</strong>\n* 참고로 DataFrame.describe() 을 사용하면 수치형 데이터만을 알려주지만,&nbsp;\n  <strong>include = ['O'] 를 지정하면, 범주형 데이터를 알려준다.</strong>\n  \n  - Name 데이터는 유니크 데이터로 891개 존재한다.\n  - 성별의 65%는 남자임을 알 수 있다.\n  - Cabin 데이터 내에는 여러 데이터에 거쳐 중복항목이 존재한다. 몇몇 승객들은 선실을 공유하였습니다.\n  - Embarked 데이터에는 3가지 데이터가 존재한다. 대부분의 사람들이 S 라는 데이터를 가지고 있습니다.\n  \n  \n  ","metadata":{}},{"cell_type":"code","source":"train_df.describe(include = ['O'])\n# include 0으로 할 경우 문자열 데이터에 관한 통계를 알려준다.","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:49.483381Z","iopub.execute_input":"2021-12-14T11:16:49.483657Z","iopub.status.idle":"2021-12-14T11:16:49.504189Z","shell.execute_reply.started":"2021-12-14T11:16:49.483626Z","shell.execute_reply":"2021-12-14T11:16:49.503579Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"## <strong>데이터 분석을 기반으로 한 가정</strong>\n- 데이터를 가지고 적절한 행동을 하기전 이러한 가정들을 검증할 것입니다.\n\n#### Correlating(상관 분석)\n- 나이와 생존간의 관계는 명확한 상관관계가 존재한다.\n- 생존 또는 또 다른 중요한 특징과 탑승지역과 관련지을 수도 있습니다.\n\n#### Correcting(정확성)\n- Ticket 데이터는 생존과 관계가 없을 뿐만 아니라, 22%의 데이터가 중복되므로 삭제하는 것이 좋습니다.\n- Cabin 데이터는 불완전하거나 많은 NULL값을 가지고 있기에 훈련 테스트 데이터에서 drop하는 것이 좋습니다.\n- PassengerID는 Survived와 관련이 없으므로, 삭제하는 것이 좋습니다.\n- Name 도 위와 동일합니다.\n\n#### Creating(제작)\n- Parch, Sibsp 기반으로 하여 가족의 총 수를 얻을 수 있습니다.\n- 새로운 특징을 추출하기 위해 Name 데이터를 다룰 수 있습니다.\n- Age 데이터를 가지고, 새로운 범주형 데이터를 만들수 있습니다.\n- Fare 또한 분석에 도움이 된다면 범주형으로 변경할 수 있습니다.\n\n\n#### Classifying(분류)\n- 문제의 설명을 기반으로 가정을 추가할 수 있습니다.\n- Wonme 는 생존할 가능성이 더 있습니다.\n- Age가 낮을수록 더욱 생존할 가능성이 존재합니다.\n- Pclass = 1 에 가까울수록 생존 할 가능성이 큽니다.","metadata":{}},{"cell_type":"markdown","source":"## <strong>Analyze by pivoting features</strong>\n\n- 몇몇 우리의 검증과 추정을 확증하기 위해, 특징을 pivot 함으로써 상관 관계를 신속하게 분석할 수 있습니다.\n- 이 단계는 공백의 데이터가 존재하지 않는 것에 한에서만 시행이 가능하다.\n- 데이터들을 pivoting 하는 것은 범주형 데이터나 이산형 데이터에 한해서만 시행하는 것이 좋다.\n\n    - Pclass : Pclass = 1 과 Survived 간의 상관관계가 있다는 것을 파악했으며, 모델의 특징에 포함하기로 한다.\n    - Sex : Female인 경우 생존률이 74% 이상임을 파악할 수 있습니다.\n    - SibSp and Parch : 값에 대하여 상관관계가 0이므로, 기능집합을 파생하는 것이 가장 좋다.\n    ","metadata":{}},{"cell_type":"code","source":"train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)\n# as_index 는 Pclass 를 그룹으로 한 것을 index화를 하는 것이냐, 안하는 것이냐를 지정하는 것이다.","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:50.011116Z","iopub.execute_input":"2021-12-14T11:16:50.011415Z","iopub.status.idle":"2021-12-14T11:16:50.025522Z","shell.execute_reply.started":"2021-12-14T11:16:50.011382Z","shell.execute_reply":"2021-12-14T11:16:50.024920Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"train_df[['Sex', 'Survived']].groupby(['Sex'], as_index = False).mean().sort_values(by='Survived', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:50.064429Z","iopub.execute_input":"2021-12-14T11:16:50.065220Z","iopub.status.idle":"2021-12-14T11:16:50.077245Z","shell.execute_reply.started":"2021-12-14T11:16:50.065179Z","shell.execute_reply":"2021-12-14T11:16:50.076414Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"train_df[['SibSp', 'Survived']].groupby(['SibSp'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:50.532248Z","iopub.execute_input":"2021-12-14T11:16:50.533235Z","iopub.status.idle":"2021-12-14T11:16:50.545705Z","shell.execute_reply.started":"2021-12-14T11:16:50.533193Z","shell.execute_reply":"2021-12-14T11:16:50.544717Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"train_df[['Parch', 'Survived']].groupby(['Parch'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:50.547265Z","iopub.execute_input":"2021-12-14T11:16:50.547609Z","iopub.status.idle":"2021-12-14T11:16:50.567570Z","shell.execute_reply.started":"2021-12-14T11:16:50.547580Z","shell.execute_reply":"2021-12-14T11:16:50.566717Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"## <strong>데이터 시각화를 통한 분석</strong>\n- 분석한 데이터를 시각화 함으로써 우리의 몇몇 가정들을 검증해 나갈것입니다.\n## 수치형 데이터 관계성\n    - 수치형 데이터와 타겟데이터와의 관계를 이해해보려 하겠습니다.\n        - history chart 는 매우 유용하다. 연속적인 수치형 데이터의 유용한 패턴을 분석하는데 유용하다.\n        - histogram은 막대를 사용함으로써 데이터가 나타난 분포를 횟수를 그래프로 나타낸 것입니다.\n        - histogram 관련한 설명 링크 : https://sohyunwriter.tistory.com/142?category=892943\n        - histogram은 어릴수록 생존률이 높은지에 관하여 관련된 시각을 보여준다.\n        \n#### Observations\n- 4세 이하는 높은 생존률을 나타낸다.\n- 나이가 많을수록 생존률이 높다.\n- 15-25세 사이의 대부분은 생존하지 못하였다.\n- 대부분의 승객들은 15- 35세이다.\n\n#### Decisions\n- 이러한 간단한 분석은 차후 흐름에 대한 결정으로 우리의 가정을 확인한다.\n    - 모델에서 나이를 고려해야 함을 알 수 있다. (classifying 2)\n    - NULL 연령 기능을 처리해야 한다. (completing 1)\n    - 연령대별로 묶어야 함을 알 수 있다. (creating 3)\n      \n\n\n    ","metadata":{}},{"cell_type":"code","source":"# FaceGrid(참고) :  https://steadiness-193.tistory.com/201\ng = sns.FacetGrid(train_df, col = 'Survived')\ng.map(plt.hist, 'Age', bins = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:50.696058Z","iopub.execute_input":"2021-12-14T11:16:50.696320Z","iopub.status.idle":"2021-12-14T11:16:51.157293Z","shell.execute_reply.started":"2021-12-14T11:16:50.696293Z","shell.execute_reply":"2021-12-14T11:16:51.155610Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"## 수치형 데이터와 순서형 데이터 간의 상관관계\n- 단일 그래프를 사용함으로써 상관관계를 식별하기 위해 여러 기능을 결합할 수 있다.\n- 숫자 및 범주 기능으로써 사용할 수 있습니다.\n\n#### Observations\n- 대부분의 승객들은 Pclass = 3, 하지만 죽지는 않았다. (classifying 2)\n- Pclass = 2 or Pclass = 3 인 유아기의 아이들은 대부분 생존했다. (classifying 2)\n- Pclass = 1인 대부분의 승객들은 생존하였다. (classifying 3)\n- Pclass 는 승객의 연령에 따라 역할이 다름을 파악할 수 있다.\n\n#### Decisions\n- 모델을 학습할 때, Pclass를 고려할 수 있다.","metadata":{}},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, col = 'Pclass',hue = 'Survived')\ngrid.map(plt.hist, 'Age', alpha = .5, bins = 20)\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:51.158645Z","iopub.execute_input":"2021-12-14T11:16:51.159102Z","iopub.status.idle":"2021-12-14T11:16:52.077197Z","shell.execute_reply.started":"2021-12-14T11:16:51.159066Z","shell.execute_reply":"2021-12-14T11:16:52.076473Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, col = 'Survived', row = 'Pclass', size = 2.2, aspect = 1.6)\ngrid.map(plt.hist, 'Age', alpha =.5, bins = 20)\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:52.078194Z","iopub.execute_input":"2021-12-14T11:16:52.078652Z","iopub.status.idle":"2021-12-14T11:16:53.500678Z","shell.execute_reply.started":"2021-12-14T11:16:52.078618Z","shell.execute_reply":"2021-12-14T11:16:53.499624Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"## 범주형 데이터 상관관계\n- Solution을 위해 범주형 데이터의 상관관계를 파악할 수 있다.\n\n## Observations.\n- 여성 승객은 남성보다는 높은 생존률을 지니고 있음을 알 수 있다.(classifying 1)\n- 남성이 더 높은 생존률을 보인 Embarked = C는 예외임을 알수 있고,Pclass와  Survived 관점에서 Pclass와 Embarked간의 상관관계가 있음을 알 수 있다. 단, Embarked 와 Survived는 직접적인 상관관계가 필수조건은 아님을 알 수 있다.\n- 남성의 경우 Pclass = 3 이 Pclass = 2 보다 생존률이 높음을 알 수 있다. (Completing 2)\n- Pclass = 3의 경우 특성이 매우 다양함을 알 수 있다. (Completing 1)\n\n## Decisions\n- 성별의 경우 모델을 학습시킬때 추가해야함을 알 수 있다.\n- 모델 학습을 완료한후 Embarked 특성을 추가한다.","metadata":{}},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, col = 'Embarked')\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette = 'deep')\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:53.502452Z","iopub.execute_input":"2021-12-14T11:16:53.502684Z","iopub.status.idle":"2021-12-14T11:16:54.785493Z","shell.execute_reply.started":"2021-12-14T11:16:53.502656Z","shell.execute_reply":"2021-12-14T11:16:54.784584Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, row = 'Embarked', size = 2.2, aspect = 1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette = 'deep')\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:54.786589Z","iopub.execute_input":"2021-12-14T11:16:54.786784Z","iopub.status.idle":"2021-12-14T11:16:55.930085Z","shell.execute_reply.started":"2021-12-14T11:16:54.786759Z","shell.execute_reply":"2021-12-14T11:16:55.929250Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"## 범주형 데이터와 수치형 데이터의 상관관계\n- 범주형 데이터와 수치형 데이터의 상관관계를 파악해야 한다. 우리는 범주형 데이터인 Embarked, Sex, Survived와 수치형 데이터인 Fare를 비교할 수 있다.\n\n## Observations\n- 높은 요금을 지불한 사람들은 생존률이 높을 알 수 있다. (creating 4)\n- 승선항과 생존률간에 관계가 있음을 알 수 있다.\n\n## Decision\n- 요금을 범위별로 묶을 수 있다.\n","metadata":{}},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, row = 'Embarked', col = 'Survived', size = 2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha = .5, ci = None)\n# alpha 는 투명도(transparency)를 의미합니다.\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:55.931111Z","iopub.execute_input":"2021-12-14T11:16:55.931302Z","iopub.status.idle":"2021-12-14T11:16:56.861213Z","shell.execute_reply.started":"2021-12-14T11:16:55.931278Z","shell.execute_reply":"2021-12-14T11:16:56.860387Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, col = 'Embarked', hue = 'Survived',  palette={0: 'k', 1: 'w'})\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha = .5, ci = None)\n# alpha 는 투명도(transparency)를 의미합니다.\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:56.862317Z","iopub.execute_input":"2021-12-14T11:16:56.862685Z","iopub.status.idle":"2021-12-14T11:16:57.443808Z","shell.execute_reply.started":"2021-12-14T11:16:56.862653Z","shell.execute_reply":"2021-12-14T11:16:57.442858Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"## 데이터 전처리(Preprocessing Data)\n- 본문에는 Wrangle Data라고 작성되어 있는데 데이터 전처리랑 비슷한 의미이다.\n- 참고 : https://bkshin.tistory.com/entry/DATA-23-Data-Wrangling\n\n- 데이터와 특정 솔루션과 관련하여 몇몇의 결정과 가정을 수집했다. 지금까지 값이나 기능을 변경할 필요가 없었다.지금부터는 문제를 해결하기 위해 데이터를 가공하면서 결정과 가정이 맞는지 파악해보겠습니다.\n\n## 데이터 삭제\n- 데이터를 삭제함으로써 더 적은 양의 데이터를 처리한다.\n- 우리의 추정과 결론을 기반으로 하여 우리는 Cabin 과 Ticket의 데이터 를 버릴 수 있다.\n- 일관성을 유지하기 위해서 훈련데이터와 테스트 데이터를 동시에 작업해줘야 한다.","metadata":{}},{"cell_type":"code","source":"print('Before', train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\n\ntrain_df = train_df.drop(['Ticket', 'Cabin'], axis = 1)\ntest_df = test_df.drop(['Ticket', 'Cabin'], axis = 1)\ncombine = [train_df, test_df]\n\nprint('After', train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:57.445607Z","iopub.execute_input":"2021-12-14T11:16:57.445838Z","iopub.status.idle":"2021-12-14T11:16:57.455911Z","shell.execute_reply.started":"2021-12-14T11:16:57.445812Z","shell.execute_reply":"2021-12-14T11:16:57.455065Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"## 존재하는 데이터로부터 새로운 데이터 추출하기\n- 만약 Name,Paseengerid 데이터를 삭제하기전에 Name 이름에서 성(Title)과 Survived간의 상관관계를   파악할 수 있도록 분석할 수 있습니다.\n- 정규표현식을 이용해서 추출할 수 있습니다.\n\n## Observation\n- 대부분의 성(Title)은 나이를 정확히 표현합니다. 예를들면 성(Title)이 Master인 사람은 평균적으로 5세 이하입니다\n- 성(Title)과 Age간의 생존관계는 서로 다릅니다.\n- 특정 성(Title)을 가진 사람은 사망했거나(Mme, Lady, Sir) 혹은 생존하였습니다.(Don, Rev, Jonkheer)\n\n## Decision\n- Model 훈련을 위해서 새로운 제목을 유지하기로 하였습니다.","metadata":{}},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand = False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:57.457367Z","iopub.execute_input":"2021-12-14T11:16:57.457787Z","iopub.status.idle":"2021-12-14T11:16:57.485332Z","shell.execute_reply.started":"2021-12-14T11:16:57.457744Z","shell.execute_reply":"2021-12-14T11:16:57.484327Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"많은것을 더 일반적인 Title으로 변경하거나 Rare로 분류할 것입니다.","metadata":{}},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')    \n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index = False).mean()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:57.486214Z","iopub.execute_input":"2021-12-14T11:16:57.486770Z","iopub.status.idle":"2021-12-14T11:16:57.505964Z","shell.execute_reply.started":"2021-12-14T11:16:57.486737Z","shell.execute_reply":"2021-12-14T11:16:57.505406Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"범주형(categorical) 데이터인 title을 순서형(ordinal) 데이터로 변환할 것입니다.","metadata":{}},{"cell_type":"code","source":"title_mapping = {\"Mr\":1 , \"Miss\":2, \"Mrs\":3, \"Master\":4, \"Rare\":5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:58.395404Z","iopub.execute_input":"2021-12-14T11:16:58.396032Z","iopub.status.idle":"2021-12-14T11:16:58.413957Z","shell.execute_reply.started":"2021-12-14T11:16:58.396002Z","shell.execute_reply":"2021-12-14T11:16:58.413363Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop(['Name', 'PassengerId'], axis = 1)\ntest_df = test_df.drop(['Name'], axis = 1)\ncombine = [train_df, test_df]\ntrain_df.shape, test_df.shape ","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:16:59.145662Z","iopub.execute_input":"2021-12-14T11:16:59.146366Z","iopub.status.idle":"2021-12-14T11:16:59.154829Z","shell.execute_reply.started":"2021-12-14T11:16:59.146311Z","shell.execute_reply":"2021-12-14T11:16:59.154097Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"## 범주형 데이터 변환\n- 문자형, 수치형 데이터를 변환할 수 있습니다. 대부분의 모델에서는 요구되는 사항입니다.\n- 먼저 female, male 데이터를 변환하겠습니다. female = 1, male = 0","metadata":{}},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female' : 1, 'male' : 0}).astype(int)\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:00.494547Z","iopub.execute_input":"2021-12-14T11:17:00.494843Z","iopub.status.idle":"2021-12-14T11:17:00.511777Z","shell.execute_reply.started":"2021-12-14T11:17:00.494812Z","shell.execute_reply":"2021-12-14T11:17:00.510964Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"## 수치형 연속형 데이터 다루기\n- 공백이 있거나 NULL값을 가진 데이터를 다루는 것부터 시작하겠습니다. 먼저 Age Feature부터 다루겠습니다.\n- 3가지 방식으로 연속형 데이터를 다룰 수 있습니다.\n    - 간단한 방식으로는 평균과 표준편차 사이에서 난수를 생성하는 방식이 있습니다.\n    - 공백이 있는 데이터를 더 정확하게 추측하는 방법으로 다른 정확한 데이터를 사용하는 방식이 존재합니다. 나이, 성별, Pclass 사이의 관계를 주목하겠습니다. Pclass 와 Gender를 결합하여 Age 에서 mean을 찾음으로써 추측을 할 수 있습니다.\n    - 첫번째 방식과 두번째 방식을 결합하는 것이 좋다. 따라서 Age를 중앙값으로 추측하는 대신 Pclass 및 Gender 조합 집합을 기반으로 평균 및 표준편차 사이의 난수를 사용할 것입니다.\n    \n    - random은 노이즈를 도입할 수 있습니다. 하지만 실행 결과가 모두 다를 수 있으므로. 2번째 방법을 이용하겠습니다.\n    ","metadata":{}},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, row = 'Pclass', col = 'Sex')\ngrid.map(plt.hist, 'Age')\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:01.588249Z","iopub.execute_input":"2021-12-14T11:17:01.588563Z","iopub.status.idle":"2021-12-14T11:17:02.959641Z","shell.execute_reply.started":"2021-12-14T11:17:01.588522Z","shell.execute_reply":"2021-12-14T11:17:02.958658Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"guess_ages = np.zeros((2, 3))\nguess_ages","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:02.960967Z","iopub.execute_input":"2021-12-14T11:17:02.961195Z","iopub.status.idle":"2021-12-14T11:17:02.966926Z","shell.execute_reply.started":"2021-12-14T11:17:02.961169Z","shell.execute_reply":"2021-12-14T11:17:02.966097Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"지금부터 Sex(0 or 1) 그리고 Pclass(1, 2, 3)을 조합하여 6번의 반복으로 Age 데이터를 추측할 것입니다.","metadata":{"execution":{"iopub.status.busy":"2021-12-13T14:25:10.042719Z","iopub.execute_input":"2021-12-13T14:25:10.043056Z","iopub.status.idle":"2021-12-13T14:25:10.048683Z","shell.execute_reply.started":"2021-12-13T14:25:10.043019Z","shell.execute_reply":"2021-12-13T14:25:10.047650Z"}}},{"cell_type":"code","source":"for dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()\n            \n            age_guess = guess_df.median()\n            \n            guess_ages[i,j] = int((age_guess/0.5) + 0.5)*0.5\n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[(dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1), 'Age'] = guess_ages[i, j]\n    \n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:04.164174Z","iopub.execute_input":"2021-12-14T11:17:04.165122Z","iopub.status.idle":"2021-12-14T11:17:04.210270Z","shell.execute_reply.started":"2021-12-14T11:17:04.165079Z","shell.execute_reply":"2021-12-14T11:17:04.209426Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"Age 데이터를 Survived와 관련하여 묶어서 확인해보겠습니다","metadata":{}},{"cell_type":"code","source":"train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index = False).mean().sort_values(by = 'AgeBand', ascending = True)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:05.737580Z","iopub.execute_input":"2021-12-14T11:17:05.738100Z","iopub.status.idle":"2021-12-14T11:17:05.756990Z","shell.execute_reply.started":"2021-12-14T11:17:05.738059Z","shell.execute_reply":"2021-12-14T11:17:05.756412Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[dataset['Age'] > 64, 'Age'] = 4\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:06.432747Z","iopub.execute_input":"2021-12-14T11:17:06.433037Z","iopub.status.idle":"2021-12-14T11:17:06.455898Z","shell.execute_reply.started":"2021-12-14T11:17:06.433004Z","shell.execute_reply":"2021-12-14T11:17:06.454798Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop(['AgeBand'], axis = 1)\ncombine = [train_df, test_df]\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:07.309096Z","iopub.execute_input":"2021-12-14T11:17:07.309424Z","iopub.status.idle":"2021-12-14T11:17:07.323939Z","shell.execute_reply.started":"2021-12-14T11:17:07.309380Z","shell.execute_reply":"2021-12-14T11:17:07.322895Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"markdown","source":"## 존재하는 Feature를 결합하여 새로운 Feature 만들기\n- 우리는 Parch, SibSp를 결합하여 식구(가족 총 인원 수)에 대한 새로운 Feature를 생성할 수 있습니다.\n- 그렇게 함으로써 Parch, SibSp데이터를 제거가 가능해집니다.","metadata":{}},{"cell_type":"code","source":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:09.133875Z","iopub.execute_input":"2021-12-14T11:17:09.134162Z","iopub.status.idle":"2021-12-14T11:17:09.150589Z","shell.execute_reply.started":"2021-12-14T11:17:09.134130Z","shell.execute_reply":"2021-12-14T11:17:09.150004Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index = False).mean()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:09.608077Z","iopub.execute_input":"2021-12-14T11:17:09.608836Z","iopub.status.idle":"2021-12-14T11:17:09.621838Z","shell.execute_reply.started":"2021-12-14T11:17:09.608802Z","shell.execute_reply":"2021-12-14T11:17:09.621333Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis = 1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis = 1)\n\ncombine = [train_df, test_df]\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:10.609894Z","iopub.execute_input":"2021-12-14T11:17:10.610307Z","iopub.status.idle":"2021-12-14T11:17:10.624963Z","shell.execute_reply.started":"2021-12-14T11:17:10.610276Z","shell.execute_reply":"2021-12-14T11:17:10.623929Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":"Pclass 와 Age 에 관한 데이터를 결합함으로써 새로운 Feature를 생성 수 있습니다.","metadata":{}},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ntrain_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:12.081553Z","iopub.execute_input":"2021-12-14T11:17:12.081855Z","iopub.status.idle":"2021-12-14T11:17:12.095714Z","shell.execute_reply.started":"2021-12-14T11:17:12.081824Z","shell.execute_reply":"2021-12-14T11:17:12.095091Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"## 범주형 데이터 다루기\n- Embarked Feature 는 S, Q, C 데이터를 가지고 있습니다. 훈련데이터에는 2개의 누락값이 존재합니다. 단순히 가장 흔히 나온 데이터로 채우겠습니다.","metadata":{}},{"cell_type":"code","source":"# mode는 최빈값을 출력합니다. 참고 : https://www.geeksforgeeks.org/python-pandas-dataframe-mode/\nfreq_port = train_df.Embarked.dropna().mode()[0]\nfreq_port","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:15.172434Z","iopub.execute_input":"2021-12-14T11:17:15.172721Z","iopub.status.idle":"2021-12-14T11:17:15.181249Z","shell.execute_reply.started":"2021-12-14T11:17:15.172689Z","shell.execute_reply":"2021-12-14T11:17:15.180605Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n\ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:15.696338Z","iopub.execute_input":"2021-12-14T11:17:15.696637Z","iopub.status.idle":"2021-12-14T11:17:15.713411Z","shell.execute_reply.started":"2021-12-14T11:17:15.696601Z","shell.execute_reply":"2021-12-14T11:17:15.712535Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:16.438254Z","iopub.execute_input":"2021-12-14T11:17:16.438732Z","iopub.status.idle":"2021-12-14T11:17:16.453447Z","shell.execute_reply.started":"2021-12-14T11:17:16.438685Z","shell.execute_reply":"2021-12-14T11:17:16.452592Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":"## 수치형 데이터 다루기\n- 최빈값을 이용함으로써 Fare요금에 대하여 누락된 값을 다룰 수 있습니다. \n- 소수 두번째 자릿수로 반올림하여 실행하겠습니다.","metadata":{}},{"cell_type":"code","source":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace = True)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:17.946024Z","iopub.execute_input":"2021-12-14T11:17:17.946494Z","iopub.status.idle":"2021-12-14T11:17:17.960977Z","shell.execute_reply.started":"2021-12-14T11:17:17.946444Z","shell.execute_reply":"2021-12-14T11:17:17.960171Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"# 참고 : https://steadiness-193.tistory.com/67\ntrain_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index = False).mean().sort_values(by = 'FareBand', ascending = True)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:18.561760Z","iopub.execute_input":"2021-12-14T11:17:18.562030Z","iopub.status.idle":"2021-12-14T11:17:18.580662Z","shell.execute_reply.started":"2021-12-14T11:17:18.562001Z","shell.execute_reply":"2021-12-14T11:17:18.579863Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"markdown","source":"FareBand를 기반으로 Fare feature 를 변경합니다.","metadata":{}},{"cell_type":"code","source":"for dataset in combine:\n    dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2\n    dataset.loc[dataset['Fare']>31 , 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis = 1)\ncombine = [train_df, test_df]\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:24.089324Z","iopub.execute_input":"2021-12-14T11:17:24.089627Z","iopub.status.idle":"2021-12-14T11:17:24.110770Z","shell.execute_reply.started":"2021-12-14T11:17:24.089598Z","shell.execute_reply":"2021-12-14T11:17:24.109889Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"## 예측 및 문제 해결하기\n- 60개 이상의 모델에서 선택을 할 수 있습니다.\n- 문제의 종류를 파악해서 문제에 적합한 모델로 해결해야 합니다.\n\n## 모델\n- Logistic Regression\n- KNN or K-Nearst Neigbors\n- Support Vector Machines\n- Navie Bayes classifier\n- Decision Tree\n- Random Forest\n- Perceptron\n- Artifical neural network\n- RVM or Relevance Vector Machine","metadata":{}},{"cell_type":"code","source":"X_train = train_df.drop('Survived', axis = 1)\nY_train = train_df['Survived']\nX_test = test_df.drop('PassengerId', axis = 1).copy()\nX_train.shape , Y_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:27.377242Z","iopub.execute_input":"2021-12-14T11:17:27.377929Z","iopub.status.idle":"2021-12-14T11:17:27.388267Z","shell.execute_reply.started":"2021-12-14T11:17:27.377878Z","shell.execute_reply":"2021-12-14T11:17:27.387422Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"Logistic Regresson는 초기 작업흐름을 파악하는 유용한 모델입니다.\n- Logistic Regresson의 특징에 관해서는 아래의 링크를 참고해주시기 바랍니다.<br></br>\n  https://ko.wikipedia.org/wiki/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1_%ED%9A%8C%EA%B7%80 ","metadata":{}},{"cell_type":"code","source":"log_reg = LogisticRegression()\nlog_reg.fit(X_train, Y_train)\nY_pred = log_reg.predict(X_test)\nacc_log = round(log_reg.score(X_train, Y_train) * 100 , 2)\n\nprint(acc_log)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:29.447994Z","iopub.execute_input":"2021-12-14T11:17:29.448893Z","iopub.status.idle":"2021-12-14T11:17:29.474473Z","shell.execute_reply.started":"2021-12-14T11:17:29.448850Z","shell.execute_reply":"2021-12-14T11:17:29.473844Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"저희의 추정과가정을 검증하게 위해 Logistic Regression을 사용하였습니다. 결정계수를 활용한 특정 계수를 확인 하였습니다. Positive Coefficients increase 로그 승산을 증가 시키며, Negative Coefficients 는 로그 승산을 감소시킵니다.\n- Sex Feature의 경우 매우 높은 양의 승산임을 알 수 있다. Survived = 1 이기 대부분이기 때문이다.\n- Pclass가 증가할수록 Survived 1일 확률이 매우 감소한다는 것을 알 수 있다.\n- Age*Class 는 Survived 와 음의 상관관계가 두번째로 높기에 modeling 하기에 매우 좋습니다.\n- Title 은 두번째로 양의 승산임을 알 수 있습니다.","metadata":{}},{"cell_type":"code","source":"coeff_df = pd.DataFrame(train_df.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df['Correlation'] = pd.Series(log_reg.coef_[0])\n\ncoeff_df.sort_values(by = 'Correlation', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:31.423064Z","iopub.execute_input":"2021-12-14T11:17:31.423787Z","iopub.status.idle":"2021-12-14T11:17:31.436719Z","shell.execute_reply.started":"2021-12-14T11:17:31.423746Z","shell.execute_reply":"2021-12-14T11:17:31.435932Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":"분류 및 회귀 분석에 사용되는 지도 학습 모델인 SVM을 사용하여 모델링 해보겠습니다.\n일련의 훈련 샘플이 주어지면 SVM은 한 범주가 다른 범주에 포함되는 모델을 구축하여 이진 선형 분류기를 생성합니다.\n- Logistic Regression 보다 confidence가 높습니다.","metadata":{}},{"cell_type":"code","source":"svc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100 , 2)\nacc_svc","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:35.618228Z","iopub.execute_input":"2021-12-14T11:17:35.618936Z","iopub.status.idle":"2021-12-14T11:17:35.660246Z","shell.execute_reply.started":"2021-12-14T11:17:35.618881Z","shell.execute_reply":"2021-12-14T11:17:35.659338Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":"KNN을 사용하여 분류와 회귀에 적용해 보겠습니다. KNN은 과반수의 투표로 구분 됩니다.\n- KNN은 Logistic Regression 보다 좋지만, SVM보다 cofidence score가 낮습니다.","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train)* 100 , 2)\nacc_knn","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:17:37.237861Z","iopub.execute_input":"2021-12-14T11:17:37.238241Z","iopub.status.idle":"2021-12-14T11:17:37.304065Z","shell.execute_reply.started":"2021-12-14T11:17:37.238213Z","shell.execute_reply":"2021-12-14T11:17:37.303310Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"Navie Bayes를 이용해보겠습니다.\n- 참고 : https://ko.wikipedia.org/wiki/%EB%82%98%EC%9D%B4%EB%B8%8C_%EB%B2%A0%EC%9D%B4%EC%A6%88_%EB%B6%84%EB%A5%98","metadata":{"execution":{"iopub.status.busy":"2021-12-13T15:35:23.438111Z","iopub.execute_input":"2021-12-13T15:35:23.438904Z","iopub.status.idle":"2021-12-13T15:35:23.446082Z","shell.execute_reply.started":"2021-12-13T15:35:23.438836Z","shell.execute_reply":"2021-12-13T15:35:23.444952Z"}}},{"cell_type":"code","source":"gaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:18:43.249247Z","iopub.execute_input":"2021-12-14T11:18:43.250032Z","iopub.status.idle":"2021-12-14T11:18:43.262863Z","shell.execute_reply.started":"2021-12-14T11:18:43.249971Z","shell.execute_reply":"2021-12-14T11:18:43.262247Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"Perceptron을 이용해보겠습니다.\n- 참고 : https://ko.wikipedia.org/wiki/%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0","metadata":{}},{"cell_type":"code","source":"perceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:18:44.296299Z","iopub.execute_input":"2021-12-14T11:18:44.296579Z","iopub.status.idle":"2021-12-14T11:18:44.311074Z","shell.execute_reply.started":"2021-12-14T11:18:44.296551Z","shell.execute_reply":"2021-12-14T11:18:44.310440Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":"LinearSVC을 이용해보겠습니다.\n- 참고 : https://jfun.tistory.com/105","metadata":{}},{"cell_type":"code","source":"linear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:18:44.853466Z","iopub.execute_input":"2021-12-14T11:18:44.854254Z","iopub.status.idle":"2021-12-14T11:18:44.908756Z","shell.execute_reply.started":"2021-12-14T11:18:44.854217Z","shell.execute_reply":"2021-12-14T11:18:44.907928Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"markdown","source":"SGDClassifier을 이용해보겠습니다.\n- 참고 : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html","metadata":{}},{"cell_type":"code","source":"sgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:18:45.949838Z","iopub.execute_input":"2021-12-14T11:18:45.950119Z","iopub.status.idle":"2021-12-14T11:18:45.966873Z","shell.execute_reply.started":"2021-12-14T11:18:45.950089Z","shell.execute_reply":"2021-12-14T11:18:45.966051Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:18:47.445242Z","iopub.execute_input":"2021-12-14T11:18:47.445582Z","iopub.status.idle":"2021-12-14T11:18:47.459930Z","shell.execute_reply.started":"2021-12-14T11:18:47.445548Z","shell.execute_reply":"2021-12-14T11:18:47.459402Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:18:47.982659Z","iopub.execute_input":"2021-12-14T11:18:47.983435Z","iopub.status.idle":"2021-12-14T11:18:48.211467Z","shell.execute_reply.started":"2021-12-14T11:18:47.983394Z","shell.execute_reply":"2021-12-14T11:18:48.210694Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"markdown","source":"## Model Evaluation\n- 모든 모델에 대한 rank를 매김으로 써 가장 적합한 모델을 선택해 보겠습니다.\n    - Decision Tree와 Random Forest는 모두 동일한 모델이지만, Overfitting 방지를 위해서 random_forest를 이용하겠습니다.","metadata":{}},{"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:18:49.594062Z","iopub.execute_input":"2021-12-14T11:18:49.594301Z","iopub.status.idle":"2021-12-14T11:18:49.606129Z","shell.execute_reply.started":"2021-12-14T11:18:49.594275Z","shell.execute_reply":"2021-12-14T11:18:49.605571Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T15:36:38.300566Z","iopub.execute_input":"2021-12-13T15:36:38.300902Z","iopub.status.idle":"2021-12-13T15:36:38.306145Z","shell.execute_reply.started":"2021-12-13T15:36:38.300860Z","shell.execute_reply":"2021-12-13T15:36:38.305523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 이상 긴글 읽어주셔서 감사합니다.\n- 추가로 GridSearchCV로 하이퍼파라미터 최적화도 실행할 수 있지만 제가 이 Notebook을 번역한 목적은 DataScience입문하는 사람을 목적으로 하였기에 여기까지만 작성하였습니다.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}