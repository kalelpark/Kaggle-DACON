{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fee58a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from itertools import combinations\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine, pdist\n",
    "\n",
    "from PIL import Image\n",
    "import clip\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets.folder import pil_loader\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dca4992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_blob_detector():\n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "    params.filterByColor = True\n",
    "    params.blobColor = 255\n",
    "    params.minThreshold = 253\n",
    "    params.maxThreshold = 255\n",
    "    params.thresholdStep = 1\n",
    "    params.minDistBetweenBlobs = 0\n",
    "    params.filterByArea = True\n",
    "    params.maxArea = 1000\n",
    "    params.filterByConvexity = False\n",
    "    params.filterByInertia = False\n",
    "    \n",
    "    return cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "def get_num_keypoint(image_path, detector):\n",
    "    im = cv2.imread(image_path)\n",
    "    im_tf = (im == [0, 0, 255]).all(-1, keepdims = True)\n",
    "    keypoints = detector.detect(im_tf.astype(np.uint8)*255)\n",
    "    return len(keypoints)\n",
    "\n",
    "def included_angle_cos_dist(v1, v2 ,v3):\n",
    "    return cosine(v1-v2, v3-v2)\n",
    "\n",
    "def cos(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / np.linalg.norm(vec1) / np.linalg.norm(vec2)\n",
    "\n",
    "def cos_vec3(v1, v2, v3):\n",
    "    vec1, vec2 = v1 - v2, v3 - v2\n",
    "    return cos(vec1, vec2)\n",
    "\n",
    "def clockwise_sin2d(vec1, vec2):\n",
    "    return (vec1[0] * vec2[1] - vec1[1] * vec2[0]) / np.linalg.norm(vec1) / np.linalg.norm(vec2)\n",
    "\n",
    "def clockwise_sin2d_vec3(v1, v2, v3):\n",
    "    vec1, vec2 = v1 - v2, v3 - v2\n",
    "    return (clockwise_sin2d(vec1, vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "612cf913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 끼인각을 찾기 위한 3개 point의 index set\n",
    "angle_triples = (\n",
    "    (0, 1, 2), # thumb\n",
    "    (1, 2, 3),\n",
    "    (2, 3, 4),\n",
    "\n",
    "    (0, 5, 6), # index\n",
    "    (5, 6, 7),\n",
    "    (6, 7, 8),\n",
    "\n",
    "    (0, 9, 10), # middle\n",
    "    (9, 10, 11),\n",
    "    (10, 11, 12),\n",
    "\n",
    "    (0, 13, 14), # ring\n",
    "    (13, 14, 15),\n",
    "    (14, 15, 16),\n",
    "\n",
    "    (0, 17, 18), # little\n",
    "    (17, 18, 19),\n",
    "    (18, 19, 20),\n",
    "\n",
    "    (1, 0, 5),\n",
    "    (17, 0, 5),\n",
    "    (0, 5, 9),\n",
    "    (5, 9, 13),\n",
    "    (9, 13, 17),\n",
    "    (13, 17, 0),\n",
    "\n",
    "    (6, 5, 9),\n",
    "    (5, 9, 10),\n",
    "    (10, 9, 13),\n",
    "    (9, 13, 14),\n",
    "    (14, 13, 17),\n",
    "    (13, 17, 18)\n",
    ")\n",
    "\n",
    "def gen_triples(array):\n",
    "    \"\"\"\n",
    "    위 3개 point index를 활용하여 array로부터 3개 point set을 반환하는 generator\n",
    "    \"\"\"\n",
    "    for idxs in angle_triples:\n",
    "        v1 = array[idxs[0]]\n",
    "        v2 = array[idxs[1]]\n",
    "        v3 = array[idxs[2]]\n",
    "        yield v1, v2, v3\n",
    "\n",
    "def cos_of_triples(array):\n",
    "    \"\"\"\n",
    "    21개 행을 갖는 keypoint array의 cosine list를 반환\n",
    "    \"\"\"\n",
    "    return list(map(lambda x: cos_vec3(*x), gen_triples(array)))\n",
    "\n",
    "def sin_of_triples(array):\n",
    "    \"\"\"\n",
    "    21개 행을 갖는 keypoint array의 sine list를 반환\n",
    "    \"\"\"\n",
    "    return list(map(lambda x: clockwise_sin2d_vec3(*x), gen_triples(array)))\n",
    "\n",
    "\n",
    "def pairwise_diff(array):\n",
    "    \"\"\"\n",
    "    21개 keypoint의 모든 pair에 대하여 distance를 산출\n",
    "    21C2 = 210개의 comibation\n",
    "    \"\"\"\n",
    "    return np.concatenate(list(map(lambda x: x[0]-x[1], combinations(array, 2))), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb155fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_file_info(file_info, image_dir, split, label_info_mapping, blob_detector, flip=False):\n",
    "    rows = []\n",
    "    row_file = {}\n",
    "\n",
    "    row_file[\"id\"] = file_info[\"id\"]\n",
    "    row_file[\"n_img\"] = len(file_info[\"annotations\"])\n",
    "    row_file[\"flip\"] = flip\n",
    "\n",
    "    # All frame freature\n",
    "    all_frame_ann_array = np.array([kps[\"data\"] for kps in file_info[\"annotations\"]])\n",
    "\n",
    "    if flip:\n",
    "        all_frame_ann_array[:, :, 0] = 1920 - all_frame_ann_array[:, :, 0]\n",
    "    if row_file[\"id\"] == 475:\n",
    "        all_frame_keypoint_array = all_frame_ann_array[:, 21:]\n",
    "    elif row_file[\"id\"] == 543:\n",
    "        all_frame_keypoint_array = all_frame_ann_array[:, :21]\n",
    "\n",
    "    all_frame_keypoint_array = all_frame_ann_array.reshape(all_frame_ann_array.shape[0], -1, 21, 3)\n",
    "    file_all_frame_one_box = np.c_[all_frame_keypoint_array.min(2), all_frame_keypoint_array.max(2)]\n",
    "\n",
    "    all_frame_palm_width = np.linalg.norm(all_frame_keypoint_array[:, :, [5, 9, 13], :2] - all_frame_keypoint_array[:, :, [9, 13, 17], :2], axis=-1)\n",
    "    pw_max_diff = (all_frame_palm_width.max(0) - all_frame_palm_width.min(0)).mean(-1)\n",
    "    file_palm_height = np.linalg.norm(all_frame_keypoint_array[:, :, 0, :2] - all_frame_keypoint_array[:, :, 5, :2], axis=-1, keepdims=True)\n",
    "    file_index_move_mean = (all_frame_keypoint_array[:, :, 8, :2] - all_frame_keypoint_array[:, :, 0, :2]) / file_palm_height\n",
    "\n",
    "    if split == \"train\":\n",
    "        # Split이 train인 경우 label 정보 추가\n",
    "        row_file[\"pose_id\"] = file_info[\"action\"][0]\n",
    "        if row_file[\"id\"] == 282: # 282의 mis-label\n",
    "            row_file[\"pose_id\"] = 74 # Fix mis-label, 약속1 -> 약속2\n",
    "        row_file.update(label_info_mapping[row_file[\"pose_id\"]])\n",
    "        if flip:\n",
    "            if row_file[\"hand_type\"] == \"left\":\n",
    "                row_file[\"hand_type\"] = \"right\"\n",
    "            elif row_file[\"hand_type\"] == \"right\":\n",
    "                row_file[\"hand_type\"] = \"left\"\n",
    "    for bbox_idx in range(all_frame_keypoint_array.shape[1]):\n",
    "        row_bbox = {\"bbox_num\": bbox_idx}\n",
    "        row_bbox.update(row_file)\n",
    "        row_bbox[\"pw_max_diff\"] = pw_max_diff[bbox_idx]\n",
    "        row_bbox[\"index_move_mean\"] = pdist(file_index_move_mean[:, bbox_idx]).mean()\n",
    "        row_bbox[\"index_move_x_mean\"] = pdist(file_index_move_mean[:, bbox_idx, :1]).mean()\n",
    "        all_frame_one_box = file_all_frame_one_box[:, bbox_idx]\n",
    "\n",
    "        for keypoint_idx in range(row_file[\"n_img\"]):\n",
    "            row = {}\n",
    "            row[\"img_num\"] = keypoint_idx\n",
    "            row.update(row_bbox)\n",
    "            ann_array = all_frame_keypoint_array[keypoint_idx].reshape(-1, 3)\n",
    "\n",
    "            keypoint_array = all_frame_keypoint_array[keypoint_idx, bbox_idx]\n",
    "\n",
    "            image_path = os.path.join(image_dir, f\"{row['id']}/{keypoint_idx}.png\")\n",
    "            if \"n_blob_keypoints\" not in row_file:\n",
    "                row_file[\"n_blob_keypoints\"] = get_num_keypoint(image_path, blob_detector)\n",
    "                row_file[\"n_hands\"] = \"single\" if row_file[\"n_blob_keypoints\"] < 23 else \"both\" # 한손의 경우 21개보다 많은 경우는 없지만 여유롭게 잡음\n",
    "                row_bbox[\"n_blob_keypoints\"] = row_file[\"n_blob_keypoints\"]\n",
    "                row_bbox[\"n_hands\"] = row_file[\"n_hands\"]\n",
    "                row[\"n_blob_keypoints\"] = row_file[\"n_blob_keypoints\"]\n",
    "                row[\"n_hands\"] = row_file[\"n_hands\"]\n",
    "\n",
    "            # 한 손 bbox의 너비와 높이\n",
    "            one_bbox = all_frame_one_box[keypoint_idx]\n",
    "            for i, b in enumerate(one_bbox):\n",
    "                row[f\"one_bbox_{i}\"] = b\n",
    "            row[\"one_bbox_w\"] = one_bbox[3] - one_bbox[0]\n",
    "            row[\"one_bbox_h\"] = one_bbox[4] - one_bbox[1]\n",
    "\n",
    "            # 양손 bbox의 너비와 높이\n",
    "            bbox = np.r_[ann_array.min(0), ann_array.max(0)]\n",
    "            for i, b in enumerate(bbox):\n",
    "                row[f\"bbox_{i}\"] = b\n",
    "            row[\"bbox_w\"] = bbox[3] - bbox[0]\n",
    "            row[\"bbox_h\"] = bbox[4] - bbox[1]\n",
    "\n",
    "            # 여러 3개쌍 key point에 대한 cos / sin 값\n",
    "            coses = cos_of_triples(keypoint_array[:, :2])\n",
    "            for i, cos_anlge in enumerate(coses):\n",
    "                row[f\"cos_{i}\"] = cos_anlge\n",
    "            sins = sin_of_triples(keypoint_array[:, :2])\n",
    "            for i, sin_angle in enumerate(sins):\n",
    "                row[f\"sin_{i}\"] = sin_angle\n",
    "            for i, sin_angle in enumerate(sins):\n",
    "                row[f\"sin_abs_{i}\"] = abs(sin_angle)\n",
    "\n",
    "            # 각 point의 pairwise diff와 distance를 normalization하기 위한 손바닥 높이\n",
    "            # 2d에 대한 scale이 성능이 좋아보임\n",
    "            palm_height = np.linalg.norm(keypoint_array[0, :2] - keypoint_array[5, :2])\n",
    "\n",
    "            # 모든 point 쌍에 대한 차\n",
    "            # 3차원이기에 pair 수 210 * 3 = 630개\n",
    "            diffs = pairwise_diff(keypoint_array) / palm_height\n",
    "            for i, diff in enumerate(diffs):\n",
    "                row[f\"diff_{i}\"] = diff\n",
    "\n",
    "            # 모든 point 쌍에 대한 Euclidean distance\n",
    "            # 2차원 distance보다 3차원 distance가 성능상 좋았음\n",
    "            dists = pdist(keypoint_array) / palm_height\n",
    "            for i, dist in enumerate(dists):\n",
    "                row[f\"dist_{i}\"] = dist\n",
    "\n",
    "            thumb_knuckle = keypoint_array[4, :2] - keypoint_array[3, :2]\n",
    "            index_knuckle = keypoint_array[8, :2] - keypoint_array[7, :2]\n",
    "            palm_knuckle = keypoint_array[13, :2] - keypoint_array[17, :2]\n",
    "\n",
    "            row[\"thumb_index_cos\"] = cos(thumb_knuckle, index_knuckle)\n",
    "            row[\"thumb_palm_cos\"] = cos(thumb_knuckle, palm_knuckle)\n",
    "            row[\"dist_index\"] = np.linalg.norm(keypoint_array[8, :2] - keypoint_array[5, :2]) / palm_height\n",
    "            row[\"dist_middle\"] = np.linalg.norm(keypoint_array[12, :2] - keypoint_array[9, :2]) / palm_height\n",
    "            row[\"dist_ring\"] = np.linalg.norm(keypoint_array[16, :2] - keypoint_array[13, :2]) / palm_height\n",
    "            row[\"dist_little\"] = np.linalg.norm(keypoint_array[20, :2] - keypoint_array[17, :2]) / palm_height\n",
    "\n",
    "            row[\"fold_thumb\"] = row[\"thumb_palm_cos\"] < 0.2\n",
    "            row[\"fold_index\"] = row[\"dist_index\"] < 0.5\n",
    "            row[\"fold_middle\"] = row[\"dist_middle\"] < 0.5\n",
    "            row[\"fold_ring\"] = row[\"dist_ring\"] < 0.5\n",
    "            row[\"fold_little\"] = row[\"dist_little\"] < 0.5\n",
    "\n",
    "            rows.append(row)\n",
    "    return rows\n",
    "\n",
    "\n",
    "def data2df(data_path, image_dir, split, label_info_mapping, csv_path=None):\n",
    "    \"\"\"\n",
    "    각 split의 keypoint 및 label 데이터를 처리하여 csv로 저장하고 data frame을 반환\n",
    "    \"\"\"\n",
    "    \n",
    "    print(data_path)\n",
    "    print(image_dir)\n",
    "    print(split)\n",
    "    \n",
    "    '''ego-vision\\new_jsons\\train\n",
    "       ego-vision\n",
    "       train'''\n",
    "    \n",
    "    data_list = os.listdir(data_path)\n",
    "    print(len(data_list))\n",
    "    image_dir = os.path.join(image_dir, split)\n",
    "    \n",
    "    blob_detector = make_blob_detector()\n",
    "    \n",
    "    print(\"Preprocessing\")\n",
    "    rows = []\n",
    "    for file_name in tqdm(data_list, split):\n",
    "        json_path = os.path.join(data_path, file_name)\n",
    "        json_path +=  '/' + str(file_name) + '.json'\n",
    "        json_path = json_path.replace('\\\\', '/')\n",
    "        with open(json_path) as f:\n",
    "            file_info = json.load(f)\n",
    "        frame_rows = preprocess_file_info(file_info, image_dir, split, label_info_mapping, blob_detector, False)\n",
    "        flip_frame_row = preprocess_file_info(file_info, image_dir, split, label_info_mapping, blob_detector, True)\n",
    "        if frame_rows[0][\"id\"] in (490, 586, 596, 613):\n",
    "            continue\n",
    "        rows.extend(frame_rows)\n",
    "        rows.extend(flip_frame_row)\n",
    "        \n",
    "    df = pd.DataFrame(rows).sort_values(\"id\").reset_index(drop=True)\n",
    "    if csv_path is not None:\n",
    "        df.to_csv(csv_path, index=False, encoding=\"cp949\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16e68f3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego-vision\\new_jsons\\train\n",
      "ego-vision\n",
      "train\n",
      "649\n",
      "Preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████| 649/649 [01:40<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego-vision\\new_jsons\\test\n",
      "ego-vision\n",
      "test\n",
      "217\n",
      "Preprocessing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████████████████████████████████████████████████████████████████████| 217/217 [00:33<00:00,  6.42it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = \"ego-vision\"\n",
    "new_json_path = os.path.join(data_path, \"new_jsons\")\n",
    "\n",
    "submission_test_path = \".\"\n",
    "os.makedirs(submission_test_path, exist_ok=True)\n",
    "os.chdir(submission_test_path)\n",
    "\n",
    "\"\"\"\n",
    "pose_name 정보를 좀더 구체적으로 수정함\n",
    "1. 약속 class를 엄지의 위치에 따라 약속1, 약속2로 나눔\n",
    "2. '숫자 1', '숫자1'과 같이 숫자 클래스가 공백으로 나누어져있기에 이를 병합\n",
    "3. 동그라미가 한손일 때와 양손일 때의 패턴의 차이가 크기에 이를 나눔\n",
    "4. 손하트가 my_hand와 your_hand의 차이가 크기에 이를 나눔\n",
    "=> pose_name 종류의 수가 41개로 바뀜\n",
    "\"\"\"\n",
    "label_info = pd.read_csv(os.path.join(data_path, \"hand_gesture_pose.csv\"))\n",
    "label_info.pose_name = label_info.pose_name.str.replace(\"숫자 \", \"숫자\")\n",
    "\n",
    "label_info.loc[label_info.pose_id == 29, \"pose_name\"] = \"약속1\"\n",
    "label_info.loc[label_info.pose_id == 54, \"pose_name\"] = \"약속1\"\n",
    "label_info.loc[label_info.pose_id == 79, \"pose_name\"] = \"약속1\"\n",
    "label_info.loc[label_info.pose_id == 129, \"pose_name\"] = \"약속1\"\n",
    "label_info.loc[label_info.pose_id == 154, \"pose_name\"] = \"약속1\"\n",
    "label_info.loc[label_info.pose_id == 49, \"pose_name\"] = \"약속2\"\n",
    "label_info.loc[label_info.pose_id == 74, \"pose_name\"] = \"약속2\"\n",
    "label_info.loc[label_info.pose_id == 124, \"pose_name\"] = \"약속2\"\n",
    "label_info.loc[label_info.pose_id == 149, \"pose_name\"] = \"약속2\"\n",
    "label_info.loc[label_info.pose_id == 174, \"pose_name\"] = \"약속2\"\n",
    "\n",
    "\n",
    "label_info.loc[label_info.pose_id == 90, \"pose_name\"] = \"동그라미-양손\"\n",
    "label_info.loc[label_info.pose_id == 190, \"pose_name\"] = \"동그라미-양손\"\n",
    "label_info.loc[label_info.pose_id == 145, \"pose_name\"] = \"손하트-yourhand\"\n",
    "assert label_info.pose_name.value_counts().shape[0] == 41 # 수정한 pose_name를 확인\n",
    "\n",
    "label_info_mappnig = {row.pop(\"pose_id\"): row for row in label_info.to_dict(\"records\")}\n",
    "train_data_path = os.path.join(data_path, \"train\")\n",
    "train_new_json_path = os.path.join(new_json_path, \"train\")\n",
    "train_df = data2df(train_new_json_path, data_path, \"train\", label_info_mappnig, \"train_annotation_frame.csv\")\n",
    "\n",
    "test_data_path = os.path.join(data_path, \"test\")\n",
    "test_new_json_path = os.path.join(new_json_path, \"test\")\n",
    "test_df = data2df(test_new_json_path, data_path, \"test\", label_info_mappnig, \"test_annotation_frame.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30bb39d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bbox(image, bbox_xyxy):\n",
    "    \"\"\"\n",
    "    1. bbox 확장 방법\n",
    "        Fixed pixel 확장: 100픽셀 확장\n",
    "    2. bbox clipping: bbox가 이미지 영역을 넘어갈 때 처리 방법\n",
    "        zero-padded bbox\n",
    "    \"\"\"\n",
    "    thr = 100\n",
    "    bbox_xyxy[0] -= thr\n",
    "    bbox_xyxy[2] += thr\n",
    "    bbox_xyxy[1] -= thr\n",
    "    bbox_xyxy[3] += thr\n",
    "    new_xyxy = bbox_xyxy\n",
    "    image = image.crop(new_xyxy)\n",
    "    return image\n",
    "\n",
    "\n",
    "class CsvDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Preprocessing을 거쳐 만들어진 csv 파일을 활용해 CLIP에 사용할 Dataset 생성\n",
    "    \"\"\"\n",
    "    def __init__(self, image_root, csv_path, transform=None) -> None:\n",
    "        super().__init__()\n",
    "        self.image_root = image_root\n",
    "        self.transform = transform\n",
    "        self.data_info = pd.read_csv(csv_path, encoding=\"cp949\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.data_info.iloc[index]\n",
    "        file_id = int(item.id)\n",
    "        img_num = item.img_num\n",
    "        img_path = os.path.join(self.image_root, f\"{file_id}/{img_num}.png\")\n",
    "        image = pil_loader(img_path)\n",
    "        if item.flip:\n",
    "            image = image.transpose(method=Image.FLIP_LEFT_RIGHT)\n",
    "        bbox_xyxy = np.array([item.one_bbox_0, item.one_bbox_1, item.one_bbox_3, item.one_bbox_4])\n",
    "        image = process_bbox(image, bbox_xyxy)\n",
    "        image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_info.shape[0]\n",
    "\n",
    "\n",
    "def get_features(dataset):\n",
    "    \"\"\"\n",
    "    데이터 저장을 위한 CLIP feature 생성\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(DataLoader(dataset, batch_size=100, num_workers=0)):\n",
    "            features = model.encode_image(images.to(device))\n",
    "            all_features.append(features)\n",
    "    return torch.cat(all_features).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc8a8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 353976522/353976522 [00:52<00:00, 6681305.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [21:54<00:00,  9.46s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [07:37<00:00,  9.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "import clip\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "\n",
    "train = CsvDataset(os.path.join(data_path, \"train\"), \"train_annotation_frame.csv\", preprocess)\n",
    "test = CsvDataset(os.path.join(data_path, \"test\"), \"test_annotation_frame.csv\", preprocess)\n",
    "\n",
    "# Calculate the image features\n",
    "\n",
    "train_features = get_features(train)\n",
    "train_clip_features = pd.DataFrame(train_features)\n",
    "train_clip_features.columns = [f\"clip_bbox_feature_{i}\" for i in range(train_features.shape[1])]\n",
    "pd.concat((train.data_info.id, train.data_info.img_num, train.data_info.bbox_num, train.data_info.flip, train_clip_features), axis=1).to_csv(\"train_annotation_clip_bbox100_frame.csv\", index=False)\n",
    "\n",
    "test_features = get_features(test)\n",
    "test_clip_features = pd.DataFrame(test_features)\n",
    "test_clip_features.columns = [f\"clip_bbox_feature_{i}\" for i in range(test_features.shape[1])]\n",
    "pd.concat((test.data_info.id, test.data_info.img_num, test.data_info.bbox_num, test.data_info.flip, test_clip_features), axis=1).to_csv(\"test_annotation_clip_bbox100_frame.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbc56030",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotation_path = \"train_annotation_frame.csv\"\n",
    "train_annotation_clip_bbox_path = \"train_annotation_clip_bbox100_frame.csv\"\n",
    "\n",
    "data_test_path = os.path.join(data_path, \"test\")\n",
    "test_annotation_path = \"test_annotation_frame.csv\"\n",
    "test_annotation_clip_bbox_path = \"test_annotation_clip_bbox100_frame.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_annotation_path, encoding=\"cp949\")\n",
    "train_df_clip_bbox = pd.read_csv(train_annotation_clip_bbox_path)\n",
    "\n",
    "test_df = pd.read_csv(test_annotation_path, encoding=\"cp949\")\n",
    "test_df_clip_bbox = pd.read_csv(test_annotation_clip_bbox_path)\n",
    "\n",
    "train_df = train_df.merge(train_df_clip_bbox, on=[\"id\", \"img_num\", \"bbox_num\", \"flip\"])\n",
    "test_df = test_df.merge(test_df_clip_bbox, on=[\"id\", \"img_num\", \"bbox_num\", \"flip\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "751c9828",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"n_hands\"] = pd.Categorical(train_df[\"n_hands\"])\n",
    "test_df[\"n_hands\"] = pd.Categorical(test_df[\"n_hands\"])\n",
    "\n",
    "features = \\\n",
    "    [f\"diff_{i}\" for i in range(630)] + \\\n",
    "    [f\"dist_{i}\" for i in range(210)] + \\\n",
    "    [f\"cos_{i}\" for i in range(27)] + \\\n",
    "    [f\"sin_{i}\" for i in range(27)] + \\\n",
    "    [f\"sin_abs_{i}\" for i in range(27)] + \\\n",
    "    [f\"clip_bbox_feature_{i}\" for i in range(512)] + \\\n",
    "    [\"n_blob_keypoints\", \"n_hands\", \"bbox_w\", \"bbox_h\", \"one_bbox_w\", \"one_bbox_h\"] + \\\n",
    "    [\"thumb_index_cos\", \"thumb_palm_cos\", \"fold_thumb\", \"fold_index\", \"fold_middle\", \"fold_ring\", \"fold_little\"] + \\\n",
    "    [\"pw_max_diff\", \"index_move_mean\", \"index_move_x_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8af226f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_df, test_df, features, target_col, path=\"log\", add_params={}):\n",
    "    print(\"Start training\")\n",
    "    print(f\"Target: {target_col}\")\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    train_df[target_col] = pd.Categorical(train_df[target_col])\n",
    "\n",
    "    x_train = train_df[features]\n",
    "    y_train = train_df[target_col].cat.codes\n",
    "    num_class = len(set(y_train))\n",
    "\n",
    "    dtrain = lgb.Dataset(x_train, label=y_train)\n",
    "\n",
    "    x_test = test_df[features]\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"num_class\": num_class,\n",
    "        \"verbosity\": -1,\n",
    "    }\n",
    "    params.update(add_params)\n",
    "    train_df[f\"pred_{target_col}\"] = pd.Categorical(train_df[target_col])\n",
    "\n",
    "    model = lgb.train(params, dtrain)\n",
    "    result = model.predict(x_test)\n",
    "    test_df[f\"pred_{target_col}\"] = pd.Categorical(result.argmax(-1))\n",
    "\n",
    "    if target_col == \"hand_type\":\n",
    "        new_df = pd.concat((test_df[[\"id\"]], pd.DataFrame(result)), axis=1)\n",
    "        flip_temp = new_df[test_df.flip].copy()\n",
    "        new_df.loc[test_df.flip, 1] = flip_temp.loc[:, 2]\n",
    "        new_df.loc[test_df.flip, 2] = flip_temp.loc[:, 1]\n",
    "    else:\n",
    "        new_df = pd.concat((test_df[[\"id\"]], pd.DataFrame(result)), axis=1)\n",
    "    merged_df = new_df.groupby(\"id\", as_index=False).mean()\n",
    "    result = merged_df.iloc[:, 1:(1+num_class)].to_numpy()\n",
    "    y_pred = result.argmax(-1)\n",
    "\n",
    "    result_df = pd.concat((merged_df.id, pd.DataFrame(np.concatenate((y_pred[:, None], result), 1))), ignore_index=True, axis=1)\n",
    "    result_df.columns = [\"id\", f\"pred_{target_col}\"] + train_df[target_col].cat.categories.to_list()\n",
    "\n",
    "    result_df.to_csv(f\"{path}/result_test_{target_col}.csv\", index=False)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12c5bd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Target: gesture_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:02,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Target: hand_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:07,  4.15s/it]C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Target: pose_name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [09:44, 194.85s/it]\n"
     ]
    }
   ],
   "source": [
    "save_path = \"submission\"\n",
    "targets = (\"gesture_type\", \"hand_type\", \"pose_name\")\n",
    "train_add_params = [\n",
    "    {\n",
    "        \"feature_pre_filter\": False,\n",
    "        \"lambda_l1\": 1.7657137779105168e-06,\n",
    "        \"lambda_l2\": 2.3530332427385596e-06,\n",
    "        \"num_leaves\": 6,\n",
    "        \"feature_fraction\": 0.4,\n",
    "        \"bagging_fraction\": 0.6541928796037666,\n",
    "        \"bagging_freq\": 5,\n",
    "        \"min_child_samples\": 20\n",
    "    },\n",
    "    {\n",
    "        \"feature_pre_filter\": False,\n",
    "        \"lambda_l1\": 1.5204270129130175e-08,\n",
    "        \"lambda_l2\": 0.31158648353398066,\n",
    "        \"num_leaves\": 140,\n",
    "        \"feature_fraction\": 0.41600000000000004,\n",
    "        \"bagging_fraction\": 0.7616580256435892,\n",
    "        \"bagging_freq\": 4,\n",
    "        \"min_child_samples\": 20\n",
    "    },\n",
    "    {\n",
    "        \"num_boost_round\": 10000,\n",
    "        \"feature_pre_filter\": False,\n",
    "        \"min_data_in_leaf\": 100,\n",
    "        \"lambda_l1\": 8.685219254418955e-07,\n",
    "        \"lambda_l2\": 8.519494831720772,\n",
    "        \"num_leaves\": 141,\n",
    "        \"feature_fraction\": 0.41600000000000004,\n",
    "        \"bagging_fraction\": 0.44262163491880324,\n",
    "        \"bagging_freq\": 1,\n",
    "    }\n",
    "]\n",
    "\n",
    "result_dfs = {}\n",
    "for target_col, add_params in tqdm(zip(targets, train_add_params)):\n",
    "    result_dfs[target_col] = train_model(train_df, test_df, features, target_col, save_path, add_params)\n",
    "    features.append(f\"pred_{target_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b46a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_col in (\"hand_type\", \"gesture_type\"):\n",
    "    probs = result_dfs[target_col].iloc[:, 2:].to_numpy()\n",
    "    one_hot = np.zeros_like(probs)\n",
    "    for i, p in enumerate(probs.argmax(-1)):\n",
    "        one_hot[i, p] = 1.\n",
    "    result_dfs[target_col].iloc[:, 2:] = one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1cf134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submision_path = os.path.join(data_path, \"sample_submission.csv\")\n",
    "submission = pd.read_csv(sample_submision_path)\n",
    "for row in label_info.to_dict(\"records\"):\n",
    "    col_prob = np.ones(result_dfs[target_col].shape[0], dtype=float)\n",
    "    for target_col in targets:\n",
    "        col_prob *= result_dfs[target_col][row[target_col]]\n",
    "    submission[f\"Label_{row['pose_id']}\"] = col_prob\n",
    "submission.iloc[:, 1:] = submission.iloc[:, 1:].to_numpy() / np.sum(submission.iloc[:, 1:].to_numpy(), axis=1, keepdims=True)\n",
    "submission.to_csv(f\"{save_path}/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4508d5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
