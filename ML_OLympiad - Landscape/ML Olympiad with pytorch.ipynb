{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62e484a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import cv2\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchcontrib.optim import SWA\n",
    "from torchensemble import VotingClassifier\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eccb081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepath = './train/'\n",
    "test_filepath = './test/'\n",
    "\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "\n",
    "train_df['filepath'] = train_filepath + train_df['image']\n",
    "test_df['image_path'] = './test/' + test_df['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9975165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_label(y):\n",
    "    values = np.array(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values).reshape(len(values), 1)\n",
    "    return integer_encoded, label_encoder\n",
    "\n",
    "target, label_encoder = prepare_label(train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "222896a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    transforms.Resize((300, 300)),\n",
    "])\n",
    "\n",
    "# transforms_train = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "#     transforms.RandomChoice([\n",
    "#         transforms.RandomResizedCrop(224),\n",
    "#         transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n",
    "#         transforms.RandomAffine(degrees=15, translate= (0.2, 0.2),\n",
    "#                                scale = (0.8, 1.2), shear = 15,\n",
    "#                                resample = Image.BILINEAR)])\n",
    "#     ])\n",
    "\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomChoice([\n",
    "#                 transforms.RandomResizedCrop(64),\n",
    "#                 transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n",
    "#                 transforms.RandomAffine(degrees=15, translate=(0.2, 0.2),\n",
    "#                                         scale=(0.8, 1.2), shear=15,\n",
    "#                                         resample=Image.BILINEAR)]),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                             std=[0.229, 0.224, 0.225])    \n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf1d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "class Img_Dataset(Dataset):\n",
    "    def __init__(self, file_list, transform):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e04dd75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.ImageFolder('./train/', transform = transformer)\n",
    "# validset = torchvision.datasets.ImageFolder('./seg_test/', transform=transformer)\n",
    "testset = Img_Dataset(test_df['image_path'].values.tolist(), transform = transformer)\n",
    "trainloader = DataLoader(trainset, batch_size = 15, shuffle = True)\n",
    "testloader = DataLoader(testset, batch_size = 15)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e368dc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7cc1c75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Model\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Epoch : [1] loss : 0.403\n",
      "Epoch : [2] loss : 0.279\n",
      "Epoch : [3] loss : 0.236\n",
      "Epoch : [4] loss : 0.200\n",
      "Epoch : [5] loss : 0.173\n",
      "Epoch : [6] loss : 0.142\n",
      "Epoch : [7] loss : 0.122\n",
      "Epoch : [8] loss : 0.107\n",
      "Epoch : [9] loss : 0.088\n",
      "Epoch : [10] loss : 0.083\n",
      "Epoch : [11] loss : 0.073\n",
      "Epoch : [12] loss : 0.068\n",
      "Epoch : [13] loss : 0.065\n",
      "Epoch : [14] loss : 0.059\n",
      "Epoch : [15] loss : 0.056\n",
      "Epoch : [16] loss : 0.054\n",
      "Epoch : [17] loss : 0.052\n",
      "Epoch : [18] loss : 0.050\n",
      "Epoch : [19] loss : 0.047\n",
      "Epoch : [20] loss : 0.040\n",
      "Epoch : [21] loss : 0.045\n",
      "Epoch : [22] loss : 0.038\n",
      "Epoch : [23] loss : 0.043\n",
      "Epoch : [24] loss : 0.039\n",
      "Epoch : [25] loss : 0.037\n",
      "Epoch : [26] loss : 0.036\n",
      "Epoch : [27] loss : 0.035\n",
      "Epoch : [28] loss : 0.034\n",
      "Epoch : [29] loss : 0.032\n",
      "Epoch : [30] loss : 0.032\n",
      "Epoch : [31] loss : 0.030\n",
      "Epoch : [32] loss : 0.033\n",
      "Epoch : [33] loss : 0.028\n",
      "Epoch : [34] loss : 0.029\n",
      "Epoch : [35] loss : 0.027\n",
      "Epoch : [36] loss : 0.028\n",
      "Epoch : [37] loss : 0.024\n",
      "Epoch : [38] loss : 0.028\n",
      "Epoch : [39] loss : 0.026\n",
      "Epoch : [40] loss : 0.026\n",
      "Epoch : [41] loss : 0.027\n",
      "Epoch : [42] loss : 0.024\n",
      "Epoch : [43] loss : 0.025\n",
      "Epoch : [44] loss : 0.024\n",
      "Epoch : [45] loss : 0.025\n",
      "Epoch : [46] loss : 0.023\n",
      "Epoch : [47] loss : 0.020\n",
      "Epoch : [48] loss : 0.024\n",
      "Epoch : [49] loss : 0.022\n",
      "Epoch : [50] loss : 0.022\n",
      "Epoch : [51] loss : 0.020\n",
      "Epoch : [52] loss : 0.022\n",
      "Epoch : [53] loss : 0.020\n",
      "Epoch : [54] loss : 0.021\n",
      "Epoch : [55] loss : 0.020\n",
      "Epoch : [56] loss : 0.017\n",
      "Epoch : [57] loss : 0.023\n",
      "Epoch : [58] loss : 0.017\n",
      "Epoch : [59] loss : 0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 5.5228e-01, -6.7893e-01, -1.2036e-01],\n",
      "          [ 7.0604e-01, -7.4363e-01, -2.6014e-01],\n",
      "          [-6.7103e-02, -2.3337e-01, -4.9352e-02]],\n",
      "\n",
      "         [[ 1.6774e+00, -1.5389e+00,  2.3472e-02],\n",
      "          [ 1.5085e+00, -1.4821e+00, -9.3046e-02],\n",
      "          [ 2.0320e-01, -5.2762e-02,  1.2994e-01]],\n",
      "\n",
      "         [[ 3.6452e-01, -3.0450e-01,  7.1253e-02],\n",
      "          [ 5.1432e-01, -4.2652e-01, -5.5994e-02],\n",
      "          [ 5.0669e-02, -4.0043e-02,  1.1402e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.6185e-01, -1.3588e-01,  2.5022e-02],\n",
      "          [-2.6496e+00, -3.7629e-01,  1.1743e-01],\n",
      "          [-4.1378e-01, -8.3885e-02,  1.2049e-01]],\n",
      "\n",
      "         [[ 1.7006e-01,  1.2990e-02,  1.2456e-01],\n",
      "          [-1.0775e+00,  1.5183e-03,  1.8688e-01],\n",
      "          [ 4.5333e-02,  1.3548e-01,  1.9922e-01]],\n",
      "\n",
      "         [[-1.8947e-02, -2.4229e-02, -1.6753e-02],\n",
      "          [-5.6020e-01, -8.6350e-02,  3.3448e-02],\n",
      "          [-2.3694e-01, -1.0895e-01, -3.8701e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0813e-01,  1.3088e+00,  4.7054e-01],\n",
      "          [ 1.2066e+00,  1.7408e+00,  5.9334e-01],\n",
      "          [ 3.5420e-01,  3.8799e-01,  1.4561e-01]],\n",
      "\n",
      "         [[-7.7879e-01, -1.0660e+00, -4.0923e-01],\n",
      "          [-8.8188e-01, -1.1459e+00, -3.4007e-01],\n",
      "          [-4.0271e-01, -5.2657e-01, -1.3684e-01]],\n",
      "\n",
      "         [[-3.5968e-01, -4.5936e-01, -8.4735e-02],\n",
      "          [-3.5785e-01, -5.0818e-01,  5.9945e-02],\n",
      "          [-1.0894e-01, -1.1721e-01,  5.3902e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.0101e-01, -3.4625e-02, -2.7801e-02],\n",
      "          [-4.7785e-01, -4.5588e-01, -7.6533e-02],\n",
      "          [ 7.1205e-01,  4.4502e-01,  1.5892e-01]],\n",
      "\n",
      "         [[-1.7336e-01, -2.0636e-01,  2.2204e-02],\n",
      "          [-2.4803e+00, -2.3398e+00, -1.3260e-01],\n",
      "          [ 2.4876e+00,  2.3954e+00,  1.7442e-01]],\n",
      "\n",
      "         [[-3.9492e-02, -2.7499e-02,  3.9952e-02],\n",
      "          [-1.9912e-01, -2.6209e-01, -7.6895e-02],\n",
      "          [ 3.8593e-01,  2.2595e-01,  1.0597e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.4196e-01, -2.0990e-02, -1.1582e-01],\n",
      "          [-2.6568e-01,  6.7497e-01,  1.5292e-01],\n",
      "          [-5.2748e-01,  1.0728e-01, -1.7936e-02]],\n",
      "\n",
      "         [[-2.8014e+00, -1.2341e-01, -6.0163e-02],\n",
      "          [-4.8187e-03,  2.7739e+00,  2.0222e-01],\n",
      "          [-2.5769e-01,  3.2138e-01,  2.7985e-02]],\n",
      "\n",
      "         [[-3.4443e-01,  1.0241e-01, -9.3005e-02],\n",
      "          [-1.2899e-01,  3.4961e-01,  8.1356e-02],\n",
      "          [-2.2318e-01,  1.7917e-01,  1.4465e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.2196e-01, -3.3494e-01, -1.1971e-01],\n",
      "          [-2.0436e-01,  1.8496e-02,  1.8614e-01],\n",
      "          [ 1.6853e-02,  5.7019e-02,  6.9445e-02]],\n",
      "\n",
      "         [[-1.8488e+00, -1.1661e+00, -2.9138e-01],\n",
      "          [-7.4050e-01, -4.0088e-01,  2.4084e-01],\n",
      "          [-7.6637e-02,  1.3302e-01,  1.2954e-01]],\n",
      "\n",
      "         [[-1.1719e+00, -8.1242e-01, -4.4127e-01],\n",
      "          [-3.7474e-01, -1.5595e-01,  2.3318e-02],\n",
      "          [-1.6059e-01, -1.2751e-01, -2.4111e-02]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.8682,  2.8161, 10.1850,  2.7147,  3.3760,  4.5403,  2.4478,  2.9007,\n",
      "         3.3080,  3.1371,  2.3027,  9.1545,  1.0475,  1.0132,  9.2771,  8.5072,\n",
      "         0.5237,  4.0323,  4.5928,  4.0315,  1.4780,  1.2753,  7.7731,  4.0652,\n",
      "         1.8817,  4.7647,  2.3384,  0.5368,  6.8995,  3.3760,  2.3568,  3.4907,\n",
      "         0.4595,  3.6863, 11.0252,  1.7179,  6.2394,  3.0920,  3.3711,  3.5761],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([  0.7292,  -3.4487,   2.1060,  -3.8857,  -5.0490,   0.8653,  -3.3761,\n",
      "          2.6246,  -6.6341,   3.0738,   2.2998,   0.6264,   1.6399,   1.4879,\n",
      "         -0.2261,   2.6721,  -0.4250,  -5.5635,   1.7269,   2.8538,   1.9103,\n",
      "          1.3404, -13.4792,   1.4569,   2.3108,   9.5005,   2.3787,  -0.6352,\n",
      "          1.9561,   7.5419,  -2.2398,   2.4391,   6.7929,   8.2529,  -2.1371,\n",
      "          2.8726, -11.2431,   2.4112,   2.4070,   8.4854], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 3.3452e-02,  1.2727e-01,  2.3497e-01],\n",
      "          [ 1.6499e-01, -2.1484e+00,  3.1053e-01],\n",
      "          [-6.9240e-02,  3.4614e-01,  2.1341e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9990e-01,  3.8325e-02, -2.9570e-01],\n",
      "          [ 3.0180e-01,  1.2427e+00, -3.2986e-01],\n",
      "          [-1.1874e-01, -1.1059e-01, -2.1356e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4020e-02,  4.2784e-01, -3.2928e-01],\n",
      "          [ 5.0951e-01,  1.8576e+00, -7.8286e-01],\n",
      "          [-4.4522e-01, -7.6117e-01,  5.0646e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1465e-01, -2.6202e-01, -3.8799e-01],\n",
      "          [-2.3855e-02,  1.1847e+00, -3.1702e-02],\n",
      "          [ 5.1054e-02,  2.9930e-01, -1.3302e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1625e-01,  7.0722e-02, -2.3742e-01],\n",
      "          [-8.5308e-02,  1.2228e+00,  2.7684e-01],\n",
      "          [-7.0695e-02,  1.8303e-01,  7.3936e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4991e-01, -7.7313e-02, -3.2161e-01],\n",
      "          [ 1.4573e-01,  1.3646e+00, -2.6627e-01],\n",
      "          [-4.0999e-02, -1.6673e-01, -3.2474e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2258e-01,  3.6025e-01, -6.6184e-02],\n",
      "          [ 3.5269e-01,  1.0906e+00, -1.8458e-01],\n",
      "          [ 2.5298e-03, -1.2588e-01, -2.7137e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3746e-01, -4.1407e-01, -2.6370e-01],\n",
      "          [-4.2425e-02,  1.5773e+00, -3.4181e-01],\n",
      "          [ 3.4480e-02, -2.2899e-01, -2.8358e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3770e-01,  7.6285e-02, -4.3449e-01],\n",
      "          [ 7.5041e-02,  4.5699e-01, -4.3018e-01],\n",
      "          [-1.7729e-01, -5.3643e-02, -2.2800e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1543e-01, -6.0290e-01, -1.6343e-01],\n",
      "          [ 1.0723e-02, -8.8491e-01,  8.1850e-02],\n",
      "          [ 1.3329e-01,  3.7825e-01,  4.1091e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.6413e-01, -1.6527e-01, -1.1696e-01],\n",
      "          [ 9.3510e-01, -4.0618e-01,  6.8892e-02],\n",
      "          [-2.4080e-01, -1.1532e-01, -2.3981e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.3696e-01, -1.8038e-01,  1.7042e-01],\n",
      "          [-7.9770e-01, -7.1305e-01, -1.4906e-02],\n",
      "          [ 4.0929e-01,  2.5004e-01,  6.3530e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1494e-01, -4.0821e-01, -3.5629e-01],\n",
      "          [-7.7938e-01,  1.0141e+00,  2.5087e-01],\n",
      "          [-1.5036e-02, -1.0334e-01, -1.4286e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.5969e-01, -1.0377e+00,  4.2639e-01],\n",
      "          [ 4.7500e-01,  3.9761e-01,  1.7375e-01],\n",
      "          [-3.5146e-01, -1.7304e-01,  2.5309e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0762e-01, -4.5407e-01,  6.1686e-02],\n",
      "          [-1.6192e-01, -7.8964e-01,  3.4796e-01],\n",
      "          [ 3.8560e-01,  4.2722e-01,  2.4299e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.3033e-01, -4.6344e-01,  6.5351e-02],\n",
      "          [ 1.0636e-02, -6.3508e-01,  3.9449e-01],\n",
      "          [ 2.6619e-01,  4.2072e-01,  3.2404e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0981e-01,  2.2009e-01, -1.2419e-01],\n",
      "          [ 7.9798e-02,  2.2301e+00, -3.0982e-01],\n",
      "          [-1.4824e-01, -4.4132e-01, -1.6150e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0397e-02,  4.6362e-01,  1.8563e-01],\n",
      "          [ 4.2284e-01,  1.3624e+00,  9.2851e-02],\n",
      "          [ 2.2635e-01,  1.9123e-01,  3.8059e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1943e-01,  1.5199e-01, -1.9576e-01],\n",
      "          [ 3.5339e-01,  1.8408e+00, -5.4149e-01],\n",
      "          [-1.1564e-01, -5.5702e-01, -1.6614e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9307e-01, -6.2168e-01, -1.0540e-01],\n",
      "          [-2.4353e-01, -1.0887e+00,  2.6102e-01],\n",
      "          [ 2.3803e-01,  3.8896e-01,  1.2524e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8849e-02,  4.0062e-01,  3.0559e-01],\n",
      "          [ 1.4581e-01, -1.8806e+00, -1.7852e-02],\n",
      "          [ 1.3594e-01,  1.7087e-01, -2.1114e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4117e-01,  5.0341e-01, -2.5029e-01],\n",
      "          [ 2.3834e-01,  1.7400e+00, -7.0246e-01],\n",
      "          [-5.1479e-01, -8.0329e-01, -2.9500e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4318e-01,  6.7260e-02, -7.8836e-02],\n",
      "          [-1.2370e-01,  1.4519e+00, -2.5552e-01],\n",
      "          [ 9.0546e-02, -6.4139e-02, -3.8339e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6981e-02,  4.7555e-01, -1.4817e-01],\n",
      "          [ 2.7557e-01,  1.7778e+00, -5.9421e-01],\n",
      "          [-5.0204e-01, -7.3520e-01, -9.3019e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.0784e-01, -6.5768e-01,  1.8145e-01],\n",
      "          [-2.9152e-01, -5.3326e-01,  3.0757e-01],\n",
      "          [ 4.6914e-01,  4.1412e-01,  1.6010e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.8119e-02, -1.1568e+00,  1.3258e+00],\n",
      "          [-3.6823e-01, -2.0014e+00,  2.6528e+00],\n",
      "          [ 5.5730e-02, -4.6329e-01,  3.0571e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1358e-01, -3.4849e-01, -1.7457e-01],\n",
      "          [-1.0040e-01,  1.2067e+00, -1.9167e-01],\n",
      "          [-2.1381e-01, -3.7697e-02, -1.1531e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2327e-01, -6.4143e-02, -9.2415e-02],\n",
      "          [ 5.7853e-01,  2.4231e+00, -2.2009e-01],\n",
      "          [-8.6228e-02, -1.0109e-01, -1.4176e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6879e-02, -5.8394e-02, -9.0590e-02],\n",
      "          [-4.7612e-01, -2.3851e+00, -1.7442e-01],\n",
      "          [ 7.4769e-02, -2.5620e-01, -1.3514e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2899e-01,  2.5848e+00,  2.2217e-01],\n",
      "          [-9.0096e-01, -2.1529e+00, -2.8904e-01],\n",
      "          [ 1.7416e-01, -5.1584e-01, -1.4026e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7153e-02, -1.0479e-01,  3.6029e-01],\n",
      "          [ 1.7865e-01, -8.5378e-01,  2.2514e-01],\n",
      "          [ 3.3056e-01,  2.3932e-01,  4.2649e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6225e-01,  2.4519e-01,  8.3703e-02],\n",
      "          [-3.1438e+00,  1.2219e-01,  1.7044e-01],\n",
      "          [ 1.4340e-01,  1.6035e-01,  6.6567e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2776e-01, -4.1736e-01, -7.5568e-01],\n",
      "          [-1.0937e-01,  8.6559e-01, -3.3544e-01],\n",
      "          [ 2.2146e-01, -3.4842e-01, -2.2538e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3255e-01, -9.1598e-01,  1.9496e-01],\n",
      "          [ 2.8358e+00, -2.1593e+00, -4.3039e-01],\n",
      "          [ 2.1440e-01, -4.7246e-01,  1.0624e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6949e-01, -6.8343e-01,  9.7393e-02],\n",
      "          [-1.6133e-01, -1.2152e+00,  3.0901e-01],\n",
      "          [-1.4228e-01, -5.9514e-01,  1.6474e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0636e-01, -2.4382e-01, -2.8583e-01],\n",
      "          [-3.5114e-01,  1.3459e+00,  4.0717e-02],\n",
      "          [-8.7516e-02, -2.6479e-01, -6.1252e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7584e-01,  4.9012e-01,  6.5571e-02],\n",
      "          [-2.2539e-02,  9.7707e-01, -2.0571e-01],\n",
      "          [-5.3005e-01, -6.2504e-01, -6.1134e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1771e-01, -3.1357e+00,  2.9126e-01],\n",
      "          [ 2.3121e-01,  1.0511e-01,  1.1774e-01],\n",
      "          [-9.9632e-04,  1.9266e-01, -1.8789e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2255e-01, -1.3746e-01,  7.6506e-02],\n",
      "          [ 5.0474e-01, -1.7617e+00,  5.8995e-03],\n",
      "          [ 2.1676e-01,  1.0202e-01,  1.5157e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5529e-01,  2.4942e+00,  7.8160e-01],\n",
      "          [-7.4391e-01, -2.1405e+00, -7.6646e-01],\n",
      "          [ 1.3780e-01, -3.0727e-01,  3.1016e-02]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.9538, 1.1919, 3.8614, 0.9033, 1.0248, 1.0867, 0.7136, 3.8314, 0.9527,\n",
      "        1.1140, 2.2831, 5.9129, 2.2485, 0.9025, 4.0031, 2.3235, 3.1336, 1.0000,\n",
      "        2.9701, 1.3266, 2.1031, 3.0029, 1.3564, 3.4689, 1.4311, 5.1478, 1.8722,\n",
      "        2.0773, 4.5231, 4.3463, 0.0643, 2.2885, 0.2448, 4.2979, 7.5031, 3.2447,\n",
      "        1.0571, 3.1534, 1.9683, 3.4140], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.2576,  0.7249,  2.0937,  0.1751, -0.6038,  1.8970,  0.0350,  1.8260,\n",
      "        -0.8337,  1.0300, -0.9542, -4.3650,  0.6825,  1.5079, -0.4560, -1.1847,\n",
      "         3.3268, -0.0882,  1.5890,  1.5290,  1.9318,  2.4749, -2.7478,  1.7401,\n",
      "         1.4713,  1.8510, -0.2629,  2.1953,  0.5287,  2.0224,  2.0529,  1.9371,\n",
      "        -0.0112,  1.7229, -3.9140,  1.0746, -0.4134,  1.8140,  1.1647,  1.9232],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 1.0598e-01]],\n",
      "\n",
      "         [[-1.0320e+00]],\n",
      "\n",
      "         [[-7.0240e-02]],\n",
      "\n",
      "         [[-7.4855e-01]],\n",
      "\n",
      "         [[ 2.2378e-01]],\n",
      "\n",
      "         [[-3.9121e-02]],\n",
      "\n",
      "         [[-3.5777e-01]],\n",
      "\n",
      "         [[ 7.7420e-02]],\n",
      "\n",
      "         [[ 3.1228e-02]],\n",
      "\n",
      "         [[ 5.0640e-02]],\n",
      "\n",
      "         [[-1.9303e-01]],\n",
      "\n",
      "         [[ 7.9371e-02]],\n",
      "\n",
      "         [[-4.6788e-02]],\n",
      "\n",
      "         [[ 1.8322e-01]],\n",
      "\n",
      "         [[-2.6567e-04]],\n",
      "\n",
      "         [[-2.2547e-01]],\n",
      "\n",
      "         [[-6.1575e-01]],\n",
      "\n",
      "         [[ 8.7367e-02]],\n",
      "\n",
      "         [[ 2.9574e-02]],\n",
      "\n",
      "         [[-2.4910e-02]],\n",
      "\n",
      "         [[ 1.8820e-01]],\n",
      "\n",
      "         [[-1.2195e-01]],\n",
      "\n",
      "         [[-2.0251e-01]],\n",
      "\n",
      "         [[-1.0265e-02]],\n",
      "\n",
      "         [[ 1.4741e-02]],\n",
      "\n",
      "         [[-6.2572e-02]],\n",
      "\n",
      "         [[-1.9909e-01]],\n",
      "\n",
      "         [[-4.1833e-01]],\n",
      "\n",
      "         [[ 1.2561e-01]],\n",
      "\n",
      "         [[-1.8521e-01]],\n",
      "\n",
      "         [[ 3.1421e-01]],\n",
      "\n",
      "         [[ 9.3544e-02]],\n",
      "\n",
      "         [[ 1.6205e-01]],\n",
      "\n",
      "         [[-8.9658e-02]],\n",
      "\n",
      "         [[ 2.7431e-01]],\n",
      "\n",
      "         [[ 2.1559e-02]],\n",
      "\n",
      "         [[ 6.2833e-02]],\n",
      "\n",
      "         [[ 1.3667e-01]],\n",
      "\n",
      "         [[ 1.6825e-01]],\n",
      "\n",
      "         [[-2.5706e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6967e-02]],\n",
      "\n",
      "         [[ 1.3703e-01]],\n",
      "\n",
      "         [[-9.5049e-02]],\n",
      "\n",
      "         [[ 3.6348e-01]],\n",
      "\n",
      "         [[-1.1960e-01]],\n",
      "\n",
      "         [[-9.5692e-02]],\n",
      "\n",
      "         [[ 3.7517e-01]],\n",
      "\n",
      "         [[-1.0358e-01]],\n",
      "\n",
      "         [[-1.7808e-01]],\n",
      "\n",
      "         [[ 8.7614e-02]],\n",
      "\n",
      "         [[-2.0087e-01]],\n",
      "\n",
      "         [[-1.3118e-01]],\n",
      "\n",
      "         [[-2.1661e-01]],\n",
      "\n",
      "         [[ 7.6763e-02]],\n",
      "\n",
      "         [[ 1.3980e-02]],\n",
      "\n",
      "         [[-1.3930e-01]],\n",
      "\n",
      "         [[-1.1641e-01]],\n",
      "\n",
      "         [[ 1.4703e-01]],\n",
      "\n",
      "         [[-2.4512e-01]],\n",
      "\n",
      "         [[-4.6575e-01]],\n",
      "\n",
      "         [[ 1.0930e-01]],\n",
      "\n",
      "         [[-3.5451e-01]],\n",
      "\n",
      "         [[ 6.4972e-01]],\n",
      "\n",
      "         [[ 1.6010e-01]],\n",
      "\n",
      "         [[-1.1331e-01]],\n",
      "\n",
      "         [[-2.7538e-01]],\n",
      "\n",
      "         [[ 8.3393e-02]],\n",
      "\n",
      "         [[-1.7239e-01]],\n",
      "\n",
      "         [[ 1.0334e-01]],\n",
      "\n",
      "         [[-1.7672e-01]],\n",
      "\n",
      "         [[ 4.6637e-01]],\n",
      "\n",
      "         [[-5.9777e-02]],\n",
      "\n",
      "         [[ 6.1221e-02]],\n",
      "\n",
      "         [[-2.4280e-01]],\n",
      "\n",
      "         [[-1.8467e-01]],\n",
      "\n",
      "         [[-1.6291e-01]],\n",
      "\n",
      "         [[ 7.0265e-01]],\n",
      "\n",
      "         [[ 8.0747e-02]],\n",
      "\n",
      "         [[-8.7332e-02]],\n",
      "\n",
      "         [[-4.8372e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.4357e-02]],\n",
      "\n",
      "         [[-4.9363e-02]],\n",
      "\n",
      "         [[-3.2311e-02]],\n",
      "\n",
      "         [[-1.6890e-01]],\n",
      "\n",
      "         [[ 4.5780e-02]],\n",
      "\n",
      "         [[-3.8364e-02]],\n",
      "\n",
      "         [[ 2.1763e-01]],\n",
      "\n",
      "         [[-3.1184e-02]],\n",
      "\n",
      "         [[ 1.5593e-02]],\n",
      "\n",
      "         [[ 3.7932e-01]],\n",
      "\n",
      "         [[-3.4854e-03]],\n",
      "\n",
      "         [[-1.5215e-02]],\n",
      "\n",
      "         [[-4.6084e-02]],\n",
      "\n",
      "         [[-4.1611e-02]],\n",
      "\n",
      "         [[ 1.6818e-01]],\n",
      "\n",
      "         [[-6.9141e-02]],\n",
      "\n",
      "         [[ 1.1341e-01]],\n",
      "\n",
      "         [[ 2.6428e-01]],\n",
      "\n",
      "         [[-1.1570e-01]],\n",
      "\n",
      "         [[-2.7953e-01]],\n",
      "\n",
      "         [[ 2.1171e-03]],\n",
      "\n",
      "         [[-2.4295e-01]],\n",
      "\n",
      "         [[-1.5732e-01]],\n",
      "\n",
      "         [[-1.0865e+00]],\n",
      "\n",
      "         [[ 1.2251e-01]],\n",
      "\n",
      "         [[-4.4151e-02]],\n",
      "\n",
      "         [[-1.0084e-01]],\n",
      "\n",
      "         [[-1.1990e-01]],\n",
      "\n",
      "         [[ 5.1763e-02]],\n",
      "\n",
      "         [[-8.5842e-02]],\n",
      "\n",
      "         [[-4.1550e-02]],\n",
      "\n",
      "         [[ 9.1801e-02]],\n",
      "\n",
      "         [[ 3.3081e-02]],\n",
      "\n",
      "         [[ 3.1945e-02]],\n",
      "\n",
      "         [[-7.9490e-03]],\n",
      "\n",
      "         [[-9.7392e-02]],\n",
      "\n",
      "         [[ 1.4771e-01]],\n",
      "\n",
      "         [[-8.6855e-02]],\n",
      "\n",
      "         [[ 3.8175e-02]],\n",
      "\n",
      "         [[-2.0197e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.4798e-02]],\n",
      "\n",
      "         [[-6.5242e-01]],\n",
      "\n",
      "         [[-7.2107e-01]],\n",
      "\n",
      "         [[-5.4284e-01]],\n",
      "\n",
      "         [[ 1.6054e-01]],\n",
      "\n",
      "         [[ 1.1155e-01]],\n",
      "\n",
      "         [[-3.6974e-02]],\n",
      "\n",
      "         [[ 7.1526e-02]],\n",
      "\n",
      "         [[-1.9504e-02]],\n",
      "\n",
      "         [[-2.8359e-02]],\n",
      "\n",
      "         [[ 5.6903e-03]],\n",
      "\n",
      "         [[-1.4179e-01]],\n",
      "\n",
      "         [[-5.8816e-02]],\n",
      "\n",
      "         [[-4.9769e-02]],\n",
      "\n",
      "         [[ 1.6107e-03]],\n",
      "\n",
      "         [[ 1.5271e-01]],\n",
      "\n",
      "         [[-2.0394e-01]],\n",
      "\n",
      "         [[-1.6254e-01]],\n",
      "\n",
      "         [[-2.7750e-02]],\n",
      "\n",
      "         [[-2.7852e-02]],\n",
      "\n",
      "         [[-5.1377e-05]],\n",
      "\n",
      "         [[ 3.5623e-01]],\n",
      "\n",
      "         [[-5.3333e-02]],\n",
      "\n",
      "         [[-5.2055e-01]],\n",
      "\n",
      "         [[ 1.0665e-02]],\n",
      "\n",
      "         [[-7.8704e-02]],\n",
      "\n",
      "         [[-6.9071e-02]],\n",
      "\n",
      "         [[-1.6393e-01]],\n",
      "\n",
      "         [[-5.8578e-02]],\n",
      "\n",
      "         [[ 1.7750e-01]],\n",
      "\n",
      "         [[-1.3904e-02]],\n",
      "\n",
      "         [[ 6.2431e-03]],\n",
      "\n",
      "         [[-5.2502e-02]],\n",
      "\n",
      "         [[-1.5751e-02]],\n",
      "\n",
      "         [[-2.5757e-01]],\n",
      "\n",
      "         [[ 8.0126e-02]],\n",
      "\n",
      "         [[ 3.1536e-02]],\n",
      "\n",
      "         [[-1.2940e-01]],\n",
      "\n",
      "         [[-6.5980e-02]],\n",
      "\n",
      "         [[ 3.4847e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.0260e-02]],\n",
      "\n",
      "         [[-7.2005e-01]],\n",
      "\n",
      "         [[-5.3783e-03]],\n",
      "\n",
      "         [[-7.9472e-01]],\n",
      "\n",
      "         [[ 4.5454e-01]],\n",
      "\n",
      "         [[ 1.7232e-01]],\n",
      "\n",
      "         [[-1.4067e-01]],\n",
      "\n",
      "         [[-1.7911e-01]],\n",
      "\n",
      "         [[ 1.1655e-01]],\n",
      "\n",
      "         [[-1.9288e-02]],\n",
      "\n",
      "         [[-4.0023e-01]],\n",
      "\n",
      "         [[ 4.7092e-02]],\n",
      "\n",
      "         [[-5.1321e-01]],\n",
      "\n",
      "         [[ 1.9056e-01]],\n",
      "\n",
      "         [[ 9.1500e-02]],\n",
      "\n",
      "         [[ 3.4899e-02]],\n",
      "\n",
      "         [[-2.2457e-01]],\n",
      "\n",
      "         [[ 3.7490e-01]],\n",
      "\n",
      "         [[-8.7948e-02]],\n",
      "\n",
      "         [[-1.2576e-01]],\n",
      "\n",
      "         [[-5.1286e-02]],\n",
      "\n",
      "         [[ 2.0784e-01]],\n",
      "\n",
      "         [[-1.0257e-01]],\n",
      "\n",
      "         [[ 7.5105e-02]],\n",
      "\n",
      "         [[ 3.7629e-02]],\n",
      "\n",
      "         [[-1.1931e-01]],\n",
      "\n",
      "         [[-3.1078e-02]],\n",
      "\n",
      "         [[-1.8770e-02]],\n",
      "\n",
      "         [[ 5.4039e-03]],\n",
      "\n",
      "         [[-4.9642e-01]],\n",
      "\n",
      "         [[ 2.6508e-01]],\n",
      "\n",
      "         [[-6.2198e-02]],\n",
      "\n",
      "         [[ 6.1637e-03]],\n",
      "\n",
      "         [[-1.1726e-01]],\n",
      "\n",
      "         [[ 1.7323e-01]],\n",
      "\n",
      "         [[-3.6794e-01]],\n",
      "\n",
      "         [[ 7.7666e-01]],\n",
      "\n",
      "         [[-1.2412e-01]],\n",
      "\n",
      "         [[-1.8645e-02]],\n",
      "\n",
      "         [[-2.1034e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0038e-01]],\n",
      "\n",
      "         [[-6.2196e-02]],\n",
      "\n",
      "         [[-6.4482e-01]],\n",
      "\n",
      "         [[ 2.7739e-02]],\n",
      "\n",
      "         [[-1.2116e-02]],\n",
      "\n",
      "         [[-6.1059e-01]],\n",
      "\n",
      "         [[ 1.8952e-01]],\n",
      "\n",
      "         [[ 1.1235e-01]],\n",
      "\n",
      "         [[ 1.7238e-01]],\n",
      "\n",
      "         [[ 1.5060e-01]],\n",
      "\n",
      "         [[-5.7409e-03]],\n",
      "\n",
      "         [[-4.3607e-01]],\n",
      "\n",
      "         [[ 8.8846e-02]],\n",
      "\n",
      "         [[ 1.7299e-01]],\n",
      "\n",
      "         [[ 9.9182e-02]],\n",
      "\n",
      "         [[-9.0092e-02]],\n",
      "\n",
      "         [[ 1.2075e-01]],\n",
      "\n",
      "         [[ 1.0568e-01]],\n",
      "\n",
      "         [[-8.8996e-01]],\n",
      "\n",
      "         [[-6.9577e-02]],\n",
      "\n",
      "         [[ 6.5522e-02]],\n",
      "\n",
      "         [[-8.8864e-01]],\n",
      "\n",
      "         [[ 1.7238e-01]],\n",
      "\n",
      "         [[-1.1796e+00]],\n",
      "\n",
      "         [[ 1.8284e-01]],\n",
      "\n",
      "         [[ 1.1372e-01]],\n",
      "\n",
      "         [[ 1.0840e-01]],\n",
      "\n",
      "         [[ 5.0447e-02]],\n",
      "\n",
      "         [[ 1.2138e-01]],\n",
      "\n",
      "         [[ 6.5904e-02]],\n",
      "\n",
      "         [[ 2.1456e-01]],\n",
      "\n",
      "         [[ 1.3094e-01]],\n",
      "\n",
      "         [[ 4.0845e-02]],\n",
      "\n",
      "         [[ 1.2906e-01]],\n",
      "\n",
      "         [[-2.8171e-01]],\n",
      "\n",
      "         [[ 1.4834e-01]],\n",
      "\n",
      "         [[-4.0874e-01]],\n",
      "\n",
      "         [[ 6.6889e-02]],\n",
      "\n",
      "         [[ 4.7172e-02]],\n",
      "\n",
      "         [[ 7.0475e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.0711e-02]],\n",
      "\n",
      "         [[ 5.0893e-02]],\n",
      "\n",
      "         [[ 3.7971e-01]],\n",
      "\n",
      "         [[-2.6541e-03]],\n",
      "\n",
      "         [[ 3.1085e-02]],\n",
      "\n",
      "         [[-5.7150e-01]],\n",
      "\n",
      "         [[ 1.7669e-01]],\n",
      "\n",
      "         [[-4.4786e-02]],\n",
      "\n",
      "         [[ 7.0930e-02]],\n",
      "\n",
      "         [[ 9.7153e-02]],\n",
      "\n",
      "         [[-2.2706e-01]],\n",
      "\n",
      "         [[-5.5965e-01]],\n",
      "\n",
      "         [[ 1.2320e-01]],\n",
      "\n",
      "         [[-2.3088e-01]],\n",
      "\n",
      "         [[-6.0045e-02]],\n",
      "\n",
      "         [[ 2.2410e-01]],\n",
      "\n",
      "         [[ 4.6081e-02]],\n",
      "\n",
      "         [[-3.9284e-02]],\n",
      "\n",
      "         [[-5.2502e-01]],\n",
      "\n",
      "         [[ 2.2538e-01]],\n",
      "\n",
      "         [[-2.5208e-01]],\n",
      "\n",
      "         [[-3.6464e-01]],\n",
      "\n",
      "         [[ 2.9736e-01]],\n",
      "\n",
      "         [[-1.3439e-01]],\n",
      "\n",
      "         [[ 3.1079e-01]],\n",
      "\n",
      "         [[ 1.3852e-01]],\n",
      "\n",
      "         [[-1.7539e-02]],\n",
      "\n",
      "         [[-3.7436e-01]],\n",
      "\n",
      "         [[-1.3999e-01]],\n",
      "\n",
      "         [[ 3.4010e-02]],\n",
      "\n",
      "         [[-1.3612e-01]],\n",
      "\n",
      "         [[-1.6013e-01]],\n",
      "\n",
      "         [[ 4.1369e-02]],\n",
      "\n",
      "         [[ 6.1749e-02]],\n",
      "\n",
      "         [[ 1.6005e-01]],\n",
      "\n",
      "         [[-7.2473e-02]],\n",
      "\n",
      "         [[ 3.9220e-02]],\n",
      "\n",
      "         [[-2.4880e-01]],\n",
      "\n",
      "         [[-8.3357e-02]],\n",
      "\n",
      "         [[ 1.6993e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.0430e-02]],\n",
      "\n",
      "         [[ 1.5200e-01]],\n",
      "\n",
      "         [[-7.1645e-01]],\n",
      "\n",
      "         [[ 1.7770e-01]],\n",
      "\n",
      "         [[ 5.3535e-01]],\n",
      "\n",
      "         [[-4.8379e-01]],\n",
      "\n",
      "         [[ 2.7350e-01]],\n",
      "\n",
      "         [[ 1.9323e-01]],\n",
      "\n",
      "         [[ 2.3096e-01]],\n",
      "\n",
      "         [[-3.6210e-01]],\n",
      "\n",
      "         [[ 1.8380e-01]],\n",
      "\n",
      "         [[-1.9234e-01]],\n",
      "\n",
      "         [[ 1.0573e-01]],\n",
      "\n",
      "         [[-6.3016e-02]],\n",
      "\n",
      "         [[-5.5747e-02]],\n",
      "\n",
      "         [[-2.5925e-01]],\n",
      "\n",
      "         [[-9.7074e-02]],\n",
      "\n",
      "         [[ 3.8495e-01]],\n",
      "\n",
      "         [[ 8.2876e-02]],\n",
      "\n",
      "         [[ 2.4314e-01]],\n",
      "\n",
      "         [[-3.4344e-02]],\n",
      "\n",
      "         [[ 1.3098e-01]],\n",
      "\n",
      "         [[ 7.1562e-01]],\n",
      "\n",
      "         [[-1.3067e-01]],\n",
      "\n",
      "         [[-7.0927e-02]],\n",
      "\n",
      "         [[ 2.1349e-01]],\n",
      "\n",
      "         [[ 9.1301e-02]],\n",
      "\n",
      "         [[-1.2465e-01]],\n",
      "\n",
      "         [[-3.0476e-01]],\n",
      "\n",
      "         [[-7.2809e-02]],\n",
      "\n",
      "         [[ 3.5194e-02]],\n",
      "\n",
      "         [[ 6.5972e-02]],\n",
      "\n",
      "         [[-7.4559e-02]],\n",
      "\n",
      "         [[ 9.0523e-02]],\n",
      "\n",
      "         [[-3.4280e-01]],\n",
      "\n",
      "         [[-8.9494e-02]],\n",
      "\n",
      "         [[ 4.6864e-01]],\n",
      "\n",
      "         [[-1.4711e-01]],\n",
      "\n",
      "         [[-9.4300e-02]],\n",
      "\n",
      "         [[ 5.0714e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.9390e-02]],\n",
      "\n",
      "         [[-1.3192e-01]],\n",
      "\n",
      "         [[-1.1711e-01]],\n",
      "\n",
      "         [[ 1.9572e-01]],\n",
      "\n",
      "         [[ 1.0741e-01]],\n",
      "\n",
      "         [[-7.9960e-01]],\n",
      "\n",
      "         [[ 2.6231e-01]],\n",
      "\n",
      "         [[-6.0958e-02]],\n",
      "\n",
      "         [[-6.2308e-02]],\n",
      "\n",
      "         [[-2.2976e-02]],\n",
      "\n",
      "         [[-1.3783e-01]],\n",
      "\n",
      "         [[-9.8839e-02]],\n",
      "\n",
      "         [[ 1.4416e-01]],\n",
      "\n",
      "         [[-4.1978e-02]],\n",
      "\n",
      "         [[-9.7720e-03]],\n",
      "\n",
      "         [[-5.4840e-01]],\n",
      "\n",
      "         [[ 3.0739e-03]],\n",
      "\n",
      "         [[ 1.4873e-01]],\n",
      "\n",
      "         [[-5.8468e-01]],\n",
      "\n",
      "         [[-1.7442e-01]],\n",
      "\n",
      "         [[ 4.7817e-02]],\n",
      "\n",
      "         [[-4.9535e-01]],\n",
      "\n",
      "         [[ 6.6148e-01]],\n",
      "\n",
      "         [[ 1.0682e-01]],\n",
      "\n",
      "         [[-4.0691e-01]],\n",
      "\n",
      "         [[ 1.7790e-01]],\n",
      "\n",
      "         [[ 1.8018e-03]],\n",
      "\n",
      "         [[-1.9263e-01]],\n",
      "\n",
      "         [[-7.7609e-02]],\n",
      "\n",
      "         [[ 7.6263e-02]],\n",
      "\n",
      "         [[ 5.4601e-02]],\n",
      "\n",
      "         [[ 4.1342e-02]],\n",
      "\n",
      "         [[ 6.5958e-02]],\n",
      "\n",
      "         [[ 2.0297e-02]],\n",
      "\n",
      "         [[-7.8673e-02]],\n",
      "\n",
      "         [[-2.7511e-02]],\n",
      "\n",
      "         [[-6.8501e-02]],\n",
      "\n",
      "         [[ 4.2277e-02]],\n",
      "\n",
      "         [[ 1.4257e-02]],\n",
      "\n",
      "         [[-9.8576e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.0269e-01]],\n",
      "\n",
      "         [[-4.1952e-01]],\n",
      "\n",
      "         [[ 6.8727e-02]],\n",
      "\n",
      "         [[-9.0701e-02]],\n",
      "\n",
      "         [[ 7.2898e-02]],\n",
      "\n",
      "         [[ 9.2912e-02]],\n",
      "\n",
      "         [[-1.0869e-01]],\n",
      "\n",
      "         [[-4.6958e-01]],\n",
      "\n",
      "         [[-1.4023e-02]],\n",
      "\n",
      "         [[-7.0747e-02]],\n",
      "\n",
      "         [[-3.8957e-01]],\n",
      "\n",
      "         [[-8.8889e-02]],\n",
      "\n",
      "         [[-4.9275e-01]],\n",
      "\n",
      "         [[ 4.1271e-02]],\n",
      "\n",
      "         [[-7.3119e-02]],\n",
      "\n",
      "         [[ 1.0044e-01]],\n",
      "\n",
      "         [[ 4.1626e-02]],\n",
      "\n",
      "         [[ 2.5872e-01]],\n",
      "\n",
      "         [[ 2.2912e-01]],\n",
      "\n",
      "         [[ 3.5093e-01]],\n",
      "\n",
      "         [[ 1.1641e-01]],\n",
      "\n",
      "         [[-1.5154e-01]],\n",
      "\n",
      "         [[ 2.0866e-02]],\n",
      "\n",
      "         [[-1.6786e-01]],\n",
      "\n",
      "         [[ 1.3103e-01]],\n",
      "\n",
      "         [[-6.2816e-01]],\n",
      "\n",
      "         [[ 1.0013e-01]],\n",
      "\n",
      "         [[ 4.1614e-02]],\n",
      "\n",
      "         [[ 7.1221e-02]],\n",
      "\n",
      "         [[ 1.1533e-01]],\n",
      "\n",
      "         [[ 2.3315e-01]],\n",
      "\n",
      "         [[-8.5196e-02]],\n",
      "\n",
      "         [[ 6.2669e-02]],\n",
      "\n",
      "         [[-5.4212e-01]],\n",
      "\n",
      "         [[ 1.7427e-01]],\n",
      "\n",
      "         [[-1.3202e-01]],\n",
      "\n",
      "         [[ 6.2471e-01]],\n",
      "\n",
      "         [[ 9.6048e-02]],\n",
      "\n",
      "         [[ 6.4906e-02]],\n",
      "\n",
      "         [[-2.6673e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.2019,  0.1078,  0.0004, -0.0639,  0.1750,  0.0690, -0.1322, -0.0545,\n",
      "         0.0231,  0.0995], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-8.5952e-01]],\n",
      "\n",
      "         [[-9.8552e-01]],\n",
      "\n",
      "         [[-1.8768e-01]],\n",
      "\n",
      "         [[-2.6922e-01]],\n",
      "\n",
      "         [[-1.0389e+00]],\n",
      "\n",
      "         [[-1.3250e-01]],\n",
      "\n",
      "         [[ 2.2276e-01]],\n",
      "\n",
      "         [[-4.6324e-01]],\n",
      "\n",
      "         [[-3.6623e-01]],\n",
      "\n",
      "         [[-7.3434e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9177e-01]],\n",
      "\n",
      "         [[ 7.4415e-01]],\n",
      "\n",
      "         [[-3.0146e-01]],\n",
      "\n",
      "         [[-1.6607e-01]],\n",
      "\n",
      "         [[ 4.7814e-01]],\n",
      "\n",
      "         [[ 1.7792e-01]],\n",
      "\n",
      "         [[-6.8775e-02]],\n",
      "\n",
      "         [[ 6.1781e-01]],\n",
      "\n",
      "         [[ 3.0475e-01]],\n",
      "\n",
      "         [[ 4.5155e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4203e-01]],\n",
      "\n",
      "         [[-7.3295e-01]],\n",
      "\n",
      "         [[ 2.9324e-02]],\n",
      "\n",
      "         [[-9.6004e-01]],\n",
      "\n",
      "         [[-1.4086e-01]],\n",
      "\n",
      "         [[-6.1868e-01]],\n",
      "\n",
      "         [[ 3.6671e-01]],\n",
      "\n",
      "         [[-1.3549e+00]],\n",
      "\n",
      "         [[-8.1383e-01]],\n",
      "\n",
      "         [[ 3.2285e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7577e-01]],\n",
      "\n",
      "         [[ 5.8567e-01]],\n",
      "\n",
      "         [[-3.6138e-01]],\n",
      "\n",
      "         [[ 9.0770e-03]],\n",
      "\n",
      "         [[ 5.8114e-01]],\n",
      "\n",
      "         [[ 1.1280e-01]],\n",
      "\n",
      "         [[-1.8841e-01]],\n",
      "\n",
      "         [[ 6.0932e-01]],\n",
      "\n",
      "         [[ 8.5803e-02]],\n",
      "\n",
      "         [[ 8.1008e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8767e-01]],\n",
      "\n",
      "         [[ 5.2288e-02]],\n",
      "\n",
      "         [[ 2.5077e-01]],\n",
      "\n",
      "         [[-1.4194e-01]],\n",
      "\n",
      "         [[ 2.4657e-01]],\n",
      "\n",
      "         [[-2.5985e-01]],\n",
      "\n",
      "         [[-4.6327e-02]],\n",
      "\n",
      "         [[ 1.7253e-01]],\n",
      "\n",
      "         [[-2.3262e-01]],\n",
      "\n",
      "         [[ 3.2840e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.6466e-02]],\n",
      "\n",
      "         [[-9.0401e-02]],\n",
      "\n",
      "         [[ 8.5312e-01]],\n",
      "\n",
      "         [[-3.1496e-01]],\n",
      "\n",
      "         [[ 3.3431e-01]],\n",
      "\n",
      "         [[ 1.1086e-01]],\n",
      "\n",
      "         [[-1.5503e-01]],\n",
      "\n",
      "         [[-1.3555e+00]],\n",
      "\n",
      "         [[-8.2905e-01]],\n",
      "\n",
      "         [[ 4.0367e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4429e-01]],\n",
      "\n",
      "         [[ 1.3394e-01]],\n",
      "\n",
      "         [[-2.1881e-01]],\n",
      "\n",
      "         [[-3.4021e-01]],\n",
      "\n",
      "         [[ 6.3582e-02]],\n",
      "\n",
      "         [[-2.9925e-01]],\n",
      "\n",
      "         [[-3.2096e-01]],\n",
      "\n",
      "         [[-6.7472e-02]],\n",
      "\n",
      "         [[ 3.2062e-01]],\n",
      "\n",
      "         [[-2.0007e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3839e-01]],\n",
      "\n",
      "         [[-5.3196e-01]],\n",
      "\n",
      "         [[-3.0110e-01]],\n",
      "\n",
      "         [[-1.0711e-02]],\n",
      "\n",
      "         [[-5.5477e-01]],\n",
      "\n",
      "         [[-1.3589e-01]],\n",
      "\n",
      "         [[-1.8210e-01]],\n",
      "\n",
      "         [[ 3.0648e-01]],\n",
      "\n",
      "         [[-2.1788e-01]],\n",
      "\n",
      "         [[-5.3420e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0941e-01]],\n",
      "\n",
      "         [[ 2.9281e-01]],\n",
      "\n",
      "         [[-3.1020e-01]],\n",
      "\n",
      "         [[-4.3375e-01]],\n",
      "\n",
      "         [[ 1.4342e-01]],\n",
      "\n",
      "         [[-1.1322e-02]],\n",
      "\n",
      "         [[-2.1969e-01]],\n",
      "\n",
      "         [[ 3.1340e-01]],\n",
      "\n",
      "         [[ 1.1087e-01]],\n",
      "\n",
      "         [[ 1.9322e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7785e-01]],\n",
      "\n",
      "         [[-8.2485e-02]],\n",
      "\n",
      "         [[ 4.4440e-01]],\n",
      "\n",
      "         [[-1.5439e-01]],\n",
      "\n",
      "         [[ 1.9940e-01]],\n",
      "\n",
      "         [[-4.7766e-01]],\n",
      "\n",
      "         [[-5.2937e-01]],\n",
      "\n",
      "         [[-4.9672e-01]],\n",
      "\n",
      "         [[-7.1336e-01]],\n",
      "\n",
      "         [[ 2.3954e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1798e-01]],\n",
      "\n",
      "         [[ 1.1458e-01]],\n",
      "\n",
      "         [[ 1.5098e-01]],\n",
      "\n",
      "         [[ 4.4596e-01]],\n",
      "\n",
      "         [[-9.7492e-02]],\n",
      "\n",
      "         [[ 2.7325e-01]],\n",
      "\n",
      "         [[ 4.6780e-01]],\n",
      "\n",
      "         [[ 3.6093e-01]],\n",
      "\n",
      "         [[ 2.2199e-01]],\n",
      "\n",
      "         [[ 4.0294e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0997e-01]],\n",
      "\n",
      "         [[ 5.3621e-01]],\n",
      "\n",
      "         [[ 6.0890e-01]],\n",
      "\n",
      "         [[ 3.7562e-01]],\n",
      "\n",
      "         [[ 9.5876e-01]],\n",
      "\n",
      "         [[ 1.1374e-01]],\n",
      "\n",
      "         [[ 4.4163e-01]],\n",
      "\n",
      "         [[ 4.0019e-01]],\n",
      "\n",
      "         [[ 7.1525e-01]],\n",
      "\n",
      "         [[ 7.9653e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.8760e-01]],\n",
      "\n",
      "         [[-3.7522e-01]],\n",
      "\n",
      "         [[ 1.5193e-01]],\n",
      "\n",
      "         [[ 4.3311e-01]],\n",
      "\n",
      "         [[-5.7186e-01]],\n",
      "\n",
      "         [[-5.5313e-02]],\n",
      "\n",
      "         [[ 4.7975e-01]],\n",
      "\n",
      "         [[ 2.3146e-01]],\n",
      "\n",
      "         [[ 4.0713e-01]],\n",
      "\n",
      "         [[-3.1775e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.1755e-02]],\n",
      "\n",
      "         [[-4.0915e-01]],\n",
      "\n",
      "         [[-1.5565e-02]],\n",
      "\n",
      "         [[ 5.8146e-01]],\n",
      "\n",
      "         [[-2.6401e-01]],\n",
      "\n",
      "         [[-9.2354e-03]],\n",
      "\n",
      "         [[ 3.8766e-01]],\n",
      "\n",
      "         [[-4.0249e-01]],\n",
      "\n",
      "         [[ 1.5602e-01]],\n",
      "\n",
      "         [[-5.3655e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.5916e-01]],\n",
      "\n",
      "         [[ 2.7678e-01]],\n",
      "\n",
      "         [[ 1.8484e+00]],\n",
      "\n",
      "         [[ 4.3537e-01]],\n",
      "\n",
      "         [[ 9.7047e-01]],\n",
      "\n",
      "         [[-7.7134e-01]],\n",
      "\n",
      "         [[ 3.4312e-01]],\n",
      "\n",
      "         [[-7.1347e-01]],\n",
      "\n",
      "         [[ 5.7287e-01]],\n",
      "\n",
      "         [[ 6.1553e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.5826e-01]],\n",
      "\n",
      "         [[ 1.1171e+00]],\n",
      "\n",
      "         [[ 3.5620e-01]],\n",
      "\n",
      "         [[ 9.1771e-01]],\n",
      "\n",
      "         [[ 1.1631e+00]],\n",
      "\n",
      "         [[-4.0519e-01]],\n",
      "\n",
      "         [[ 6.6889e-01]],\n",
      "\n",
      "         [[ 1.9571e-01]],\n",
      "\n",
      "         [[ 3.8063e-01]],\n",
      "\n",
      "         [[ 1.4926e+00]]],\n",
      "\n",
      "\n",
      "        [[[-2.0319e+00]],\n",
      "\n",
      "         [[-2.3130e-01]],\n",
      "\n",
      "         [[ 3.7556e-02]],\n",
      "\n",
      "         [[-5.6026e-01]],\n",
      "\n",
      "         [[-1.0209e+00]],\n",
      "\n",
      "         [[ 4.7544e-02]],\n",
      "\n",
      "         [[ 1.6593e-01]],\n",
      "\n",
      "         [[ 1.0589e-01]],\n",
      "\n",
      "         [[ 1.1069e-01]],\n",
      "\n",
      "         [[-5.2807e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2033e-02]],\n",
      "\n",
      "         [[ 4.4423e-01]],\n",
      "\n",
      "         [[-6.3946e-01]],\n",
      "\n",
      "         [[-1.0305e+00]],\n",
      "\n",
      "         [[-2.0353e-01]],\n",
      "\n",
      "         [[-4.6842e-01]],\n",
      "\n",
      "         [[ 1.8008e-01]],\n",
      "\n",
      "         [[-4.5379e-01]],\n",
      "\n",
      "         [[-3.4921e-01]],\n",
      "\n",
      "         [[ 3.1457e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.8960e-02]],\n",
      "\n",
      "         [[-4.7612e-01]],\n",
      "\n",
      "         [[-2.5390e-01]],\n",
      "\n",
      "         [[ 8.0110e-02]],\n",
      "\n",
      "         [[-1.1179e-01]],\n",
      "\n",
      "         [[-1.3318e+00]],\n",
      "\n",
      "         [[-1.3825e+00]],\n",
      "\n",
      "         [[-1.5729e-01]],\n",
      "\n",
      "         [[-9.7575e-01]],\n",
      "\n",
      "         [[ 2.5513e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4117e-02]],\n",
      "\n",
      "         [[ 1.5705e-02]],\n",
      "\n",
      "         [[-1.9724e+00]],\n",
      "\n",
      "         [[-6.5007e-01]],\n",
      "\n",
      "         [[ 4.0905e-01]],\n",
      "\n",
      "         [[-7.0682e-01]],\n",
      "\n",
      "         [[-3.3639e-01]],\n",
      "\n",
      "         [[-6.6239e-02]],\n",
      "\n",
      "         [[ 4.2851e-02]],\n",
      "\n",
      "         [[ 3.4007e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.5403e-01]],\n",
      "\n",
      "         [[-1.6289e-01]],\n",
      "\n",
      "         [[-4.4693e-01]],\n",
      "\n",
      "         [[ 1.1794e-01]],\n",
      "\n",
      "         [[-5.1099e-01]],\n",
      "\n",
      "         [[-1.5472e-01]],\n",
      "\n",
      "         [[ 3.7027e-01]],\n",
      "\n",
      "         [[-5.6935e-02]],\n",
      "\n",
      "         [[ 8.7754e-02]],\n",
      "\n",
      "         [[-1.4457e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.8176e-01]],\n",
      "\n",
      "         [[-1.2166e+00]],\n",
      "\n",
      "         [[-2.8169e-01]],\n",
      "\n",
      "         [[ 4.5118e-01]],\n",
      "\n",
      "         [[-1.1828e-02]],\n",
      "\n",
      "         [[-6.0705e-01]],\n",
      "\n",
      "         [[-7.3153e-01]],\n",
      "\n",
      "         [[ 1.1040e-02]],\n",
      "\n",
      "         [[-1.2401e+00]],\n",
      "\n",
      "         [[-5.9926e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7322e-02]],\n",
      "\n",
      "         [[ 1.8441e-01]],\n",
      "\n",
      "         [[ 6.4029e-02]],\n",
      "\n",
      "         [[-3.2444e-01]],\n",
      "\n",
      "         [[ 8.9450e-03]],\n",
      "\n",
      "         [[ 4.7248e-03]],\n",
      "\n",
      "         [[-2.4074e-01]],\n",
      "\n",
      "         [[ 1.0342e-01]],\n",
      "\n",
      "         [[-2.0956e-01]],\n",
      "\n",
      "         [[ 3.1297e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0420e-01]],\n",
      "\n",
      "         [[-2.6422e-03]],\n",
      "\n",
      "         [[-1.4229e+00]],\n",
      "\n",
      "         [[-1.0999e+00]],\n",
      "\n",
      "         [[-6.1594e-03]],\n",
      "\n",
      "         [[-1.1224e+00]],\n",
      "\n",
      "         [[-4.3113e-01]],\n",
      "\n",
      "         [[-6.8252e-01]],\n",
      "\n",
      "         [[-9.4669e-02]],\n",
      "\n",
      "         [[-6.7810e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3222e-01]],\n",
      "\n",
      "         [[-1.1510e-01]],\n",
      "\n",
      "         [[-1.1329e+00]],\n",
      "\n",
      "         [[-7.9573e-01]],\n",
      "\n",
      "         [[ 9.1970e-02]],\n",
      "\n",
      "         [[-8.4767e-01]],\n",
      "\n",
      "         [[-1.8399e-01]],\n",
      "\n",
      "         [[-6.1003e-01]],\n",
      "\n",
      "         [[-1.1562e+00]],\n",
      "\n",
      "         [[ 8.4944e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.8268e-01]],\n",
      "\n",
      "         [[-9.7188e-01]],\n",
      "\n",
      "         [[-2.3598e-02]],\n",
      "\n",
      "         [[ 1.0167e-01]],\n",
      "\n",
      "         [[-5.2215e-01]],\n",
      "\n",
      "         [[-1.3134e-01]],\n",
      "\n",
      "         [[-4.4143e-01]],\n",
      "\n",
      "         [[ 1.7388e-02]],\n",
      "\n",
      "         [[-2.8162e-01]],\n",
      "\n",
      "         [[-9.6346e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1825e-03]],\n",
      "\n",
      "         [[ 5.6014e-02]],\n",
      "\n",
      "         [[ 2.8283e-01]],\n",
      "\n",
      "         [[ 4.6852e-01]],\n",
      "\n",
      "         [[-3.7656e-01]],\n",
      "\n",
      "         [[ 6.8898e-01]],\n",
      "\n",
      "         [[ 5.5204e-01]],\n",
      "\n",
      "         [[ 8.7796e-01]],\n",
      "\n",
      "         [[ 2.2686e-01]],\n",
      "\n",
      "         [[ 3.5704e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6869e-01]],\n",
      "\n",
      "         [[-7.5730e-01]],\n",
      "\n",
      "         [[-1.9733e-01]],\n",
      "\n",
      "         [[-1.0946e-03]],\n",
      "\n",
      "         [[-2.6273e-01]],\n",
      "\n",
      "         [[-3.4010e-01]],\n",
      "\n",
      "         [[-3.4746e-01]],\n",
      "\n",
      "         [[ 1.0547e-01]],\n",
      "\n",
      "         [[-1.1476e-01]],\n",
      "\n",
      "         [[-1.6973e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.7591e-01]],\n",
      "\n",
      "         [[-9.2393e-04]],\n",
      "\n",
      "         [[-1.3381e-01]],\n",
      "\n",
      "         [[ 3.6698e-01]],\n",
      "\n",
      "         [[-3.4545e-01]],\n",
      "\n",
      "         [[-8.3161e-02]],\n",
      "\n",
      "         [[-9.4235e-03]],\n",
      "\n",
      "         [[ 1.2528e-01]],\n",
      "\n",
      "         [[ 5.3343e-02]],\n",
      "\n",
      "         [[-7.7707e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.9646e-01]],\n",
      "\n",
      "         [[-5.3667e-01]],\n",
      "\n",
      "         [[-1.8294e-01]],\n",
      "\n",
      "         [[ 8.5469e-02]],\n",
      "\n",
      "         [[-6.8281e-01]],\n",
      "\n",
      "         [[ 2.8020e-01]],\n",
      "\n",
      "         [[-3.4138e-02]],\n",
      "\n",
      "         [[ 1.5849e-01]],\n",
      "\n",
      "         [[-2.2121e-01]],\n",
      "\n",
      "         [[-1.3616e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2062e-01]],\n",
      "\n",
      "         [[-4.5614e-02]],\n",
      "\n",
      "         [[-1.3258e+00]],\n",
      "\n",
      "         [[ 2.8396e-01]],\n",
      "\n",
      "         [[ 1.9620e-01]],\n",
      "\n",
      "         [[ 2.9474e-01]],\n",
      "\n",
      "         [[ 1.0718e-02]],\n",
      "\n",
      "         [[ 1.4950e+00]],\n",
      "\n",
      "         [[ 7.1069e-01]],\n",
      "\n",
      "         [[ 1.8428e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0719e-01]],\n",
      "\n",
      "         [[-7.9583e-01]],\n",
      "\n",
      "         [[ 1.9621e-01]],\n",
      "\n",
      "         [[-5.1204e-01]],\n",
      "\n",
      "         [[-8.6202e-01]],\n",
      "\n",
      "         [[-5.0033e-02]],\n",
      "\n",
      "         [[ 1.4833e-01]],\n",
      "\n",
      "         [[-4.1522e-01]],\n",
      "\n",
      "         [[ 1.2002e-01]],\n",
      "\n",
      "         [[-8.0232e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.7958e-02]],\n",
      "\n",
      "         [[ 2.6240e-01]],\n",
      "\n",
      "         [[-4.8939e-02]],\n",
      "\n",
      "         [[ 3.3359e-01]],\n",
      "\n",
      "         [[-2.2461e-01]],\n",
      "\n",
      "         [[ 5.7404e-02]],\n",
      "\n",
      "         [[ 6.6304e-01]],\n",
      "\n",
      "         [[ 4.3935e-01]],\n",
      "\n",
      "         [[ 4.3955e-01]],\n",
      "\n",
      "         [[ 1.1534e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.8651e-01]],\n",
      "\n",
      "         [[-6.7694e-01]],\n",
      "\n",
      "         [[ 1.1200e-01]],\n",
      "\n",
      "         [[-1.2236e-01]],\n",
      "\n",
      "         [[-8.6718e-01]],\n",
      "\n",
      "         [[ 8.8355e-02]],\n",
      "\n",
      "         [[ 3.5941e-01]],\n",
      "\n",
      "         [[-2.3975e-01]],\n",
      "\n",
      "         [[-9.8621e-02]],\n",
      "\n",
      "         [[-1.0253e+00]]],\n",
      "\n",
      "\n",
      "        [[[-3.0019e-01]],\n",
      "\n",
      "         [[ 4.6954e-01]],\n",
      "\n",
      "         [[ 3.8344e-01]],\n",
      "\n",
      "         [[ 3.6944e-01]],\n",
      "\n",
      "         [[ 2.5558e-01]],\n",
      "\n",
      "         [[ 2.0663e-01]],\n",
      "\n",
      "         [[ 7.2445e-01]],\n",
      "\n",
      "         [[ 5.8166e-01]],\n",
      "\n",
      "         [[ 1.4311e-01]],\n",
      "\n",
      "         [[ 4.5657e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5578e-01]],\n",
      "\n",
      "         [[-3.7700e-01]],\n",
      "\n",
      "         [[-4.7984e-01]],\n",
      "\n",
      "         [[ 2.4611e-01]],\n",
      "\n",
      "         [[-1.2213e-01]],\n",
      "\n",
      "         [[-1.0500e-01]],\n",
      "\n",
      "         [[-3.3018e-01]],\n",
      "\n",
      "         [[ 2.2361e-01]],\n",
      "\n",
      "         [[ 5.5632e-02]],\n",
      "\n",
      "         [[-2.2713e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1181e-03]],\n",
      "\n",
      "         [[-1.9869e-01]],\n",
      "\n",
      "         [[-4.1347e-01]],\n",
      "\n",
      "         [[-8.2327e-01]],\n",
      "\n",
      "         [[-4.5573e-01]],\n",
      "\n",
      "         [[-5.8928e-02]],\n",
      "\n",
      "         [[-1.2710e-01]],\n",
      "\n",
      "         [[-5.6400e-02]],\n",
      "\n",
      "         [[-1.3208e-02]],\n",
      "\n",
      "         [[-2.1551e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1658e-01]],\n",
      "\n",
      "         [[-9.4147e-02]],\n",
      "\n",
      "         [[-2.5898e-01]],\n",
      "\n",
      "         [[-1.4278e-01]],\n",
      "\n",
      "         [[-6.7862e-01]],\n",
      "\n",
      "         [[ 2.2304e-02]],\n",
      "\n",
      "         [[ 2.3207e-01]],\n",
      "\n",
      "         [[ 5.6211e-02]],\n",
      "\n",
      "         [[ 3.0306e-01]],\n",
      "\n",
      "         [[-2.5198e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.5409e-01]],\n",
      "\n",
      "         [[-5.4579e-01]],\n",
      "\n",
      "         [[ 2.3278e-01]],\n",
      "\n",
      "         [[-1.6766e-03]],\n",
      "\n",
      "         [[-9.0616e-01]],\n",
      "\n",
      "         [[ 2.3322e-01]],\n",
      "\n",
      "         [[ 1.0574e-01]],\n",
      "\n",
      "         [[-1.0511e-01]],\n",
      "\n",
      "         [[-2.0111e-01]],\n",
      "\n",
      "         [[-5.8008e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.9775e-01]],\n",
      "\n",
      "         [[-6.6121e-01]],\n",
      "\n",
      "         [[-4.0381e-01]],\n",
      "\n",
      "         [[ 3.9736e-01]],\n",
      "\n",
      "         [[-7.5191e-01]],\n",
      "\n",
      "         [[ 1.5474e-01]],\n",
      "\n",
      "         [[-7.7966e-02]],\n",
      "\n",
      "         [[ 3.5680e-02]],\n",
      "\n",
      "         [[-2.2256e-01]],\n",
      "\n",
      "         [[-7.8248e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.3438, -0.6011, -1.9278,  0.0329, -0.3077, -1.2710,  0.3147, -1.0950,\n",
      "        -0.0283, -0.3733, -1.4081, -0.8966, -0.9283, -0.1304, -2.4334, -2.0012,\n",
      "        -0.0545,  0.4685, -1.8873, -0.9599,  0.2461, -1.5959,  0.2758, -1.9523,\n",
      "        -0.2132, -0.5374, -1.5014,  0.0802,  0.0825, -0.9286, -0.1786,  0.5354,\n",
      "        -0.5217, -0.8729, -0.4347, -1.0737,  0.5588,  0.3486,  0.2154, -0.4255],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 1.4634e-01]],\n",
      "\n",
      "         [[ 4.5988e-01]],\n",
      "\n",
      "         [[ 1.4995e+00]],\n",
      "\n",
      "         [[ 2.6088e-01]],\n",
      "\n",
      "         [[-2.5800e-01]],\n",
      "\n",
      "         [[ 6.8399e-01]],\n",
      "\n",
      "         [[ 6.3802e-01]],\n",
      "\n",
      "         [[-2.2387e-01]],\n",
      "\n",
      "         [[ 2.6425e-01]],\n",
      "\n",
      "         [[ 5.0077e-01]],\n",
      "\n",
      "         [[-1.7003e-01]],\n",
      "\n",
      "         [[-3.4696e-03]],\n",
      "\n",
      "         [[-3.6270e-01]],\n",
      "\n",
      "         [[-5.4460e-01]],\n",
      "\n",
      "         [[ 5.3601e-01]],\n",
      "\n",
      "         [[-1.5226e-01]],\n",
      "\n",
      "         [[ 2.8099e-01]],\n",
      "\n",
      "         [[ 1.5420e-01]],\n",
      "\n",
      "         [[ 5.2583e-01]],\n",
      "\n",
      "         [[-1.0516e+00]],\n",
      "\n",
      "         [[-4.0622e-02]],\n",
      "\n",
      "         [[ 4.1496e-01]],\n",
      "\n",
      "         [[ 6.5096e-01]],\n",
      "\n",
      "         [[-1.2866e+00]],\n",
      "\n",
      "         [[-1.0911e+00]],\n",
      "\n",
      "         [[ 8.2013e-03]],\n",
      "\n",
      "         [[-2.0668e-01]],\n",
      "\n",
      "         [[ 1.3326e-01]],\n",
      "\n",
      "         [[-1.1784e-02]],\n",
      "\n",
      "         [[-2.6707e-01]],\n",
      "\n",
      "         [[-1.5428e+00]],\n",
      "\n",
      "         [[-2.1725e-01]],\n",
      "\n",
      "         [[-8.1703e-01]],\n",
      "\n",
      "         [[-2.5585e-01]],\n",
      "\n",
      "         [[-4.0174e-02]],\n",
      "\n",
      "         [[-3.0284e-01]],\n",
      "\n",
      "         [[ 1.0362e-01]],\n",
      "\n",
      "         [[ 1.9009e-01]],\n",
      "\n",
      "         [[-1.1873e-02]],\n",
      "\n",
      "         [[-1.2465e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7227e-01]],\n",
      "\n",
      "         [[-2.1785e-01]],\n",
      "\n",
      "         [[-2.0888e-01]],\n",
      "\n",
      "         [[ 1.2719e-01]],\n",
      "\n",
      "         [[-5.8643e-02]],\n",
      "\n",
      "         [[-1.0392e+00]],\n",
      "\n",
      "         [[-6.4174e-01]],\n",
      "\n",
      "         [[-7.4615e-02]],\n",
      "\n",
      "         [[ 1.5815e-02]],\n",
      "\n",
      "         [[ 2.5017e-01]],\n",
      "\n",
      "         [[-1.7742e-01]],\n",
      "\n",
      "         [[ 2.2987e-01]],\n",
      "\n",
      "         [[ 2.6725e-01]],\n",
      "\n",
      "         [[ 1.8198e-01]],\n",
      "\n",
      "         [[ 7.5396e-01]],\n",
      "\n",
      "         [[-3.7914e-01]],\n",
      "\n",
      "         [[ 4.6512e-01]],\n",
      "\n",
      "         [[ 4.4966e-02]],\n",
      "\n",
      "         [[-3.6458e-01]],\n",
      "\n",
      "         [[-8.8569e-01]],\n",
      "\n",
      "         [[-5.5180e-02]],\n",
      "\n",
      "         [[-4.2771e-01]],\n",
      "\n",
      "         [[ 1.9057e-02]],\n",
      "\n",
      "         [[-1.7672e+00]],\n",
      "\n",
      "         [[ 3.6222e-01]],\n",
      "\n",
      "         [[ 2.4613e-01]],\n",
      "\n",
      "         [[-7.3958e-02]],\n",
      "\n",
      "         [[-5.5654e-01]],\n",
      "\n",
      "         [[-2.7642e-01]],\n",
      "\n",
      "         [[ 3.3242e-01]],\n",
      "\n",
      "         [[-2.0207e-01]],\n",
      "\n",
      "         [[ 1.6938e-01]],\n",
      "\n",
      "         [[ 3.1896e-01]],\n",
      "\n",
      "         [[ 3.9830e-01]],\n",
      "\n",
      "         [[ 4.9723e-02]],\n",
      "\n",
      "         [[ 1.2232e-01]],\n",
      "\n",
      "         [[ 1.7369e-01]],\n",
      "\n",
      "         [[ 2.6143e-01]],\n",
      "\n",
      "         [[ 2.7745e-02]],\n",
      "\n",
      "         [[ 4.4350e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5747e-01]],\n",
      "\n",
      "         [[ 9.5319e-01]],\n",
      "\n",
      "         [[-4.2884e-01]],\n",
      "\n",
      "         [[ 5.2822e-01]],\n",
      "\n",
      "         [[-2.9052e-01]],\n",
      "\n",
      "         [[ 1.0398e-01]],\n",
      "\n",
      "         [[ 9.8481e-01]],\n",
      "\n",
      "         [[ 3.5321e-01]],\n",
      "\n",
      "         [[-7.8186e-01]],\n",
      "\n",
      "         [[ 1.0168e-01]],\n",
      "\n",
      "         [[ 3.7037e-01]],\n",
      "\n",
      "         [[-1.6411e-02]],\n",
      "\n",
      "         [[ 1.5838e-01]],\n",
      "\n",
      "         [[-4.9695e-03]],\n",
      "\n",
      "         [[-1.9015e-01]],\n",
      "\n",
      "         [[ 2.9960e-01]],\n",
      "\n",
      "         [[ 8.6641e-01]],\n",
      "\n",
      "         [[ 7.9993e-02]],\n",
      "\n",
      "         [[-1.4431e-01]],\n",
      "\n",
      "         [[ 9.3142e-02]],\n",
      "\n",
      "         [[ 9.2673e-02]],\n",
      "\n",
      "         [[-1.8352e-01]],\n",
      "\n",
      "         [[ 4.4193e-01]],\n",
      "\n",
      "         [[-3.5262e-01]],\n",
      "\n",
      "         [[-2.2232e-01]],\n",
      "\n",
      "         [[ 3.2107e-02]],\n",
      "\n",
      "         [[-6.6183e-02]],\n",
      "\n",
      "         [[-3.3313e-02]],\n",
      "\n",
      "         [[-5.2548e-01]],\n",
      "\n",
      "         [[ 5.0267e-01]],\n",
      "\n",
      "         [[ 9.3732e-02]],\n",
      "\n",
      "         [[ 4.0397e-01]],\n",
      "\n",
      "         [[-2.3142e-01]],\n",
      "\n",
      "         [[-7.8258e-02]],\n",
      "\n",
      "         [[ 2.1990e-01]],\n",
      "\n",
      "         [[ 6.7895e-01]],\n",
      "\n",
      "         [[-9.6389e-01]],\n",
      "\n",
      "         [[ 9.5177e-02]],\n",
      "\n",
      "         [[ 8.0174e-01]],\n",
      "\n",
      "         [[-2.7357e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1160e+00]],\n",
      "\n",
      "         [[-1.9460e-01]],\n",
      "\n",
      "         [[-1.2257e-01]],\n",
      "\n",
      "         [[-8.6120e-01]],\n",
      "\n",
      "         [[-2.6631e-01]],\n",
      "\n",
      "         [[-1.9064e-02]],\n",
      "\n",
      "         [[-3.3632e-01]],\n",
      "\n",
      "         [[-1.0945e+00]],\n",
      "\n",
      "         [[ 3.4441e-01]],\n",
      "\n",
      "         [[ 5.5555e-02]],\n",
      "\n",
      "         [[ 5.9839e-02]],\n",
      "\n",
      "         [[ 6.0797e-01]],\n",
      "\n",
      "         [[-6.8644e-01]],\n",
      "\n",
      "         [[-3.5894e-01]],\n",
      "\n",
      "         [[-6.0943e-02]],\n",
      "\n",
      "         [[ 4.2863e-01]],\n",
      "\n",
      "         [[ 5.8665e-01]],\n",
      "\n",
      "         [[ 1.0380e-01]],\n",
      "\n",
      "         [[-5.1706e-02]],\n",
      "\n",
      "         [[-8.5184e-02]],\n",
      "\n",
      "         [[-4.9684e-01]],\n",
      "\n",
      "         [[ 4.0545e-01]],\n",
      "\n",
      "         [[-3.8566e-01]],\n",
      "\n",
      "         [[-2.6533e-02]],\n",
      "\n",
      "         [[-1.2567e-02]],\n",
      "\n",
      "         [[-3.0469e-02]],\n",
      "\n",
      "         [[ 6.6112e-02]],\n",
      "\n",
      "         [[-6.4627e-01]],\n",
      "\n",
      "         [[-4.2729e-01]],\n",
      "\n",
      "         [[ 2.0824e-01]],\n",
      "\n",
      "         [[-7.2541e-01]],\n",
      "\n",
      "         [[-1.1901e-02]],\n",
      "\n",
      "         [[-4.9929e-01]],\n",
      "\n",
      "         [[ 1.2522e-01]],\n",
      "\n",
      "         [[-8.4462e-02]],\n",
      "\n",
      "         [[-4.3287e-02]],\n",
      "\n",
      "         [[ 3.8794e-01]],\n",
      "\n",
      "         [[ 2.6315e-01]],\n",
      "\n",
      "         [[-7.5767e-01]],\n",
      "\n",
      "         [[ 9.1118e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2849e-01]],\n",
      "\n",
      "         [[ 1.3035e-01]],\n",
      "\n",
      "         [[ 4.7861e-02]],\n",
      "\n",
      "         [[-1.9144e-01]],\n",
      "\n",
      "         [[ 4.5721e-02]],\n",
      "\n",
      "         [[-5.7393e-02]],\n",
      "\n",
      "         [[-4.3168e-01]],\n",
      "\n",
      "         [[-2.1770e-01]],\n",
      "\n",
      "         [[ 5.6789e-01]],\n",
      "\n",
      "         [[ 6.2341e-02]],\n",
      "\n",
      "         [[-1.5325e-01]],\n",
      "\n",
      "         [[-3.2336e-01]],\n",
      "\n",
      "         [[-2.4288e-01]],\n",
      "\n",
      "         [[-2.6372e-01]],\n",
      "\n",
      "         [[ 1.3586e-02]],\n",
      "\n",
      "         [[ 5.4898e-02]],\n",
      "\n",
      "         [[-3.7526e-01]],\n",
      "\n",
      "         [[-3.7891e-01]],\n",
      "\n",
      "         [[ 2.1235e-01]],\n",
      "\n",
      "         [[ 7.5793e-02]],\n",
      "\n",
      "         [[ 1.3790e+00]],\n",
      "\n",
      "         [[-1.3034e-01]],\n",
      "\n",
      "         [[-1.3713e-01]],\n",
      "\n",
      "         [[ 2.1692e-01]],\n",
      "\n",
      "         [[-1.6595e-01]],\n",
      "\n",
      "         [[ 1.6636e-01]],\n",
      "\n",
      "         [[ 6.2511e-02]],\n",
      "\n",
      "         [[ 1.0845e-01]],\n",
      "\n",
      "         [[ 6.0464e-01]],\n",
      "\n",
      "         [[ 3.7931e-01]],\n",
      "\n",
      "         [[ 2.9906e-01]],\n",
      "\n",
      "         [[-6.4623e-01]],\n",
      "\n",
      "         [[-3.4770e-01]],\n",
      "\n",
      "         [[ 1.0113e+00]],\n",
      "\n",
      "         [[-8.4933e-02]],\n",
      "\n",
      "         [[-3.5817e-01]],\n",
      "\n",
      "         [[ 3.8091e-01]],\n",
      "\n",
      "         [[ 3.8445e-01]],\n",
      "\n",
      "         [[ 8.2670e-01]],\n",
      "\n",
      "         [[ 4.3830e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.3654e-01]],\n",
      "\n",
      "         [[ 4.2653e-01]],\n",
      "\n",
      "         [[-4.4579e-02]],\n",
      "\n",
      "         [[ 6.2564e-01]],\n",
      "\n",
      "         [[ 5.6007e-02]],\n",
      "\n",
      "         [[ 4.8513e-01]],\n",
      "\n",
      "         [[ 8.2786e-02]],\n",
      "\n",
      "         [[ 3.9423e-01]],\n",
      "\n",
      "         [[-7.4504e-01]],\n",
      "\n",
      "         [[ 9.2348e-02]],\n",
      "\n",
      "         [[ 9.0126e-01]],\n",
      "\n",
      "         [[ 3.7615e-02]],\n",
      "\n",
      "         [[ 1.3899e-01]],\n",
      "\n",
      "         [[ 3.6704e-01]],\n",
      "\n",
      "         [[-1.2285e-01]],\n",
      "\n",
      "         [[ 3.5398e-01]],\n",
      "\n",
      "         [[ 7.2350e-01]],\n",
      "\n",
      "         [[-7.3612e-01]],\n",
      "\n",
      "         [[ 3.9772e-01]],\n",
      "\n",
      "         [[ 2.8895e-01]],\n",
      "\n",
      "         [[ 2.1234e-01]],\n",
      "\n",
      "         [[ 1.8642e-02]],\n",
      "\n",
      "         [[ 5.1071e-01]],\n",
      "\n",
      "         [[-2.4990e-02]],\n",
      "\n",
      "         [[ 7.1224e-02]],\n",
      "\n",
      "         [[ 2.4898e-01]],\n",
      "\n",
      "         [[ 9.6348e-01]],\n",
      "\n",
      "         [[ 1.1456e+00]],\n",
      "\n",
      "         [[-1.8060e-01]],\n",
      "\n",
      "         [[ 7.5873e-01]],\n",
      "\n",
      "         [[-2.1480e-01]],\n",
      "\n",
      "         [[-2.0338e-01]],\n",
      "\n",
      "         [[-3.1244e-01]],\n",
      "\n",
      "         [[ 5.1522e-01]],\n",
      "\n",
      "         [[-7.4144e-01]],\n",
      "\n",
      "         [[ 6.0669e-01]],\n",
      "\n",
      "         [[-2.8108e-01]],\n",
      "\n",
      "         [[ 2.6737e-01]],\n",
      "\n",
      "         [[ 4.3360e-02]],\n",
      "\n",
      "         [[ 4.7697e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6421e-01]],\n",
      "\n",
      "         [[-7.4031e-01]],\n",
      "\n",
      "         [[ 2.8874e-01]],\n",
      "\n",
      "         [[-1.1733e+00]],\n",
      "\n",
      "         [[-4.9233e-01]],\n",
      "\n",
      "         [[-6.7078e-01]],\n",
      "\n",
      "         [[-9.1078e-01]],\n",
      "\n",
      "         [[-1.1287e-01]],\n",
      "\n",
      "         [[ 9.0064e-01]],\n",
      "\n",
      "         [[ 2.5245e-01]],\n",
      "\n",
      "         [[-6.9539e-01]],\n",
      "\n",
      "         [[ 8.3032e-02]],\n",
      "\n",
      "         [[-6.1193e-01]],\n",
      "\n",
      "         [[-4.9066e-01]],\n",
      "\n",
      "         [[ 2.7058e-01]],\n",
      "\n",
      "         [[-3.3747e-01]],\n",
      "\n",
      "         [[-3.9881e-01]],\n",
      "\n",
      "         [[ 2.0903e-01]],\n",
      "\n",
      "         [[-2.2675e-01]],\n",
      "\n",
      "         [[ 2.7984e-01]],\n",
      "\n",
      "         [[-2.0923e-02]],\n",
      "\n",
      "         [[ 4.4160e-01]],\n",
      "\n",
      "         [[-3.6703e-01]],\n",
      "\n",
      "         [[ 1.1794e-01]],\n",
      "\n",
      "         [[ 2.2184e-01]],\n",
      "\n",
      "         [[ 2.0200e-03]],\n",
      "\n",
      "         [[-3.8329e-01]],\n",
      "\n",
      "         [[-1.0250e-01]],\n",
      "\n",
      "         [[ 5.3966e-01]],\n",
      "\n",
      "         [[-3.1231e-01]],\n",
      "\n",
      "         [[-1.6531e-01]],\n",
      "\n",
      "         [[-1.2442e+00]],\n",
      "\n",
      "         [[-3.1255e-02]],\n",
      "\n",
      "         [[-8.7481e-02]],\n",
      "\n",
      "         [[ 3.8891e-01]],\n",
      "\n",
      "         [[ 6.9877e-03]],\n",
      "\n",
      "         [[ 1.5179e-01]],\n",
      "\n",
      "         [[-3.5514e-01]],\n",
      "\n",
      "         [[-5.0912e-01]],\n",
      "\n",
      "         [[ 6.3202e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2530e-01]],\n",
      "\n",
      "         [[ 2.9420e-01]],\n",
      "\n",
      "         [[-1.8373e-01]],\n",
      "\n",
      "         [[-1.3614e-01]],\n",
      "\n",
      "         [[-2.3771e-01]],\n",
      "\n",
      "         [[ 8.5397e-02]],\n",
      "\n",
      "         [[-1.8404e-01]],\n",
      "\n",
      "         [[ 3.1324e-01]],\n",
      "\n",
      "         [[-5.2193e-01]],\n",
      "\n",
      "         [[ 1.6018e-01]],\n",
      "\n",
      "         [[ 3.4234e-01]],\n",
      "\n",
      "         [[ 1.5260e-01]],\n",
      "\n",
      "         [[ 4.2495e-01]],\n",
      "\n",
      "         [[-5.1003e-01]],\n",
      "\n",
      "         [[ 1.2451e-01]],\n",
      "\n",
      "         [[-4.3710e-01]],\n",
      "\n",
      "         [[-2.8405e-01]],\n",
      "\n",
      "         [[-4.5591e-01]],\n",
      "\n",
      "         [[-5.2253e-02]],\n",
      "\n",
      "         [[ 4.1986e-02]],\n",
      "\n",
      "         [[ 3.9952e-01]],\n",
      "\n",
      "         [[-2.8058e-01]],\n",
      "\n",
      "         [[-2.8181e-01]],\n",
      "\n",
      "         [[-8.5312e-02]],\n",
      "\n",
      "         [[ 1.2593e-01]],\n",
      "\n",
      "         [[ 3.8415e-01]],\n",
      "\n",
      "         [[ 1.2601e-01]],\n",
      "\n",
      "         [[-3.0632e-01]],\n",
      "\n",
      "         [[ 7.6420e-02]],\n",
      "\n",
      "         [[ 9.2070e-01]],\n",
      "\n",
      "         [[ 1.1716e-01]],\n",
      "\n",
      "         [[-2.0318e-01]],\n",
      "\n",
      "         [[-6.1450e-01]],\n",
      "\n",
      "         [[ 1.6296e-01]],\n",
      "\n",
      "         [[ 3.5888e-01]],\n",
      "\n",
      "         [[ 5.9129e-01]],\n",
      "\n",
      "         [[-1.0097e+00]],\n",
      "\n",
      "         [[ 1.4197e+00]],\n",
      "\n",
      "         [[ 8.3041e-02]],\n",
      "\n",
      "         [[ 3.1137e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.3325e-01]],\n",
      "\n",
      "         [[-1.4747e-01]],\n",
      "\n",
      "         [[-5.5561e-02]],\n",
      "\n",
      "         [[-1.0860e-01]],\n",
      "\n",
      "         [[ 3.8900e-01]],\n",
      "\n",
      "         [[-5.6904e-02]],\n",
      "\n",
      "         [[-4.2998e-01]],\n",
      "\n",
      "         [[ 1.2778e-01]],\n",
      "\n",
      "         [[-1.1076e-01]],\n",
      "\n",
      "         [[ 3.3977e-02]],\n",
      "\n",
      "         [[-1.5571e-01]],\n",
      "\n",
      "         [[ 2.3919e-01]],\n",
      "\n",
      "         [[ 5.2693e-01]],\n",
      "\n",
      "         [[ 8.5055e-01]],\n",
      "\n",
      "         [[ 2.1497e-01]],\n",
      "\n",
      "         [[-3.1687e-01]],\n",
      "\n",
      "         [[-1.4869e+00]],\n",
      "\n",
      "         [[ 2.1778e-01]],\n",
      "\n",
      "         [[ 1.4060e-01]],\n",
      "\n",
      "         [[-3.9206e-02]],\n",
      "\n",
      "         [[-1.0977e+00]],\n",
      "\n",
      "         [[-1.8560e-02]],\n",
      "\n",
      "         [[-2.5718e-01]],\n",
      "\n",
      "         [[-2.3546e-01]],\n",
      "\n",
      "         [[ 6.9615e-03]],\n",
      "\n",
      "         [[ 2.9501e-02]],\n",
      "\n",
      "         [[-1.8162e-01]],\n",
      "\n",
      "         [[ 1.2939e+00]],\n",
      "\n",
      "         [[-4.7119e-01]],\n",
      "\n",
      "         [[-9.7738e-01]],\n",
      "\n",
      "         [[-1.7336e-01]],\n",
      "\n",
      "         [[ 7.2444e-01]],\n",
      "\n",
      "         [[-7.5285e-01]],\n",
      "\n",
      "         [[-4.3629e-01]],\n",
      "\n",
      "         [[-5.7101e-01]],\n",
      "\n",
      "         [[ 3.1701e-01]],\n",
      "\n",
      "         [[-6.8203e-01]],\n",
      "\n",
      "         [[-9.9196e-01]],\n",
      "\n",
      "         [[-1.3638e-01]],\n",
      "\n",
      "         [[ 1.4390e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2697e-01]],\n",
      "\n",
      "         [[ 2.0971e-01]],\n",
      "\n",
      "         [[ 3.3506e-02]],\n",
      "\n",
      "         [[-1.6697e-02]],\n",
      "\n",
      "         [[ 6.8216e-01]],\n",
      "\n",
      "         [[ 2.7269e-01]],\n",
      "\n",
      "         [[-1.7057e-01]],\n",
      "\n",
      "         [[ 1.3356e-01]],\n",
      "\n",
      "         [[-2.6549e-02]],\n",
      "\n",
      "         [[ 6.1412e-02]],\n",
      "\n",
      "         [[ 4.6639e-01]],\n",
      "\n",
      "         [[ 3.4440e-01]],\n",
      "\n",
      "         [[ 6.4279e-01]],\n",
      "\n",
      "         [[ 3.7544e-01]],\n",
      "\n",
      "         [[ 1.0666e-01]],\n",
      "\n",
      "         [[ 1.6383e-01]],\n",
      "\n",
      "         [[-1.6441e+00]],\n",
      "\n",
      "         [[ 8.7757e-01]],\n",
      "\n",
      "         [[ 4.1763e-02]],\n",
      "\n",
      "         [[ 2.4586e-02]],\n",
      "\n",
      "         [[-7.5911e-02]],\n",
      "\n",
      "         [[ 2.1138e-01]],\n",
      "\n",
      "         [[-5.5456e-02]],\n",
      "\n",
      "         [[-8.2820e-02]],\n",
      "\n",
      "         [[-8.6978e-02]],\n",
      "\n",
      "         [[-1.5525e+00]],\n",
      "\n",
      "         [[-8.9688e-03]],\n",
      "\n",
      "         [[ 1.5069e+00]],\n",
      "\n",
      "         [[ 4.1714e-01]],\n",
      "\n",
      "         [[ 5.0335e-01]],\n",
      "\n",
      "         [[-4.2415e-01]],\n",
      "\n",
      "         [[-3.9844e-01]],\n",
      "\n",
      "         [[-7.0544e-01]],\n",
      "\n",
      "         [[ 1.3705e+00]],\n",
      "\n",
      "         [[-4.9903e-01]],\n",
      "\n",
      "         [[ 7.1176e-02]],\n",
      "\n",
      "         [[ 4.5331e-01]],\n",
      "\n",
      "         [[-9.3303e-02]],\n",
      "\n",
      "         [[-6.3940e-01]],\n",
      "\n",
      "         [[-4.2772e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0357e-01]],\n",
      "\n",
      "         [[-1.6840e-01]],\n",
      "\n",
      "         [[-1.6958e-02]],\n",
      "\n",
      "         [[ 8.8636e-02]],\n",
      "\n",
      "         [[-3.9003e-01]],\n",
      "\n",
      "         [[-6.8516e-02]],\n",
      "\n",
      "         [[-4.5288e-01]],\n",
      "\n",
      "         [[-1.9798e-01]],\n",
      "\n",
      "         [[-5.7096e-01]],\n",
      "\n",
      "         [[-1.6934e-01]],\n",
      "\n",
      "         [[ 2.3068e-01]],\n",
      "\n",
      "         [[-9.3698e-01]],\n",
      "\n",
      "         [[ 2.2808e-01]],\n",
      "\n",
      "         [[ 3.2182e-01]],\n",
      "\n",
      "         [[ 1.7036e-01]],\n",
      "\n",
      "         [[ 3.3792e-01]],\n",
      "\n",
      "         [[-1.2931e-01]],\n",
      "\n",
      "         [[ 5.8780e-01]],\n",
      "\n",
      "         [[ 1.5486e-02]],\n",
      "\n",
      "         [[ 4.6088e-02]],\n",
      "\n",
      "         [[ 8.5343e-01]],\n",
      "\n",
      "         [[ 1.9964e-02]],\n",
      "\n",
      "         [[ 3.6071e-01]],\n",
      "\n",
      "         [[ 7.6006e-02]],\n",
      "\n",
      "         [[ 3.7731e-01]],\n",
      "\n",
      "         [[-2.8164e-01]],\n",
      "\n",
      "         [[-2.0837e-01]],\n",
      "\n",
      "         [[ 1.9154e-01]],\n",
      "\n",
      "         [[ 6.1025e-01]],\n",
      "\n",
      "         [[ 5.8890e-01]],\n",
      "\n",
      "         [[ 2.1784e-01]],\n",
      "\n",
      "         [[ 3.5790e-01]],\n",
      "\n",
      "         [[-1.4615e-01]],\n",
      "\n",
      "         [[-3.7228e-01]],\n",
      "\n",
      "         [[-4.5894e-01]],\n",
      "\n",
      "         [[ 1.0025e+00]],\n",
      "\n",
      "         [[-2.4766e-01]],\n",
      "\n",
      "         [[ 5.9835e-01]],\n",
      "\n",
      "         [[ 2.7576e-01]],\n",
      "\n",
      "         [[ 4.6390e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8527e-01]],\n",
      "\n",
      "         [[-2.6881e-01]],\n",
      "\n",
      "         [[-4.5438e-01]],\n",
      "\n",
      "         [[-3.5802e-01]],\n",
      "\n",
      "         [[-2.7553e-02]],\n",
      "\n",
      "         [[ 6.4432e-01]],\n",
      "\n",
      "         [[ 8.7682e-01]],\n",
      "\n",
      "         [[ 6.9695e-02]],\n",
      "\n",
      "         [[-3.9214e-01]],\n",
      "\n",
      "         [[-3.7295e-01]],\n",
      "\n",
      "         [[-2.1562e-01]],\n",
      "\n",
      "         [[-6.2440e-01]],\n",
      "\n",
      "         [[ 2.1544e-02]],\n",
      "\n",
      "         [[-2.3847e-01]],\n",
      "\n",
      "         [[ 2.7722e-01]],\n",
      "\n",
      "         [[-1.3194e-01]],\n",
      "\n",
      "         [[ 8.1427e-01]],\n",
      "\n",
      "         [[-2.0575e-01]],\n",
      "\n",
      "         [[-1.1114e+00]],\n",
      "\n",
      "         [[ 8.9108e-02]],\n",
      "\n",
      "         [[-1.2315e-01]],\n",
      "\n",
      "         [[ 5.3063e-01]],\n",
      "\n",
      "         [[ 5.6793e-02]],\n",
      "\n",
      "         [[-8.0974e-02]],\n",
      "\n",
      "         [[-4.1580e-01]],\n",
      "\n",
      "         [[-2.0520e-01]],\n",
      "\n",
      "         [[-1.2378e-01]],\n",
      "\n",
      "         [[ 2.8196e-01]],\n",
      "\n",
      "         [[-2.2610e-01]],\n",
      "\n",
      "         [[-2.6447e-01]],\n",
      "\n",
      "         [[-9.4469e-02]],\n",
      "\n",
      "         [[ 2.9581e-01]],\n",
      "\n",
      "         [[-3.0965e-01]],\n",
      "\n",
      "         [[-4.1687e-01]],\n",
      "\n",
      "         [[-1.1355e+00]],\n",
      "\n",
      "         [[ 4.7035e-01]],\n",
      "\n",
      "         [[ 4.2415e-01]],\n",
      "\n",
      "         [[-7.0300e-02]],\n",
      "\n",
      "         [[-2.5831e-01]],\n",
      "\n",
      "         [[ 5.1556e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3757e-01]],\n",
      "\n",
      "         [[-7.1091e-02]],\n",
      "\n",
      "         [[-1.1248e-01]],\n",
      "\n",
      "         [[-2.5392e-01]],\n",
      "\n",
      "         [[-7.4750e-02]],\n",
      "\n",
      "         [[ 1.6657e-03]],\n",
      "\n",
      "         [[ 4.7147e-01]],\n",
      "\n",
      "         [[-1.1340e-03]],\n",
      "\n",
      "         [[ 2.2449e-01]],\n",
      "\n",
      "         [[-9.9845e-01]],\n",
      "\n",
      "         [[ 1.9180e-01]],\n",
      "\n",
      "         [[-4.6385e-02]],\n",
      "\n",
      "         [[-1.9784e-01]],\n",
      "\n",
      "         [[ 6.3901e-01]],\n",
      "\n",
      "         [[ 4.5619e-01]],\n",
      "\n",
      "         [[-3.3107e-01]],\n",
      "\n",
      "         [[ 1.0544e+00]],\n",
      "\n",
      "         [[-6.0445e-01]],\n",
      "\n",
      "         [[-1.3793e+00]],\n",
      "\n",
      "         [[ 6.1967e-01]],\n",
      "\n",
      "         [[-2.4958e-01]],\n",
      "\n",
      "         [[ 1.1790e+00]],\n",
      "\n",
      "         [[ 7.8356e-01]],\n",
      "\n",
      "         [[-1.2494e-01]],\n",
      "\n",
      "         [[-7.8198e-01]],\n",
      "\n",
      "         [[-1.7337e-02]],\n",
      "\n",
      "         [[ 1.3335e-01]],\n",
      "\n",
      "         [[-8.9083e-01]],\n",
      "\n",
      "         [[ 2.5709e-01]],\n",
      "\n",
      "         [[ 1.1008e-01]],\n",
      "\n",
      "         [[ 1.6930e-01]],\n",
      "\n",
      "         [[-4.1385e-02]],\n",
      "\n",
      "         [[-5.3773e-03]],\n",
      "\n",
      "         [[ 4.3914e-01]],\n",
      "\n",
      "         [[ 3.2119e-01]],\n",
      "\n",
      "         [[ 4.4044e-01]],\n",
      "\n",
      "         [[ 1.6114e-01]],\n",
      "\n",
      "         [[-9.6433e-01]],\n",
      "\n",
      "         [[ 2.3215e-01]],\n",
      "\n",
      "         [[-1.0967e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6894e-01]],\n",
      "\n",
      "         [[ 4.3473e-01]],\n",
      "\n",
      "         [[-3.3914e-02]],\n",
      "\n",
      "         [[ 4.4351e-01]],\n",
      "\n",
      "         [[-5.4745e-01]],\n",
      "\n",
      "         [[ 1.3778e-01]],\n",
      "\n",
      "         [[ 3.6288e-01]],\n",
      "\n",
      "         [[ 1.4398e-01]],\n",
      "\n",
      "         [[-1.2530e-01]],\n",
      "\n",
      "         [[-2.8448e-01]],\n",
      "\n",
      "         [[-3.7509e-01]],\n",
      "\n",
      "         [[ 4.4409e-01]],\n",
      "\n",
      "         [[ 4.8047e-02]],\n",
      "\n",
      "         [[-2.4954e-01]],\n",
      "\n",
      "         [[ 1.8774e-01]],\n",
      "\n",
      "         [[-1.5731e-01]],\n",
      "\n",
      "         [[ 1.5854e-01]],\n",
      "\n",
      "         [[-1.0494e+00]],\n",
      "\n",
      "         [[-5.4967e-02]],\n",
      "\n",
      "         [[ 2.3255e-01]],\n",
      "\n",
      "         [[-1.1894e+00]],\n",
      "\n",
      "         [[ 1.1417e-01]],\n",
      "\n",
      "         [[-2.9210e-01]],\n",
      "\n",
      "         [[ 2.0713e-02]],\n",
      "\n",
      "         [[-2.3645e-01]],\n",
      "\n",
      "         [[ 3.1290e-02]],\n",
      "\n",
      "         [[ 3.6518e-01]],\n",
      "\n",
      "         [[ 4.6406e-01]],\n",
      "\n",
      "         [[-1.2275e+00]],\n",
      "\n",
      "         [[-5.5759e-01]],\n",
      "\n",
      "         [[-4.6837e-01]],\n",
      "\n",
      "         [[ 2.9829e-01]],\n",
      "\n",
      "         [[-4.7209e-01]],\n",
      "\n",
      "         [[-9.0386e-02]],\n",
      "\n",
      "         [[ 8.8800e-02]],\n",
      "\n",
      "         [[-1.1286e+00]],\n",
      "\n",
      "         [[-2.7288e-01]],\n",
      "\n",
      "         [[-3.0807e-01]],\n",
      "\n",
      "         [[-7.9108e-01]],\n",
      "\n",
      "         [[ 2.1574e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.8880e-01]],\n",
      "\n",
      "         [[-4.0860e-01]],\n",
      "\n",
      "         [[-1.2323e-01]],\n",
      "\n",
      "         [[-4.9198e-02]],\n",
      "\n",
      "         [[ 5.6483e-01]],\n",
      "\n",
      "         [[ 1.9732e-01]],\n",
      "\n",
      "         [[-4.9661e-01]],\n",
      "\n",
      "         [[ 2.2187e+00]],\n",
      "\n",
      "         [[-2.9816e-01]],\n",
      "\n",
      "         [[ 2.5150e-01]],\n",
      "\n",
      "         [[ 4.7759e-01]],\n",
      "\n",
      "         [[ 1.8438e-01]],\n",
      "\n",
      "         [[ 4.8076e-01]],\n",
      "\n",
      "         [[ 2.3129e-01]],\n",
      "\n",
      "         [[ 7.2064e-01]],\n",
      "\n",
      "         [[ 2.4608e-01]],\n",
      "\n",
      "         [[-1.2144e-01]],\n",
      "\n",
      "         [[ 4.1692e-01]],\n",
      "\n",
      "         [[ 1.0589e-01]],\n",
      "\n",
      "         [[-1.1891e-01]],\n",
      "\n",
      "         [[ 8.4065e-02]],\n",
      "\n",
      "         [[ 4.6019e-01]],\n",
      "\n",
      "         [[-2.3959e-01]],\n",
      "\n",
      "         [[-2.1386e-01]],\n",
      "\n",
      "         [[-1.2938e-01]],\n",
      "\n",
      "         [[ 9.8480e-01]],\n",
      "\n",
      "         [[ 7.7391e-01]],\n",
      "\n",
      "         [[-1.4821e-01]],\n",
      "\n",
      "         [[-2.1290e-01]],\n",
      "\n",
      "         [[ 1.0102e-01]],\n",
      "\n",
      "         [[ 4.1096e-01]],\n",
      "\n",
      "         [[ 5.0097e-01]],\n",
      "\n",
      "         [[-5.1896e-01]],\n",
      "\n",
      "         [[ 1.9703e-01]],\n",
      "\n",
      "         [[ 1.4890e-01]],\n",
      "\n",
      "         [[ 1.8797e-01]],\n",
      "\n",
      "         [[-2.5958e-01]],\n",
      "\n",
      "         [[-6.3432e-02]],\n",
      "\n",
      "         [[ 4.2231e-01]],\n",
      "\n",
      "         [[ 5.1068e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5445e+00]],\n",
      "\n",
      "         [[ 6.6913e-01]],\n",
      "\n",
      "         [[-1.8631e-01]],\n",
      "\n",
      "         [[-6.4583e-01]],\n",
      "\n",
      "         [[-1.5831e-01]],\n",
      "\n",
      "         [[-2.4045e-01]],\n",
      "\n",
      "         [[ 2.8158e-02]],\n",
      "\n",
      "         [[-6.3145e-01]],\n",
      "\n",
      "         [[ 4.1187e-01]],\n",
      "\n",
      "         [[-2.0921e-01]],\n",
      "\n",
      "         [[ 3.9030e-01]],\n",
      "\n",
      "         [[-2.0600e-01]],\n",
      "\n",
      "         [[ 2.4217e-02]],\n",
      "\n",
      "         [[ 2.2371e-01]],\n",
      "\n",
      "         [[ 2.0205e-01]],\n",
      "\n",
      "         [[-1.7950e-01]],\n",
      "\n",
      "         [[-1.3175e-01]],\n",
      "\n",
      "         [[-9.3261e-02]],\n",
      "\n",
      "         [[-1.1542e-01]],\n",
      "\n",
      "         [[ 7.7671e-02]],\n",
      "\n",
      "         [[ 3.8793e-01]],\n",
      "\n",
      "         [[-9.2207e-02]],\n",
      "\n",
      "         [[-2.1268e-01]],\n",
      "\n",
      "         [[ 1.5055e-01]],\n",
      "\n",
      "         [[-1.4089e-01]],\n",
      "\n",
      "         [[-7.3664e-02]],\n",
      "\n",
      "         [[-1.0441e-01]],\n",
      "\n",
      "         [[-4.0523e-01]],\n",
      "\n",
      "         [[ 5.7862e-01]],\n",
      "\n",
      "         [[-2.5660e-02]],\n",
      "\n",
      "         [[ 2.9021e-01]],\n",
      "\n",
      "         [[-9.9728e-01]],\n",
      "\n",
      "         [[ 9.2377e-02]],\n",
      "\n",
      "         [[ 1.2083e-02]],\n",
      "\n",
      "         [[-1.6506e-01]],\n",
      "\n",
      "         [[ 1.3595e-01]],\n",
      "\n",
      "         [[ 4.2112e-01]],\n",
      "\n",
      "         [[ 1.0386e-02]],\n",
      "\n",
      "         [[-1.1344e+00]],\n",
      "\n",
      "         [[-2.0458e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2860e-02]],\n",
      "\n",
      "         [[ 1.6893e-01]],\n",
      "\n",
      "         [[-1.7421e-01]],\n",
      "\n",
      "         [[-3.2111e-01]],\n",
      "\n",
      "         [[ 5.0138e-02]],\n",
      "\n",
      "         [[ 9.7563e-02]],\n",
      "\n",
      "         [[ 1.2860e-01]],\n",
      "\n",
      "         [[-1.9525e-02]],\n",
      "\n",
      "         [[ 2.5710e-01]],\n",
      "\n",
      "         [[-1.3027e+00]],\n",
      "\n",
      "         [[-2.5523e-01]],\n",
      "\n",
      "         [[-1.9036e-01]],\n",
      "\n",
      "         [[ 2.0217e-01]],\n",
      "\n",
      "         [[-5.7964e-01]],\n",
      "\n",
      "         [[-1.8104e-01]],\n",
      "\n",
      "         [[-4.3607e-01]],\n",
      "\n",
      "         [[-9.6317e-01]],\n",
      "\n",
      "         [[-2.1265e-01]],\n",
      "\n",
      "         [[-1.1546e+00]],\n",
      "\n",
      "         [[ 6.4828e-01]],\n",
      "\n",
      "         [[ 2.0872e-01]],\n",
      "\n",
      "         [[ 1.1668e+00]],\n",
      "\n",
      "         [[ 1.3852e-01]],\n",
      "\n",
      "         [[ 8.9552e-02]],\n",
      "\n",
      "         [[-4.3017e-01]],\n",
      "\n",
      "         [[ 9.7454e-02]],\n",
      "\n",
      "         [[-6.7675e-02]],\n",
      "\n",
      "         [[ 1.0348e+00]],\n",
      "\n",
      "         [[ 1.6978e-01]],\n",
      "\n",
      "         [[-3.2804e-01]],\n",
      "\n",
      "         [[ 1.3222e-01]],\n",
      "\n",
      "         [[ 2.5053e-01]],\n",
      "\n",
      "         [[ 1.4263e-02]],\n",
      "\n",
      "         [[-3.0738e-01]],\n",
      "\n",
      "         [[ 1.8113e-01]],\n",
      "\n",
      "         [[-1.8652e-01]],\n",
      "\n",
      "         [[ 2.3921e-02]],\n",
      "\n",
      "         [[ 9.5321e-01]],\n",
      "\n",
      "         [[-2.0749e-01]],\n",
      "\n",
      "         [[ 9.2785e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1650e-01]],\n",
      "\n",
      "         [[ 3.1407e-01]],\n",
      "\n",
      "         [[-9.5303e-02]],\n",
      "\n",
      "         [[-1.4865e-01]],\n",
      "\n",
      "         [[ 3.1767e-01]],\n",
      "\n",
      "         [[ 3.7205e-02]],\n",
      "\n",
      "         [[ 9.7161e-02]],\n",
      "\n",
      "         [[-1.5434e-01]],\n",
      "\n",
      "         [[-1.4472e-01]],\n",
      "\n",
      "         [[-5.3882e-02]],\n",
      "\n",
      "         [[-4.1656e-01]],\n",
      "\n",
      "         [[ 1.0647e-01]],\n",
      "\n",
      "         [[-4.6503e-01]],\n",
      "\n",
      "         [[-5.9733e-01]],\n",
      "\n",
      "         [[ 5.4681e-02]],\n",
      "\n",
      "         [[-3.7657e-02]],\n",
      "\n",
      "         [[ 1.9097e+00]],\n",
      "\n",
      "         [[ 2.8877e-01]],\n",
      "\n",
      "         [[-7.8038e-02]],\n",
      "\n",
      "         [[-5.5710e-02]],\n",
      "\n",
      "         [[-1.2780e-02]],\n",
      "\n",
      "         [[-4.5365e-02]],\n",
      "\n",
      "         [[-2.4685e-01]],\n",
      "\n",
      "         [[ 1.2137e-01]],\n",
      "\n",
      "         [[ 8.5967e-02]],\n",
      "\n",
      "         [[-3.9736e-01]],\n",
      "\n",
      "         [[-4.3950e-01]],\n",
      "\n",
      "         [[-1.2395e+00]],\n",
      "\n",
      "         [[-9.1387e-01]],\n",
      "\n",
      "         [[-1.2824e+00]],\n",
      "\n",
      "         [[ 2.9798e-01]],\n",
      "\n",
      "         [[-7.4984e-01]],\n",
      "\n",
      "         [[ 5.4912e-01]],\n",
      "\n",
      "         [[ 9.2772e-01]],\n",
      "\n",
      "         [[ 1.3249e-01]],\n",
      "\n",
      "         [[ 1.9309e-01]],\n",
      "\n",
      "         [[-1.0134e+00]],\n",
      "\n",
      "         [[-1.0320e-01]],\n",
      "\n",
      "         [[-2.0974e-01]],\n",
      "\n",
      "         [[ 1.3407e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7747e-01]],\n",
      "\n",
      "         [[-1.2954e-01]],\n",
      "\n",
      "         [[-5.2911e-02]],\n",
      "\n",
      "         [[-9.7418e-02]],\n",
      "\n",
      "         [[-7.7222e-02]],\n",
      "\n",
      "         [[ 2.8248e-01]],\n",
      "\n",
      "         [[-1.7092e-01]],\n",
      "\n",
      "         [[-2.0421e-01]],\n",
      "\n",
      "         [[-3.0283e-01]],\n",
      "\n",
      "         [[-2.4041e-01]],\n",
      "\n",
      "         [[ 1.9827e-01]],\n",
      "\n",
      "         [[ 1.6946e-01]],\n",
      "\n",
      "         [[ 1.3291e-01]],\n",
      "\n",
      "         [[-6.2578e-02]],\n",
      "\n",
      "         [[ 4.9419e-02]],\n",
      "\n",
      "         [[-1.0732e-01]],\n",
      "\n",
      "         [[ 1.3404e-01]],\n",
      "\n",
      "         [[ 3.6161e-01]],\n",
      "\n",
      "         [[ 6.9299e-02]],\n",
      "\n",
      "         [[ 6.6808e-03]],\n",
      "\n",
      "         [[ 1.0241e-01]],\n",
      "\n",
      "         [[ 3.0118e-01]],\n",
      "\n",
      "         [[ 5.7139e-02]],\n",
      "\n",
      "         [[ 1.1948e-01]],\n",
      "\n",
      "         [[-1.2378e-01]],\n",
      "\n",
      "         [[-2.9851e+00]],\n",
      "\n",
      "         [[-4.7633e-02]],\n",
      "\n",
      "         [[-2.8579e-02]],\n",
      "\n",
      "         [[-4.7507e-02]],\n",
      "\n",
      "         [[-1.9839e-02]],\n",
      "\n",
      "         [[-3.3140e-01]],\n",
      "\n",
      "         [[-5.3526e-01]],\n",
      "\n",
      "         [[-1.3137e-01]],\n",
      "\n",
      "         [[ 1.1012e+00]],\n",
      "\n",
      "         [[ 5.8370e-02]],\n",
      "\n",
      "         [[ 2.1499e-01]],\n",
      "\n",
      "         [[-2.6794e-01]],\n",
      "\n",
      "         [[ 1.8852e-01]],\n",
      "\n",
      "         [[-5.5042e-01]],\n",
      "\n",
      "         [[-2.4464e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.8631e-01]],\n",
      "\n",
      "         [[ 1.8757e-01]],\n",
      "\n",
      "         [[-8.5894e-02]],\n",
      "\n",
      "         [[ 1.0801e-01]],\n",
      "\n",
      "         [[-2.1000e-01]],\n",
      "\n",
      "         [[-2.5569e-01]],\n",
      "\n",
      "         [[ 4.7560e-01]],\n",
      "\n",
      "         [[-1.3597e-01]],\n",
      "\n",
      "         [[-3.3116e-01]],\n",
      "\n",
      "         [[-5.1948e-01]],\n",
      "\n",
      "         [[ 2.0462e-01]],\n",
      "\n",
      "         [[-2.7545e-01]],\n",
      "\n",
      "         [[ 9.0026e-02]],\n",
      "\n",
      "         [[-1.2546e-01]],\n",
      "\n",
      "         [[-2.4465e-02]],\n",
      "\n",
      "         [[-3.0917e-01]],\n",
      "\n",
      "         [[-2.1438e-01]],\n",
      "\n",
      "         [[-6.9179e-01]],\n",
      "\n",
      "         [[-9.4102e-01]],\n",
      "\n",
      "         [[ 7.2208e-01]],\n",
      "\n",
      "         [[-6.5180e-02]],\n",
      "\n",
      "         [[ 1.5445e+00]],\n",
      "\n",
      "         [[ 3.8568e-01]],\n",
      "\n",
      "         [[ 4.1778e-01]],\n",
      "\n",
      "         [[-1.3465e+00]],\n",
      "\n",
      "         [[-2.0907e-01]],\n",
      "\n",
      "         [[ 4.8967e-02]],\n",
      "\n",
      "         [[ 1.8091e-01]],\n",
      "\n",
      "         [[ 2.3190e-01]],\n",
      "\n",
      "         [[-2.2458e-01]],\n",
      "\n",
      "         [[ 3.2080e-01]],\n",
      "\n",
      "         [[ 1.1247e-02]],\n",
      "\n",
      "         [[-1.7649e-02]],\n",
      "\n",
      "         [[ 1.1310e-01]],\n",
      "\n",
      "         [[-2.3005e-01]],\n",
      "\n",
      "         [[-3.3952e-01]],\n",
      "\n",
      "         [[-3.1882e-01]],\n",
      "\n",
      "         [[ 2.8947e-01]],\n",
      "\n",
      "         [[ 9.7949e-02]],\n",
      "\n",
      "         [[-7.8490e-04]]],\n",
      "\n",
      "\n",
      "        [[[-2.3838e-01]],\n",
      "\n",
      "         [[ 2.4292e-01]],\n",
      "\n",
      "         [[ 1.2578e-01]],\n",
      "\n",
      "         [[ 3.4404e-01]],\n",
      "\n",
      "         [[-7.6309e-02]],\n",
      "\n",
      "         [[ 2.2863e-01]],\n",
      "\n",
      "         [[ 6.1637e-01]],\n",
      "\n",
      "         [[ 2.1463e-01]],\n",
      "\n",
      "         [[-4.7180e-01]],\n",
      "\n",
      "         [[-4.1913e-01]],\n",
      "\n",
      "         [[-4.2028e-02]],\n",
      "\n",
      "         [[ 1.7881e-01]],\n",
      "\n",
      "         [[ 5.2995e-01]],\n",
      "\n",
      "         [[ 2.2914e-01]],\n",
      "\n",
      "         [[ 7.5938e-02]],\n",
      "\n",
      "         [[-2.5886e-01]],\n",
      "\n",
      "         [[ 2.4357e-01]],\n",
      "\n",
      "         [[ 4.8846e-01]],\n",
      "\n",
      "         [[ 4.3310e-02]],\n",
      "\n",
      "         [[ 6.9143e-02]],\n",
      "\n",
      "         [[ 1.0032e+00]],\n",
      "\n",
      "         [[ 1.4068e-01]],\n",
      "\n",
      "         [[ 6.9734e-01]],\n",
      "\n",
      "         [[ 1.2818e-01]],\n",
      "\n",
      "         [[-1.4467e-02]],\n",
      "\n",
      "         [[-3.5820e-01]],\n",
      "\n",
      "         [[ 1.9959e-01]],\n",
      "\n",
      "         [[-4.2925e-01]],\n",
      "\n",
      "         [[ 4.7952e-01]],\n",
      "\n",
      "         [[-1.6130e-01]],\n",
      "\n",
      "         [[ 4.8141e-01]],\n",
      "\n",
      "         [[ 1.5245e+00]],\n",
      "\n",
      "         [[-1.2426e-01]],\n",
      "\n",
      "         [[-6.6773e-01]],\n",
      "\n",
      "         [[ 3.4813e-01]],\n",
      "\n",
      "         [[-9.2787e-02]],\n",
      "\n",
      "         [[-1.4915e-01]],\n",
      "\n",
      "         [[ 6.0555e-01]],\n",
      "\n",
      "         [[ 1.4540e-01]],\n",
      "\n",
      "         [[-3.8926e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9674e-01]],\n",
      "\n",
      "         [[-1.8884e-01]],\n",
      "\n",
      "         [[-8.5731e-02]],\n",
      "\n",
      "         [[-1.0032e+00]],\n",
      "\n",
      "         [[ 9.8261e-01]],\n",
      "\n",
      "         [[ 2.3726e-02]],\n",
      "\n",
      "         [[-6.0450e-01]],\n",
      "\n",
      "         [[-8.0214e-01]],\n",
      "\n",
      "         [[ 3.2263e-01]],\n",
      "\n",
      "         [[ 4.1987e-01]],\n",
      "\n",
      "         [[-4.7382e-02]],\n",
      "\n",
      "         [[-5.8392e-02]],\n",
      "\n",
      "         [[-5.4344e-01]],\n",
      "\n",
      "         [[-3.8563e-01]],\n",
      "\n",
      "         [[ 1.8497e-01]],\n",
      "\n",
      "         [[-1.0105e-01]],\n",
      "\n",
      "         [[-1.2567e+00]],\n",
      "\n",
      "         [[ 1.3378e+00]],\n",
      "\n",
      "         [[-6.2775e-02]],\n",
      "\n",
      "         [[ 2.5710e-01]],\n",
      "\n",
      "         [[-6.0264e-02]],\n",
      "\n",
      "         [[ 2.3595e-01]],\n",
      "\n",
      "         [[-8.1212e-01]],\n",
      "\n",
      "         [[-3.6201e-02]],\n",
      "\n",
      "         [[ 1.3435e-01]],\n",
      "\n",
      "         [[ 3.9248e-01]],\n",
      "\n",
      "         [[-2.3364e-01]],\n",
      "\n",
      "         [[ 3.7077e-01]],\n",
      "\n",
      "         [[ 3.8071e-02]],\n",
      "\n",
      "         [[-3.3013e-01]],\n",
      "\n",
      "         [[-2.0236e-01]],\n",
      "\n",
      "         [[ 9.9115e-04]],\n",
      "\n",
      "         [[ 1.9622e-01]],\n",
      "\n",
      "         [[ 1.8440e-01]],\n",
      "\n",
      "         [[-6.1546e-02]],\n",
      "\n",
      "         [[-5.4996e-01]],\n",
      "\n",
      "         [[ 7.4573e-01]],\n",
      "\n",
      "         [[-2.0066e-01]],\n",
      "\n",
      "         [[ 2.2753e-01]],\n",
      "\n",
      "         [[-4.8362e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.6200e-02]],\n",
      "\n",
      "         [[-6.0906e-01]],\n",
      "\n",
      "         [[ 2.3274e+00]],\n",
      "\n",
      "         [[-3.4343e-01]],\n",
      "\n",
      "         [[ 2.2148e-01]],\n",
      "\n",
      "         [[ 3.0959e-01]],\n",
      "\n",
      "         [[-2.3762e-01]],\n",
      "\n",
      "         [[ 2.4331e-01]],\n",
      "\n",
      "         [[-4.2571e-01]],\n",
      "\n",
      "         [[ 1.4291e-01]],\n",
      "\n",
      "         [[ 9.5644e-02]],\n",
      "\n",
      "         [[-2.9385e-01]],\n",
      "\n",
      "         [[ 1.0080e-01]],\n",
      "\n",
      "         [[ 4.1201e-01]],\n",
      "\n",
      "         [[ 1.9141e-01]],\n",
      "\n",
      "         [[-2.5574e-01]],\n",
      "\n",
      "         [[-1.3798e-01]],\n",
      "\n",
      "         [[-7.5512e-01]],\n",
      "\n",
      "         [[ 1.2703e-01]],\n",
      "\n",
      "         [[-1.2052e+00]],\n",
      "\n",
      "         [[ 8.1260e-02]],\n",
      "\n",
      "         [[ 1.2801e-01]],\n",
      "\n",
      "         [[ 3.3673e-02]],\n",
      "\n",
      "         [[-1.2744e+00]],\n",
      "\n",
      "         [[-9.8528e-01]],\n",
      "\n",
      "         [[-1.0628e-01]],\n",
      "\n",
      "         [[ 2.3337e-01]],\n",
      "\n",
      "         [[-2.3230e-01]],\n",
      "\n",
      "         [[ 2.4596e-01]],\n",
      "\n",
      "         [[ 1.5781e-01]],\n",
      "\n",
      "         [[-3.1027e-01]],\n",
      "\n",
      "         [[ 1.6693e-01]],\n",
      "\n",
      "         [[ 3.7402e-01]],\n",
      "\n",
      "         [[ 7.7608e-02]],\n",
      "\n",
      "         [[-2.5754e-02]],\n",
      "\n",
      "         [[ 1.0944e-01]],\n",
      "\n",
      "         [[ 4.3290e-01]],\n",
      "\n",
      "         [[-4.9142e-02]],\n",
      "\n",
      "         [[ 2.4568e-02]],\n",
      "\n",
      "         [[ 4.4272e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2274e-01]],\n",
      "\n",
      "         [[-8.9101e-02]],\n",
      "\n",
      "         [[ 2.0545e-01]],\n",
      "\n",
      "         [[-5.9194e-01]],\n",
      "\n",
      "         [[ 6.0439e-01]],\n",
      "\n",
      "         [[-3.4679e-01]],\n",
      "\n",
      "         [[-5.8415e-01]],\n",
      "\n",
      "         [[-1.8442e-01]],\n",
      "\n",
      "         [[ 3.9012e-01]],\n",
      "\n",
      "         [[ 2.1682e-01]],\n",
      "\n",
      "         [[ 4.6803e-02]],\n",
      "\n",
      "         [[-6.1384e-02]],\n",
      "\n",
      "         [[-4.2241e-01]],\n",
      "\n",
      "         [[ 8.3702e-01]],\n",
      "\n",
      "         [[ 2.1698e-01]],\n",
      "\n",
      "         [[ 2.0563e-01]],\n",
      "\n",
      "         [[-2.9154e-01]],\n",
      "\n",
      "         [[ 6.0954e-01]],\n",
      "\n",
      "         [[-4.0136e-02]],\n",
      "\n",
      "         [[ 6.2099e-02]],\n",
      "\n",
      "         [[-2.5769e-01]],\n",
      "\n",
      "         [[ 3.2015e-01]],\n",
      "\n",
      "         [[-3.2941e-01]],\n",
      "\n",
      "         [[ 1.2338e-01]],\n",
      "\n",
      "         [[-4.9365e-03]],\n",
      "\n",
      "         [[ 2.2382e-01]],\n",
      "\n",
      "         [[ 2.0388e-01]],\n",
      "\n",
      "         [[-2.5019e-01]],\n",
      "\n",
      "         [[-5.4267e-01]],\n",
      "\n",
      "         [[-8.4808e-01]],\n",
      "\n",
      "         [[-1.2593e-02]],\n",
      "\n",
      "         [[-2.0751e-01]],\n",
      "\n",
      "         [[ 1.5770e-01]],\n",
      "\n",
      "         [[-2.0845e-01]],\n",
      "\n",
      "         [[-1.1770e-01]],\n",
      "\n",
      "         [[ 2.9213e-02]],\n",
      "\n",
      "         [[ 2.8405e-01]],\n",
      "\n",
      "         [[-1.2605e+00]],\n",
      "\n",
      "         [[-2.5006e-01]],\n",
      "\n",
      "         [[ 1.3493e+00]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([4.0082, 4.5936, 2.8101, 5.6547, 4.3262, 4.4555, 1.2917, 5.1736, 8.9985,\n",
      "        9.2978, 2.2137, 3.1054, 7.4037, 3.9721, 2.8465, 4.5645, 6.3179, 9.4029,\n",
      "        2.3246, 0.5840, 6.0351, 2.9995, 3.8479, 3.8310], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.2387, -0.6071,  0.2578,  3.2988, -0.9843, -1.4602,  3.2823,  0.9359,\n",
      "         1.6380,  1.2263, -0.2200,  0.0267, -0.8973, -0.9513,  1.6574,  2.3093,\n",
      "        -0.4439,  2.9918, -0.3922,  0.9406, -1.2100,  5.7254,  0.9005, -0.7022],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 2.9880e-01,  5.5876e-01,  2.0120e-01],\n",
      "          [ 6.7314e-01, -1.1279e+00, -5.3636e-01],\n",
      "          [ 3.1524e-01, -2.6184e-01, -3.3506e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3959e-01, -2.5289e-01,  1.3933e-01],\n",
      "          [-6.8126e-01, -5.4629e-01,  1.4857e-02],\n",
      "          [-3.8288e-01, -3.8976e-01, -4.1318e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1891e-01,  1.5952e+00,  1.0315e-01],\n",
      "          [-1.9833e-01, -7.5204e-01,  7.8120e-03],\n",
      "          [-1.4793e-01, -3.6319e-01, -1.0721e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7008e-01,  9.8889e-02,  2.4914e-01],\n",
      "          [ 3.3027e-01, -1.1272e+00, -5.7890e-02],\n",
      "          [ 2.0807e-01, -5.2550e-01,  3.5859e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3864e-01, -1.3947e-01,  3.2058e-01],\n",
      "          [ 3.7407e-01,  3.4426e-01, -1.2368e+00],\n",
      "          [ 9.3296e-02,  1.7296e-01, -1.3751e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.8660e-01, -2.2499e-01, -7.5582e-02],\n",
      "          [-2.3058e-01,  1.2041e+00,  1.6286e-02],\n",
      "          [-6.8258e-01, -3.6932e-01, -1.6640e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.5506e-02, -4.1910e-01,  5.1398e-01],\n",
      "          [-2.1394e-01, -5.6270e-01,  1.6838e+00],\n",
      "          [-2.4181e-01, -1.0999e-01, -2.8975e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6305e-01, -1.6329e-01, -5.6667e-02],\n",
      "          [-6.5607e-02,  1.3464e+00,  7.2224e-01],\n",
      "          [-2.1663e-01,  1.5217e-01,  4.2516e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0230e-01, -1.7019e-01, -1.3217e-01],\n",
      "          [ 2.5094e-01, -3.7189e-01, -6.4717e-01],\n",
      "          [-7.5248e-01, -5.9854e-01,  2.6218e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0178e-01, -1.2081e-01, -1.1938e-01],\n",
      "          [ 1.0568e+00,  1.0714e+00,  2.6241e-01],\n",
      "          [ 3.5684e-01,  2.3343e-01, -2.2966e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8011e-01, -2.7521e-01, -2.1657e-01],\n",
      "          [-1.0424e+00,  1.8528e-01,  3.4602e-01],\n",
      "          [ 2.4242e-02,  1.6801e-01, -8.9579e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.2340e-01,  3.8792e-03, -2.1041e-01],\n",
      "          [-2.7982e-01, -4.4209e-01,  1.0877e-01],\n",
      "          [-1.8892e-01, -6.3912e-01, -5.6382e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.0228e-01, -4.1113e-01, -4.0023e-02],\n",
      "          [-9.1331e-01, -3.5290e-01, -3.5920e-01],\n",
      "          [ 4.1807e-02,  1.7883e-01,  1.5260e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5056e-01,  1.6433e+00,  3.1829e-01],\n",
      "          [-1.4550e-01, -2.1747e-01, -2.8410e-01],\n",
      "          [ 3.0245e-02,  6.5560e-02, -1.9831e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.5429e-02, -2.7463e-01, -1.6078e-01],\n",
      "          [-5.2300e-02, -2.7377e+00,  7.2853e-02],\n",
      "          [ 9.9088e-02, -3.5618e-01, -1.3951e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1068e+00, -5.9750e-01, -1.5479e-01],\n",
      "          [-1.7005e-01, -1.2949e-01,  1.3705e-01],\n",
      "          [-3.8640e-01,  4.7850e-01, -5.8219e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.3218e-02,  3.4194e-01,  2.3014e-01],\n",
      "          [-1.3775e+00, -1.9332e-01,  2.9466e-02],\n",
      "          [-1.4144e-01, -2.8142e-01,  9.4516e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6303e-01,  4.6788e-01,  9.4335e-02],\n",
      "          [ 3.0234e-01,  3.8737e-01,  4.8646e-01],\n",
      "          [ 7.9414e-02,  1.6387e-01,  5.9914e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8165e-01,  4.9372e-01, -9.4302e-05],\n",
      "          [ 1.1427e+00,  2.1424e-01,  3.3650e-01],\n",
      "          [-7.1889e-02,  5.0342e-01, -1.1055e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3005e-02,  6.7625e-01,  6.6290e-02],\n",
      "          [ 5.4867e-01, -1.0990e+00, -7.1011e-01],\n",
      "          [ 9.0672e-02, -3.9287e-01, -4.6121e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.3823e-02,  4.4752e-01, -1.0088e+00],\n",
      "          [ 1.3216e-01, -3.4873e-02,  6.1074e-01],\n",
      "          [ 2.7485e-01, -4.6745e-01,  4.3600e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9791e-02, -4.4882e-02, -2.3271e-01],\n",
      "          [ 1.7283e+00, -5.0467e-01, -4.4229e-01],\n",
      "          [-2.6931e-01, -4.5514e-01, -2.1239e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2834e-01, -8.1150e-01, -4.1524e-01],\n",
      "          [-8.5094e-01,  1.3254e+00,  2.6959e-01],\n",
      "          [ 6.3669e-02,  3.6773e-01,  3.3779e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.4061e-02, -3.0012e-01,  1.4367e-01],\n",
      "          [ 2.0547e-03, -1.6960e-01,  4.3335e-01],\n",
      "          [ 8.6276e-02, -1.8597e+00, -1.1766e-02]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([2.1489, 1.7477, 1.8216, 2.9000, 1.7030, 0.5701, 2.6233, 5.0648, 1.5308,\n",
      "        1.8454, 1.5395, 3.3282, 1.5984, 1.6421, 3.5079, 1.1343, 1.3654, 1.6268,\n",
      "        2.9892, 0.8082, 1.2746, 2.3688, 3.0356, 1.5625], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.6930, -3.2464,  1.8114, -2.5899,  1.3800,  1.1579,  2.5179, -1.6591,\n",
      "         2.6175,  4.8880,  1.9223, -3.9824,  4.0993,  2.6208, -0.1704,  1.9747,\n",
      "         2.4836,  3.2227,  1.8547,  5.8225,  1.7834,  1.9590,  1.5149,  1.8578],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0083]],\n",
      "\n",
      "         [[-0.3694]],\n",
      "\n",
      "         [[ 0.0207]],\n",
      "\n",
      "         [[ 0.5048]],\n",
      "\n",
      "         [[-0.0639]],\n",
      "\n",
      "         [[-0.1018]],\n",
      "\n",
      "         [[ 0.0022]],\n",
      "\n",
      "         [[-0.1568]],\n",
      "\n",
      "         [[ 0.1546]],\n",
      "\n",
      "         [[ 0.2605]],\n",
      "\n",
      "         [[ 0.0549]],\n",
      "\n",
      "         [[-0.7061]],\n",
      "\n",
      "         [[-0.8247]],\n",
      "\n",
      "         [[-0.1463]],\n",
      "\n",
      "         [[-0.0681]],\n",
      "\n",
      "         [[ 0.0769]],\n",
      "\n",
      "         [[-0.6740]],\n",
      "\n",
      "         [[-0.0647]],\n",
      "\n",
      "         [[ 0.0281]],\n",
      "\n",
      "         [[-0.0315]],\n",
      "\n",
      "         [[ 0.0964]],\n",
      "\n",
      "         [[ 0.1316]],\n",
      "\n",
      "         [[-0.0405]],\n",
      "\n",
      "         [[ 0.1958]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0088]],\n",
      "\n",
      "         [[-0.3129]],\n",
      "\n",
      "         [[-0.2217]],\n",
      "\n",
      "         [[-0.0947]],\n",
      "\n",
      "         [[-0.4763]],\n",
      "\n",
      "         [[-0.0048]],\n",
      "\n",
      "         [[-0.2479]],\n",
      "\n",
      "         [[-1.5532]],\n",
      "\n",
      "         [[ 0.0777]],\n",
      "\n",
      "         [[ 0.2059]],\n",
      "\n",
      "         [[-0.2460]],\n",
      "\n",
      "         [[ 0.6070]],\n",
      "\n",
      "         [[ 0.0033]],\n",
      "\n",
      "         [[-0.5034]],\n",
      "\n",
      "         [[ 0.0488]],\n",
      "\n",
      "         [[-0.0955]],\n",
      "\n",
      "         [[ 0.0146]],\n",
      "\n",
      "         [[-0.2113]],\n",
      "\n",
      "         [[ 0.6617]],\n",
      "\n",
      "         [[-0.0261]],\n",
      "\n",
      "         [[-0.1014]],\n",
      "\n",
      "         [[-0.2694]],\n",
      "\n",
      "         [[-0.0204]],\n",
      "\n",
      "         [[ 0.0558]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0788]],\n",
      "\n",
      "         [[-0.3541]],\n",
      "\n",
      "         [[ 0.0367]],\n",
      "\n",
      "         [[ 0.1339]],\n",
      "\n",
      "         [[ 0.1185]],\n",
      "\n",
      "         [[ 0.1523]],\n",
      "\n",
      "         [[ 0.0059]],\n",
      "\n",
      "         [[-0.2482]],\n",
      "\n",
      "         [[-0.0738]],\n",
      "\n",
      "         [[ 0.2215]],\n",
      "\n",
      "         [[ 0.1216]],\n",
      "\n",
      "         [[-0.9204]],\n",
      "\n",
      "         [[-0.7953]],\n",
      "\n",
      "         [[ 0.1813]],\n",
      "\n",
      "         [[-0.0897]],\n",
      "\n",
      "         [[ 0.2005]],\n",
      "\n",
      "         [[-0.8486]],\n",
      "\n",
      "         [[ 0.0319]],\n",
      "\n",
      "         [[-0.1497]],\n",
      "\n",
      "         [[-0.0853]],\n",
      "\n",
      "         [[ 0.0994]],\n",
      "\n",
      "         [[ 0.0103]],\n",
      "\n",
      "         [[ 0.0482]],\n",
      "\n",
      "         [[ 0.0088]]],\n",
      "\n",
      "\n",
      "        [[[-0.1469]],\n",
      "\n",
      "         [[-0.4280]],\n",
      "\n",
      "         [[-0.0679]],\n",
      "\n",
      "         [[-0.1499]],\n",
      "\n",
      "         [[ 0.1233]],\n",
      "\n",
      "         [[ 0.0857]],\n",
      "\n",
      "         [[-0.4883]],\n",
      "\n",
      "         [[-1.1127]],\n",
      "\n",
      "         [[-0.1961]],\n",
      "\n",
      "         [[ 0.1785]],\n",
      "\n",
      "         [[-0.1161]],\n",
      "\n",
      "         [[ 0.6167]],\n",
      "\n",
      "         [[ 0.3172]],\n",
      "\n",
      "         [[-0.1374]],\n",
      "\n",
      "         [[-0.0692]],\n",
      "\n",
      "         [[ 0.2037]],\n",
      "\n",
      "         [[-0.1174]],\n",
      "\n",
      "         [[-0.3976]],\n",
      "\n",
      "         [[-0.6593]],\n",
      "\n",
      "         [[ 0.1002]],\n",
      "\n",
      "         [[ 0.0132]],\n",
      "\n",
      "         [[-0.1076]],\n",
      "\n",
      "         [[-0.0939]],\n",
      "\n",
      "         [[ 0.1429]]],\n",
      "\n",
      "\n",
      "        [[[-0.0196]],\n",
      "\n",
      "         [[-0.6229]],\n",
      "\n",
      "         [[ 0.0898]],\n",
      "\n",
      "         [[ 0.9704]],\n",
      "\n",
      "         [[ 0.0181]],\n",
      "\n",
      "         [[-0.1077]],\n",
      "\n",
      "         [[-0.1058]],\n",
      "\n",
      "         [[-0.2476]],\n",
      "\n",
      "         [[ 0.0506]],\n",
      "\n",
      "         [[-0.2076]],\n",
      "\n",
      "         [[ 0.0832]],\n",
      "\n",
      "         [[-0.6292]],\n",
      "\n",
      "         [[-0.3634]],\n",
      "\n",
      "         [[-0.0399]],\n",
      "\n",
      "         [[-0.1670]],\n",
      "\n",
      "         [[-0.1704]],\n",
      "\n",
      "         [[ 0.0929]],\n",
      "\n",
      "         [[ 0.0453]],\n",
      "\n",
      "         [[-0.0692]],\n",
      "\n",
      "         [[-0.0426]],\n",
      "\n",
      "         [[-0.0802]],\n",
      "\n",
      "         [[ 0.0226]],\n",
      "\n",
      "         [[ 0.0080]],\n",
      "\n",
      "         [[-0.0560]]],\n",
      "\n",
      "\n",
      "        [[[-0.6675]],\n",
      "\n",
      "         [[-0.2003]],\n",
      "\n",
      "         [[-0.0304]],\n",
      "\n",
      "         [[ 0.4146]],\n",
      "\n",
      "         [[-0.0029]],\n",
      "\n",
      "         [[ 0.0191]],\n",
      "\n",
      "         [[-0.1916]],\n",
      "\n",
      "         [[-1.0007]],\n",
      "\n",
      "         [[ 0.0704]],\n",
      "\n",
      "         [[ 0.1411]],\n",
      "\n",
      "         [[-0.0629]],\n",
      "\n",
      "         [[ 0.4406]],\n",
      "\n",
      "         [[-0.1152]],\n",
      "\n",
      "         [[-0.1489]],\n",
      "\n",
      "         [[-0.1215]],\n",
      "\n",
      "         [[ 0.0146]],\n",
      "\n",
      "         [[-0.1553]],\n",
      "\n",
      "         [[-0.0106]],\n",
      "\n",
      "         [[ 0.3574]],\n",
      "\n",
      "         [[-0.0132]],\n",
      "\n",
      "         [[ 0.0191]],\n",
      "\n",
      "         [[-0.2384]],\n",
      "\n",
      "         [[-0.8798]],\n",
      "\n",
      "         [[-0.1026]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.0917, 0.0256, 0.1046, 0.0629, 0.0022, 0.0136], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-6.5421e-02]],\n",
      "\n",
      "         [[-4.3098e-01]],\n",
      "\n",
      "         [[ 1.0286e-01]],\n",
      "\n",
      "         [[-5.0610e-01]],\n",
      "\n",
      "         [[-2.6196e-01]],\n",
      "\n",
      "         [[-1.1469e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.5972e-01]],\n",
      "\n",
      "         [[-1.2149e-01]],\n",
      "\n",
      "         [[ 3.7992e-03]],\n",
      "\n",
      "         [[-8.3088e-02]],\n",
      "\n",
      "         [[-4.6915e-01]],\n",
      "\n",
      "         [[-1.2325e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.3858e-02]],\n",
      "\n",
      "         [[-4.6280e-01]],\n",
      "\n",
      "         [[ 1.0157e-01]],\n",
      "\n",
      "         [[-3.6518e-01]],\n",
      "\n",
      "         [[-8.5246e-02]],\n",
      "\n",
      "         [[-5.0821e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6570e-07]],\n",
      "\n",
      "         [[-2.9717e-01]],\n",
      "\n",
      "         [[ 1.0034e-01]],\n",
      "\n",
      "         [[-3.3616e-01]],\n",
      "\n",
      "         [[-6.2449e-01]],\n",
      "\n",
      "         [[-3.2293e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4965e-01]],\n",
      "\n",
      "         [[-1.5012e+00]],\n",
      "\n",
      "         [[ 2.7733e-01]],\n",
      "\n",
      "         [[-6.2927e-01]],\n",
      "\n",
      "         [[ 3.8557e-01]],\n",
      "\n",
      "         [[-9.0548e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0248e-01]],\n",
      "\n",
      "         [[-4.3492e-01]],\n",
      "\n",
      "         [[-1.0570e-01]],\n",
      "\n",
      "         [[-9.8568e-01]],\n",
      "\n",
      "         [[ 6.9803e-02]],\n",
      "\n",
      "         [[-5.0324e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6391e-02]],\n",
      "\n",
      "         [[-4.4515e-01]],\n",
      "\n",
      "         [[-1.2201e-01]],\n",
      "\n",
      "         [[-1.0335e+00]],\n",
      "\n",
      "         [[ 2.7350e-01]],\n",
      "\n",
      "         [[ 2.3793e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6563e-01]],\n",
      "\n",
      "         [[ 4.3746e-01]],\n",
      "\n",
      "         [[ 4.4615e-01]],\n",
      "\n",
      "         [[ 2.1509e-01]],\n",
      "\n",
      "         [[-5.2134e-02]],\n",
      "\n",
      "         [[ 2.0837e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4687e-03]],\n",
      "\n",
      "         [[-7.5026e-01]],\n",
      "\n",
      "         [[-1.5874e-01]],\n",
      "\n",
      "         [[-5.1223e-01]],\n",
      "\n",
      "         [[-3.6320e-01]],\n",
      "\n",
      "         [[-4.5798e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1102e-01]],\n",
      "\n",
      "         [[-4.6466e-02]],\n",
      "\n",
      "         [[ 8.8448e-01]],\n",
      "\n",
      "         [[ 8.3285e-02]],\n",
      "\n",
      "         [[-1.6871e+00]],\n",
      "\n",
      "         [[-9.8764e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.5435e-02]],\n",
      "\n",
      "         [[-1.2114e+00]],\n",
      "\n",
      "         [[-2.1482e-01]],\n",
      "\n",
      "         [[-8.2461e-01]],\n",
      "\n",
      "         [[ 3.1579e-02]],\n",
      "\n",
      "         [[-3.7164e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6880e-01]],\n",
      "\n",
      "         [[ 2.1483e-01]],\n",
      "\n",
      "         [[ 7.3566e-01]],\n",
      "\n",
      "         [[ 2.7442e-01]],\n",
      "\n",
      "         [[ 3.4261e-01]],\n",
      "\n",
      "         [[ 6.6295e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.7224e-01]],\n",
      "\n",
      "         [[-5.9854e-01]],\n",
      "\n",
      "         [[-8.8964e-01]],\n",
      "\n",
      "         [[-4.7487e-01]],\n",
      "\n",
      "         [[ 6.6319e-01]],\n",
      "\n",
      "         [[-5.4642e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.3803e-01]],\n",
      "\n",
      "         [[-7.9284e-01]],\n",
      "\n",
      "         [[-3.4585e-01]],\n",
      "\n",
      "         [[-4.3642e-01]],\n",
      "\n",
      "         [[-1.8418e-01]],\n",
      "\n",
      "         [[-4.9695e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4235e-01]],\n",
      "\n",
      "         [[-2.5193e-01]],\n",
      "\n",
      "         [[ 4.0084e-01]],\n",
      "\n",
      "         [[-5.7336e-01]],\n",
      "\n",
      "         [[ 8.7377e-01]],\n",
      "\n",
      "         [[ 2.3904e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3910e-01]],\n",
      "\n",
      "         [[-9.1991e-01]],\n",
      "\n",
      "         [[ 2.2753e-01]],\n",
      "\n",
      "         [[-2.3068e-01]],\n",
      "\n",
      "         [[ 8.7785e-02]],\n",
      "\n",
      "         [[-3.2303e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4321e-03]],\n",
      "\n",
      "         [[-2.8181e-02]],\n",
      "\n",
      "         [[ 3.2427e-01]],\n",
      "\n",
      "         [[ 3.7282e-01]],\n",
      "\n",
      "         [[-3.4420e-01]],\n",
      "\n",
      "         [[-1.0452e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.8312e-01]],\n",
      "\n",
      "         [[-2.2754e-01]],\n",
      "\n",
      "         [[ 1.3416e-01]],\n",
      "\n",
      "         [[-7.2094e-02]],\n",
      "\n",
      "         [[-4.6830e-01]],\n",
      "\n",
      "         [[-8.6077e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.4285e-01]],\n",
      "\n",
      "         [[-1.9568e-01]],\n",
      "\n",
      "         [[-7.0386e-01]],\n",
      "\n",
      "         [[-6.9053e-01]],\n",
      "\n",
      "         [[-2.6721e-02]],\n",
      "\n",
      "         [[-1.7541e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0940e+00]],\n",
      "\n",
      "         [[-3.2343e-02]],\n",
      "\n",
      "         [[-1.8288e+00]],\n",
      "\n",
      "         [[ 1.1304e-01]],\n",
      "\n",
      "         [[-6.0182e-01]],\n",
      "\n",
      "         [[-1.7342e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1171e-01]],\n",
      "\n",
      "         [[-9.7175e-01]],\n",
      "\n",
      "         [[-2.5528e-01]],\n",
      "\n",
      "         [[-8.4205e-01]],\n",
      "\n",
      "         [[ 4.0104e-01]],\n",
      "\n",
      "         [[-6.1820e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5634e-01]],\n",
      "\n",
      "         [[-1.3047e+00]],\n",
      "\n",
      "         [[ 2.2667e-01]],\n",
      "\n",
      "         [[-4.4039e-01]],\n",
      "\n",
      "         [[ 4.0906e-01]],\n",
      "\n",
      "         [[-9.6209e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.9100e-02]],\n",
      "\n",
      "         [[ 2.7190e-02]],\n",
      "\n",
      "         [[ 6.6647e-02]],\n",
      "\n",
      "         [[ 2.0867e-02]],\n",
      "\n",
      "         [[ 5.7668e-01]],\n",
      "\n",
      "         [[-1.0959e+00]]],\n",
      "\n",
      "\n",
      "        [[[-2.3900e-01]],\n",
      "\n",
      "         [[-8.4685e-01]],\n",
      "\n",
      "         [[-3.0871e-01]],\n",
      "\n",
      "         [[-2.7423e-01]],\n",
      "\n",
      "         [[-1.7143e-01]],\n",
      "\n",
      "         [[-2.9543e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-9.6052e-01,  3.8097e-01, -5.4572e-01, -5.2367e-02, -3.9834e-01,\n",
      "         3.9016e-04, -8.6734e-01, -1.1357e+00,  2.8234e-01,  5.5440e-01,\n",
      "        -2.6620e-01, -4.8494e-01, -8.2929e-01, -4.9361e-02, -6.4731e-01,\n",
      "         3.9602e-02, -3.4188e-01,  4.2080e-01, -3.9774e-02, -2.7043e-01,\n",
      "        -2.9248e-02, -9.6571e-01, -1.5684e+00,  9.5765e-02], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-1.2858e+00]],\n",
      "\n",
      "         [[ 8.9504e-01]],\n",
      "\n",
      "         [[-1.0343e-01]],\n",
      "\n",
      "         [[-8.0432e-02]],\n",
      "\n",
      "         [[-2.4664e-01]],\n",
      "\n",
      "         [[-1.8562e-01]],\n",
      "\n",
      "         [[-3.0114e-01]],\n",
      "\n",
      "         [[-5.0898e-01]],\n",
      "\n",
      "         [[-3.2888e-01]],\n",
      "\n",
      "         [[ 4.7668e-01]],\n",
      "\n",
      "         [[ 2.6936e-01]],\n",
      "\n",
      "         [[ 3.3499e-01]],\n",
      "\n",
      "         [[ 3.6341e-01]],\n",
      "\n",
      "         [[ 3.4877e-01]],\n",
      "\n",
      "         [[-1.1320e-01]],\n",
      "\n",
      "         [[-2.2291e-01]],\n",
      "\n",
      "         [[ 8.0241e-02]],\n",
      "\n",
      "         [[-1.2020e-01]],\n",
      "\n",
      "         [[ 1.1676e-01]],\n",
      "\n",
      "         [[-3.9129e-01]],\n",
      "\n",
      "         [[-1.8903e-01]],\n",
      "\n",
      "         [[-4.4136e-01]],\n",
      "\n",
      "         [[ 1.4403e+00]],\n",
      "\n",
      "         [[ 3.3558e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.1197e-01]],\n",
      "\n",
      "         [[ 1.1025e+00]],\n",
      "\n",
      "         [[-1.0427e-01]],\n",
      "\n",
      "         [[-2.7003e-02]],\n",
      "\n",
      "         [[ 4.2659e-01]],\n",
      "\n",
      "         [[ 8.8359e-02]],\n",
      "\n",
      "         [[ 4.5990e-01]],\n",
      "\n",
      "         [[ 2.1736e-01]],\n",
      "\n",
      "         [[-5.1346e-01]],\n",
      "\n",
      "         [[ 7.8951e-01]],\n",
      "\n",
      "         [[-2.3462e-01]],\n",
      "\n",
      "         [[-3.5491e-01]],\n",
      "\n",
      "         [[ 9.4159e-01]],\n",
      "\n",
      "         [[-6.4480e-02]],\n",
      "\n",
      "         [[-3.0057e-01]],\n",
      "\n",
      "         [[-3.4017e-02]],\n",
      "\n",
      "         [[-3.3565e-01]],\n",
      "\n",
      "         [[-6.2639e-01]],\n",
      "\n",
      "         [[-3.7687e-02]],\n",
      "\n",
      "         [[ 3.8394e-01]],\n",
      "\n",
      "         [[ 3.6469e-01]],\n",
      "\n",
      "         [[ 4.5055e-02]],\n",
      "\n",
      "         [[ 3.6930e-01]],\n",
      "\n",
      "         [[ 3.2027e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5112e-01]],\n",
      "\n",
      "         [[-7.2367e-01]],\n",
      "\n",
      "         [[ 2.8216e-01]],\n",
      "\n",
      "         [[-4.2986e-01]],\n",
      "\n",
      "         [[-3.1284e-02]],\n",
      "\n",
      "         [[-1.6333e-01]],\n",
      "\n",
      "         [[ 1.5881e-01]],\n",
      "\n",
      "         [[-4.3300e-01]],\n",
      "\n",
      "         [[-1.8376e-01]],\n",
      "\n",
      "         [[ 1.1828e+00]],\n",
      "\n",
      "         [[-5.9723e-01]],\n",
      "\n",
      "         [[-1.1678e-01]],\n",
      "\n",
      "         [[ 2.0291e-01]],\n",
      "\n",
      "         [[-8.2267e-01]],\n",
      "\n",
      "         [[ 1.3585e-01]],\n",
      "\n",
      "         [[ 3.1148e-02]],\n",
      "\n",
      "         [[ 1.1340e-01]],\n",
      "\n",
      "         [[-4.8439e-01]],\n",
      "\n",
      "         [[-1.0173e-01]],\n",
      "\n",
      "         [[-2.4684e-01]],\n",
      "\n",
      "         [[ 1.6821e-01]],\n",
      "\n",
      "         [[ 3.7432e-02]],\n",
      "\n",
      "         [[ 2.4055e-01]],\n",
      "\n",
      "         [[-6.6410e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5293e-01]],\n",
      "\n",
      "         [[-2.0914e-02]],\n",
      "\n",
      "         [[ 3.3518e-02]],\n",
      "\n",
      "         [[ 1.1738e+00]],\n",
      "\n",
      "         [[-8.0299e-03]],\n",
      "\n",
      "         [[-3.8202e-01]],\n",
      "\n",
      "         [[ 3.3710e-01]],\n",
      "\n",
      "         [[ 4.4942e-01]],\n",
      "\n",
      "         [[-4.4371e-01]],\n",
      "\n",
      "         [[ 3.2360e-01]],\n",
      "\n",
      "         [[-1.3489e-01]],\n",
      "\n",
      "         [[-3.2948e-01]],\n",
      "\n",
      "         [[ 1.5728e-01]],\n",
      "\n",
      "         [[ 5.7545e-01]],\n",
      "\n",
      "         [[ 3.4779e-01]],\n",
      "\n",
      "         [[-3.9160e-01]],\n",
      "\n",
      "         [[-4.5354e-01]],\n",
      "\n",
      "         [[-6.9457e-01]],\n",
      "\n",
      "         [[ 3.4403e-01]],\n",
      "\n",
      "         [[-7.2624e-02]],\n",
      "\n",
      "         [[ 1.9643e-01]],\n",
      "\n",
      "         [[ 3.0250e-01]],\n",
      "\n",
      "         [[-3.9666e-01]],\n",
      "\n",
      "         [[-9.0326e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.6788e-02]],\n",
      "\n",
      "         [[-8.2547e-02]],\n",
      "\n",
      "         [[ 3.9017e-01]],\n",
      "\n",
      "         [[-1.7470e-01]],\n",
      "\n",
      "         [[ 9.3163e-01]],\n",
      "\n",
      "         [[-6.5535e-01]],\n",
      "\n",
      "         [[-1.6277e-01]],\n",
      "\n",
      "         [[-5.8696e-01]],\n",
      "\n",
      "         [[-1.9850e-02]],\n",
      "\n",
      "         [[-1.0280e-01]],\n",
      "\n",
      "         [[-9.7268e-01]],\n",
      "\n",
      "         [[ 3.8699e-02]],\n",
      "\n",
      "         [[-4.6648e-01]],\n",
      "\n",
      "         [[ 3.9982e-01]],\n",
      "\n",
      "         [[-2.6913e-01]],\n",
      "\n",
      "         [[ 2.4249e-01]],\n",
      "\n",
      "         [[-2.7200e-01]],\n",
      "\n",
      "         [[ 1.1536e-01]],\n",
      "\n",
      "         [[-5.4237e-01]],\n",
      "\n",
      "         [[-1.3435e-01]],\n",
      "\n",
      "         [[ 1.6932e-01]],\n",
      "\n",
      "         [[ 2.9077e-04]],\n",
      "\n",
      "         [[-3.0299e-01]],\n",
      "\n",
      "         [[ 2.5580e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6653e-01]],\n",
      "\n",
      "         [[-3.3992e-01]],\n",
      "\n",
      "         [[ 4.7050e-01]],\n",
      "\n",
      "         [[ 9.1118e-01]],\n",
      "\n",
      "         [[ 3.6672e-01]],\n",
      "\n",
      "         [[ 1.8232e+00]],\n",
      "\n",
      "         [[-1.3231e-01]],\n",
      "\n",
      "         [[ 2.5897e-01]],\n",
      "\n",
      "         [[-2.7518e-01]],\n",
      "\n",
      "         [[ 2.8590e-01]],\n",
      "\n",
      "         [[ 2.8310e-01]],\n",
      "\n",
      "         [[ 1.3246e-01]],\n",
      "\n",
      "         [[-3.6581e-02]],\n",
      "\n",
      "         [[-5.0200e-01]],\n",
      "\n",
      "         [[ 3.1019e-01]],\n",
      "\n",
      "         [[-2.2147e-01]],\n",
      "\n",
      "         [[ 2.8328e-01]],\n",
      "\n",
      "         [[ 2.2834e-02]],\n",
      "\n",
      "         [[-3.9036e-01]],\n",
      "\n",
      "         [[-3.7725e-01]],\n",
      "\n",
      "         [[ 4.8544e-01]],\n",
      "\n",
      "         [[-1.4218e-01]],\n",
      "\n",
      "         [[ 4.5612e-02]],\n",
      "\n",
      "         [[ 1.8898e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.3660e-01]],\n",
      "\n",
      "         [[ 2.5445e-01]],\n",
      "\n",
      "         [[ 2.4515e-01]],\n",
      "\n",
      "         [[ 1.2694e-01]],\n",
      "\n",
      "         [[ 4.3738e-01]],\n",
      "\n",
      "         [[ 1.1700e-01]],\n",
      "\n",
      "         [[-5.2266e-01]],\n",
      "\n",
      "         [[-2.4286e-01]],\n",
      "\n",
      "         [[-2.6334e-01]],\n",
      "\n",
      "         [[-5.2068e-01]],\n",
      "\n",
      "         [[-2.9739e-01]],\n",
      "\n",
      "         [[ 4.0367e-01]],\n",
      "\n",
      "         [[ 1.7757e-03]],\n",
      "\n",
      "         [[-1.4181e+00]],\n",
      "\n",
      "         [[ 5.9226e-02]],\n",
      "\n",
      "         [[ 6.4245e-01]],\n",
      "\n",
      "         [[-3.9403e-01]],\n",
      "\n",
      "         [[ 4.8459e-01]],\n",
      "\n",
      "         [[ 1.4788e-01]],\n",
      "\n",
      "         [[ 8.4465e-04]],\n",
      "\n",
      "         [[-2.8257e-01]],\n",
      "\n",
      "         [[-1.9742e-01]],\n",
      "\n",
      "         [[ 2.3177e-01]],\n",
      "\n",
      "         [[ 2.8722e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8318e-01]],\n",
      "\n",
      "         [[ 3.2425e-01]],\n",
      "\n",
      "         [[-3.2393e-01]],\n",
      "\n",
      "         [[ 1.7583e-01]],\n",
      "\n",
      "         [[-2.5799e-01]],\n",
      "\n",
      "         [[ 6.4913e-01]],\n",
      "\n",
      "         [[-3.9972e-01]],\n",
      "\n",
      "         [[-1.1442e+00]],\n",
      "\n",
      "         [[-7.0553e-02]],\n",
      "\n",
      "         [[ 9.7251e-02]],\n",
      "\n",
      "         [[-4.2092e-01]],\n",
      "\n",
      "         [[ 2.8528e-02]],\n",
      "\n",
      "         [[-4.9351e-02]],\n",
      "\n",
      "         [[ 3.6140e-01]],\n",
      "\n",
      "         [[ 3.0997e-01]],\n",
      "\n",
      "         [[ 5.6723e-01]],\n",
      "\n",
      "         [[-4.2459e-01]],\n",
      "\n",
      "         [[ 5.1594e-01]],\n",
      "\n",
      "         [[ 1.1520e-01]],\n",
      "\n",
      "         [[-1.1749e-01]],\n",
      "\n",
      "         [[-1.3941e-01]],\n",
      "\n",
      "         [[-6.3019e-01]],\n",
      "\n",
      "         [[-1.2269e-01]],\n",
      "\n",
      "         [[-7.3554e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.5641e-02]],\n",
      "\n",
      "         [[ 7.3954e-02]],\n",
      "\n",
      "         [[ 8.9134e-01]],\n",
      "\n",
      "         [[-2.6190e-03]],\n",
      "\n",
      "         [[ 2.8458e-01]],\n",
      "\n",
      "         [[-1.1635e-01]],\n",
      "\n",
      "         [[-3.3149e-01]],\n",
      "\n",
      "         [[ 3.4346e-01]],\n",
      "\n",
      "         [[ 1.8997e-01]],\n",
      "\n",
      "         [[-8.3387e-01]],\n",
      "\n",
      "         [[ 1.2480e-01]],\n",
      "\n",
      "         [[-1.5692e-02]],\n",
      "\n",
      "         [[-1.0699e+00]],\n",
      "\n",
      "         [[ 4.9290e-01]],\n",
      "\n",
      "         [[-1.4973e-01]],\n",
      "\n",
      "         [[-2.7053e-01]],\n",
      "\n",
      "         [[ 8.5166e-01]],\n",
      "\n",
      "         [[ 1.4271e+00]],\n",
      "\n",
      "         [[-4.4555e-01]],\n",
      "\n",
      "         [[-5.7731e-02]],\n",
      "\n",
      "         [[ 1.9866e-02]],\n",
      "\n",
      "         [[ 2.8833e-01]],\n",
      "\n",
      "         [[ 7.4249e-02]],\n",
      "\n",
      "         [[-7.8872e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6009e-01]],\n",
      "\n",
      "         [[-2.3907e-02]],\n",
      "\n",
      "         [[-1.3485e-01]],\n",
      "\n",
      "         [[ 3.1816e-01]],\n",
      "\n",
      "         [[-2.7936e-01]],\n",
      "\n",
      "         [[-3.4401e-01]],\n",
      "\n",
      "         [[ 4.6230e-01]],\n",
      "\n",
      "         [[ 3.5883e-02]],\n",
      "\n",
      "         [[ 1.1099e+00]],\n",
      "\n",
      "         [[-6.5464e-01]],\n",
      "\n",
      "         [[ 2.3945e-01]],\n",
      "\n",
      "         [[-3.0975e-01]],\n",
      "\n",
      "         [[-7.3118e-01]],\n",
      "\n",
      "         [[-3.7349e-01]],\n",
      "\n",
      "         [[ 2.6693e-01]],\n",
      "\n",
      "         [[ 1.2487e-01]],\n",
      "\n",
      "         [[ 7.4935e-01]],\n",
      "\n",
      "         [[ 8.4488e-01]],\n",
      "\n",
      "         [[ 1.3728e+00]],\n",
      "\n",
      "         [[-2.1348e-01]],\n",
      "\n",
      "         [[ 2.4906e-01]],\n",
      "\n",
      "         [[-6.5385e-01]],\n",
      "\n",
      "         [[-1.5636e-01]],\n",
      "\n",
      "         [[ 2.2838e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3259e-01]],\n",
      "\n",
      "         [[-5.7137e-01]],\n",
      "\n",
      "         [[ 5.0031e-01]],\n",
      "\n",
      "         [[-3.8706e-01]],\n",
      "\n",
      "         [[-2.2275e-01]],\n",
      "\n",
      "         [[-2.5645e-01]],\n",
      "\n",
      "         [[ 5.9871e-01]],\n",
      "\n",
      "         [[-2.5844e-01]],\n",
      "\n",
      "         [[-7.2367e-01]],\n",
      "\n",
      "         [[ 4.0383e-01]],\n",
      "\n",
      "         [[ 2.1034e-01]],\n",
      "\n",
      "         [[-1.5246e-01]],\n",
      "\n",
      "         [[ 1.4229e-02]],\n",
      "\n",
      "         [[-1.9198e-01]],\n",
      "\n",
      "         [[-6.8563e-02]],\n",
      "\n",
      "         [[ 5.7389e-01]],\n",
      "\n",
      "         [[-4.7412e-02]],\n",
      "\n",
      "         [[ 7.8856e-01]],\n",
      "\n",
      "         [[-2.8092e-01]],\n",
      "\n",
      "         [[-4.3436e-01]],\n",
      "\n",
      "         [[-3.2905e-01]],\n",
      "\n",
      "         [[ 2.8053e-01]],\n",
      "\n",
      "         [[-7.0702e-02]],\n",
      "\n",
      "         [[ 1.0964e+00]]],\n",
      "\n",
      "\n",
      "        [[[-4.6568e-01]],\n",
      "\n",
      "         [[ 2.2922e-01]],\n",
      "\n",
      "         [[-1.6827e-01]],\n",
      "\n",
      "         [[ 3.4887e-01]],\n",
      "\n",
      "         [[-7.1255e-02]],\n",
      "\n",
      "         [[ 1.2292e-01]],\n",
      "\n",
      "         [[ 1.6775e-01]],\n",
      "\n",
      "         [[ 5.3611e-01]],\n",
      "\n",
      "         [[-1.2518e-01]],\n",
      "\n",
      "         [[ 2.2094e-01]],\n",
      "\n",
      "         [[ 2.3881e-01]],\n",
      "\n",
      "         [[ 1.1508e+00]],\n",
      "\n",
      "         [[ 1.0555e+00]],\n",
      "\n",
      "         [[ 1.7168e-01]],\n",
      "\n",
      "         [[-7.9708e-02]],\n",
      "\n",
      "         [[-6.5116e-02]],\n",
      "\n",
      "         [[ 2.6808e-01]],\n",
      "\n",
      "         [[ 2.7714e-01]],\n",
      "\n",
      "         [[ 3.7833e-01]],\n",
      "\n",
      "         [[-6.3077e-01]],\n",
      "\n",
      "         [[-1.9436e-01]],\n",
      "\n",
      "         [[ 1.9040e-01]],\n",
      "\n",
      "         [[ 1.6678e-01]],\n",
      "\n",
      "         [[ 3.9906e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1258e-02]],\n",
      "\n",
      "         [[-9.3429e-02]],\n",
      "\n",
      "         [[ 2.2369e-01]],\n",
      "\n",
      "         [[ 1.4557e-01]],\n",
      "\n",
      "         [[-3.4853e-02]],\n",
      "\n",
      "         [[ 2.7834e-01]],\n",
      "\n",
      "         [[-8.5409e-02]],\n",
      "\n",
      "         [[-1.5131e-01]],\n",
      "\n",
      "         [[-4.6117e-01]],\n",
      "\n",
      "         [[ 4.0419e-01]],\n",
      "\n",
      "         [[ 5.5643e-02]],\n",
      "\n",
      "         [[-2.5532e-01]],\n",
      "\n",
      "         [[ 6.3738e-01]],\n",
      "\n",
      "         [[ 4.1553e-01]],\n",
      "\n",
      "         [[ 1.9081e-01]],\n",
      "\n",
      "         [[-1.9365e-01]],\n",
      "\n",
      "         [[-2.8670e-01]],\n",
      "\n",
      "         [[-7.7285e-01]],\n",
      "\n",
      "         [[ 3.4061e-01]],\n",
      "\n",
      "         [[-1.9219e+00]],\n",
      "\n",
      "         [[ 6.8739e-02]],\n",
      "\n",
      "         [[-3.0384e-01]],\n",
      "\n",
      "         [[ 6.8935e-02]],\n",
      "\n",
      "         [[ 2.3050e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1433e-01]],\n",
      "\n",
      "         [[ 1.1940e-01]],\n",
      "\n",
      "         [[ 1.1492e-01]],\n",
      "\n",
      "         [[ 4.6486e-01]],\n",
      "\n",
      "         [[-2.3432e-01]],\n",
      "\n",
      "         [[-2.1944e-01]],\n",
      "\n",
      "         [[-2.3961e-02]],\n",
      "\n",
      "         [[ 6.8863e-01]],\n",
      "\n",
      "         [[ 6.2295e-01]],\n",
      "\n",
      "         [[ 3.0012e-01]],\n",
      "\n",
      "         [[-7.9007e-01]],\n",
      "\n",
      "         [[ 2.5340e-01]],\n",
      "\n",
      "         [[-3.4033e-02]],\n",
      "\n",
      "         [[ 4.3903e-04]],\n",
      "\n",
      "         [[-6.1385e-01]],\n",
      "\n",
      "         [[ 8.7449e-01]],\n",
      "\n",
      "         [[ 5.5649e-01]],\n",
      "\n",
      "         [[-1.6703e-01]],\n",
      "\n",
      "         [[ 8.0166e-02]],\n",
      "\n",
      "         [[-4.9760e-03]],\n",
      "\n",
      "         [[ 3.2949e-01]],\n",
      "\n",
      "         [[ 1.2205e-01]],\n",
      "\n",
      "         [[-5.1813e-01]],\n",
      "\n",
      "         [[ 4.3941e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3604e-01]],\n",
      "\n",
      "         [[ 1.5474e-02]],\n",
      "\n",
      "         [[ 1.7388e-01]],\n",
      "\n",
      "         [[-7.2998e-01]],\n",
      "\n",
      "         [[ 3.7386e-01]],\n",
      "\n",
      "         [[ 9.3838e-01]],\n",
      "\n",
      "         [[ 3.9058e-01]],\n",
      "\n",
      "         [[ 1.1492e-01]],\n",
      "\n",
      "         [[-2.8444e-01]],\n",
      "\n",
      "         [[ 4.6872e-01]],\n",
      "\n",
      "         [[-5.6841e-02]],\n",
      "\n",
      "         [[-3.8352e-02]],\n",
      "\n",
      "         [[ 2.5964e-01]],\n",
      "\n",
      "         [[ 2.8565e-01]],\n",
      "\n",
      "         [[-5.2752e-01]],\n",
      "\n",
      "         [[-5.4019e-01]],\n",
      "\n",
      "         [[ 2.1848e-01]],\n",
      "\n",
      "         [[-3.4569e-01]],\n",
      "\n",
      "         [[ 4.3584e-01]],\n",
      "\n",
      "         [[-2.4805e-02]],\n",
      "\n",
      "         [[-9.5357e-02]],\n",
      "\n",
      "         [[-5.7992e-02]],\n",
      "\n",
      "         [[ 9.0242e-01]],\n",
      "\n",
      "         [[ 2.7764e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6543e-02]],\n",
      "\n",
      "         [[-6.5124e-01]],\n",
      "\n",
      "         [[-6.4700e-03]],\n",
      "\n",
      "         [[ 5.1444e-01]],\n",
      "\n",
      "         [[-1.1821e-01]],\n",
      "\n",
      "         [[ 3.0653e-02]],\n",
      "\n",
      "         [[ 5.9052e-01]],\n",
      "\n",
      "         [[-3.4069e-01]],\n",
      "\n",
      "         [[-4.3361e-01]],\n",
      "\n",
      "         [[-4.7050e-01]],\n",
      "\n",
      "         [[ 1.6298e-01]],\n",
      "\n",
      "         [[-3.4083e-01]],\n",
      "\n",
      "         [[ 1.5120e-01]],\n",
      "\n",
      "         [[-8.0195e-02]],\n",
      "\n",
      "         [[ 8.1856e-01]],\n",
      "\n",
      "         [[ 7.0050e-01]],\n",
      "\n",
      "         [[-7.1903e-01]],\n",
      "\n",
      "         [[ 3.0992e-01]],\n",
      "\n",
      "         [[ 1.0772e-03]],\n",
      "\n",
      "         [[ 3.0002e-01]],\n",
      "\n",
      "         [[-7.9642e-01]],\n",
      "\n",
      "         [[ 1.8625e-02]],\n",
      "\n",
      "         [[ 1.7271e-01]],\n",
      "\n",
      "         [[ 4.4817e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8869e-01]],\n",
      "\n",
      "         [[-8.3398e-02]],\n",
      "\n",
      "         [[ 3.3014e-02]],\n",
      "\n",
      "         [[-2.6621e-01]],\n",
      "\n",
      "         [[ 3.5908e-01]],\n",
      "\n",
      "         [[-2.2986e-01]],\n",
      "\n",
      "         [[-1.9232e-01]],\n",
      "\n",
      "         [[ 1.4738e-01]],\n",
      "\n",
      "         [[ 6.1304e-01]],\n",
      "\n",
      "         [[-3.1952e-01]],\n",
      "\n",
      "         [[-2.4609e-01]],\n",
      "\n",
      "         [[-1.3751e-01]],\n",
      "\n",
      "         [[-5.4185e-01]],\n",
      "\n",
      "         [[-1.8262e-01]],\n",
      "\n",
      "         [[-3.6047e-01]],\n",
      "\n",
      "         [[ 1.9680e-01]],\n",
      "\n",
      "         [[ 2.7407e-01]],\n",
      "\n",
      "         [[ 9.2193e-01]],\n",
      "\n",
      "         [[-3.9164e-01]],\n",
      "\n",
      "         [[-1.6360e+00]],\n",
      "\n",
      "         [[ 7.5644e-02]],\n",
      "\n",
      "         [[-7.7671e-02]],\n",
      "\n",
      "         [[-3.1384e-02]],\n",
      "\n",
      "         [[-3.4453e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6212e-02]],\n",
      "\n",
      "         [[ 1.0916e-01]],\n",
      "\n",
      "         [[ 5.0144e-01]],\n",
      "\n",
      "         [[ 4.0153e-01]],\n",
      "\n",
      "         [[-2.8152e-02]],\n",
      "\n",
      "         [[ 3.6109e-02]],\n",
      "\n",
      "         [[ 3.5120e-01]],\n",
      "\n",
      "         [[ 1.5484e-01]],\n",
      "\n",
      "         [[-1.2223e+00]],\n",
      "\n",
      "         [[ 7.3972e-01]],\n",
      "\n",
      "         [[ 2.5552e-01]],\n",
      "\n",
      "         [[-2.9483e-01]],\n",
      "\n",
      "         [[ 7.1146e-01]],\n",
      "\n",
      "         [[ 7.7864e-01]],\n",
      "\n",
      "         [[ 2.9835e-01]],\n",
      "\n",
      "         [[ 2.7189e-01]],\n",
      "\n",
      "         [[-8.0761e-01]],\n",
      "\n",
      "         [[-6.3557e-01]],\n",
      "\n",
      "         [[ 9.4689e-01]],\n",
      "\n",
      "         [[ 4.0360e-01]],\n",
      "\n",
      "         [[ 2.7379e-02]],\n",
      "\n",
      "         [[-6.4029e-01]],\n",
      "\n",
      "         [[-6.6415e-02]],\n",
      "\n",
      "         [[-8.2200e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.0400e-01]],\n",
      "\n",
      "         [[ 5.2113e-01]],\n",
      "\n",
      "         [[-2.5715e-01]],\n",
      "\n",
      "         [[ 2.8710e-01]],\n",
      "\n",
      "         [[-6.4840e-01]],\n",
      "\n",
      "         [[ 2.9871e-01]],\n",
      "\n",
      "         [[ 1.1263e+00]],\n",
      "\n",
      "         [[ 1.7753e-01]],\n",
      "\n",
      "         [[-1.2628e-01]],\n",
      "\n",
      "         [[-3.5157e-02]],\n",
      "\n",
      "         [[-1.2912e-01]],\n",
      "\n",
      "         [[-1.4128e-01]],\n",
      "\n",
      "         [[-6.2839e-02]],\n",
      "\n",
      "         [[-4.4198e-01]],\n",
      "\n",
      "         [[ 2.0752e-01]],\n",
      "\n",
      "         [[-7.2788e-01]],\n",
      "\n",
      "         [[ 1.0751e-01]],\n",
      "\n",
      "         [[ 6.3682e-02]],\n",
      "\n",
      "         [[-1.6449e+00]],\n",
      "\n",
      "         [[-4.6205e-01]],\n",
      "\n",
      "         [[ 4.6592e-01]],\n",
      "\n",
      "         [[-2.8347e-01]],\n",
      "\n",
      "         [[-4.7196e-01]],\n",
      "\n",
      "         [[-2.3092e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4778e-01]],\n",
      "\n",
      "         [[-4.9508e-02]],\n",
      "\n",
      "         [[ 5.5196e-02]],\n",
      "\n",
      "         [[ 1.3875e-01]],\n",
      "\n",
      "         [[-1.4047e+00]],\n",
      "\n",
      "         [[ 3.1366e-01]],\n",
      "\n",
      "         [[ 3.6006e-01]],\n",
      "\n",
      "         [[ 2.0974e-01]],\n",
      "\n",
      "         [[-3.9831e-01]],\n",
      "\n",
      "         [[-5.3714e-01]],\n",
      "\n",
      "         [[ 7.0702e-01]],\n",
      "\n",
      "         [[-3.1474e-01]],\n",
      "\n",
      "         [[ 7.5933e-02]],\n",
      "\n",
      "         [[-1.2959e-01]],\n",
      "\n",
      "         [[ 1.4174e-02]],\n",
      "\n",
      "         [[ 5.2644e-01]],\n",
      "\n",
      "         [[ 1.6412e-01]],\n",
      "\n",
      "         [[-2.3339e-01]],\n",
      "\n",
      "         [[ 3.2258e-01]],\n",
      "\n",
      "         [[-1.0132e-01]],\n",
      "\n",
      "         [[ 9.4464e-01]],\n",
      "\n",
      "         [[ 2.2145e-01]],\n",
      "\n",
      "         [[ 1.6338e-01]],\n",
      "\n",
      "         [[-2.3095e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.4750e-01]],\n",
      "\n",
      "         [[ 3.2094e-01]],\n",
      "\n",
      "         [[ 3.0547e-01]],\n",
      "\n",
      "         [[-4.6927e-01]],\n",
      "\n",
      "         [[ 2.0271e-01]],\n",
      "\n",
      "         [[ 5.7645e-01]],\n",
      "\n",
      "         [[-4.4645e-02]],\n",
      "\n",
      "         [[-8.1742e-01]],\n",
      "\n",
      "         [[-3.1134e-01]],\n",
      "\n",
      "         [[ 1.0361e+00]],\n",
      "\n",
      "         [[-3.0315e-01]],\n",
      "\n",
      "         [[ 4.4899e-02]],\n",
      "\n",
      "         [[ 1.6359e-01]],\n",
      "\n",
      "         [[-3.1832e-01]],\n",
      "\n",
      "         [[-2.0346e-02]],\n",
      "\n",
      "         [[ 1.8295e-01]],\n",
      "\n",
      "         [[ 3.7403e-01]],\n",
      "\n",
      "         [[ 5.3729e-02]],\n",
      "\n",
      "         [[ 3.2949e-01]],\n",
      "\n",
      "         [[-4.4351e-01]],\n",
      "\n",
      "         [[-5.8250e-01]],\n",
      "\n",
      "         [[ 5.4977e-01]],\n",
      "\n",
      "         [[ 1.0741e-01]],\n",
      "\n",
      "         [[ 7.7660e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5909e-02]],\n",
      "\n",
      "         [[-6.5385e-01]],\n",
      "\n",
      "         [[-1.5360e-02]],\n",
      "\n",
      "         [[ 1.4305e-01]],\n",
      "\n",
      "         [[-2.5502e-01]],\n",
      "\n",
      "         [[ 1.1943e-01]],\n",
      "\n",
      "         [[-1.7028e-01]],\n",
      "\n",
      "         [[-1.9147e-01]],\n",
      "\n",
      "         [[-5.7501e-01]],\n",
      "\n",
      "         [[ 2.0689e+00]],\n",
      "\n",
      "         [[ 4.6598e-01]],\n",
      "\n",
      "         [[-2.5887e-01]],\n",
      "\n",
      "         [[-7.1100e-02]],\n",
      "\n",
      "         [[-3.0224e-01]],\n",
      "\n",
      "         [[ 2.8940e-01]],\n",
      "\n",
      "         [[-9.3150e-02]],\n",
      "\n",
      "         [[-3.4239e-01]],\n",
      "\n",
      "         [[-3.2205e-01]],\n",
      "\n",
      "         [[-1.2063e-01]],\n",
      "\n",
      "         [[-3.6978e-02]],\n",
      "\n",
      "         [[ 2.4157e-01]],\n",
      "\n",
      "         [[-6.7561e-01]],\n",
      "\n",
      "         [[-6.9711e-02]],\n",
      "\n",
      "         [[-3.1487e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0503e+00]],\n",
      "\n",
      "         [[ 7.4577e-01]],\n",
      "\n",
      "         [[ 2.4252e-01]],\n",
      "\n",
      "         [[-8.4966e-02]],\n",
      "\n",
      "         [[-2.0201e-01]],\n",
      "\n",
      "         [[ 9.5263e-02]],\n",
      "\n",
      "         [[-1.5106e-01]],\n",
      "\n",
      "         [[ 1.9750e-01]],\n",
      "\n",
      "         [[ 4.0686e-01]],\n",
      "\n",
      "         [[-7.9157e-01]],\n",
      "\n",
      "         [[-2.3012e-01]],\n",
      "\n",
      "         [[ 2.9691e-01]],\n",
      "\n",
      "         [[-6.8766e-02]],\n",
      "\n",
      "         [[-4.0504e-01]],\n",
      "\n",
      "         [[-2.1414e-01]],\n",
      "\n",
      "         [[-4.4379e-02]],\n",
      "\n",
      "         [[ 3.3470e-01]],\n",
      "\n",
      "         [[ 2.1035e-01]],\n",
      "\n",
      "         [[-1.6120e-01]],\n",
      "\n",
      "         [[-1.0012e-01]],\n",
      "\n",
      "         [[-7.1835e-02]],\n",
      "\n",
      "         [[ 5.2089e-01]],\n",
      "\n",
      "         [[ 8.3929e-01]],\n",
      "\n",
      "         [[-2.4298e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1819e-01]],\n",
      "\n",
      "         [[-4.6428e-01]],\n",
      "\n",
      "         [[ 6.5240e-01]],\n",
      "\n",
      "         [[ 5.8141e-02]],\n",
      "\n",
      "         [[-5.0553e-02]],\n",
      "\n",
      "         [[-1.1440e-01]],\n",
      "\n",
      "         [[ 6.6481e-01]],\n",
      "\n",
      "         [[ 3.7978e-01]],\n",
      "\n",
      "         [[ 7.8177e-01]],\n",
      "\n",
      "         [[ 2.1157e-01]],\n",
      "\n",
      "         [[-9.3134e-01]],\n",
      "\n",
      "         [[-1.5622e-01]],\n",
      "\n",
      "         [[-3.0889e-01]],\n",
      "\n",
      "         [[ 3.4965e-01]],\n",
      "\n",
      "         [[ 2.0819e-01]],\n",
      "\n",
      "         [[ 3.4395e-01]],\n",
      "\n",
      "         [[ 3.4045e-01]],\n",
      "\n",
      "         [[-6.8353e-01]],\n",
      "\n",
      "         [[ 1.7729e-01]],\n",
      "\n",
      "         [[-1.9963e-01]],\n",
      "\n",
      "         [[ 7.4209e-01]],\n",
      "\n",
      "         [[ 3.9656e-01]],\n",
      "\n",
      "         [[ 3.2640e-01]],\n",
      "\n",
      "         [[ 3.9561e-02]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([2.0243, 2.7833, 3.8372, 4.0741, 1.0889, 1.4839, 3.5451, 3.1635, 6.9901,\n",
      "        7.7066, 3.3659, 1.6293, 4.4213, 1.9938, 1.8455, 2.0930, 3.8998, 7.9504,\n",
      "        3.1037, 3.6158, 2.7215, 2.6969, 0.9980, 3.3962], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.4801, -0.5148,  2.3988,  0.4174,  1.6731, -0.8659, -0.4892, -0.1584,\n",
      "         1.6508,  1.3063,  0.3567,  0.6176,  1.1415,  4.3147, -1.4999,  0.4271,\n",
      "        -1.5980, -0.9073, -1.5180,  0.2317, -0.5327,  0.2581, -0.1308, -2.6170],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.8850]],\n",
      "\n",
      "         [[-0.3232]],\n",
      "\n",
      "         [[-0.3395]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1955]],\n",
      "\n",
      "         [[ 0.5298]],\n",
      "\n",
      "         [[ 0.1478]]],\n",
      "\n",
      "\n",
      "        [[[-0.1199]],\n",
      "\n",
      "         [[-0.4377]],\n",
      "\n",
      "         [[ 0.0056]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3488]],\n",
      "\n",
      "         [[-0.2058]],\n",
      "\n",
      "         [[-0.0358]]],\n",
      "\n",
      "\n",
      "        [[[-1.3412]],\n",
      "\n",
      "         [[-0.6838]],\n",
      "\n",
      "         [[-0.2104]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5324]],\n",
      "\n",
      "         [[-0.7147]],\n",
      "\n",
      "         [[-0.1027]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0128]],\n",
      "\n",
      "         [[ 0.4365]],\n",
      "\n",
      "         [[ 0.0934]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1495]],\n",
      "\n",
      "         [[ 0.0885]],\n",
      "\n",
      "         [[ 0.1530]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2152]],\n",
      "\n",
      "         [[-0.4209]],\n",
      "\n",
      "         [[-0.0517]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4146]],\n",
      "\n",
      "         [[-0.2236]],\n",
      "\n",
      "         [[ 0.2111]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6922]],\n",
      "\n",
      "         [[-0.1304]],\n",
      "\n",
      "         [[-0.4743]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1572]],\n",
      "\n",
      "         [[ 0.4592]],\n",
      "\n",
      "         [[ 0.1822]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 6.0223e-01,  1.8423e+00,  2.7041e+00,  8.9761e-01,  1.3560e+00,\n",
      "         7.9785e-01,  1.5398e-03,  1.7940e+00,  1.0244e-01, -4.1909e-03,\n",
      "         1.1056e+00,  7.8219e-01,  1.6163e+00,  5.1340e-01,  5.1370e-01,\n",
      "         1.4487e+00, -1.4012e+00,  8.6595e-01,  9.0448e-01,  7.2867e-01,\n",
      "         1.9140e+00,  6.9320e-02,  1.1851e+00,  4.8550e-02,  9.6541e-01,\n",
      "         2.4852e+00,  1.2083e+00,  3.4637e-01,  2.0775e+00,  4.9404e+00,\n",
      "         2.4630e+00,  1.1282e+00,  2.7496e+00,  1.0890e+00,  1.1344e+00,\n",
      "         8.4117e-01,  1.6130e-01,  8.5786e-01,  1.2088e+00,  1.6445e+00,\n",
      "         5.3596e+00,  2.8801e+00,  2.2691e+00,  3.0583e+00,  7.3811e-01,\n",
      "         1.2651e+00,  3.4639e+00,  3.7449e-01,  6.7163e-01,  1.4225e+00,\n",
      "         9.6682e-01,  1.8815e+00,  5.8293e+00,  8.3764e-01,  2.1754e+00,\n",
      "         2.8982e-01,  7.2638e-01,  5.4625e-01,  4.2382e+00,  6.8831e-01,\n",
      "         3.3948e+00,  1.8240e+00,  4.0412e-01,  1.4216e+00,  4.7331e+00,\n",
      "         2.0844e+00, -3.9795e-04,  1.4187e-01,  8.4637e-01,  7.2618e-01,\n",
      "         2.9627e+00,  1.3094e+00,  3.7210e-01,  1.1633e+00,  1.3120e+00,\n",
      "         1.0658e+00,  1.2450e+00,  4.0395e-01,  1.5768e+00,  1.1805e+00,\n",
      "         6.3979e-01,  1.9808e+00,  6.4923e-01,  6.9911e-01,  7.1801e-01,\n",
      "         3.6485e+00,  9.6760e-01,  3.0679e-01,  3.4688e+00,  8.9160e-01,\n",
      "         2.0912e-01,  1.1234e+00,  4.0696e+00,  1.0711e+00,  7.4651e-01,\n",
      "         1.2190e+00,  4.6328e-01,  2.8797e+00,  1.5557e+00,  1.2294e+00,\n",
      "         2.3176e+00,  8.4071e-01,  5.2822e+00,  9.7717e-01,  1.6104e-01,\n",
      "         3.2528e+00,  1.6073e+00,  1.3285e+00,  8.3311e-01,  9.4810e-01,\n",
      "         1.8830e-01,  9.1697e-01,  1.0672e-01,  1.2966e+00,  5.5732e+00,\n",
      "         1.6547e+00,  1.5291e-01,  1.8331e+00,  1.7616e+00,  1.6128e+00,\n",
      "         1.9646e+00,  3.9983e+00,  1.7740e+00,  1.9988e+00,  3.4819e+00,\n",
      "         2.9418e+00,  1.5901e+00,  3.5785e-01,  3.8481e+00,  8.2012e-01,\n",
      "         1.2478e+00,  1.3752e+00,  1.6168e+00,  4.9083e+00,  6.5758e-01,\n",
      "         1.3874e+00,  3.5683e+00,  2.5576e+00,  2.2938e+00,  1.0832e+00,\n",
      "         9.5055e-01,  7.3140e-01,  1.3329e+00,  4.3025e+00], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([  1.8659,   0.5845,   1.9982,   1.4575,  -2.0502,   3.0420,  -0.2686,\n",
      "          2.8968,   3.6148,  -0.5079,   2.2936,   2.2284,   2.4879,   1.2897,\n",
      "          0.0946,   2.3970,   2.8415,   1.9275,   2.6005,   2.5434,  -0.0504,\n",
      "          3.4838,   2.6658,   0.1260,   3.0889,  -3.9171,   1.1444,   1.9484,\n",
      "          2.5829,   0.8222,  -2.5815,   2.2671,  -2.0791,   2.3155,   2.6665,\n",
      "          2.4380,   2.5240,   1.5964,   1.4400,   2.6008,  -0.6909,  -0.7852,\n",
      "          3.6553,  -3.4033,   1.9133,   2.1997,   2.5254,   3.2620,   1.0345,\n",
      "          2.2987,  -1.7734,  -1.8056,   2.3208,  -1.1859,   2.2108,   1.8466,\n",
      "         -1.4442,   2.0863,  -5.3670,   2.3311,   1.7551,   2.1879,   1.3076,\n",
      "         -2.8695, -10.6070,   1.8477,  -0.0539,   2.7805,   1.3158,  -0.3909,\n",
      "         -0.1694,   2.6031,   2.3105,   0.3756,   0.5704,   0.8024,   1.5697,\n",
      "          0.0124,   1.9897,  -1.2128,   3.0401,   1.9855,  -1.4727,   1.6658,\n",
      "          0.1132,  -3.7410,   2.9923,   1.4622,  -1.3613,  -0.8992,  -0.1043,\n",
      "          2.0451,   1.7803,   2.0943,   2.0941,   1.6231,  -1.7327,  -4.5214,\n",
      "          2.1481,   0.7361,   3.1624,   2.3744,   0.8871,   2.6529,   0.1284,\n",
      "          4.6737,   1.6963,   2.0214,   1.7109,   1.9275,   1.8358,  -1.4562,\n",
      "          1.7510,   3.3208,   1.1809,  -1.6469,  -0.1812,   2.1532,   2.2875,\n",
      "         -1.3828,  -2.5346,   2.2440,   1.9924,   1.6713,  -2.6801,  -2.3509,\n",
      "         -2.2083,   0.6273,   3.8062,   1.7618,   2.5102,  -1.5469,   1.0299,\n",
      "          2.2145,   5.3636,   4.8248,  -2.5312,   0.0329,  -8.5830,   2.3510,\n",
      "          2.3355,   1.3028,   2.6118,  -6.1122], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.7419,  0.2260, -0.2342],\n",
      "          [-0.1445, -0.9096,  0.0635],\n",
      "          [-0.2840, -0.0020,  0.5606]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0190,  0.1976,  0.2684],\n",
      "          [ 0.4848,  0.8299,  0.6454],\n",
      "          [ 0.1339,  0.3334,  0.2498]]],\n",
      "\n",
      "\n",
      "        [[[-0.0433,  0.0722,  0.1651],\n",
      "          [-0.9161, -0.9039, -0.1829],\n",
      "          [-0.0761, -0.1861, -0.1049]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.7294, -0.1991, -0.1083],\n",
      "          [-0.7819,  0.2047,  0.6920],\n",
      "          [ 0.2488,  0.0624, -0.3836]]],\n",
      "\n",
      "\n",
      "        [[[-0.4753, -0.6399,  0.1080],\n",
      "          [-0.4540, -0.6621, -0.0120],\n",
      "          [-0.2915, -0.2185,  0.1864]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1929,  0.7824,  0.1775],\n",
      "          [ 0.1640,  0.8585,  0.2012],\n",
      "          [ 0.0227,  0.2725,  0.0247]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 3.2767,  2.6390,  1.2984,  4.5218,  1.5432,  5.6352,  6.5423,  1.1193,\n",
      "         4.3309,  4.4674,  4.0488,  5.2422,  4.4327,  5.4835,  4.5616,  3.3268,\n",
      "         4.8347,  4.5177,  5.4996,  5.3215,  4.1034,  4.6647,  3.2074,  4.3590,\n",
      "         4.7878,  2.5751,  4.0164,  5.9381,  4.0913,  4.4158,  2.6177,  5.5375,\n",
      "         5.1785,  3.4372,  1.9867,  3.2737,  3.1014,  4.6258,  4.3939,  2.2286,\n",
      "         3.7788,  3.3107,  7.4044, 12.0555,  5.6244,  4.3304,  3.5078,  3.5517,\n",
      "         5.8244,  2.9919,  6.1301,  4.2306,  4.6887,  2.5509,  4.8908,  3.5178,\n",
      "         1.8227,  5.4643,  3.6751,  3.4382,  3.2870,  3.7902,  5.8333,  2.4196,\n",
      "         8.7220,  4.3774,  3.0544,  4.8479,  4.9317,  2.9714,  2.1772,  3.5776,\n",
      "         5.6245,  3.2179,  2.4910,  2.6027,  4.9144,  1.2750,  5.1683,  2.3733,\n",
      "         5.7045,  4.2336,  1.4632,  3.9762,  3.0930,  3.8387,  4.4865,  4.9912,\n",
      "         3.2285,  1.7326,  3.6793,  4.6286,  4.7662,  5.0277,  5.1702,  4.1761,\n",
      "         1.0310,  3.5408,  3.6345,  1.4373,  4.5396,  1.7019,  4.0988,  4.9417,\n",
      "         4.5922,  6.5759,  2.2994,  3.7310,  5.3365,  4.9155,  3.8306,  1.3943,\n",
      "         4.6192,  4.6272,  3.8626,  3.4972,  3.8946,  4.4369,  4.3757,  4.1346,\n",
      "         2.5988,  3.2030,  3.1727,  3.5749,  4.2590,  2.2833,  2.5152,  4.8981,\n",
      "         6.7678,  5.7853,  3.4246,  1.6637,  4.1592,  5.2557,  4.3275,  3.8776,\n",
      "         6.4614,  2.4588,  6.8320,  5.2062,  4.1258,  4.4706,  2.6716,  7.1734],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.2746e+00,  9.3433e-01,  2.9012e+00, -8.3105e-01,  1.8984e+00,\n",
      "        -4.9896e-01, -4.5867e+00,  1.5268e+00, -9.9055e-01, -7.6002e-01,\n",
      "        -1.2282e+00, -1.6482e-01, -8.9090e-02, -6.9789e-01, -9.3458e-01,\n",
      "        -9.0712e-01, -9.2344e-01, -1.4786e+00, -8.5196e-01, -2.3344e-01,\n",
      "         9.3460e-01, -8.0126e-01, -1.1465e+00, -1.1621e+00, -1.1407e+00,\n",
      "         9.2874e-01, -5.2023e-01, -5.5861e-01, -3.8132e-02,  1.0442e-01,\n",
      "         6.0334e-01, -7.4616e-01,  1.6181e+00, -1.0843e+00,  3.0238e+00,\n",
      "        -1.1914e+00, -1.6268e+00, -1.0043e+00, -8.1269e-01,  1.5632e+00,\n",
      "         3.3666e+00,  2.7647e+00,  1.5148e+00, -8.3543e-01, -7.4551e-01,\n",
      "        -4.6634e-01,  1.4870e+00, -1.2501e+00, -7.1283e-01, -2.4359e+00,\n",
      "        -4.1233e-01, -6.2760e-02,  2.7570e-01,  2.1097e+00, -9.1351e-01,\n",
      "        -1.5055e+00,  1.7321e+00, -6.8161e-01, -3.7656e+00, -1.3570e+00,\n",
      "         1.4949e+00, -1.4762e+00, -6.0465e-01,  1.7601e+00, -5.5959e+00,\n",
      "        -9.8294e-01, -1.0969e+00, -1.3294e+00, -4.4378e-01,  1.4525e+00,\n",
      "         2.0537e+00, -9.9043e-01, -1.0990e+00,  8.1162e-01, -1.6672e+00,\n",
      "         9.9374e-01, -6.2837e-01,  2.9784e+00, -5.2680e-01,  2.3354e+00,\n",
      "        -4.4001e-01,  1.9302e+00,  3.8040e+00, -1.0226e+00,  1.8828e+00,\n",
      "         7.6819e-01, -7.2817e-01, -7.3364e-01,  3.4376e+00,  1.7466e+00,\n",
      "        -8.7018e-01, -1.2236e+00,  7.2841e-01, -7.9337e-01, -1.2646e+00,\n",
      "         7.1103e-01,  5.5141e-03, -1.7547e+00,  5.2686e-01,  3.4253e+00,\n",
      "        -8.2873e-01,  1.9132e+00,  1.4147e+00, -6.9641e-01, -6.7290e-01,\n",
      "         2.1250e-01, -7.8440e-01,  1.1330e+00, -5.4972e-01, -7.7683e-01,\n",
      "        -1.2329e+00,  1.7665e+00, -1.0151e+00, -1.7050e+00,  2.3016e+00,\n",
      "         5.8926e-01, -1.1853e+00, -5.5556e-01,  3.6761e-01,  2.4059e+00,\n",
      "        -1.2999e+00,  1.0712e+00,  3.6436e-01, -1.6162e+00, -7.3698e-01,\n",
      "         4.2777e-01, -1.3637e-01, -9.8050e-01, -7.2303e-01, -6.0657e-01,\n",
      "        -7.8775e-01,  1.6580e+00,  1.2162e-01,  4.7646e-01, -5.9376e+00,\n",
      "         2.1066e+00,  1.8025e+00,  2.7142e+00, -1.0205e+00, -8.4580e-01,\n",
      "        -1.1122e+00, -9.0760e-01, -1.6269e+00,  1.4599e+00], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-1.5900e-01]],\n",
      "\n",
      "         [[ 1.9318e-02]],\n",
      "\n",
      "         [[ 4.8359e-01]],\n",
      "\n",
      "         [[ 9.2557e-02]],\n",
      "\n",
      "         [[ 5.5503e-01]],\n",
      "\n",
      "         [[-2.6351e-02]],\n",
      "\n",
      "         [[-7.7269e-02]],\n",
      "\n",
      "         [[ 2.6324e-01]],\n",
      "\n",
      "         [[ 8.2846e-02]],\n",
      "\n",
      "         [[-2.0762e-03]],\n",
      "\n",
      "         [[-1.4410e-01]],\n",
      "\n",
      "         [[-7.0669e-02]],\n",
      "\n",
      "         [[ 2.1548e-01]],\n",
      "\n",
      "         [[-2.0606e-03]],\n",
      "\n",
      "         [[-9.3169e-02]],\n",
      "\n",
      "         [[-2.7731e-02]],\n",
      "\n",
      "         [[ 1.9792e-02]],\n",
      "\n",
      "         [[-1.0919e-01]],\n",
      "\n",
      "         [[-2.6514e-01]],\n",
      "\n",
      "         [[-7.2078e-02]],\n",
      "\n",
      "         [[-2.1564e-01]],\n",
      "\n",
      "         [[ 7.0224e-02]],\n",
      "\n",
      "         [[ 6.0173e-02]],\n",
      "\n",
      "         [[-3.0134e-01]],\n",
      "\n",
      "         [[ 1.3025e-01]],\n",
      "\n",
      "         [[ 3.2501e-01]],\n",
      "\n",
      "         [[ 9.0573e-02]],\n",
      "\n",
      "         [[-6.7694e-02]],\n",
      "\n",
      "         [[-6.4829e-03]],\n",
      "\n",
      "         [[ 6.9044e-01]],\n",
      "\n",
      "         [[-3.8724e-01]],\n",
      "\n",
      "         [[ 1.1176e-02]],\n",
      "\n",
      "         [[ 6.2413e-01]],\n",
      "\n",
      "         [[-1.0568e-01]],\n",
      "\n",
      "         [[ 7.8770e-02]],\n",
      "\n",
      "         [[-3.5748e-01]],\n",
      "\n",
      "         [[-7.4374e-02]],\n",
      "\n",
      "         [[ 6.4552e-02]],\n",
      "\n",
      "         [[ 7.9937e-02]],\n",
      "\n",
      "         [[-2.5845e-01]],\n",
      "\n",
      "         [[ 2.0870e-02]],\n",
      "\n",
      "         [[-1.8771e-02]],\n",
      "\n",
      "         [[ 7.2155e-01]],\n",
      "\n",
      "         [[ 5.7998e-01]],\n",
      "\n",
      "         [[-3.2165e-03]],\n",
      "\n",
      "         [[ 1.1262e-01]],\n",
      "\n",
      "         [[ 1.5491e-01]],\n",
      "\n",
      "         [[-2.0305e-01]],\n",
      "\n",
      "         [[ 1.0503e-01]],\n",
      "\n",
      "         [[ 3.4372e-01]],\n",
      "\n",
      "         [[ 1.7288e-01]],\n",
      "\n",
      "         [[-2.8678e-01]],\n",
      "\n",
      "         [[ 2.8399e-01]],\n",
      "\n",
      "         [[ 5.2136e-01]],\n",
      "\n",
      "         [[ 3.5791e-02]],\n",
      "\n",
      "         [[-2.6290e-01]],\n",
      "\n",
      "         [[-7.1118e-02]],\n",
      "\n",
      "         [[-1.8848e-01]],\n",
      "\n",
      "         [[ 1.6818e-01]],\n",
      "\n",
      "         [[-3.4569e-01]],\n",
      "\n",
      "         [[ 1.9902e-01]],\n",
      "\n",
      "         [[-2.4841e-01]],\n",
      "\n",
      "         [[ 2.5229e-02]],\n",
      "\n",
      "         [[ 1.7620e-02]],\n",
      "\n",
      "         [[-1.0571e-01]],\n",
      "\n",
      "         [[ 3.1131e-02]],\n",
      "\n",
      "         [[-1.1784e-01]],\n",
      "\n",
      "         [[-1.7210e-02]],\n",
      "\n",
      "         [[-1.8611e-01]],\n",
      "\n",
      "         [[ 6.5664e-02]],\n",
      "\n",
      "         [[ 1.4705e-02]],\n",
      "\n",
      "         [[-1.9426e-01]],\n",
      "\n",
      "         [[-1.1489e-01]],\n",
      "\n",
      "         [[ 9.9364e-01]],\n",
      "\n",
      "         [[-2.9883e-02]],\n",
      "\n",
      "         [[-2.0311e-01]],\n",
      "\n",
      "         [[-1.5819e-01]],\n",
      "\n",
      "         [[ 5.1671e-01]],\n",
      "\n",
      "         [[-1.4421e-01]],\n",
      "\n",
      "         [[ 7.8642e-02]],\n",
      "\n",
      "         [[ 1.7329e-02]],\n",
      "\n",
      "         [[ 2.4837e-01]],\n",
      "\n",
      "         [[ 4.5900e-01]],\n",
      "\n",
      "         [[-1.6226e-01]],\n",
      "\n",
      "         [[ 2.4306e-01]],\n",
      "\n",
      "         [[-2.0667e-01]],\n",
      "\n",
      "         [[-5.3157e-02]],\n",
      "\n",
      "         [[ 1.1424e-02]],\n",
      "\n",
      "         [[ 1.0336e-02]],\n",
      "\n",
      "         [[ 3.4479e-01]],\n",
      "\n",
      "         [[ 4.3014e-01]],\n",
      "\n",
      "         [[-3.0363e-02]],\n",
      "\n",
      "         [[ 2.0596e-01]],\n",
      "\n",
      "         [[-1.0212e-02]],\n",
      "\n",
      "         [[-1.0254e-01]],\n",
      "\n",
      "         [[ 2.8600e-01]],\n",
      "\n",
      "         [[-1.1245e-01]],\n",
      "\n",
      "         [[-3.8517e-01]],\n",
      "\n",
      "         [[ 1.5839e-01]],\n",
      "\n",
      "         [[ 4.3120e-01]],\n",
      "\n",
      "         [[-1.2590e-01]],\n",
      "\n",
      "         [[ 2.3069e-01]],\n",
      "\n",
      "         [[ 1.6233e-01]],\n",
      "\n",
      "         [[-1.3264e-01]],\n",
      "\n",
      "         [[-2.0358e-01]],\n",
      "\n",
      "         [[-2.5425e-01]],\n",
      "\n",
      "         [[-2.1705e-01]],\n",
      "\n",
      "         [[ 2.8725e-01]],\n",
      "\n",
      "         [[-1.0500e-01]],\n",
      "\n",
      "         [[ 1.8478e-02]],\n",
      "\n",
      "         [[-1.6305e-01]],\n",
      "\n",
      "         [[-1.4056e-02]],\n",
      "\n",
      "         [[-2.5102e-02]],\n",
      "\n",
      "         [[-2.6923e-03]],\n",
      "\n",
      "         [[ 3.8148e-01]],\n",
      "\n",
      "         [[-7.0292e-01]],\n",
      "\n",
      "         [[-2.7137e-02]],\n",
      "\n",
      "         [[-2.6151e-02]],\n",
      "\n",
      "         [[ 2.0438e-01]],\n",
      "\n",
      "         [[ 2.3442e-01]],\n",
      "\n",
      "         [[-2.1540e-01]],\n",
      "\n",
      "         [[ 2.0709e-01]],\n",
      "\n",
      "         [[-4.5454e-01]],\n",
      "\n",
      "         [[ 3.2113e-02]],\n",
      "\n",
      "         [[-6.6078e-01]],\n",
      "\n",
      "         [[ 5.0372e-02]],\n",
      "\n",
      "         [[-2.7391e-01]],\n",
      "\n",
      "         [[-7.9986e-02]],\n",
      "\n",
      "         [[ 1.6633e-01]],\n",
      "\n",
      "         [[-5.4272e-02]],\n",
      "\n",
      "         [[ 3.8491e-01]],\n",
      "\n",
      "         [[ 1.1658e-01]],\n",
      "\n",
      "         [[-2.1123e-01]],\n",
      "\n",
      "         [[ 3.1029e-01]],\n",
      "\n",
      "         [[-1.0931e-01]],\n",
      "\n",
      "         [[-2.5098e-01]],\n",
      "\n",
      "         [[ 5.0922e-01]],\n",
      "\n",
      "         [[ 6.6067e-01]],\n",
      "\n",
      "         [[-2.0213e-01]],\n",
      "\n",
      "         [[-5.9966e-02]],\n",
      "\n",
      "         [[ 7.7854e-02]],\n",
      "\n",
      "         [[ 1.1095e-01]],\n",
      "\n",
      "         [[-2.4458e-02]],\n",
      "\n",
      "         [[ 4.9176e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5230e-01]],\n",
      "\n",
      "         [[ 4.5402e-01]],\n",
      "\n",
      "         [[-3.3116e-02]],\n",
      "\n",
      "         [[ 2.7937e-02]],\n",
      "\n",
      "         [[ 3.6748e-01]],\n",
      "\n",
      "         [[ 1.2632e-01]],\n",
      "\n",
      "         [[-6.4855e-03]],\n",
      "\n",
      "         [[ 3.1459e-01]],\n",
      "\n",
      "         [[ 6.9556e-02]],\n",
      "\n",
      "         [[-3.4907e-04]],\n",
      "\n",
      "         [[ 2.5842e-01]],\n",
      "\n",
      "         [[ 1.2138e-01]],\n",
      "\n",
      "         [[ 3.3618e-02]],\n",
      "\n",
      "         [[ 1.7684e-02]],\n",
      "\n",
      "         [[ 5.4881e-02]],\n",
      "\n",
      "         [[ 3.8593e-01]],\n",
      "\n",
      "         [[ 1.5223e-01]],\n",
      "\n",
      "         [[ 8.0906e-02]],\n",
      "\n",
      "         [[ 1.6794e-01]],\n",
      "\n",
      "         [[ 1.5115e-01]],\n",
      "\n",
      "         [[-1.1760e-01]],\n",
      "\n",
      "         [[-6.9518e-02]],\n",
      "\n",
      "         [[-2.1114e-01]],\n",
      "\n",
      "         [[-2.6592e-02]],\n",
      "\n",
      "         [[-5.1105e-02]],\n",
      "\n",
      "         [[-2.3916e-02]],\n",
      "\n",
      "         [[-2.1709e-01]],\n",
      "\n",
      "         [[ 1.0651e-01]],\n",
      "\n",
      "         [[ 2.4833e-02]],\n",
      "\n",
      "         [[-1.5363e-01]],\n",
      "\n",
      "         [[-1.5021e-01]],\n",
      "\n",
      "         [[ 5.7353e-02]],\n",
      "\n",
      "         [[ 2.8995e-01]],\n",
      "\n",
      "         [[-4.8102e-02]],\n",
      "\n",
      "         [[ 5.4428e-01]],\n",
      "\n",
      "         [[ 3.4045e-01]],\n",
      "\n",
      "         [[ 3.6943e-02]],\n",
      "\n",
      "         [[ 1.6977e-01]],\n",
      "\n",
      "         [[ 7.1819e-02]],\n",
      "\n",
      "         [[-7.0977e-01]],\n",
      "\n",
      "         [[ 1.1991e-02]],\n",
      "\n",
      "         [[-3.5686e-02]],\n",
      "\n",
      "         [[-5.2067e-01]],\n",
      "\n",
      "         [[ 5.1395e-01]],\n",
      "\n",
      "         [[ 1.4614e-01]],\n",
      "\n",
      "         [[-2.0697e-02]],\n",
      "\n",
      "         [[-4.7557e-03]],\n",
      "\n",
      "         [[ 2.3126e-01]],\n",
      "\n",
      "         [[ 6.9552e-02]],\n",
      "\n",
      "         [[ 9.3449e-01]],\n",
      "\n",
      "         [[ 1.4744e-01]],\n",
      "\n",
      "         [[-2.0577e-01]],\n",
      "\n",
      "         [[ 2.4048e-02]],\n",
      "\n",
      "         [[ 3.5067e-01]],\n",
      "\n",
      "         [[ 8.9704e-02]],\n",
      "\n",
      "         [[-1.8643e-02]],\n",
      "\n",
      "         [[-8.2311e-02]],\n",
      "\n",
      "         [[ 1.3192e-01]],\n",
      "\n",
      "         [[ 2.9978e-01]],\n",
      "\n",
      "         [[ 3.1107e-01]],\n",
      "\n",
      "         [[-5.8944e-02]],\n",
      "\n",
      "         [[-3.5272e-01]],\n",
      "\n",
      "         [[ 3.3957e-02]],\n",
      "\n",
      "         [[-4.9718e-01]],\n",
      "\n",
      "         [[-1.9601e-02]],\n",
      "\n",
      "         [[ 6.4252e-02]],\n",
      "\n",
      "         [[ 1.4896e-01]],\n",
      "\n",
      "         [[ 1.5665e-01]],\n",
      "\n",
      "         [[ 1.5763e-01]],\n",
      "\n",
      "         [[-1.3298e-01]],\n",
      "\n",
      "         [[ 1.4821e-02]],\n",
      "\n",
      "         [[ 1.0279e-01]],\n",
      "\n",
      "         [[ 1.4765e-01]],\n",
      "\n",
      "         [[-5.1267e-01]],\n",
      "\n",
      "         [[-3.9201e-03]],\n",
      "\n",
      "         [[ 2.6442e-01]],\n",
      "\n",
      "         [[ 1.8133e-01]],\n",
      "\n",
      "         [[-3.0091e-01]],\n",
      "\n",
      "         [[ 1.9843e-01]],\n",
      "\n",
      "         [[-1.8037e-02]],\n",
      "\n",
      "         [[ 8.8001e-02]],\n",
      "\n",
      "         [[-1.5578e-02]],\n",
      "\n",
      "         [[ 3.2738e-02]],\n",
      "\n",
      "         [[ 3.6635e-01]],\n",
      "\n",
      "         [[ 2.2863e-01]],\n",
      "\n",
      "         [[ 9.8944e-01]],\n",
      "\n",
      "         [[ 1.7933e-01]],\n",
      "\n",
      "         [[ 1.7251e-01]],\n",
      "\n",
      "         [[-1.2279e-01]],\n",
      "\n",
      "         [[-1.8548e-01]],\n",
      "\n",
      "         [[ 4.5488e-02]],\n",
      "\n",
      "         [[-8.5692e-02]],\n",
      "\n",
      "         [[ 2.4653e-02]],\n",
      "\n",
      "         [[ 1.5933e-01]],\n",
      "\n",
      "         [[ 1.7824e-01]],\n",
      "\n",
      "         [[-2.3821e-02]],\n",
      "\n",
      "         [[-3.0375e-01]],\n",
      "\n",
      "         [[-2.0074e-01]],\n",
      "\n",
      "         [[-1.2939e-02]],\n",
      "\n",
      "         [[ 1.1988e-01]],\n",
      "\n",
      "         [[ 1.4302e-01]],\n",
      "\n",
      "         [[ 2.1030e-01]],\n",
      "\n",
      "         [[ 4.2262e-02]],\n",
      "\n",
      "         [[ 6.1390e-02]],\n",
      "\n",
      "         [[ 2.7594e-01]],\n",
      "\n",
      "         [[ 2.4112e-01]],\n",
      "\n",
      "         [[ 4.1191e-01]],\n",
      "\n",
      "         [[-1.7337e-02]],\n",
      "\n",
      "         [[ 1.6596e-01]],\n",
      "\n",
      "         [[ 1.7442e-02]],\n",
      "\n",
      "         [[ 2.5676e-01]],\n",
      "\n",
      "         [[ 1.0659e-01]],\n",
      "\n",
      "         [[ 9.8079e-02]],\n",
      "\n",
      "         [[-3.7244e-02]],\n",
      "\n",
      "         [[-1.2067e-01]],\n",
      "\n",
      "         [[-1.1089e-02]],\n",
      "\n",
      "         [[ 2.6262e-01]],\n",
      "\n",
      "         [[ 1.1723e-01]],\n",
      "\n",
      "         [[-1.1254e-02]],\n",
      "\n",
      "         [[-6.1843e-02]],\n",
      "\n",
      "         [[ 4.7331e-02]],\n",
      "\n",
      "         [[-9.9704e-02]],\n",
      "\n",
      "         [[ 4.0631e-01]],\n",
      "\n",
      "         [[-1.7235e-01]],\n",
      "\n",
      "         [[-5.1950e-01]],\n",
      "\n",
      "         [[-1.1015e-01]],\n",
      "\n",
      "         [[ 1.5406e-01]],\n",
      "\n",
      "         [[ 4.1664e-02]],\n",
      "\n",
      "         [[ 2.7444e-01]],\n",
      "\n",
      "         [[ 1.4451e-01]],\n",
      "\n",
      "         [[ 6.6356e-02]],\n",
      "\n",
      "         [[-1.1555e-01]],\n",
      "\n",
      "         [[-1.8480e-01]],\n",
      "\n",
      "         [[ 9.0112e-03]],\n",
      "\n",
      "         [[-3.6736e-02]],\n",
      "\n",
      "         [[-4.6173e-01]],\n",
      "\n",
      "         [[-5.6241e-01]],\n",
      "\n",
      "         [[ 1.2003e-01]],\n",
      "\n",
      "         [[ 8.4521e-02]],\n",
      "\n",
      "         [[ 6.2688e-02]],\n",
      "\n",
      "         [[ 1.4797e-01]],\n",
      "\n",
      "         [[ 7.7807e-02]],\n",
      "\n",
      "         [[-2.4037e-01]],\n",
      "\n",
      "         [[ 3.6772e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.4023e-02]],\n",
      "\n",
      "         [[-3.6930e-01]],\n",
      "\n",
      "         [[-1.7778e-01]],\n",
      "\n",
      "         [[-9.8803e-02]],\n",
      "\n",
      "         [[-1.7628e-01]],\n",
      "\n",
      "         [[ 8.2027e-02]],\n",
      "\n",
      "         [[-6.8946e-02]],\n",
      "\n",
      "         [[-2.4265e-01]],\n",
      "\n",
      "         [[-5.7556e-02]],\n",
      "\n",
      "         [[ 2.1571e-01]],\n",
      "\n",
      "         [[-6.3199e-02]],\n",
      "\n",
      "         [[-2.3952e-01]],\n",
      "\n",
      "         [[-1.7995e-01]],\n",
      "\n",
      "         [[-9.3256e-02]],\n",
      "\n",
      "         [[-3.0821e-02]],\n",
      "\n",
      "         [[-3.0285e-01]],\n",
      "\n",
      "         [[-1.2017e-01]],\n",
      "\n",
      "         [[-1.2586e-01]],\n",
      "\n",
      "         [[-7.0065e-03]],\n",
      "\n",
      "         [[-1.4481e-01]],\n",
      "\n",
      "         [[-1.3901e-01]],\n",
      "\n",
      "         [[ 1.3569e-02]],\n",
      "\n",
      "         [[ 1.5671e-01]],\n",
      "\n",
      "         [[ 3.3261e-02]],\n",
      "\n",
      "         [[-1.2047e-02]],\n",
      "\n",
      "         [[-6.6190e-01]],\n",
      "\n",
      "         [[-1.3059e-02]],\n",
      "\n",
      "         [[-1.5746e-01]],\n",
      "\n",
      "         [[-1.5270e-01]],\n",
      "\n",
      "         [[-6.6337e-01]],\n",
      "\n",
      "         [[-3.1500e-01]],\n",
      "\n",
      "         [[-1.5808e-01]],\n",
      "\n",
      "         [[-1.0443e+00]],\n",
      "\n",
      "         [[-2.4372e-01]],\n",
      "\n",
      "         [[-8.3449e-02]],\n",
      "\n",
      "         [[-1.8848e-01]],\n",
      "\n",
      "         [[-5.8717e-03]],\n",
      "\n",
      "         [[-5.9282e-02]],\n",
      "\n",
      "         [[-1.9870e-01]],\n",
      "\n",
      "         [[-1.4168e-01]],\n",
      "\n",
      "         [[-1.5918e-01]],\n",
      "\n",
      "         [[-2.2345e-01]],\n",
      "\n",
      "         [[-1.8389e-01]],\n",
      "\n",
      "         [[-1.6743e+00]],\n",
      "\n",
      "         [[-2.1420e-01]],\n",
      "\n",
      "         [[-9.7397e-02]],\n",
      "\n",
      "         [[-1.8858e-01]],\n",
      "\n",
      "         [[-5.6490e-02]],\n",
      "\n",
      "         [[-1.9880e-01]],\n",
      "\n",
      "         [[ 1.7043e-01]],\n",
      "\n",
      "         [[-1.2467e-01]],\n",
      "\n",
      "         [[-5.3360e-01]],\n",
      "\n",
      "         [[-1.2884e-01]],\n",
      "\n",
      "         [[-5.0602e-02]],\n",
      "\n",
      "         [[-6.0488e-02]],\n",
      "\n",
      "         [[ 8.0620e-02]],\n",
      "\n",
      "         [[-3.1695e-01]],\n",
      "\n",
      "         [[-1.5310e-01]],\n",
      "\n",
      "         [[-4.2276e-01]],\n",
      "\n",
      "         [[-1.4736e-01]],\n",
      "\n",
      "         [[-8.3964e-02]],\n",
      "\n",
      "         [[ 4.0510e-01]],\n",
      "\n",
      "         [[-1.3901e-01]],\n",
      "\n",
      "         [[-8.2502e-02]],\n",
      "\n",
      "         [[-2.2289e-01]],\n",
      "\n",
      "         [[-9.5289e-01]],\n",
      "\n",
      "         [[-1.4145e-01]],\n",
      "\n",
      "         [[-6.9234e-01]],\n",
      "\n",
      "         [[-1.4422e-01]],\n",
      "\n",
      "         [[-7.3152e-02]],\n",
      "\n",
      "         [[ 1.1241e-01]],\n",
      "\n",
      "         [[-2.9490e-01]],\n",
      "\n",
      "         [[-8.9642e-02]],\n",
      "\n",
      "         [[-3.6141e-01]],\n",
      "\n",
      "         [[-1.0829e-01]],\n",
      "\n",
      "         [[ 1.7461e-02]],\n",
      "\n",
      "         [[-1.4974e-01]],\n",
      "\n",
      "         [[-1.1679e-01]],\n",
      "\n",
      "         [[-9.3503e-02]],\n",
      "\n",
      "         [[-4.7005e-01]],\n",
      "\n",
      "         [[-1.6665e-01]],\n",
      "\n",
      "         [[-1.9618e-01]],\n",
      "\n",
      "         [[ 3.0354e-02]],\n",
      "\n",
      "         [[-1.3002e-01]],\n",
      "\n",
      "         [[-1.6850e-01]],\n",
      "\n",
      "         [[ 1.0875e-01]],\n",
      "\n",
      "         [[-7.6890e-02]],\n",
      "\n",
      "         [[ 3.2651e-03]],\n",
      "\n",
      "         [[-3.6156e-01]],\n",
      "\n",
      "         [[-1.0665e-01]],\n",
      "\n",
      "         [[ 6.7265e-02]],\n",
      "\n",
      "         [[ 3.7931e-02]],\n",
      "\n",
      "         [[-3.9222e-02]],\n",
      "\n",
      "         [[-2.2145e-02]],\n",
      "\n",
      "         [[-5.8203e-01]],\n",
      "\n",
      "         [[-1.9541e-01]],\n",
      "\n",
      "         [[-1.9144e-01]],\n",
      "\n",
      "         [[ 2.0296e-01]],\n",
      "\n",
      "         [[-8.6439e-02]],\n",
      "\n",
      "         [[-1.0436e-03]],\n",
      "\n",
      "         [[-1.0395e-01]],\n",
      "\n",
      "         [[-3.3897e-01]],\n",
      "\n",
      "         [[-7.9588e-02]],\n",
      "\n",
      "         [[-1.3255e-01]],\n",
      "\n",
      "         [[-1.1106e-01]],\n",
      "\n",
      "         [[-4.5234e-01]],\n",
      "\n",
      "         [[-3.2951e-01]],\n",
      "\n",
      "         [[-1.7571e-01]],\n",
      "\n",
      "         [[-3.7304e-02]],\n",
      "\n",
      "         [[-1.5927e-01]],\n",
      "\n",
      "         [[-1.0943e-01]],\n",
      "\n",
      "         [[-1.6603e-01]],\n",
      "\n",
      "         [[-2.1737e-02]],\n",
      "\n",
      "         [[-3.2063e-01]],\n",
      "\n",
      "         [[-1.1807e-01]],\n",
      "\n",
      "         [[-4.4231e-01]],\n",
      "\n",
      "         [[-2.0702e-01]],\n",
      "\n",
      "         [[-9.4527e-02]],\n",
      "\n",
      "         [[-2.1749e-01]],\n",
      "\n",
      "         [[-1.0018e-01]],\n",
      "\n",
      "         [[ 2.5532e-01]],\n",
      "\n",
      "         [[-1.2427e-01]],\n",
      "\n",
      "         [[-2.4589e-01]],\n",
      "\n",
      "         [[ 3.5003e-01]],\n",
      "\n",
      "         [[ 7.9591e-02]],\n",
      "\n",
      "         [[-6.8004e-01]],\n",
      "\n",
      "         [[-6.2680e-02]],\n",
      "\n",
      "         [[ 1.2229e-02]],\n",
      "\n",
      "         [[-2.3964e-01]],\n",
      "\n",
      "         [[-1.1697e-01]],\n",
      "\n",
      "         [[-3.1310e-01]],\n",
      "\n",
      "         [[-2.1745e-01]],\n",
      "\n",
      "         [[ 5.8514e-02]],\n",
      "\n",
      "         [[-4.4605e-02]],\n",
      "\n",
      "         [[-7.2179e-02]],\n",
      "\n",
      "         [[-2.6000e-01]],\n",
      "\n",
      "         [[-1.7473e-01]],\n",
      "\n",
      "         [[-6.5617e-01]],\n",
      "\n",
      "         [[ 2.6457e-03]],\n",
      "\n",
      "         [[-1.5406e-01]],\n",
      "\n",
      "         [[-8.2095e-02]],\n",
      "\n",
      "         [[-1.1090e-01]],\n",
      "\n",
      "         [[-1.1438e-01]],\n",
      "\n",
      "         [[ 7.5432e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2451e-01]],\n",
      "\n",
      "         [[ 5.3828e-02]],\n",
      "\n",
      "         [[-6.3174e-02]],\n",
      "\n",
      "         [[-3.7778e-01]],\n",
      "\n",
      "         [[-2.5719e-01]],\n",
      "\n",
      "         [[-3.8568e-01]],\n",
      "\n",
      "         [[ 1.4788e-01]],\n",
      "\n",
      "         [[-1.5192e-01]],\n",
      "\n",
      "         [[-6.1725e-02]],\n",
      "\n",
      "         [[-1.7360e-02]],\n",
      "\n",
      "         [[-1.8889e-01]],\n",
      "\n",
      "         [[-3.1830e-01]],\n",
      "\n",
      "         [[-3.0173e-01]],\n",
      "\n",
      "         [[-3.3238e-01]],\n",
      "\n",
      "         [[-3.1216e-01]],\n",
      "\n",
      "         [[-3.8012e-04]],\n",
      "\n",
      "         [[-2.0567e-01]],\n",
      "\n",
      "         [[-1.3679e-02]],\n",
      "\n",
      "         [[-5.7401e-01]],\n",
      "\n",
      "         [[-3.0637e-01]],\n",
      "\n",
      "         [[-4.1879e-01]],\n",
      "\n",
      "         [[-2.5429e-01]],\n",
      "\n",
      "         [[-6.6658e-02]],\n",
      "\n",
      "         [[-3.8575e-01]],\n",
      "\n",
      "         [[-3.1629e-01]],\n",
      "\n",
      "         [[-1.0824e+00]],\n",
      "\n",
      "         [[-5.9437e-01]],\n",
      "\n",
      "         [[-4.0217e-01]],\n",
      "\n",
      "         [[-3.5865e-01]],\n",
      "\n",
      "         [[ 3.1630e-02]],\n",
      "\n",
      "         [[ 5.4896e-01]],\n",
      "\n",
      "         [[-3.6319e-01]],\n",
      "\n",
      "         [[ 5.8862e-02]],\n",
      "\n",
      "         [[ 2.2645e-01]],\n",
      "\n",
      "         [[ 6.5648e-02]],\n",
      "\n",
      "         [[ 1.0368e-01]],\n",
      "\n",
      "         [[ 7.1812e-02]],\n",
      "\n",
      "         [[-7.5312e-02]],\n",
      "\n",
      "         [[-5.4863e-01]],\n",
      "\n",
      "         [[ 2.9777e-03]],\n",
      "\n",
      "         [[-5.4453e-01]],\n",
      "\n",
      "         [[-4.9990e-01]],\n",
      "\n",
      "         [[-9.6170e-02]],\n",
      "\n",
      "         [[-2.0697e-01]],\n",
      "\n",
      "         [[-4.5431e-01]],\n",
      "\n",
      "         [[-2.9299e-01]],\n",
      "\n",
      "         [[-2.0801e-01]],\n",
      "\n",
      "         [[-7.2264e-02]],\n",
      "\n",
      "         [[-3.0392e-01]],\n",
      "\n",
      "         [[-5.2551e-02]],\n",
      "\n",
      "         [[ 8.0291e-04]],\n",
      "\n",
      "         [[ 1.5844e-01]],\n",
      "\n",
      "         [[-2.7525e-01]],\n",
      "\n",
      "         [[-3.9532e-01]],\n",
      "\n",
      "         [[-5.8562e-01]],\n",
      "\n",
      "         [[-1.2509e-01]],\n",
      "\n",
      "         [[-2.2314e-01]],\n",
      "\n",
      "         [[-5.1520e-01]],\n",
      "\n",
      "         [[ 1.0469e-01]],\n",
      "\n",
      "         [[ 4.5102e-02]],\n",
      "\n",
      "         [[-2.8441e-01]],\n",
      "\n",
      "         [[-1.8915e-01]],\n",
      "\n",
      "         [[-3.0021e-01]],\n",
      "\n",
      "         [[ 7.2216e-02]],\n",
      "\n",
      "         [[ 1.4493e-02]],\n",
      "\n",
      "         [[ 2.2019e-01]],\n",
      "\n",
      "         [[ 3.5764e-02]],\n",
      "\n",
      "         [[ 2.4897e-01]],\n",
      "\n",
      "         [[-3.3469e-01]],\n",
      "\n",
      "         [[-8.5269e-01]],\n",
      "\n",
      "         [[-1.5384e-01]],\n",
      "\n",
      "         [[-2.5767e-02]],\n",
      "\n",
      "         [[-2.6853e-01]],\n",
      "\n",
      "         [[ 3.4826e-02]],\n",
      "\n",
      "         [[ 2.5652e-01]],\n",
      "\n",
      "         [[-2.4016e-01]],\n",
      "\n",
      "         [[-4.9854e-01]],\n",
      "\n",
      "         [[-1.5611e-01]],\n",
      "\n",
      "         [[-4.9463e-01]],\n",
      "\n",
      "         [[-3.0945e-01]],\n",
      "\n",
      "         [[-3.0100e-01]],\n",
      "\n",
      "         [[-2.3603e-01]],\n",
      "\n",
      "         [[-1.2339e-03]],\n",
      "\n",
      "         [[-1.0008e-01]],\n",
      "\n",
      "         [[-5.1915e-02]],\n",
      "\n",
      "         [[ 3.0019e-02]],\n",
      "\n",
      "         [[-1.9217e-01]],\n",
      "\n",
      "         [[-1.7863e-01]],\n",
      "\n",
      "         [[-5.5241e-01]],\n",
      "\n",
      "         [[-4.2587e-01]],\n",
      "\n",
      "         [[-2.3451e-01]],\n",
      "\n",
      "         [[-6.9561e-01]],\n",
      "\n",
      "         [[-1.8376e-01]],\n",
      "\n",
      "         [[-1.3316e-01]],\n",
      "\n",
      "         [[ 1.3412e-01]],\n",
      "\n",
      "         [[-3.3500e-01]],\n",
      "\n",
      "         [[ 3.8022e-01]],\n",
      "\n",
      "         [[ 4.5184e-01]],\n",
      "\n",
      "         [[-2.8279e-01]],\n",
      "\n",
      "         [[-1.4398e-01]],\n",
      "\n",
      "         [[-3.8499e-01]],\n",
      "\n",
      "         [[-3.4456e-02]],\n",
      "\n",
      "         [[-1.1079e-01]],\n",
      "\n",
      "         [[-5.5402e-01]],\n",
      "\n",
      "         [[-3.7611e-01]],\n",
      "\n",
      "         [[ 6.8340e-03]],\n",
      "\n",
      "         [[-9.0117e-02]],\n",
      "\n",
      "         [[-2.4681e-01]],\n",
      "\n",
      "         [[-2.8397e-01]],\n",
      "\n",
      "         [[-3.2453e-01]],\n",
      "\n",
      "         [[ 1.6082e-02]],\n",
      "\n",
      "         [[-7.2683e-02]],\n",
      "\n",
      "         [[-2.0244e-01]],\n",
      "\n",
      "         [[ 9.1001e-02]],\n",
      "\n",
      "         [[-4.2431e-02]],\n",
      "\n",
      "         [[ 1.9364e-01]],\n",
      "\n",
      "         [[ 1.8974e-01]],\n",
      "\n",
      "         [[-5.0823e-01]],\n",
      "\n",
      "         [[-3.0191e-01]],\n",
      "\n",
      "         [[-5.9232e-02]],\n",
      "\n",
      "         [[ 1.6462e-01]],\n",
      "\n",
      "         [[-1.3258e-01]],\n",
      "\n",
      "         [[-3.7456e-01]],\n",
      "\n",
      "         [[-1.5088e-01]],\n",
      "\n",
      "         [[ 5.4190e-01]],\n",
      "\n",
      "         [[ 1.3929e-01]],\n",
      "\n",
      "         [[-1.9790e-01]],\n",
      "\n",
      "         [[-3.8781e-01]],\n",
      "\n",
      "         [[-4.7532e-01]],\n",
      "\n",
      "         [[-2.7734e-01]],\n",
      "\n",
      "         [[ 1.2819e-01]],\n",
      "\n",
      "         [[-9.1403e-02]],\n",
      "\n",
      "         [[-5.5056e-01]],\n",
      "\n",
      "         [[-1.1777e-01]],\n",
      "\n",
      "         [[-9.0295e-02]],\n",
      "\n",
      "         [[-4.9115e-01]],\n",
      "\n",
      "         [[-7.5506e-01]],\n",
      "\n",
      "         [[-4.6459e-01]],\n",
      "\n",
      "         [[ 9.6740e-01]],\n",
      "\n",
      "         [[-3.6012e-01]],\n",
      "\n",
      "         [[-2.0830e-01]],\n",
      "\n",
      "         [[-1.8392e-01]],\n",
      "\n",
      "         [[ 8.3201e-02]],\n",
      "\n",
      "         [[-1.4521e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4831e-03]],\n",
      "\n",
      "         [[ 2.6065e-01]],\n",
      "\n",
      "         [[-4.5331e-02]],\n",
      "\n",
      "         [[ 9.9774e-03]],\n",
      "\n",
      "         [[-1.9422e-02]],\n",
      "\n",
      "         [[-5.4206e-02]],\n",
      "\n",
      "         [[ 1.0728e-02]],\n",
      "\n",
      "         [[-1.9032e-01]],\n",
      "\n",
      "         [[-2.7462e-02]],\n",
      "\n",
      "         [[ 1.1901e-02]],\n",
      "\n",
      "         [[ 1.4286e-01]],\n",
      "\n",
      "         [[ 6.6675e-02]],\n",
      "\n",
      "         [[ 1.6290e-01]],\n",
      "\n",
      "         [[ 3.7880e-02]],\n",
      "\n",
      "         [[ 4.2884e-02]],\n",
      "\n",
      "         [[ 4.6904e-01]],\n",
      "\n",
      "         [[-5.7821e-02]],\n",
      "\n",
      "         [[-5.4431e-02]],\n",
      "\n",
      "         [[ 3.6241e-02]],\n",
      "\n",
      "         [[ 2.2767e-02]],\n",
      "\n",
      "         [[-7.8785e-02]],\n",
      "\n",
      "         [[ 2.6721e-02]],\n",
      "\n",
      "         [[ 2.1525e-01]],\n",
      "\n",
      "         [[ 1.0067e-01]],\n",
      "\n",
      "         [[-3.6018e-01]],\n",
      "\n",
      "         [[-1.3794e-01]],\n",
      "\n",
      "         [[-1.5849e-01]],\n",
      "\n",
      "         [[ 6.7950e-02]],\n",
      "\n",
      "         [[ 1.9467e-02]],\n",
      "\n",
      "         [[ 2.1496e-01]],\n",
      "\n",
      "         [[-2.1532e-02]],\n",
      "\n",
      "         [[ 8.7311e-02]],\n",
      "\n",
      "         [[-1.5657e-01]],\n",
      "\n",
      "         [[-4.2152e-02]],\n",
      "\n",
      "         [[ 2.4577e-01]],\n",
      "\n",
      "         [[-8.4638e-02]],\n",
      "\n",
      "         [[-6.9136e-03]],\n",
      "\n",
      "         [[ 1.7656e-01]],\n",
      "\n",
      "         [[ 1.1865e-01]],\n",
      "\n",
      "         [[ 4.0074e-01]],\n",
      "\n",
      "         [[ 7.3911e-02]],\n",
      "\n",
      "         [[ 1.1612e-01]],\n",
      "\n",
      "         [[-6.1988e-03]],\n",
      "\n",
      "         [[-4.7096e-01]],\n",
      "\n",
      "         [[ 8.3016e-02]],\n",
      "\n",
      "         [[-1.1101e-02]],\n",
      "\n",
      "         [[ 1.3414e-01]],\n",
      "\n",
      "         [[ 9.1001e-02]],\n",
      "\n",
      "         [[-8.1432e-02]],\n",
      "\n",
      "         [[-6.9689e-01]],\n",
      "\n",
      "         [[ 1.6887e-01]],\n",
      "\n",
      "         [[-3.9763e-02]],\n",
      "\n",
      "         [[ 9.9341e-02]],\n",
      "\n",
      "         [[-7.6290e-01]],\n",
      "\n",
      "         [[ 1.3181e-01]],\n",
      "\n",
      "         [[ 7.3446e-02]],\n",
      "\n",
      "         [[ 1.2730e-01]],\n",
      "\n",
      "         [[ 8.6486e-02]],\n",
      "\n",
      "         [[ 4.6516e-02]],\n",
      "\n",
      "         [[ 6.4894e-02]],\n",
      "\n",
      "         [[ 1.4545e-01]],\n",
      "\n",
      "         [[ 2.4375e-01]],\n",
      "\n",
      "         [[ 3.0003e-02]],\n",
      "\n",
      "         [[ 1.4659e-01]],\n",
      "\n",
      "         [[-8.2358e-02]],\n",
      "\n",
      "         [[-5.0498e-02]],\n",
      "\n",
      "         [[ 3.5359e-02]],\n",
      "\n",
      "         [[-3.2460e-01]],\n",
      "\n",
      "         [[ 4.5563e-02]],\n",
      "\n",
      "         [[-3.0648e-01]],\n",
      "\n",
      "         [[ 1.5055e-01]],\n",
      "\n",
      "         [[ 1.4656e-01]],\n",
      "\n",
      "         [[ 4.4437e-02]],\n",
      "\n",
      "         [[-7.0516e-02]],\n",
      "\n",
      "         [[-1.2784e-01]],\n",
      "\n",
      "         [[-7.1524e-02]],\n",
      "\n",
      "         [[-3.2123e-02]],\n",
      "\n",
      "         [[ 4.3576e-02]],\n",
      "\n",
      "         [[ 3.4187e-02]],\n",
      "\n",
      "         [[ 3.2080e-01]],\n",
      "\n",
      "         [[-7.1473e-03]],\n",
      "\n",
      "         [[ 1.0171e-01]],\n",
      "\n",
      "         [[ 3.5598e-01]],\n",
      "\n",
      "         [[ 8.3795e-02]],\n",
      "\n",
      "         [[ 4.8599e-02]],\n",
      "\n",
      "         [[-6.5988e-01]],\n",
      "\n",
      "         [[ 1.0174e-01]],\n",
      "\n",
      "         [[ 2.0006e-01]],\n",
      "\n",
      "         [[ 2.3306e-01]],\n",
      "\n",
      "         [[ 1.5212e-01]],\n",
      "\n",
      "         [[-3.6273e-01]],\n",
      "\n",
      "         [[-4.4158e-02]],\n",
      "\n",
      "         [[ 4.1643e-02]],\n",
      "\n",
      "         [[ 1.1735e-01]],\n",
      "\n",
      "         [[-1.5151e-01]],\n",
      "\n",
      "         [[ 7.6942e-02]],\n",
      "\n",
      "         [[-2.4143e-02]],\n",
      "\n",
      "         [[ 1.2155e-01]],\n",
      "\n",
      "         [[ 1.1563e-01]],\n",
      "\n",
      "         [[ 3.6365e-01]],\n",
      "\n",
      "         [[ 7.2665e-02]],\n",
      "\n",
      "         [[-2.7947e-01]],\n",
      "\n",
      "         [[ 2.9456e-01]],\n",
      "\n",
      "         [[ 1.0323e-01]],\n",
      "\n",
      "         [[-6.3252e-02]],\n",
      "\n",
      "         [[-2.0167e-01]],\n",
      "\n",
      "         [[-3.0707e-01]],\n",
      "\n",
      "         [[ 7.9988e-02]],\n",
      "\n",
      "         [[ 3.1043e-02]],\n",
      "\n",
      "         [[ 1.2728e-01]],\n",
      "\n",
      "         [[ 4.6389e-02]],\n",
      "\n",
      "         [[-9.3037e-02]],\n",
      "\n",
      "         [[ 5.9757e-02]],\n",
      "\n",
      "         [[-1.0250e-01]],\n",
      "\n",
      "         [[ 1.2845e-01]],\n",
      "\n",
      "         [[ 3.0332e-01]],\n",
      "\n",
      "         [[-7.8226e-02]],\n",
      "\n",
      "         [[ 1.0848e-01]],\n",
      "\n",
      "         [[ 9.0051e-02]],\n",
      "\n",
      "         [[-3.6109e-02]],\n",
      "\n",
      "         [[-4.1850e-02]],\n",
      "\n",
      "         [[-1.3770e-01]],\n",
      "\n",
      "         [[ 1.2149e-01]],\n",
      "\n",
      "         [[ 2.2020e-01]],\n",
      "\n",
      "         [[ 4.2255e-01]],\n",
      "\n",
      "         [[-4.0804e-02]],\n",
      "\n",
      "         [[ 3.6711e-01]],\n",
      "\n",
      "         [[-8.9746e-03]],\n",
      "\n",
      "         [[ 3.0278e-01]],\n",
      "\n",
      "         [[ 5.8331e-02]],\n",
      "\n",
      "         [[-2.7086e-01]],\n",
      "\n",
      "         [[-5.6634e-02]],\n",
      "\n",
      "         [[-9.8409e-02]],\n",
      "\n",
      "         [[-2.2212e-01]],\n",
      "\n",
      "         [[ 1.3063e-01]],\n",
      "\n",
      "         [[ 3.4305e-01]],\n",
      "\n",
      "         [[ 2.7786e-01]],\n",
      "\n",
      "         [[-3.4751e-01]],\n",
      "\n",
      "         [[ 1.4429e-01]],\n",
      "\n",
      "         [[-4.7526e-02]],\n",
      "\n",
      "         [[ 1.9297e-02]],\n",
      "\n",
      "         [[ 9.9722e-02]],\n",
      "\n",
      "         [[ 1.7646e-01]],\n",
      "\n",
      "         [[-3.0450e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0815e-01]],\n",
      "\n",
      "         [[-1.7708e-01]],\n",
      "\n",
      "         [[-1.8548e-01]],\n",
      "\n",
      "         [[-2.0017e-01]],\n",
      "\n",
      "         [[-6.8891e-02]],\n",
      "\n",
      "         [[-7.4098e-02]],\n",
      "\n",
      "         [[-2.0521e+00]],\n",
      "\n",
      "         [[ 1.2898e-02]],\n",
      "\n",
      "         [[-9.1764e-02]],\n",
      "\n",
      "         [[-5.8940e-03]],\n",
      "\n",
      "         [[-3.4031e-04]],\n",
      "\n",
      "         [[-1.5786e-01]],\n",
      "\n",
      "         [[-1.4387e-01]],\n",
      "\n",
      "         [[-1.7786e-01]],\n",
      "\n",
      "         [[-1.4986e-01]],\n",
      "\n",
      "         [[-1.3818e-01]],\n",
      "\n",
      "         [[-1.7865e-01]],\n",
      "\n",
      "         [[ 7.2551e-02]],\n",
      "\n",
      "         [[-1.3223e-02]],\n",
      "\n",
      "         [[-1.2629e-01]],\n",
      "\n",
      "         [[-1.3016e-01]],\n",
      "\n",
      "         [[-1.3107e-01]],\n",
      "\n",
      "         [[-5.3512e-02]],\n",
      "\n",
      "         [[ 8.5956e-03]],\n",
      "\n",
      "         [[-1.7333e-01]],\n",
      "\n",
      "         [[-6.0488e-02]],\n",
      "\n",
      "         [[-1.2826e-01]],\n",
      "\n",
      "         [[-1.0997e-01]],\n",
      "\n",
      "         [[-6.7595e-02]],\n",
      "\n",
      "         [[-2.3755e-01]],\n",
      "\n",
      "         [[-3.6999e-01]],\n",
      "\n",
      "         [[-1.8091e-01]],\n",
      "\n",
      "         [[-2.6080e-02]],\n",
      "\n",
      "         [[-7.4693e-02]],\n",
      "\n",
      "         [[ 3.0285e-02]],\n",
      "\n",
      "         [[ 1.3413e-01]],\n",
      "\n",
      "         [[-3.3442e-02]],\n",
      "\n",
      "         [[-4.6525e-02]],\n",
      "\n",
      "         [[-1.7809e-01]],\n",
      "\n",
      "         [[-3.5735e-01]],\n",
      "\n",
      "         [[-8.3815e-02]],\n",
      "\n",
      "         [[-1.6742e-01]],\n",
      "\n",
      "         [[-1.5137e-01]],\n",
      "\n",
      "         [[-6.1731e-02]],\n",
      "\n",
      "         [[-1.8483e-01]],\n",
      "\n",
      "         [[-1.1651e-01]],\n",
      "\n",
      "         [[-1.0526e-01]],\n",
      "\n",
      "         [[ 1.3248e-02]],\n",
      "\n",
      "         [[-1.8822e-01]],\n",
      "\n",
      "         [[ 3.8600e-02]],\n",
      "\n",
      "         [[-1.8997e-01]],\n",
      "\n",
      "         [[-5.0869e-01]],\n",
      "\n",
      "         [[-2.1474e-01]],\n",
      "\n",
      "         [[-1.0051e-01]],\n",
      "\n",
      "         [[-2.6104e-01]],\n",
      "\n",
      "         [[ 2.0251e-02]],\n",
      "\n",
      "         [[-1.6593e-01]],\n",
      "\n",
      "         [[-2.3760e-02]],\n",
      "\n",
      "         [[-2.1080e-01]],\n",
      "\n",
      "         [[-9.4550e-02]],\n",
      "\n",
      "         [[-1.0052e-01]],\n",
      "\n",
      "         [[ 1.5313e-01]],\n",
      "\n",
      "         [[-2.2631e-01]],\n",
      "\n",
      "         [[-4.7759e-01]],\n",
      "\n",
      "         [[ 2.9574e-01]],\n",
      "\n",
      "         [[-9.7793e-02]],\n",
      "\n",
      "         [[ 4.7765e-02]],\n",
      "\n",
      "         [[-2.2473e-01]],\n",
      "\n",
      "         [[-8.1357e-02]],\n",
      "\n",
      "         [[ 1.2006e-01]],\n",
      "\n",
      "         [[-7.0068e-02]],\n",
      "\n",
      "         [[ 3.7130e-02]],\n",
      "\n",
      "         [[-8.8708e-02]],\n",
      "\n",
      "         [[-1.1162e-01]],\n",
      "\n",
      "         [[-9.6234e-02]],\n",
      "\n",
      "         [[-1.9582e-01]],\n",
      "\n",
      "         [[-3.3378e-02]],\n",
      "\n",
      "         [[-1.3562e-01]],\n",
      "\n",
      "         [[-5.3757e-02]],\n",
      "\n",
      "         [[-1.7723e-01]],\n",
      "\n",
      "         [[-2.0556e-01]],\n",
      "\n",
      "         [[-1.3878e-01]],\n",
      "\n",
      "         [[-1.3204e-01]],\n",
      "\n",
      "         [[ 3.2410e-02]],\n",
      "\n",
      "         [[-8.6907e-01]],\n",
      "\n",
      "         [[-1.0570e-02]],\n",
      "\n",
      "         [[-2.1352e-02]],\n",
      "\n",
      "         [[-5.7260e-02]],\n",
      "\n",
      "         [[-1.7707e-01]],\n",
      "\n",
      "         [[-3.7631e-01]],\n",
      "\n",
      "         [[ 1.3551e-01]],\n",
      "\n",
      "         [[ 9.5165e-02]],\n",
      "\n",
      "         [[-1.6998e-01]],\n",
      "\n",
      "         [[-1.3877e-02]],\n",
      "\n",
      "         [[-1.8425e-01]],\n",
      "\n",
      "         [[-1.5305e-01]],\n",
      "\n",
      "         [[-7.1056e-01]],\n",
      "\n",
      "         [[ 1.9183e-02]],\n",
      "\n",
      "         [[-1.6065e-01]],\n",
      "\n",
      "         [[-1.0233e-01]],\n",
      "\n",
      "         [[ 8.8850e-02]],\n",
      "\n",
      "         [[-3.7913e-01]],\n",
      "\n",
      "         [[-1.3420e-01]],\n",
      "\n",
      "         [[-6.0594e-02]],\n",
      "\n",
      "         [[-3.4569e-02]],\n",
      "\n",
      "         [[-1.0303e-01]],\n",
      "\n",
      "         [[ 4.1778e-02]],\n",
      "\n",
      "         [[-1.7386e-01]],\n",
      "\n",
      "         [[-1.0554e-01]],\n",
      "\n",
      "         [[-2.6465e-01]],\n",
      "\n",
      "         [[ 3.4026e-02]],\n",
      "\n",
      "         [[-2.5717e-01]],\n",
      "\n",
      "         [[-1.1241e-01]],\n",
      "\n",
      "         [[-4.6507e-02]],\n",
      "\n",
      "         [[-4.3326e-02]],\n",
      "\n",
      "         [[-2.5950e-01]],\n",
      "\n",
      "         [[-1.1142e-01]],\n",
      "\n",
      "         [[-5.3598e-02]],\n",
      "\n",
      "         [[-1.3473e-01]],\n",
      "\n",
      "         [[-1.1325e-01]],\n",
      "\n",
      "         [[-3.2034e-01]],\n",
      "\n",
      "         [[-1.4723e-01]],\n",
      "\n",
      "         [[ 8.0480e-03]],\n",
      "\n",
      "         [[ 1.8181e-02]],\n",
      "\n",
      "         [[ 2.4435e-01]],\n",
      "\n",
      "         [[-1.2754e-01]],\n",
      "\n",
      "         [[-2.8086e-01]],\n",
      "\n",
      "         [[-9.3733e-02]],\n",
      "\n",
      "         [[-1.4953e-01]],\n",
      "\n",
      "         [[-1.5313e-01]],\n",
      "\n",
      "         [[-4.9416e-02]],\n",
      "\n",
      "         [[-2.0268e-01]],\n",
      "\n",
      "         [[-1.2680e-01]],\n",
      "\n",
      "         [[-1.4677e-01]],\n",
      "\n",
      "         [[ 7.6572e-03]],\n",
      "\n",
      "         [[-2.2194e-01]],\n",
      "\n",
      "         [[-2.0773e-01]],\n",
      "\n",
      "         [[-2.0187e-01]],\n",
      "\n",
      "         [[ 3.9894e-01]],\n",
      "\n",
      "         [[-2.0223e-01]],\n",
      "\n",
      "         [[-9.2124e-02]],\n",
      "\n",
      "         [[-9.0725e-02]],\n",
      "\n",
      "         [[-1.0292e-02]],\n",
      "\n",
      "         [[-7.2748e-02]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.2247, -0.0402, -0.1689, -0.1513,  0.1090, -0.1636], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-6.9004e-02]],\n",
      "\n",
      "         [[-5.3400e-01]],\n",
      "\n",
      "         [[ 4.0471e-01]],\n",
      "\n",
      "         [[ 3.0564e-01]],\n",
      "\n",
      "         [[-2.4665e-02]],\n",
      "\n",
      "         [[ 5.9387e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9567e-01]],\n",
      "\n",
      "         [[ 4.2767e-01]],\n",
      "\n",
      "         [[-1.6784e-02]],\n",
      "\n",
      "         [[-8.6012e-01]],\n",
      "\n",
      "         [[ 3.4943e-01]],\n",
      "\n",
      "         [[ 1.2736e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.5031e-02]],\n",
      "\n",
      "         [[ 2.4866e-01]],\n",
      "\n",
      "         [[ 6.6907e-02]],\n",
      "\n",
      "         [[-7.9657e-01]],\n",
      "\n",
      "         [[ 2.6785e-01]],\n",
      "\n",
      "         [[ 1.5529e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8656e-01]],\n",
      "\n",
      "         [[ 3.0451e-01]],\n",
      "\n",
      "         [[-9.7222e-02]],\n",
      "\n",
      "         [[ 1.5043e-01]],\n",
      "\n",
      "         [[ 5.8483e-01]],\n",
      "\n",
      "         [[ 7.9063e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.1715e-01]],\n",
      "\n",
      "         [[ 7.3044e-01]],\n",
      "\n",
      "         [[ 2.1359e-02]],\n",
      "\n",
      "         [[-5.2877e-01]],\n",
      "\n",
      "         [[ 5.8370e-01]],\n",
      "\n",
      "         [[ 1.4218e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2734e-01]],\n",
      "\n",
      "         [[ 7.1139e-01]],\n",
      "\n",
      "         [[ 3.7924e-03]],\n",
      "\n",
      "         [[ 1.2613e-01]],\n",
      "\n",
      "         [[ 6.9562e-01]],\n",
      "\n",
      "         [[ 3.9230e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5565e-01]],\n",
      "\n",
      "         [[-2.1515e-01]],\n",
      "\n",
      "         [[-1.1902e-03]],\n",
      "\n",
      "         [[ 9.9027e-01]],\n",
      "\n",
      "         [[-2.9759e-01]],\n",
      "\n",
      "         [[ 1.8500e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5335e-01]],\n",
      "\n",
      "         [[-4.5368e-03]],\n",
      "\n",
      "         [[-8.3947e-01]],\n",
      "\n",
      "         [[-2.3013e-01]],\n",
      "\n",
      "         [[ 1.4625e-01]],\n",
      "\n",
      "         [[ 1.9724e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.7104e-01]],\n",
      "\n",
      "         [[-9.2868e-02]],\n",
      "\n",
      "         [[ 1.0672e-01]],\n",
      "\n",
      "         [[ 2.1684e-01]],\n",
      "\n",
      "         [[-3.2907e-01]],\n",
      "\n",
      "         [[-9.8232e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.0804e-01]],\n",
      "\n",
      "         [[-6.1346e-02]],\n",
      "\n",
      "         [[ 3.0062e-01]],\n",
      "\n",
      "         [[-1.2111e-01]],\n",
      "\n",
      "         [[-2.8951e-01]],\n",
      "\n",
      "         [[ 1.5996e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7001e-01]],\n",
      "\n",
      "         [[ 3.9456e-01]],\n",
      "\n",
      "         [[ 6.9320e-02]],\n",
      "\n",
      "         [[ 2.6899e-02]],\n",
      "\n",
      "         [[ 1.1931e-01]],\n",
      "\n",
      "         [[ 7.2148e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.2763e-01]],\n",
      "\n",
      "         [[ 5.6037e-01]],\n",
      "\n",
      "         [[ 1.0484e-01]],\n",
      "\n",
      "         [[ 1.4843e-01]],\n",
      "\n",
      "         [[ 9.4343e-01]],\n",
      "\n",
      "         [[ 2.5161e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2635e-01]],\n",
      "\n",
      "         [[ 2.7501e-01]],\n",
      "\n",
      "         [[ 1.1812e-01]],\n",
      "\n",
      "         [[ 7.5018e-02]],\n",
      "\n",
      "         [[ 4.9210e-01]],\n",
      "\n",
      "         [[-2.1411e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4180e-01]],\n",
      "\n",
      "         [[ 4.5398e-01]],\n",
      "\n",
      "         [[ 1.1407e-03]],\n",
      "\n",
      "         [[ 5.6060e-02]],\n",
      "\n",
      "         [[ 4.1802e-01]],\n",
      "\n",
      "         [[ 3.2356e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5619e-01]],\n",
      "\n",
      "         [[ 3.9397e-01]],\n",
      "\n",
      "         [[-5.0610e-02]],\n",
      "\n",
      "         [[ 3.2800e-04]],\n",
      "\n",
      "         [[ 4.6601e-01]],\n",
      "\n",
      "         [[ 4.0361e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8043e-01]],\n",
      "\n",
      "         [[ 1.2489e-01]],\n",
      "\n",
      "         [[ 2.9627e-01]],\n",
      "\n",
      "         [[ 4.0029e-02]],\n",
      "\n",
      "         [[ 4.3168e-01]],\n",
      "\n",
      "         [[ 4.0157e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5971e-01]],\n",
      "\n",
      "         [[ 5.5501e-01]],\n",
      "\n",
      "         [[-7.9669e-02]],\n",
      "\n",
      "         [[ 3.2082e-02]],\n",
      "\n",
      "         [[ 4.9105e-01]],\n",
      "\n",
      "         [[ 2.5870e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.8621e-02]],\n",
      "\n",
      "         [[-4.9130e-01]],\n",
      "\n",
      "         [[ 3.1175e-01]],\n",
      "\n",
      "         [[ 4.3052e-01]],\n",
      "\n",
      "         [[-1.7932e-01]],\n",
      "\n",
      "         [[-8.9060e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8789e-01]],\n",
      "\n",
      "         [[ 2.9912e-01]],\n",
      "\n",
      "         [[-5.3259e-02]],\n",
      "\n",
      "         [[ 2.8713e-02]],\n",
      "\n",
      "         [[ 4.1257e-01]],\n",
      "\n",
      "         [[ 2.0460e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.7116e-01]],\n",
      "\n",
      "         [[ 7.4527e-01]],\n",
      "\n",
      "         [[ 4.0613e-02]],\n",
      "\n",
      "         [[ 6.0671e-02]],\n",
      "\n",
      "         [[ 4.3907e-01]],\n",
      "\n",
      "         [[ 1.0473e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6241e-01]],\n",
      "\n",
      "         [[ 5.6565e-01]],\n",
      "\n",
      "         [[ 1.0635e-01]],\n",
      "\n",
      "         [[ 1.0236e-01]],\n",
      "\n",
      "         [[ 9.7985e-01]],\n",
      "\n",
      "         [[ 1.1412e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0123e-01]],\n",
      "\n",
      "         [[-4.5516e-01]],\n",
      "\n",
      "         [[ 1.3606e-01]],\n",
      "\n",
      "         [[ 1.2318e-01]],\n",
      "\n",
      "         [[-4.7669e-01]],\n",
      "\n",
      "         [[-8.9508e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8318e-01]],\n",
      "\n",
      "         [[ 2.2550e-01]],\n",
      "\n",
      "         [[ 1.5277e-01]],\n",
      "\n",
      "         [[-7.9461e-02]],\n",
      "\n",
      "         [[ 2.7374e-01]],\n",
      "\n",
      "         [[ 2.6949e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4434e-01]],\n",
      "\n",
      "         [[ 3.0059e-01]],\n",
      "\n",
      "         [[ 6.7674e-02]],\n",
      "\n",
      "         [[ 1.4020e-01]],\n",
      "\n",
      "         [[ 1.6891e-03]],\n",
      "\n",
      "         [[ 1.5558e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4381e-01]],\n",
      "\n",
      "         [[-4.4585e-02]],\n",
      "\n",
      "         [[ 2.2382e-01]],\n",
      "\n",
      "         [[-1.0283e-01]],\n",
      "\n",
      "         [[ 5.7406e-01]],\n",
      "\n",
      "         [[-2.0327e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8608e-01]],\n",
      "\n",
      "         [[-2.8108e-01]],\n",
      "\n",
      "         [[ 2.6788e-01]],\n",
      "\n",
      "         [[ 1.0204e-01]],\n",
      "\n",
      "         [[-3.8606e-01]],\n",
      "\n",
      "         [[-3.2856e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2541e-01]],\n",
      "\n",
      "         [[ 1.0132e-01]],\n",
      "\n",
      "         [[-1.0780e-01]],\n",
      "\n",
      "         [[-1.5780e-01]],\n",
      "\n",
      "         [[-7.9107e-02]],\n",
      "\n",
      "         [[ 9.7221e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9942e-01]],\n",
      "\n",
      "         [[ 5.6318e-01]],\n",
      "\n",
      "         [[ 1.6569e-01]],\n",
      "\n",
      "         [[ 3.1673e-02]],\n",
      "\n",
      "         [[ 4.8008e-01]],\n",
      "\n",
      "         [[ 3.5390e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7257e-01]],\n",
      "\n",
      "         [[-1.0132e-01]],\n",
      "\n",
      "         [[ 6.1143e-02]],\n",
      "\n",
      "         [[-1.0365e-01]],\n",
      "\n",
      "         [[ 1.6569e-01]],\n",
      "\n",
      "         [[ 8.3789e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7551e-01]],\n",
      "\n",
      "         [[ 1.6455e-01]],\n",
      "\n",
      "         [[ 3.4826e-01]],\n",
      "\n",
      "         [[-3.9033e-01]],\n",
      "\n",
      "         [[ 1.1436e-01]],\n",
      "\n",
      "         [[-1.3194e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.6347e-01]],\n",
      "\n",
      "         [[ 1.0716e-01]],\n",
      "\n",
      "         [[-1.4533e-02]],\n",
      "\n",
      "         [[ 4.2851e-01]],\n",
      "\n",
      "         [[ 5.8460e-02]],\n",
      "\n",
      "         [[ 2.3174e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2024e-01]],\n",
      "\n",
      "         [[ 4.4940e-01]],\n",
      "\n",
      "         [[ 3.5517e-02]],\n",
      "\n",
      "         [[ 2.5158e-02]],\n",
      "\n",
      "         [[ 6.8630e-01]],\n",
      "\n",
      "         [[ 3.5784e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8753e-01]],\n",
      "\n",
      "         [[-4.3347e-01]],\n",
      "\n",
      "         [[ 2.1576e-01]],\n",
      "\n",
      "         [[ 9.0233e-01]],\n",
      "\n",
      "         [[-1.3886e-01]],\n",
      "\n",
      "         [[ 3.8448e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.5351e-01]],\n",
      "\n",
      "         [[ 2.0582e-01]],\n",
      "\n",
      "         [[ 2.2021e-01]],\n",
      "\n",
      "         [[ 3.3981e-01]],\n",
      "\n",
      "         [[ 3.1884e-02]],\n",
      "\n",
      "         [[ 7.4309e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1521e-01]],\n",
      "\n",
      "         [[-1.3189e-01]],\n",
      "\n",
      "         [[ 1.3735e-01]],\n",
      "\n",
      "         [[-2.1775e-01]],\n",
      "\n",
      "         [[-9.8617e-03]],\n",
      "\n",
      "         [[-1.1555e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4683e-01]],\n",
      "\n",
      "         [[ 5.9714e-01]],\n",
      "\n",
      "         [[ 2.8095e-02]],\n",
      "\n",
      "         [[-1.3224e-02]],\n",
      "\n",
      "         [[ 7.1408e-01]],\n",
      "\n",
      "         [[ 6.9016e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9912e-01]],\n",
      "\n",
      "         [[-2.4065e-01]],\n",
      "\n",
      "         [[ 2.3246e-01]],\n",
      "\n",
      "         [[-1.7224e-01]],\n",
      "\n",
      "         [[ 3.1319e-02]],\n",
      "\n",
      "         [[ 2.3076e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9974e-01]],\n",
      "\n",
      "         [[ 6.2024e-01]],\n",
      "\n",
      "         [[ 8.6614e-03]],\n",
      "\n",
      "         [[ 2.0367e-01]],\n",
      "\n",
      "         [[ 6.3346e-01]],\n",
      "\n",
      "         [[ 1.0549e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1833e-01]],\n",
      "\n",
      "         [[ 6.6122e-02]],\n",
      "\n",
      "         [[ 7.0715e-02]],\n",
      "\n",
      "         [[ 8.6532e-02]],\n",
      "\n",
      "         [[ 5.5880e-01]],\n",
      "\n",
      "         [[ 5.5421e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0563e-02]],\n",
      "\n",
      "         [[ 2.7951e-01]],\n",
      "\n",
      "         [[ 3.1223e-02]],\n",
      "\n",
      "         [[-3.0995e-01]],\n",
      "\n",
      "         [[-8.3843e-02]],\n",
      "\n",
      "         [[ 3.4661e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.6269e-01]],\n",
      "\n",
      "         [[ 4.7634e-01]],\n",
      "\n",
      "         [[ 7.7890e-02]],\n",
      "\n",
      "         [[-5.2596e-03]],\n",
      "\n",
      "         [[ 6.9906e-01]],\n",
      "\n",
      "         [[ 1.4388e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2203e-01]],\n",
      "\n",
      "         [[ 4.0271e-01]],\n",
      "\n",
      "         [[ 7.6773e-03]],\n",
      "\n",
      "         [[-8.9324e-02]],\n",
      "\n",
      "         [[ 4.2897e-01]],\n",
      "\n",
      "         [[ 2.0311e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.5977e-01]],\n",
      "\n",
      "         [[-4.5313e-01]],\n",
      "\n",
      "         [[ 8.5731e-01]],\n",
      "\n",
      "         [[-1.2951e-01]],\n",
      "\n",
      "         [[-6.0245e-01]],\n",
      "\n",
      "         [[-1.0786e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.5096e-01]],\n",
      "\n",
      "         [[-1.1191e-01]],\n",
      "\n",
      "         [[ 4.8439e-02]],\n",
      "\n",
      "         [[-2.7914e-01]],\n",
      "\n",
      "         [[-8.3567e-02]],\n",
      "\n",
      "         [[-9.0379e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3322e-01]],\n",
      "\n",
      "         [[ 4.2346e-01]],\n",
      "\n",
      "         [[ 1.4909e-01]],\n",
      "\n",
      "         [[ 8.5036e-02]],\n",
      "\n",
      "         [[ 1.0346e+00]],\n",
      "\n",
      "         [[ 5.9840e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9073e-01]],\n",
      "\n",
      "         [[ 1.4511e-01]],\n",
      "\n",
      "         [[ 8.8005e-02]],\n",
      "\n",
      "         [[ 1.5440e-01]],\n",
      "\n",
      "         [[ 6.0759e-01]],\n",
      "\n",
      "         [[ 1.0789e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9945e-01]],\n",
      "\n",
      "         [[ 4.5425e-01]],\n",
      "\n",
      "         [[ 7.5778e-02]],\n",
      "\n",
      "         [[-4.3467e-02]],\n",
      "\n",
      "         [[ 7.3433e-01]],\n",
      "\n",
      "         [[ 9.9530e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9874e-01]],\n",
      "\n",
      "         [[ 5.6534e-01]],\n",
      "\n",
      "         [[ 6.7753e-03]],\n",
      "\n",
      "         [[ 1.3463e-01]],\n",
      "\n",
      "         [[ 3.5304e-01]],\n",
      "\n",
      "         [[ 3.4383e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5382e-01]],\n",
      "\n",
      "         [[ 8.6866e-02]],\n",
      "\n",
      "         [[-4.6028e-02]],\n",
      "\n",
      "         [[ 1.6454e-01]],\n",
      "\n",
      "         [[ 6.4014e-01]],\n",
      "\n",
      "         [[ 1.2354e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1496e-01]],\n",
      "\n",
      "         [[-2.7265e-01]],\n",
      "\n",
      "         [[-5.2112e-01]],\n",
      "\n",
      "         [[-8.0350e-02]],\n",
      "\n",
      "         [[ 7.4328e-01]],\n",
      "\n",
      "         [[ 3.9099e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4503e-01]],\n",
      "\n",
      "         [[ 2.8027e-02]],\n",
      "\n",
      "         [[ 1.4063e-01]],\n",
      "\n",
      "         [[ 1.2878e-02]],\n",
      "\n",
      "         [[ 3.3691e-01]],\n",
      "\n",
      "         [[ 1.1981e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.8650e-01]],\n",
      "\n",
      "         [[ 4.7750e-02]],\n",
      "\n",
      "         [[ 1.6351e-03]],\n",
      "\n",
      "         [[-3.0591e-01]],\n",
      "\n",
      "         [[ 2.1226e-01]],\n",
      "\n",
      "         [[ 5.1447e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8483e-01]],\n",
      "\n",
      "         [[ 2.8142e-01]],\n",
      "\n",
      "         [[-1.0749e-02]],\n",
      "\n",
      "         [[ 8.8702e-02]],\n",
      "\n",
      "         [[ 6.3796e-01]],\n",
      "\n",
      "         [[ 9.8516e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7600e-01]],\n",
      "\n",
      "         [[ 1.4060e-01]],\n",
      "\n",
      "         [[ 1.8208e-01]],\n",
      "\n",
      "         [[ 1.3159e-01]],\n",
      "\n",
      "         [[ 7.4483e-01]],\n",
      "\n",
      "         [[-8.3371e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2074e-01]],\n",
      "\n",
      "         [[-1.1629e-01]],\n",
      "\n",
      "         [[-9.6997e-02]],\n",
      "\n",
      "         [[ 2.3412e-02]],\n",
      "\n",
      "         [[ 4.1665e-01]],\n",
      "\n",
      "         [[ 2.0339e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.1543e-02]],\n",
      "\n",
      "         [[ 1.7517e-02]],\n",
      "\n",
      "         [[-6.6356e-02]],\n",
      "\n",
      "         [[ 1.4384e-01]],\n",
      "\n",
      "         [[-1.7029e-01]],\n",
      "\n",
      "         [[ 2.5624e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0021e-01]],\n",
      "\n",
      "         [[ 1.2334e-01]],\n",
      "\n",
      "         [[ 1.0691e-01]],\n",
      "\n",
      "         [[ 6.6211e-02]],\n",
      "\n",
      "         [[ 3.4241e-01]],\n",
      "\n",
      "         [[ 5.9837e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8519e-01]],\n",
      "\n",
      "         [[-1.7951e-01]],\n",
      "\n",
      "         [[-7.1218e-02]],\n",
      "\n",
      "         [[ 7.9928e-03]],\n",
      "\n",
      "         [[ 3.7781e-02]],\n",
      "\n",
      "         [[-2.5693e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8195e-01]],\n",
      "\n",
      "         [[-9.1385e-02]],\n",
      "\n",
      "         [[ 5.5995e-02]],\n",
      "\n",
      "         [[-4.9129e-01]],\n",
      "\n",
      "         [[ 2.6901e-01]],\n",
      "\n",
      "         [[-3.3305e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5181e-01]],\n",
      "\n",
      "         [[-8.5331e-04]],\n",
      "\n",
      "         [[ 1.2398e-01]],\n",
      "\n",
      "         [[ 7.0849e-02]],\n",
      "\n",
      "         [[-1.3726e-01]],\n",
      "\n",
      "         [[ 6.0776e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3322e-01]],\n",
      "\n",
      "         [[ 7.3002e-01]],\n",
      "\n",
      "         [[-2.6302e-02]],\n",
      "\n",
      "         [[ 1.3200e-01]],\n",
      "\n",
      "         [[ 5.0910e-01]],\n",
      "\n",
      "         [[ 5.0789e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.0703e-01]],\n",
      "\n",
      "         [[ 5.8233e-01]],\n",
      "\n",
      "         [[ 8.5017e-02]],\n",
      "\n",
      "         [[ 8.0500e-02]],\n",
      "\n",
      "         [[ 6.9491e-01]],\n",
      "\n",
      "         [[ 2.1066e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6870e-01]],\n",
      "\n",
      "         [[ 1.9198e-01]],\n",
      "\n",
      "         [[ 9.7884e-02]],\n",
      "\n",
      "         [[ 1.0775e-01]],\n",
      "\n",
      "         [[ 9.1164e-01]],\n",
      "\n",
      "         [[ 4.0268e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4830e-01]],\n",
      "\n",
      "         [[ 2.7750e-01]],\n",
      "\n",
      "         [[ 1.0022e-01]],\n",
      "\n",
      "         [[-8.3546e-01]],\n",
      "\n",
      "         [[ 2.5622e-01]],\n",
      "\n",
      "         [[-1.0712e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.6592e-01]],\n",
      "\n",
      "         [[-2.6613e-01]],\n",
      "\n",
      "         [[ 1.5720e-01]],\n",
      "\n",
      "         [[-3.4028e-02]],\n",
      "\n",
      "         [[-9.9363e-02]],\n",
      "\n",
      "         [[-2.4389e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9543e-01]],\n",
      "\n",
      "         [[ 2.5651e-01]],\n",
      "\n",
      "         [[ 1.0401e-01]],\n",
      "\n",
      "         [[-6.6225e-02]],\n",
      "\n",
      "         [[ 3.7469e-01]],\n",
      "\n",
      "         [[-1.7922e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.4280e-02]],\n",
      "\n",
      "         [[-1.3082e-01]],\n",
      "\n",
      "         [[ 3.1565e-01]],\n",
      "\n",
      "         [[ 1.3330e-01]],\n",
      "\n",
      "         [[-1.1401e-02]],\n",
      "\n",
      "         [[ 2.4956e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2720e-01]],\n",
      "\n",
      "         [[ 1.2916e-01]],\n",
      "\n",
      "         [[-1.2256e-02]],\n",
      "\n",
      "         [[ 1.6226e-01]],\n",
      "\n",
      "         [[ 8.2267e-02]],\n",
      "\n",
      "         [[ 8.1835e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0003e-01]],\n",
      "\n",
      "         [[ 4.3114e-01]],\n",
      "\n",
      "         [[ 7.0742e-02]],\n",
      "\n",
      "         [[ 8.3293e-02]],\n",
      "\n",
      "         [[ 4.1738e-01]],\n",
      "\n",
      "         [[ 4.5868e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9593e-01]],\n",
      "\n",
      "         [[-4.1208e-01]],\n",
      "\n",
      "         [[-2.0294e-03]],\n",
      "\n",
      "         [[-5.2998e-01]],\n",
      "\n",
      "         [[ 5.2174e-02]],\n",
      "\n",
      "         [[-3.7557e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4561e-01]],\n",
      "\n",
      "         [[ 1.6012e-01]],\n",
      "\n",
      "         [[ 4.1034e-02]],\n",
      "\n",
      "         [[ 7.8073e-02]],\n",
      "\n",
      "         [[ 2.3092e-01]],\n",
      "\n",
      "         [[ 2.4529e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8564e-03]],\n",
      "\n",
      "         [[ 7.6588e-02]],\n",
      "\n",
      "         [[ 4.1556e-01]],\n",
      "\n",
      "         [[ 2.7502e-01]],\n",
      "\n",
      "         [[ 1.0127e-01]],\n",
      "\n",
      "         [[ 9.4305e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8858e-01]],\n",
      "\n",
      "         [[ 4.5419e-01]],\n",
      "\n",
      "         [[ 1.6058e-02]],\n",
      "\n",
      "         [[ 1.1998e-01]],\n",
      "\n",
      "         [[ 7.6304e-01]],\n",
      "\n",
      "         [[ 5.6805e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6327e-01]],\n",
      "\n",
      "         [[ 7.1530e-01]],\n",
      "\n",
      "         [[ 2.1849e-01]],\n",
      "\n",
      "         [[-6.2256e-01]],\n",
      "\n",
      "         [[ 5.9534e-01]],\n",
      "\n",
      "         [[ 3.1645e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0801e-01]],\n",
      "\n",
      "         [[-5.3719e-01]],\n",
      "\n",
      "         [[ 4.2327e-01]],\n",
      "\n",
      "         [[ 1.0324e-01]],\n",
      "\n",
      "         [[-1.4292e-01]],\n",
      "\n",
      "         [[ 9.0849e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2247e-01]],\n",
      "\n",
      "         [[-1.2388e-01]],\n",
      "\n",
      "         [[ 1.4124e-01]],\n",
      "\n",
      "         [[ 1.3457e-01]],\n",
      "\n",
      "         [[ 6.0173e-02]],\n",
      "\n",
      "         [[-3.2188e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7177e-01]],\n",
      "\n",
      "         [[ 1.1086e-01]],\n",
      "\n",
      "         [[-3.6690e-02]],\n",
      "\n",
      "         [[ 4.7542e-02]],\n",
      "\n",
      "         [[ 3.3029e-01]],\n",
      "\n",
      "         [[ 2.7723e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5629e-01]],\n",
      "\n",
      "         [[ 7.1516e-02]],\n",
      "\n",
      "         [[ 7.7772e-02]],\n",
      "\n",
      "         [[-9.6023e-01]],\n",
      "\n",
      "         [[ 2.8998e-02]],\n",
      "\n",
      "         [[-6.0523e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9887e-01]],\n",
      "\n",
      "         [[ 5.2014e-01]],\n",
      "\n",
      "         [[-1.5263e-02]],\n",
      "\n",
      "         [[-3.4220e-02]],\n",
      "\n",
      "         [[ 4.7535e-01]],\n",
      "\n",
      "         [[ 7.4158e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2978e-01]],\n",
      "\n",
      "         [[ 2.8045e-01]],\n",
      "\n",
      "         [[-7.2559e-03]],\n",
      "\n",
      "         [[ 2.6711e-01]],\n",
      "\n",
      "         [[ 3.3626e-01]],\n",
      "\n",
      "         [[ 1.9930e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3068e-01]],\n",
      "\n",
      "         [[ 4.7828e-01]],\n",
      "\n",
      "         [[-4.1644e-02]],\n",
      "\n",
      "         [[ 1.4111e-01]],\n",
      "\n",
      "         [[ 5.6151e-01]],\n",
      "\n",
      "         [[ 1.6339e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4268e-01]],\n",
      "\n",
      "         [[ 3.8173e-01]],\n",
      "\n",
      "         [[ 6.4308e-02]],\n",
      "\n",
      "         [[-1.4070e-01]],\n",
      "\n",
      "         [[ 8.6190e-01]],\n",
      "\n",
      "         [[ 9.6093e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5310e-01]],\n",
      "\n",
      "         [[ 3.5947e-01]],\n",
      "\n",
      "         [[ 7.3805e-02]],\n",
      "\n",
      "         [[ 1.2840e-01]],\n",
      "\n",
      "         [[ 5.0350e-01]],\n",
      "\n",
      "         [[ 5.0077e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0133e-01]],\n",
      "\n",
      "         [[ 5.9867e-01]],\n",
      "\n",
      "         [[ 3.1065e-02]],\n",
      "\n",
      "         [[ 2.0968e-01]],\n",
      "\n",
      "         [[ 4.3731e-01]],\n",
      "\n",
      "         [[ 1.1634e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1413e-01]],\n",
      "\n",
      "         [[ 2.3877e-01]],\n",
      "\n",
      "         [[ 9.5359e-02]],\n",
      "\n",
      "         [[-5.4160e-01]],\n",
      "\n",
      "         [[ 4.9759e-01]],\n",
      "\n",
      "         [[ 2.7604e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.9465e-01]],\n",
      "\n",
      "         [[ 1.2811e-01]],\n",
      "\n",
      "         [[ 3.2845e-02]],\n",
      "\n",
      "         [[-4.3596e-02]],\n",
      "\n",
      "         [[-4.9155e-01]],\n",
      "\n",
      "         [[-4.1260e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4537e-01]],\n",
      "\n",
      "         [[ 4.1180e-01]],\n",
      "\n",
      "         [[ 9.0303e-03]],\n",
      "\n",
      "         [[ 3.0104e-02]],\n",
      "\n",
      "         [[ 4.5997e-01]],\n",
      "\n",
      "         [[ 3.8679e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8253e-01]],\n",
      "\n",
      "         [[ 3.4733e-01]],\n",
      "\n",
      "         [[ 1.1522e-01]],\n",
      "\n",
      "         [[-4.3068e-02]],\n",
      "\n",
      "         [[ 2.4957e-01]],\n",
      "\n",
      "         [[ 2.0517e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2505e-01]],\n",
      "\n",
      "         [[ 5.4708e-01]],\n",
      "\n",
      "         [[-3.6550e-02]],\n",
      "\n",
      "         [[ 1.3371e-01]],\n",
      "\n",
      "         [[ 7.5748e-01]],\n",
      "\n",
      "         [[ 8.9676e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2469e-01]],\n",
      "\n",
      "         [[ 1.9752e-01]],\n",
      "\n",
      "         [[ 2.1736e-01]],\n",
      "\n",
      "         [[-4.9478e-01]],\n",
      "\n",
      "         [[ 2.5879e-01]],\n",
      "\n",
      "         [[ 2.4847e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.7948e-02]],\n",
      "\n",
      "         [[-1.7395e-01]],\n",
      "\n",
      "         [[ 2.9934e-01]],\n",
      "\n",
      "         [[ 3.4362e-01]],\n",
      "\n",
      "         [[ 2.7108e-01]],\n",
      "\n",
      "         [[ 2.3848e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7488e-01]],\n",
      "\n",
      "         [[ 5.3652e-01]],\n",
      "\n",
      "         [[ 5.5302e-02]],\n",
      "\n",
      "         [[ 1.1527e-01]],\n",
      "\n",
      "         [[ 5.5940e-01]],\n",
      "\n",
      "         [[-3.4908e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1198e-01]],\n",
      "\n",
      "         [[ 3.1608e-01]],\n",
      "\n",
      "         [[ 3.7662e-02]],\n",
      "\n",
      "         [[ 7.7009e-02]],\n",
      "\n",
      "         [[ 6.5999e-01]],\n",
      "\n",
      "         [[ 1.1882e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.5342e-01]],\n",
      "\n",
      "         [[ 5.2929e-01]],\n",
      "\n",
      "         [[ 6.1715e-02]],\n",
      "\n",
      "         [[-3.6468e-02]],\n",
      "\n",
      "         [[ 4.7021e-01]],\n",
      "\n",
      "         [[ 5.1754e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6547e-02]],\n",
      "\n",
      "         [[-1.1266e-01]],\n",
      "\n",
      "         [[ 4.1613e-01]],\n",
      "\n",
      "         [[-1.5271e-01]],\n",
      "\n",
      "         [[ 2.2727e-02]],\n",
      "\n",
      "         [[-3.4284e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9692e-01]],\n",
      "\n",
      "         [[ 4.8575e-01]],\n",
      "\n",
      "         [[ 2.0682e-01]],\n",
      "\n",
      "         [[ 2.9220e-03]],\n",
      "\n",
      "         [[ 7.7513e-01]],\n",
      "\n",
      "         [[ 1.2735e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4444e-01]],\n",
      "\n",
      "         [[-3.5860e-01]],\n",
      "\n",
      "         [[ 2.0490e-01]],\n",
      "\n",
      "         [[-2.1896e-01]],\n",
      "\n",
      "         [[-3.4096e-01]],\n",
      "\n",
      "         [[-3.0289e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9905e-01]],\n",
      "\n",
      "         [[-2.9095e-01]],\n",
      "\n",
      "         [[ 5.8539e-03]],\n",
      "\n",
      "         [[-1.4031e-01]],\n",
      "\n",
      "         [[-2.6690e-02]],\n",
      "\n",
      "         [[ 6.6712e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1078e-01]],\n",
      "\n",
      "         [[ 1.0835e-01]],\n",
      "\n",
      "         [[ 1.1765e-01]],\n",
      "\n",
      "         [[ 2.7760e-04]],\n",
      "\n",
      "         [[ 4.1470e-01]],\n",
      "\n",
      "         [[ 6.6686e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5593e-01]],\n",
      "\n",
      "         [[-3.7243e-01]],\n",
      "\n",
      "         [[ 9.9363e-02]],\n",
      "\n",
      "         [[ 4.5383e-01]],\n",
      "\n",
      "         [[-2.0982e-01]],\n",
      "\n",
      "         [[ 6.6859e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.4463e-01]],\n",
      "\n",
      "         [[ 3.6165e-01]],\n",
      "\n",
      "         [[ 9.0336e-02]],\n",
      "\n",
      "         [[-4.3264e-02]],\n",
      "\n",
      "         [[ 3.7457e-01]],\n",
      "\n",
      "         [[ 2.7040e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0266e-01]],\n",
      "\n",
      "         [[ 1.8979e-01]],\n",
      "\n",
      "         [[ 2.3645e-01]],\n",
      "\n",
      "         [[-8.3348e-02]],\n",
      "\n",
      "         [[ 1.9125e-01]],\n",
      "\n",
      "         [[ 3.0998e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6936e-01]],\n",
      "\n",
      "         [[ 6.9032e-01]],\n",
      "\n",
      "         [[-1.1769e-02]],\n",
      "\n",
      "         [[ 8.9124e-02]],\n",
      "\n",
      "         [[ 5.7208e-01]],\n",
      "\n",
      "         [[ 2.9541e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7514e-01]],\n",
      "\n",
      "         [[ 2.4523e-01]],\n",
      "\n",
      "         [[-8.9306e-02]],\n",
      "\n",
      "         [[ 7.1636e-02]],\n",
      "\n",
      "         [[ 4.7636e-01]],\n",
      "\n",
      "         [[ 4.3012e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0855e-01]],\n",
      "\n",
      "         [[ 1.9326e-01]],\n",
      "\n",
      "         [[-2.0782e-02]],\n",
      "\n",
      "         [[ 4.4152e-02]],\n",
      "\n",
      "         [[ 4.3174e-01]],\n",
      "\n",
      "         [[ 1.6711e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.5566e-01]],\n",
      "\n",
      "         [[-5.6585e-01]],\n",
      "\n",
      "         [[ 7.0557e-01]],\n",
      "\n",
      "         [[ 1.7983e-01]],\n",
      "\n",
      "         [[-3.9838e-01]],\n",
      "\n",
      "         [[-3.7639e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.6191e-01]],\n",
      "\n",
      "         [[-6.8103e-02]],\n",
      "\n",
      "         [[ 3.4484e-01]],\n",
      "\n",
      "         [[ 7.1214e-01]],\n",
      "\n",
      "         [[ 7.8921e-02]],\n",
      "\n",
      "         [[ 5.8783e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2112e-01]],\n",
      "\n",
      "         [[ 4.4219e-01]],\n",
      "\n",
      "         [[ 1.4405e-01]],\n",
      "\n",
      "         [[-4.2311e-02]],\n",
      "\n",
      "         [[ 8.0154e-01]],\n",
      "\n",
      "         [[ 2.5272e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2687e-01]],\n",
      "\n",
      "         [[ 7.7922e-02]],\n",
      "\n",
      "         [[-4.9267e-02]],\n",
      "\n",
      "         [[ 1.2651e-01]],\n",
      "\n",
      "         [[ 4.3096e-01]],\n",
      "\n",
      "         [[ 2.6451e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5870e-01]],\n",
      "\n",
      "         [[ 3.0471e-01]],\n",
      "\n",
      "         [[ 1.2876e-01]],\n",
      "\n",
      "         [[ 2.3791e-01]],\n",
      "\n",
      "         [[ 6.1224e-01]],\n",
      "\n",
      "         [[ 1.1673e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0968e-01]],\n",
      "\n",
      "         [[ 6.0609e-01]],\n",
      "\n",
      "         [[ 7.0439e-02]],\n",
      "\n",
      "         [[-1.8679e-03]],\n",
      "\n",
      "         [[ 4.0070e-01]],\n",
      "\n",
      "         [[ 6.8052e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6438e-01]],\n",
      "\n",
      "         [[ 1.0256e-01]],\n",
      "\n",
      "         [[-1.4578e-01]],\n",
      "\n",
      "         [[ 3.4960e-01]],\n",
      "\n",
      "         [[ 6.8352e-02]],\n",
      "\n",
      "         [[ 2.1535e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7555e-01]],\n",
      "\n",
      "         [[ 6.1726e-01]],\n",
      "\n",
      "         [[-3.0166e-02]],\n",
      "\n",
      "         [[ 4.3674e-02]],\n",
      "\n",
      "         [[ 4.6048e-01]],\n",
      "\n",
      "         [[-8.2429e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.8991e-01]],\n",
      "\n",
      "         [[-3.3927e-02]],\n",
      "\n",
      "         [[ 2.5402e-01]],\n",
      "\n",
      "         [[ 1.6357e-01]],\n",
      "\n",
      "         [[ 1.1055e-01]],\n",
      "\n",
      "         [[-1.7475e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7212e-01]],\n",
      "\n",
      "         [[ 2.8936e-01]],\n",
      "\n",
      "         [[-1.0642e-01]],\n",
      "\n",
      "         [[-4.1940e-02]],\n",
      "\n",
      "         [[ 8.8865e-01]],\n",
      "\n",
      "         [[ 1.0783e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.8863e-01]],\n",
      "\n",
      "         [[-6.1721e-01]],\n",
      "\n",
      "         [[-9.0890e-02]],\n",
      "\n",
      "         [[ 8.4199e-01]],\n",
      "\n",
      "         [[-6.8542e-01]],\n",
      "\n",
      "         [[ 7.5741e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8070e-01]],\n",
      "\n",
      "         [[ 1.7442e-01]],\n",
      "\n",
      "         [[ 1.2005e-01]],\n",
      "\n",
      "         [[-5.2312e-03]],\n",
      "\n",
      "         [[ 2.2599e-01]],\n",
      "\n",
      "         [[ 1.1522e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3763e-01]],\n",
      "\n",
      "         [[ 2.3905e-01]],\n",
      "\n",
      "         [[ 9.6833e-02]],\n",
      "\n",
      "         [[-7.0061e-02]],\n",
      "\n",
      "         [[ 4.0372e-01]],\n",
      "\n",
      "         [[ 8.3541e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2215e-01]],\n",
      "\n",
      "         [[ 5.8584e-01]],\n",
      "\n",
      "         [[ 1.5611e-01]],\n",
      "\n",
      "         [[ 8.2817e-02]],\n",
      "\n",
      "         [[ 6.2434e-01]],\n",
      "\n",
      "         [[ 7.8280e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3095e-01]],\n",
      "\n",
      "         [[ 8.5431e-01]],\n",
      "\n",
      "         [[-5.9668e-02]],\n",
      "\n",
      "         [[-3.7244e-01]],\n",
      "\n",
      "         [[ 5.8567e-01]],\n",
      "\n",
      "         [[ 2.4992e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2440e-02]],\n",
      "\n",
      "         [[ 3.5723e-01]],\n",
      "\n",
      "         [[ 8.1271e-02]],\n",
      "\n",
      "         [[-2.6215e-01]],\n",
      "\n",
      "         [[ 6.8621e-02]],\n",
      "\n",
      "         [[ 3.3067e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6892e-01]],\n",
      "\n",
      "         [[ 3.0179e-01]],\n",
      "\n",
      "         [[-6.5323e-02]],\n",
      "\n",
      "         [[ 2.6249e-02]],\n",
      "\n",
      "         [[ 6.7104e-01]],\n",
      "\n",
      "         [[ 3.5058e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7453e-01]],\n",
      "\n",
      "         [[ 5.6931e-02]],\n",
      "\n",
      "         [[ 3.6410e-01]],\n",
      "\n",
      "         [[-3.1324e-01]],\n",
      "\n",
      "         [[ 4.1042e-01]],\n",
      "\n",
      "         [[ 6.2364e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.1334e-02]],\n",
      "\n",
      "         [[-1.6603e-01]],\n",
      "\n",
      "         [[-4.0006e-02]],\n",
      "\n",
      "         [[-8.6312e-02]],\n",
      "\n",
      "         [[-1.1755e-01]],\n",
      "\n",
      "         [[ 1.0798e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4368e-01]],\n",
      "\n",
      "         [[-2.8921e-01]],\n",
      "\n",
      "         [[ 8.0933e-02]],\n",
      "\n",
      "         [[-4.2117e-02]],\n",
      "\n",
      "         [[-3.5878e-01]],\n",
      "\n",
      "         [[ 3.5432e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.3808e-01]],\n",
      "\n",
      "         [[-8.2772e-01]],\n",
      "\n",
      "         [[ 1.1044e-01]],\n",
      "\n",
      "         [[ 9.4872e-01]],\n",
      "\n",
      "         [[-6.5440e-01]],\n",
      "\n",
      "         [[-2.9058e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.9497e-04]],\n",
      "\n",
      "         [[-2.2718e-01]],\n",
      "\n",
      "         [[ 2.1445e-01]],\n",
      "\n",
      "         [[-1.4600e-01]],\n",
      "\n",
      "         [[-1.5255e-01]],\n",
      "\n",
      "         [[ 2.5915e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3132e-01]],\n",
      "\n",
      "         [[ 3.6770e-01]],\n",
      "\n",
      "         [[-1.0436e-01]],\n",
      "\n",
      "         [[ 1.3894e-02]],\n",
      "\n",
      "         [[ 4.9420e-01]],\n",
      "\n",
      "         [[ 8.8368e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5441e-01]],\n",
      "\n",
      "         [[ 1.9351e-01]],\n",
      "\n",
      "         [[ 7.2266e-01]],\n",
      "\n",
      "         [[-6.6091e-02]],\n",
      "\n",
      "         [[-4.5836e-01]],\n",
      "\n",
      "         [[-5.8302e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4952e-01]],\n",
      "\n",
      "         [[ 2.6915e-01]],\n",
      "\n",
      "         [[ 1.0885e-01]],\n",
      "\n",
      "         [[-1.1291e-01]],\n",
      "\n",
      "         [[ 2.8298e-01]],\n",
      "\n",
      "         [[ 4.2013e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2309e-01]],\n",
      "\n",
      "         [[ 1.6224e-02]],\n",
      "\n",
      "         [[ 7.1784e-02]],\n",
      "\n",
      "         [[ 5.7517e-02]],\n",
      "\n",
      "         [[ 3.1469e-01]],\n",
      "\n",
      "         [[ 1.7252e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1007e-01]],\n",
      "\n",
      "         [[ 1.3185e-01]],\n",
      "\n",
      "         [[-3.6119e-02]],\n",
      "\n",
      "         [[ 1.7492e-01]],\n",
      "\n",
      "         [[ 1.3447e-01]],\n",
      "\n",
      "         [[ 4.8438e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9937e-01]],\n",
      "\n",
      "         [[ 3.0985e-01]],\n",
      "\n",
      "         [[ 9.9659e-02]],\n",
      "\n",
      "         [[ 4.5979e-02]],\n",
      "\n",
      "         [[ 7.6855e-01]],\n",
      "\n",
      "         [[ 1.2680e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9989e-01]],\n",
      "\n",
      "         [[ 4.1793e-01]],\n",
      "\n",
      "         [[-5.8371e-03]],\n",
      "\n",
      "         [[ 8.9336e-02]],\n",
      "\n",
      "         [[ 8.3270e-01]],\n",
      "\n",
      "         [[ 8.3087e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7391e-01]],\n",
      "\n",
      "         [[-9.0450e-02]],\n",
      "\n",
      "         [[ 2.6439e-02]],\n",
      "\n",
      "         [[ 1.3167e-01]],\n",
      "\n",
      "         [[-4.0280e-02]],\n",
      "\n",
      "         [[ 1.6500e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4153e-01]],\n",
      "\n",
      "         [[ 1.5163e-01]],\n",
      "\n",
      "         [[ 6.8563e-02]],\n",
      "\n",
      "         [[-6.4181e-01]],\n",
      "\n",
      "         [[ 5.0671e-01]],\n",
      "\n",
      "         [[ 7.0775e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5524e-01]],\n",
      "\n",
      "         [[ 7.2285e-02]],\n",
      "\n",
      "         [[-5.0049e-02]],\n",
      "\n",
      "         [[-2.6709e-01]],\n",
      "\n",
      "         [[-1.5635e-01]],\n",
      "\n",
      "         [[ 7.8139e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8756e-01]],\n",
      "\n",
      "         [[ 7.6511e-01]],\n",
      "\n",
      "         [[ 2.5685e-02]],\n",
      "\n",
      "         [[-6.2497e-01]],\n",
      "\n",
      "         [[ 6.7456e-01]],\n",
      "\n",
      "         [[ 2.4848e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.4345e-01]],\n",
      "\n",
      "         [[ 1.6088e-02]],\n",
      "\n",
      "         [[-1.4018e-01]],\n",
      "\n",
      "         [[-3.4390e-01]],\n",
      "\n",
      "         [[-9.2783e-02]],\n",
      "\n",
      "         [[ 2.2353e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8226e-01]],\n",
      "\n",
      "         [[ 2.3256e-01]],\n",
      "\n",
      "         [[-1.1025e-01]],\n",
      "\n",
      "         [[ 8.6019e-02]],\n",
      "\n",
      "         [[ 5.3153e-01]],\n",
      "\n",
      "         [[ 1.1211e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8236e-02]],\n",
      "\n",
      "         [[ 5.1850e-01]],\n",
      "\n",
      "         [[-1.2679e-01]],\n",
      "\n",
      "         [[ 8.0284e-02]],\n",
      "\n",
      "         [[ 2.1702e-01]],\n",
      "\n",
      "         [[-2.7862e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2562e-01]],\n",
      "\n",
      "         [[ 8.0535e-01]],\n",
      "\n",
      "         [[-1.0990e-01]],\n",
      "\n",
      "         [[ 1.3394e-01]],\n",
      "\n",
      "         [[ 5.8855e-01]],\n",
      "\n",
      "         [[ 1.4139e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1539e-01]],\n",
      "\n",
      "         [[-3.0293e-02]],\n",
      "\n",
      "         [[-3.5876e-02]],\n",
      "\n",
      "         [[-2.8545e-01]],\n",
      "\n",
      "         [[ 3.6745e-01]],\n",
      "\n",
      "         [[ 4.8642e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.8080e-01]],\n",
      "\n",
      "         [[-2.5308e-01]],\n",
      "\n",
      "         [[-1.1543e-01]],\n",
      "\n",
      "         [[-5.7480e-02]],\n",
      "\n",
      "         [[-1.8626e-01]],\n",
      "\n",
      "         [[ 1.7958e-03]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1981,  0.2224,  0.4152,  0.4560,  0.5989,  0.6686, -0.3945,  0.0706,\n",
      "        -0.3927, -0.3943,  0.3024,  0.7453,  0.3548,  0.4901,  0.3319,  0.3523,\n",
      "         0.4433, -0.4613,  0.3382,  0.4454,  0.7249, -0.6123,  0.2179, -0.0757,\n",
      "         0.0628, -0.3671, -0.1743,  0.4329, -0.0456,  0.1219, -0.0336,  0.4619,\n",
      "        -0.1176, -0.0019,  0.3753,  0.6617, -0.2169,  0.5924,  0.2721, -0.0353,\n",
      "         0.5815,  0.4087, -0.3785, -0.1812,  0.5774,  0.4443,  0.6169,  0.5045,\n",
      "         0.2856,  0.1499, -0.0490,  0.1132,  0.4001,  0.4806,  0.0169, -0.3032,\n",
      "         0.2492, -0.1311, -0.1141, -0.1839,  0.5956,  0.7324,  0.3445,  0.0531,\n",
      "        -0.4194,  0.2036, -0.1531,  0.0091,  0.2628, -0.2901,  0.1335, -0.0929,\n",
      "         0.5494,  0.7038, -0.3509,  0.2312,  0.2327,  0.1152,  0.2845,  0.4363,\n",
      "         0.5061,  0.5204,  0.4127,  0.2633,  0.4387, -0.3526,  0.4065,  0.3408,\n",
      "         0.6785,  0.2460,  0.1935,  0.5912,  0.4627,  0.5137, -0.2916,  0.5655,\n",
      "        -0.5370, -0.0939,  0.2470, -0.5176,  0.2665,  0.1245,  0.3267,  0.2994,\n",
      "         0.2275, -0.2731, -0.1588,  0.4814,  0.1787,  0.4655,  0.5518,  0.0938,\n",
      "         0.3715, -0.2300,  0.2918, -0.5854,  0.1853,  0.2048,  0.5899,  0.7066,\n",
      "         0.0876,  0.4529,  0.3287, -0.2031, -0.4842, -0.5785, -0.0244,  0.3785,\n",
      "        -0.0042,  0.2008,  0.0979,  0.1053,  0.4158,  0.5761, -0.2938,  0.2648,\n",
      "        -0.0066,  0.5794, -0.0157,  0.3412,  0.0804,  0.4722,  0.1797, -0.1723],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2518]],\n",
      "\n",
      "         [[ 0.4633]],\n",
      "\n",
      "         [[-0.0240]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6679]],\n",
      "\n",
      "         [[-0.2125]],\n",
      "\n",
      "         [[ 0.0621]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2377]],\n",
      "\n",
      "         [[ 0.3167]],\n",
      "\n",
      "         [[ 0.3182]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1689]],\n",
      "\n",
      "         [[-0.1762]],\n",
      "\n",
      "         [[ 0.1151]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0452]],\n",
      "\n",
      "         [[-0.0057]],\n",
      "\n",
      "         [[-0.4249]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3342]],\n",
      "\n",
      "         [[-0.5890]],\n",
      "\n",
      "         [[ 0.1183]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3202]],\n",
      "\n",
      "         [[-0.1022]],\n",
      "\n",
      "         [[-0.0522]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1939]],\n",
      "\n",
      "         [[ 0.3196]],\n",
      "\n",
      "         [[ 0.0663]]],\n",
      "\n",
      "\n",
      "        [[[-0.1181]],\n",
      "\n",
      "         [[ 0.4482]],\n",
      "\n",
      "         [[ 0.0954]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2835]],\n",
      "\n",
      "         [[ 0.6494]],\n",
      "\n",
      "         [[ 0.1419]]],\n",
      "\n",
      "\n",
      "        [[[-0.2553]],\n",
      "\n",
      "         [[-0.2477]],\n",
      "\n",
      "         [[ 0.0047]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5658]],\n",
      "\n",
      "         [[ 0.1954]],\n",
      "\n",
      "         [[ 0.1073]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([9.5370, 6.6565, 7.4151, 6.2307, 5.5931, 8.0003, 4.0376, 6.5528, 4.7596,\n",
      "        7.2989, 4.7574, 5.3343, 5.9458, 5.7065, 4.6583, 4.9312, 5.8381, 7.0169,\n",
      "        3.1611, 8.4539, 3.7786, 5.7495, 7.9177, 7.0809, 5.8749, 4.8478, 5.4564,\n",
      "        6.4442, 6.0641, 7.9018, 6.7882, 6.3135], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0170, -0.0357,  0.0140,  0.0108, -0.0063, -0.0069,  0.0044, -0.0003,\n",
      "         0.0045, -0.0190, -0.0277,  0.0011,  0.0464,  0.0046,  0.0045, -0.0091,\n",
      "        -0.0092, -0.0229, -0.0454, -0.0622, -0.0107, -0.0230,  0.0317,  0.0208,\n",
      "         0.0291, -0.0003, -0.0018,  0.0377,  0.0257,  0.0336, -0.0295,  0.0171],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0707]],\n",
      "\n",
      "         [[ 0.2284]],\n",
      "\n",
      "         [[ 0.2638]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0449]],\n",
      "\n",
      "         [[-0.4031]],\n",
      "\n",
      "         [[ 0.0648]]],\n",
      "\n",
      "\n",
      "        [[[-0.1337]],\n",
      "\n",
      "         [[ 0.3927]],\n",
      "\n",
      "         [[ 0.3128]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0971]],\n",
      "\n",
      "         [[-0.8619]],\n",
      "\n",
      "         [[ 0.3069]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2777]],\n",
      "\n",
      "         [[ 0.9549]],\n",
      "\n",
      "         [[ 0.6694]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3151]],\n",
      "\n",
      "         [[ 0.5966]],\n",
      "\n",
      "         [[-0.3186]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.5724]],\n",
      "\n",
      "         [[ 0.2752]],\n",
      "\n",
      "         [[ 0.2493]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1163]],\n",
      "\n",
      "         [[-0.3661]],\n",
      "\n",
      "         [[-0.0274]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8006]],\n",
      "\n",
      "         [[ 0.3806]],\n",
      "\n",
      "         [[-0.1090]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1938]],\n",
      "\n",
      "         [[ 0.3086]],\n",
      "\n",
      "         [[-0.2373]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0821]],\n",
      "\n",
      "         [[-0.0638]],\n",
      "\n",
      "         [[-0.2834]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1734]],\n",
      "\n",
      "         [[ 0.1413]],\n",
      "\n",
      "         [[ 0.1482]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.8447e+00,  7.6670e-03,  2.1140e-01,  4.2979e+00,  1.3025e+00,\n",
      "         2.0161e+00,  1.3108e-01,  3.0595e+00,  1.1951e+00,  1.7312e+00,\n",
      "         9.1551e-01,  1.6427e+00,  1.4679e+00,  1.9486e+00,  3.1480e+00,\n",
      "         2.2035e+00,  1.0351e+00,  1.3800e+00,  2.8085e+00,  5.8473e-01,\n",
      "         9.8452e-01,  7.0442e-01,  4.9752e+00,  3.4664e+00,  9.6694e-01,\n",
      "         1.5270e+00,  8.7459e-01,  6.2529e-01,  9.8813e-01,  1.8694e+00,\n",
      "         1.7129e+00,  2.6542e+00,  1.6224e+00,  2.0898e+00,  1.3478e+00,\n",
      "         1.4463e+00,  2.0954e+00,  5.9240e-01,  8.5577e-01,  1.5604e+00,\n",
      "         2.1208e+00,  7.1303e-01,  1.0454e+00,  1.6831e+00,  7.2079e-01,\n",
      "         1.2366e+00, -2.5961e-01,  1.4678e+00,  2.7413e+00,  1.7292e+00,\n",
      "         3.4228e+00,  1.8552e+00,  1.1153e+00,  1.2402e+00,  1.7148e+00,\n",
      "         1.8932e+00,  4.3287e-01,  7.1586e-01,  1.2571e+00,  1.4897e+00,\n",
      "         1.3781e+00,  2.6219e+00,  1.2590e+00,  3.3446e+00,  3.9070e+00,\n",
      "         2.1863e+00,  4.7905e-01,  4.2703e-01,  2.1724e+00,  4.2194e-01,\n",
      "         1.5559e+00,  2.5751e+00,  1.5423e+00,  1.3394e+00,  7.4695e-01,\n",
      "         1.1476e+00,  2.5573e+00,  1.2899e+00,  2.2598e-01,  1.0448e+00,\n",
      "         2.4095e-03,  6.9542e-01,  1.3647e+00,  5.2393e-01,  1.6389e+00,\n",
      "         3.3421e-01,  1.4433e+00,  3.1694e-01,  2.5609e-01,  8.0051e-01,\n",
      "         1.1194e+00,  1.0289e+00,  4.4963e-01,  5.3560e-01,  2.0223e+00,\n",
      "         1.7783e+00,  2.3958e+00,  9.1622e-01,  6.9956e-01,  4.9923e-01,\n",
      "         1.7394e+00,  2.6125e+00,  1.5556e+00,  1.9685e+00,  6.2478e-01,\n",
      "         2.5041e+00,  9.9073e-01,  8.2642e-01,  9.5102e-01,  1.7606e+00,\n",
      "         1.5268e+00,  7.7293e-01,  3.2959e-01,  2.1362e+00,  1.1357e+00,\n",
      "         2.3315e+00,  1.7181e+00,  1.4358e+00,  1.1017e+00,  1.0758e+00,\n",
      "         1.4245e+00,  2.7488e+00,  1.7861e+00,  1.3981e+00,  1.1375e+00,\n",
      "         1.9715e+00,  5.1953e-01,  5.6455e-01,  7.7255e-01,  5.2956e-01,\n",
      "         1.2011e+00,  1.6564e+00,  1.0983e+00,  3.2063e-01,  1.4248e+00,\n",
      "         1.3470e+00,  7.8324e-01,  1.5028e+00,  6.1464e-01,  1.7529e+00,\n",
      "         1.2454e+00,  1.0304e+00,  2.9488e+00,  7.9885e-01,  5.3420e-01,\n",
      "         1.5539e+00,  1.6061e+00,  1.4758e+00,  1.8074e+00,  1.9187e+00,\n",
      "         2.2617e-01,  1.5202e+00,  1.0313e+00,  1.4547e+00,  1.8086e+00,\n",
      "         3.9842e-01,  5.4919e-01,  8.7390e-01,  1.4992e-01,  1.4831e+00,\n",
      "         1.1206e+00,  1.7006e+00,  9.2877e-01,  4.3199e+00,  3.4759e+00,\n",
      "         4.9177e-01,  1.1521e+00,  5.5140e-01,  1.4891e+00,  9.8266e-01,\n",
      "         1.4462e+00,  2.5619e+00,  5.2957e-01,  8.6281e-01,  1.9120e+00,\n",
      "         8.1635e-01,  5.2671e-01,  3.8094e-01,  1.0901e+00,  1.2649e+00,\n",
      "         9.9978e-01,  1.0624e+00,  6.5278e-01,  6.5175e-01,  1.5274e+00,\n",
      "         8.5587e-01,  3.0928e+00,  1.5171e+00,  1.9715e+00,  1.6755e+00,\n",
      "         2.2215e+00,  1.2538e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-7.1799e-01, -1.1364e-01, -9.8862e-02, -5.6063e+00, -6.7307e-01,\n",
      "        -1.9837e+00, -2.5775e-01, -4.3029e+00,  2.3738e-01, -6.1658e-01,\n",
      "        -2.0742e+00, -1.0668e+00, -1.5527e+00, -2.7490e-01, -3.2715e+00,\n",
      "         1.7939e-01,  1.1623e+00, -7.8389e-01, -2.8601e+00,  1.1567e+00,\n",
      "         2.7754e+00, -3.6767e-01,  4.0619e+00, -2.1881e+00,  8.5086e-01,\n",
      "        -8.1098e-01,  1.2685e+00,  8.3668e-01, -7.6662e-01, -8.4122e-01,\n",
      "        -4.3184e-01,  2.2033e+00, -7.8875e-01, -2.0640e+00,  7.5021e-01,\n",
      "         1.3449e+00, -6.3379e-01,  3.8214e-01,  9.6939e-01,  2.4705e+00,\n",
      "        -6.3344e-02,  5.0147e-01,  1.2145e+00,  2.2328e+00, -2.6870e-01,\n",
      "        -8.4554e-01, -5.8331e-01,  2.5004e+00,  2.8915e+00,  2.7762e+00,\n",
      "        -4.3059e-02, -1.1061e+00, -4.4072e-01,  2.0573e+00,  8.4172e-01,\n",
      "         8.1157e-01, -3.1373e-03,  1.5747e+00,  3.5636e+00,  2.0506e+00,\n",
      "        -1.1794e+00,  1.0166e+00, -7.7342e-01, -1.4980e+00, -3.9340e+00,\n",
      "        -1.2752e+00,  1.4211e+00, -1.6683e-01,  1.6970e+00,  1.6838e+00,\n",
      "         2.8026e+00, -6.6465e-01,  1.3432e+00,  1.7377e+00,  3.9911e-01,\n",
      "         2.3901e-01, -6.7980e-01,  9.5964e-01, -1.2330e-01, -2.3875e-01,\n",
      "        -9.0506e-01, -5.2437e-01, -4.6622e+00,  6.9647e-01, -6.0110e-01,\n",
      "        -1.9297e-01,  2.1306e+00,  4.0563e-01,  3.5915e-01,  1.6621e+00,\n",
      "        -2.6029e-01,  1.3153e+00,  1.2904e+00,  1.9137e+00,  3.8381e-02,\n",
      "         2.3000e+00,  1.8746e+00,  1.2487e+00,  1.3098e+00,  2.5333e-01,\n",
      "         1.0376e+00, -4.8593e-01,  2.2101e+00,  7.1921e-01,  8.6813e-02,\n",
      "         1.1328e+00,  1.1826e+00, -7.9599e-01,  1.3918e+00,  1.4355e+00,\n",
      "        -1.0068e+00,  2.1163e-01,  2.2226e-01, -2.1725e+00,  1.0025e+00,\n",
      "         1.3891e+00, -5.7944e-01,  2.1067e+00, -1.1868e+00,  2.7829e+00,\n",
      "         3.4029e-01, -1.4769e+00, -1.0429e+00,  8.9542e-01,  9.7464e-01,\n",
      "        -1.1384e+00,  9.5037e-01, -7.5152e-01,  1.0377e+00, -7.0249e-01,\n",
      "        -1.0415e+00, -1.6918e+00,  2.0788e+00, -3.0402e-01, -4.5416e-01,\n",
      "         2.9134e-01,  7.0005e-01,  1.2298e+00,  1.8449e+00,  1.4474e+00,\n",
      "         9.0334e-01,  1.3564e+00, -1.7278e+00, -3.9796e-01,  6.0940e-02,\n",
      "        -1.1875e+00,  1.2737e-01,  8.9835e-01, -1.3489e+00,  1.1406e-01,\n",
      "         2.6619e-01,  1.7881e+00,  1.5594e+00, -1.5394e+00,  1.6217e+00,\n",
      "        -2.5365e-01,  1.3050e+00, -7.0141e-01,  7.3737e-01,  1.8483e+00,\n",
      "         1.8624e+00, -3.5224e-01, -7.0917e-01, -3.9208e+00, -1.4739e+00,\n",
      "        -1.0498e-02, -1.3278e+00,  4.4360e-01,  4.8528e-01, -1.5266e-01,\n",
      "         3.0202e-01, -1.3248e+00,  5.1642e-03,  7.2978e-01,  1.5401e+00,\n",
      "        -8.7068e-01, -1.6492e-01,  1.2222e+00, -6.1391e-01,  1.9043e+00,\n",
      "        -1.1906e+00,  1.7758e+00, -1.7226e+00, -1.9367e-01,  1.6406e+00,\n",
      "         1.6402e+00, -1.1173e+00, -8.7788e-01, -1.2654e+00,  7.1822e-01,\n",
      "        -6.6611e-01,  2.5778e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 1.5878e-01,  2.9019e-01,  2.3767e-01],\n",
      "          [ 4.5031e-01,  6.1252e-01,  8.1448e-01],\n",
      "          [-2.4055e-02, -3.9652e-02,  1.8605e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.0110e-01,  3.8601e-01,  7.6641e-02],\n",
      "          [-7.1501e-01, -9.1601e-02,  2.0814e-01],\n",
      "          [-6.7777e-01, -7.5796e-01, -3.7111e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.0402e-01,  3.7776e-01,  2.6785e-02],\n",
      "          [-8.0222e-01,  6.6475e-01, -1.1554e-01],\n",
      "          [-2.2519e-01,  3.9347e-01, -4.1423e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.4974e-01, -3.4269e-01, -3.5680e-01],\n",
      "          [-3.3206e-01,  1.2144e+00, -2.2559e-01],\n",
      "          [ 5.5559e-04, -1.5032e-01, -5.1544e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.9940e-02,  4.9011e-02,  4.9976e-01],\n",
      "          [ 6.7740e-02, -9.6267e-01, -3.6426e-04],\n",
      "          [ 4.2752e-01,  6.8945e-02, -5.9389e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6723e-01, -4.4906e-01, -1.1039e-02],\n",
      "          [-4.8490e-02,  9.4331e-01,  1.1684e-02],\n",
      "          [ 2.0520e-02, -3.9958e-02,  5.5721e-01]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.5303, 2.1264, 2.3907, 3.0842, 1.6949, 0.1267, 2.2182, 5.1811, 1.3714,\n",
      "        1.7665, 1.8197, 2.4613, 1.1997, 1.3286, 1.6507, 2.9158, 1.4110, 0.7310,\n",
      "        0.6248, 1.9684, 1.4186, 1.4210, 4.9250, 3.7515, 2.7697, 1.3603, 0.8805,\n",
      "        1.7664, 2.1411, 3.0517, 3.2281, 1.9910, 0.8225, 0.1614, 1.7355, 2.0539,\n",
      "        1.3929, 2.6788, 1.5499, 1.7718, 1.0127, 2.4621, 1.9212, 1.7423, 0.7257,\n",
      "        2.7062, 1.7867, 1.8808, 2.3134, 2.3637, 0.5628, 0.9200, 1.1861, 1.6963,\n",
      "        1.4679, 1.9827, 2.4858, 1.9863, 2.2570, 1.9013, 1.3931, 1.0672, 0.3306,\n",
      "        1.6118, 1.9160, 0.8492, 1.3595, 2.6954, 2.0978, 1.5931, 3.2217, 1.9299,\n",
      "        1.5938, 1.6808, 1.1717, 1.1382, 1.0446, 2.6899, 1.2893, 1.7496, 0.2297,\n",
      "        1.5893, 3.2805, 1.5038, 1.6777, 1.7711, 2.2714, 1.9572, 2.9239, 1.9700,\n",
      "        1.1132, 2.1435, 1.6753, 1.7685, 0.7879, 2.4538, 1.7466, 1.9696, 1.3755,\n",
      "        1.4838, 1.8152, 0.5826, 1.7872, 1.5081, 1.9475, 1.0082, 1.3702, 0.8539,\n",
      "        1.7583, 1.3153, 0.7441, 2.1000, 2.4832, 1.4199, 2.2814, 2.2191, 2.4425,\n",
      "        2.1679, 0.8247, 1.7038, 0.8570, 1.3029, 0.0978, 1.7570, 1.5939, 0.5122,\n",
      "        2.3774, 1.5957, 1.5314, 1.5055, 1.1465, 2.2227, 2.1485, 2.7070, 1.4889,\n",
      "        1.6648, 1.8955, 1.9273, 1.5175, 1.9488, 1.9092, 2.2932, 0.7264, 1.6215,\n",
      "        1.4132, 1.5841, 1.0510, 0.9813, 1.1661, 1.3699, 2.1711, 2.5508, 1.6291,\n",
      "        2.5057, 1.8739, 2.2612, 1.7098, 1.6578, 1.3653, 2.4775, 1.2345, 1.4158,\n",
      "        2.6119, 1.4759, 5.2660, 2.6218, 1.0531, 2.1360, 2.3866, 1.1968, 2.6446,\n",
      "        0.9333, 1.2178, 1.5923, 1.4794, 1.7689, 2.5763, 1.9593, 1.1029, 1.7117,\n",
      "        0.8954, 2.3592, 0.6809, 2.3945, 1.5842, 1.7419, 2.3261, 1.0816, 1.0993,\n",
      "        1.3969, 1.5300, 1.7884], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-2.1393, -1.3595, -1.0970, -2.5972,  0.2123,  0.0238, -1.3370, -0.8481,\n",
      "        -0.6411,  0.7015,  0.5147,  0.4741,  0.2739,  0.3449,  0.1196, -1.5875,\n",
      "        -1.4198,  1.0536, -0.2439, -2.7834,  1.0558, -0.9690, -3.5375, -1.5349,\n",
      "        -1.4928,  0.9895,  0.8852,  0.6758, -1.9101, -0.6999, -3.4768, -2.5107,\n",
      "         0.3040, -0.0806, -1.8378, -1.5124, -0.6644, -1.3075, -1.8126, -0.2039,\n",
      "         0.9356, -1.9046, -0.7679, -1.1643,  0.8521,  0.5955, -0.0895, -1.5351,\n",
      "        -0.9934, -0.2444, -0.3317,  0.8062,  1.0966, -2.0238, -1.1422, -1.3947,\n",
      "        -1.3238,  0.4596,  2.1179, -2.0346,  0.3471, -0.0234,  0.3581, -2.3292,\n",
      "         0.1076, -0.7188, -1.5952, -3.0580, -1.8044, -1.8253, -2.2190, -2.0940,\n",
      "        -0.2828, -1.8982, -0.6380,  0.8037,  1.3752, -2.3291, -1.6622,  0.2941,\n",
      "         0.0089, -1.7703, -2.5997, -1.3078,  1.2363, -2.2728, -0.7875, -0.9457,\n",
      "        -0.8759, -1.7196, -4.2580, -1.7236, -1.1868, -1.0702,  1.2481, -1.1903,\n",
      "        -1.1195, -1.1849, -1.2765, -1.1658, -0.9428, -0.4934, -1.0681, -0.9530,\n",
      "        -0.2163,  0.7296, -1.4528,  0.4850, -1.9613,  0.1310,  1.0283, -2.4548,\n",
      "        -1.0853, -1.6152, -1.1467, -0.8886,  0.2494, -1.3108, -0.7548, -1.2831,\n",
      "         0.4133,  0.4124,  0.4259, -0.8992, -0.1730,  0.0303,  2.3836, -1.3924,\n",
      "         1.4499, -2.5548,  1.0479, -0.7570, -1.1427, -1.2929, -0.9669, -2.0160,\n",
      "        -1.8497,  0.1519, -1.9749, -1.4457, -0.2016, -1.6918,  1.4574,  1.2266,\n",
      "        -2.3271,  0.2683, -0.5958, -1.2670,  0.4407,  0.1724, -2.3492, -1.1238,\n",
      "         0.0789, -0.9065, -0.8356, -1.1167, -1.4312, -1.1068,  0.1664, -1.3117,\n",
      "         0.8214,  0.7439, -2.0014,  0.4448, -0.4364, -1.3107,  0.6109, -0.5000,\n",
      "        -1.8435, -1.1559, -2.1459,  0.3824,  0.9291, -1.5577,  0.6532, -1.6609,\n",
      "        -1.3950, -2.3176,  0.6162, -0.9700,  0.4699, -0.2630,  0.5297, -0.8378,\n",
      "        -1.2936,  0.1688, -1.6657,  0.5590, -0.4826,  1.7868,  0.3650, -2.5075],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.3354]],\n",
      "\n",
      "         [[-0.0094]],\n",
      "\n",
      "         [[ 0.2246]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2800]],\n",
      "\n",
      "         [[-0.5334]],\n",
      "\n",
      "         [[ 0.5199]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3722]],\n",
      "\n",
      "         [[-0.0328]],\n",
      "\n",
      "         [[ 0.1736]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0389]],\n",
      "\n",
      "         [[-0.0146]],\n",
      "\n",
      "         [[ 0.1861]]],\n",
      "\n",
      "\n",
      "        [[[-0.0315]],\n",
      "\n",
      "         [[-0.2775]],\n",
      "\n",
      "         [[-0.2456]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2943]],\n",
      "\n",
      "         [[-0.2939]],\n",
      "\n",
      "         [[ 0.0908]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1406]],\n",
      "\n",
      "         [[ 0.1450]],\n",
      "\n",
      "         [[ 0.4951]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2326]],\n",
      "\n",
      "         [[-0.0715]],\n",
      "\n",
      "         [[-0.1572]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4506]],\n",
      "\n",
      "         [[-0.0309]],\n",
      "\n",
      "         [[-0.3955]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1829]],\n",
      "\n",
      "         [[ 0.1900]],\n",
      "\n",
      "         [[-0.1661]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1943]],\n",
      "\n",
      "         [[-0.0029]],\n",
      "\n",
      "         [[ 0.0769]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1252]],\n",
      "\n",
      "         [[-0.3655]],\n",
      "\n",
      "         [[ 0.3634]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.3067, -0.0368, -0.2642, -0.3216, -0.1978,  0.1443,  0.2118, -0.0617],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0452]],\n",
      "\n",
      "         [[ 0.3784]],\n",
      "\n",
      "         [[ 0.2378]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0475]],\n",
      "\n",
      "         [[-0.1635]],\n",
      "\n",
      "         [[-0.0182]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1882]],\n",
      "\n",
      "         [[-0.2504]],\n",
      "\n",
      "         [[ 0.1764]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1482]],\n",
      "\n",
      "         [[-0.0333]],\n",
      "\n",
      "         [[ 0.1304]]],\n",
      "\n",
      "\n",
      "        [[[-0.0096]],\n",
      "\n",
      "         [[ 0.5352]],\n",
      "\n",
      "         [[-0.1604]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0842]],\n",
      "\n",
      "         [[ 0.7999]],\n",
      "\n",
      "         [[ 0.1636]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0315]],\n",
      "\n",
      "         [[ 0.1960]],\n",
      "\n",
      "         [[ 0.0594]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3574]],\n",
      "\n",
      "         [[ 0.3011]],\n",
      "\n",
      "         [[ 0.8407]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3823]],\n",
      "\n",
      "         [[ 0.3028]],\n",
      "\n",
      "         [[-0.3797]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4287]],\n",
      "\n",
      "         [[ 0.5313]],\n",
      "\n",
      "         [[ 0.2953]]],\n",
      "\n",
      "\n",
      "        [[[-0.3212]],\n",
      "\n",
      "         [[-0.1354]],\n",
      "\n",
      "         [[ 0.0537]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1295]],\n",
      "\n",
      "         [[-0.6119]],\n",
      "\n",
      "         [[-0.2399]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.0487, -0.0976,  0.3627,  0.3214,  0.4895, -0.3726, -0.0253, -0.7713,\n",
      "        -0.3786,  0.4475, -0.1071, -0.0356,  0.2567,  0.0114,  0.1420,  0.2765,\n",
      "         0.1122,  0.2867, -0.1837, -0.2783,  1.0584, -0.0259,  0.2207, -0.0829,\n",
      "         0.2127,  0.3532,  0.3632,  0.7032,  0.4706, -0.6347,  0.0791, -0.0281,\n",
      "        -0.1384, -0.2988,  0.6147,  0.3498, -0.2586,  0.4923, -0.2529,  0.7639,\n",
      "        -0.2214, -0.0424,  0.5928,  0.0899, -0.3929,  0.4370,  0.4916,  0.2230,\n",
      "         0.9107,  0.6513, -0.6934,  0.1125,  0.3814,  0.4152,  0.1476,  0.7219,\n",
      "        -0.0127,  0.1637,  0.7778,  0.5765,  0.3125,  0.0299, -0.1674, -0.1360,\n",
      "         0.1385, -0.4495, -0.1131, -0.1348, -0.4428,  0.1209, -0.0520, -0.5464,\n",
      "         0.1432, -0.0609, -0.1695,  0.3504, -0.1517, -0.1641, -0.3184,  0.3885,\n",
      "        -0.6138, -0.0920, -0.5331, -0.5881,  0.2858, -0.0527,  0.1637,  0.1349,\n",
      "         0.1683,  0.0238, -0.3087,  0.2205, -0.3659,  0.3322, -0.2126,  0.0524,\n",
      "         0.3185,  0.0240, -0.1024, -0.2697, -0.7252, -0.3190,  0.1908,  0.0983,\n",
      "         0.3786, -0.7023,  0.2273,  0.2455, -0.4595, -0.2012,  0.8880,  0.3385,\n",
      "         0.0161, -0.5346, -0.2627,  0.5796, -0.4811,  0.0374, -0.1307,  0.5154,\n",
      "         0.1083,  0.2952,  0.1218,  0.3412, -0.3412,  0.3394,  0.9059,  0.4636,\n",
      "         0.6803,  0.2891,  0.5715,  0.0809, -0.2636, -0.0043, -0.5597,  0.0889,\n",
      "        -0.5145,  0.6325, -0.0973, -0.1698, -0.4357,  0.4197,  0.2879,  0.3131,\n",
      "         0.0688, -0.4965, -0.5972, -0.1253,  0.3237, -0.2550,  0.0858,  0.2605,\n",
      "        -0.6199, -0.6384,  0.7182,  0.2998, -0.0177,  0.0690, -0.3806,  0.1358,\n",
      "         0.6077,  0.4554,  0.0995,  0.5510, -0.4934,  0.2425,  0.2395,  0.3914,\n",
      "        -0.3295, -0.5377,  0.1414,  0.2278,  0.7932,  0.0032, -0.7262,  0.1342,\n",
      "         0.3932, -0.1229,  0.5004,  0.7137, -0.0563,  0.1152,  0.2229,  0.0313,\n",
      "         0.3922,  0.5293, -0.1586,  0.3902, -0.2032,  0.7557,  0.4693, -0.2420],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.3252]],\n",
      "\n",
      "         [[-0.0960]],\n",
      "\n",
      "         [[ 0.1523]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1642]],\n",
      "\n",
      "         [[ 0.1470]],\n",
      "\n",
      "         [[-0.0823]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0248]],\n",
      "\n",
      "         [[-0.6030]],\n",
      "\n",
      "         [[ 0.3161]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2702]],\n",
      "\n",
      "         [[-0.3617]],\n",
      "\n",
      "         [[ 0.2867]]],\n",
      "\n",
      "\n",
      "        [[[-0.4070]],\n",
      "\n",
      "         [[ 0.4734]],\n",
      "\n",
      "         [[-0.9431]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5381]],\n",
      "\n",
      "         [[ 0.2501]],\n",
      "\n",
      "         [[ 0.1027]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3997]],\n",
      "\n",
      "         [[ 0.3612]],\n",
      "\n",
      "         [[ 0.2582]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5719]],\n",
      "\n",
      "         [[ 0.4680]],\n",
      "\n",
      "         [[ 0.0066]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3765]],\n",
      "\n",
      "         [[-0.1408]],\n",
      "\n",
      "         [[-0.5886]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5152]],\n",
      "\n",
      "         [[-0.2684]],\n",
      "\n",
      "         [[-0.2428]]],\n",
      "\n",
      "\n",
      "        [[[-0.3893]],\n",
      "\n",
      "         [[-0.7270]],\n",
      "\n",
      "         [[-0.0181]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5423]],\n",
      "\n",
      "         [[ 0.6137]],\n",
      "\n",
      "         [[-0.0633]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.9705, 3.2328, 2.0439, 0.0521, 3.5405, 1.8310, 4.1163, 2.2422, 5.1621,\n",
      "        1.9903, 4.9715, 3.2674, 0.1991, 2.8876, 3.3084, 2.1839, 3.2671, 2.4718,\n",
      "        5.9214, 1.2973, 6.0044, 2.3518, 1.7232, 1.2235, 3.3925, 3.2880, 1.6211,\n",
      "        3.4943, 2.6466, 2.4565, 1.2010, 4.0801], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.3851, -3.4133, -1.7440,  0.2844,  2.0963, -1.0967, -0.7647,  0.9228,\n",
      "        -0.5976,  1.1199,  3.7042,  0.5249, -0.1122, -0.1367,  0.6281, -2.7791,\n",
      "        -2.8145,  0.4060,  4.9025,  0.2500,  0.1759, -3.7301,  0.3803,  0.1034,\n",
      "        -0.9623, -0.3081, -2.3204, -4.4590,  0.6155, -2.0942, -1.7878, -2.0348],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.3119]],\n",
      "\n",
      "         [[ 0.1503]],\n",
      "\n",
      "         [[ 0.2830]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3612]],\n",
      "\n",
      "         [[-0.0745]],\n",
      "\n",
      "         [[-0.1473]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2308]],\n",
      "\n",
      "         [[ 0.2003]],\n",
      "\n",
      "         [[ 1.2875]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0999]],\n",
      "\n",
      "         [[-0.0638]],\n",
      "\n",
      "         [[-0.0588]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7840]],\n",
      "\n",
      "         [[-0.2172]],\n",
      "\n",
      "         [[-0.0831]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3379]],\n",
      "\n",
      "         [[-0.0428]],\n",
      "\n",
      "         [[-0.0206]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.7905]],\n",
      "\n",
      "         [[ 0.9267]],\n",
      "\n",
      "         [[ 0.3870]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0997]],\n",
      "\n",
      "         [[ 0.5643]],\n",
      "\n",
      "         [[ 0.1694]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5280]],\n",
      "\n",
      "         [[ 0.0383]],\n",
      "\n",
      "         [[-0.5611]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3153]],\n",
      "\n",
      "         [[ 0.4040]],\n",
      "\n",
      "         [[ 0.2116]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2098]],\n",
      "\n",
      "         [[ 0.3521]],\n",
      "\n",
      "         [[ 0.0561]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2783]],\n",
      "\n",
      "         [[ 0.6574]],\n",
      "\n",
      "         [[ 0.1322]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.5814,  0.2088,  0.8039,  1.2357,  1.9387,  0.7494,  1.3190,  0.8338,\n",
      "         0.9411,  1.0997,  1.7022,  0.6400,  0.3835,  1.3289,  1.3470,  1.5891,\n",
      "         0.6719,  1.6977,  1.2499,  0.6805,  1.0924,  1.5735,  1.8406,  1.5192,\n",
      "         0.9535,  0.9915,  1.6213,  1.4394,  3.8775,  1.0811,  0.0041,  0.4658,\n",
      "         0.7612,  1.9719,  1.2967,  1.1376,  2.0962,  1.6375,  0.4416,  1.6154,\n",
      "         2.5514,  1.1243,  0.5959,  1.4605,  0.6815,  1.0083,  1.1650,  0.5946,\n",
      "         0.7076,  0.6424,  0.6933,  0.3508,  1.7086,  2.6067,  1.3652,  1.4839,\n",
      "         0.7001,  1.8033,  0.7714,  0.1145,  0.6538,  0.9447,  1.7262,  0.8270,\n",
      "         0.9684,  1.5756,  1.5174,  0.9908,  1.0805,  2.0006,  0.8164,  1.0604,\n",
      "         0.5820,  1.8198,  0.6928,  0.6584,  3.0233,  1.5661,  0.4621,  0.4433,\n",
      "         1.1594,  1.4774,  0.2707,  1.4956,  1.3500,  1.3765,  1.1846,  0.4595,\n",
      "         1.6436,  1.7767,  1.6377,  0.9655,  0.8780,  0.2572,  1.3530,  1.5109,\n",
      "         1.5965,  1.5057,  0.6986,  2.0899,  1.4595,  2.4764,  0.4968,  0.8225,\n",
      "         1.0012,  1.0145,  1.7018,  1.0352,  0.6260,  1.3422,  0.4847,  1.0810,\n",
      "         1.6412,  1.1434,  2.8302,  1.3354,  1.7351,  1.0290,  0.3747,  0.6740,\n",
      "         1.6470,  1.5772,  2.1962,  0.4210,  0.6397,  1.5846,  0.4265,  0.9409,\n",
      "         0.7955,  0.5158,  1.7478,  2.0165,  1.0179,  0.6170,  1.8957,  0.2751,\n",
      "         2.9577,  1.7252,  1.6354,  0.9449,  0.8298,  3.6071,  0.9673,  2.3401,\n",
      "         1.7123,  0.8258,  1.0330,  0.7540,  0.8507,  1.1501,  1.3267,  1.5493,\n",
      "         0.3145,  2.4931,  1.3286,  3.0225,  1.6288,  1.7507,  1.5521,  0.7898,\n",
      "         2.0941,  0.8640,  0.3362,  0.9806,  2.0774,  1.1570,  1.5994,  0.3198,\n",
      "         2.0806,  0.6593, -0.2108,  1.7504,  0.9170,  0.8355,  2.3204,  1.8067,\n",
      "         2.5636,  2.5860,  0.2568,  1.6994,  1.1662,  1.3537,  0.4756,  1.8987,\n",
      "         0.6513,  1.1630,  1.7141,  0.8855,  0.7762,  2.6077,  2.1535,  2.8576],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.0264,  0.4541, -0.0475, -0.4894,  1.0604,  0.2943, -4.4812, -1.5631,\n",
      "        -1.7883, -1.0618,  0.7479,  1.1718,  0.2832, -1.1519,  0.8129, -1.8435,\n",
      "         0.4096,  1.8053,  1.9817,  1.1892, -1.5503,  1.4815,  0.5068, -2.3070,\n",
      "        -0.1022, -0.0060,  3.5632, -1.9831, -4.8572,  1.7839,  1.7237,  0.6578,\n",
      "         0.6956,  1.1439,  0.2793, -1.1931, -1.3227,  0.4888,  0.0184,  0.4369,\n",
      "         0.0942, -1.0488,  1.4758,  1.0910,  1.0366,  1.7393,  1.2826, -0.6256,\n",
      "        -0.7025, -0.6659, -0.8996, -0.1619,  1.0180, -0.2474,  1.6473, -0.7524,\n",
      "         1.4440,  1.3680,  0.2797,  0.3823,  0.1608,  1.8722, -0.2327,  0.5517,\n",
      "        -0.8858, -0.3228,  0.8963,  1.4575,  1.3995, -2.2865, -0.4983,  1.6683,\n",
      "        -0.5657,  0.4715,  0.4753,  0.8508,  0.4142,  1.2842, -1.0799,  0.7492,\n",
      "         1.6322,  1.5491,  0.0367,  0.3194,  2.1035,  1.7985,  1.8048,  0.4323,\n",
      "        -0.0078,  0.6420,  0.9387,  1.2230, -0.5447, -0.4176, -0.3639,  1.2306,\n",
      "         2.2475, -1.5340, -0.4075, -1.3562, -1.6334,  0.6469, -0.2367,  1.7558,\n",
      "         0.0881,  1.0593,  1.2301, -0.0515, -1.1587,  0.6960, -0.1116, -1.8660,\n",
      "         1.1608, -0.6720, -0.1136,  1.3394,  2.3786,  0.8985,  0.0267,  0.8577,\n",
      "         1.5638,  0.8805,  2.2688,  2.3442, -1.0123,  1.5092,  0.1621,  1.0340,\n",
      "        -1.0313,  0.2176,  2.1319, -4.3366,  1.3559,  0.0962,  1.3591,  0.7513,\n",
      "        -1.9453,  1.6649,  1.8760, -0.6852,  1.3778, -0.8130,  0.6851,  1.1744,\n",
      "         1.7677,  1.4493, -0.1786,  0.2814,  1.2483, -1.1066, -1.1192,  1.2644,\n",
      "        -0.4796,  0.5699,  0.6664, -0.2941,  0.2607,  1.3226, -0.3158,  2.1839,\n",
      "        -0.0236, -2.9593,  0.2693, -0.7847,  0.8841,  1.1996, -1.3932,  0.0393,\n",
      "        -1.4552, -1.0335, -0.1910,  2.9410,  0.2862, -1.4886, -0.5042, -0.8981,\n",
      "         1.2466,  0.9683,  0.2725,  1.8119,  1.0981, -0.8756,  1.5804,  2.3660,\n",
      "        -0.1285, -0.6532, -1.8267,  0.9833, -0.2759,  1.3945,  1.7114, -1.3690],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0485, -0.0630, -0.0513],\n",
      "          [ 0.4252,  0.4414,  0.3301],\n",
      "          [-0.4333, -0.2118, -0.3669]]],\n",
      "\n",
      "\n",
      "        [[[-0.2888, -0.1422, -0.4135],\n",
      "          [-0.3020, -0.1545, -0.4807],\n",
      "          [-0.2196, -0.0609, -0.5126]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4152,  0.1412, -0.5000],\n",
      "          [-0.3560, -0.4792,  0.4154],\n",
      "          [-0.1433,  0.4276,  0.2309]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.6198, -0.4018, -0.3916],\n",
      "          [-0.5761,  0.3903,  0.0890],\n",
      "          [-0.2258, -0.1465, -0.0581]]],\n",
      "\n",
      "\n",
      "        [[[-0.2854, -0.5334,  0.0028],\n",
      "          [ 0.2898, -0.1012,  0.7911],\n",
      "          [-0.0984, -0.5315, -0.1603]]],\n",
      "\n",
      "\n",
      "        [[[-0.2904, -0.2219,  0.3342],\n",
      "          [-0.1150, -0.5520,  0.5081],\n",
      "          [-0.4226, -0.7737, -0.2988]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.1421, 0.7250, 2.3663, 2.3466, 1.4598, 1.3534, 3.8457, 0.7630, 1.8145,\n",
      "        0.7275, 1.8268, 1.7450, 1.5756, 0.7841, 2.1500, 3.7725, 0.7456, 2.1659,\n",
      "        1.8031, 1.7553, 4.1437, 1.1842, 2.1929, 1.8702, 0.7410, 1.5642, 2.6031,\n",
      "        1.9414, 2.3575, 2.6095, 0.5109, 1.7475, 1.0859, 2.1723, 1.7084, 0.4477,\n",
      "        0.9836, 1.6995, 1.7998, 1.1443, 1.7198, 1.2946, 1.8857, 1.4513, 1.0276,\n",
      "        2.0157, 1.5593, 1.2460, 0.9987, 1.0142, 4.1375, 1.7009, 1.7151, 2.5006,\n",
      "        1.7688, 2.8430, 1.3434, 1.7225, 1.6608, 1.7585, 2.5723, 1.7963, 1.7518,\n",
      "        1.4098, 0.4034, 1.6064, 1.9099, 1.5695, 1.6385, 1.4156, 2.1792, 1.7787,\n",
      "        1.5172, 0.7603, 2.1583, 1.2522, 1.9949, 2.4524, 1.8766, 2.2082, 1.0528,\n",
      "        0.8836, 1.7963, 1.1991, 1.9568, 1.4171, 1.6759, 1.9058, 1.5047, 0.9133,\n",
      "        2.1942, 1.0120, 3.2159, 1.5511, 0.2940, 1.6368, 2.2018, 1.2576, 2.0788,\n",
      "        1.2854, 0.8479, 1.0035, 1.8705, 3.1151, 1.3245, 1.8667, 0.9050, 3.2336,\n",
      "        0.7308, 0.9815, 1.7452, 1.6258, 1.8048, 1.8965, 1.7698, 1.5271, 2.2787,\n",
      "        1.1428, 1.9213, 2.1631, 2.5686, 1.3320, 2.5533, 1.4418, 1.7848, 2.0543,\n",
      "        1.5769, 1.9736, 1.2158, 2.4873, 2.0464, 2.4544, 2.0196, 1.7656, 2.1238,\n",
      "        2.3809, 1.3900, 1.8345, 1.8515, 1.5401, 2.1636, 3.1487, 1.3162, 1.3405,\n",
      "        1.4939, 1.6238, 2.1578, 1.1090, 1.5312, 0.7720, 1.1397, 1.4747, 1.6936,\n",
      "        1.8133, 2.1463, 2.0284, 1.7129, 1.9598, 1.8672, 1.3896, 0.9825, 2.6962,\n",
      "        1.9234, 1.5289, 1.2276, 2.0059, 3.2808, 1.6046, 1.0186, 1.2562, 2.2516,\n",
      "        2.7439, 1.8820, 0.7510, 1.1940, 0.7134, 2.2841, 1.8231, 0.9833, 2.3100,\n",
      "        2.0530, 2.8784, 1.9371, 1.9766, 0.6985, 1.6546, 1.1741, 1.6801, 1.8846,\n",
      "        2.0943, 1.0807, 1.7424], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-4.5650e-03, -3.7512e-02, -1.6333e+00, -1.8442e+00,  1.0594e+00,\n",
      "        -1.8820e+00, -2.9875e+00, -3.5114e-01,  2.6876e-01,  1.7647e-01,\n",
      "        -1.2620e+00, -1.8402e+00, -1.4508e+00, -2.5882e-01, -1.3537e+00,\n",
      "        -2.5050e+00, -2.4895e-01, -1.5394e+00, -1.2246e+00, -1.0298e+00,\n",
      "        -7.1367e-01,  2.7575e-03, -8.2853e-01, -2.3268e-01,  9.7913e-01,\n",
      "        -2.1099e+00, -3.3006e+00, -2.2409e+00, -4.5478e-01, -1.2295e+00,\n",
      "         2.0709e-01, -2.2846e+00,  1.3352e-01, -9.5006e-01, -1.8350e+00,\n",
      "        -6.0013e-02,  1.7742e+00, -2.0024e+00, -1.1683e+00, -2.1777e-01,\n",
      "         5.8156e-01, -2.4944e-02, -1.1723e+00, -1.6169e+00,  1.0646e+00,\n",
      "        -1.4660e+00, -1.9642e+00, -2.3709e+00,  7.6866e-01, -1.3753e-02,\n",
      "        -2.6715e+00, -1.8697e+00, -7.8192e-01, -1.4366e+00, -1.7908e+00,\n",
      "         9.3135e-01, -1.3121e+00, -1.3004e+00, -1.0902e+00, -1.3180e+00,\n",
      "        -2.3119e+00, -1.5869e+00,  7.3607e-01, -1.8412e+00, -1.4736e-01,\n",
      "        -1.0029e+00, -1.6922e+00, -1.9761e+00, -1.2348e+00, -1.0285e+00,\n",
      "        -1.9937e+00, -1.4383e+00, -1.2902e+00,  1.8327e+00, -9.7722e-01,\n",
      "        -1.0180e+00, -5.5920e-01, -9.6298e-01, -8.8677e-01, -1.6697e+00,\n",
      "        -3.5321e-01,  1.9116e+00, -1.8398e+00, -8.0533e-01, -1.6001e+00,\n",
      "        -1.6280e+00, -3.7062e-01, -7.2912e-01, -1.0320e+00, -2.5694e-01,\n",
      "        -1.2679e+00,  4.2285e-01, -1.6538e+00, -1.1892e+00,  7.2989e-01,\n",
      "        -7.9489e-01, -1.7352e+00, -2.8345e+00, -9.6775e-01, -1.0638e+00,\n",
      "         2.9520e-01,  3.1098e-01, -2.0520e+00, -1.2349e+00, -2.3040e+00,\n",
      "        -1.5616e+00,  5.3974e-01, -3.1829e+00,  1.8956e-02, -6.6817e-01,\n",
      "        -1.5495e+00, -5.1363e-01, -2.6235e+00, -1.6023e+00, -8.7756e-01,\n",
      "        -1.2538e+00, -1.2363e+00,  2.0213e-01, -1.7041e+00, -1.7421e+00,\n",
      "        -2.1267e+00, -1.4373e+00, -2.2691e+00,  1.5772e-01,  6.0027e-01,\n",
      "        -8.7715e-01, -2.2925e+00, -1.4438e+00, -8.2838e-01, -1.0402e+00,\n",
      "        -1.5556e+00, -4.3038e-01, -3.1045e-01, -1.4496e+00, -1.5870e+00,\n",
      "        -9.2924e-01,  3.4400e-01, -2.3371e-01, -1.1502e+00, -1.5551e+00,\n",
      "        -1.6146e+00, -2.1876e+00, -7.8082e-01,  9.4697e-01, -6.4683e-01,\n",
      "        -1.7831e+00, -1.9736e+00,  1.1688e+00, -1.4124e+00, -2.4719e-01,\n",
      "        -1.4522e-01, -1.0912e+00, -1.1073e+00, -7.1141e-01, -7.7386e-01,\n",
      "        -3.4792e-01, -1.8477e-01, -1.6246e+00, -7.9111e-01, -1.4570e+00,\n",
      "         1.4277e-01, -3.5705e+00, -1.9361e+00, -1.1156e-01,  5.2919e-01,\n",
      "        -6.5428e-01,  7.9993e-01, -1.2158e+00, -3.9399e+00, -1.2466e+00,\n",
      "        -1.3882e+00, -2.6760e+00, -1.4961e+00,  1.7247e-01,  3.8630e-01,\n",
      "         9.4907e-01, -1.2643e+00, -1.1358e+00, -2.1239e+00, -1.9392e+00,\n",
      "        -1.0925e+00,  1.5500e-01, -1.9740e+00, -2.0096e+00, -2.6905e-01,\n",
      "        -2.2001e+00, -8.7331e-02, -2.4620e+00, -1.6447e+00, -1.6705e+00,\n",
      "         1.6470e-01, -1.1457e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0516]],\n",
      "\n",
      "         [[-0.4154]],\n",
      "\n",
      "         [[-0.2599]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3137]],\n",
      "\n",
      "         [[-0.1299]],\n",
      "\n",
      "         [[ 0.1413]]],\n",
      "\n",
      "\n",
      "        [[[-0.0181]],\n",
      "\n",
      "         [[ 0.2734]],\n",
      "\n",
      "         [[ 0.1611]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1942]],\n",
      "\n",
      "         [[-0.1315]],\n",
      "\n",
      "         [[-0.0042]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0219]],\n",
      "\n",
      "         [[-0.0877]],\n",
      "\n",
      "         [[-0.0963]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1461]],\n",
      "\n",
      "         [[ 0.0745]],\n",
      "\n",
      "         [[-0.1721]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0086]],\n",
      "\n",
      "         [[ 0.2647]],\n",
      "\n",
      "         [[ 0.5960]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1621]],\n",
      "\n",
      "         [[-0.0884]],\n",
      "\n",
      "         [[-0.3076]]],\n",
      "\n",
      "\n",
      "        [[[-0.0047]],\n",
      "\n",
      "         [[ 0.6440]],\n",
      "\n",
      "         [[ 0.0252]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0791]],\n",
      "\n",
      "         [[-0.0680]],\n",
      "\n",
      "         [[-0.0304]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1024]],\n",
      "\n",
      "         [[ 0.0301]],\n",
      "\n",
      "         [[ 0.2045]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3387]],\n",
      "\n",
      "         [[ 0.2194]],\n",
      "\n",
      "         [[-0.1478]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1525,  0.0547,  0.1314,  0.0475,  0.0726,  0.0067,  0.1168,  0.3033],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0636]],\n",
      "\n",
      "         [[-0.5903]],\n",
      "\n",
      "         [[ 0.0366]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4505]],\n",
      "\n",
      "         [[-0.4067]],\n",
      "\n",
      "         [[-0.0993]]],\n",
      "\n",
      "\n",
      "        [[[-0.0655]],\n",
      "\n",
      "         [[-0.2312]],\n",
      "\n",
      "         [[-0.0735]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9842]],\n",
      "\n",
      "         [[-0.7991]],\n",
      "\n",
      "         [[-0.2063]]],\n",
      "\n",
      "\n",
      "        [[[-0.7058]],\n",
      "\n",
      "         [[ 0.0252]],\n",
      "\n",
      "         [[ 0.8546]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3142]],\n",
      "\n",
      "         [[ 0.3089]],\n",
      "\n",
      "         [[ 0.0542]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3146]],\n",
      "\n",
      "         [[ 0.1162]],\n",
      "\n",
      "         [[ 0.3129]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1419]],\n",
      "\n",
      "         [[ 0.2626]],\n",
      "\n",
      "         [[-0.2480]]],\n",
      "\n",
      "\n",
      "        [[[-0.0417]],\n",
      "\n",
      "         [[ 0.0677]],\n",
      "\n",
      "         [[ 0.5224]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5220]],\n",
      "\n",
      "         [[-0.0220]],\n",
      "\n",
      "         [[ 0.2057]]],\n",
      "\n",
      "\n",
      "        [[[-0.4326]],\n",
      "\n",
      "         [[-0.3181]],\n",
      "\n",
      "         [[ 0.1384]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4143]],\n",
      "\n",
      "         [[ 0.0560]],\n",
      "\n",
      "         [[-0.1306]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.3519, -0.2000,  0.3454, -0.1705, -0.4794, -0.1576, -0.3942, -0.1199,\n",
      "         0.8934, -0.0080, -0.2757, -0.2738, -0.3610, -0.8124, -0.2358,  0.5132,\n",
      "        -0.4188, -0.4403, -0.1227,  0.1238, -0.5336,  0.4102,  0.3907,  0.3184,\n",
      "         0.0449,  0.1778,  0.4657,  0.1296, -0.4017,  0.5839, -0.3909,  0.1875,\n",
      "         0.2876,  0.0525,  0.5579, -0.4398,  0.0346,  0.3425,  0.3509,  0.3455,\n",
      "         0.6015,  0.4709, -0.2521,  0.1412,  0.5075,  0.1244,  0.2504,  0.0420,\n",
      "         0.4343, -0.0317, -0.1824, -0.2788,  0.0525, -0.8889,  0.6443, -0.4942,\n",
      "         0.0470, -0.1332, -0.6796, -0.2678,  0.5821, -0.1971,  0.6544, -0.1952,\n",
      "         0.0324,  0.2683,  0.1847, -0.2302,  0.4375,  0.0679, -0.4468, -0.2277,\n",
      "        -0.0647,  0.2001,  0.4538,  0.3024,  0.3062,  0.2139,  0.3389,  0.5360,\n",
      "         0.2622, -0.3515,  0.1902, -0.1289, -0.1850, -0.4902,  0.2043,  0.1557,\n",
      "        -0.1302,  0.1400,  0.1653,  0.1980,  0.3184, -0.1701, -0.1146,  0.2171,\n",
      "         0.1162, -0.1636,  0.2183, -0.1978, -0.2660, -0.1887,  0.5239, -0.4571,\n",
      "         0.4191,  0.2967,  0.3192, -0.2606, -0.1015, -0.3453,  0.3901, -0.2850,\n",
      "         0.1423,  0.4912, -0.2643, -0.2115,  0.1544, -0.1673,  0.0987,  0.5372,\n",
      "         0.1362, -0.2454,  0.1364,  0.0384,  0.3324,  0.2191, -0.0930,  0.4540,\n",
      "         0.6268,  0.2208,  0.1955, -0.4477,  0.0213,  0.0222, -0.6754,  0.4506,\n",
      "         1.0866,  0.3755,  0.0756, -0.3478,  0.2503,  0.0269, -0.7008,  0.0511,\n",
      "        -0.0752, -0.1202,  0.0190,  0.4048, -0.1805, -0.3481,  0.3261, -0.1724,\n",
      "        -0.2123,  0.2113,  0.1307, -0.2969, -0.8568, -0.0685, -0.0967, -0.1769,\n",
      "        -0.0249, -0.4060, -0.1544, -0.3900,  0.2686,  0.3993, -0.4461, -0.1654,\n",
      "        -0.3050, -0.0036,  0.3034,  0.5290, -0.1920,  0.2790,  0.3003,  0.7923,\n",
      "        -0.3969, -0.0716, -0.0254, -0.1831,  0.1897, -0.3143,  0.1618,  0.0533,\n",
      "        -1.0103,  0.0307, -0.3735, -0.1468,  0.0984,  0.0947,  0.3070, -0.1960],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0451]],\n",
      "\n",
      "         [[ 0.3935]],\n",
      "\n",
      "         [[-0.2055]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1913]],\n",
      "\n",
      "         [[ 0.0887]],\n",
      "\n",
      "         [[ 0.6800]]],\n",
      "\n",
      "\n",
      "        [[[-0.3727]],\n",
      "\n",
      "         [[ 0.0349]],\n",
      "\n",
      "         [[ 0.3103]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2451]],\n",
      "\n",
      "         [[-0.4008]],\n",
      "\n",
      "         [[-0.1062]]],\n",
      "\n",
      "\n",
      "        [[[-0.7485]],\n",
      "\n",
      "         [[ 0.0243]],\n",
      "\n",
      "         [[ 0.3887]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3522]],\n",
      "\n",
      "         [[-0.3453]],\n",
      "\n",
      "         [[ 0.0046]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3565]],\n",
      "\n",
      "         [[ 0.8640]],\n",
      "\n",
      "         [[-0.3596]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1627]],\n",
      "\n",
      "         [[-0.2367]],\n",
      "\n",
      "         [[ 0.0323]]],\n",
      "\n",
      "\n",
      "        [[[-0.1156]],\n",
      "\n",
      "         [[-0.3597]],\n",
      "\n",
      "         [[ 0.3122]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5583]],\n",
      "\n",
      "         [[ 0.3243]],\n",
      "\n",
      "         [[ 0.0822]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0968]],\n",
      "\n",
      "         [[-0.0766]],\n",
      "\n",
      "         [[ 0.0045]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4523]],\n",
      "\n",
      "         [[ 0.1681]],\n",
      "\n",
      "         [[ 0.0751]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.1652, 2.4494, 1.2653, 0.6022, 2.2400, 1.6893, 4.7574, 1.0255, 3.4954,\n",
      "        2.2666, 4.1276, 2.7298, 0.2751, 2.0719, 4.4674, 1.4456, 2.3245, 1.9047,\n",
      "        4.0207, 1.4879, 4.1973, 1.9722, 1.6571, 1.3404, 2.5195, 3.5346, 1.4218,\n",
      "        2.4043, 2.7856, 1.3717, 1.3798, 2.2342], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.3249, -1.6127, -1.2022,  0.2848,  0.8098, -0.8216,  1.9943,  0.5948,\n",
      "        -1.9156, -0.2691,  2.5231, -1.3391, -0.0608, -0.6991, -2.0699, -2.8844,\n",
      "        -3.2221, -0.5591,  1.5424,  0.5670, -1.3274, -3.6477,  0.1366, -0.2491,\n",
      "         0.4220, -1.1002, -1.1126, -2.6171,  0.5572, -1.1850, -0.5298, -1.6973],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.1321]],\n",
      "\n",
      "         [[ 0.1655]],\n",
      "\n",
      "         [[ 0.2907]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2765]],\n",
      "\n",
      "         [[-0.3349]],\n",
      "\n",
      "         [[-0.0273]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1519]],\n",
      "\n",
      "         [[-0.5035]],\n",
      "\n",
      "         [[-0.1711]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3258]],\n",
      "\n",
      "         [[-0.4551]],\n",
      "\n",
      "         [[ 0.1237]]],\n",
      "\n",
      "\n",
      "        [[[-0.3706]],\n",
      "\n",
      "         [[-0.2073]],\n",
      "\n",
      "         [[-0.3291]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0076]],\n",
      "\n",
      "         [[-0.0923]],\n",
      "\n",
      "         [[ 0.4732]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1989]],\n",
      "\n",
      "         [[-0.0715]],\n",
      "\n",
      "         [[ 0.6880]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4248]],\n",
      "\n",
      "         [[-0.2166]],\n",
      "\n",
      "         [[-0.1435]]],\n",
      "\n",
      "\n",
      "        [[[-0.5654]],\n",
      "\n",
      "         [[-0.2628]],\n",
      "\n",
      "         [[-0.7408]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1739]],\n",
      "\n",
      "         [[-0.0417]],\n",
      "\n",
      "         [[ 0.2922]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8228]],\n",
      "\n",
      "         [[ 0.1819]],\n",
      "\n",
      "         [[-0.3179]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2974]],\n",
      "\n",
      "         [[ 0.0202]],\n",
      "\n",
      "         [[ 0.0652]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.7219,  1.4659,  3.9728,  1.2073,  0.9762,  0.5159,  1.2951,  1.8019,\n",
      "         0.7370,  1.4967,  1.8912,  1.9437,  0.4435,  1.3046,  0.1558,  1.9360,\n",
      "         0.9531,  1.9663,  1.0293,  0.3012,  0.9704,  0.9631,  1.7097,  0.2742,\n",
      "         1.6539,  3.0956,  0.2486,  1.9555,  1.0243,  0.8348,  2.6886,  1.3871,\n",
      "         0.8408,  1.0563,  1.4773,  0.5768,  1.2194,  2.2001,  0.9992,  2.0895,\n",
      "         1.1234,  1.0942,  0.2109,  2.6666,  1.6144,  2.0843,  1.0391,  1.1955,\n",
      "         0.9075,  0.9811,  1.7842,  1.2820,  0.9800,  3.0899,  0.2914,  1.1515,\n",
      "         0.5822,  0.9413,  0.9665,  1.8748,  1.1668,  1.0544,  1.9501,  1.4487,\n",
      "         2.4508,  1.2621,  1.3868,  3.6986,  1.4532,  0.6449,  1.6611,  0.3649,\n",
      "        -0.2827,  0.2354,  1.8643,  1.5757,  0.3646,  1.3700,  0.9005,  1.1483,\n",
      "         1.6566,  0.4047,  1.7807,  1.0353,  1.2424,  0.5158,  1.5106,  1.4608,\n",
      "         0.4815,  1.0469,  1.5880,  1.5790,  2.4727,  1.3703,  0.6791,  1.2088,\n",
      "         0.3313,  1.9149,  2.6086,  0.2883,  3.6658, -0.6180,  2.2935,  2.5526,\n",
      "         0.6999,  1.3667,  0.5497, -0.1707,  1.1698,  0.5166, -0.3318,  0.7490,\n",
      "         0.7729,  0.5903,  0.9441,  0.9287,  1.9158,  0.4859,  1.4688,  1.1144,\n",
      "         0.9319,  1.1048,  0.5082,  0.4733,  0.2314,  1.4695,  0.2154,  0.9478,\n",
      "         1.2304,  0.3147,  1.2958,  0.3827,  0.3757,  1.0809,  0.9469,  1.0796,\n",
      "         0.7950,  0.8181,  1.6960,  2.1694,  2.7768,  1.0772,  1.1286,  1.6536,\n",
      "         1.6013,  1.2614,  1.1115,  3.6145,  2.1616,  1.6578,  1.7398,  1.5508,\n",
      "         0.9149,  0.9442,  1.8046,  0.8931,  3.2905,  1.2056,  1.2502,  0.9666,\n",
      "         1.0297,  1.0352,  0.1936,  1.0243,  1.3113,  1.3142,  1.4394,  0.9438,\n",
      "         3.1092,  1.7338,  0.4637,  1.8603,  1.6197,  1.9267,  0.9698,  1.6688,\n",
      "         1.7218,  1.4888,  0.8049,  0.1469,  0.9286,  0.7969,  0.9507,  0.8968,\n",
      "         0.2575,  0.9791,  0.8029,  2.0265,  0.5879,  0.2607,  1.6887,  0.7475],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 3.6595e-01,  1.6023e+00, -2.1987e-01, -5.6077e-01,  2.1668e+00,\n",
      "         2.4201e-01, -1.2629e+00,  1.3034e+00, -8.7857e-01,  2.9544e-01,\n",
      "        -6.9918e-02, -6.8020e-01,  6.5364e-02, -7.0664e-01,  5.6762e-02,\n",
      "        -9.2707e-01, -1.4630e+00,  1.1122e+00, -2.2334e-01,  1.4073e-01,\n",
      "         1.3016e+00, -1.3415e+00,  3.1930e-01,  1.5194e-01,  1.2887e+00,\n",
      "         1.5591e-01,  3.7583e-01, -2.8612e-01,  2.6198e-01,  6.0050e-02,\n",
      "        -1.3262e+00, -1.5540e+00,  9.2784e-02, -1.7571e+00, -8.6709e-01,\n",
      "        -1.4688e-01, -3.9352e-01,  1.3021e+00, -8.8906e-01,  8.3572e-01,\n",
      "         2.6625e-04,  1.4979e+00,  2.0877e-01,  3.2688e-03, -1.4769e+00,\n",
      "        -8.5520e-01,  1.9348e+00, -1.1329e+00, -3.0777e-01, -1.5387e+00,\n",
      "         1.3036e+00,  6.4196e-01, -4.1734e-01,  1.1396e-01,  1.2890e-01,\n",
      "        -3.3312e-01,  9.8542e-02, -1.5436e-02, -1.0218e+00, -8.2544e-01,\n",
      "        -7.1210e-01, -8.5580e-01, -3.5642e-01, -1.1336e+00,  2.4437e-02,\n",
      "        -9.4819e-01, -8.6893e-01,  1.9215e+00, -1.2119e-01, -3.6523e-01,\n",
      "         2.9644e-01, -1.4096e-01, -2.1844e-01,  4.2263e-01,  2.1283e+00,\n",
      "         1.3651e+00, -1.0769e-01,  3.6574e-01, -1.7992e+00,  1.6126e-01,\n",
      "        -1.2695e+00,  2.1853e-01, -2.3462e-01, -3.8108e-01, -5.4332e-01,\n",
      "         2.5586e-01, -1.4428e+00, -6.2706e-01, -7.9881e-02, -1.2263e-01,\n",
      "        -2.5021e-01, -3.2054e-01, -2.8859e-01, -8.4952e-01, -9.3362e-02,\n",
      "        -1.1173e+00,  3.2007e-01, -2.7255e-01,  1.1022e+00, -1.0645e-01,\n",
      "         1.3749e+00,  6.3342e-02, -4.8869e-01,  1.5276e+00, -6.3545e-03,\n",
      "         2.1403e+00, -5.9737e-02, -1.6256e-01,  5.9871e-01,  1.1052e-01,\n",
      "        -1.0150e-01,  1.1083e-01, -1.4200e-01, -4.7982e-01, -3.6879e-01,\n",
      "        -1.3016e+00, -1.3740e+00,  8.1326e-01,  2.1840e-01, -1.5053e+00,\n",
      "        -9.5438e-01, -4.3102e-01, -1.3620e-01, -7.3937e-01, -8.6360e-02,\n",
      "         1.7346e+00,  1.5560e-01,  2.2044e-01,  5.0668e-01,  1.7485e-01,\n",
      "        -2.3147e-01, -1.2866e-01,  1.1743e-01, -1.1366e+00, -1.3951e-01,\n",
      "        -1.3734e+00,  9.1425e-01,  3.3263e-01,  1.5166e+00, -1.5711e+00,\n",
      "         5.6169e-01,  1.3008e-01, -9.9350e-01, -3.9325e-01,  1.3950e+00,\n",
      "        -1.1796e+00, -3.5847e-01,  1.3960e+00, -1.8407e-01, -7.5514e-01,\n",
      "         1.3876e+00,  1.0159e+00,  7.7938e-02,  4.7458e-01,  5.8404e-01,\n",
      "         6.1567e-03,  1.0213e+00, -1.1092e+00,  4.5668e-01, -8.3250e-01,\n",
      "         1.2794e+00, -1.3161e+00,  4.3807e-01,  3.2188e-01, -1.9965e-01,\n",
      "        -8.7477e-01, -3.4645e-01, -1.4873e+00,  8.2613e-01,  1.4438e+00,\n",
      "         1.9150e-01, -9.2195e-01,  2.0206e+00,  4.9372e-02, -1.6612e+00,\n",
      "        -1.5209e+00,  1.0423e+00, -1.4904e+00, -4.9947e-01,  4.7594e-02,\n",
      "        -1.8212e+00,  4.8088e-02, -1.1239e+00, -1.7100e+00,  1.2982e-01,\n",
      "        -2.9022e-01,  1.4273e-01, -3.1597e-01, -3.9819e-01,  1.2535e-01,\n",
      "         1.8675e+00, -1.0571e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0731, -0.1177, -0.4772, -0.3002, -0.2458],\n",
      "          [ 0.0193,  0.4700,  0.8255,  0.3917, -0.0323],\n",
      "          [-0.5052,  0.6852,  1.0455,  0.6092, -0.4061],\n",
      "          [-0.1646,  0.2460,  0.2645,  0.4440, -0.1728],\n",
      "          [-0.3361, -0.3028, -0.3129,  0.0033,  0.0778]]],\n",
      "\n",
      "\n",
      "        [[[-0.2584, -0.3636, -0.0831,  0.5578,  0.0202],\n",
      "          [-0.0987, -0.5115,  0.1955,  0.3891, -0.3132],\n",
      "          [-0.3713,  0.1062,  0.7268, -0.5215, -0.0198],\n",
      "          [ 0.2770,  0.5259,  0.1501, -0.6278, -0.0542],\n",
      "          [ 0.2307,  0.1314, -0.5255, -0.4177,  0.4219]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0730,  0.1442,  0.1329,  0.3997,  0.0805],\n",
      "          [-0.3869, -0.8696, -0.1902, -0.1448,  0.3934],\n",
      "          [-0.3126, -0.5609, -0.5285, -0.6867, -0.3146],\n",
      "          [ 0.2017, -0.6504, -0.5411, -0.6937, -0.3018],\n",
      "          [ 0.0034,  0.0451, -0.0214, -0.1719, -0.0332]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.5404,  0.2640,  0.3353,  0.1076, -0.5425],\n",
      "          [ 0.1815,  0.7154,  0.3715,  0.2449,  0.2309],\n",
      "          [ 0.1658,  0.0096, -0.1458,  0.0281, -0.3593],\n",
      "          [-0.6951, -0.6677, -0.5412, -0.1775, -0.0783],\n",
      "          [-0.0432, -0.1982, -0.2511,  0.1395,  0.1013]]],\n",
      "\n",
      "\n",
      "        [[[-0.3169, -0.5476, -0.2621, -0.6613, -0.4221],\n",
      "          [-0.1183,  0.4903,  0.9217,  0.3068, -0.2509],\n",
      "          [-0.2978,  0.5139,  1.3328,  0.2522, -0.0164],\n",
      "          [-0.1033,  0.3022,  0.5567,  0.1823,  0.1689],\n",
      "          [-0.2598, -0.1301, -0.0247, -0.1761,  0.1097]]],\n",
      "\n",
      "\n",
      "        [[[-0.2165, -0.2311, -0.5720, -0.4071, -0.0884],\n",
      "          [-0.4047,  0.2058,  0.6443,  0.1110, -0.2351],\n",
      "          [-0.3443,  0.9808,  1.6348,  0.5573, -0.2447],\n",
      "          [-0.3476,  0.0628,  0.4573, -0.0729, -0.1608],\n",
      "          [-0.3195, -0.3606, -0.4330, -0.3369, -0.1825]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.8343, 2.6181, 2.3520, 1.9752, 2.5505, 2.7072, 1.6918, 2.0043, 1.6913,\n",
      "        1.9761, 1.8256, 1.4689, 2.8758, 1.6687, 2.5964, 1.7428, 1.6680, 2.0017,\n",
      "        2.8687, 3.0317, 3.1473, 1.1708, 1.9219, 2.6625, 2.1433, 1.2815, 3.3654,\n",
      "        1.7007, 2.5324, 2.2710, 2.4507, 1.7579, 2.3550, 1.6600, 1.3656, 2.2835,\n",
      "        2.6242, 2.3451, 2.4883, 1.9961, 2.4908, 2.9012, 3.1937, 1.2556, 1.7349,\n",
      "        1.1294, 3.3666, 1.6451, 1.7445, 0.7145, 1.6214, 1.7160, 2.0586, 1.7432,\n",
      "        2.3949, 2.3137, 2.4210, 2.2590, 1.3218, 1.4130, 2.0874, 1.9868, 1.7777,\n",
      "        0.9305, 1.4369, 1.6080, 2.7280, 3.7570, 3.1285, 0.7722, 2.3382, 1.9721,\n",
      "        3.1536, 3.2674, 1.5943, 1.6662, 2.3733, 1.9608, 1.0488, 2.5308, 1.8424,\n",
      "        2.1327, 1.5874, 1.5563, 1.2059, 1.9258, 1.5280, 2.5520, 2.2321, 2.3052,\n",
      "        2.8347, 1.6562, 2.1271, 3.1860, 2.4699, 1.7997, 2.7389, 2.1724, 3.8461,\n",
      "        3.0529, 4.0014, 2.3595, 1.7403, 2.3911, 2.8956, 2.8662, 2.2195, 2.7573,\n",
      "        2.1612, 1.9105, 1.8337, 1.3261, 1.5566, 1.2164, 2.2188, 1.5411, 2.7409,\n",
      "        3.1329, 2.0779, 1.5201, 0.9359, 2.4705, 1.4682, 2.6808, 2.9465, 2.3713,\n",
      "        2.7123, 2.1798, 2.2884, 1.3074, 1.2612, 2.1963, 3.0407, 1.4258, 2.0457,\n",
      "        0.8750, 2.4944, 2.2716, 2.3654, 2.5303, 1.6107, 1.9731, 1.6832, 1.4210,\n",
      "        2.4679, 1.3426, 1.0634, 1.5492, 1.4301, 1.8272, 2.4361, 2.1711, 2.9600,\n",
      "        2.2632, 2.0648, 2.5008, 2.9255, 1.2008, 2.5575, 1.4306, 2.0687, 0.9432,\n",
      "        2.3094, 2.3137, 2.1084, 1.3184, 2.7605, 1.2985, 1.4405, 2.6398, 2.1302,\n",
      "        1.2093, 1.6592, 2.1941, 1.1316, 2.0460, 2.1140, 2.2050, 1.5018, 2.1739,\n",
      "        1.3092, 2.2668, 2.5156, 1.5907, 2.8623, 2.1403, 2.2460, 2.1923, 3.1990,\n",
      "        2.0610, 1.7756, 2.3856], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.7497, -1.2177,  0.3870,  1.9425, -2.4175, -1.6292,  0.9092,  2.8873,\n",
      "        -0.3281,  2.8425,  1.8636,  2.4467, -0.8128,  3.1209, -1.0220,  1.4974,\n",
      "         3.4090,  2.8009, -1.1490, -0.7857, -1.1071,  3.4101, -1.6521, -1.4273,\n",
      "        -0.4540,  2.6192, -0.8922,  2.0997, -0.9730, -0.9651,  1.4009,  1.3953,\n",
      "        -1.1842,  2.4509,  0.5618, -0.9966, -0.4101, -1.7880, -0.2557, -1.2391,\n",
      "        -0.5229, -0.8409, -0.8037,  1.8438,  1.7682,  2.1110, -1.3392,  1.6727,\n",
      "         2.3008,  3.1962,  3.1993,  3.2978, -1.2264,  2.8280, -0.8536, -1.1237,\n",
      "        -1.4682, -1.5803,  4.5136,  1.8137, -0.7399, -1.0677,  2.2336,  1.5303,\n",
      "         3.8781,  2.1502, -1.5725, -1.9623,  0.0515,  3.4784,  0.2129, -1.6397,\n",
      "        -1.4975, -0.5054,  3.4619,  4.1854, -1.5364,  2.9246,  1.7908,  0.0184,\n",
      "         1.5492, -1.2779,  1.8149,  0.6588,  1.5906, -1.4037, -2.1173,  0.7637,\n",
      "        -0.8107, -0.3981,  0.2788,  2.0828,  1.0730, -1.6934,  2.4251,  1.7151,\n",
      "        -1.3275,  0.2196, -1.6859, -0.7401, -0.9459, -0.7398,  1.1275, -1.1059,\n",
      "        -0.7330, -0.9695, -1.0433, -1.2933, -1.5588,  2.5190, -0.6108,  3.4784,\n",
      "         1.3987, -1.0285,  1.9707,  2.7283,  1.0361, -0.8288, -0.0558,  2.0749,\n",
      "         2.9322, -0.9661,  2.9465, -0.8078, -0.6273, -0.8666, -0.7989,  4.7103,\n",
      "        -1.2124,  4.0024,  2.5600, -0.3933, -0.7676,  1.9771,  2.3401,  3.2194,\n",
      "        -1.0085, -0.4980, -1.2471,  1.1172,  1.7223,  0.3721,  1.5323,  2.4880,\n",
      "        -1.0781,  1.7560,  1.5865,  2.8026,  0.9038,  2.1000, -1.2686, -0.4879,\n",
      "        -0.0559,  2.4106, -1.2952, -0.6686, -0.4159,  3.2314, -0.2113,  3.3440,\n",
      "        -0.5810,  3.6692, -1.2775, -1.3384,  0.0235,  2.1166,  0.1025,  1.6086,\n",
      "         2.8101, -1.0079, -0.5816,  2.0859,  4.7746,  3.0572,  3.7366,  0.8031,\n",
      "        -0.9785,  0.7586,  2.6435, -1.2336,  2.6188, -1.1034, -1.1142,  2.3228,\n",
      "        -0.8084,  2.9346, -0.5494,  2.0112, -0.6144, -1.4554,  4.2693,  3.0212],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0614]],\n",
      "\n",
      "         [[-0.0219]],\n",
      "\n",
      "         [[-0.0990]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0431]],\n",
      "\n",
      "         [[-0.4002]],\n",
      "\n",
      "         [[-0.1133]]],\n",
      "\n",
      "\n",
      "        [[[-0.0864]],\n",
      "\n",
      "         [[-0.0728]],\n",
      "\n",
      "         [[-0.0958]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0644]],\n",
      "\n",
      "         [[-0.4238]],\n",
      "\n",
      "         [[ 0.0403]]],\n",
      "\n",
      "\n",
      "        [[[-0.1891]],\n",
      "\n",
      "         [[-0.0259]],\n",
      "\n",
      "         [[-0.1243]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0028]],\n",
      "\n",
      "         [[-0.0120]],\n",
      "\n",
      "         [[-0.1597]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0393]],\n",
      "\n",
      "         [[-0.0645]],\n",
      "\n",
      "         [[-0.0550]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0331]],\n",
      "\n",
      "         [[-0.0691]],\n",
      "\n",
      "         [[-0.0023]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2639]],\n",
      "\n",
      "         [[-0.0524]],\n",
      "\n",
      "         [[-0.1423]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0616]],\n",
      "\n",
      "         [[-0.3038]],\n",
      "\n",
      "         [[-0.1063]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1588]],\n",
      "\n",
      "         [[-0.0755]],\n",
      "\n",
      "         [[-0.0981]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0625]],\n",
      "\n",
      "         [[ 0.0254]],\n",
      "\n",
      "         [[-0.0186]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1194, -0.1027, -0.1067, -0.0825, -0.1165, -0.0964, -0.1044, -0.0766],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2127]],\n",
      "\n",
      "         [[-0.1280]],\n",
      "\n",
      "         [[-0.0426]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1101]],\n",
      "\n",
      "         [[ 0.3135]],\n",
      "\n",
      "         [[ 0.3487]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0985]],\n",
      "\n",
      "         [[-0.0844]],\n",
      "\n",
      "         [[-0.0090]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0101]],\n",
      "\n",
      "         [[ 0.0805]],\n",
      "\n",
      "         [[-0.0825]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0832]],\n",
      "\n",
      "         [[-0.0326]],\n",
      "\n",
      "         [[ 0.0198]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0568]],\n",
      "\n",
      "         [[ 0.1102]],\n",
      "\n",
      "         [[-0.0584]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0007]],\n",
      "\n",
      "         [[-0.1132]],\n",
      "\n",
      "         [[-0.2263]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0676]],\n",
      "\n",
      "         [[-0.0388]],\n",
      "\n",
      "         [[-0.1128]]],\n",
      "\n",
      "\n",
      "        [[[-0.5057]],\n",
      "\n",
      "         [[-0.6868]],\n",
      "\n",
      "         [[ 0.0892]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0915]],\n",
      "\n",
      "         [[-0.3342]],\n",
      "\n",
      "         [[ 0.0814]]],\n",
      "\n",
      "\n",
      "        [[[-0.3186]],\n",
      "\n",
      "         [[-0.0729]],\n",
      "\n",
      "         [[-0.1578]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0994]],\n",
      "\n",
      "         [[ 0.0596]],\n",
      "\n",
      "         [[ 0.0113]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.2994, -0.2594,  0.1607, -0.1537, -0.1107, -0.1786,  0.1125, -0.0758,\n",
      "        -0.3001,  0.4904,  0.7076,  0.2599, -0.2422, -0.1001,  0.2227,  0.1922,\n",
      "        -0.0272,  0.2696, -0.3182, -0.1062, -0.1415,  0.0528,  0.0666,  0.5887,\n",
      "         0.1122, -0.1049,  0.3631, -0.0284,  0.2450, -0.0482,  0.3495,  0.2190,\n",
      "         0.0728,  0.2349, -0.3546, -0.1060, -0.4155, -0.0092,  0.0451,  0.2753,\n",
      "         0.1223,  0.0409,  0.2953,  0.2669,  0.1358, -0.2848,  0.4600, -0.1598,\n",
      "        -0.1972,  0.0920,  0.5507,  0.3806, -0.4790,  0.5529, -0.4359,  0.2638,\n",
      "        -0.1113, -0.0107,  0.0334, -0.3632, -0.3063, -0.2307,  0.0353, -0.2921,\n",
      "        -0.3712, -0.0725, -0.3530,  0.1609,  0.1760, -0.5645,  0.2814,  0.0065,\n",
      "        -0.0952,  0.0712, -0.1100,  0.5263, -0.0439,  0.0756, -0.4717, -0.1737,\n",
      "         0.0855, -0.4192, -0.2317,  0.1859, -0.4024, -0.3869, -0.4510, -0.1190,\n",
      "         0.2580,  0.0742, -0.0854, -0.0011,  0.5955, -0.0130,  0.2377,  0.0388,\n",
      "        -0.0594,  0.1044,  0.4967,  0.0174,  0.3392,  0.1058,  0.4856, -0.1497,\n",
      "        -0.5066, -0.0645,  0.2343,  0.3589,  0.0095, -0.4229, -0.0401,  0.2228,\n",
      "        -0.4290, -0.0982,  0.1490,  0.0408,  0.3276, -0.0438, -0.3989,  0.2097,\n",
      "         0.3325,  0.1334, -0.2472, -0.1787, -0.2429,  0.3084,  0.1491,  0.6648,\n",
      "         0.3386, -0.0429, -0.2656, -0.2091,  0.2332,  0.0585,  0.0316, -0.4832,\n",
      "         0.2960, -0.2225,  0.0033,  0.5838,  0.0505,  0.2244, -0.0444,  0.1992,\n",
      "         0.4042, -0.3840, -0.3426,  0.6718, -0.2083,  1.0124,  0.0511,  0.0815,\n",
      "        -0.3920,  0.6335, -0.0841, -0.1004,  0.2399, -0.1457,  0.0572, -0.0162,\n",
      "        -0.2163,  0.2672,  0.1693,  0.3114, -0.1007,  0.0346, -0.1923, -0.1133,\n",
      "         0.2455,  0.0962, -0.0107, -0.1576,  0.2350,  0.2357,  0.2747,  0.3006,\n",
      "        -0.2787,  0.0264, -0.0357, -0.0517, -0.0889, -0.0247, -0.2458,  0.2003,\n",
      "        -0.2331,  0.4652,  0.1848,  0.5343, -0.2362,  0.0805, -0.3999,  0.5082],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.3700]],\n",
      "\n",
      "         [[ 0.0802]],\n",
      "\n",
      "         [[-0.0694]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0760]],\n",
      "\n",
      "         [[ 1.6424]],\n",
      "\n",
      "         [[-0.4876]]],\n",
      "\n",
      "\n",
      "        [[[-0.7194]],\n",
      "\n",
      "         [[ 0.0773]],\n",
      "\n",
      "         [[-0.3087]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2386]],\n",
      "\n",
      "         [[ 0.3485]],\n",
      "\n",
      "         [[-0.1226]]],\n",
      "\n",
      "\n",
      "        [[[-0.3321]],\n",
      "\n",
      "         [[-0.0398]],\n",
      "\n",
      "         [[-0.4102]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5160]],\n",
      "\n",
      "         [[ 0.5077]],\n",
      "\n",
      "         [[-1.6955]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1154]],\n",
      "\n",
      "         [[-0.2809]],\n",
      "\n",
      "         [[ 0.1535]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2729]],\n",
      "\n",
      "         [[ 0.3969]],\n",
      "\n",
      "         [[ 0.0924]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0099]],\n",
      "\n",
      "         [[ 0.0031]],\n",
      "\n",
      "         [[-0.0346]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5096]],\n",
      "\n",
      "         [[-0.3650]],\n",
      "\n",
      "         [[-0.3629]]],\n",
      "\n",
      "\n",
      "        [[[-0.3787]],\n",
      "\n",
      "         [[-0.3836]],\n",
      "\n",
      "         [[-0.0400]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0377]],\n",
      "\n",
      "         [[-0.5317]],\n",
      "\n",
      "         [[ 0.2163]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([7.1073, 7.4536, 5.1951, 7.8819, 3.2644, 5.8017, 4.0760, 5.1821, 6.8468,\n",
      "        7.1024, 5.3875, 6.2121, 5.7579, 6.0547, 9.5484, 5.7841, 3.1733, 4.5890,\n",
      "        9.9539, 7.0236, 5.6928, 3.8739, 5.6572, 5.5152, 8.2328, 5.7331, 7.5324,\n",
      "        6.3497, 9.0779, 4.9502, 5.9072, 6.7918, 5.8617, 5.0633, 6.2260, 5.1459,\n",
      "        6.8677, 6.0743, 5.5436, 6.1286, 7.5906, 7.3592, 5.3561, 7.9526, 6.8024,\n",
      "        5.9952, 6.1168, 7.1640], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.0080, -0.0215, -0.0033, -0.0155, -0.0097,  0.0112,  0.0119, -0.0222,\n",
      "         0.0116,  0.0244,  0.0025,  0.0077, -0.0010,  0.0131, -0.0122,  0.0304,\n",
      "         0.0013, -0.0142,  0.0471, -0.0063,  0.0075,  0.0035,  0.0154,  0.0009,\n",
      "         0.0534, -0.0099, -0.0174, -0.0123,  0.0268,  0.0086,  0.0056, -0.0120,\n",
      "         0.0296, -0.0054,  0.0121, -0.0066, -0.0239, -0.0007, -0.0114, -0.0010,\n",
      "         0.0081, -0.0106, -0.0017, -0.0102,  0.0270,  0.0097,  0.0005, -0.0182],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2741]],\n",
      "\n",
      "         [[ 0.5271]],\n",
      "\n",
      "         [[-0.3991]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1824]],\n",
      "\n",
      "         [[ 0.3476]],\n",
      "\n",
      "         [[ 0.1005]]],\n",
      "\n",
      "\n",
      "        [[[-0.1896]],\n",
      "\n",
      "         [[ 0.3047]],\n",
      "\n",
      "         [[-0.6527]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5559]],\n",
      "\n",
      "         [[ 0.1236]],\n",
      "\n",
      "         [[ 0.8613]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0644]],\n",
      "\n",
      "         [[-0.1988]],\n",
      "\n",
      "         [[-0.1239]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0863]],\n",
      "\n",
      "         [[ 0.2802]],\n",
      "\n",
      "         [[-0.3047]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0656]],\n",
      "\n",
      "         [[-0.0990]],\n",
      "\n",
      "         [[ 0.2736]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0408]],\n",
      "\n",
      "         [[ 0.5281]],\n",
      "\n",
      "         [[ 0.1766]]],\n",
      "\n",
      "\n",
      "        [[[-0.4714]],\n",
      "\n",
      "         [[ 0.6130]],\n",
      "\n",
      "         [[-0.3910]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3489]],\n",
      "\n",
      "         [[ 0.2847]],\n",
      "\n",
      "         [[ 0.1295]]],\n",
      "\n",
      "\n",
      "        [[[-0.4140]],\n",
      "\n",
      "         [[ 0.4598]],\n",
      "\n",
      "         [[-0.3149]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1590]],\n",
      "\n",
      "         [[-0.3110]],\n",
      "\n",
      "         [[-0.0709]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.2461,  0.1706,  1.0498,  0.0353,  1.1241,  2.5003,  2.1971,  0.9239,\n",
      "         0.3764,  0.2716,  0.3512,  1.5734,  0.9489,  1.7177,  0.6157,  1.3421,\n",
      "         0.5736,  0.7953,  1.1677,  1.6298,  1.2789,  0.9187,  0.1916,  0.2250,\n",
      "         0.9909,  0.8708,  0.4587,  1.0493,  0.5547,  0.5864,  0.7318,  0.4295,\n",
      "         1.1172,  1.1862,  1.4098,  0.8003,  0.3218,  0.3861,  0.4101,  0.4954,\n",
      "         0.8438,  0.1110,  0.8920,  0.9182,  1.0043,  1.3626,  1.7642, -0.2507,\n",
      "         0.5014,  1.3768,  0.4803,  1.8612,  0.2285,  0.8312,  2.6767,  1.0712,\n",
      "         0.5651,  0.4342,  1.5162,  0.6475,  1.2400,  1.1980,  0.2529,  0.6317,\n",
      "         0.4297,  1.4189,  2.6126,  0.9855,  0.3074,  2.0605,  1.4628,  1.1609,\n",
      "         1.1284,  1.3174,  1.1123,  3.2119,  1.5734,  0.8909,  1.1338,  1.4505,\n",
      "         1.2937,  0.8904,  2.2913,  1.5315,  0.9216,  0.4106,  1.5059,  0.2421,\n",
      "         0.2439,  0.2233,  1.8289,  1.2168,  0.8251,  0.6095,  0.6360,  0.8434,\n",
      "         0.6401,  1.0205,  0.4116,  1.5958,  1.4329,  0.8933,  1.9534,  2.1699,\n",
      "         1.0954,  0.5733,  1.1024,  1.5738,  1.0856,  0.3081,  1.3619,  1.6066,\n",
      "         0.6037, -0.0759,  0.4068,  1.7070,  0.1354,  0.6808,  0.6678,  0.9872,\n",
      "         1.7368,  0.8305, -0.1780,  1.1053,  0.6453,  0.5757,  0.0800,  0.9171,\n",
      "         0.3830,  1.0820,  0.4790,  0.9702,  0.2683,  0.8142,  1.2985,  0.7274,\n",
      "         0.6019,  0.8517,  0.2465,  0.2733,  0.4712,  1.0778,  0.5704,  1.7296,\n",
      "         0.4120,  0.3396,  0.0409,  0.3731,  1.0594,  3.4854,  0.8384,  0.5936,\n",
      "         0.9114,  1.8385,  2.7092,  0.9765,  0.4284,  0.8504,  0.2068,  0.3849,\n",
      "         1.5324,  1.9349,  0.7128,  1.3050,  1.4873,  1.8677,  1.5223,  0.9454,\n",
      "         1.2627,  0.8140,  0.3896,  1.2540,  1.1382,  1.0205,  2.2674,  0.5666,\n",
      "         0.5128,  0.4995,  1.2844,  1.1193,  1.1105,  1.2584,  0.6386,  0.8806,\n",
      "         1.5359,  1.0725,  1.2860,  0.5920,  1.1046,  0.4181,  1.3980,  0.2279,\n",
      "         1.0153,  0.1644,  1.0099,  0.2486,  0.9481,  1.4198,  1.8412,  0.9068,\n",
      "         0.1295,  0.9991,  0.8125,  0.1987,  0.8957,  1.9596,  0.3800,  0.1551,\n",
      "         0.4921,  0.6115,  1.1497,  1.0013,  0.7866,  1.0731,  0.7833,  0.8222,\n",
      "         0.5364,  2.8698,  0.6408,  1.1040,  0.8303,  1.3571,  0.3211,  1.3594,\n",
      "         0.6984,  0.3985,  1.8306,  0.6465,  0.8548,  0.9519,  1.4341,  0.6926,\n",
      "         1.8725,  1.3223,  1.7540,  1.5528,  1.7874,  1.1345,  0.2747,  1.1373,\n",
      "         1.5671,  1.7463,  1.0780,  0.6308,  0.7825,  0.9464,  0.7693,  0.5021,\n",
      "         0.7730,  0.5353,  1.2690,  0.2470,  1.5873,  1.0600,  0.7613,  0.7499,\n",
      "         2.0992,  2.1395,  0.9574,  2.4554,  2.1194,  0.5181,  1.1499,  0.6221,\n",
      "         1.5696,  0.3976,  1.0405,  0.7326,  1.2117,  0.1158,  1.4934,  0.6134,\n",
      "         0.7705,  1.2035,  0.8721,  0.2560,  1.7542,  1.7510,  1.4885,  0.7600,\n",
      "         1.3300,  0.4971,  1.3538,  1.2702,  1.6464,  1.8983,  0.3571,  1.5289],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 3.6792e-01,  3.2581e-01,  1.8476e+00,  5.5925e-01, -5.8207e-01,\n",
      "        -7.9416e-02, -1.8050e+00, -1.4489e-01,  3.2398e-01,  8.7916e-02,\n",
      "        -3.6486e-01, -1.5618e+00, -3.5813e-01,  1.6749e+00,  5.5648e-02,\n",
      "        -1.7147e-01,  6.8151e-01,  1.0862e+00, -6.6701e-01,  2.6849e+00,\n",
      "         2.2627e+00,  6.1926e-02,  3.5834e-01, -8.7870e-02,  1.4883e+00,\n",
      "         7.2289e-01,  1.0790e-01, -4.3757e-01, -1.4198e-01,  6.0923e-01,\n",
      "         2.9977e-01, -1.7992e-01,  1.0759e+00, -3.1281e-01,  8.6739e-01,\n",
      "         1.1338e+00, -1.1093e-01, -3.5220e-01,  1.2340e-01,  3.9549e-01,\n",
      "        -1.1341e+00,  4.2998e-01,  1.7631e+00,  4.2545e-01, -2.0843e+00,\n",
      "         4.3159e-01, -7.7819e-01,  7.3510e-02,  9.8212e-02,  8.8915e-01,\n",
      "         2.4250e-01, -3.6191e+00, -2.3388e-01,  2.1976e-01, -7.0405e-01,\n",
      "        -1.3404e+00, -5.1060e-02, -1.7096e-01,  1.9883e-01, -6.1945e-03,\n",
      "        -1.4640e+00, -5.7052e-01, -3.8030e-01,  5.4079e-02, -2.5434e-01,\n",
      "         1.3710e+00, -2.5138e+00,  1.0913e-02,  4.8480e-01,  6.9708e-01,\n",
      "        -3.3203e-01,  2.3697e-01,  9.2905e-01,  1.0180e+00,  9.3339e-01,\n",
      "        -2.8392e+00,  7.5301e-01,  1.3971e+00, -6.8058e-01,  6.6235e-01,\n",
      "         1.9527e+00,  3.6663e-01, -9.3006e-01, -1.5398e+00,  2.7023e-01,\n",
      "         1.3210e-01,  4.0891e-01, -2.8340e-01, -1.7254e-01, -2.3520e-02,\n",
      "         6.2562e-01,  1.1946e+00, -3.2722e-01, -6.3166e-01, -7.8959e-02,\n",
      "         3.4689e-01,  2.2368e-02,  1.2952e+00, -2.2967e-01, -3.5638e-01,\n",
      "        -5.4023e-01,  1.4640e+00, -3.0005e-01,  2.5804e-01, -2.4077e-01,\n",
      "        -1.4860e-01, -8.8362e-01,  3.1977e+00, -6.1324e-01, -2.3987e-01,\n",
      "         8.9740e-01, -1.0907e+00,  2.6419e-01,  2.2673e-01, -1.3784e-01,\n",
      "         4.1929e-01, -9.4345e-02,  5.6815e-01,  4.6496e-01, -1.0739e+00,\n",
      "         2.4607e-01, -2.1290e-01,  2.5086e-01,  1.6854e+00,  4.0911e-01,\n",
      "         1.6440e-01,  2.9619e+00,  1.4103e+00,  2.7379e-01, -1.1476e+00,\n",
      "        -3.2343e-03,  1.4015e+00, -6.4896e-02, -8.2331e-01,  1.2387e+00,\n",
      "         9.8807e-01, -2.5536e-01,  7.8258e-01,  2.7079e-01,  3.8707e-01,\n",
      "        -1.6382e-01, -2.0289e-02,  1.1047e+00, -1.9716e-01,  7.3786e-01,\n",
      "        -2.0210e-01,  2.6396e-01,  1.9506e-01,  9.3258e-02, -3.1901e-01,\n",
      "        -7.4028e-01,  6.1864e-01, -6.6480e-01,  1.0894e-01,  1.1740e+00,\n",
      "        -7.8380e-01, -2.4612e-01,  2.3312e-01,  8.6231e-02,  7.0981e-03,\n",
      "         7.4014e-01,  2.1588e-01, -5.7254e-02,  7.3137e-01, -1.2997e+00,\n",
      "         1.6763e+00, -3.9562e-01,  1.5008e+00,  5.3841e-02, -1.4859e+00,\n",
      "         2.6744e-01,  2.3576e+00, -1.0095e+00, -7.0457e-01,  2.1923e-01,\n",
      "        -2.2605e-01, -6.4242e-01, -2.5924e-01, -9.0323e-01,  6.9520e-01,\n",
      "        -6.0901e-01, -1.8039e+00,  5.8763e-01, -1.0085e+00,  7.4087e-01,\n",
      "        -5.1395e-01, -1.6799e-01, -9.3029e-01,  1.4160e+00,  1.0267e-01,\n",
      "        -9.7724e-01,  7.7285e-02,  1.1873e+00,  3.9775e-01,  8.4124e-01,\n",
      "        -3.2090e-01, -1.0518e+00,  2.1947e-01, -1.6364e+00,  1.0156e+00,\n",
      "        -1.8838e-01,  1.1411e+00, -2.3224e-01,  1.9441e-01,  2.4123e-01,\n",
      "        -3.8643e-01, -6.6478e-02,  1.4174e-01, -2.5568e-01,  3.3203e-01,\n",
      "        -8.2450e-01,  5.9760e-01, -3.1018e-01,  4.5758e-01,  1.1438e+00,\n",
      "        -2.7855e-01, -1.8205e-01, -1.8026e+00, -3.9793e-01, -3.3037e-01,\n",
      "         6.2534e-01,  1.1432e-01, -2.0275e-01,  1.0753e+00, -6.4383e-01,\n",
      "         5.3596e-02,  1.4150e-01, -4.1973e-01,  2.7562e-01, -7.8528e-01,\n",
      "         3.4914e-02,  7.1473e-01,  4.2446e-01,  8.4848e-01,  8.1760e-01,\n",
      "         7.0076e-01, -1.2454e-01, -6.8375e-01, -3.6642e-01,  1.6870e+00,\n",
      "         7.6157e-01, -1.8077e-01, -8.6983e-01,  8.6272e-01, -8.5136e-02,\n",
      "         1.6495e+00,  7.4655e-01, -4.1477e-01,  4.5240e-01,  3.6010e-01,\n",
      "        -1.3501e+00,  1.1893e-01,  1.1365e+00, -2.5160e-01,  9.4156e-01,\n",
      "        -1.2008e+00, -4.2763e-01,  1.6339e+00, -1.2720e+00,  2.6510e-02,\n",
      "        -3.1901e+00, -5.6968e-01,  1.1003e-01, -1.2107e-01,  6.4617e-01,\n",
      "         8.9739e-01, -6.5404e-01, -9.5499e-01,  4.8033e-02,  1.0939e-01,\n",
      "         1.1620e+00, -5.5766e-02,  7.0977e-03,  1.9112e+00, -1.0370e+00,\n",
      "        -2.2969e-01,  1.1070e+00,  9.6879e-02,  1.4260e+00,  1.7453e-01,\n",
      "        -3.6465e-01, -5.0060e-01,  9.5897e-01, -1.4799e+00,  1.0758e+00,\n",
      "         5.0020e-01,  1.2034e-01,  2.7742e-01], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0822,  0.0140, -0.9637, -0.4079, -0.3812],\n",
      "          [-0.1085,  0.0020,  0.2525,  0.6548,  0.0519],\n",
      "          [-0.7034, -0.5175,  0.3410,  0.1237, -0.4929],\n",
      "          [-0.2432,  0.0855,  0.3626,  0.0636,  0.2639],\n",
      "          [-0.2619, -0.1582, -0.2202, -0.1882,  0.0901]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3146, -0.1980, -0.1455,  0.0921, -0.0157],\n",
      "          [ 0.1860,  0.0723,  0.1075, -0.4521, -0.4378],\n",
      "          [ 0.3176,  0.5515,  0.0693, -1.2646, -0.4626],\n",
      "          [ 0.3567,  0.4814,  0.1925, -0.1095, -0.1444],\n",
      "          [ 0.5429,  0.0825,  0.2194,  0.0530,  0.3219]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1513,  0.2493,  0.3458, -0.1900,  0.3209],\n",
      "          [-0.3121, -0.0369,  0.0972,  0.3231,  0.1669],\n",
      "          [-0.2273,  0.1205, -0.6235, -0.0455,  0.6569],\n",
      "          [-0.2902,  0.1304,  0.2210, -0.4529, -0.7895],\n",
      "          [-0.6242, -0.5947,  0.0980, -0.1316, -0.0422]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4883, -0.1834, -0.6168,  0.2718, -0.3084],\n",
      "          [-0.1798,  0.0558,  0.0526,  0.1853, -0.2896],\n",
      "          [-0.2835, -0.2111,  0.8484, -0.1058, -0.6551],\n",
      "          [-0.3261,  0.2301,  0.3646,  0.2483, -0.3514],\n",
      "          [-0.5657,  0.2852, -0.4348,  0.1199, -0.0763]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2705, -0.2272, -0.3876, -0.0606, -0.0334],\n",
      "          [ 0.5804,  0.1706, -0.1831, -0.2422,  0.1069],\n",
      "          [ 0.3725,  0.0427,  0.6935,  0.4866,  0.3477],\n",
      "          [ 0.2002, -0.5405, -0.9392, -0.2197, -0.0131],\n",
      "          [-0.0931, -0.2206, -0.1497, -0.1820, -0.2696]]],\n",
      "\n",
      "\n",
      "        [[[-0.1909,  0.0678, -0.1390,  0.0214, -0.1662],\n",
      "          [-0.0941, -0.1638, -0.4828, -0.3890, -0.4389],\n",
      "          [ 0.2499,  0.1926,  0.0047, -0.0877,  0.3761],\n",
      "          [ 0.2191,  0.0809,  0.6269,  0.8339,  0.6375],\n",
      "          [ 0.6025,  0.0046, -0.2220, -0.1066, -0.2154]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.3838, 2.4241, 1.8817, 1.4661, 2.0566, 1.6990, 2.5068, 2.1851, 1.4263,\n",
      "        1.7786, 1.8291, 0.9893, 1.8667, 1.1820, 1.8870, 1.5464, 1.7127, 1.9925,\n",
      "        1.1754, 2.2616, 2.6860, 1.9746, 1.1724, 1.6364, 2.1182, 1.2977, 1.4389,\n",
      "        1.5564, 1.4872, 2.0522, 2.1351, 2.0372, 1.0278, 1.5306, 1.8249, 1.6636,\n",
      "        2.3711, 1.8981, 1.4276, 1.0202, 0.9064, 1.6225, 2.0740, 1.5616, 0.7896,\n",
      "        1.9024, 1.6087, 1.9551, 1.4631, 1.7830, 1.9117, 4.1744, 1.5784, 1.8112,\n",
      "        3.4580, 1.5664, 1.7228, 1.8170, 1.6725, 1.5243, 1.8955, 1.4885, 1.8467,\n",
      "        1.3967, 1.6165, 0.8242, 4.0481, 1.6225, 1.0216, 0.7285, 1.6986, 1.9860,\n",
      "        1.5238, 1.7369, 1.8269, 3.4515, 1.9698, 2.0284, 2.2047, 1.7318, 2.3056,\n",
      "        1.7366, 3.3759, 2.1187, 1.8242, 1.5864, 0.8847, 1.5838, 2.0477, 2.5322,\n",
      "        0.9959, 2.7296, 2.5124, 1.5119, 1.6247, 2.0917, 2.4234, 1.9198, 1.1448,\n",
      "        1.7504, 1.9098, 1.4843, 0.3651, 1.8351, 0.4806, 0.9856, 1.7170, 2.7230,\n",
      "        1.9636, 1.7129, 1.6259, 3.3253, 0.7379, 1.7702, 1.8075, 2.2976, 2.3132,\n",
      "        0.8310, 1.2308, 0.8113, 0.0828, 1.9184, 1.6554, 1.6155, 0.4394, 1.6921,\n",
      "        1.6200, 1.7540, 1.4959, 0.5187, 2.9497, 1.8973, 1.7186, 0.9241, 1.7672,\n",
      "        1.8063, 1.9975, 1.9818, 1.4723, 1.5651, 1.5951, 1.2467, 1.7858, 0.1569,\n",
      "        1.5381, 1.5140, 1.9869, 2.0037, 1.5893, 4.2574, 1.6838, 2.0137, 1.7178,\n",
      "        1.5688, 3.2943, 0.8012, 1.5199, 2.8383, 2.0852, 2.1615, 1.7042, 1.6684,\n",
      "        0.7874, 1.8072, 0.5642, 2.3707, 1.8573, 2.3174, 1.8416, 0.5120, 2.7099,\n",
      "        2.3964, 0.9153, 2.5673, 1.9009, 1.6800, 1.3042, 2.8850, 0.5649, 1.5527,\n",
      "        1.5182, 1.5784, 1.6286, 1.1433, 1.9387, 2.0978, 1.7921, 1.6525, 2.0119,\n",
      "        2.0675, 1.0558, 2.8490, 1.6467, 1.2480, 1.8136, 1.9902, 0.9903, 1.4480,\n",
      "        2.2511, 1.6307, 2.4255, 1.8417, 3.8665, 1.8302, 1.7513, 0.6444, 2.6204,\n",
      "        1.8752, 0.9598, 1.6578, 1.6660, 1.6188, 1.6565, 2.2211, 1.6224, 0.9447,\n",
      "        2.5260, 1.9000, 1.9182, 1.5711, 1.5862, 1.1195, 1.5944, 1.9126, 1.9895,\n",
      "        1.8017, 1.2211, 1.1536, 1.8649, 0.8098, 1.1820, 1.9616, 0.8457, 1.8428,\n",
      "        2.0365, 1.7816, 2.2274, 1.4829, 1.4865, 2.1478, 2.0879, 0.3855, 1.5135,\n",
      "        1.6770, 3.6820, 1.8379, 0.8777, 1.4176, 0.3680, 1.9926, 1.2342, 2.1023,\n",
      "        1.2729, 1.8395, 1.5993, 1.1803, 0.6701, 2.0082, 0.5829, 1.5042, 1.1554,\n",
      "        1.4992, 1.3010, 1.4929, 1.8986, 1.3603, 1.3313, 0.5623, 1.5452, 2.5087,\n",
      "        2.5327, 1.5139, 1.8292, 1.7131, 1.3623, 1.9174, 1.6978, 2.2188, 2.5718,\n",
      "        1.8870, 1.4898, 1.8412, 2.0800, 1.8882, 1.1147, 1.7663, 1.5910, 1.6813],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.2492, -1.4190, -1.7883, -1.5593, -1.2669, -0.8260, -1.4295, -1.1212,\n",
      "        -1.8796, -1.5645, -1.2931,  0.3691, -1.5156, -0.2997, -1.3567, -0.9719,\n",
      "        -1.7295, -1.5553,  0.2780, -2.3016, -2.4081,  0.1888, -0.6710, -1.2317,\n",
      "        -0.6877, -0.1894, -1.4096, -0.5338, -1.6654, -1.3782, -0.7365, -1.3157,\n",
      "         0.3553, -1.6223, -1.4528, -0.9305, -0.9279, -1.1974, -1.5077, -0.5508,\n",
      "         0.3745, -1.4203, -1.5981, -1.2815,  0.4292, -0.8216, -1.7662, -1.0562,\n",
      "        -0.5824, -1.3764, -1.7890, -1.5659, -1.4518, -1.6075, -1.4526,  0.5830,\n",
      "        -2.3132, -1.6869, -0.9865, -1.7594, -2.2643, -1.6693, -1.0405, -2.2160,\n",
      "        -0.6144, -0.0629, -3.9671, -1.1352,  0.2811,  0.1842, -0.1136, -3.1043,\n",
      "        -1.1657, -1.1212, -1.9565, -4.4219, -2.6771, -1.7288, -2.6768, -0.8473,\n",
      "        -1.4887, -1.2055, -0.8245, -0.4340,  1.2953, -1.3876,  0.2789, -1.3475,\n",
      "        -1.3821, -1.3184,  0.3753, -1.3510, -1.1696, -2.9808, -1.4786, -1.7995,\n",
      "        -2.2217, -1.5640, -0.6373, -1.0295,  0.1055, -2.2156,  0.0596, -0.8834,\n",
      "         0.0709,  0.1151, -3.0039, -2.0213, -2.3175, -1.1125, -0.1130, -0.9611,\n",
      "         0.0963, -1.5800, -1.4668, -0.6933, -1.3013,  0.5948, -0.6253,  0.5147,\n",
      "         1.0495, -2.1191, -1.1378, -1.1813, -0.0774, -0.4672, -1.1093, -1.3961,\n",
      "        -1.1916, -0.1577, -1.0025, -0.7401, -1.8830, -0.0086, -1.0915, -1.5487,\n",
      "        -1.4867, -2.2572, -1.3277, -1.3570, -2.0096,  0.5649, -1.4176,  0.1229,\n",
      "        -1.0800, -1.2404, -1.2326, -1.5263, -1.3714, -2.5003, -1.9698, -1.8774,\n",
      "        -1.8066, -0.7952, -1.9802,  1.1815, -2.1612, -2.2931, -2.0367, -1.4568,\n",
      "        -1.7796, -1.1846,  0.1299, -2.0018, -0.2805, -1.8790, -1.2095, -1.3192,\n",
      "        -1.4226,  0.2387, -1.0420, -2.4452, -0.0481, -1.3094, -2.1469, -1.4585,\n",
      "        -0.6729, -1.3612, -0.1537, -2.6430,  0.1197,  0.4869, -1.5826, -0.1161,\n",
      "        -1.6096, -0.3645, -0.4972,  0.2244, -0.2779, -0.9639,  0.2588, -1.3773,\n",
      "        -1.4299, -1.6197, -1.5541,  1.2336,  0.0260, -0.8243, -0.9252, -1.9321,\n",
      "        -1.2382, -1.3914, -0.8473, -1.2459, -1.2902,  0.2679, -1.3166, -1.4748,\n",
      "         0.2570, -1.1543, -2.2690, -1.9347, -2.7862, -1.4645, -0.8773, -0.5751,\n",
      "        -1.2884, -2.8537, -1.2068, -1.5092, -1.3609, -0.1347, -1.0456, -1.1300,\n",
      "        -2.4341, -1.1962,  0.2778, -2.8429, -2.1855, -0.1243, -0.4537, -1.6737,\n",
      "         0.2065, -1.8556, -1.0967, -2.3696, -1.0314,  0.2647, -0.8624, -1.3641,\n",
      "        -2.3416, -0.1504, -1.5287, -1.8760, -1.0228, -2.3195,  0.7881, -0.7038,\n",
      "         0.0405, -1.0641,  0.6864, -1.3718, -0.9441, -3.7334, -1.1372, -2.0554,\n",
      "         0.1298, -0.0197, -0.2769,  0.5995,  0.1920,  0.1410, -1.9039,  0.7734,\n",
      "        -1.0355, -0.6282, -0.5579,  0.0605, -1.6538, -1.5982, -2.2306, -1.6971,\n",
      "        -0.3462, -2.4190, -2.7558, -2.4130, -0.8430, -2.4323, -0.8767, -0.5327,\n",
      "        -0.6139, -2.3881, -1.2478, -0.1750,  1.4278,  1.0906, -1.2596, -1.4066],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.4045]],\n",
      "\n",
      "         [[ 0.2798]],\n",
      "\n",
      "         [[ 0.1005]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1337]],\n",
      "\n",
      "         [[ 0.3520]],\n",
      "\n",
      "         [[ 0.1868]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4322]],\n",
      "\n",
      "         [[ 0.0279]],\n",
      "\n",
      "         [[-0.2844]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1533]],\n",
      "\n",
      "         [[-0.4099]],\n",
      "\n",
      "         [[-0.3799]]],\n",
      "\n",
      "\n",
      "        [[[-0.0147]],\n",
      "\n",
      "         [[-0.3362]],\n",
      "\n",
      "         [[ 0.0607]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3491]],\n",
      "\n",
      "         [[-0.1989]],\n",
      "\n",
      "         [[-0.0086]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0389]],\n",
      "\n",
      "         [[ 0.0377]],\n",
      "\n",
      "         [[ 0.2389]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1100]],\n",
      "\n",
      "         [[-0.1480]],\n",
      "\n",
      "         [[ 0.3339]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4182]],\n",
      "\n",
      "         [[ 0.3632]],\n",
      "\n",
      "         [[-0.0278]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0655]],\n",
      "\n",
      "         [[-0.1427]],\n",
      "\n",
      "         [[ 0.0230]]],\n",
      "\n",
      "\n",
      "        [[[-0.0421]],\n",
      "\n",
      "         [[-0.2465]],\n",
      "\n",
      "         [[ 0.1339]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0310]],\n",
      "\n",
      "         [[ 0.3121]],\n",
      "\n",
      "         [[ 0.6739]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.0612,  0.1890, -0.0782,  0.0705,  0.1575, -0.3982, -0.2430, -0.3575,\n",
      "        -0.3528,  0.1618,  0.1107,  0.0498], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.1194]],\n",
      "\n",
      "         [[-0.0635]],\n",
      "\n",
      "         [[ 0.3299]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1992]],\n",
      "\n",
      "         [[ 0.5242]],\n",
      "\n",
      "         [[-0.4013]]],\n",
      "\n",
      "\n",
      "        [[[-0.0083]],\n",
      "\n",
      "         [[ 0.1138]],\n",
      "\n",
      "         [[ 0.1625]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1958]],\n",
      "\n",
      "         [[ 0.3417]],\n",
      "\n",
      "         [[ 0.0216]]],\n",
      "\n",
      "\n",
      "        [[[-0.0415]],\n",
      "\n",
      "         [[ 0.0517]],\n",
      "\n",
      "         [[ 0.0592]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0480]],\n",
      "\n",
      "         [[ 0.2980]],\n",
      "\n",
      "         [[-0.0765]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2223]],\n",
      "\n",
      "         [[-0.0695]],\n",
      "\n",
      "         [[-0.0182]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9170]],\n",
      "\n",
      "         [[-0.1171]],\n",
      "\n",
      "         [[ 0.0946]]],\n",
      "\n",
      "\n",
      "        [[[-0.0459]],\n",
      "\n",
      "         [[ 0.2109]],\n",
      "\n",
      "         [[ 0.5223]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2912]],\n",
      "\n",
      "         [[-0.2767]],\n",
      "\n",
      "         [[-0.3389]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5642]],\n",
      "\n",
      "         [[ 0.1194]],\n",
      "\n",
      "         [[-0.0924]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0994]],\n",
      "\n",
      "         [[-0.2514]],\n",
      "\n",
      "         [[-0.2764]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 3.3577e-01,  3.8895e-02,  1.9670e-01, -2.7115e-01,  2.2612e-01,\n",
      "         2.8809e-01,  1.7629e-01,  4.7425e-01,  2.5682e-01, -5.1865e-02,\n",
      "        -5.9864e-03,  7.9611e-02, -2.7999e-02,  2.8609e-01, -2.8562e-01,\n",
      "         2.6717e-01, -3.8851e-01,  2.1526e-01,  5.1328e-01,  9.3432e-04,\n",
      "         3.4499e-01,  1.2957e-01, -2.1172e-01,  6.4761e-02, -3.5111e-01,\n",
      "         2.6889e-01,  2.4188e-01,  3.7501e-02, -2.3179e-01,  5.5776e-01,\n",
      "        -2.8508e-01,  3.8178e-01,  6.7971e-01,  2.7654e-02,  1.2632e-01,\n",
      "        -4.5936e-02,  1.8220e-01,  2.5513e-01,  1.2738e-01, -3.9320e-01,\n",
      "         1.1029e-01, -8.7285e-02,  4.5911e-01, -7.2534e-02,  6.8140e-01,\n",
      "         2.7572e-01,  2.6564e-01,  2.9390e-01,  6.5476e-03,  3.8669e-01,\n",
      "         4.0488e-01, -5.3207e-01,  2.3057e-01,  4.0295e-01,  1.8818e-01,\n",
      "         6.2305e-01, -1.3943e-01,  4.3153e-02,  1.6359e-01,  3.6401e-01,\n",
      "        -9.0736e-02, -6.8189e-02,  3.5452e-01,  1.4832e-01,  2.1152e-01,\n",
      "         3.5622e-01,  2.3771e-01, -6.6984e-02,  3.3149e-01, -5.7614e-01,\n",
      "         2.3594e-01,  4.5199e-01,  1.5696e-01,  5.8128e-01,  1.4973e-01,\n",
      "         3.7599e-01,  1.4126e-01,  4.0653e-01,  1.4997e-01,  3.4843e-01,\n",
      "         5.2330e-01,  1.6903e-01,  5.8388e-04, -3.1523e-01,  7.5566e-02,\n",
      "         1.7679e-01,  5.3608e-01, -6.6518e-01,  3.1833e-01, -3.8222e-02,\n",
      "         2.0882e-01, -2.7421e-01, -1.9909e-01,  6.7999e-01,  5.1885e-01,\n",
      "         2.3496e-02,  9.5418e-01,  1.8280e-01, -8.6642e-03,  2.9953e-01,\n",
      "         2.6829e-01,  1.8325e-01,  9.1341e-02, -1.2466e-01,  3.2913e-02,\n",
      "         4.7200e-01, -4.8418e-03,  2.5806e-01,  4.1515e-01,  1.7851e-01,\n",
      "         2.2756e-01,  1.1648e-01,  3.5160e-01, -2.8926e-01,  3.1476e-01,\n",
      "         2.5402e-01, -1.0560e-01,  6.3419e-02,  3.1493e-01,  5.1672e-01,\n",
      "        -4.8115e-01,  3.4635e-01,  4.2836e-01,  6.4240e-02, -2.9792e-01,\n",
      "         3.2259e-01,  2.4945e-01,  2.3993e-01,  1.1153e-01, -1.4532e-01,\n",
      "        -4.7177e-01,  2.1215e-01, -5.9065e-02,  2.0034e-02,  4.2869e-01,\n",
      "         6.3608e-01,  4.2853e-01,  3.2257e-01, -1.6604e-01, -2.6270e-01,\n",
      "         4.8108e-01, -1.5701e-01, -2.0642e-01, -1.2322e-01, -2.0402e-01,\n",
      "        -2.6550e-01, -2.0689e-02, -1.2215e-01,  2.8943e-01,  1.0374e+00,\n",
      "        -2.3908e-01, -1.3057e-01, -4.3342e-01,  2.0692e-01,  4.6766e-01,\n",
      "         1.8352e-01,  9.5758e-02, -8.7608e-02,  1.5293e-01,  5.4358e-02,\n",
      "         1.7890e-01, -3.0180e-01,  6.3460e-02, -5.8477e-01,  3.7912e-01,\n",
      "         6.7887e-01, -2.7509e-01,  3.5770e-01,  4.7748e-02,  2.2801e-01,\n",
      "         3.5992e-01,  4.2707e-01,  5.0532e-02, -1.7541e-01,  1.2533e-01,\n",
      "        -3.0768e-01, -7.7887e-03,  2.0812e-01, -2.5769e-01,  2.1209e-01,\n",
      "        -5.2392e-01,  8.8592e-01,  1.6703e-01,  1.7288e-01,  1.0571e-01,\n",
      "         2.7288e-01,  3.0910e-01,  3.8519e-01,  2.7266e-01,  4.0732e-01,\n",
      "         2.4087e-01, -4.3020e-02,  5.8623e-02, -5.9607e-02,  3.6946e-01,\n",
      "         8.6557e-01, -1.8045e-03, -1.1774e-01,  1.8279e-01, -4.4704e-01,\n",
      "        -3.1502e-02,  4.0260e-02, -2.8482e-01,  4.6441e-01,  3.7588e-01,\n",
      "         5.8036e-01,  1.1958e-01,  1.7137e-01,  2.6780e-01, -1.3611e-01,\n",
      "        -2.3002e-02,  7.1112e-02,  3.8312e-01,  2.3311e-02,  7.0144e-02,\n",
      "         9.4629e-02,  4.2180e-01,  2.2445e-01, -6.3894e-02,  2.5932e-01,\n",
      "        -4.8380e-02,  3.5083e-01, -3.4816e-01, -2.4497e-02,  2.0379e-03,\n",
      "         5.0925e-01, -7.7623e-02, -8.9601e-03, -3.5050e-02,  1.3802e-01,\n",
      "        -5.6999e-01,  3.2037e-02, -3.5024e-01,  9.9869e-02, -1.8577e-04,\n",
      "        -6.9572e-02, -5.0210e-01,  2.6226e-01,  4.9702e-02,  2.8263e-01,\n",
      "         9.8582e-02,  1.7103e-01,  1.0398e-01, -3.5961e-01, -1.0311e-01,\n",
      "         7.1695e-01,  3.8289e-01,  8.1085e-02, -4.1062e-02,  2.0407e-01,\n",
      "         5.5454e-01,  5.5964e-01, -4.7401e-01,  4.5755e-01, -8.2786e-02,\n",
      "         2.1912e-01,  2.5116e-02, -9.3768e-02, -2.6223e-01,  8.0127e-01,\n",
      "         6.0649e-01,  3.3943e-01,  4.3642e-02,  3.6949e-01, -8.2690e-02,\n",
      "         3.7350e-01,  2.0287e-01,  4.0752e-01,  5.6620e-02, -1.2902e-03,\n",
      "        -8.1983e-02,  6.1034e-02,  6.8579e-01,  3.1395e-01,  5.0168e-01,\n",
      "         5.8312e-01, -2.1772e-01,  1.8923e-01,  1.7522e-01,  5.2793e-01,\n",
      "         4.9566e-01,  5.4565e-02,  3.0093e-02, -1.9059e-01, -4.5622e-01,\n",
      "         5.1710e-01, -2.1439e-02, -7.5429e-02], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.4307]],\n",
      "\n",
      "         [[ 0.0747]],\n",
      "\n",
      "         [[ 0.3472]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1995]],\n",
      "\n",
      "         [[ 0.1426]],\n",
      "\n",
      "         [[ 0.4120]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1183]],\n",
      "\n",
      "         [[-0.1314]],\n",
      "\n",
      "         [[ 0.1856]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4052]],\n",
      "\n",
      "         [[-0.0367]],\n",
      "\n",
      "         [[-0.0657]]],\n",
      "\n",
      "\n",
      "        [[[-0.3634]],\n",
      "\n",
      "         [[ 0.9715]],\n",
      "\n",
      "         [[ 0.8207]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.8938]],\n",
      "\n",
      "         [[ 0.0673]],\n",
      "\n",
      "         [[ 0.2114]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0567]],\n",
      "\n",
      "         [[ 0.0239]],\n",
      "\n",
      "         [[ 0.2994]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7818]],\n",
      "\n",
      "         [[ 0.2568]],\n",
      "\n",
      "         [[ 0.7454]]],\n",
      "\n",
      "\n",
      "        [[[-0.1186]],\n",
      "\n",
      "         [[-0.1779]],\n",
      "\n",
      "         [[-0.4407]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0370]],\n",
      "\n",
      "         [[-0.0372]],\n",
      "\n",
      "         [[ 0.4495]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4431]],\n",
      "\n",
      "         [[ 0.1098]],\n",
      "\n",
      "         [[ 0.0750]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4400]],\n",
      "\n",
      "         [[ 0.1854]],\n",
      "\n",
      "         [[-0.1400]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.7101, 0.9365, 3.8579, 1.0601, 5.5926, 0.4790, 1.7404, 1.2573, 0.9481,\n",
      "        0.8519, 0.7993, 1.4977, 0.9245, 1.2863, 1.1950, 1.9160, 3.9426, 5.2306,\n",
      "        0.6466, 1.1153, 1.5185, 2.6325, 1.7369, 4.0055, 0.9820, 0.9261, 0.9786,\n",
      "        1.4401, 0.9569, 1.1735, 1.0472, 1.2939, 1.1929, 3.7994, 1.8620, 2.0916,\n",
      "        0.9202, 1.3298, 1.6221, 1.0040, 1.1430, 1.1491, 1.9382, 0.8995, 0.6648,\n",
      "        0.9604, 1.0427, 0.5328], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.9949, -1.5892,  0.6020, -1.6808, -2.1774,  1.0935,  1.3325, -0.2222,\n",
      "         1.2818, -0.6633, -0.3959, -0.6892,  0.1596, -0.8953,  0.6601,  3.7189,\n",
      "        -1.5885, -1.6223,  0.2945, -0.5078,  0.8917,  0.4648,  1.1545,  0.2776,\n",
      "        -2.4508, -0.4389, -0.3618, -1.1068, -0.0109, -0.5897,  1.0198, -0.1134,\n",
      "         0.9775,  0.4425, -0.0903, -1.1279,  0.7661,  2.2533,  1.4576, -0.4245,\n",
      "         1.7573, -0.1673, -1.8401, -0.6252,  0.1121,  0.0539,  0.6577,  0.2050],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.5265]],\n",
      "\n",
      "         [[ 0.0851]],\n",
      "\n",
      "         [[ 0.1911]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2475]],\n",
      "\n",
      "         [[ 0.3785]],\n",
      "\n",
      "         [[-0.3546]]],\n",
      "\n",
      "\n",
      "        [[[-0.0548]],\n",
      "\n",
      "         [[-0.2724]],\n",
      "\n",
      "         [[-0.5157]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0923]],\n",
      "\n",
      "         [[ 0.0105]],\n",
      "\n",
      "         [[-0.5513]]],\n",
      "\n",
      "\n",
      "        [[[-0.2225]],\n",
      "\n",
      "         [[ 0.5744]],\n",
      "\n",
      "         [[ 0.0024]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1507]],\n",
      "\n",
      "         [[-0.4957]],\n",
      "\n",
      "         [[-0.3117]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2286]],\n",
      "\n",
      "         [[ 0.1721]],\n",
      "\n",
      "         [[ 0.2070]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1366]],\n",
      "\n",
      "         [[-0.4030]],\n",
      "\n",
      "         [[-0.1323]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0245]],\n",
      "\n",
      "         [[ 0.3601]],\n",
      "\n",
      "         [[-0.4237]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3516]],\n",
      "\n",
      "         [[-0.5491]],\n",
      "\n",
      "         [[-0.0139]]],\n",
      "\n",
      "\n",
      "        [[[-0.7141]],\n",
      "\n",
      "         [[-0.3926]],\n",
      "\n",
      "         [[-0.5117]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1994]],\n",
      "\n",
      "         [[-0.0501]],\n",
      "\n",
      "         [[-0.0894]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.5297,  1.6471,  1.9249,  0.5801,  2.0867,  1.7709,  0.8470,  0.7981,\n",
      "         0.3635,  1.4016,  0.8326,  1.5273,  0.2010,  1.0257,  2.0341,  0.5816,\n",
      "         1.3518,  0.7761,  0.6413,  0.8215,  1.2704,  1.5456,  1.5286,  0.8709,\n",
      "         0.3298,  0.5004,  0.9854,  1.3440,  0.3811,  0.1662,  0.7148,  0.6190,\n",
      "         0.0974,  1.4006,  1.7161,  1.3960,  0.9704,  1.3020,  1.8689,  0.8270,\n",
      "         1.8205,  0.4204,  0.4779,  0.5026,  1.1134,  0.1035,  2.1470,  1.5640,\n",
      "         0.6253,  0.1707,  0.9425,  0.7634,  1.2845,  1.3289,  1.4017,  0.9758,\n",
      "         1.9727,  1.2105,  2.3323,  0.3615,  0.5476,  1.8462,  1.9921,  1.5562,\n",
      "         0.8585,  1.4058,  0.7474,  1.0627,  0.4509,  1.4128,  1.3365,  1.9197,\n",
      "        -0.2065,  1.1046,  1.1872,  1.0613,  1.2711,  0.1739,  0.8996,  1.3889,\n",
      "         0.9739, -0.1805,  0.6588,  1.0393,  0.8355,  1.4507,  1.7726,  0.5239,\n",
      "         0.8772,  0.0643,  1.9618,  0.7648,  0.9520,  1.2228,  1.1348,  2.1542,\n",
      "         0.3518,  1.9169,  2.5046,  1.0649,  2.5814,  2.1550,  1.3556,  2.5535,\n",
      "         1.7622,  1.1353,  0.7100,  1.2857, -0.1470,  1.8813,  1.5389,  0.5716,\n",
      "         1.0373,  1.0277,  0.6280,  0.3725,  1.7428,  1.8705,  1.5904,  0.8218,\n",
      "         0.6867,  0.9032,  0.7098,  2.3704,  1.7709,  3.0729,  0.9088,  1.3858,\n",
      "         0.2337,  0.4046,  1.6052,  1.9938,  1.4266,  0.0973,  1.4338,  1.5488,\n",
      "         1.6348,  0.2324,  0.1165,  1.9330,  1.2331,  0.8246,  1.6308,  0.3783,\n",
      "         0.2729,  1.4545,  0.7097,  1.5421,  0.0671,  1.7159,  0.8121,  0.4387,\n",
      "         2.3823,  1.8728,  0.2140,  1.3954,  2.0236,  0.7414,  1.6940,  0.2663,\n",
      "         1.2119,  1.0536,  0.3161,  1.7645,  0.8229,  0.7929,  0.2484,  0.3991,\n",
      "         1.0318,  0.3642,  1.3748,  1.9700,  2.6073,  1.2807,  1.1156,  1.1904,\n",
      "         1.0429,  1.3034,  1.7543,  1.3876,  1.7370,  0.6282,  1.0218,  1.0805,\n",
      "         1.6459,  0.9894,  1.0169,  1.2431,  2.0254,  1.3882,  1.5002,  0.2906,\n",
      "         1.2429,  0.2154,  0.9211,  0.0693,  2.3283,  1.0097,  1.7764,  0.6754,\n",
      "         0.5299,  1.8423,  0.1452,  0.6021,  1.9098,  0.7222,  1.0193,  1.2883,\n",
      "         3.0391,  1.3728,  1.3372,  0.5921,  0.2773,  1.8346,  0.6675,  1.6163,\n",
      "         1.4331,  0.9999,  1.3531,  1.2795,  1.1072,  0.7737,  1.1902,  0.6525,\n",
      "         1.7801,  1.6472,  0.2444,  2.0507,  0.1258,  0.6106,  0.7052,  0.6989,\n",
      "         2.8337,  1.3273,  1.4521,  1.3102,  0.5614,  1.6539,  0.9022,  0.2545,\n",
      "         0.4197,  1.2833,  2.9922,  2.0632,  1.2591,  1.7136,  0.1567,  0.8926,\n",
      "         0.5866,  0.5250,  0.2293,  0.4285,  0.5175,  1.9787,  1.4073,  0.8204,\n",
      "         1.4535,  1.2784,  0.2703,  1.4795,  2.1545,  1.3129,  1.0589,  0.9014,\n",
      "         0.3845,  1.5880,  1.9028,  2.2308,  0.8508,  1.2145,  0.9582,  1.9333,\n",
      "         0.1615,  0.7361,  1.6858,  1.4360,  1.0230,  0.3712,  2.0316,  1.5766,\n",
      "         1.5829,  1.2504,  1.2310,  1.1680,  0.6223,  1.2018,  0.6597,  1.6723],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-4.0125e+00,  1.6562e+00, -1.1446e-01,  7.9080e-02,  8.8381e-01,\n",
      "         2.1894e+00,  1.8267e+00, -3.0487e-01, -1.5937e-01,  1.2787e+00,\n",
      "        -6.1054e-01,  1.3977e+00, -1.9829e-01,  6.2122e-01,  2.1571e-01,\n",
      "        -3.8592e-01,  1.0222e+00, -4.9216e-03, -1.2110e+00, -7.1429e-01,\n",
      "         1.2010e-01,  1.5689e+00,  1.6843e-01, -1.0698e+00,  3.9518e-01,\n",
      "         1.4594e+00, -1.2783e+00,  1.4580e-01, -2.7346e-01, -1.4735e-01,\n",
      "        -7.4941e-01, -1.2041e-01, -1.9408e-01,  1.7302e-01,  1.7613e-02,\n",
      "        -1.4340e+00, -1.3728e+00,  1.0581e+00,  1.6750e+00,  9.6549e-01,\n",
      "         1.2087e+00, -9.8815e-02, -2.6171e-02, -7.7254e-01,  2.1342e-01,\n",
      "        -2.3851e-02, -5.3046e-01, -4.7921e-01,  3.5851e-01, -2.3343e-01,\n",
      "         3.3923e-01, -2.3556e-01,  8.6338e-01, -3.5865e+00, -6.7585e-01,\n",
      "        -3.2751e-01,  1.1470e+00,  1.4332e+00,  3.0954e-01,  3.1866e-01,\n",
      "         3.4406e-01, -3.6903e-01,  1.4560e-01, -1.1854e-01, -1.4443e+00,\n",
      "         8.2430e-01, -4.6282e-01, -8.1314e-01, -9.2047e-02, -1.1879e+00,\n",
      "         5.8862e-01, -1.0694e+00,  1.9466e-01,  1.1227e+00, -2.2516e+00,\n",
      "        -1.8474e+00,  7.8773e-01,  1.2471e-01, -1.5960e-01, -6.0725e-01,\n",
      "         2.2401e-01, -3.1820e-01, -4.3802e-01,  1.2072e+00,  4.3011e-01,\n",
      "         9.0422e-03,  5.5170e-01,  9.7588e-01,  3.2470e-01, -2.0386e-01,\n",
      "         2.6345e-01, -9.7717e-01,  1.2194e-01, -6.5691e-01, -1.0996e+00,\n",
      "        -9.3494e-01,  3.2815e-01, -4.2724e+00,  7.2943e-01,  3.4693e-01,\n",
      "        -2.7708e-01, -1.1824e+00, -1.4079e+00, -2.8556e+00,  1.8428e-01,\n",
      "        -8.7305e-02, -1.4813e+00, -9.5696e-01,  3.5391e-01, -1.3359e+00,\n",
      "        -7.0269e-01, -3.6307e-01,  1.0751e+00, -1.1895e+00, -7.2050e-01,\n",
      "         1.2661e-01,  7.1239e-01, -1.9132e+00, -3.9805e-01,  2.1092e+00,\n",
      "         9.4094e-01, -5.2805e-01, -8.6510e-01,  2.2307e-01,  3.1323e-03,\n",
      "        -2.2030e+00,  9.5682e-01, -7.6159e-02, -1.8454e-01, -4.5336e-01,\n",
      "         7.4452e-02,  7.7393e-02,  5.4776e-01,  3.0176e-01,  7.9555e-01,\n",
      "         9.1441e-01,  8.1367e-01,  1.9772e-01,  2.9457e+00, -2.0720e-01,\n",
      "        -3.6690e-01, -1.5151e-01, -1.4410e+00, -4.4979e-01, -3.6556e-01,\n",
      "         7.5151e-01,  2.5502e-02,  2.8148e-01, -3.7747e-01,  6.1226e-01,\n",
      "         1.0887e+00,  5.3128e-01, -2.4827e+00,  1.4011e-01,  3.8177e-01,\n",
      "         5.4233e-01, -1.0228e+00, -1.7421e+00,  6.8619e-01, -1.8413e-02,\n",
      "         1.0933e+00, -1.4935e+00, -6.4544e-02, -5.4159e-03,  8.1408e-01,\n",
      "        -2.0021e+00,  4.6770e-02,  8.3167e-02, -1.4531e+00,  6.4343e-02,\n",
      "        -5.1276e-01,  1.2532e+00, -1.7437e+00,  6.6366e-01,  8.0287e-01,\n",
      "        -1.6378e+00,  1.6490e+00,  2.0835e+00, -4.0969e+00, -3.4744e-01,\n",
      "         6.9887e-01, -3.8343e-02, -1.2918e+00,  1.2736e+00, -2.8573e-01,\n",
      "        -9.6031e-01,  2.4279e+00, -4.2997e-01, -2.0826e+00,  1.3557e+00,\n",
      "        -1.2043e+00,  3.3804e-01,  2.6864e-01,  2.4087e-01,  4.8409e-02,\n",
      "        -3.0464e-01, -1.7079e-01,  1.6042e+00, -9.7346e-01,  5.9273e-02,\n",
      "        -6.2320e-02,  2.7696e+00,  2.0240e-01,  6.0957e-01,  1.0659e+00,\n",
      "         1.5300e+00,  9.3311e-01, -9.4003e-02, -2.1970e+00,  1.1411e+00,\n",
      "        -7.4029e-01, -3.5575e-01,  8.2447e-02,  6.7028e-01,  1.5256e+00,\n",
      "         4.0437e-01,  9.6459e-01, -3.9459e-01,  2.4637e+00, -5.0963e-01,\n",
      "        -1.2641e+00, -8.1923e-01, -1.2092e+00, -8.3395e-01,  3.0996e-01,\n",
      "        -2.2213e+00, -6.8627e-01,  8.5398e-01,  3.4093e-01,  1.7191e-01,\n",
      "         1.1360e+00,  1.0011e-02,  2.0915e+00,  5.9127e-01,  9.7629e-02,\n",
      "         8.1586e-01,  4.3779e-01, -8.1910e-01, -1.4284e-01, -7.6627e-01,\n",
      "        -2.0577e-01, -1.1322e+00, -3.6373e+00,  1.0964e+00,  6.8238e-01,\n",
      "        -2.0032e-01, -7.6450e-02,  1.0756e-01, -4.1156e-01,  2.5740e-01,\n",
      "        -5.7513e-01,  9.4373e-03,  4.4943e-03,  3.2277e-01, -1.2727e-01,\n",
      "        -7.1651e-01, -1.1358e+00,  2.1601e-01, -9.3845e-03, -6.0307e-01,\n",
      "         1.6461e-01, -9.4817e-01,  2.0143e-01,  1.0168e+00,  1.3228e-01,\n",
      "        -5.0107e+00, -4.3911e-01, -9.5910e-01,  6.7344e-02,  1.0067e+00,\n",
      "         4.3952e-01,  2.2878e-01, -4.1309e-01,  1.1915e+00,  6.4597e-01,\n",
      "        -2.5207e-01,  7.2479e-01, -3.5163e-01, -2.3019e+00,  1.5681e+00,\n",
      "        -1.4597e+00,  6.7515e-01,  1.6626e+00, -7.4889e-01,  2.6047e-01,\n",
      "        -7.8063e-01, -1.1342e+00, -1.1519e+00], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-1.4951e-02,  5.9711e-01,  4.5359e-01,  9.4194e-02, -4.0740e-02],\n",
      "          [ 2.8559e-01,  3.0451e-01,  4.8522e-02,  3.9610e-02,  2.8335e-01],\n",
      "          [ 6.0425e-01,  6.1802e-01,  5.2097e-01,  3.2564e-01,  2.7327e-01],\n",
      "          [ 1.6593e-01, -5.2373e-02,  2.4173e-01,  1.0040e-01,  3.6633e-01],\n",
      "          [-7.7128e-02,  1.1874e-01,  2.4038e-01,  4.9619e-01,  4.7642e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6274e-02,  3.5469e-02, -2.1183e-01,  3.9353e-01, -2.7547e-01],\n",
      "          [-1.9619e-01,  2.7859e-01, -2.5090e-01,  4.2307e-01, -3.2641e-01],\n",
      "          [-2.6906e-02,  9.3801e-01, -2.3992e-01,  4.8531e-01,  1.3471e-01],\n",
      "          [ 9.3736e-03,  9.4612e-02, -5.3702e-01,  4.2450e-01, -2.1868e-01],\n",
      "          [-1.0026e-01,  1.1649e-01, -6.2656e-01,  3.9533e-01, -2.5281e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4494e-01, -3.7765e-01,  9.5971e-02, -3.2322e-01, -1.0608e-01],\n",
      "          [-2.6497e-02,  3.5164e-01,  4.4258e-01, -5.0708e-01, -2.9461e-01],\n",
      "          [ 1.5524e-01,  8.8463e-01,  5.0482e-02, -5.0892e-01, -5.0007e-02],\n",
      "          [-1.8503e-01,  1.4166e-01, -4.2146e-01, -4.2788e-03, -3.8827e-02],\n",
      "          [-2.3117e-01, -1.2496e-01, -2.6577e-01,  3.4002e-01, -2.0839e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.0700e-01,  5.8128e-01,  3.1350e-01, -2.3077e-01,  1.8470e-02],\n",
      "          [-5.2837e-01, -3.5518e-01,  4.8964e-01, -8.6457e-02, -1.8607e-01],\n",
      "          [-8.8824e-01, -5.2425e-01, -1.4797e-01, -1.5739e-01, -1.4036e-01],\n",
      "          [-4.7801e-01, -1.4672e-01, -1.9271e-04, -1.2483e-01, -8.1790e-02],\n",
      "          [ 1.1963e-01,  1.0699e-02, -4.4448e-01, -3.3841e-01, -1.5999e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6521e-01,  3.6002e-01,  5.9035e-01,  6.3994e-01,  2.4867e-01],\n",
      "          [ 1.7095e-01,  6.8376e-03, -7.7550e-01, -2.8471e-01,  4.5386e-02],\n",
      "          [-3.0361e-01, -1.7835e-01, -1.5874e-01, -8.6364e-02, -2.8748e-01],\n",
      "          [-2.7641e-01, -2.8622e-01, -1.1038e+00,  4.8981e-01, -2.6092e-02],\n",
      "          [ 1.4533e-01,  3.3817e-02,  1.5057e-01,  2.7464e-02,  2.3063e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.8290e-01, -4.0642e-01, -5.3739e-01,  3.1812e-01, -1.8640e-01],\n",
      "          [-3.2651e-01,  1.3100e-01, -9.9347e-02,  1.9932e-01, -4.6308e-01],\n",
      "          [-2.8809e-01,  8.0016e-02,  6.0960e-01, -2.0757e-02, -3.3703e-01],\n",
      "          [-2.2001e-01,  3.3467e-01,  3.4228e-01, -1.3135e-01, -3.7688e-01],\n",
      "          [ 2.4098e-01, -1.5448e-01, -6.9337e-01, -7.0445e-02, -2.4431e-01]]]],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 3.0895e+00,  2.0245e+00,  2.1712e+00,  1.4159e+00,  2.0757e+00,\n",
      "         2.0273e+00,  1.5873e+00,  1.2967e+00,  1.8082e+00,  1.8352e+00,\n",
      "         1.4492e+00,  1.4776e+00,  2.0420e+00,  1.9966e+00,  1.8258e+00,\n",
      "         1.4238e+00,  5.8664e-01,  1.7980e+00,  8.6681e-01,  5.4862e-01,\n",
      "         2.1919e+00,  1.8639e+00,  4.6823e-01,  4.7407e-01,  1.2194e+00,\n",
      "         1.3174e+00,  7.4236e-01,  1.2195e+00,  1.5687e+00,  1.0470e+00,\n",
      "         1.2267e+00,  9.1837e-01,  1.7153e+00,  1.5848e+00,  2.4510e+00,\n",
      "         3.6412e-01,  1.5107e+00,  1.6043e+00,  9.3889e-01,  4.5308e-01,\n",
      "         2.1132e+00,  1.5061e+00,  1.6422e+00,  1.6455e+00,  1.5849e+00,\n",
      "         1.7690e+00,  2.1613e-01,  5.8184e-01,  1.0524e+00,  1.3513e+00,\n",
      "         1.5118e+00,  1.5897e+00,  1.0438e+00,  2.2637e+00,  1.8250e+00,\n",
      "         2.0048e-01,  1.6953e+00,  1.4535e+00,  1.9685e+00,  1.6604e+00,\n",
      "         1.1067e+00,  9.1753e-01,  1.4886e+00,  8.5973e-01,  6.9673e-01,\n",
      "         2.0577e+00,  1.6628e+00,  1.3237e+00,  1.1869e+00,  9.5290e-01,\n",
      "         1.9470e+00,  3.3679e+00,  2.2399e+00,  1.6647e+00,  7.0261e-01,\n",
      "         2.3411e+00,  1.7006e+00,  1.7046e+00,  7.4183e-01,  1.2662e+00,\n",
      "         1.7500e+00,  1.6233e+00,  1.5046e+00,  1.9763e+00,  1.8494e+00,\n",
      "         2.4271e+00,  1.6460e+00,  5.4314e-01,  1.6059e+00,  8.3596e-01,\n",
      "         2.0694e+00,  2.0073e+00,  1.0811e+00,  9.4235e-01,  1.7448e+00,\n",
      "         1.4855e-01,  1.8662e+00,  5.1141e+00,  2.7096e+00,  1.2721e+00,\n",
      "         1.8909e+00,  3.7134e+00,  8.6852e-01,  2.4493e+00,  1.5769e+00,\n",
      "         1.4443e+00,  8.0199e-01,  2.3707e+00,  1.9420e+00,  1.6483e+00,\n",
      "         2.2872e+00,  1.5806e+00,  1.6951e+00,  3.6102e+00,  8.2455e-01,\n",
      "         1.7277e+00,  1.5354e+00,  1.9192e+00,  1.0491e+00,  1.0760e+00,\n",
      "         2.1901e+00,  1.5383e+00,  6.1465e-01,  2.9505e+00,  1.1313e+00,\n",
      "         2.3508e+00,  1.0610e+00,  1.6833e+00,  1.6463e+00,  8.2898e-01,\n",
      "         7.9001e-01,  1.5041e+00,  4.6055e-01,  1.6254e+00,  1.3680e+00,\n",
      "         1.5865e+00,  1.7290e+00,  1.6097e+00,  1.5857e-03,  7.7702e-01,\n",
      "         2.1264e+00,  1.9501e+00,  2.5327e+00,  1.6689e+00,  1.7046e+00,\n",
      "         7.1486e-01,  8.1857e-01,  1.0402e+00,  9.7443e-02,  1.7024e+00,\n",
      "         1.9025e+00,  1.8928e+00,  1.9180e+00,  2.2278e+00,  1.9753e+00,\n",
      "         2.2261e+00,  1.3055e+00,  7.0469e-01,  1.9347e+00,  1.6435e+00,\n",
      "         1.5991e+00,  1.6579e+00,  1.5780e+00,  1.0852e+00,  1.5202e+00,\n",
      "         1.0791e+00,  1.2827e+00,  1.9461e+00,  6.0202e-01,  1.7048e+00,\n",
      "         7.3311e-01,  1.3724e+00,  2.0288e+00,  9.6647e-01,  1.9374e+00,\n",
      "         1.5451e-01,  1.7701e+00,  1.9416e+00,  3.1833e+00,  1.6139e+00,\n",
      "         2.2879e+00,  1.8186e+00,  6.7570e-01,  1.2697e+00,  3.9619e-01,\n",
      "         1.4871e+00,  1.9562e+00,  1.9715e+00,  2.7930e+00,  1.5074e+00,\n",
      "         1.4038e+00,  1.7104e+00,  2.7339e+00,  1.9340e+00,  9.0729e-01,\n",
      "         7.7688e-02,  1.9221e+00,  2.3817e+00,  1.6021e+00,  1.5073e+00,\n",
      "         2.0166e+00,  2.0360e+00,  1.7123e+00,  2.2414e+00,  2.0911e+00,\n",
      "         1.8551e+00,  9.6189e-01,  1.6498e+00,  3.1070e+00,  1.9861e+00,\n",
      "         8.3506e-01,  1.7336e+00,  9.6296e-01,  1.5705e+00,  1.8603e+00,\n",
      "         1.8453e+00,  1.9598e+00,  1.5924e+00,  2.3393e+00,  1.6965e+00,\n",
      "         8.3227e-01,  1.1464e+00,  1.2102e+00,  1.0163e+00,  5.0182e-01,\n",
      "         1.6277e+00,  1.7434e+00,  1.2396e+00,  1.6375e+00,  1.7180e+00,\n",
      "         2.0699e+00,  1.9609e+00,  1.9903e+00,  1.7358e+00,  1.8596e+00,\n",
      "         6.5909e-01,  1.1919e+00,  2.0723e+00,  1.0212e+00,  1.2666e+00,\n",
      "         1.8476e+00,  5.8946e-01,  5.1435e+00,  2.1269e+00,  1.5740e+00,\n",
      "         8.5888e-01,  1.4541e+00,  1.3142e+00,  1.8890e+00,  1.5834e+00,\n",
      "         7.3299e-01,  1.7146e+00,  2.9507e+00,  1.1983e+00,  1.8753e+00,\n",
      "         2.1061e+00,  1.4149e+00,  1.3101e+00,  1.8941e+00,  9.1124e-01,\n",
      "         1.1156e+00, -1.1294e-01,  1.5955e+00,  2.2291e+00,  1.8038e+00,\n",
      "         4.7331e+00,  1.6471e+00,  2.9926e+00,  1.3662e+00,  1.7019e+00,\n",
      "         1.6439e+00,  6.8799e-01,  1.6463e+00,  1.7921e+00,  2.4399e+00,\n",
      "         2.0541e+00,  2.1758e+00,  1.8439e+00,  2.0293e+00,  2.3664e+00,\n",
      "         7.5662e-01,  1.1588e+00,  1.7263e+00,  6.9750e-01,  1.1773e+00,\n",
      "         4.2049e-01,  8.0003e-01,  2.1803e+00], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.6678, -1.0690, -1.2885,  0.2151, -1.1319, -2.5011, -0.2228, -1.9191,\n",
      "        -0.2492, -1.1458, -1.3963, -0.5023, -1.2361, -1.5123, -1.3577, -2.0141,\n",
      "        -0.0497, -3.5040, -0.0924,  0.6443, -1.2346, -1.3261,  1.0913,  0.3872,\n",
      "        -1.8934, -0.1749,  0.2154, -0.8387, -0.8898, -0.7514, -0.8214, -0.0075,\n",
      "        -1.6241, -1.3043, -1.8494, -0.2223, -0.7276, -1.7001, -0.4977, -0.1414,\n",
      "        -1.0830, -0.7482, -1.3484, -1.4392, -1.3962, -1.4764,  1.5987,  0.9721,\n",
      "        -1.2913, -1.1563,  0.1796, -1.6126, -0.2414, -3.2778, -0.1684,  0.8602,\n",
      "        -0.8609, -0.9899, -1.7946, -1.2601,  0.6623,  0.6480, -1.4481, -0.4456,\n",
      "        -0.2070, -2.8317, -3.3005, -1.0269,  0.0460,  0.8768, -2.6414,  0.3471,\n",
      "        -1.2864, -0.5648,  0.5184, -0.6288, -0.6295, -1.1290, -0.1790,  0.3782,\n",
      "        -2.0559, -1.4837, -1.1174, -1.6213, -1.1513, -0.9184, -1.2267,  0.0218,\n",
      "        -1.5873, -0.3575, -1.6374, -1.8830,  0.3145, -0.1448, -1.5770,  0.0329,\n",
      "        -1.1436, -3.5226, -1.8250, -1.1192, -0.9638,  0.5281, -0.1135, -3.6806,\n",
      "        -1.1062, -0.7166, -0.4211,  0.0149, -2.4099, -0.8817, -2.4328, -1.4171,\n",
      "        -1.7231, -0.4702, -0.1264, -1.4479, -1.0851, -1.1190,  0.0977, -1.0905,\n",
      "        -0.9900, -1.1837, -0.1716, -2.1883,  0.0333,  0.7487, -0.9932, -2.7723,\n",
      "        -1.2493, -0.0739, -0.0074,  0.9758, -0.0958, -1.6271, -0.8996, -1.3353,\n",
      "        -1.0137, -1.5890, -0.0280, -0.1775, -1.0429, -1.1602, -0.3932, -1.5106,\n",
      "        -1.5033, -0.0473,  0.3794, -0.3599,  0.0116, -1.3432, -1.4384, -0.8380,\n",
      "        -0.3813, -1.8661, -1.3071, -1.9518, -1.0031, -0.0132, -1.3195, -0.5956,\n",
      "        -1.4929, -0.8628, -1.3124,  0.3121, -1.8442, -5.5411,  0.0333, -2.0398,\n",
      "         0.0180, -1.3618,  0.2474, -0.0210, -1.0630, -0.5111, -1.6571,  0.3899,\n",
      "        -1.1927, -1.4874, -3.8265, -0.6810, -1.7887, -0.9300,  0.9874, -1.2426,\n",
      "         0.5897, -2.3740, -0.5176, -0.8828, -1.0942, -1.0459, -2.4438, -1.2127,\n",
      "        -1.0257, -1.3614,  0.0313,  0.0148, -1.8137, -0.8404, -1.2449, -1.4125,\n",
      "        -1.6006, -1.4844, -1.1448, -0.7885, -1.9801, -1.5000, -2.0352, -2.6304,\n",
      "        -0.3798, -1.4056, -0.1235, -1.1837, -0.2912, -1.4004, -1.5858, -1.4015,\n",
      "        -1.4552, -2.1804, -1.4158, -1.8128,  0.4114, -0.9810, -1.5364, -0.1168,\n",
      "        -0.2289, -0.3367, -0.7308, -1.0362, -1.3694, -1.6093, -2.7864, -1.6561,\n",
      "        -0.7370, -1.0912, -1.1045,  0.2515, -0.8671, -1.3696, -0.2789, -2.2239,\n",
      "        -1.6859, -0.1519, -0.8480, -0.4492, -1.3819, -0.1889, -1.2533, -1.3526,\n",
      "        -1.0249, -2.1959, -0.1260, -2.2029, -2.1430, -0.2255, -1.4275, -2.6303,\n",
      "        -0.9735, -0.8596, -1.5410,  0.2437,  0.8886,  0.0606, -0.9127, -0.2237,\n",
      "        -1.4392, -3.9663, -0.0760,  0.6224, -0.3309, -1.8122, -1.6522, -0.3390,\n",
      "        -1.3816, -1.5690, -0.6993, -1.0797, -1.2116, -1.3137, -0.0963, -1.2994,\n",
      "         0.7329, -1.1807, -0.7707,  0.4114, -0.4647, -0.0643,  0.5270,  0.1427],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.7674]],\n",
      "\n",
      "         [[-0.0057]],\n",
      "\n",
      "         [[-0.3480]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3465]],\n",
      "\n",
      "         [[-0.1784]],\n",
      "\n",
      "         [[ 0.0061]]],\n",
      "\n",
      "\n",
      "        [[[-0.1790]],\n",
      "\n",
      "         [[ 0.0400]],\n",
      "\n",
      "         [[ 0.2142]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1759]],\n",
      "\n",
      "         [[ 0.0894]],\n",
      "\n",
      "         [[ 0.2577]]],\n",
      "\n",
      "\n",
      "        [[[-0.2850]],\n",
      "\n",
      "         [[ 0.0499]],\n",
      "\n",
      "         [[ 0.0351]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0923]],\n",
      "\n",
      "         [[-0.0476]],\n",
      "\n",
      "         [[-0.1357]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6991]],\n",
      "\n",
      "         [[ 0.3553]],\n",
      "\n",
      "         [[ 0.5111]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1094]],\n",
      "\n",
      "         [[ 0.2952]],\n",
      "\n",
      "         [[ 0.2683]]],\n",
      "\n",
      "\n",
      "        [[[-0.4538]],\n",
      "\n",
      "         [[-0.2383]],\n",
      "\n",
      "         [[-0.2388]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0057]],\n",
      "\n",
      "         [[ 0.1172]],\n",
      "\n",
      "         [[ 0.1364]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3221]],\n",
      "\n",
      "         [[-0.3208]],\n",
      "\n",
      "         [[ 0.1801]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0735]],\n",
      "\n",
      "         [[-0.0652]],\n",
      "\n",
      "         [[-0.2491]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.2083,  0.1254, -0.0165,  0.3164,  0.0305,  0.0784,  0.1889,  0.1976,\n",
      "         0.2808,  0.3454,  0.2585,  0.0293], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2638]],\n",
      "\n",
      "         [[-0.2978]],\n",
      "\n",
      "         [[-0.3459]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5399]],\n",
      "\n",
      "         [[-0.0658]],\n",
      "\n",
      "         [[ 0.1199]]],\n",
      "\n",
      "\n",
      "        [[[-0.6338]],\n",
      "\n",
      "         [[ 0.5679]],\n",
      "\n",
      "         [[-0.3115]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1980]],\n",
      "\n",
      "         [[ 0.3817]],\n",
      "\n",
      "         [[ 0.0009]]],\n",
      "\n",
      "\n",
      "        [[[-0.3552]],\n",
      "\n",
      "         [[ 0.0224]],\n",
      "\n",
      "         [[ 0.3460]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0939]],\n",
      "\n",
      "         [[ 0.3188]],\n",
      "\n",
      "         [[ 0.4852]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0815]],\n",
      "\n",
      "         [[-0.2221]],\n",
      "\n",
      "         [[-0.1411]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1838]],\n",
      "\n",
      "         [[-0.0898]],\n",
      "\n",
      "         [[-0.0704]]],\n",
      "\n",
      "\n",
      "        [[[-0.1867]],\n",
      "\n",
      "         [[ 0.2158]],\n",
      "\n",
      "         [[-0.1269]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6381]],\n",
      "\n",
      "         [[ 0.1431]],\n",
      "\n",
      "         [[ 0.3148]]],\n",
      "\n",
      "\n",
      "        [[[-0.0433]],\n",
      "\n",
      "         [[ 0.2375]],\n",
      "\n",
      "         [[ 0.2896]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1738]],\n",
      "\n",
      "         [[ 0.2706]],\n",
      "\n",
      "         [[ 0.2103]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0940,  0.1954,  0.4828, -0.2806,  0.3780, -0.1258,  0.0143, -0.1366,\n",
      "        -0.0538,  0.1580,  0.0728, -0.0418,  0.1916,  0.3650,  0.1245, -0.0527,\n",
      "         0.2851, -0.4931,  0.2531, -0.3020,  0.1081,  0.2127, -0.3403,  0.1923,\n",
      "         0.1553,  0.0568,  0.5156, -0.3799,  0.3560,  0.1903, -0.3230, -0.2831,\n",
      "        -0.3278,  0.2111, -0.3119, -0.4170, -0.2418,  0.0025, -0.6734, -0.2821,\n",
      "         0.4980,  0.2122,  0.1129, -0.0968,  0.2869,  0.2184,  0.1096,  0.3487,\n",
      "        -0.0086, -0.0139, -0.0175, -0.1293,  0.1948, -0.3639, -0.4753, -0.1127,\n",
      "         0.0877,  0.5693,  0.0137,  0.3538, -0.2607, -0.1703, -0.2428, -0.4263,\n",
      "         0.0939,  0.0684,  0.3308, -0.1066,  0.2147,  0.1099,  0.3947, -1.1052,\n",
      "        -0.0615, -0.2636,  0.5527,  0.1653,  0.1390,  0.2998, -0.0012,  0.3315,\n",
      "         0.4707, -0.6215,  0.0705, -0.0237,  0.1511, -0.1078,  0.2737, -0.6217,\n",
      "        -0.4679, -0.5099,  0.2646, -0.0509, -0.1691, -0.0457,  0.2504, -0.4558,\n",
      "         0.3864, -0.3147,  0.3958,  0.0157, -0.1868, -0.2715,  0.3327, -0.2497,\n",
      "         0.0189,  0.0872, -0.2088, -0.7158,  0.3667,  0.2240,  0.1621,  0.2319,\n",
      "         0.0043, -0.1342,  0.1816, -0.2272,  0.0164, -0.1163, -0.1634, -0.0539,\n",
      "         0.2212,  0.5952, -0.3392,  0.4230, -0.1489,  0.2126,  0.1181,  0.0883,\n",
      "         0.0096, -0.0017,  0.3569,  0.1089, -0.0376, -0.0742,  0.1075,  0.1058,\n",
      "        -0.1035,  0.2633, -0.4568, -0.1451, -0.1167,  0.0854, -0.2227, -0.1372,\n",
      "        -0.4425, -0.2062,  0.7262,  0.1617, -0.5763, -0.0581, -0.1660, -0.0185,\n",
      "        -0.2675, -0.0412,  0.2935, -0.1381, -0.0780,  0.1054, -0.1733,  0.2182,\n",
      "        -0.1731,  0.0616, -0.2211,  0.2955,  0.1583, -0.4042, -0.2218, -0.1597,\n",
      "         0.3572,  0.1726,  0.1535, -0.1708,  0.0107,  0.1809,  0.6772, -0.1053,\n",
      "         0.4991,  0.2500, -0.3250,  0.0826,  0.0959,  0.3044,  0.1140, -0.1350,\n",
      "        -0.1538,  0.3019,  0.9752, -0.1309,  0.3683,  0.2622,  0.4353,  0.1116,\n",
      "         0.3971,  0.3711,  0.3042, -0.7430,  0.0987,  0.2606,  0.1598, -0.1377,\n",
      "         0.4321,  0.5016,  0.1928,  0.3507,  0.0277,  0.3770, -0.1035,  0.2019,\n",
      "        -0.2475, -0.0196, -0.5305,  0.0132, -0.1281, -0.0927, -0.5865, -0.0485,\n",
      "        -0.1873, -0.1774,  0.4482, -0.1550, -0.2595, -0.1348,  0.3324,  0.1903,\n",
      "        -0.0868, -0.1097,  0.0883,  0.2755, -0.0416,  0.1559,  0.4214,  0.0337,\n",
      "        -0.0278, -0.1706,  0.0836,  0.0326,  0.1961, -0.3782,  0.0064, -0.1261,\n",
      "         0.1227,  0.1692, -0.6122,  0.4344, -0.4134, -0.1501, -0.1990,  0.0965,\n",
      "        -0.3910,  0.0766, -0.1779,  0.0875, -0.0802, -0.1232, -0.0205,  0.0967,\n",
      "        -0.1532,  0.2067,  0.2004,  0.0751, -0.0097, -0.4063, -0.0288,  0.0212,\n",
      "         0.0333, -0.1561, -0.1183, -0.3912,  0.2082,  0.1357, -0.0639, -0.2325,\n",
      "        -0.2984,  0.3058, -0.1524,  0.1033,  0.5335, -0.1590,  0.1177,  0.5247,\n",
      "         0.5334, -0.0252,  0.4115,  0.6681,  0.0254, -0.1269,  0.3330,  0.5529],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1504]],\n",
      "\n",
      "         [[-0.4569]],\n",
      "\n",
      "         [[-0.6067]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4170]],\n",
      "\n",
      "         [[ 0.4757]],\n",
      "\n",
      "         [[-0.7776]]],\n",
      "\n",
      "\n",
      "        [[[-0.0244]],\n",
      "\n",
      "         [[-0.7108]],\n",
      "\n",
      "         [[-0.1241]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3050]],\n",
      "\n",
      "         [[-0.3415]],\n",
      "\n",
      "         [[-0.6365]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0198]],\n",
      "\n",
      "         [[-0.1737]],\n",
      "\n",
      "         [[ 0.4561]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3148]],\n",
      "\n",
      "         [[ 0.4062]],\n",
      "\n",
      "         [[ 0.2330]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1875]],\n",
      "\n",
      "         [[-0.4012]],\n",
      "\n",
      "         [[ 0.1447]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0171]],\n",
      "\n",
      "         [[ 0.4748]],\n",
      "\n",
      "         [[-0.4387]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1163]],\n",
      "\n",
      "         [[-0.2613]],\n",
      "\n",
      "         [[-0.3909]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0207]],\n",
      "\n",
      "         [[-0.3169]],\n",
      "\n",
      "         [[-0.0716]]],\n",
      "\n",
      "\n",
      "        [[[-0.1121]],\n",
      "\n",
      "         [[ 1.4109]],\n",
      "\n",
      "         [[ 0.1218]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3584]],\n",
      "\n",
      "         [[-0.5171]],\n",
      "\n",
      "         [[ 0.1999]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.4070, 0.5542, 2.5929, 1.0251, 3.7711, 0.8194, 1.7746, 1.2944, 0.7794,\n",
      "        0.5790, 0.7805, 1.1974, 1.0231, 1.4165, 0.6594, 1.1866, 2.0512, 4.0979,\n",
      "        0.6921, 0.4522, 0.7906, 1.9783, 1.8971, 2.8806, 0.8679, 0.5723, 0.7472,\n",
      "        1.1948, 0.4549, 0.6837, 0.8384, 0.8906, 1.0047, 2.2037, 1.0774, 1.5134,\n",
      "        0.5678, 1.0959, 1.5317, 0.6599, 0.7841, 0.8830, 1.6281, 0.7497, 0.3602,\n",
      "        0.9851, 0.9919, 0.3445], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.6621, -0.7941, -0.3971, -1.3426, -1.3986,  0.5462,  0.0472, -0.5122,\n",
      "         0.8504, -0.4526, -0.5037, -0.2979,  0.4813, -0.6058,  0.3107,  2.3012,\n",
      "        -0.1428, -0.8687,  0.4645, -0.2422,  0.8639,  0.5951,  0.7174,  0.9326,\n",
      "        -1.3867,  0.0824, -0.1635, -0.3863,  0.3261,  0.1589, -0.1809, -0.4431,\n",
      "         0.9901,  0.2891,  0.4701, -1.1247,  0.7352,  2.3886,  0.0322, -0.3265,\n",
      "         1.4501,  0.3604, -0.6229,  0.1240, -0.3359, -0.1326,  0.3792,  0.3134],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.3626]],\n",
      "\n",
      "         [[-0.0455]],\n",
      "\n",
      "         [[-0.0439]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0696]],\n",
      "\n",
      "         [[-0.0218]],\n",
      "\n",
      "         [[-0.4284]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2715]],\n",
      "\n",
      "         [[ 0.3661]],\n",
      "\n",
      "         [[ 0.2385]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0484]],\n",
      "\n",
      "         [[ 0.0434]],\n",
      "\n",
      "         [[ 0.0345]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4611]],\n",
      "\n",
      "         [[ 0.2597]],\n",
      "\n",
      "         [[ 0.3284]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5271]],\n",
      "\n",
      "         [[-0.0024]],\n",
      "\n",
      "         [[-0.0207]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2197]],\n",
      "\n",
      "         [[ 0.0750]],\n",
      "\n",
      "         [[ 0.1016]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5875]],\n",
      "\n",
      "         [[-0.4241]],\n",
      "\n",
      "         [[ 0.1895]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2435]],\n",
      "\n",
      "         [[-0.2559]],\n",
      "\n",
      "         [[ 0.3910]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4634]],\n",
      "\n",
      "         [[-0.0844]],\n",
      "\n",
      "         [[-0.3056]]],\n",
      "\n",
      "\n",
      "        [[[-0.2642]],\n",
      "\n",
      "         [[ 0.4127]],\n",
      "\n",
      "         [[-0.2568]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0891]],\n",
      "\n",
      "         [[ 0.6335]],\n",
      "\n",
      "         [[-0.2663]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.9426, 1.1288, 0.7906, 1.5116, 1.1182, 1.0330, 1.8211, 0.9048, 2.2942,\n",
      "        0.8562, 1.0278, 0.8097, 1.2260, 1.1926, 1.2886, 2.7173, 1.1447, 1.7878,\n",
      "        1.6406, 1.0687, 0.9342, 2.5157, 1.1314, 0.8437, 0.6519, 1.0113, 1.3987,\n",
      "        0.9097, 0.9096, 1.5589, 0.9311, 0.8326, 1.0820, 0.3372, 0.8239, 0.9553,\n",
      "        0.8627, 0.7879, 1.6298, 0.6940, 1.0881, 1.0556, 1.0908, 2.9320, 0.4882,\n",
      "        1.1177, 0.5134, 1.0130, 1.2521, 0.9466, 2.1165, 1.2548, 1.0653, 0.9268,\n",
      "        1.6861, 1.3029, 0.4881, 2.1206, 0.7099, 1.9047, 1.8816, 0.8500, 0.8669,\n",
      "        0.8216, 0.7750, 1.1965, 1.0269, 1.1235, 1.9865, 2.2208, 1.1552, 1.5660,\n",
      "        0.7678, 2.2058, 1.0647, 1.4547, 1.1565, 1.4251, 0.7187, 2.6613, 1.0265,\n",
      "        0.8034, 0.9169, 1.3811, 2.4962, 1.2064, 0.8342, 1.2480, 1.1275, 1.0666,\n",
      "        0.9084, 0.9614, 0.9616, 1.4525, 1.0474, 1.2578, 1.4325, 1.0158, 0.8930,\n",
      "        1.5823, 0.8088, 1.7640, 1.1183, 1.5565, 1.3966, 0.8038, 0.9276, 2.6236,\n",
      "        1.2596, 1.0996, 0.9148, 1.4758, 2.0150, 0.6162, 2.3676, 0.8725, 1.0334,\n",
      "        0.5764, 1.5370, 1.2904, 0.7823, 1.8543, 0.4874, 1.1795, 0.9721, 0.7532,\n",
      "        1.8583, 1.1801, 3.3998, 0.7975, 1.0973, 1.1421, 0.5638, 1.0288, 0.6864,\n",
      "        0.9023, 0.1178, 0.5762, 0.8508, 0.2102, 1.1708, 1.1263, 3.1887, 0.8497,\n",
      "        0.7407, 2.1541, 1.9099, 0.8876, 0.9841, 0.9622, 0.7468, 0.9480, 1.4232,\n",
      "        0.9701, 1.3636, 0.8263, 1.2350, 1.1190, 1.2282, 1.6233, 1.6183, 1.0446,\n",
      "        1.0713, 0.1355, 1.2590, 0.3478, 1.3004, 0.7835, 1.5697, 1.6988, 2.9640,\n",
      "        1.1605, 0.7079, 0.8637, 0.9563, 0.3715, 0.9178, 0.4627, 1.2217, 2.7006,\n",
      "        0.9012, 0.9408, 1.4560, 2.5345, 0.2965, 1.0449, 0.8697, 1.0673, 1.2008,\n",
      "        1.1190, 1.3515, 1.9527, 1.0522, 0.8275, 2.7372, 0.4506, 0.9611, 1.1559,\n",
      "        2.0263, 1.1826, 2.5164, 0.8890, 0.8753, 1.2716, 1.0138, 0.8489, 0.6170,\n",
      "        0.6719, 0.9153, 1.4418, 1.2072, 2.3881, 0.8173, 1.1901, 0.3774, 1.0837,\n",
      "        0.8456, 2.2723, 1.9912, 0.5252, 2.0957, 1.9073, 0.4797, 1.3553, 0.7447,\n",
      "        0.7505, 1.2547, 0.6078, 1.4281, 2.0026, 1.5022, 1.1442, 0.4153, 1.0873,\n",
      "        1.8561, 0.8705, 1.1857, 1.9802, 0.6567, 1.3043, 0.5826, 1.5209, 1.1982,\n",
      "        0.9598, 1.9818, 1.0955, 1.2574, 1.4361, 0.2365, 1.1467, 1.8355, 1.7303,\n",
      "        0.9708, 1.1643, 0.9366, 1.7852, 1.1725, 1.5970, 0.9206, 1.9648, 2.3219,\n",
      "        0.9014, 1.7101, 1.8482, 1.0840, 1.8449, 1.6696, 1.5254, 0.9006, 1.8522,\n",
      "        1.0651, 0.5115, 0.8862, 2.2563, 1.1877, 1.2165, 1.5250, 1.7960, 3.4398,\n",
      "        0.9467, 1.6615, 0.6576, 1.1640, 1.1134, 0.6543, 1.0575, 1.4480, 1.2045],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.1770e+00, -5.5982e-01, -9.0874e-01, -1.0423e+00, -1.4264e+00,\n",
      "        -1.1324e+00, -1.1039e+00, -1.6405e+00, -4.5936e-01, -1.7539e+00,\n",
      "        -1.8308e+00, -5.3341e-01, -1.3093e+00, -1.3164e+00, -9.0090e-01,\n",
      "        -1.2817e-01, -7.7093e-01, -8.9726e-01,  1.0116e+00, -6.7955e-01,\n",
      "        -5.9719e-01,  2.6173e-01, -1.5824e+00, -8.7126e-01, -1.8891e-01,\n",
      "        -1.6540e+00,  8.1180e-01, -1.7727e+00, -1.6626e+00,  7.1380e-01,\n",
      "        -1.1132e+00, -5.7279e-01, -1.4523e+00, -2.1312e-01,  3.1106e+00,\n",
      "        -3.2794e-01, -1.6190e+00,  1.1879e-01, -1.8295e+00,  9.4923e-02,\n",
      "         2.5667e+00, -7.0267e-01,  1.0556e+00, -4.1255e+00,  1.6258e-01,\n",
      "        -1.5363e+00, -8.0085e-02, -1.0198e+00, -1.4077e+00, -1.5988e+00,\n",
      "        -7.6688e-01,  1.4799e+00, -1.4794e+00, -1.2406e+00, -9.8456e-01,\n",
      "        -8.6323e-01,  2.0272e-01, -6.9217e-01, -2.0001e-01,  1.3243e+00,\n",
      "        -1.7183e-01, -7.7948e-01, -1.3860e-01, -1.4348e+00, -1.0751e+00,\n",
      "         2.0577e+00, -1.6951e+00, -1.7230e+00, -4.7136e-01, -4.1459e-01,\n",
      "        -1.3331e+00, -1.0470e+00, -1.6122e+00, -6.7638e-01, -6.8206e-01,\n",
      "        -1.1448e+00, -1.1853e+00, -1.3435e+00, -1.4543e+00, -3.4490e-01,\n",
      "        -6.8679e-01,  1.1449e+00, -3.3958e-02,  1.1141e+00, -6.1661e-01,\n",
      "        -5.4234e-01, -1.5851e+00, -2.1281e+00, -1.8794e+00, -1.2799e+00,\n",
      "        -1.3659e+00, -4.2424e-01, -4.5487e-01,  6.4387e-02,  2.2422e+00,\n",
      "        -5.8398e-01, -2.0783e+00, -1.6851e+00, -1.4057e+00, -7.0952e-01,\n",
      "        -1.4653e+00, -8.2095e-01, -1.4328e+00, -1.1797e+00, -1.0641e+00,\n",
      "        -1.1669e+00, -1.5032e+00, -5.7557e-01, -1.2111e+00, -1.1909e+00,\n",
      "        -8.6323e-01,  1.9087e+00,  3.4133e-01, -2.9497e-01,  1.3229e-01,\n",
      "        -1.8213e+00, -7.0557e-01, -8.6915e-01, -9.5271e-01, -9.9051e-01,\n",
      "        -1.3967e+00, -5.7892e-01,  5.0769e-01, -1.6825e+00, -1.7753e+00,\n",
      "        -1.6091e+00, -3.3728e-01, -4.2875e-01, -6.7973e-02,  1.7436e+00,\n",
      "        -1.2555e+00, -5.0457e-01,  3.8458e-01, -2.4624e+00,  2.3292e+00,\n",
      "        -1.7269e+00, -7.8505e-02,  4.2261e-01, -1.8300e+00,  4.4204e-02,\n",
      "        -1.7263e+00, -1.8409e+00, -4.7922e+00, -9.7286e-01, -2.1517e-01,\n",
      "        -6.7544e-02,  1.1566e+00, -1.4978e+00, -1.7444e+00, -1.6232e+00,\n",
      "         3.6120e-01,  8.4515e-01, -1.4652e+00, -1.4134e+00, -8.2917e-01,\n",
      "        -1.7524e+00, -9.2569e-01, -1.6735e+00, -2.3031e-01, -4.4853e-01,\n",
      "        -2.6235e-01,  1.8587e+00, -1.3746e+00, -5.0928e-02,  1.1160e-02,\n",
      "        -2.6858e-01, -1.3615e+00, -1.7532e+00, -8.6779e-01,  7.8534e-01,\n",
      "         4.9586e-02, -8.4661e-01, -1.8155e+00, -1.8387e+00, -1.4426e+00,\n",
      "        -4.7566e-01,  7.7709e-02, -1.7461e-01, -1.6195e+00,  3.4247e-01,\n",
      "        -1.2297e+00, -1.3519e+00, -7.8755e-01, -4.0803e-01,  4.9825e-02,\n",
      "        -1.5789e+00, -3.5678e-01, -3.8086e-01, -1.5499e+00, -2.0792e+00,\n",
      "        -5.6847e-01, -6.8575e-01, -8.7733e-01, -1.1207e+00,  1.1005e+00,\n",
      "         6.1534e-01, -1.4972e+00, -1.0537e+00, -1.3219e+00, -1.2311e+00,\n",
      "         1.7350e+00, -8.2319e-01, -8.3439e-01, -1.3571e+00, -8.1376e-02,\n",
      "         8.6454e-01,  2.9718e-01, -1.3082e+00, -1.8836e+00, -1.7557e+00,\n",
      "        -1.1023e+00,  4.0611e-02, -3.7585e-01, -1.1902e+00,  9.0205e-03,\n",
      "        -1.6881e+00, -9.3612e-01, -5.5598e-01, -4.8737e-01,  6.9248e-01,\n",
      "        -6.6934e-01, -1.0832e-01,  4.6388e-01,  1.2098e-01, -8.4394e-01,\n",
      "        -1.3835e+00, -1.8536e+00, -1.5768e+00,  1.2604e+00, -1.2700e+00,\n",
      "        -7.0932e-01, -1.6912e+00, -2.1524e-01, -1.2314e+00, -6.1397e-01,\n",
      "        -1.4332e+00, -1.3041e+00, -1.9611e+00, -5.4771e-01, -1.5332e+00,\n",
      "        -8.3746e-01, -2.5926e+00, -1.9213e+00, -1.7239e+00, -7.6216e-01,\n",
      "        -1.3209e+00, -7.4871e-01, -2.4080e-01, -1.0554e-01, -1.2763e+00,\n",
      "         1.6265e+00, -1.0944e+00, -1.3853e+00, -1.5222e+00, -1.5081e+00,\n",
      "        -7.8235e-01, -1.5764e+00, -7.9155e-01,  4.0184e-01,  7.7533e-01,\n",
      "         9.5576e-01, -1.6272e+00, -4.9254e-01, -5.6822e-01, -1.5360e+00,\n",
      "        -2.6062e+00,  1.7444e+00,  1.9482e+00, -1.4959e+00, -6.8691e-01,\n",
      "        -1.3445e+00,  1.0191e+00, -1.5495e+00,  5.2787e-01, -1.3409e+00,\n",
      "         5.7171e-01, -2.1454e-02, -8.5115e-01, -8.9430e-02, -1.3962e+00,\n",
      "        -7.1333e-01, -4.1757e-01, -8.1084e-01, -1.3682e+00,  2.4970e-03,\n",
      "        -1.3018e+00, -1.2063e+00, -1.6636e-01], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.4948,  0.5500,  0.2776],\n",
      "          [ 0.4019,  0.6099,  0.3393],\n",
      "          [ 0.5622,  0.2908, -0.0526]]],\n",
      "\n",
      "\n",
      "        [[[-0.4945, -0.6009,  0.1624],\n",
      "          [-0.4161,  0.3754,  0.2943],\n",
      "          [ 0.2833,  0.5131, -0.1375]]],\n",
      "\n",
      "\n",
      "        [[[-0.4537, -0.4947, -0.4438],\n",
      "          [ 0.0496,  0.0068,  0.6557],\n",
      "          [-0.1493,  0.4691,  0.0049]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1366,  0.6477,  0.2652],\n",
      "          [ 0.5972,  0.4003,  0.2432],\n",
      "          [ 0.0493,  0.4657,  0.2632]]],\n",
      "\n",
      "\n",
      "        [[[-0.1714, -0.3272, -0.2615],\n",
      "          [-0.6839, -0.4888, -0.3899],\n",
      "          [-0.1743, -0.2110, -0.3887]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6346, -0.0906, -0.0071],\n",
      "          [ 0.0264,  1.1191,  0.0373],\n",
      "          [-0.0961, -0.0132,  0.2929]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.9854,  1.4045,  1.2547,  1.4004,  1.4313,  1.7247,  2.1685,  0.8744,\n",
      "         1.8525,  1.2790,  1.1605,  1.7625,  1.5513,  1.2360,  1.3854,  1.8151,\n",
      "         1.7939,  1.2254,  2.6319,  1.2077,  1.7921,  2.0017,  0.9564,  1.8289,\n",
      "         0.9480,  1.2444,  1.6544,  1.2513,  1.7496,  1.7576,  1.1335,  1.3776,\n",
      "         1.1219,  1.8900,  2.3724,  1.9973,  1.4844,  1.4684,  0.7898,  1.7473,\n",
      "         1.5949,  1.2093,  1.6311,  1.2915,  1.6811,  1.4320,  2.0565,  1.0682,\n",
      "         1.8417,  1.0481,  1.7774,  1.9396,  0.8478,  1.5682,  2.0307,  1.3404,\n",
      "         1.0656,  2.0517,  2.3051,  1.6452,  1.8800,  1.5539,  1.5247,  0.9853,\n",
      "         1.6679,  2.2522,  1.0219,  1.1719,  2.1190,  4.0134,  1.5347,  2.4451,\n",
      "         1.5808,  1.0278,  0.8606,  2.3217,  1.6358,  1.8901,  1.6290,  1.9006,\n",
      "         1.6774,  2.3719,  2.1223,  2.5560,  3.6066,  1.2980,  1.3019,  1.1882,\n",
      "         1.1808,  1.0914,  1.5085,  1.2818,  1.5423,  2.0345,  1.8122,  1.8428,\n",
      "         1.6336,  1.1390,  0.8949,  1.2922,  1.1027,  1.1723,  1.1042,  1.2176,\n",
      "         1.4164,  1.2252,  1.4907,  2.1737,  1.2774,  1.0574,  1.6456,  0.9157,\n",
      "         0.8793,  1.4849,  1.6726,  0.7484,  1.5708,  1.6527,  1.8989,  1.0861,\n",
      "         1.1233,  1.6482,  1.8773,  0.6352,  1.4041,  0.5808,  1.5650,  0.9020,\n",
      "         3.5912,  2.7820,  1.8387,  1.8725,  2.0728,  1.2960,  1.9548,  1.0285,\n",
      "         2.2575,  1.9697,  1.1800,  2.0596,  1.2105,  1.1461,  3.1745,  1.1091,\n",
      "         1.4340,  1.6791,  0.7630,  0.7081,  1.6869,  1.3770,  1.7786,  1.7181,\n",
      "         0.8599,  1.0276,  0.6572,  1.4245,  1.5674,  1.0273,  1.1744,  1.5494,\n",
      "         1.5280,  2.2912,  1.5242,  1.7186,  0.7531,  1.4298,  1.6311,  1.8707,\n",
      "         1.9625,  1.2681,  1.6353,  1.6038,  0.9103,  1.0483,  1.4322,  1.8319,\n",
      "         1.8058,  1.8079,  1.2098,  2.6244,  1.3050,  1.0406,  0.6853,  1.4476,\n",
      "         2.0018,  0.8069,  1.6862,  1.3765,  1.3837,  1.5123,  1.3962,  1.9713,\n",
      "         1.8259,  1.2472,  1.8171,  1.9350,  0.9704,  1.3773,  2.2608,  1.2131,\n",
      "         3.1165,  0.9560,  1.7448,  0.9163,  1.7921,  1.5813,  1.7213,  0.6003,\n",
      "         0.9451,  2.1535,  1.1129,  1.9753,  1.5732,  1.3053,  2.0876,  1.4921,\n",
      "         1.2628,  1.8472,  1.0608,  1.3813,  1.4987,  1.6900,  2.3094,  1.8343,\n",
      "         1.4099,  1.1445,  1.3681,  1.3855,  1.6969,  2.6270,  1.1098,  0.9514,\n",
      "         1.6932,  1.6097,  2.4121,  0.7553,  1.1168,  1.5463,  1.5586,  1.6677,\n",
      "         1.5670,  0.7372,  1.3912,  1.2608,  2.3533,  1.4155,  1.8776,  1.3371,\n",
      "         1.0098,  0.9533,  2.0082,  1.6843,  1.3301,  0.6897,  1.3642,  2.2219,\n",
      "         0.8907,  1.4209,  2.0630,  1.3714,  2.1996,  1.2180,  1.3496,  0.7892,\n",
      "         1.4868, -1.2097,  1.2812,  0.9191,  1.0862,  1.7168,  0.9681,  1.2035,\n",
      "         1.2356,  1.5480,  1.1857,  1.8297,  3.0098,  1.8991,  2.0523,  1.1865,\n",
      "         1.8349,  1.0289,  1.4874,  1.7504,  1.8994,  1.5243,  1.9089,  0.9802],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.4436,  0.1673,  0.7587,  1.1061,  1.7199,  3.0656,  1.5211,  1.7789,\n",
      "         0.5780,  0.2505,  1.7291, -0.8216,  2.8270,  2.2352,  2.7497, -0.8049,\n",
      "         1.5989,  1.4844, -0.7673,  3.4663,  3.2986,  0.5401,  1.7854,  2.8965,\n",
      "         3.5109,  1.9081, -1.3125,  2.3621,  1.8165, -1.5166,  2.7944, -0.0994,\n",
      "         2.8817, -0.4787, -0.0895, -0.6534,  1.9746,  4.3817,  1.4679, -0.4967,\n",
      "        -1.1238,  3.1114, -0.0475, -1.8936, -1.4729,  2.4866, -0.9854,  1.5088,\n",
      "         2.3529,  2.2219,  2.4386, -1.2149,  2.6863, -0.3277,  2.6856, -0.4283,\n",
      "         1.1940,  1.7608, -1.3064,  3.4545, -0.1242, -0.7190, -0.7406,  3.1289,\n",
      "         3.0171, -0.6933,  2.0744,  2.1745,  0.2079, -1.6282,  2.1554,  0.5200,\n",
      "         3.1051,  1.5109,  2.9081,  1.7992,  2.8825,  2.5943,  2.2005,  0.4959,\n",
      "        -1.1234, -0.9225, -0.7630, -1.8120, -1.1197,  3.0738,  2.4456,  1.9377,\n",
      "         1.5868,  1.3308,  0.6693,  2.5031, -0.3691, -0.4063, -1.4082,  2.6792,\n",
      "         2.3885,  2.4006,  1.5862,  2.3412,  2.4648,  1.9362,  1.6442,  2.8453,\n",
      "         1.5692,  2.5993,  0.6924,  0.0850,  2.4670,  2.8310,  0.6048,  0.6085,\n",
      "         2.7430, -1.3714,  0.4291, -0.1922, -2.1481, -2.0852,  1.2498,  1.5014,\n",
      "         0.0131,  3.9774, -0.7546,  2.4379,  1.8628,  0.9683,  2.1818,  3.4978,\n",
      "        -0.9567, -1.6910,  2.5701, -0.2896, -0.7441,  1.5606, -0.8739,  2.1422,\n",
      "        -1.0092, -2.3506,  2.1095, -0.9835,  2.4313,  1.4278, -3.4449,  1.7220,\n",
      "        -1.3044,  0.9665,  1.8744,  0.8822,  2.1932,  2.4080, -0.8882, -0.9443,\n",
      "         1.8373,  2.4765,  3.1345,  3.1006,  2.7678,  1.9437,  1.8437,  2.6646,\n",
      "         1.7425, -0.6757,  2.5101, -1.0490,  3.1698,  2.6889,  1.0023,  2.0870,\n",
      "         1.2600,  0.5900,  0.5832, -0.0970,  1.6142,  1.1151,  1.2074, -1.4865,\n",
      "        -0.8964, -1.8909,  1.8723,  1.0418,  3.5818,  2.3639,  1.5745,  1.8174,\n",
      "        -1.0654,  2.0477, -1.0327,  3.9698,  1.8206,  2.2808,  2.7546,  0.6073,\n",
      "         0.2590,  2.4804,  0.0943, -2.1544,  2.7027,  2.2198,  1.2531,  2.5742,\n",
      "        -1.3939, -0.0182,  2.8048,  2.4997,  3.8551, -1.0105, -0.7867,  2.1859,\n",
      "         1.9836,  2.9719,  1.7532,  0.5467,  4.0572,  2.3044, -1.1646,  0.8334,\n",
      "         3.2400,  0.7514,  3.8289, -1.0676,  1.0235, -0.3900, -2.0568, -1.0772,\n",
      "        -1.5544, -0.5316,  1.4800,  2.6468, -1.2780,  0.6558,  3.9566,  2.0684,\n",
      "        -0.7666,  2.4154,  0.8336,  1.4742,  1.9709,  2.1537, -0.7671,  1.5391,\n",
      "        -1.0581, -1.5256,  1.7736,  2.3927,  0.4920,  2.0019,  2.0680,  3.0015,\n",
      "         1.0815,  3.1278, -1.1876,  1.7874,  0.5336,  0.4944,  2.1500,  2.2556,\n",
      "         2.2150,  3.0478, -0.5083,  1.8082,  1.0126,  2.9405,  2.4550,  3.3588,\n",
      "         2.7020, -2.5546,  2.3290,  2.5034,  2.5753,  2.7747,  2.1047, -0.5094,\n",
      "         0.8119, -0.1529,  3.1627, -0.6295, -0.5310,  0.7458,  3.0298, -0.0800,\n",
      "         1.3855, -1.2884, -0.1548,  3.2364, -0.1185,  2.4834,  2.2808,  3.8963],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0995]],\n",
      "\n",
      "         [[ 0.0357]],\n",
      "\n",
      "         [[-0.0176]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0195]],\n",
      "\n",
      "         [[-0.0184]],\n",
      "\n",
      "         [[ 0.0262]]],\n",
      "\n",
      "\n",
      "        [[[-0.0201]],\n",
      "\n",
      "         [[-0.1063]],\n",
      "\n",
      "         [[-0.0484]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0289]],\n",
      "\n",
      "         [[ 0.0126]],\n",
      "\n",
      "         [[-0.0184]]],\n",
      "\n",
      "\n",
      "        [[[-0.0635]],\n",
      "\n",
      "         [[-0.0156]],\n",
      "\n",
      "         [[-0.0582]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0399]],\n",
      "\n",
      "         [[-0.0131]],\n",
      "\n",
      "         [[-0.0972]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1098]],\n",
      "\n",
      "         [[-0.0573]],\n",
      "\n",
      "         [[-0.0835]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0660]],\n",
      "\n",
      "         [[-0.0586]],\n",
      "\n",
      "         [[-0.1212]]],\n",
      "\n",
      "\n",
      "        [[[-0.0317]],\n",
      "\n",
      "         [[-0.0142]],\n",
      "\n",
      "         [[-0.0408]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0385]],\n",
      "\n",
      "         [[-0.0654]],\n",
      "\n",
      "         [[ 0.0065]]],\n",
      "\n",
      "\n",
      "        [[[-0.0819]],\n",
      "\n",
      "         [[-0.0390]],\n",
      "\n",
      "         [[-0.0681]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0709]],\n",
      "\n",
      "         [[-0.0289]],\n",
      "\n",
      "         [[-0.1703]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0448, -0.0316, -0.0640, -0.0542, -0.0810, -0.0784, -0.0527, -0.0579,\n",
      "        -0.0772, -0.0647, -0.0489, -0.0566], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-1.8379e-01]],\n",
      "\n",
      "         [[ 1.9231e-02]],\n",
      "\n",
      "         [[-1.6530e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7721e-01]],\n",
      "\n",
      "         [[-6.7502e-02]],\n",
      "\n",
      "         [[-1.0337e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2788e-01]],\n",
      "\n",
      "         [[-7.2407e-02]],\n",
      "\n",
      "         [[ 3.9324e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0900e-01]],\n",
      "\n",
      "         [[ 7.3327e-03]],\n",
      "\n",
      "         [[ 1.3766e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2336e-02]],\n",
      "\n",
      "         [[ 1.2556e-01]],\n",
      "\n",
      "         [[-6.1333e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7207e-02]],\n",
      "\n",
      "         [[ 9.0237e-02]],\n",
      "\n",
      "         [[-2.7513e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-8.1034e-02]],\n",
      "\n",
      "         [[-6.1644e-02]],\n",
      "\n",
      "         [[-4.9292e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.0369e-02]],\n",
      "\n",
      "         [[ 4.3128e-02]],\n",
      "\n",
      "         [[-1.0504e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.6893e-02]],\n",
      "\n",
      "         [[ 1.0257e-01]],\n",
      "\n",
      "         [[-3.6991e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.6844e-02]],\n",
      "\n",
      "         [[-4.9073e-02]],\n",
      "\n",
      "         [[-1.2417e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.8613e-02]],\n",
      "\n",
      "         [[-2.9957e-01]],\n",
      "\n",
      "         [[-2.3711e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9674e-01]],\n",
      "\n",
      "         [[-2.9362e-01]],\n",
      "\n",
      "         [[-2.6349e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.4682, -0.0700,  0.0594, -0.3093,  0.1012,  0.3094,  0.6001, -0.1508,\n",
      "         0.0498,  0.1923,  0.1276,  0.1615,  0.2528,  0.1086,  0.0578, -0.6727,\n",
      "         0.6065, -0.0530,  0.1223, -0.3496, -0.0935,  0.0479, -0.0713,  0.1789,\n",
      "         0.0701,  0.0137,  0.0191,  0.0655,  0.0587, -0.0468, -0.2017, -0.1371,\n",
      "        -0.2049,  0.1505,  0.0648,  0.3677,  0.2303,  0.4857, -0.1981, -0.0237,\n",
      "        -0.2847, -0.2466, -0.4127, -0.4614, -0.0266, -0.0432,  0.2648, -0.1577,\n",
      "         0.7870, -0.2172,  0.6357,  0.0260, -0.3272, -0.3012,  0.9234, -0.3711,\n",
      "        -0.1679,  0.5743,  0.4126,  0.3860, -0.1289, -0.0430, -0.1469, -0.2957,\n",
      "         0.0675,  0.3903, -0.0605,  0.0334, -0.1871, -0.0916,  0.1774,  0.7335,\n",
      "         0.0452, -0.0485,  0.0773,  0.3321, -0.0239,  0.3059,  0.3895,  0.0403,\n",
      "         0.0261,  0.1346,  0.1328,  0.0551, -0.0640, -0.3500,  0.0168,  0.2366,\n",
      "         0.0516, -0.0716,  0.1973,  0.0713, -0.0904,  0.0942,  0.2231,  0.1112,\n",
      "         0.1630, -0.1024, -0.1905,  0.2624, -0.2487, -0.2361, -0.0348, -0.1632,\n",
      "         0.0830, -0.0957,  0.2191,  0.1329, -0.0289, -0.4901,  0.2076, -0.4560,\n",
      "        -0.1999, -0.1583,  0.1202, -0.3821,  0.0486, -0.0530,  0.7909,  0.0551,\n",
      "         0.0029, -0.0963, -0.1199, -0.4710,  0.0586, -0.4498,  0.6076,  0.1237,\n",
      "         0.0968,  0.3196,  0.4005, -0.1373, -0.1891,  0.2509, -0.0881, -0.2354,\n",
      "         0.1690,  0.4887, -0.0506,  0.1603, -0.0344,  0.0366, -0.6164, -0.0357,\n",
      "         0.0703,  0.3243, -0.3011, -0.4270,  0.2599,  0.1340, -0.3586,  0.1252,\n",
      "        -0.1876, -0.1602, -0.7115, -0.0859,  0.1756, -0.1592,  0.0398,  0.0284,\n",
      "         0.2332,  0.1050,  0.0675, -0.2216, -0.3509,  0.2174,  0.1498,  0.2500,\n",
      "         0.8169, -0.3147, -0.0951, -0.1734, -0.2997, -0.1880,  0.0300, -0.0806,\n",
      "        -0.1899,  0.0448,  0.1803,  0.5905, -0.1869, -0.1971, -0.6247,  0.0858,\n",
      "        -0.0557, -0.3262,  0.0963, -0.4481, -0.0531,  0.0714, -0.1045,  0.4375,\n",
      "         0.0658, -0.1244,  0.2531, -0.3478, -0.1868,  0.0487,  0.4668, -0.1186,\n",
      "         0.0874, -0.2858,  0.0898, -0.5202,  0.5126, -0.6877, -0.1054, -0.6674,\n",
      "        -0.2017,  0.7450, -0.0322,  0.1017,  0.4076,  0.0989, -0.0054,  0.0816,\n",
      "        -0.0544,  0.1547,  0.1595, -0.0320,  0.1425,  0.0303,  0.3805,  0.2330,\n",
      "        -0.1805, -0.2193,  0.0845, -0.1348, -0.1023,  0.1449, -0.5710, -0.1764,\n",
      "        -0.0892,  0.0953,  0.7309, -0.4748, -0.1570, -0.3448, -0.0060,  0.2640,\n",
      "        -0.1362, -0.0472,  0.2048, -0.1186,  0.2237,  0.2433,  0.2901, -0.1620,\n",
      "        -0.0723, -0.2678, -0.0017,  0.9702,  0.1838, -0.4410, -0.0280,  0.7504,\n",
      "        -0.1775,  0.0187,  0.1166,  0.1556,  0.7857, -0.1311,  0.5015,  0.0244,\n",
      "         0.0192,  0.1627,  0.0755,  0.0074, -0.2426,  0.1697, -0.1936, -0.4894,\n",
      "         0.0473, -0.2583, -0.0952,  0.0053, -0.0385, -0.0107,  0.4030, -0.1118,\n",
      "         0.4114, -0.2285,  0.0878, -0.6879,  0.0308,  0.1490,  0.7771, -0.6248],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 1.3345]],\n",
      "\n",
      "         [[-0.3434]],\n",
      "\n",
      "         [[ 0.1008]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2081]],\n",
      "\n",
      "         [[-0.1448]],\n",
      "\n",
      "         [[ 0.1795]]],\n",
      "\n",
      "\n",
      "        [[[-0.5461]],\n",
      "\n",
      "         [[ 0.1341]],\n",
      "\n",
      "         [[-0.7950]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1528]],\n",
      "\n",
      "         [[-0.0431]],\n",
      "\n",
      "         [[ 0.0679]]],\n",
      "\n",
      "\n",
      "        [[[-0.6600]],\n",
      "\n",
      "         [[ 0.1217]],\n",
      "\n",
      "         [[ 0.0066]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2996]],\n",
      "\n",
      "         [[-0.8740]],\n",
      "\n",
      "         [[ 0.5876]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6145]],\n",
      "\n",
      "         [[-0.1716]],\n",
      "\n",
      "         [[ 0.0088]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1607]],\n",
      "\n",
      "         [[ 0.3877]],\n",
      "\n",
      "         [[ 0.4778]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1518]],\n",
      "\n",
      "         [[ 0.2974]],\n",
      "\n",
      "         [[ 0.5805]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3616]],\n",
      "\n",
      "         [[ 0.1407]],\n",
      "\n",
      "         [[ 0.0513]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1108]],\n",
      "\n",
      "         [[-0.9729]],\n",
      "\n",
      "         [[-0.0637]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1246]],\n",
      "\n",
      "         [[ 0.1817]],\n",
      "\n",
      "         [[ 0.5903]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 8.2082,  5.0158,  6.1712,  5.5914,  5.6623,  5.4616,  4.8982,  5.5408,\n",
      "         2.4802,  7.0251,  3.6941,  6.2384,  7.6783,  2.8090,  3.8849,  4.8444,\n",
      "         4.0770,  7.9062,  3.7235,  2.2361,  4.6119,  3.2988,  5.4568,  4.5822,\n",
      "         4.3961,  3.8512,  4.2980,  5.2044,  9.1100,  3.9075,  5.7659,  4.1330,\n",
      "         4.0828,  6.7179,  5.6430,  4.2764,  2.1519,  5.7528,  3.6164,  3.3348,\n",
      "         4.0458,  4.8476,  6.8573,  3.9847,  8.8003,  5.3321,  4.6474, 10.5468,\n",
      "         9.1517,  4.9746,  6.1990,  6.7320,  4.4828,  3.3764,  8.9818,  9.4183,\n",
      "         4.8871,  9.8403,  5.4472,  3.7254,  6.2902,  4.0922,  3.6904,  7.6575,\n",
      "         3.4689,  5.1737,  4.3474,  4.8402,  2.8616,  6.3668,  9.0966,  6.1971,\n",
      "         4.8575,  5.1721,  4.8895,  4.3599,  4.7241,  4.4877,  4.8520,  4.3478,\n",
      "         5.6411,  3.3902,  2.7324,  4.9138,  2.8538,  3.0092,  8.3781,  7.6624,\n",
      "         4.7848,  5.0438,  5.6773,  6.3032,  8.5048,  8.7169,  3.9466,  8.0806],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-9.5109e-03,  1.2767e-02, -1.0688e-02,  8.6861e-03, -5.3866e-03,\n",
      "        -2.0219e-02,  2.5198e-03,  1.4225e-02, -3.5198e-03,  8.1910e-05,\n",
      "         2.0679e-03, -4.1250e-03, -1.0478e-02,  2.3081e-04, -1.9946e-03,\n",
      "         1.0087e-02, -1.1054e-02, -1.6663e-02,  6.3408e-03, -1.5711e-03,\n",
      "         6.9466e-03,  1.1453e-02, -2.8221e-03,  2.5794e-03, -4.7045e-03,\n",
      "        -4.0384e-03,  2.7162e-03,  1.3166e-03, -1.9332e-02, -1.8390e-02,\n",
      "        -2.9693e-03,  4.5639e-03,  6.6668e-03,  2.4813e-02,  1.2900e-02,\n",
      "        -8.4401e-03,  2.4236e-03, -1.6913e-02, -1.3106e-02, -1.1093e-03,\n",
      "        -1.8055e-02, -1.2594e-02,  1.0258e-02,  1.1581e-02,  6.6427e-04,\n",
      "         1.7135e-03, -7.9652e-03, -1.1935e-02, -1.0318e-02, -5.3437e-03,\n",
      "         2.1237e-02,  8.3591e-03, -1.2515e-02, -1.9385e-02, -3.1848e-02,\n",
      "        -1.8752e-04,  4.7803e-03, -5.3541e-03, -1.2796e-02,  1.8622e-02,\n",
      "         1.3626e-03,  3.2544e-04,  2.4118e-03, -1.5104e-02, -3.8640e-03,\n",
      "        -9.4225e-04, -2.5901e-03, -1.1027e-02,  5.0710e-03, -2.7282e-03,\n",
      "         8.7060e-03, -3.1034e-03,  6.8195e-05, -5.9488e-03, -1.8171e-03,\n",
      "         6.5522e-03, -8.3054e-03, -8.5229e-03,  2.2410e-03, -1.6788e-02,\n",
      "        -1.1699e-02,  5.8270e-03,  5.3950e-03, -1.0332e-02,  1.3022e-03,\n",
      "         4.5331e-03, -7.4547e-03, -1.3035e-02, -2.2717e-03,  4.6849e-03,\n",
      "         3.5376e-03, -1.0772e-02, -5.0111e-03, -1.4937e-02,  1.3406e-03,\n",
      "        -1.3020e-02], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.4127]],\n",
      "\n",
      "         [[-0.2562]],\n",
      "\n",
      "         [[-0.0273]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1760]],\n",
      "\n",
      "         [[-0.2517]],\n",
      "\n",
      "         [[ 0.2611]]],\n",
      "\n",
      "\n",
      "        [[[-0.4124]],\n",
      "\n",
      "         [[ 0.1539]],\n",
      "\n",
      "         [[-0.1693]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4089]],\n",
      "\n",
      "         [[-0.0618]],\n",
      "\n",
      "         [[ 0.2106]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1468]],\n",
      "\n",
      "         [[ 0.4207]],\n",
      "\n",
      "         [[ 0.3519]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2285]],\n",
      "\n",
      "         [[-0.3573]],\n",
      "\n",
      "         [[ 0.2977]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.7070]],\n",
      "\n",
      "         [[-0.3847]],\n",
      "\n",
      "         [[-0.3351]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1210]],\n",
      "\n",
      "         [[ 0.0017]],\n",
      "\n",
      "         [[ 0.1929]]],\n",
      "\n",
      "\n",
      "        [[[-0.4729]],\n",
      "\n",
      "         [[ 0.0294]],\n",
      "\n",
      "         [[-0.0925]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6018]],\n",
      "\n",
      "         [[ 0.1458]],\n",
      "\n",
      "         [[ 0.3307]]],\n",
      "\n",
      "\n",
      "        [[[-0.0805]],\n",
      "\n",
      "         [[ 0.4666]],\n",
      "\n",
      "         [[ 0.5248]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3191]],\n",
      "\n",
      "         [[ 0.4273]],\n",
      "\n",
      "         [[ 0.0085]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.6667,  0.2856,  0.0833,  0.8173,  1.1268,  1.8282,  1.4813,  1.5873,\n",
      "         0.3888,  0.5430,  0.1667,  1.0975,  0.8535,  2.0525,  1.4920,  2.2828,\n",
      "         2.2006,  0.5679,  0.9274,  1.2038,  0.5904,  1.6710,  0.8813,  0.8794,\n",
      "         0.2813,  0.6953,  0.2707,  1.0350,  0.5875,  0.5101,  1.1739,  0.2102,\n",
      "         1.8631,  1.3438,  0.7407,  0.4108,  0.8008,  2.0473,  0.7175,  0.5840,\n",
      "         0.0409,  1.2634,  0.5846,  0.3493,  0.7426,  0.5340,  0.7625,  1.0356,\n",
      "         0.6350,  0.4113,  0.7925,  2.2745,  1.7091,  0.4711,  1.3747,  0.8017,\n",
      "         1.9024,  1.1728,  0.9258,  1.7821,  0.5963,  0.8745,  2.2025,  0.8178,\n",
      "         0.6241,  1.2762,  0.4900,  0.3897,  1.3958,  1.0022,  0.3358,  1.9812,\n",
      "         0.4113,  1.7829,  0.3198,  0.1251,  0.2493,  0.2691,  1.4475,  0.1635,\n",
      "         1.0872,  0.8602,  1.0405,  1.1226,  1.2290,  1.0436,  0.9470,  1.7823,\n",
      "         0.4609,  0.4688,  1.6667,  1.5466,  0.3355,  0.5332,  0.6711,  0.9887,\n",
      "         1.2030,  0.1655,  2.1171,  0.7293,  0.7300,  0.5480,  0.5142, -0.0738,\n",
      "         1.6697,  0.6985,  0.4864,  1.3051,  0.7673,  0.0607,  0.6876,  1.1738,\n",
      "         1.0018,  1.1451,  1.6328,  1.1440,  0.9895,  1.0464,  0.9008,  0.4467,\n",
      "         1.3413,  0.6816,  1.1055,  1.0425,  1.1540,  0.6212,  2.2057,  0.9239,\n",
      "         2.0383,  0.9367,  0.6303,  2.5305,  1.6698,  0.6401,  0.9872,  1.7496,\n",
      "         1.5692,  0.7342,  1.4712,  1.4995,  0.6561,  0.3097,  1.1031,  0.5860,\n",
      "         0.3737,  0.3450,  1.1912,  0.9963,  1.0203,  1.4212,  0.1958,  1.7637,\n",
      "         0.4832,  1.5288,  0.9855,  1.2628,  0.7553,  2.1428,  1.2270,  1.5518,\n",
      "         2.5703,  2.3544,  0.9439,  1.4579,  1.0104,  0.4245,  1.2956,  0.6552,\n",
      "         0.9658,  1.8944,  0.5686,  0.7098,  1.5024,  0.4050,  1.3235,  1.0680,\n",
      "         1.5241,  0.8918,  0.5071,  1.1979,  0.7942,  1.6545,  0.4380,  1.6601,\n",
      "         2.2015,  0.9042,  1.3682,  0.7969,  0.8948,  1.0294,  0.9500,  1.4343,\n",
      "         1.9445,  1.2927,  0.4712,  0.9663,  1.2964,  1.4398,  1.2580,  0.4283,\n",
      "         1.3759,  1.7222,  1.2455,  0.8824,  1.3333,  0.8500,  0.9940,  0.9747,\n",
      "         1.3481,  0.2839,  1.4742,  0.1581,  0.7893,  1.2733,  0.5595,  1.1767,\n",
      "         0.4832,  1.4025,  1.3366,  1.2290,  1.9842,  1.5098,  1.5839,  0.0935,\n",
      "         0.7393,  1.4420,  1.4865,  1.0075,  0.5539,  0.6869,  0.9606,  0.7991,\n",
      "         1.7744,  1.3402,  1.1600,  1.0124,  1.2801,  0.8686,  0.4779,  0.8565,\n",
      "         1.4519,  1.1790,  1.9951,  1.1738,  1.4915,  0.5874,  0.8624,  1.0322,\n",
      "         0.5876,  1.0270,  1.0877,  1.0667,  0.5095,  0.4366,  0.8147,  1.3162,\n",
      "         0.2381,  1.7049,  0.6970,  0.2726,  0.6237,  0.8371,  1.0938,  1.4643,\n",
      "         0.3682,  0.4405,  0.7695,  0.9277,  0.8595,  0.3440,  0.4430,  1.7972,\n",
      "         1.6245,  1.5856,  1.1037,  1.0881,  0.4001,  0.3829,  0.0612,  1.0170,\n",
      "         0.9321,  1.3985,  1.4733,  0.3501,  0.7050,  0.6604,  0.8935,  0.5498,\n",
      "         0.2716,  0.5659,  1.4928,  0.3040,  0.6397,  1.0083,  2.1929,  0.8075,\n",
      "         1.4865,  0.8661,  1.1322,  1.1223,  0.7462,  1.2473,  1.0926,  1.1172,\n",
      "         1.1198,  0.7226,  1.7799,  0.8462,  1.9191,  0.4976,  1.2640,  0.6669,\n",
      "         1.8369,  1.1945,  0.3193,  0.5931,  0.8890,  1.3448,  0.7981,  1.4295,\n",
      "         0.6780,  0.0231,  0.5816,  1.5745,  0.4756,  1.4614,  1.8633,  1.2186,\n",
      "         1.8030,  1.1859,  0.8382,  1.3551,  1.1847,  0.4549,  0.7527,  1.7531,\n",
      "         0.4888,  1.0183,  1.7488,  0.9184,  1.8758,  0.7727,  0.7667,  0.4692,\n",
      "        -0.0441,  0.8379,  0.9910,  1.5545,  0.2914,  1.0476,  2.1951,  0.8764,\n",
      "         1.0151,  1.1969,  2.0528,  0.4899,  1.0021,  1.3561,  0.8976,  0.8994,\n",
      "         2.1723,  0.6434,  0.2259,  1.2662,  0.5666,  0.5330,  1.8710,  0.2920,\n",
      "         0.7210,  0.4230,  0.3779,  0.9167,  1.4927,  0.9048,  1.5151,  0.6271,\n",
      "         0.2508,  0.6004,  1.0663,  0.9696,  1.9006,  1.3548,  0.3434,  1.1941,\n",
      "         1.3619,  1.5666,  1.8876,  1.5050,  1.0955,  0.9808,  0.3965,  1.5791,\n",
      "         0.5630,  0.5795,  0.9924,  1.4993,  0.2117,  1.4948,  1.4359,  0.8737,\n",
      "         2.0576,  0.9021,  1.1037,  2.3343,  0.3880,  1.7635,  2.6167,  1.0360,\n",
      "        -0.1048,  2.1871,  1.3307, -0.2159,  1.1413,  1.2486,  2.1569,  1.6437,\n",
      "         1.3164,  1.4514,  0.6513,  1.9568,  1.5974,  0.0044,  1.1997,  0.6369,\n",
      "         1.4530,  0.5784,  1.4360,  0.7833,  0.7217,  0.5991,  1.4992,  1.0496,\n",
      "         1.4562,  1.2996,  1.1830,  0.5346,  0.9412,  0.5058,  0.4009,  0.8761,\n",
      "         1.2587,  1.3350,  1.2911,  1.0057,  0.3734,  0.9595,  1.5624,  0.5511,\n",
      "         2.0313,  0.9460,  0.7648,  0.9598,  0.4550,  0.7501,  0.2859,  1.0516,\n",
      "         1.2246,  0.4485,  1.9278,  1.0870,  1.0671,  1.0564,  0.4727,  1.4072,\n",
      "         1.1573,  0.8299,  1.0917,  1.1665,  1.8730,  0.8353,  0.5416,  1.4887,\n",
      "         0.5290,  0.7886,  0.9595,  1.0356,  0.8315,  0.3123,  0.6593,  2.0134,\n",
      "         1.2416,  0.8889,  0.4180,  0.6777,  1.9304,  0.6726,  0.8265,  0.8503,\n",
      "         1.5758, -0.1414,  0.4417,  0.6724,  0.6697,  0.2943,  0.7534,  1.2958,\n",
      "         0.6293,  0.2263,  0.5965,  2.0455,  0.8329,  0.7945,  2.5386,  1.8798,\n",
      "         0.7847,  0.9139,  1.3803,  0.7484,  1.1049,  0.2373,  2.6207,  1.9323,\n",
      "         1.3773,  1.0702,  0.7157,  1.8053,  1.4557,  1.2177,  0.3943,  0.4926,\n",
      "         1.9689,  1.4492,  1.8532,  0.8425,  1.5975,  0.2453,  1.0778,  1.2506,\n",
      "         1.8979,  0.9791,  1.6575,  0.0310,  0.4267,  1.6935,  2.0024,  1.7316,\n",
      "         1.7714,  0.4936,  1.9930,  1.8735,  0.1069,  1.4983,  0.6583,  2.1928,\n",
      "         1.2700,  2.0855,  0.8129,  0.5040,  0.7278,  0.3081,  0.7781,  0.9230,\n",
      "         1.2297,  1.6208,  0.7168,  1.6743,  0.8511,  0.5893,  1.4627, -0.0780,\n",
      "         1.0868,  0.4671,  0.6606,  0.1982,  2.3926,  2.9756,  0.2800,  1.8858,\n",
      "         1.5068,  1.0864,  0.6925,  0.6225,  0.3922,  0.5989,  2.1705,  0.4513],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.5603e+00,  3.9370e-01,  5.9708e-01,  1.2097e+00, -7.3852e-01,\n",
      "         3.0717e-01,  3.2592e-01, -2.3427e-01, -1.4099e-01,  9.1566e-01,\n",
      "        -9.3229e-02, -6.9869e-01, -3.1050e-01,  5.9623e-01,  2.6326e-01,\n",
      "         2.1921e-01,  4.2605e-01,  4.3490e-01,  6.6532e-01, -1.0413e+00,\n",
      "         6.6990e-01, -1.7622e+00, -2.9399e-01, -1.4534e-01,  2.5938e-01,\n",
      "        -1.2458e+00,  9.8331e-01,  1.1274e+00,  1.1091e+00,  1.5765e+00,\n",
      "         7.3883e-01, -2.6949e-02, -1.2070e-02, -9.4997e-01,  1.1443e+00,\n",
      "         2.4389e-01,  7.2290e-01,  1.0604e-01,  4.7070e-01,  1.2885e+00,\n",
      "         6.7758e-01, -3.9730e-01,  1.1487e+00, -3.2891e-01,  7.6179e-01,\n",
      "        -5.2093e-01,  4.0651e-01, -1.5037e+00,  4.2317e-01,  1.2264e-02,\n",
      "        -1.0468e+00, -3.8995e+00, -9.3166e-01,  1.5991e-01,  1.7174e+00,\n",
      "         1.0221e-01, -1.3269e+00,  2.3777e+00, -1.3049e+00, -4.8344e-01,\n",
      "         6.7044e-01,  1.3110e+00, -2.3398e+00,  1.6016e-01, -2.0244e-01,\n",
      "         1.2636e+00, -2.6070e-01,  8.7928e-02,  4.5975e-01,  1.9135e-03,\n",
      "        -1.3600e-01, -9.8136e-02,  3.5327e-01,  1.1102e+00, -4.7515e-01,\n",
      "         5.9492e-01,  2.6035e-01,  1.4802e+00,  3.5195e-01, -1.7656e-01,\n",
      "         7.2766e-01, -1.1153e+00,  6.9628e-01, -7.2502e-01, -3.3547e-01,\n",
      "        -8.7058e-01,  7.3748e-01,  5.7845e-01,  2.5635e-01,  1.1621e+00,\n",
      "         2.5705e-01, -3.7812e-01,  1.0960e+00,  6.7632e-03, -3.3129e-01,\n",
      "         1.0581e+00, -7.7948e-01,  8.3655e-01,  8.1842e-02,  1.4005e+00,\n",
      "        -2.8045e-01,  1.7696e+00,  4.5622e-01,  6.3746e-01, -2.6143e-01,\n",
      "        -4.3882e-01,  1.1455e-01, -8.6381e-01,  1.3901e+00, -1.5505e+00,\n",
      "         7.0710e-01, -1.0616e+00, -1.2649e-01, -7.2011e-01, -1.8203e+00,\n",
      "        -9.8326e-01, -3.6716e-01,  1.4362e+00, -1.6257e-01,  3.1844e-01,\n",
      "        -7.9142e-01,  1.0894e+00, -1.5849e+00, -6.7537e-01, -1.1372e+00,\n",
      "        -2.2669e+00, -2.6122e+00,  9.7332e-02, -5.0473e-01,  6.0418e-01,\n",
      "         6.0062e-01,  1.3386e-01, -9.9771e-02,  3.6358e-01,  1.4812e+00,\n",
      "        -5.1574e-01,  7.1605e-01,  8.5465e-01, -2.7066e+00, -2.2832e+00,\n",
      "         5.9763e-01,  2.6291e-01,  7.4723e-01,  1.4608e+00,  6.2556e-01,\n",
      "         6.2701e-01,  4.2357e-01,  1.6617e+00, -1.0676e+00, -2.1132e+00,\n",
      "         8.1780e-01, -2.8335e-01,  5.4344e-01, -2.0723e+00,  1.4110e+00,\n",
      "        -1.5612e-01,  2.5031e-01,  4.6713e-01,  1.1886e+00, -7.0117e-03,\n",
      "         6.8966e-01, -3.7621e+00,  1.3724e-03,  1.2164e+00, -8.4488e-01,\n",
      "         2.3715e-01, -4.4307e-01,  2.2454e-02, -5.0260e-01,  3.1022e-01,\n",
      "         3.9166e-01, -3.9984e-01, -1.0905e+00, -1.3220e+00, -7.6437e-01,\n",
      "        -1.4559e-01, -2.1294e-01,  1.4232e+00, -3.4934e-01, -2.2768e-01,\n",
      "         6.0447e-01, -1.5775e+00,  6.3105e-01, -4.7665e-01,  1.4509e-01,\n",
      "        -1.7068e+00,  1.7768e-01,  1.4712e+00, -1.4133e+00, -6.8221e-01,\n",
      "        -7.0181e-01,  5.0690e-01,  1.9567e-01,  8.0364e-01, -3.5260e-01,\n",
      "         1.3902e+00,  8.1284e-01,  1.2095e+00, -1.3398e+00,  9.8683e-02,\n",
      "        -2.2835e-01, -5.7835e-02,  1.1694e+00,  1.3645e+00, -1.3591e+00,\n",
      "        -6.4222e-02, -1.5725e+00, -1.2831e+00,  2.3974e-01, -1.2821e-01,\n",
      "         1.3139e+00, -1.3137e-01, -8.2081e-01,  7.7661e-01,  4.2992e-01,\n",
      "        -1.0863e+00,  1.0201e+00, -6.9249e-01, -6.5963e-01, -1.3029e+00,\n",
      "         1.3967e-01, -2.1886e+00,  1.5769e+00, -2.5864e-02,  4.1397e-01,\n",
      "         1.3582e+00, -9.0047e-01,  9.6960e-02,  7.2832e-01,  4.7623e-01,\n",
      "         1.0039e+00,  8.4001e-01,  9.0673e-01, -1.8539e+00,  1.6627e+00,\n",
      "         7.4422e-01,  4.8626e-01, -8.8422e-01,  3.8498e-01,  5.9232e-01,\n",
      "         5.9750e-01,  1.0469e-01,  5.8993e-04,  2.3694e-01,  1.9695e-01,\n",
      "         2.6600e-01, -1.9410e+00, -1.2315e+00, -1.3253e-01, -7.7766e-01,\n",
      "        -8.6558e-01, -4.5135e-02, -1.8616e-01,  3.0820e-01, -9.3244e-02,\n",
      "         6.8148e-01, -6.7853e-03, -1.7416e+00, -2.9236e-01,  8.9807e-01,\n",
      "        -9.8270e-01, -1.2526e-01, -1.2411e+00,  9.3404e-02,  2.1426e+00,\n",
      "         1.3660e+00,  1.0500e+00,  8.6948e-01,  1.2088e+00,  6.8582e-01,\n",
      "         1.5294e-01, -5.8393e-01,  1.0897e-01, -4.8392e-01, -5.1875e-01,\n",
      "        -1.6560e+00,  3.3274e-01, -1.1628e-03,  1.0541e+00, -1.8042e+00,\n",
      "        -1.7945e+00, -1.9046e+00, -1.9547e-01,  1.1000e+00,  1.1133e+00,\n",
      "         6.9198e-02, -1.1310e-01, -6.6983e-02,  1.7934e-01,  6.3501e-01,\n",
      "        -1.4354e+00,  1.7158e-01, -2.2141e+00, -2.1774e+00,  2.3790e-01,\n",
      "        -6.1606e-01,  1.6335e+00,  1.6451e+00, -6.9967e-01, -7.8100e-01,\n",
      "         1.9590e+00,  9.8273e-01, -9.3353e-01,  1.0232e+00, -2.5885e+00,\n",
      "         1.0033e+00, -2.4265e+00,  1.2460e+00,  1.4794e+00,  2.6960e-01,\n",
      "        -5.3225e-01,  1.0108e+00,  1.6080e-01, -6.1887e-01,  1.5184e+00,\n",
      "        -7.6352e-01,  1.5339e+00,  1.2841e+00, -9.1945e-01,  8.5772e-01,\n",
      "         1.5772e-01, -1.5858e-01,  1.0572e+00, -5.7589e-01,  1.4652e+00,\n",
      "         6.3786e-01, -5.9160e+00, -8.9968e-01, -2.4052e+00, -1.8353e+00,\n",
      "         8.0814e-02,  2.1084e+00,  5.3938e-01,  8.7737e-01,  6.8762e-01,\n",
      "        -1.0148e+00,  9.2065e-01,  8.4568e-01,  6.0633e-01,  1.6019e+00,\n",
      "        -7.4690e-02,  5.1973e-01,  1.2208e+00,  5.3790e-01,  1.3771e+00,\n",
      "         1.7517e+00,  1.2277e-02, -1.5058e+00,  9.8627e-01, -2.3223e+00,\n",
      "         1.1548e+00,  7.0859e-01, -3.4295e-01, -8.3753e-01,  6.2151e-02,\n",
      "         4.5747e-01, -1.8897e-01,  8.5850e-01, -1.0244e+00,  7.5753e-01,\n",
      "         1.5544e+00,  8.3503e-01, -1.1294e-01,  8.1182e-01,  1.5198e-01,\n",
      "         7.0347e-02, -2.2356e+00,  1.0865e+00,  8.3672e-01,  1.1567e+00,\n",
      "         8.9805e-02, -1.6335e+00, -2.1250e-01, -9.3910e-01, -2.8462e+00,\n",
      "         7.2495e-01, -3.9644e+00,  1.7117e+00, -1.2752e+00,  9.7164e-01,\n",
      "        -2.7427e+00,  5.9544e-01, -5.1115e-02,  1.5568e+00,  1.8858e+00,\n",
      "        -6.9698e-01,  8.2892e-03,  2.7056e-01,  5.6021e-01, -1.0433e+00,\n",
      "         1.5203e+00,  1.1883e+00,  4.5798e-01,  2.8685e-02, -2.1487e+00,\n",
      "        -3.0353e-01,  9.7948e-01, -1.0528e+00,  6.6234e-01, -9.8300e-01,\n",
      "         5.4061e-01,  1.0109e+00, -7.3682e-01,  1.7992e-01,  2.9395e-01,\n",
      "        -9.5070e-01,  5.0803e-01,  2.6473e-01, -2.8481e-01,  4.4723e-01,\n",
      "         1.3992e+00,  8.3233e-01, -1.4151e+00,  1.8503e+00, -2.3299e+00,\n",
      "         4.4064e-01,  4.0934e-01, -1.5353e+00,  1.7704e-01, -1.4766e+00,\n",
      "        -1.2737e+00,  4.9766e-01, -4.4237e-01,  7.6993e-01, -1.1731e+00,\n",
      "         1.0389e+00, -1.9326e+00,  1.1934e+00, -8.1651e-01,  3.0566e-01,\n",
      "         1.4487e+00, -1.0351e+00,  8.3870e-01, -2.6358e+00,  8.6477e-01,\n",
      "        -1.0890e-01, -9.0778e-01,  3.1883e-01,  7.8501e-01,  4.6471e-01,\n",
      "         1.1620e+00,  2.9642e-01, -7.1089e-01,  1.6084e+00,  1.4110e+00,\n",
      "         1.2507e+00, -2.1695e+00,  5.5994e-01, -1.8211e+00, -3.6844e-01,\n",
      "        -6.9811e-01,  1.0074e+00, -3.8244e-02,  1.0448e+00, -2.9464e-02,\n",
      "        -1.4209e+00, -5.7621e-02, -1.0517e-01,  6.2556e-01, -1.7244e+00,\n",
      "         1.1709e+00,  1.0449e+00,  7.6530e-01,  4.8082e-01, -5.4817e-02,\n",
      "         8.8801e-01,  9.0770e-01, -1.5750e+00, -5.3125e-01,  1.7864e+00,\n",
      "        -2.9030e-02, -4.6594e-01,  2.2095e-01, -6.6584e-01,  1.4146e+00,\n",
      "         3.7051e-01, -9.8684e-01,  1.6855e+00,  1.7475e+00, -1.8619e+00,\n",
      "         1.1591e+00,  8.4935e-01,  7.7285e-01,  6.1147e-01,  8.6933e-01,\n",
      "        -2.8635e-01,  2.1310e-01, -7.4727e-01,  5.8201e-01,  7.4371e-01,\n",
      "         1.7593e-01, -1.8445e+00,  8.4795e-01, -3.5474e-01,  1.2576e+00,\n",
      "         2.3695e-01,  1.4456e-01,  1.9983e-01,  9.9170e-01, -5.3366e-02,\n",
      "        -1.2833e+00,  7.9035e-01, -4.4167e-01,  9.2894e-01,  2.5652e-01,\n",
      "         3.1181e-03,  1.3495e+00, -1.7370e+00, -2.0270e+00,  1.1055e+00,\n",
      "         7.9044e-01,  1.3380e+00, -9.6846e-01, -1.6879e+00,  1.2387e+00,\n",
      "        -2.6418e-01,  1.6864e+00,  1.9439e+00,  1.2033e+00, -1.1430e-01,\n",
      "        -4.2796e-01,  1.1639e+00, -7.4563e-01,  7.1651e-01, -1.6510e+00,\n",
      "         5.2576e-01,  1.4985e+00, -4.8419e-01,  1.0166e-01,  6.8329e-02,\n",
      "        -1.5129e+00,  3.2244e-01,  1.2905e+00, -6.8320e-01,  1.2616e+00,\n",
      "        -4.8238e-01, -1.9060e+00, -4.1211e-01,  6.2444e-01, -5.8500e-01,\n",
      "         1.3679e+00, -1.7969e+00, -9.2043e-02,  1.4666e-01, -1.3096e-02,\n",
      "        -1.0341e+00, -5.5604e-01,  4.0019e-02, -2.0071e+00,  1.6913e-01,\n",
      "         8.4854e-01, -1.2923e+00, -2.7200e-01, -3.7741e-01,  6.9994e-01,\n",
      "        -1.8372e+00, -4.7677e-01,  5.7138e-01,  4.4942e-01,  5.8331e-01,\n",
      "        -6.2200e-01,  3.2195e-01,  5.3790e-01, -2.0150e-01,  1.1993e+00,\n",
      "        -4.8316e-02,  3.1371e-01,  1.1026e+00,  6.4897e-01, -8.7977e-02,\n",
      "         9.0217e-01,  1.4052e+00,  2.0699e-02,  1.0400e+00, -3.9741e+00,\n",
      "        -1.9284e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.4390,  0.1201,  0.0125],\n",
      "          [ 0.4780,  0.4961,  0.1542],\n",
      "          [-0.1230, -0.1585, -0.3432]]],\n",
      "\n",
      "\n",
      "        [[[-0.2757,  0.2307,  0.5533],\n",
      "          [ 0.1852, -0.2542,  0.0440],\n",
      "          [-0.5188, -0.4633,  0.1023]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0283,  0.3949,  0.3982],\n",
      "          [-0.3720,  0.0476,  0.3075],\n",
      "          [-0.5414, -0.4672, -0.3534]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1175,  0.0538, -0.1533],\n",
      "          [-0.7887, -0.4484, -0.3920],\n",
      "          [-0.5526, -0.0692, -0.2799]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0808,  0.0930, -0.4955],\n",
      "          [ 0.1336, -0.5618,  0.2861],\n",
      "          [-0.2650, -0.4068,  0.4053]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1179,  0.5335,  0.2677],\n",
      "          [-0.3277, -0.4890, -0.0031],\n",
      "          [-0.3778, -0.4269, -0.3119]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 6.5973e-01,  1.2997e+00,  1.7208e+00,  1.5475e+00,  7.7133e-01,\n",
      "         1.6900e+00,  1.1544e+00,  2.4373e+00,  1.6779e+00,  1.5331e+00,\n",
      "         9.4952e-01,  1.0061e+00,  9.7624e-01,  9.1754e-01,  9.1715e-01,\n",
      "         2.7650e+00,  1.5715e+00,  2.0278e+00,  1.5109e+00,  2.8855e+00,\n",
      "         1.0659e+00,  3.8352e+00,  4.4967e-01,  1.1357e+00,  1.0113e+00,\n",
      "         5.1394e-01,  1.4205e+00,  1.7078e+00,  2.7996e+00,  1.2406e+00,\n",
      "         1.3397e+00,  1.7077e+00,  1.0983e+00,  1.6984e+00,  1.4926e+00,\n",
      "         1.5425e+00,  1.4703e+00,  5.4350e-01,  1.2355e+00,  1.6876e+00,\n",
      "         6.9280e-01,  1.3825e+00,  1.5389e+00,  1.8260e+00,  9.1081e-01,\n",
      "         3.7318e-01,  9.9098e-01,  4.8818e-01,  1.9581e+00,  1.3460e+00,\n",
      "         1.1990e+00,  5.0613e+00,  7.3664e-01,  1.5880e+00,  1.9911e+00,\n",
      "         2.1614e+00,  1.5271e+00,  2.2306e+00,  1.2978e+00,  1.8767e+00,\n",
      "         7.5818e-01,  1.7549e+00,  4.2559e+00,  1.3149e+00,  1.4030e+00,\n",
      "         1.5081e+00,  1.1069e+00,  1.4084e+00,  1.4710e+00,  1.5993e+00,\n",
      "         1.8034e+00,  1.5003e+00,  1.4657e+00,  5.2592e-01,  6.4168e-01,\n",
      "         2.1336e+00,  1.4026e+00,  1.2819e+00,  1.8587e+00,  1.7767e+00,\n",
      "         1.5420e+00,  8.9263e-01,  1.1450e+00,  1.7035e+00,  1.8645e+00,\n",
      "         9.1895e-01,  1.7495e+00,  1.7960e+00,  1.9386e+00,  6.6725e-01,\n",
      "         1.6336e+00,  1.2473e+00,  2.3366e+00,  1.5811e+00,  1.8537e+00,\n",
      "         1.1062e+00,  4.6571e-01,  1.2324e+00,  8.0596e-01,  2.2000e+00,\n",
      "         1.5971e+00,  1.7372e+00,  1.3472e+00,  6.4696e-02,  1.6982e+00,\n",
      "         1.5334e+00,  8.4084e-01,  1.4848e+00,  1.4184e+00,  9.7239e-03,\n",
      "         1.2183e+00,  6.9253e-01,  1.5486e+00,  1.4402e+00,  2.4965e+00,\n",
      "         2.5504e-01,  1.6336e+00,  2.1415e+00,  1.7779e+00,  1.7591e+00,\n",
      "         9.3348e-01,  2.0072e+00,  1.5032e+00, -5.0274e-03,  6.8350e-01,\n",
      "         1.4292e+00,  4.1250e+00,  9.8898e-01,  1.6865e+00,  1.4692e+00,\n",
      "         1.2090e+00,  2.3339e-01,  1.6630e+00,  1.5851e+00,  2.1715e+00,\n",
      "         3.3280e+00,  7.1078e-01,  1.4785e+00,  2.9648e+00,  2.5962e+00,\n",
      "         2.0131e-01,  1.3941e+00,  1.3871e+00,  1.4209e+00,  1.2118e+00,\n",
      "         1.8355e+00,  1.0497e+00,  1.1435e+00,  1.1145e+00,  1.7750e+00,\n",
      "         1.2233e+00,  1.0854e+00,  1.9154e+00,  3.7309e+00,  4.2145e-01,\n",
      "         6.4449e-01,  1.0012e+00,  1.7235e-01,  1.3259e+00,  7.3414e-01,\n",
      "         1.7520e+00,  4.8401e+00,  1.3724e+00,  1.5604e+00,  1.3213e+00,\n",
      "         1.7142e+00,  1.4187e+00,  1.1484e+00,  1.6780e+00,  1.1892e+00,\n",
      "         1.4864e+00,  1.3784e+00,  8.2227e-01,  1.1820e+00,  7.9406e-01,\n",
      "         1.4466e+00,  1.4768e+00,  1.5157e+00,  9.1530e-01,  1.2534e+00,\n",
      "         1.3392e+00,  2.4917e+00,  2.3153e+00,  2.3813e-02,  1.5271e+00,\n",
      "         2.2059e+00,  1.0048e+00,  2.0137e+00,  1.0976e+00,  1.5847e+00,\n",
      "         1.3936e+00,  2.6549e+00,  1.1764e+00,  1.4793e+00,  1.7273e+00,\n",
      "         1.7114e+00,  8.8657e-01,  1.8002e+00,  7.1460e-01,  1.7557e+00,\n",
      "         1.3916e+00,  2.2784e+00,  1.0317e+00,  2.4347e+00,  6.8700e-01,\n",
      "         1.6535e+00, -1.5632e-03,  6.4196e-01,  1.4182e+00,  1.3825e+00,\n",
      "         2.3302e+00,  1.5921e+00,  1.6609e+00,  9.4511e-01,  1.7795e+00,\n",
      "         5.5631e-01,  1.5745e+00,  2.1617e+00,  9.6093e-01,  1.4404e+00,\n",
      "         1.7041e+00,  2.6092e+00,  6.7722e-01,  1.6341e+00,  1.4248e+00,\n",
      "         1.9384e+00,  2.5111e-01,  1.7010e+00,  1.8230e+00,  1.6468e+00,\n",
      "         1.5843e+00,  1.6658e+00,  2.0432e+00,  4.9925e+00,  2.3236e+00,\n",
      "         1.5793e+00,  1.2652e+00,  1.4123e+00,  1.6072e+00,  1.0145e+00,\n",
      "         1.7924e+00,  1.9540e+00,  1.5156e+00,  1.5476e+00,  2.1158e+00,\n",
      "         9.0867e-01,  8.5067e-02,  2.0193e+00,  1.6281e+00,  8.4845e-01,\n",
      "         1.3886e+00,  1.4096e+00,  1.7476e+00,  1.3494e+00,  1.5767e+00,\n",
      "         6.3245e-01,  1.6781e+00,  3.8138e+00,  1.1122e+00,  1.6034e+00,\n",
      "         7.6505e-01,  1.5084e+00,  8.0678e-02,  8.7469e-01,  2.0016e+00,\n",
      "         1.4597e+00,  1.4572e+00,  8.8461e-01,  1.9307e+00,  2.0983e+00,\n",
      "         1.4993e+00,  6.1269e-01,  1.4363e+00,  1.0385e+00,  1.8527e+00,\n",
      "         1.8250e+00,  9.4620e-01,  1.4101e+00,  9.1203e-01,  1.1647e+00,\n",
      "         1.1497e+00,  1.0049e+00,  2.4771e+00,  1.7499e+00,  1.9387e+00,\n",
      "         1.8155e+00,  1.6028e+00,  8.2806e-01,  1.4339e+00,  1.3446e+00,\n",
      "         2.5597e+00,  2.3611e+00,  2.7826e-01,  4.3553e-01,  2.2558e+00,\n",
      "         1.2785e+00,  2.4449e+00,  1.5464e+00,  4.3316e-01,  1.8663e+00,\n",
      "         1.8021e+00,  6.9874e-01,  5.5771e-01,  1.8157e+00,  8.1458e-01,\n",
      "         1.5553e+00,  2.4805e+00,  2.2477e+00,  3.4546e-01,  1.8096e+00,\n",
      "         9.1795e-01,  1.7200e+00,  7.6660e-01,  1.0060e+00,  1.4888e+00,\n",
      "         1.1074e+00,  2.1733e+00,  1.3355e+00,  9.4288e-01,  1.0629e+00,\n",
      "         1.5210e+00,  1.1241e+00,  1.7934e+00,  1.1705e+00,  1.6444e+00,\n",
      "         1.4092e+00,  6.0947e+00,  8.2534e-01,  3.6196e+00,  1.4632e+00,\n",
      "         1.4512e+00,  5.4610e-01,  1.7468e+00,  9.2727e-01,  1.7546e+00,\n",
      "         8.5123e-01,  1.4520e+00,  1.5082e+00,  2.6185e+00,  1.7765e+00,\n",
      "         1.8123e+00,  1.3369e+00,  1.6919e+00,  1.2682e+00,  1.5187e+00,\n",
      "         2.4823e+00,  1.6602e+00,  1.4649e+00,  1.2200e+00,  3.2199e-01,\n",
      "         3.1644e-01,  2.1615e+00,  1.4345e+00,  5.4471e-01,  2.4283e+00,\n",
      "         1.6238e+00,  1.2463e+00,  4.9695e-01,  1.4049e+00,  1.9319e+00,\n",
      "         8.0332e-01,  1.0485e+00,  1.4432e+00,  1.1385e+00,  1.6230e+00,\n",
      "         1.5659e+00,  3.8411e+00,  2.3063e+00,  1.2108e+00,  1.2066e+00,\n",
      "         1.2685e+00,  4.6109e-01,  8.3324e-01,  1.5989e+00,  2.3872e+00,\n",
      "         1.8700e+00,  1.7996e-01,  7.5479e-01,  9.7279e-01,  1.9606e+00,\n",
      "         3.2068e+00,  1.5006e+00,  1.7748e+00,  1.6363e+00,  1.1298e+00,\n",
      "         4.5917e-01,  6.2886e-01,  1.2758e+00,  1.7532e+00,  1.3450e+00,\n",
      "         9.4235e-01,  1.3352e+00,  1.8192e+00,  1.5146e+00,  7.1233e-01,\n",
      "         1.3141e+00,  1.9669e+00,  3.0626e+00,  1.4189e+00,  1.7219e+00,\n",
      "         1.3411e+00,  1.6390e+00,  2.4028e+00,  1.8213e+00,  1.6578e+00,\n",
      "        -7.2157e-03,  2.5800e+00,  1.5879e+00,  3.5302e-01,  2.6555e+00,\n",
      "         1.2162e+00,  1.7090e+00,  2.6692e+00,  2.1138e+00,  1.2327e+00,\n",
      "         6.8252e-01,  1.2013e+00,  1.5733e+00,  1.8395e+00,  2.0649e+00,\n",
      "         2.1947e+00,  9.0645e-01,  8.9041e-01,  1.7536e+00,  3.6708e-01,\n",
      "         1.2259e+00,  1.7524e+00,  2.0388e+00,  6.4817e-01,  1.1823e+00,\n",
      "         7.1683e-01,  1.4377e+00,  9.4329e-01,  6.1158e-01,  1.2951e+00,\n",
      "         1.2908e+00,  4.8965e-01,  1.3111e+00,  1.2138e+00,  1.5372e+00,\n",
      "         1.3463e+00,  1.5044e+00,  1.5092e+00,  2.0625e+00,  1.6638e+00,\n",
      "         1.8224e+00,  2.1177e+00,  1.9273e+00,  3.0477e+00,  1.1453e+00,\n",
      "         1.6515e+00,  1.6318e+00,  1.3158e+00,  1.3578e+00,  1.7732e+00,\n",
      "         1.5840e+00,  2.1334e+00,  1.2840e+00,  1.9090e+00,  1.8098e+00,\n",
      "         1.1976e+00,  1.7849e+00,  1.0915e+00,  6.5704e-01,  2.2586e+00,\n",
      "         1.5092e+00,  1.1914e+00,  2.4866e+00,  6.5582e-01,  1.7345e+00,\n",
      "         1.8789e+00,  1.5035e+00,  1.9821e+00,  1.4567e+00,  1.2176e+00,\n",
      "         1.5009e+00,  1.3377e+00,  1.4688e+00,  1.7331e+00,  2.3933e+00,\n",
      "         9.0812e-01,  1.5266e+00,  1.6046e+00,  2.5744e+00,  6.0338e-01,\n",
      "         1.4910e+00,  1.6635e+00,  3.1425e+00,  1.0865e+00,  1.5525e+00,\n",
      "         1.8277e+00, -8.2960e-02,  1.6066e+00,  1.7389e+00,  1.9231e+00,\n",
      "         1.3688e+00,  1.4376e+00,  2.1450e+00,  1.1504e+00,  8.3962e-01,\n",
      "         5.3056e-01,  1.5883e+00,  2.2658e+00,  1.8413e+00,  1.9478e+00,\n",
      "         1.3647e+00,  1.8600e+00, -5.6487e-02,  1.0700e+00,  1.5400e+00,\n",
      "         1.7248e+00,  5.9377e-01,  3.4141e-01,  5.2465e-01,  1.6844e+00,\n",
      "         1.3170e+00,  1.8401e+00,  1.8751e+00,  1.8788e+00,  9.1300e-01,\n",
      "         1.0190e+00,  8.6760e-01,  8.2978e-01,  1.7063e+00,  4.0289e+00,\n",
      "         1.2574e+00,  2.0666e+00,  2.3946e+00,  6.7256e-01,  1.0804e+00,\n",
      "         3.0125e+00,  1.5922e+00,  1.5558e+00,  2.0533e+00,  8.4162e-01,\n",
      "         9.2903e-01,  2.0038e+00,  7.9927e-01,  7.8404e-01,  5.4327e-01,\n",
      "         1.2885e+00,  3.8690e+00,  1.4890e+00,  9.6848e-01,  2.0274e+00,\n",
      "         1.8622e+00,  7.3973e-01,  1.7451e+00,  1.7518e+00,  1.5257e+00,\n",
      "         2.1443e+00,  5.0068e-01,  7.4830e-01,  6.8842e-01,  1.7423e+00,\n",
      "         3.7003e+00,  2.0388e+00,  1.4533e+00,  1.9077e+00,  1.2411e+00,\n",
      "         1.7592e+00,  2.1690e-01,  1.1995e+00,  5.5334e-01,  5.4532e-01,\n",
      "         2.1289e+00,  1.5954e+00,  1.1316e+00,  1.6860e+00,  1.5891e+00,\n",
      "         1.6072e+00,  1.9656e+00,  1.3020e+00,  6.4960e-01,  4.3580e+00,\n",
      "         1.7019e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.0193e-01, -1.8078e+00, -1.1740e+00, -1.7630e+00, -2.6549e-04,\n",
      "        -1.2284e+00, -7.6057e-01, -1.3952e+00, -1.3246e+00, -2.0764e+00,\n",
      "        -1.4203e+00, -2.7489e-01, -2.2125e+00, -3.9826e-01,  1.1947e-01,\n",
      "        -9.7618e-01, -6.2058e-01, -1.2009e+00, -7.1475e-01, -4.7732e-01,\n",
      "        -5.1342e-01,  3.3966e-01,  3.2465e-01, -6.9314e-01, -2.5858e+00,\n",
      "        -5.6413e-03, -1.6009e+00, -1.4403e+00, -2.3513e+00, -2.1688e+00,\n",
      "        -6.0630e-01, -1.3010e+00, -4.0039e-01, -8.8672e-01, -4.0386e-01,\n",
      "        -1.5685e+00, -5.4324e-01, -1.3731e-01, -1.1382e+00, -1.4330e+00,\n",
      "         2.7982e-01, -9.4294e-01, -1.0150e+00, -1.4497e+00, -3.1256e-01,\n",
      "        -2.5586e-01, -1.1538e+00, -2.6448e-01, -1.7748e+00, -1.5207e+00,\n",
      "        -3.4074e-01, -5.7888e-01, -2.7393e-02, -1.3528e+00, -2.0741e+00,\n",
      "        -1.6841e+00, -1.1380e+00, -2.4327e+00, -4.3903e-01, -1.5819e+00,\n",
      "         2.8971e-01, -2.4457e+00,  1.0815e-01, -1.1027e+00, -1.8952e+00,\n",
      "        -2.3054e+00, -2.5634e+00, -1.3811e+00, -1.3570e+00, -1.5105e+00,\n",
      "        -1.2210e+00, -7.1739e-01, -1.4392e+00, -2.7504e-01,  6.2630e-01,\n",
      "        -5.4201e-01, -1.4355e+00, -2.0181e+00, -1.3735e+00, -1.2292e+00,\n",
      "        -1.0890e+00, -2.9624e-01, -1.5245e+00, -3.2172e-01, -5.8933e-01,\n",
      "         3.0102e-01, -1.5414e+00, -2.2933e+00, -7.2789e-01, -3.8100e-01,\n",
      "        -1.6155e+00, -1.8856e-02, -2.0932e+00, -1.6919e+00, -9.8992e-01,\n",
      "        -2.6395e+00,  1.4417e-01, -3.5930e-01, -2.6288e-01, -1.6956e+00,\n",
      "        -2.7353e+00, -2.6273e+00, -1.1471e+00,  9.6335e-02,  2.6269e-02,\n",
      "        -2.4794e+00, -1.3620e+00, -1.7158e+00, -1.4680e+00, -3.5692e-02,\n",
      "        -6.3582e-01,  1.6895e-01, -1.0605e+00, -1.4577e+00, -1.3678e-01,\n",
      "        -1.6418e-01, -2.8305e+00, -1.8826e+00, -1.5351e+00, -5.6283e-01,\n",
      "         2.2337e-01, -1.5159e+00, -1.5194e+00,  6.9846e-02,  7.4779e-02,\n",
      "        -5.1603e-01, -1.2846e-01, -1.7975e-01, -1.0667e+00, -1.7014e+00,\n",
      "        -2.0830e+00, -1.8512e-01,  1.2506e-01, -1.0391e+00,  2.0219e-01,\n",
      "        -1.3155e+00, -1.0430e-01, -2.2485e+00, -6.4768e-01,  7.8377e-01,\n",
      "         2.8983e-02, -1.6791e+00, -1.2430e+00, -1.3465e+00, -2.0439e+00,\n",
      "        -1.4213e+00, -1.6082e+00, -1.9724e+00,  5.5617e-02, -5.5834e-01,\n",
      "        -1.5642e+00,  4.7234e-01, -1.3302e+00,  3.2145e-01,  8.8713e-02,\n",
      "        -9.7882e-02,  1.9960e-01, -3.5830e-01, -1.5384e+00, -2.2945e-01,\n",
      "         1.3998e-02, -3.1055e-01, -2.0884e+00, -1.2134e+00, -1.8021e+00,\n",
      "        -1.2604e+00, -5.8548e-01, -1.8232e+00, -1.5801e+00, -5.9054e-01,\n",
      "        -1.5756e+00, -2.1570e+00, -4.5465e-02, -6.2069e-01, -4.7924e-01,\n",
      "        -1.2151e+00, -4.5808e-01, -9.0634e-01, -2.5479e-01, -3.1250e-01,\n",
      "        -1.7209e+00, -1.8506e-01, -1.7095e+00, -1.9286e-01, -4.7384e-01,\n",
      "        -1.2543e+00, -4.7206e-01, -1.2677e+00, -3.0065e-01,  3.8488e-02,\n",
      "        -1.7646e+00, -1.3302e+00, -1.1361e-01, -1.6391e+00, -1.2185e+00,\n",
      "        -1.9206e+00, -1.0181e-02, -3.6028e-01,  5.1881e-01, -1.4363e+00,\n",
      "        -1.1539e+00, -5.4505e-01, -9.9659e-02, -2.0750e+00,  1.5155e+00,\n",
      "        -1.5981e+00,  6.7964e-02,  1.1735e-01, -8.0391e-01, -1.4901e+00,\n",
      "        -9.1278e-01, -5.3694e-02, -8.8398e-01, -2.4456e-01, -1.8249e+00,\n",
      "         1.9455e-01, -2.0118e+00, -2.1864e-01, -5.2970e-01, -2.8978e+00,\n",
      "        -8.6073e-01, -2.2434e-01, -2.0042e-01, -1.2189e+00, -1.2056e+00,\n",
      "        -1.2095e+00, -9.9558e-02, -7.2794e-01, -1.6390e+00, -1.6235e+00,\n",
      "        -1.0912e+00, -1.5868e+00,  3.0180e-01, -2.1816e+00, -2.0293e+00,\n",
      "        -5.3991e-03, -1.7182e+00, -5.4896e-01, -1.5330e+00, -7.2910e-01,\n",
      "        -1.5653e+00, -1.7056e+00, -1.1642e+00, -2.0038e+00, -1.2703e+00,\n",
      "         1.0548e-01,  1.4523e-02, -6.6868e-01, -1.6393e+00,  7.7695e-01,\n",
      "        -8.3526e-01, -1.4550e+00, -1.5227e+00, -1.3946e+00, -2.5097e+00,\n",
      "         1.0301e-01, -1.5173e+00, -3.9850e-02, -1.8570e+00, -2.5482e+00,\n",
      "        -2.8375e+00, -1.1593e+00,  2.5904e-01, -4.7906e-01, -1.1227e+00,\n",
      "        -1.3358e+00, -1.2377e+00, -1.8360e+00, -5.9034e-01, -2.3356e+00,\n",
      "        -2.2615e+00, -3.2339e-01, -5.2432e-01, -2.7703e-02, -1.8008e-01,\n",
      "        -6.2806e-01, -1.8449e+00, -1.6140e+00, -3.6932e-01, -1.7963e+00,\n",
      "        -1.9449e+00,  1.2166e-02,  8.9007e-02, -1.6148e+00, -1.3949e+00,\n",
      "        -1.5768e+00, -1.5059e+00, -5.6627e+00, -1.6012e+00, -7.4193e-01,\n",
      "        -4.5070e-01, -1.2101e+00,  1.6043e-02, -2.9422e-01, -1.4127e+00,\n",
      "        -1.5524e+00, -2.0274e+00, -1.8135e+00, -8.5635e-03,  4.7376e-01,\n",
      "        -1.6975e+00,  5.9668e-02, -6.8041e-02, -4.8575e-01, -1.2715e-01,\n",
      "        -1.0621e+00,  2.4150e-02, -1.7986e+00, -5.7877e-02, -1.6467e+00,\n",
      "         1.5329e-01, -1.7497e+00, -5.4734e-02, -6.3283e-01,  2.4941e-01,\n",
      "         1.1979e+00, -1.1849e+00, -1.7466e+00,  4.0216e-01, -1.1914e+00,\n",
      "        -1.2705e+00, -1.6512e+00, -1.9709e+00, -1.4059e+00, -1.8012e+00,\n",
      "         2.5409e-02, -1.6744e+00,  1.7102e-01, -3.2631e-01, -2.9325e+00,\n",
      "        -1.7420e+00, -1.2855e-01, -1.5013e+00, -3.6054e-01, -2.4825e+00,\n",
      "        -1.8084e-01, -1.5430e+00,  8.3078e-02, -3.1575e-01, -1.8390e+00,\n",
      "         5.3784e-01, -1.5646e+00, -1.5512e+00, -1.7030e+00, -1.6277e+00,\n",
      "        -1.7644e+00, -1.8856e+00, -6.6352e-01, -9.6904e-01, -1.4108e-01,\n",
      "        -1.1314e-01, -1.1759e+00, -7.7396e-01, -8.1124e-02, -1.9480e+00,\n",
      "        -1.7390e+00, -3.9782e-01, -3.4375e-01, -7.9353e-01, -1.7450e+00,\n",
      "        -4.5574e-02, -5.1720e-01, -1.2835e+00, -1.5378e+00, -1.3675e+00,\n",
      "        -1.4096e+00, -3.7844e-01, -1.8326e+00, -6.4537e-01, -1.9801e-01,\n",
      "        -1.3020e+00,  1.2140e-02, -1.6055e-01, -2.1566e+00, -5.8877e-01,\n",
      "        -1.3980e+00, -1.3555e+00,  2.5235e-02,  5.4232e-01, -1.7859e+00,\n",
      "        -5.1749e-01, -1.5637e+00, -1.3385e+00, -1.0195e+00,  1.6429e-01,\n",
      "        -5.0057e-01, -2.4835e-01, -4.4448e-02, -7.7837e-01, -7.6491e-01,\n",
      "        -1.9653e+00, -9.6072e-01, -7.6607e-01, -1.2034e+00,  1.5194e-01,\n",
      "        -2.2694e+00, -1.5887e+00, -5.4815e-02, -7.4091e-01, -1.4749e+00,\n",
      "        -7.7932e-01, -1.5960e+00, -9.2858e-01, -9.6087e-01, -1.5638e+00,\n",
      "         1.4546e-01, -1.5325e+00, -1.6262e+00, -6.7658e-02, -1.3306e+00,\n",
      "        -1.9134e+00, -2.1596e+00,  1.3659e-01, -1.6670e+00, -3.1482e-01,\n",
      "         1.5692e+00, -3.6105e-02, -1.7860e+00, -2.0659e+00,  2.7059e-01,\n",
      "        -3.6476e-01, -4.9153e-01, -5.3267e-01, -1.3874e+00,  4.2893e-01,\n",
      "        -1.4215e+00, -2.7535e+00, -1.5038e+00, -6.1683e-01,  3.6565e-01,\n",
      "         6.0504e-01, -7.9703e-01, -1.2017e-01, -1.3080e-01, -1.7671e+00,\n",
      "        -2.4640e+00, -1.7996e-01, -1.8119e+00, -4.4903e-01, -2.3775e+00,\n",
      "        -1.6826e+00, -6.1142e-01, -2.4876e+00, -1.9356e+00, -1.2986e+00,\n",
      "        -1.1956e+00, -5.7888e-01, -9.4024e-01, -1.0380e-01, -5.7765e-01,\n",
      "        -9.5464e-01, -9.0182e-01, -2.4868e+00, -1.6632e+00, -1.2730e+00,\n",
      "        -1.5367e+00, -1.6109e+00, -3.6457e-01,  1.4146e-01,  5.1472e-01,\n",
      "        -1.9418e+00, -1.7601e+00, -7.4294e-01,  2.8493e-02, -1.3332e+00,\n",
      "        -9.5265e-01, -1.6713e+00, -2.3757e-01, -1.0411e+00, -1.2069e+00,\n",
      "        -1.0002e+00, -5.7992e-01, -1.0872e+00, -1.1746e+00, -9.6000e-01,\n",
      "        -2.3474e+00, -2.6626e+00, -1.5655e+00, -1.5015e+00,  7.7792e-02,\n",
      "         1.1813e-01, -1.5847e+00, -1.4442e+00, -1.6735e+00, -2.6162e-01,\n",
      "        -6.7263e-01, -2.1988e+00, -1.7635e+00, -3.0447e-01, -1.1780e+00,\n",
      "        -1.1154e+00, -5.7956e-02, -1.2945e+00, -1.3221e+00, -4.7499e-01,\n",
      "        -1.0845e+00, -1.3857e+00, -8.4120e-01, -6.9770e-01,  1.6071e-03,\n",
      "        -2.5529e-01, -1.4642e+00, -8.3030e-01, -2.4949e+00, -1.1390e+00,\n",
      "        -2.4392e+00, -1.5796e+00,  2.6721e-02, -3.5464e-01, -1.2453e+00,\n",
      "         4.2272e-01, -2.4657e-01, -1.1090e-01, -1.1948e-01, -1.4121e+00,\n",
      "         1.2423e+00, -2.0859e+00, -1.5583e+00, -1.8929e+00, -2.9559e-01,\n",
      "        -4.5405e-01, -3.7363e-01, -2.0336e-01, -1.3367e+00,  5.0514e-01,\n",
      "        -1.6567e+00, -1.3476e+00,  6.5103e-02, -1.7896e-01,  3.4609e-01,\n",
      "         3.7067e-01, -1.5815e+00, -1.8793e+00,  2.4945e-02, -1.1151e-01,\n",
      "        -1.9727e-01,  5.5132e-02,  1.0983e+00,  9.1182e-01,  3.9068e-01,\n",
      "        -5.2446e-01,  3.4663e-01, -1.3073e+00,  8.5873e-01, -6.8456e-01,\n",
      "        -1.0099e+00, -3.9160e-01, -1.4131e+00, -5.0046e-01, -1.6843e+00,\n",
      "        -1.1472e+00,  2.7424e-02,  2.5427e-01, -1.5967e-01, -1.2094e+00,\n",
      "        -6.0543e-01, -8.9824e-01, -1.7440e+00,  2.5955e-01, -2.1111e+00,\n",
      "        -2.2933e+00,  1.3410e-02, -1.1224e+00,  1.2220e-02, -4.4347e-02,\n",
      "        -2.4242e-01, -1.7374e+00,  1.6301e-01, -1.0463e+00, -1.8969e+00,\n",
      "        -1.2317e+00, -6.7725e-01, -7.8713e-01, -1.3534e-01, -3.0520e+00,\n",
      "        -1.5685e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-2.4379e-01]],\n",
      "\n",
      "         [[-1.3204e-01]],\n",
      "\n",
      "         [[-1.0395e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3452e-01]],\n",
      "\n",
      "         [[ 1.0506e+00]],\n",
      "\n",
      "         [[ 1.0306e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.7857e-02]],\n",
      "\n",
      "         [[ 3.3209e-01]],\n",
      "\n",
      "         [[-1.6170e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4698e-01]],\n",
      "\n",
      "         [[-4.5345e-02]],\n",
      "\n",
      "         [[ 3.5631e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1702e-01]],\n",
      "\n",
      "         [[-7.1003e-02]],\n",
      "\n",
      "         [[ 6.4076e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5273e-01]],\n",
      "\n",
      "         [[-6.4233e-01]],\n",
      "\n",
      "         [[-6.4668e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.3232e-01]],\n",
      "\n",
      "         [[-8.7707e-03]],\n",
      "\n",
      "         [[ 3.9696e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4973e-02]],\n",
      "\n",
      "         [[-5.2919e-02]],\n",
      "\n",
      "         [[-3.3584e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6384e-01]],\n",
      "\n",
      "         [[-1.6420e-02]],\n",
      "\n",
      "         [[ 1.0534e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1454e-01]],\n",
      "\n",
      "         [[-1.6686e-01]],\n",
      "\n",
      "         [[ 2.2457e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5273e-01]],\n",
      "\n",
      "         [[-1.9847e-04]],\n",
      "\n",
      "         [[ 3.4756e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0474e-02]],\n",
      "\n",
      "         [[-4.9791e-01]],\n",
      "\n",
      "         [[-8.8691e-02]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1446, -0.1978,  0.0499,  0.0733,  0.1743,  0.0835,  0.1208, -0.2047,\n",
      "         0.2604,  0.2678,  0.0419, -0.0095,  0.3452,  0.1881,  0.0429,  0.0383,\n",
      "         0.0740, -0.0568, -0.0385,  0.0900, -0.2075,  0.0732,  0.1332,  0.1782],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.3192]],\n",
      "\n",
      "         [[-0.1648]],\n",
      "\n",
      "         [[-0.1952]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3090]],\n",
      "\n",
      "         [[ 0.2336]],\n",
      "\n",
      "         [[ 0.0631]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0967]],\n",
      "\n",
      "         [[ 0.0791]],\n",
      "\n",
      "         [[ 0.3540]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2633]],\n",
      "\n",
      "         [[ 0.3908]],\n",
      "\n",
      "         [[ 0.2162]]],\n",
      "\n",
      "\n",
      "        [[[-0.3576]],\n",
      "\n",
      "         [[ 0.0791]],\n",
      "\n",
      "         [[-0.3882]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2941]],\n",
      "\n",
      "         [[-0.0522]],\n",
      "\n",
      "         [[-0.3508]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1836]],\n",
      "\n",
      "         [[ 0.1446]],\n",
      "\n",
      "         [[ 0.0604]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5396]],\n",
      "\n",
      "         [[-0.3493]],\n",
      "\n",
      "         [[ 0.0886]]],\n",
      "\n",
      "\n",
      "        [[[-0.2528]],\n",
      "\n",
      "         [[-0.4832]],\n",
      "\n",
      "         [[-0.0659]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1375]],\n",
      "\n",
      "         [[-0.2475]],\n",
      "\n",
      "         [[-0.1722]]],\n",
      "\n",
      "\n",
      "        [[[-0.1311]],\n",
      "\n",
      "         [[ 0.4340]],\n",
      "\n",
      "         [[ 0.5394]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3369]],\n",
      "\n",
      "         [[ 0.1849]],\n",
      "\n",
      "         [[ 0.6573]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-8.1689e-03,  3.8689e-01,  5.9237e-02,  1.9656e-01, -1.1394e-01,\n",
      "         2.4684e-01,  3.2649e-01,  4.0909e-01,  3.3247e-01,  9.7573e-03,\n",
      "         4.8853e-01,  4.3091e-02, -1.4780e-01, -2.1778e-01,  1.6392e-01,\n",
      "         4.3169e-01,  1.3717e-01,  3.8117e-01, -2.7300e-01, -4.3973e-02,\n",
      "         2.6217e-03, -2.6323e-01,  6.4367e-02, -2.5414e-01, -4.0166e-01,\n",
      "         1.9709e-01,  1.3259e-01,  1.7276e-01, -4.1559e-02, -6.2352e-02,\n",
      "        -3.7925e-01, -3.2875e-01,  3.9470e-01, -2.2498e-01,  4.3088e-01,\n",
      "        -2.3560e-01, -8.7938e-02,  4.0000e-01,  3.9084e-01,  5.3297e-01,\n",
      "         4.3993e-02, -4.5096e-01,  8.2204e-02, -1.1350e-01,  3.4360e-01,\n",
      "         3.1358e-01,  3.7960e-01,  1.8809e-01,  2.5316e-01,  3.3615e-01,\n",
      "         3.1975e-02, -1.0169e-01,  1.3125e-01,  3.4670e-01,  1.3720e-01,\n",
      "         1.9099e-01, -4.6452e-02, -1.5790e-01, -3.8551e-01, -1.9040e-01,\n",
      "        -3.1244e-01,  4.4895e-01, -4.1386e-02, -3.7627e-01, -4.8640e-02,\n",
      "        -1.4453e-01,  4.4066e-01,  2.4910e-01,  8.6814e-02,  4.6949e-01,\n",
      "         4.5994e-01,  4.7003e-01,  3.6249e-02, -2.6338e-01,  2.5875e-01,\n",
      "        -8.7860e-02,  2.3126e-01, -4.1002e-02,  2.6321e-02, -3.8308e-01,\n",
      "         8.9807e-03, -1.1674e-01,  8.5768e-02,  9.0922e-02, -1.3127e-01,\n",
      "         4.9776e-02,  3.6425e-01,  3.5380e-01,  2.9167e-01,  3.0916e-01,\n",
      "        -4.6143e-02,  6.7209e-03,  4.2270e-02, -3.1738e-01,  3.4669e-01,\n",
      "        -9.0915e-04, -2.0760e-01,  4.0580e-01, -1.4459e-01,  5.0709e-01,\n",
      "         4.0375e-01,  1.8881e-01, -1.9246e-01, -7.1309e-02,  3.9705e-01,\n",
      "         2.4716e-01,  6.8828e-02,  1.6144e-02,  1.4648e-01, -2.0407e-01,\n",
      "        -4.9609e-02,  2.5810e-01, -3.4769e-01, -1.1419e-01, -1.3718e-01,\n",
      "         7.5528e-02,  3.5311e-01,  2.7629e-01,  2.9239e-01, -2.5159e-01,\n",
      "         2.5049e-01,  2.6628e-01,  1.7212e-01, -4.0689e-01,  6.7912e-02,\n",
      "        -3.6415e-01, -4.5719e-02, -1.1812e-01, -3.3840e-01, -7.7004e-02,\n",
      "         2.5322e-01, -9.3260e-02, -1.6318e-01,  3.5279e-01,  1.5894e-01,\n",
      "         1.7847e-02, -4.0498e-01,  9.6401e-02, -1.6612e-01,  4.6546e-01,\n",
      "        -3.9956e-01,  3.3281e-01, -3.1721e-02,  3.8857e-01,  2.4026e-01,\n",
      "         7.2955e-02,  2.5038e-01,  2.3186e-01,  3.3009e-01, -1.9870e-01,\n",
      "         4.2737e-01,  1.3470e-01,  3.7982e-02, -2.9976e-01, -3.0579e-01,\n",
      "        -2.8758e-01, -1.2106e-01, -2.4745e-01,  6.2200e-02, -3.3048e-01,\n",
      "        -2.6910e-01, -2.7698e-01,  1.0718e-01, -4.0383e-02,  4.2893e-01,\n",
      "         3.2333e-01, -2.8192e-01, -2.2262e-01, -3.0865e-01, -3.2689e-01,\n",
      "         3.3703e-01, -4.6400e-02,  7.6078e-02,  2.3888e-02,  3.5799e-01,\n",
      "        -1.8453e-01,  3.4934e-01, -2.8282e-01,  3.0902e-02, -2.1118e-01,\n",
      "         4.7742e-01, -3.5763e-01,  3.6782e-01,  7.9591e-02,  1.2608e-01,\n",
      "        -2.1666e-01, -1.3061e-01,  4.6095e-01,  1.6170e-01, -1.4343e-01,\n",
      "         5.4742e-02,  4.6797e-01, -4.4006e-01, -1.8966e-01,  1.8884e-01,\n",
      "        -1.5761e-01,  3.3375e-02,  2.4689e-01,  1.9814e-01, -3.0844e-01,\n",
      "         2.6888e-01, -2.0477e-01,  6.9302e-02,  3.0752e-01, -5.6518e-02,\n",
      "        -1.1632e-02, -3.0736e-01,  3.4298e-01, -3.2508e-01,  2.0230e-02,\n",
      "         2.8692e-01, -2.9361e-02, -2.2612e-01,  2.1364e-01,  4.5942e-02,\n",
      "        -1.6162e-01, -1.7725e-01, -2.6917e-01, -2.7222e-01,  1.3967e-01,\n",
      "         4.4752e-02,  1.8566e-01, -1.2487e-01,  1.7921e-01, -8.3679e-02,\n",
      "         1.1745e-01, -4.8614e-02,  1.3616e-01,  3.0899e-01,  2.6836e-01,\n",
      "         5.3007e-01,  1.7376e-01, -5.0564e-01,  4.9975e-01,  1.4792e-02,\n",
      "        -7.0459e-02,  2.2709e-01, -2.5615e-01,  3.2020e-01,  3.0564e-02,\n",
      "         3.7594e-01,  2.8940e-01,  1.1317e-01,  3.5133e-01, -4.2902e-02,\n",
      "        -3.3387e-01,  2.8566e-01,  4.7711e-02, -1.4109e-01, -9.8014e-02,\n",
      "        -4.5867e-01, -1.0602e-01,  4.2675e-01,  1.4645e-01,  2.2063e-01,\n",
      "        -2.8707e-02,  4.3505e-02, -4.0849e-01, -6.5008e-02,  3.5210e-01,\n",
      "        -1.7006e-02,  2.4245e-01, -6.0915e-02, -3.7215e-01, -1.5866e-02,\n",
      "        -4.2345e-01,  2.8604e-01, -1.8147e-01,  2.3055e-01,  1.0807e-01,\n",
      "         3.4854e-01, -5.7669e-02,  4.1275e-01, -3.7487e-01, -2.2596e-01,\n",
      "         4.1953e-01,  3.2566e-01,  7.1819e-02, -1.5661e-01,  5.4111e-02,\n",
      "        -2.8089e-01, -8.8486e-02, -3.6714e-01, -2.3632e-01,  9.0847e-02,\n",
      "        -1.5062e-02,  4.2082e-02, -3.5312e-01,  8.6177e-02,  3.5608e-01,\n",
      "        -2.1611e-01, -5.4731e-02, -4.0438e-01, -1.3430e-01, -1.3777e-01,\n",
      "         2.5123e-01,  4.0823e-01, -3.2624e-01, -2.4786e-01, -1.9130e-01,\n",
      "         3.9041e-01, -1.9893e-01, -4.4696e-02, -6.4870e-02,  3.3056e-01,\n",
      "        -2.8778e-01, -1.7378e-01,  3.6525e-01, -8.4216e-02,  4.1429e-01,\n",
      "        -4.2480e-02,  2.2414e-01,  8.9436e-02,  3.2161e-01, -1.2385e-01,\n",
      "        -2.4034e-01,  1.0628e-01,  1.2065e-01,  1.4971e-01,  1.3121e-01,\n",
      "        -1.0846e-02,  3.4422e-01,  1.8897e-01,  2.9913e-01,  2.3340e-01,\n",
      "         1.6408e-01, -3.7368e-01,  1.6249e-02, -1.4382e-01,  4.2613e-01,\n",
      "         1.2131e-01, -4.3159e-01,  2.7786e-02, -3.0956e-01,  4.9252e-02,\n",
      "        -3.4781e-01,  5.0636e-02, -2.5592e-02,  2.7136e-01,  1.5081e-01,\n",
      "        -1.2153e-01,  2.3566e-01,  4.1251e-01,  5.3191e-02, -5.8345e-01,\n",
      "         3.4989e-01, -2.4094e-01, -3.8261e-01,  4.3854e-02, -2.3368e-01,\n",
      "        -1.5311e-01,  2.5836e-01,  4.1408e-01, -2.6782e-01, -8.9230e-02,\n",
      "        -4.3628e-01,  1.0110e-01,  6.7452e-03, -1.4494e-01, -3.8280e-01,\n",
      "         2.4042e-03, -3.3658e-01,  2.9619e-01,  3.1265e-02,  3.3859e-01,\n",
      "        -3.7230e-01, -1.8677e-01, -1.3721e-01,  1.5541e-01,  2.5035e-01,\n",
      "        -1.2103e-01, -7.8406e-04, -1.2329e-01,  3.5450e-01, -1.5000e-01,\n",
      "         8.9926e-03, -4.3253e-02, -1.2425e-02,  1.5112e-01,  2.2540e-01,\n",
      "        -3.8114e-01, -3.9335e-01,  2.0938e-01,  3.2756e-01, -2.6361e-02,\n",
      "         5.0783e-04, -2.4595e-01,  5.0150e-01, -8.0334e-02, -9.8515e-02,\n",
      "         3.5118e-01,  3.0595e-01, -4.0635e-02,  7.6621e-02,  3.0963e-01,\n",
      "        -8.2450e-02, -9.4421e-02, -3.5619e-01,  6.4347e-02,  4.1396e-02,\n",
      "         3.5697e-01,  2.8917e-01, -9.6214e-02,  3.5769e-02,  8.6598e-02,\n",
      "         4.5548e-02, -9.6076e-02, -1.0440e-01, -3.9812e-01, -2.7686e-01,\n",
      "         3.4063e-01,  1.0413e-01, -2.3458e-01,  1.0087e-01,  6.0160e-02,\n",
      "         1.6430e-01, -2.7768e-01,  3.3971e-01,  4.8359e-01, -3.7864e-01,\n",
      "        -1.8003e-01, -1.7126e-01,  2.6739e-01,  1.1044e-01,  7.6595e-03,\n",
      "         3.7857e-01, -3.1937e-01, -3.1486e-01, -6.9493e-02,  2.2744e-01,\n",
      "         6.8408e-02, -1.3812e-01, -2.5015e-01, -2.8367e-01,  1.9954e-01,\n",
      "         3.0884e-01, -1.7864e-01,  1.5121e-01, -2.6890e-02,  6.4276e-02,\n",
      "         3.7979e-02,  4.1565e-01,  4.1363e-01,  3.3571e-01, -6.1340e-02,\n",
      "         5.1103e-01, -1.2569e-02,  4.6309e-01, -3.8834e-01, -3.8615e-02,\n",
      "        -4.2085e-01,  1.5782e-01,  6.5812e-02,  3.7412e-01, -3.5654e-01,\n",
      "        -3.0150e-01,  3.6077e-01,  2.3400e-02, -2.7138e-01, -2.1834e-01,\n",
      "         2.1589e-01,  4.0047e-01, -4.0359e-01, -3.9355e-01, -2.1119e-03,\n",
      "        -2.7162e-03,  1.8855e-01, -1.1286e-01,  2.1699e-02,  2.0485e-01,\n",
      "        -3.7227e-01, -2.2361e-01,  1.6595e-01, -3.9445e-01, -9.5026e-04,\n",
      "         4.4369e-01,  2.2860e-01, -3.4848e-02,  1.1347e-01, -6.3604e-02,\n",
      "        -3.6377e-01,  2.0841e-01, -2.1347e-01, -4.7716e-01,  3.9619e-01,\n",
      "         3.7226e-01,  4.3414e-01, -7.5302e-02, -2.2299e-02, -4.0859e-01,\n",
      "         4.2041e-01, -1.7440e-01, -2.8361e-01,  2.9211e-01,  3.2957e-01,\n",
      "         3.6881e-01,  1.1131e-01,  2.0884e-02, -3.0649e-03,  2.7601e-02,\n",
      "        -2.8659e-01,  2.7565e-01,  2.9992e-01,  2.1808e-01,  1.0936e-01,\n",
      "         3.6527e-01, -1.2644e-01, -4.1396e-01,  8.0896e-02,  9.2963e-02,\n",
      "        -1.6869e-02, -1.1302e-01,  4.0338e-01,  1.6953e-01, -3.4461e-01,\n",
      "        -2.6563e-01,  6.7989e-02, -3.5663e-01, -6.7622e-02,  2.8726e-01,\n",
      "        -1.3497e-01,  2.0862e-01, -2.0980e-02,  5.4773e-02, -1.0508e-01,\n",
      "        -4.9227e-01,  3.8577e-01, -5.6796e-02, -2.6295e-01,  2.2759e-01,\n",
      "         5.1908e-01, -4.1861e-01,  1.1171e-01, -8.7122e-02, -4.0132e-01,\n",
      "         7.3009e-02, -4.3526e-01, -2.3771e-01, -4.6143e-01, -1.0744e-01,\n",
      "         1.6775e-01,  5.5173e-03, -3.4057e-01,  1.5269e-01,  1.4427e-01,\n",
      "         1.0023e-01,  2.8069e-02, -1.1810e-01, -2.7129e-01,  3.2071e-02,\n",
      "         4.9407e-01, -6.3456e-03, -7.1226e-02, -4.1504e-01,  5.5727e-02,\n",
      "        -3.8591e-02, -7.4237e-02,  4.0334e-01, -3.5708e-01,  2.7464e-01,\n",
      "        -4.7235e-01, -4.0321e-02,  4.2046e-01, -9.6683e-02, -1.8285e-01,\n",
      "         1.6011e-01,  2.1292e-01, -5.6782e-02,  2.0621e-01,  3.0454e-01,\n",
      "        -1.4178e-01,  4.4402e-01, -1.5076e-02, -1.5904e-01,  5.1661e-02,\n",
      "         1.6668e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.1854]],\n",
      "\n",
      "         [[ 0.0011]],\n",
      "\n",
      "         [[ 0.1584]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2004]],\n",
      "\n",
      "         [[ 0.1441]],\n",
      "\n",
      "         [[ 0.8617]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0310]],\n",
      "\n",
      "         [[-0.3016]],\n",
      "\n",
      "         [[ 0.2347]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6408]],\n",
      "\n",
      "         [[ 0.1984]],\n",
      "\n",
      "         [[ 0.8615]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1331]],\n",
      "\n",
      "         [[-0.0403]],\n",
      "\n",
      "         [[ 0.0395]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2479]],\n",
      "\n",
      "         [[-0.0866]],\n",
      "\n",
      "         [[-0.1341]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2520]],\n",
      "\n",
      "         [[-0.5975]],\n",
      "\n",
      "         [[-0.2312]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0273]],\n",
      "\n",
      "         [[ 0.4613]],\n",
      "\n",
      "         [[-0.1550]]],\n",
      "\n",
      "\n",
      "        [[[-0.0066]],\n",
      "\n",
      "         [[-0.5989]],\n",
      "\n",
      "         [[-0.2596]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1356]],\n",
      "\n",
      "         [[-0.1715]],\n",
      "\n",
      "         [[-0.5214]]],\n",
      "\n",
      "\n",
      "        [[[-0.3236]],\n",
      "\n",
      "         [[ 0.2278]],\n",
      "\n",
      "         [[ 0.3211]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1378]],\n",
      "\n",
      "         [[-0.0942]],\n",
      "\n",
      "         [[-0.4783]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.5309, 1.0685, 0.9166, 1.0427, 0.2757, 0.3193, 0.4507, 0.5020, 2.5335,\n",
      "        0.8875, 1.4826, 0.1774, 1.0786, 2.2966, 1.1459, 0.4998, 1.7417, 1.0801,\n",
      "        1.0925, 2.3529, 0.8349, 1.7416, 0.8357, 0.6646, 0.7768, 1.0899, 0.9689,\n",
      "        0.4033, 0.1179, 1.1808, 0.3750, 1.2470, 1.8675, 0.9678, 0.5679, 1.0980,\n",
      "        2.0375, 0.9078, 2.7274, 1.9789, 0.5964, 0.7996, 0.4238, 1.4912, 0.0934,\n",
      "        0.5171, 0.8825, 0.0703, 0.1331, 0.9514, 0.9890, 0.7767, 0.6906, 1.8344,\n",
      "        0.3957, 0.5305, 0.6910, 0.0763, 1.0345, 1.6738, 0.5775, 1.0752, 1.6965,\n",
      "        1.0068, 1.4222, 1.0038, 0.9266, 0.7186, 2.0483, 0.6555, 1.1348, 0.3438,\n",
      "        0.3853, 0.9063, 0.8382, 1.1908, 1.2185, 0.3781, 0.8696, 1.1951, 0.5180,\n",
      "        2.0358, 1.9582, 0.5096, 1.6978, 1.4107, 0.1850, 0.4663, 0.6254, 0.3513,\n",
      "        0.8138, 0.7268, 0.9162, 0.5664, 1.0242, 0.8554], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.4700, -0.0272,  0.2028, -0.7623,  0.2614,  0.7852, -0.4069, -0.3273,\n",
      "        -0.3888, -0.3225,  0.4654,  1.1165,  0.2709,  1.7515, -0.1744, -0.1813,\n",
      "         0.8014, -0.3399,  0.0313, -1.7225,  0.0704, -0.2368, -0.0099,  0.2426,\n",
      "         1.1860,  0.5008,  0.7242,  0.2125, -0.4296,  0.6379,  0.4622, -0.0663,\n",
      "        -0.2287, -0.9232,  0.2920, -0.2085,  0.3134,  1.0882,  0.0191,  0.0542,\n",
      "        -0.7266, -0.8770,  0.0473,  0.3485, -0.4526, -0.1788, -0.1744,  0.5235,\n",
      "         0.6377,  0.2275,  0.5011,  0.3873,  0.4661, -0.6064, -0.5621,  0.3292,\n",
      "         1.0090,  0.1716, -0.1440,  0.2418,  0.3671,  0.0848, -0.7968, -0.9687,\n",
      "         0.6981, -1.0308,  0.2232,  0.5889, -0.4453,  0.2105, -0.4378,  0.2752,\n",
      "        -0.2905,  0.3188,  0.6877,  0.3127,  0.2052,  0.9059,  0.0120, -0.1604,\n",
      "        -0.4459,  0.2785, -0.0303, -0.8840,  1.1905, -0.8044,  0.7389,  0.3836,\n",
      "         0.3598,  0.2321,  0.3395, -0.1607,  0.2453, -0.4279,  0.2657,  0.2852],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0946]],\n",
      "\n",
      "         [[ 0.3158]],\n",
      "\n",
      "         [[ 0.4348]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1157]],\n",
      "\n",
      "         [[ 0.2332]],\n",
      "\n",
      "         [[-0.3041]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4387]],\n",
      "\n",
      "         [[-0.0567]],\n",
      "\n",
      "         [[ 0.3045]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6236]],\n",
      "\n",
      "         [[ 0.4741]],\n",
      "\n",
      "         [[-0.0404]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1808]],\n",
      "\n",
      "         [[ 0.0776]],\n",
      "\n",
      "         [[-0.0052]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7323]],\n",
      "\n",
      "         [[ 0.2100]],\n",
      "\n",
      "         [[-0.0673]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0037]],\n",
      "\n",
      "         [[-0.4884]],\n",
      "\n",
      "         [[ 0.1199]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2684]],\n",
      "\n",
      "         [[-0.1108]],\n",
      "\n",
      "         [[-0.0662]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0996]],\n",
      "\n",
      "         [[ 0.6309]],\n",
      "\n",
      "         [[ 0.0757]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6488]],\n",
      "\n",
      "         [[-0.3607]],\n",
      "\n",
      "         [[ 0.3051]]],\n",
      "\n",
      "\n",
      "        [[[-0.0379]],\n",
      "\n",
      "         [[-0.1300]],\n",
      "\n",
      "         [[-0.2192]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0764]],\n",
      "\n",
      "         [[ 0.2672]],\n",
      "\n",
      "         [[ 0.1125]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.1763,  0.8487,  0.7523,  1.1961,  0.2038,  0.5157,  0.3527,  1.0900,\n",
      "         0.8083,  0.3085,  1.9163,  1.1482,  0.9895,  1.3880,  1.3853,  1.5223,\n",
      "         0.2874,  0.0752,  0.4358,  0.8048,  1.1642,  0.5523,  0.9735,  0.9248,\n",
      "         1.2560,  0.5581,  0.8986,  1.1488,  1.3350,  0.9720,  0.5829,  1.1346,\n",
      "         0.5931,  0.5595, -0.0893,  1.3345,  0.7307,  1.1532,  0.8624,  0.8276,\n",
      "         0.5429,  1.5792, -0.1366,  0.5732,  0.8852,  0.8381,  1.7670,  2.0689,\n",
      "         1.7192,  1.5016,  1.6898,  0.4809,  1.1429,  0.9603,  0.5338,  0.6951,\n",
      "         0.9853,  0.6783,  0.6344,  1.2045,  0.6336,  0.6597,  0.8164,  0.7833,\n",
      "         1.4402,  1.0394,  0.7764,  0.7288,  0.8163,  0.5214,  0.9212,  0.9985,\n",
      "         0.3898,  1.6227,  1.1053,  0.4725,  1.0445,  1.0344,  1.1169,  0.8207,\n",
      "         1.2628,  1.4388,  1.3078,  0.7980,  1.0876,  0.4689,  0.5219,  1.3873,\n",
      "         0.4443,  1.1134,  0.9719,  1.2057,  0.8816,  0.6020,  1.4389,  1.0196,\n",
      "         0.3859,  0.9808,  1.1445,  1.3323,  1.4399,  1.8553,  0.9647,  0.9378,\n",
      "         0.2470,  0.9206,  0.0456,  1.9609,  1.5436,  0.2416,  1.1066,  1.5620,\n",
      "         0.9640,  1.2571,  0.4434,  0.6967,  1.0756,  1.0633,  0.8091,  1.0669,\n",
      "         0.2782,  1.2577,  0.4325,  0.6838,  1.5854,  1.1766,  1.1602,  0.9226,\n",
      "         1.0938,  1.9982,  0.9260,  0.3894,  1.2129,  0.3968,  1.4069,  0.9371,\n",
      "         0.9086,  1.2726,  1.3540,  1.0501,  0.7345,  0.5223,  0.7280,  1.1428,\n",
      "         1.4094,  0.7184,  0.7815,  0.9054,  0.7200,  1.3954,  1.1021,  0.0986,\n",
      "         0.3396,  1.1586,  0.9512,  0.3999,  1.1636,  1.2668,  0.5565,  1.1265,\n",
      "         1.0799,  0.3634,  1.0960,  1.5318,  1.1059,  1.1217,  1.0488,  0.9322,\n",
      "         0.6370,  1.2639,  0.5824,  1.4604,  0.1975,  0.0091,  0.2620,  1.8225,\n",
      "         2.4135,  0.6862,  1.4395,  1.4971,  0.2990,  1.4191,  0.4523,  1.4042,\n",
      "         0.3000,  0.3614,  0.7232,  0.5653,  1.3206,  1.0040,  1.4740,  0.8989,\n",
      "         0.0544,  1.1172,  1.4973,  0.8578,  1.0315,  0.3318,  1.0697,  1.3669,\n",
      "         2.4245,  1.2510,  0.8555,  0.2995,  0.2041,  0.3744,  0.7438,  1.7804,\n",
      "         2.2265,  1.5519,  1.0023,  0.3031,  0.8477,  1.1353,  1.5998,  1.3617,\n",
      "         1.3421,  0.9146,  0.4110,  1.2774,  1.2287,  0.7246,  0.8507,  0.1923,\n",
      "         0.3233,  0.7159,  0.5516,  0.5390,  0.9936,  1.5679,  0.9467,  0.7126,\n",
      "         0.2469,  0.2126,  0.7697,  1.4811,  0.6334,  1.1660,  1.3854,  1.5852,\n",
      "         1.1242,  0.3246,  0.9955,  0.9254,  0.6166,  0.8319,  1.4077,  1.1098,\n",
      "         0.0611,  0.5830,  0.2960,  0.4786,  0.6826,  0.4329,  0.5025,  0.5242,\n",
      "         0.3984,  1.5734,  0.9311,  1.2655,  1.0198,  0.2332,  0.8187,  1.1156,\n",
      "         0.4314,  1.2445,  0.5319,  1.8532,  1.1387,  1.1468,  0.4996,  0.0954,\n",
      "         1.2149,  0.8356,  0.1917,  0.8287,  0.6760,  0.8002,  1.0526,  0.8216,\n",
      "         1.1480,  0.3158,  0.9212,  1.2154,  0.7069,  1.2926,  0.9143,  0.6695,\n",
      "         0.7647,  0.2345,  1.0958,  1.0918,  0.5911,  2.1434,  1.2407,  0.5044,\n",
      "         0.8947,  0.9693,  1.0727,  0.7051,  1.2625,  1.8133,  0.2801,  0.6705,\n",
      "         1.0113,  0.5954,  2.5316,  0.2167,  1.9252,  0.6782,  1.0609,  0.5483,\n",
      "         2.6525,  1.3643,  0.8023,  1.2794,  0.2845,  0.3102,  0.1299,  0.5457,\n",
      "         0.7857,  0.8754,  0.8003,  1.5579,  0.3004,  1.5946,  1.3295,  1.6544,\n",
      "         1.0232,  1.6759,  0.9902,  0.8064,  1.2499,  0.8083,  0.9445,  0.8403,\n",
      "         1.1080,  0.4190,  0.4761,  0.8185,  1.6997,  1.4074,  0.8787,  1.2147,\n",
      "         1.5225,  0.5282,  1.7036,  0.7062,  0.6681,  1.3325,  0.8814,  1.1021,\n",
      "         1.2945,  0.9342,  0.4872,  0.9255, -0.1113,  0.7095,  1.1425,  1.1890,\n",
      "         0.0544,  0.4834,  1.0997,  0.4778,  1.1484,  0.2743,  0.2992,  0.3925,\n",
      "         1.3685,  0.8826, -0.0459,  0.6651,  0.8404,  0.3414,  1.4112,  1.5732,\n",
      "         0.6882,  1.0753,  0.0703,  1.5166, -0.0758,  1.1225,  0.4104,  1.2039,\n",
      "         0.8311,  0.9707,  1.0168,  1.3864,  0.3110,  0.9102,  1.1607,  1.8634,\n",
      "         1.0179,  2.1369,  0.6579,  0.9162, -0.1123,  0.6192,  1.2082,  0.8623,\n",
      "         0.2332,  0.5981,  0.9812,  1.1374,  0.8184,  0.7334,  0.6384,  0.9588,\n",
      "         1.7450,  0.9479,  0.1664,  0.5291,  0.9578,  2.1042,  1.5901,  0.1529,\n",
      "         1.6983,  0.9909,  1.5555,  0.7548,  0.3412,  0.9612,  2.0668,  1.4880,\n",
      "         1.4193,  2.0785,  1.5798,  0.2990,  0.3668,  1.7583,  0.8346,  1.2682,\n",
      "         1.0146,  1.0960,  0.8287,  1.5205,  0.3761,  2.2201,  1.5869, -0.2017,\n",
      "         0.9607,  0.4794,  0.6244,  0.4770,  0.7876,  0.7146,  0.7022,  0.3928,\n",
      "         0.2925,  0.8286,  1.6233,  0.8118,  1.6818,  1.8880,  0.8131,  1.2234,\n",
      "         0.9452,  0.2491,  0.9941,  0.3907,  0.7489,  0.5795,  1.2304,  1.9268,\n",
      "         0.5375,  1.5617,  1.1534,  1.0598,  2.0658,  0.9072,  1.2263,  0.6905,\n",
      "         0.5122,  0.7767,  0.3162,  1.1740,  1.5537,  1.0779,  1.8562,  0.7222,\n",
      "         0.6478,  1.1422,  1.3147,  1.2776,  0.2659,  0.1324,  1.5820,  0.9241,\n",
      "         1.2549,  0.8554,  0.1427,  0.1871,  0.3339,  1.2148,  0.6392,  1.8167,\n",
      "         1.3569,  0.3476,  0.5609,  1.1692,  1.0773,  0.8768,  0.8463,  0.4779,\n",
      "         1.0932,  1.6188,  0.8557,  0.6828,  0.7677,  1.3878,  1.5648,  0.9284,\n",
      "         1.0151,  0.9373,  1.1547,  0.6212,  0.7118,  1.0702,  1.0712,  1.0954,\n",
      "         0.4651,  1.0662,  0.1264,  0.9341,  0.5738,  1.4271,  1.2342,  1.8462,\n",
      "         0.6822,  0.8656,  1.4313,  0.4572,  0.9419,  0.7825,  1.0591,  0.1645,\n",
      "         0.4594,  0.8223,  0.5677,  1.0651,  0.4568,  1.3808,  1.6461,  1.0320,\n",
      "         0.7319,  1.2564,  0.2938,  1.1506,  0.7206,  1.0811,  1.5620,  1.5846,\n",
      "         0.7878,  1.6340,  0.6372,  1.4336,  0.4971,  1.5352,  1.3375,  1.1253,\n",
      "         0.9136,  1.4002,  0.9265,  0.7630,  0.5513,  0.6490,  0.8404,  0.8331,\n",
      "         1.0969,  1.1403,  0.5806,  0.8166,  0.2468,  1.0516,  1.6631,  0.8312],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-6.9903e-01, -1.2573e+00,  5.8686e-01, -1.1919e+00,  1.5608e-01,\n",
      "         2.2500e-01,  2.1038e-01,  1.0780e+00, -4.0934e-01,  1.1766e-01,\n",
      "         1.1170e-01,  1.4137e-01, -1.3662e+00, -1.5197e+00, -1.2821e+00,\n",
      "         6.3392e-01,  1.3803e-01, -6.3719e-01,  5.2136e-01,  4.1280e-01,\n",
      "        -7.3342e-01,  1.4777e-01, -6.9625e-01,  3.0509e-01, -7.0899e-01,\n",
      "        -4.9886e-01,  4.7291e-01, -1.9100e+00, -9.4036e-01,  4.8036e-01,\n",
      "        -5.0147e-01, -1.0004e+00,  3.0392e-02,  9.0306e-02, -9.4435e-02,\n",
      "        -1.4590e+00,  2.7903e-02,  3.2090e-02,  1.1201e-01, -2.6704e-01,\n",
      "         6.9768e-01, -7.6887e-01, -1.3128e-01,  3.7805e-01, -1.2144e+00,\n",
      "        -3.3139e-01, -6.8261e-01,  4.0756e-01, -1.1992e-01, -8.0991e-01,\n",
      "        -1.9106e+00, -2.9312e-01,  8.3532e-02, -1.4568e+00, -5.9546e-01,\n",
      "        -4.3156e-01,  1.0215e+00, -6.6392e-01,  3.7456e-01,  5.3492e-01,\n",
      "        -6.1133e-01,  1.5105e-01,  1.0047e+00,  3.8504e-01, -1.3055e-01,\n",
      "         1.0157e+00, -7.2677e-01,  1.2801e+00, -1.8879e+00,  1.0520e-01,\n",
      "        -1.5385e+00,  9.6344e-02,  2.8789e-01, -3.5807e-01, -7.0071e-01,\n",
      "         7.5877e-01, -7.6801e-01,  9.1229e-02, -5.8350e-02, -2.1778e+00,\n",
      "         8.7338e-01, -4.5792e-01,  7.2825e-01,  4.7413e-01,  1.9478e-01,\n",
      "         1.6171e+00,  4.9671e-01, -5.6857e-01, -5.0522e-02, -1.4830e-01,\n",
      "        -1.3831e+00, -9.2517e-01, -2.5385e-01, -8.2870e-02,  1.3013e-02,\n",
      "        -6.5856e-01, -3.0207e-01, -3.6522e-01, -1.0935e+00, -2.3447e-01,\n",
      "        -7.4591e-01, -1.8346e+00, -1.6741e+00,  3.7925e-01,  5.2375e-01,\n",
      "         8.9192e-01, -7.4667e-01, -2.3859e-01,  6.5833e-01, -2.5694e-02,\n",
      "         7.2737e-01, -1.0490e+00,  8.4199e-01, -1.7762e-01,  1.3732e-01,\n",
      "         1.0993e+00, -1.4159e+00,  7.3626e-01, -5.2024e-01, -9.3325e-01,\n",
      "        -1.5446e-01, -1.6602e+00,  1.8645e-01, -1.7272e+00, -1.9438e-01,\n",
      "         5.7568e-01,  1.0033e-01,  9.5595e-01, -1.8255e+00, -5.6047e-01,\n",
      "         3.4071e-01,  7.8825e-03, -1.7101e+00,  3.8985e-03, -2.6560e-01,\n",
      "        -4.9286e-01, -1.2644e+00,  1.0238e+00, -1.6061e+00,  2.6072e-01,\n",
      "        -3.2337e-01,  2.9547e-01, -2.1714e-01, -1.5635e+00,  8.9878e-01,\n",
      "         1.0130e-02, -1.2812e-01, -3.5559e-01,  6.1728e-01,  1.4078e-01,\n",
      "         5.6563e-01, -2.1252e-01,  2.1028e-01,  6.8457e-02, -4.7778e-01,\n",
      "        -1.7715e+00,  2.6800e-01,  1.6713e-01,  2.1768e-01, -2.0229e+00,\n",
      "         1.3546e+00,  6.0179e-01,  7.1153e-01,  2.0876e-01, -1.0832e+00,\n",
      "         2.9211e-01, -1.3519e+00,  4.6024e-01, -1.4849e+00, -3.0386e-03,\n",
      "         1.9733e-01, -5.6479e-01,  1.2157e+00,  2.5249e-01, -2.2644e-01,\n",
      "        -9.2559e-01, -6.1301e-01,  2.8261e-01, -8.8545e-01,  2.5699e-01,\n",
      "         8.7324e-02, -1.1575e+00,  5.0745e-01, -4.4888e-01,  4.7598e-01,\n",
      "        -1.0714e-01, -1.4564e-01,  6.4379e-01, -1.0517e+00, -8.3295e-01,\n",
      "        -8.8496e-02,  1.1438e+00,  7.8998e-01,  1.9994e+00,  1.8147e-02,\n",
      "        -1.7202e-01,  9.7358e-01,  1.1433e-01,  1.4444e-01, -6.5652e-01,\n",
      "        -1.6626e+00, -2.6324e-02, -1.2880e+00,  5.0642e-01,  1.2002e-01,\n",
      "         1.8597e-01,  1.3999e+00,  1.5040e-01, -1.4583e-01, -1.1641e+00,\n",
      "        -2.4086e-01,  3.1824e-01,  5.9577e-01,  1.0690e-01,  9.7752e-01,\n",
      "        -7.9595e-01, -5.0688e-01,  7.6727e-02,  1.8736e+00, -1.7513e-01,\n",
      "        -4.9499e-01,  6.0868e-01, -1.5379e+00,  2.0555e-01,  2.8509e-01,\n",
      "         5.9859e-01, -2.4127e-01,  4.6069e-02,  7.9720e-01,  4.5180e-01,\n",
      "        -8.1481e-01, -7.5273e-02,  6.9638e-01,  1.1558e+00,  1.3932e+00,\n",
      "        -1.6100e+00, -1.7063e+00, -2.6190e-01, -2.5864e-01, -2.0765e+00,\n",
      "        -1.2476e+00, -8.1355e-03,  6.1251e-01, -1.4694e+00,  8.1391e-01,\n",
      "         1.2289e+00,  2.2241e-01, -1.5710e+00, -7.9312e-01,  4.5860e-01,\n",
      "         8.3933e-02,  6.1422e-01, -1.0651e+00,  6.8821e-01,  6.9988e-02,\n",
      "         1.2886e+00,  7.8362e-01, -5.9849e-01,  1.0620e+00, -5.4947e-01,\n",
      "         4.5963e-01, -2.0197e-01,  4.3659e-02, -2.4080e+00, -5.2337e-01,\n",
      "         9.7514e-01,  6.4202e-01,  3.2561e-01, -1.0916e+00,  1.3570e+00,\n",
      "         4.7469e-01,  9.6941e-01, -1.6285e+00, -1.4568e+00,  3.5544e-01,\n",
      "        -1.2445e+00,  1.3001e-01,  8.8167e-01,  2.8329e-01,  9.1619e-01,\n",
      "         1.3766e-01,  7.1280e-01,  5.6059e-01,  7.4696e-01, -1.4795e+00,\n",
      "        -2.1483e-02, -1.1787e+00,  4.4521e-01,  1.0990e+00,  2.9918e-01,\n",
      "        -1.1402e+00, -1.3670e+00,  3.3699e-01,  2.9195e-01, -4.1262e-02,\n",
      "         2.5220e-01, -1.0105e+00,  4.0519e-01, -2.0387e-01,  9.5769e-01,\n",
      "        -3.2101e-01, -8.4185e-01,  7.6678e-01, -4.8904e-01, -1.2836e+00,\n",
      "         3.1935e-01,  2.5502e-01, -6.8970e-02,  1.0645e+00,  8.6255e-01,\n",
      "         1.0086e+00,  1.5543e-01, -5.6781e-01, -1.6126e+00,  1.3343e+00,\n",
      "        -3.7037e-01,  1.5368e-02,  4.1954e-01,  1.9786e-01,  1.2532e+00,\n",
      "        -6.4259e-01, -1.0046e+00,  6.4122e-01, -1.3984e-01,  5.9956e-01,\n",
      "         3.4067e-01, -8.6723e-01, -1.4847e+00, -4.0155e-01, -1.4448e-01,\n",
      "        -1.7381e+00,  6.3141e-01, -5.7470e-01, -1.9064e-01,  4.3796e-01,\n",
      "        -5.4612e-01,  7.7044e-01,  6.4875e-01,  1.2994e+00,  4.5344e-01,\n",
      "         2.1606e-01, -2.6022e+00,  7.7088e-01,  2.2681e-01, -1.2747e+00,\n",
      "         1.4737e+00, -7.2158e-01, -7.2820e-02,  7.2396e-01, -1.0083e+00,\n",
      "        -1.2700e-01,  4.0551e-01, -1.6122e-01, -6.4224e-01, -1.6546e+00,\n",
      "         6.1380e-01, -3.8353e-01, -3.2466e-02, -7.3674e-02,  7.5524e-01,\n",
      "         3.0280e-01,  7.6095e-01, -1.1725e+00, -1.3044e+00,  1.6704e-01,\n",
      "         3.3193e-01,  9.0347e-04,  1.3136e+00, -3.4211e-01, -6.0592e-01,\n",
      "        -1.3783e+00,  3.1452e-01,  6.5848e-01, -5.1235e-02,  1.9065e+00,\n",
      "        -1.8657e+00, -2.7480e-01, -6.7709e-01,  1.2587e+00, -5.9794e-01,\n",
      "         6.3697e-01, -5.6468e-01,  8.2480e-01, -1.0180e+00, -1.6701e+00,\n",
      "        -6.9620e-01, -1.7890e+00,  7.1801e-01,  1.8860e+00, -7.6675e-01,\n",
      "         6.3862e-01, -5.5433e-02, -8.1321e-01, -2.7259e+00, -4.2226e-01,\n",
      "        -1.5965e+00,  1.0420e+00, -1.3462e-01,  5.2014e-02, -2.0308e+00,\n",
      "        -9.7586e-01,  9.4712e-01,  3.5047e-01, -1.3516e+00,  1.3635e+00,\n",
      "        -1.8696e-01, -2.2907e-01, -2.9126e-01,  5.3450e-01,  5.4775e-01,\n",
      "         4.8189e-01, -5.7243e-03, -4.5972e-02, -7.2415e-01, -6.7484e-01,\n",
      "        -2.1264e-01, -1.5305e-01, -2.6149e+00,  4.9394e-01, -3.4761e-01,\n",
      "        -2.9432e-01,  1.1578e+00, -3.3189e+00,  1.1813e+00,  3.9530e-01,\n",
      "        -2.4903e-01, -1.5223e+00,  1.4563e+00,  2.7632e-02,  2.8477e-02,\n",
      "        -4.1385e-01, -5.0961e-01,  8.5701e-02, -7.0270e-01, -1.4671e+00,\n",
      "        -3.0157e-02,  3.8112e-02, -2.2922e+00, -3.7455e-02,  3.5607e-02,\n",
      "         5.4917e-01,  5.4474e-01, -1.9427e+00,  8.3593e-02, -1.0005e-01,\n",
      "        -9.0938e-02, -3.3137e-01,  7.2442e-01,  1.2005e+00,  8.7175e-01,\n",
      "        -1.7442e+00, -5.2462e-01, -2.5332e+00, -1.5416e+00,  8.7612e-01,\n",
      "        -1.2810e+00, -7.4424e-01,  6.2076e-01,  6.3389e-01,  3.9359e-02,\n",
      "        -1.5201e+00, -1.1102e-01, -6.1541e-01, -1.1313e+00, -1.2613e-01,\n",
      "         1.4126e-01,  4.7202e-01, -1.4747e+00,  1.0980e+00,  8.0105e-01,\n",
      "        -4.8839e-02,  7.2482e-01, -1.3897e-01, -1.1977e+00,  9.3533e-02,\n",
      "        -5.8886e-01, -1.1112e-01, -1.2189e-01,  4.2151e-01,  3.3269e-01,\n",
      "         6.0101e-01,  4.3257e-01,  1.1904e+00, -1.6652e+00,  1.3761e-01,\n",
      "         9.6176e-01, -1.4035e+00,  6.3893e-01,  2.3357e-01,  7.5025e-01,\n",
      "         4.6269e-01,  6.2247e-01,  1.1311e-01, -5.8949e-01, -8.5037e-01,\n",
      "         1.9783e-01, -5.2285e-01,  3.3187e-01,  9.0281e-01, -3.2767e-01,\n",
      "        -3.2434e-01,  3.7104e-01, -9.3539e-01, -1.8012e-01, -7.1740e-01,\n",
      "        -5.7353e-01,  8.4981e-01,  6.1574e-01, -1.1752e+00, -9.0886e-01,\n",
      "         7.7744e-03,  3.8863e-01, -1.2334e+00, -1.8832e-01, -3.4441e-01,\n",
      "        -1.0965e+00,  2.7339e-01, -9.6324e-01, -1.9083e-01, -1.3811e+00,\n",
      "        -4.8706e-01,  4.5460e-01,  8.5128e-01,  4.8647e-01,  1.5674e+00,\n",
      "        -3.9530e-01, -2.6970e-01, -7.9168e-01, -2.8904e-01, -2.0693e-01,\n",
      "        -5.7105e-01,  8.8600e-01,  1.3353e+00,  1.4318e-01, -2.9200e-02,\n",
      "         1.3433e+00, -1.9588e-01,  2.1507e-01, -1.9032e-01, -1.6396e+00,\n",
      "         7.1771e-01,  1.3385e+00, -4.0382e-01, -6.2597e-01, -1.0808e-01,\n",
      "         2.5153e-01, -4.5743e-02, -4.3776e-01,  4.4403e-01,  1.2624e+00,\n",
      "         2.2811e-01, -8.4388e-01,  4.5453e-01, -5.4465e-01,  4.8157e-01,\n",
      "         2.5203e-01,  3.6344e-01, -1.9044e+00, -1.4576e+00,  1.0860e+00,\n",
      "         2.2688e-01, -6.1046e-01, -6.9646e-02, -1.1948e+00, -8.4680e-01,\n",
      "        -1.7508e+00,  8.7247e-01, -4.0204e-01, -8.4493e-03, -1.2464e+00,\n",
      "         2.5540e-01,  1.6970e-01,  3.2298e-01,  4.2924e-01,  6.7757e-01,\n",
      "         1.4492e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.3788,  0.3690,  0.2931],\n",
      "          [ 0.3077,  0.2300,  0.1480],\n",
      "          [ 0.4210,  0.4488,  0.3494]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4263,  0.1687, -0.0279],\n",
      "          [-0.0495,  0.6833,  0.1769],\n",
      "          [ 0.1267,  0.4717,  0.2746]]],\n",
      "\n",
      "\n",
      "        [[[-0.2650, -0.3697, -0.4050],\n",
      "          [-0.0315,  0.4219,  0.2742],\n",
      "          [-0.2668, -0.3566,  0.0045]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1206, -0.1011,  0.2278],\n",
      "          [ 0.1804, -0.7573,  0.5046],\n",
      "          [ 0.2393,  0.0744,  0.1724]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7008,  0.5828, -0.1900],\n",
      "          [-0.0767, -0.1398, -0.2895],\n",
      "          [-0.2774, -0.1262,  0.0772]]],\n",
      "\n",
      "\n",
      "        [[[-0.7358, -0.2314, -0.2321],\n",
      "          [-0.2416,  0.4488, -0.1794],\n",
      "          [-0.1023, -0.1604, -0.4393]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.3337,  2.3035,  0.4589,  1.0242,  1.4632,  1.8331,  2.1390,  2.0121,\n",
      "         1.4531,  0.5420,  1.4946,  1.6230,  1.2077,  1.0280,  3.4172,  1.8543,\n",
      "         1.4309,  1.6078,  1.6334,  1.1392,  0.8401,  1.4888,  1.4472,  2.0822,\n",
      "         1.6727,  1.8457,  0.7630,  1.1076,  2.2782,  1.8454,  1.2018,  1.4899,\n",
      "         1.6379,  2.1265,  1.7522,  1.0727,  1.2920,  1.4415,  1.3650,  1.6115,\n",
      "         2.3064,  1.4633,  1.7005,  1.4775,  1.6396,  1.6691,  0.8522,  1.8559,\n",
      "         1.2265,  1.0046,  2.7785,  0.9954,  1.2389,  1.6019,  1.2241,  1.4276,\n",
      "         2.2939,  1.3687,  2.0705,  1.1070,  1.4496,  1.6506,  1.6624,  1.6267,\n",
      "         1.0907,  2.1056,  0.7279,  1.9493,  1.3950,  1.6207,  0.9733,  1.2491,\n",
      "         1.7703,  0.4457,  1.2940,  2.0329,  1.6618,  1.2941,  1.2380,  0.5556,\n",
      "         2.5975,  1.5958,  1.4315,  0.9453,  1.7400,  1.9978,  1.4159,  1.2182,\n",
      "         1.9824,  0.5974,  1.1330,  2.9157,  1.6668,  0.5470,  0.7677,  1.2911,\n",
      "         1.4286,  1.3342,  0.4356,  0.7483,  2.3657,  1.9691,  0.5962,  1.5194,\n",
      "         1.3200,  0.4083,  1.5405,  1.0163,  1.7627,  2.1132,  1.3847,  2.1046,\n",
      "         1.5543,  1.5337,  2.0607,  1.6981,  1.0342,  1.7973,  0.7287,  1.5151,\n",
      "         1.8413,  3.2742,  1.7311, -0.1553,  1.6347,  1.4800,  0.9409,  1.6592,\n",
      "         1.2640, -0.1840,  0.9702,  1.6225,  0.8575,  1.8253,  1.1395,  0.9431,\n",
      "         1.8071,  2.1613,  1.4781,  1.9504,  1.6415,  1.8615,  1.6632,  1.7678,\n",
      "         2.1224,  2.1535,  1.8271,  1.0269,  3.0089,  1.4213,  0.9134,  1.7425,\n",
      "         1.6963,  1.7003,  1.0101,  1.8929,  1.4358,  1.4251,  1.9562,  2.3019,\n",
      "         2.0195,  1.7235,  2.0733,  2.2472,  0.8945,  2.2876,  1.1304,  1.1333,\n",
      "         1.7722,  1.3145,  1.8742,  1.5802,  1.5910,  1.2248,  1.7092,  3.0698,\n",
      "         1.8760,  1.9754,  1.2366,  1.7014,  1.6615, -0.0129,  1.5305,  1.5513,\n",
      "         1.8722,  1.0128,  1.9869,  1.6144,  1.6682,  2.2942,  1.2124,  1.6669,\n",
      "         1.8375,  2.3106,  1.9555,  1.4698,  1.5043,  1.2147,  1.9805,  1.1356,\n",
      "         4.4339,  1.0684,  1.6153,  1.5426,  1.9391,  0.8625,  2.6066,  2.9871,\n",
      "         1.5588,  2.0870,  1.5008,  1.5377,  1.9328,  1.6905,  1.7507,  1.2337,\n",
      "         1.1466,  1.4278,  1.8248,  1.4829,  1.0644,  1.3245,  1.1828,  3.7828,\n",
      "         1.7260,  1.8014,  1.4011,  1.4006,  1.7839,  1.9258,  1.6768,  1.4568,\n",
      "         1.3848,  1.6200,  2.1237,  1.6750,  2.1353,  1.0942,  1.1368,  2.8841,\n",
      "         1.0144,  1.4925,  0.9977,  0.5140,  1.9956,  1.7616,  0.4928,  1.6383,\n",
      "         0.8992,  1.5054,  1.5447,  1.6252,  1.4133,  1.6083,  2.1461,  1.3716,\n",
      "         2.6361,  1.8598,  2.0308,  1.3688,  1.9570,  1.7192,  1.9771,  1.7860,\n",
      "         1.4166,  2.0929,  1.6891,  1.1118,  1.4172,  1.7378,  2.0361,  1.6654,\n",
      "         3.7287,  0.4752,  1.7765,  0.6458,  1.2783,  0.6150,  1.4916,  1.6856,\n",
      "         0.5051,  1.2547,  1.6210,  1.5214,  0.9242,  1.6164,  0.3526,  0.2146,\n",
      "         2.1952,  1.8472,  0.9592,  1.5854,  0.4812,  2.2287,  1.8482,  2.0150,\n",
      "         1.2714,  1.8571,  1.5788,  1.7158,  0.9693,  2.2896,  1.5728,  0.9342,\n",
      "         1.2231,  1.3194,  2.9645,  1.6913,  2.0691,  1.8760,  1.7023,  1.7958,\n",
      "         2.8411,  0.4466,  1.4889,  0.7674,  1.5672,  1.5884,  1.5372,  1.2952,\n",
      "         1.4813,  1.8470,  1.2121,  1.0001,  0.6382,  3.4573,  1.1697,  3.0086,\n",
      "         1.0737,  1.6926,  1.0371,  2.0520,  1.7497,  0.3168,  1.6770,  1.2701,\n",
      "         1.3485,  2.3509,  1.3324,  0.8219,  1.2235,  1.5997,  2.1556,  1.6853,\n",
      "         3.0904,  1.9100,  2.0986,  1.0663,  1.9721,  3.3249,  1.3668,  1.5058,\n",
      "         0.8639,  1.1437,  0.8614,  1.7258,  0.9556,  1.4409,  1.5617,  2.0703,\n",
      "         1.5178,  1.5973,  1.3991,  1.5399,  1.3199,  1.9849,  1.6207,  1.2970,\n",
      "         1.2939,  1.8263,  0.8935,  1.7946,  0.6486,  1.3830,  2.9138,  1.4929,\n",
      "         1.5492,  1.7125,  0.6685,  0.6469,  2.5210,  1.6585,  1.9829,  1.1818,\n",
      "         0.9591,  1.3604,  0.8932,  1.7633,  1.7595,  1.4436,  2.3372,  1.8943,\n",
      "         1.3682,  4.5034,  1.3957,  0.9308,  1.6370,  1.5162,  0.5883,  0.8784,\n",
      "         0.5774,  1.8618,  0.6077,  1.2908,  2.2895,  1.6906,  0.9977,  1.1319,\n",
      "         0.3725,  1.8512,  1.6140,  1.7031,  1.2586,  2.6287,  1.7561,  1.8605,\n",
      "         1.8763,  2.4523,  1.6516,  1.6444,  1.0996,  1.8467,  4.4855,  1.4661,\n",
      "         1.5474,  1.9692,  3.2148,  2.1796,  0.8242,  1.5405,  2.0523,  1.1624,\n",
      "         1.3043,  1.4430,  1.4251,  1.5712,  2.1552,  4.7075,  1.7320,  0.2335,\n",
      "         1.2294,  2.2329,  0.4169,  1.9106,  0.3772,  1.6871,  1.2995,  1.8480,\n",
      "         1.7575,  1.7364,  3.4973,  1.3889,  2.2206,  1.5061,  1.3111,  0.9218,\n",
      "         1.0344,  1.5084,  1.4069,  1.7577,  1.3314,  1.4702,  1.3095,  2.1590,\n",
      "         1.6396,  1.1514,  2.1621,  2.2461,  2.4663,  0.3612,  1.6526,  1.5199,\n",
      "         1.7476,  1.0292,  2.2677,  1.4721,  1.1740,  0.5269,  1.5324,  1.3991,\n",
      "         1.4364,  1.4776,  1.6920,  1.0336,  1.8609,  1.3065,  2.8235,  1.7077,\n",
      "         1.3732,  2.2027,  1.2123,  1.5854,  1.0873,  0.9244,  0.8450,  1.3890,\n",
      "         1.5633,  1.0616,  1.6547,  1.5237,  1.4968,  1.3917,  0.8660,  1.9555,\n",
      "         1.9871,  1.3849,  0.5332,  1.9256,  1.2316,  1.8751,  1.0884,  1.9890,\n",
      "         0.9886,  1.2466,  1.3467,  0.8196,  1.8910,  1.0737,  1.1068,  0.7215,\n",
      "         2.3641,  1.9862,  0.1607,  1.9389,  2.0494,  1.5548,  1.0929,  0.0803,\n",
      "         0.7698,  1.2844,  1.2217,  1.9565,  1.6742,  1.8080,  1.5253,  0.8534,\n",
      "         0.9146,  2.0913,  1.8132,  0.7999,  1.7963,  2.5746,  1.0833,  1.3216,\n",
      "         2.3649,  1.2649,  1.7006,  0.9640,  1.6670,  2.1567,  1.2625,  0.0920,\n",
      "         0.9949,  1.2231,  1.5773,  0.7723,  1.7968,  3.7536,  2.8523,  1.6584,\n",
      "         0.8817,  0.9361,  0.9650,  1.6603,  1.4208,  0.0734,  2.0142,  1.4508,\n",
      "         0.8436,  1.4802,  2.5287,  1.7359,  1.6402,  1.3384,  1.6480,  1.5930],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-2.4866e-01, -7.4560e-01, -3.0959e-01, -3.0138e-01, -1.5394e+00,\n",
      "        -1.2255e+00, -1.2212e+00, -1.2246e+00, -3.3162e+00, -1.4089e-01,\n",
      "        -4.8719e-01, -1.1199e+00,  4.9703e-01,  5.0686e-01,  2.9674e-01,\n",
      "        -7.1744e-01, -2.0724e+00, -4.5166e-01, -1.7620e+00, -1.4755e+00,\n",
      "        -3.3380e-01, -1.3899e+00, -8.6920e-01, -2.1092e+00, -7.8410e-01,\n",
      "        -1.5334e+00,  1.6700e-01,  6.6326e-01, -2.1749e+00, -1.1381e+00,\n",
      "        -1.5630e+00, -1.0906e+00, -2.8091e+00, -7.9286e-01, -9.8489e-01,\n",
      "        -2.1466e-01, -1.1321e+00, -9.1795e-01, -5.8335e-01, -3.3608e+00,\n",
      "        -1.2129e+00, -9.2373e-01, -1.2081e+00, -1.3476e+00, -2.6999e+00,\n",
      "        -1.0755e+00,  3.7335e-01, -4.0859e-01, -7.3575e-01, -4.5971e-01,\n",
      "        -9.0900e-02, -7.9884e-01, -1.8679e+00, -8.9951e-01, -6.6625e-01,\n",
      "        -1.0322e+00, -3.0053e-01, -2.6343e+00, -1.6298e+00, -1.2321e+00,\n",
      "        -3.5381e+00, -5.4728e-01, -1.3917e+00, -1.2296e+00, -2.3660e-01,\n",
      "        -1.2190e+00,  7.7353e-01, -1.2978e+00, -5.6555e-01, -1.5031e+00,\n",
      "        -3.0093e-02, -1.2148e+00, -1.5190e+00,  7.9697e-02, -1.1034e+00,\n",
      "        -1.0587e+00, -2.2540e-01, -1.7250e+00, -6.8240e-01, -7.3540e-02,\n",
      "        -1.9189e+00, -7.8256e-01, -7.0098e-01, -4.0904e-01, -7.6780e-01,\n",
      "        -3.9230e+00, -1.1799e-01, -4.9957e-01, -1.6507e+00, -7.9137e-02,\n",
      "         4.6122e-01, -1.0129e+00, -2.2788e+00, -5.6391e-01, -2.5709e-01,\n",
      "         7.3365e-01, -3.0820e+00, -1.9261e+00, -1.0979e-01, -2.4457e-01,\n",
      "         1.6241e-01,  3.0938e-01, -1.2465e-01, -9.8712e-01, -9.3534e-01,\n",
      "        -1.9646e-01, -1.4027e+00, -4.2445e-01, -1.4094e+00, -1.3612e+00,\n",
      "        -1.5043e-02,  4.5704e-02, -9.8473e-01, -9.2491e-01, -1.3489e+00,\n",
      "        -1.9519e+00, -5.8041e-01, -1.1568e+00,  3.8570e-01, -1.3861e+00,\n",
      "        -1.0594e+00, -4.5225e-01,  1.5875e-01, -2.0119e-03, -2.1477e+00,\n",
      "        -5.1490e-01, -1.2995e-01, -1.0513e+00,  1.8883e-01,  4.5981e-02,\n",
      "         1.5304e-01, -1.2528e+00, -4.8478e-01, -1.6148e+00, -7.8842e-01,\n",
      "        -7.1003e-01, -1.3999e+00, -1.3464e+00, -5.0735e-01, -1.2266e+00,\n",
      "        -1.1914e+00, -1.3896e+00, -1.5625e+00, -5.1226e-01, -1.4105e+00,\n",
      "        -2.0616e+00, -9.2007e-01,  5.9717e-01, -8.3375e-01, -7.2605e-01,\n",
      "         2.1292e-01, -1.5954e+00, -1.3901e+00, -1.0558e+00, -9.5563e-01,\n",
      "        -1.2186e+00, -1.3234e+00, -6.2839e-01, -1.6969e+00, -1.2455e+00,\n",
      "        -1.7729e+00, -1.0468e+00, -2.1251e+00, -8.8589e-01,  1.0733e-01,\n",
      "        -1.4017e+00, -2.7246e-01, -1.1862e+00, -1.2565e+00, -1.5115e+00,\n",
      "        -1.5452e+00, -4.8257e-01, -2.2688e+00, -3.9521e-01, -1.9169e+00,\n",
      "         7.5864e-01, -1.1989e+00, -1.1317e+00, -1.0147e+00, -2.2844e-01,\n",
      "        -7.9610e-02, -5.9323e-02, -1.2704e+00, -3.8659e-01, -1.2172e+00,\n",
      "        -5.5425e-01, -2.8759e-01, -1.0332e+00, -4.7884e-01, -1.0760e+00,\n",
      "        -4.7976e-01, -1.7755e+00, -1.5842e+00, -1.7104e+00, -8.8524e-01,\n",
      "         3.5893e-01, -1.4737e+00, -1.4397e+00, -9.8729e-01, -6.5003e-01,\n",
      "         8.0761e-01, -2.7832e+00, -1.8889e+00, -9.1161e-01, -1.3411e+00,\n",
      "         7.8486e-01, -7.7169e-01, -3.0418e-01, -9.7560e-01, -2.1554e-01,\n",
      "        -1.7801e+00, -1.6567e+00, -1.4065e+00, -1.9981e+00, -4.6938e-01,\n",
      "        -6.6001e-01, -6.2414e-01, -7.7659e-01, -2.1320e+00, -2.3093e+00,\n",
      "        -4.6061e-01, -1.4428e+00, -1.3283e+00, -1.4158e+00, -1.3054e+00,\n",
      "        -1.4261e+00, -1.5216e+00, -2.2333e+00, -8.5803e-01, -4.4027e-01,\n",
      "        -9.2292e-01, -6.6564e-01, -5.8772e-01, -1.5346e+00, -1.0983e+00,\n",
      "         2.7989e-01, -2.2825e+00,  2.3959e-01, -4.0449e-01, -1.8062e-01,\n",
      "        -2.6566e-01, -1.1687e+00, -5.6565e-01, -5.1427e-01, -1.4492e+00,\n",
      "        -8.8319e-01, -5.0471e-02, -8.1737e-01, -3.2017e-01, -8.4392e-01,\n",
      "        -1.4611e+00, -5.9979e-01, -7.5007e-01, -2.3425e+00, -1.8688e+00,\n",
      "        -1.9452e+00, -1.5643e+00, -7.6007e-01, -1.9279e+00,  9.7091e-02,\n",
      "        -1.5216e+00, -1.7032e+00, -1.3131e+00, -2.1300e+00, -2.7670e+00,\n",
      "        -1.4832e+00, -1.3623e+00, -4.2444e-01, -1.3460e+00, -8.6190e-01,\n",
      "        -1.3183e+00,  3.8745e-02,  2.8817e-01, -3.8250e-01, -1.5933e+00,\n",
      "        -3.4709e-01, -7.5827e-01, -7.2870e-02, -1.2768e+00, -1.1917e+00,\n",
      "        -3.8348e-01, -7.9123e-01, -1.1658e+00, -1.0762e+00, -2.6070e-01,\n",
      "        -8.2121e-01,  1.6417e-03, -7.8999e-02, -7.8685e-01, -1.3287e+00,\n",
      "         1.0980e-01, -2.5035e+00, -1.9068e-01, -1.5870e+00, -9.0962e-01,\n",
      "        -1.2686e+00, -2.0678e+00, -1.2343e+00, -2.4730e+00, -1.7698e+00,\n",
      "        -2.2823e-01, -2.9343e-01, -1.4956e+00,  1.3180e-01, -2.2242e+00,\n",
      "        -7.6258e-01, -1.3499e+00, -1.6118e+00, -1.5223e+00, -1.2169e+00,\n",
      "        -1.5986e+00, -1.3143e+00, -1.0195e+00, -1.1907e-01, -5.2644e-01,\n",
      "        -8.8931e-01, -1.9455e+00, -2.2630e+00, -1.7066e+00, -1.4789e+00,\n",
      "        -8.4317e-01, -1.5091e+00, -1.2576e+00, -2.0735e-01, -2.9916e-01,\n",
      "        -8.3472e-01, -1.4647e-01, -5.7005e-01, -7.8531e-01, -1.7000e+00,\n",
      "        -6.2548e-01, -1.4636e+00, -7.1026e-01, -2.9751e-01, -1.4824e+00,\n",
      "        -7.0033e-01, -1.0163e+00, -1.7874e+00, -2.1122e+00, -7.2490e-01,\n",
      "        -9.2067e-02, -1.4234e+00, -5.5811e-01, -1.1596e+00, -2.7555e-02,\n",
      "        -2.5585e+00, -1.0101e+00, -4.5940e-01, -2.2484e+00,  6.4819e-01,\n",
      "        -1.2531e+00, -1.3217e+00, -8.7144e-01, -5.6213e-01, -3.4428e-01,\n",
      "        -1.1579e+00, -1.0014e+00, -1.5390e+00, -1.6730e+00, -1.1474e+00,\n",
      "        -1.3046e+00, -1.4041e+00, -1.1054e+00, -7.2012e-01, -4.7650e-01,\n",
      "        -1.6648e+00, -1.4918e+00, -1.2157e+00,  1.5491e-01, -2.1543e+00,\n",
      "        -2.7208e-01, -1.3867e+00,  4.4166e-01, -6.7505e-01, -2.5435e+00,\n",
      "        -5.3592e-01, -1.6605e+00, -2.8825e+00, -3.0218e-01, -1.6907e-01,\n",
      "        -1.1260e+00, -1.7351e+00, -2.1024e+00, -4.4908e-01, -4.8171e-02,\n",
      "        -5.1475e-02, -1.1489e-01, -1.5360e+00, -1.6242e+00, -9.7516e-01,\n",
      "        -1.2027e+00, -5.1191e-01, -2.1723e+00, -1.4437e-01, -1.0441e+00,\n",
      "        -7.3605e-01, -1.1856e+00, -6.2487e-01, -1.2161e-01, -1.6129e+00,\n",
      "        -2.7295e-01, -1.9837e+00, -7.9246e-01, -3.9970e-01, -1.4494e+00,\n",
      "        -5.9914e-01, -4.4852e-01,  1.1866e+00,  2.1411e-01, -1.6387e+00,\n",
      "        -1.5319e+00, -1.1155e+00, -1.9637e+00, -7.7328e-01, -1.0438e+00,\n",
      "        -1.3843e+00, -2.5526e-01, -1.5094e+00, -2.0264e+00, -1.8522e+00,\n",
      "        -2.4283e-01, -1.4755e+00, -1.2596e+00, -1.7343e+00, -2.9355e+00,\n",
      "        -1.2267e+00,  3.8202e-01, -1.2153e+00, -7.3358e-01, -3.9973e-01,\n",
      "        -1.4469e+00, -1.1667e+00, -1.0386e+00, -5.2180e-01, -5.1293e-01,\n",
      "        -1.2107e+00, -2.2696e+00, -3.1720e-01, -9.3519e-02,  3.5064e-02,\n",
      "        -9.2219e-01, -5.9407e-01, -1.2368e+00, -1.4732e+00,  8.3684e-01,\n",
      "        -1.2388e+00, -2.0258e+00, -1.3995e+00, -1.7560e+00, -1.0117e+00,\n",
      "         4.7456e-01, -8.3172e-01, -4.6111e-01, -2.7996e+00, -1.4674e+00,\n",
      "         1.6554e-01, -5.2159e-01, -1.2710e+00,  2.8424e-01, -1.0099e+00,\n",
      "        -8.8011e-01, -1.7708e+00, -1.9862e-02, -5.3580e-01, -1.8527e+00,\n",
      "         1.8054e-01, -1.1910e+00, -8.3372e-01, -1.8164e+00, -7.3968e-02,\n",
      "        -1.4955e+00, -1.0773e+00, -1.4717e+00, -7.7575e-01, -4.1695e-02,\n",
      "        -1.5124e+00, -2.0306e-01, -4.1265e-01, -8.2939e-01, -9.4951e-01,\n",
      "        -1.3543e+00, -1.1537e+00, -1.5335e+00, -3.8954e-01, -1.2728e+00,\n",
      "        -8.6179e-01,  4.1734e-01, -1.4329e+00, -1.3734e+00, -1.4102e+00,\n",
      "        -1.7186e+00, -1.6649e+00, -2.1738e+00, -4.7492e-02, -3.7581e+00,\n",
      "        -2.5655e+00, -1.2643e+00, -4.9833e-01, -9.8744e-01, -1.3212e+00,\n",
      "        -1.1237e+00, -1.3872e+00, -1.6147e-01, -1.8238e+00, -7.2915e-01,\n",
      "        -9.3522e-01, -2.1305e-01, -9.2280e-01, -2.1793e+00, -1.6062e+00,\n",
      "        -2.0019e+00, -1.3995e+00,  1.8124e-01, -6.7231e-01, -1.7366e+00,\n",
      "        -5.2184e-01, -1.5198e+00, -2.7712e-01, -7.6834e-01, -5.1812e-01,\n",
      "        -9.6025e-01, -9.0412e-01, -1.5855e-01, -9.2432e-01, -3.1884e+00,\n",
      "        -2.8252e-02, -5.4902e-01,  4.5895e-04, -9.7022e-02, -2.4183e-01,\n",
      "        -5.6953e-01, -8.8234e-01, -2.0277e+00, -1.3349e+00, -1.3423e+00,\n",
      "        -2.9719e-01, -3.5458e-01, -9.5093e-01, -1.5400e+00, -1.0426e-01,\n",
      "        -9.2067e-01, -2.2798e+00,  1.6975e-01, -2.1284e-01, -8.0106e-01,\n",
      "        -6.7099e-01, -1.1673e+00, -3.2096e-01, -7.8480e-01, -1.5575e+00,\n",
      "        -1.1645e+00, -9.7178e-02, -4.4429e-02, -3.3449e-01, -6.6340e-01,\n",
      "        -5.6124e-01, -1.2141e+00, -2.9765e-03, -9.9637e-01, -1.7621e+00,\n",
      "        -1.0159e+00, -6.1620e-01, -3.0581e-01, -1.5785e+00, -1.2426e+00,\n",
      "        -2.3511e-02, -1.6766e+00, -1.7756e+00,  2.1670e-01, -2.6646e+00,\n",
      "        -1.4749e+00, -7.6164e-01, -1.2214e+00,  3.3844e-01, -9.2707e-01,\n",
      "        -9.0361e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.5187]],\n",
      "\n",
      "         [[-0.5384]],\n",
      "\n",
      "         [[-0.0219]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0876]],\n",
      "\n",
      "         [[ 0.4992]],\n",
      "\n",
      "         [[-0.2376]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0819]],\n",
      "\n",
      "         [[-0.1486]],\n",
      "\n",
      "         [[ 0.0049]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3101]],\n",
      "\n",
      "         [[ 0.1194]],\n",
      "\n",
      "         [[-0.1822]]],\n",
      "\n",
      "\n",
      "        [[[-0.2026]],\n",
      "\n",
      "         [[-0.5045]],\n",
      "\n",
      "         [[ 0.0754]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0539]],\n",
      "\n",
      "         [[ 0.0530]],\n",
      "\n",
      "         [[-0.1035]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4579]],\n",
      "\n",
      "         [[-0.2813]],\n",
      "\n",
      "         [[-0.0696]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1292]],\n",
      "\n",
      "         [[ 0.1333]],\n",
      "\n",
      "         [[ 0.1005]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5816]],\n",
      "\n",
      "         [[ 0.4823]],\n",
      "\n",
      "         [[ 0.1863]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0397]],\n",
      "\n",
      "         [[ 0.1848]],\n",
      "\n",
      "         [[-0.2237]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4218]],\n",
      "\n",
      "         [[ 0.0885]],\n",
      "\n",
      "         [[ 0.2379]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2263]],\n",
      "\n",
      "         [[-0.0081]],\n",
      "\n",
      "         [[ 0.4663]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1659, -0.3257,  0.0132, -0.0007, -0.2783,  0.0384,  0.1304,  0.1092,\n",
      "        -0.0803,  0.1389,  0.1510,  0.0439,  0.1382,  0.1508,  0.0521,  0.3360,\n",
      "        -0.2554,  0.0476,  0.1971,  0.0681,  0.0357, -0.0107, -0.1146,  0.1680],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.4209]],\n",
      "\n",
      "         [[-0.2821]],\n",
      "\n",
      "         [[-0.3201]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0955]],\n",
      "\n",
      "         [[ 0.0038]],\n",
      "\n",
      "         [[-0.0540]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2597]],\n",
      "\n",
      "         [[ 0.2110]],\n",
      "\n",
      "         [[-0.6250]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0569]],\n",
      "\n",
      "         [[ 0.2780]],\n",
      "\n",
      "         [[-0.2302]]],\n",
      "\n",
      "\n",
      "        [[[-0.3196]],\n",
      "\n",
      "         [[-0.0641]],\n",
      "\n",
      "         [[-0.0265]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3620]],\n",
      "\n",
      "         [[ 0.0637]],\n",
      "\n",
      "         [[-0.2713]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.4140]],\n",
      "\n",
      "         [[-0.0568]],\n",
      "\n",
      "         [[-0.4414]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0396]],\n",
      "\n",
      "         [[ 0.0930]],\n",
      "\n",
      "         [[-0.0219]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0212]],\n",
      "\n",
      "         [[ 0.0385]],\n",
      "\n",
      "         [[-0.2595]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2793]],\n",
      "\n",
      "         [[ 0.1139]],\n",
      "\n",
      "         [[ 0.3680]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1239]],\n",
      "\n",
      "         [[-0.1921]],\n",
      "\n",
      "         [[ 0.0541]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4630]],\n",
      "\n",
      "         [[ 0.4286]],\n",
      "\n",
      "         [[-0.1377]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-6.0132e-01,  4.1082e-02, -3.5127e-01, -8.2402e-02, -1.4416e-01,\n",
      "         1.8610e-01, -1.3150e-01,  3.6714e-01, -2.6308e-01, -1.7463e-01,\n",
      "        -4.0716e-02,  4.3888e-01,  2.8875e-01,  2.6890e-01,  9.2507e-02,\n",
      "         2.1322e-01,  2.4138e-01, -2.0293e-01,  3.1692e-02, -1.4208e-01,\n",
      "        -1.6980e-01,  3.0999e-01, -4.7100e-01,  1.5218e-02, -1.2622e-01,\n",
      "        -2.0462e-01,  1.6794e-01,  3.1406e-01,  2.2888e-01, -1.0078e-01,\n",
      "        -3.0591e-01,  2.6656e-01,  4.5568e-01, -2.2483e-01, -3.7270e-01,\n",
      "        -3.4443e-01, -2.3799e-01,  2.7193e-01, -6.8732e-02, -4.7048e-01,\n",
      "         3.8169e-01, -1.4008e-01, -4.7487e-01, -6.1439e-02,  1.3642e-04,\n",
      "        -1.8585e-01,  1.2626e-01,  3.2137e-01, -3.0267e-01,  4.0145e-01,\n",
      "        -3.2823e-01, -2.5999e-01,  2.8277e-01,  1.7026e-01,  1.7879e-01,\n",
      "         4.3144e-01, -5.0246e-03,  3.6801e-01, -1.8183e-01,  9.3539e-02,\n",
      "         2.0104e-01, -6.9443e-03, -3.8014e-01,  9.0042e-03,  7.5001e-02,\n",
      "         4.9712e-01,  2.9098e-01,  3.3056e-01, -1.8732e-01,  1.8689e-01,\n",
      "        -1.7427e-01, -2.3215e-02,  1.4881e-01, -5.3294e-02,  1.8234e-02,\n",
      "        -7.5744e-02, -3.1008e-02, -3.1635e-01, -2.0475e-01, -3.9708e-02,\n",
      "         2.6645e-01,  1.6776e-01, -2.9316e-01, -2.6670e-01,  2.7862e-02,\n",
      "         8.3652e-03,  2.2781e-03, -3.1977e-01,  7.2637e-04, -3.1931e-01,\n",
      "        -4.2613e-01, -1.4708e-01,  4.6170e-01, -2.3893e-01, -1.5439e-01,\n",
      "         5.6649e-01,  1.8935e-01,  1.7731e-01, -2.8756e-01, -4.7582e-01,\n",
      "         4.6113e-03, -2.4605e-01,  2.8544e-01,  2.5338e-01,  1.1844e-01,\n",
      "        -1.8962e-01,  3.2307e-02, -4.2201e-02, -2.7989e-01,  2.7592e-01,\n",
      "         3.9062e-01,  2.6998e-02, -4.5475e-01, -1.3802e-01,  3.9454e-01,\n",
      "        -5.4953e-02, -2.5908e-02, -1.5365e-01,  2.0462e-01,  4.2439e-02,\n",
      "         7.8842e-02, -3.4766e-01,  3.9661e-01, -2.7081e-01,  4.5399e-03,\n",
      "         3.8492e-01, -2.5153e-01,  3.6159e-02, -1.6821e-02, -5.2740e-02,\n",
      "         1.8063e-01, -6.4004e-02,  7.7117e-02, -1.5742e-01, -1.8141e-01,\n",
      "        -5.6273e-01, -1.8777e-01,  4.9420e-01, -7.6652e-02,  1.5697e-02,\n",
      "         2.3155e-01,  3.7218e-01,  2.6899e-01, -2.3797e-01,  8.9996e-02,\n",
      "         2.2062e-01,  3.1721e-01,  3.3514e-01, -9.4352e-02, -5.0776e-01,\n",
      "         1.6939e-01,  5.2608e-02,  3.1822e-01, -5.6232e-01, -3.1631e-02,\n",
      "         3.2835e-01, -3.7925e-01,  2.5260e-01,  2.7062e-01,  3.2912e-01,\n",
      "         4.3590e-02, -2.5551e-01,  2.0937e-01,  1.1946e-01,  4.4020e-01,\n",
      "        -5.3037e-02, -1.1041e-01, -1.6016e-02, -2.5103e-01,  2.4493e-01,\n",
      "        -3.6280e-01, -4.1662e-01, -5.3449e-01, -4.0510e-01, -1.9220e-01,\n",
      "        -3.2134e-01, -3.4939e-01,  1.6012e-01, -1.3289e-01,  2.0683e-02,\n",
      "        -3.8865e-02, -2.4233e-01,  3.3228e-01, -6.8508e-02,  3.6216e-01,\n",
      "         1.6807e-01, -2.2589e-01,  5.9443e-01, -2.2166e-01,  1.2907e-01,\n",
      "        -1.7463e-01,  1.4197e-02, -5.0766e-01,  3.5984e-01, -3.9341e-01,\n",
      "        -2.0131e-01,  2.1208e-01,  1.3437e-01,  2.9556e-01,  3.3002e-01,\n",
      "        -2.2876e-01, -1.5560e-01,  8.2876e-02, -5.7060e-01,  4.5756e-01,\n",
      "        -1.9382e-01, -3.4337e-05, -9.4685e-03, -2.0266e-01, -4.4880e-01,\n",
      "         1.5528e-01,  8.1404e-02,  3.0543e-01, -2.2566e-01,  2.6097e-01,\n",
      "        -1.2917e-01, -4.6562e-01, -4.8109e-01, -2.8561e-01, -4.4126e-02,\n",
      "         4.1430e-01, -2.4978e-02, -6.1391e-02, -1.0187e-01,  2.2853e-02,\n",
      "         4.2657e-01, -1.1897e-01,  4.6095e-01, -2.0534e-02,  2.7775e-01,\n",
      "         1.4364e-02,  4.8678e-01,  8.2573e-02, -5.4189e-01,  5.1217e-01,\n",
      "         4.7800e-01,  2.0237e-01, -2.3214e-01,  4.1336e-01, -2.7743e-01,\n",
      "        -4.7142e-01,  1.5429e-02,  7.9514e-02,  6.0106e-02, -1.5485e-01,\n",
      "         1.5365e-01, -1.2244e-01, -5.1615e-01,  3.7294e-01, -4.4142e-02,\n",
      "        -2.3852e-01, -3.3095e-01, -1.0248e-02,  7.7357e-02,  3.6276e-01,\n",
      "        -1.8145e-01, -3.5333e-03, -2.1952e-02,  4.1459e-01,  3.9560e-01,\n",
      "        -9.1043e-02,  1.4299e-01,  3.9093e-01,  1.0495e-01,  3.7607e-01,\n",
      "         2.3917e-01, -3.1995e-02, -1.9874e-01,  1.6846e-01,  3.2176e-01,\n",
      "         2.3612e-01, -2.4013e-01, -3.1040e-01, -9.5063e-03,  2.2427e-01,\n",
      "         3.7815e-01, -4.1358e-01, -1.0275e-01, -1.0289e-01, -3.5208e-01,\n",
      "        -2.7630e-02, -1.9534e-01, -1.6428e-01,  3.1857e-01,  6.1816e-03,\n",
      "         5.0735e-03, -2.7200e-02, -5.2386e-01,  5.7763e-02, -1.9686e-01,\n",
      "         3.1555e-01,  3.5224e-01, -3.6809e-01,  3.9098e-01,  3.2659e-01,\n",
      "         8.8861e-02, -1.4902e-01,  4.9115e-01,  4.3664e-01,  3.2395e-01,\n",
      "        -4.2753e-01,  2.5255e-01,  5.0129e-01,  2.9790e-01,  2.8319e-01,\n",
      "        -9.8950e-02,  4.6060e-01, -7.1470e-02,  3.5502e-01,  2.2802e-01,\n",
      "        -7.3753e-03,  3.7583e-02,  2.3366e-02, -2.7767e-01,  4.2709e-01,\n",
      "         2.9409e-01,  3.2408e-01,  3.8146e-01,  3.2348e-01, -1.4435e-01,\n",
      "        -9.2967e-02, -2.7780e-01,  2.6007e-01,  2.8243e-01, -2.5654e-01,\n",
      "         1.6730e-01,  3.5108e-01,  7.6859e-02, -6.0185e-03, -1.2913e-01,\n",
      "        -1.7622e-02,  2.2708e-01, -3.9616e-01, -2.1652e-01,  1.4105e-01,\n",
      "        -1.3860e-01, -3.0142e-01,  4.1338e-01,  1.9285e-02, -1.8666e-01,\n",
      "        -4.5817e-01,  3.6385e-01, -4.2554e-02, -2.1601e-01, -3.5447e-01,\n",
      "         3.4539e-01, -1.5367e-01, -5.6564e-03,  4.7694e-01,  2.9174e-02,\n",
      "        -8.0036e-04, -5.6850e-01, -3.5261e-01, -3.5140e-01, -1.0806e-01,\n",
      "         3.2223e-01,  3.1094e-01,  2.1704e-01,  1.9608e-01,  3.7016e-01,\n",
      "        -3.1970e-01,  3.2463e-01,  1.1475e-01, -1.7360e-01, -1.2523e-01,\n",
      "         1.2332e-01,  1.8879e-01, -1.2115e-01,  3.9954e-01,  1.9940e-01,\n",
      "        -5.5335e-01,  2.4258e-01,  8.2321e-02,  2.1744e-01,  3.7278e-01,\n",
      "        -4.3391e-01,  4.9961e-02, -2.2469e-01, -3.4219e-01,  2.9118e-01,\n",
      "         1.5959e-01,  8.1106e-02,  5.0663e-01, -5.1178e-01,  3.4222e-01,\n",
      "        -2.0697e-01,  3.9225e-01,  4.6896e-01,  1.0650e-01,  3.3093e-01,\n",
      "         4.5389e-01, -1.1355e-01,  2.9603e-01,  6.2396e-02, -4.8607e-02,\n",
      "        -3.5696e-01, -4.4792e-01,  1.0933e-01,  1.2460e-01, -1.3588e-01,\n",
      "         3.6490e-01,  3.4457e-01,  3.1893e-02, -1.1549e-01,  3.3553e-01,\n",
      "        -1.9884e-01, -3.9861e-02,  4.9442e-01, -1.8345e-01,  2.5742e-01,\n",
      "        -1.9266e-01,  2.5541e-01, -4.3615e-01,  5.3244e-02, -1.7741e-01,\n",
      "        -2.9187e-01, -2.5887e-01,  1.0420e-01, -7.7792e-02,  4.9132e-02,\n",
      "         9.5928e-02, -4.7037e-02, -4.7094e-01,  3.0926e-01,  6.9469e-02,\n",
      "        -2.3290e-01, -1.1738e-01,  7.5354e-02,  5.4397e-02,  3.5832e-01,\n",
      "        -1.5144e-01, -3.4855e-02, -6.0354e-02, -1.0917e-01, -1.4219e-01,\n",
      "         2.2846e-01,  7.9654e-02, -2.6589e-01, -4.2223e-01, -3.6412e-01,\n",
      "        -2.5798e-02,  3.6549e-01,  1.9079e-01,  1.7902e-01,  3.8504e-02,\n",
      "         9.0692e-02,  4.4416e-01,  3.9060e-01, -5.8727e-02,  1.3458e-01,\n",
      "        -4.8276e-01,  1.7495e-01, -1.3837e-01, -3.0120e-02,  3.6582e-02,\n",
      "         1.3516e-01,  1.1729e-01,  8.1208e-02,  6.2684e-02, -1.2023e-01,\n",
      "        -1.9116e-01,  1.5217e-01,  4.5649e-01,  5.6008e-01,  2.7860e-01,\n",
      "         1.8344e-01, -1.6074e-01, -1.8177e-01, -1.3805e-01, -2.8237e-01,\n",
      "        -1.6306e-01,  2.4248e-01, -2.2482e-01, -2.2119e-01, -1.7328e-01,\n",
      "        -2.9651e-01, -4.3864e-01, -1.1884e-01,  2.7002e-01, -4.0642e-01,\n",
      "         4.0234e-01, -4.9102e-02, -1.4054e-01, -1.0893e-01,  1.3904e-01,\n",
      "        -6.0228e-02, -2.6837e-01,  3.5572e-01,  1.0892e-01,  2.1689e-01,\n",
      "         3.0662e-01, -2.4133e-01, -5.0039e-01,  5.8866e-01,  1.3340e-02,\n",
      "        -4.0616e-01,  1.7637e-01,  1.4001e-01,  1.3446e-01, -2.5688e-01,\n",
      "        -1.2668e-01, -2.0664e-01,  3.8346e-01,  4.2308e-01,  1.0874e-01,\n",
      "        -4.6006e-01, -3.6397e-01,  2.1671e-01, -1.4661e-01,  4.1064e-01,\n",
      "        -2.2855e-01, -4.2191e-01,  1.5147e-01, -2.9532e-01,  1.6746e-01,\n",
      "         7.0747e-02,  3.0469e-01,  5.0576e-02, -3.7268e-02,  2.1213e-01,\n",
      "         2.0203e-02,  4.0727e-01, -4.0689e-01, -3.5051e-01,  3.3569e-01,\n",
      "         4.8615e-01, -3.5564e-01, -2.4696e-01, -6.5633e-01, -4.0709e-01,\n",
      "        -3.5838e-01,  2.2404e-01, -4.0464e-01, -1.0896e-01,  6.7266e-02,\n",
      "        -1.6767e-01, -1.7426e-02,  4.8223e-01,  4.5629e-01, -9.4033e-02,\n",
      "         4.9034e-01,  1.7746e-01,  1.6032e-01,  5.6713e-01, -3.0475e-01,\n",
      "         2.8097e-01,  3.9282e-01, -4.6892e-01,  2.7190e-02,  7.8468e-02,\n",
      "        -8.5854e-02,  1.2599e-01,  2.6061e-01,  4.0719e-02,  3.3569e-01,\n",
      "        -4.5401e-01,  1.2751e-01,  9.3098e-03, -2.6135e-01,  3.6753e-01,\n",
      "        -4.2089e-01,  1.2286e-01, -2.0558e-01,  7.4574e-02, -2.8031e-01,\n",
      "        -4.3993e-01,  5.3288e-01,  8.9737e-02, -5.4484e-02, -5.2670e-01,\n",
      "        -4.4364e-02,  4.2264e-01, -5.3380e-01,  1.6508e-01, -1.4616e-01,\n",
      "        -2.1821e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 2.4797e-01]],\n",
      "\n",
      "         [[ 2.8779e-01]],\n",
      "\n",
      "         [[-5.1479e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6529e-02]],\n",
      "\n",
      "         [[ 4.3614e-01]],\n",
      "\n",
      "         [[ 6.4051e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1231e-02]],\n",
      "\n",
      "         [[-5.2330e-02]],\n",
      "\n",
      "         [[ 2.0792e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9003e-01]],\n",
      "\n",
      "         [[ 4.0722e-02]],\n",
      "\n",
      "         [[ 3.5041e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2771e-01]],\n",
      "\n",
      "         [[ 6.9332e-01]],\n",
      "\n",
      "         [[ 1.2491e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8020e-01]],\n",
      "\n",
      "         [[-1.1866e-05]],\n",
      "\n",
      "         [[-1.8620e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 7.9277e-02]],\n",
      "\n",
      "         [[-3.5266e-02]],\n",
      "\n",
      "         [[-3.0017e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.0849e-01]],\n",
      "\n",
      "         [[ 6.0154e-01]],\n",
      "\n",
      "         [[-8.6208e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0193e-01]],\n",
      "\n",
      "         [[ 2.7429e-01]],\n",
      "\n",
      "         [[-3.4224e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1989e-01]],\n",
      "\n",
      "         [[ 1.1469e-01]],\n",
      "\n",
      "         [[-2.0256e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2525e-01]],\n",
      "\n",
      "         [[ 4.2711e-01]],\n",
      "\n",
      "         [[ 2.8896e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9328e-01]],\n",
      "\n",
      "         [[ 1.1635e-01]],\n",
      "\n",
      "         [[ 4.2989e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.0346,  0.7540,  0.5861,  0.7123,  0.3716,  0.4469,  0.6961,  0.3489,\n",
      "         2.9204,  0.4324,  1.5544,  0.4740,  0.3783,  2.6266,  0.6429,  0.5139,\n",
      "         1.3577,  0.3871,  0.8789,  2.1111,  0.6250,  1.3906,  0.6243,  0.4039,\n",
      "         1.0640,  1.3832,  0.8816,  0.5370,  0.2293,  1.0722,  0.2033,  0.9950,\n",
      "         1.4829,  0.1853,  0.2782,  1.2605,  2.5155,  0.4937,  1.1397,  1.6985,\n",
      "         0.5253,  0.2888,  0.1669,  1.1484,  0.2458,  0.4443,  0.6152,  0.0792,\n",
      "         0.3139,  0.3393,  0.5838,  0.3583,  0.6823,  1.6280,  0.3131,  0.3644,\n",
      "         1.3357,  0.1446,  0.4538,  1.1777,  0.4639,  1.6222,  1.7910,  0.1177,\n",
      "         1.2142,  0.6033,  0.7661,  0.9423,  1.6478,  0.3464, -0.0377,  0.5409,\n",
      "         0.6091,  0.5738,  0.8602,  0.8657,  0.9904,  0.8299,  0.5401,  1.1058,\n",
      "         0.0659,  1.4797,  1.9358,  0.6036,  1.3168,  1.4556,  0.0692,  0.7724,\n",
      "         0.3411,  0.3799,  0.6570,  0.1984,  0.1871,  0.4183,  0.7854,  0.1020],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 3.9441e-01, -2.6280e-02, -1.9648e-01, -8.9235e-01,  3.6459e-01,\n",
      "         1.5012e-01, -1.0540e+00, -7.6283e-01,  4.4103e-01, -9.7413e-01,\n",
      "         6.4420e-01,  7.6888e-01, -1.6323e-01,  1.4555e+00,  8.9009e-02,\n",
      "        -3.3915e-02,  1.6482e-01, -6.0938e-01,  4.2968e-01, -1.5188e+00,\n",
      "        -2.4838e-01, -6.7980e-01, -4.3806e-03, -3.8719e-01,  1.8000e-01,\n",
      "         1.9706e-01,  6.2888e-01,  7.1655e-02, -3.8646e-01,  4.3337e-01,\n",
      "        -9.8484e-02, -7.1309e-02,  2.4229e-01,  9.0494e-03,  6.7810e-01,\n",
      "        -4.9852e-01,  4.9506e-01,  1.1053e+00,  3.0910e-01,  4.5512e-01,\n",
      "        -7.6005e-01, -4.1376e-01,  1.1769e-02,  1.4208e-01,  1.4923e-01,\n",
      "         2.0372e-02, -4.6009e-01,  3.3950e-02,  3.5057e-01,  1.6252e-01,\n",
      "         2.2372e-01,  1.5812e-01,  4.1064e-01, -1.0193e+00, -4.4707e-01,\n",
      "         2.9332e-01,  1.4618e-01, -8.0228e-04,  1.6104e-01,  8.5166e-01,\n",
      "         5.2324e-01,  6.9600e-01, -3.3049e-01, -3.9272e-01,  6.4623e-01,\n",
      "        -7.5676e-01,  9.2983e-01,  3.4630e-01, -6.9633e-01,  2.8014e-02,\n",
      "        -4.4683e-01,  1.8813e-02,  2.4536e-01,  3.1576e-01,  3.1157e-01,\n",
      "         1.3878e-01,  1.2668e-01,  3.7554e-01, -8.0975e-02, -1.8911e-01,\n",
      "        -1.9849e-01,  1.1603e+00, -3.0706e-01, -7.5770e-01,  5.8591e-01,\n",
      "        -9.0598e-01,  7.5407e-01,  6.2085e-01, -4.1743e-01, -3.4326e-01,\n",
      "         1.9841e-01, -1.0930e-01, -4.7600e-02, -1.6971e-01,  6.5975e-01,\n",
      "         4.1850e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.6342]],\n",
      "\n",
      "         [[-0.2653]],\n",
      "\n",
      "         [[-0.1939]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1598]],\n",
      "\n",
      "         [[-0.3592]],\n",
      "\n",
      "         [[ 0.2206]]],\n",
      "\n",
      "\n",
      "        [[[-0.3905]],\n",
      "\n",
      "         [[-0.3036]],\n",
      "\n",
      "         [[-0.1696]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2327]],\n",
      "\n",
      "         [[-0.2453]],\n",
      "\n",
      "         [[ 0.3759]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0154]],\n",
      "\n",
      "         [[ 0.1616]],\n",
      "\n",
      "         [[ 0.1289]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5397]],\n",
      "\n",
      "         [[ 0.6260]],\n",
      "\n",
      "         [[-0.2751]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2470]],\n",
      "\n",
      "         [[-0.1071]],\n",
      "\n",
      "         [[ 0.5613]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0303]],\n",
      "\n",
      "         [[-0.3753]],\n",
      "\n",
      "         [[ 0.1073]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2491]],\n",
      "\n",
      "         [[ 0.3526]],\n",
      "\n",
      "         [[-0.1132]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1788]],\n",
      "\n",
      "         [[ 0.1635]],\n",
      "\n",
      "         [[ 0.6467]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1722]],\n",
      "\n",
      "         [[-0.2247]],\n",
      "\n",
      "         [[-0.3815]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5981]],\n",
      "\n",
      "         [[ 0.0730]],\n",
      "\n",
      "         [[ 0.1940]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.4180,  1.0565,  1.2606,  1.5050,  1.1934,  0.6227,  1.5997,  0.7592,\n",
      "         0.9825,  0.2139,  1.2264,  0.9486,  0.4930,  1.5046,  0.8954,  1.1157,\n",
      "         0.5880,  0.9704,  1.2444,  1.0706,  1.6922,  0.3001,  0.1889,  0.7270,\n",
      "         0.8837,  1.6705,  1.0222,  1.6926,  1.0445,  0.8950,  1.1185,  0.6984,\n",
      "         1.1347,  1.3652,  2.4004,  0.9238,  1.0496,  0.6618,  0.4681,  1.9006,\n",
      "         0.3603,  1.4823,  0.4713,  1.0589,  0.9236,  1.1342,  1.8356,  1.2034,\n",
      "         0.4307,  1.3937,  0.8354,  1.9710,  0.9888,  0.7939,  0.8029,  0.9450,\n",
      "         0.1988,  1.8473,  1.4003,  1.5797,  1.2958,  1.0911,  1.0888,  1.5584,\n",
      "         0.7311,  0.7647,  1.3171,  0.4324,  0.3510,  0.7190,  0.4064,  1.2858,\n",
      "         0.6941,  0.3781,  1.0006,  1.2799,  0.9341,  1.3058,  1.6299,  1.4842,\n",
      "         0.7752,  1.1546,  0.7867,  1.8205,  1.8427,  1.3281,  0.3412,  1.0272,\n",
      "         0.8112,  0.9740,  0.7050,  1.2762,  0.7155,  1.4098,  1.1584,  0.7447,\n",
      "         1.4691,  1.6604,  0.3470,  1.0319,  1.4839,  0.5395,  1.1383,  1.4983,\n",
      "         0.8018,  0.7118,  1.4331,  1.8167,  0.7088,  1.3103,  2.3186,  0.5933,\n",
      "         1.2650,  0.5014,  1.3242,  1.5790,  0.9819,  1.2405,  0.7685,  0.6118,\n",
      "         1.1918,  0.5809,  1.1804, -0.0847,  1.3351,  0.9988,  0.5452,  0.6717,\n",
      "         0.5383,  1.7862,  1.2899,  1.8034,  0.9414,  0.2189,  1.8905,  1.0402,\n",
      "         0.4352,  1.2736,  0.9326,  0.7348,  0.3096,  1.8718,  1.5753,  0.9660,\n",
      "         1.0626,  0.9251,  0.6196,  0.8124,  0.4636,  1.2162,  1.2014,  1.0238,\n",
      "         1.0383,  0.1207,  1.0504,  0.5142,  1.1725,  0.9659,  1.4877,  1.0642,\n",
      "         0.5825,  0.6321,  0.5615,  1.1863,  1.0804,  1.8906,  0.7737,  1.6825,\n",
      "         0.6114,  1.0580,  0.4236,  0.6672,  1.6117,  1.1132,  2.2540,  1.0711,\n",
      "         1.1877,  1.0732,  0.8401,  2.1315,  1.3755,  1.4091,  1.2692,  1.4484,\n",
      "         0.9569,  0.7312,  0.8203,  0.9013,  1.0784,  0.8038,  0.5396,  1.4233,\n",
      "         1.0538,  2.0613,  1.1445,  1.7795,  1.0012,  1.4222,  0.7044,  1.1706,\n",
      "         0.4470,  0.6787,  1.5925, -0.0085,  1.4263,  1.2320,  1.0407,  1.3003,\n",
      "         0.9875,  0.1425,  2.3025,  0.3586,  1.0502,  1.0110,  0.3975,  0.4344,\n",
      "         0.0615,  1.5330,  0.7468,  1.0796,  1.0652,  0.3801,  0.8300,  1.5514,\n",
      "         1.4111,  0.7479,  1.3838,  1.6558,  0.4768,  1.0176,  1.4015,  0.7040,\n",
      "         0.5785,  0.4555,  1.0735,  1.3301,  1.3891,  1.0306,  0.8573,  0.4435,\n",
      "         1.1349,  0.7689,  0.6643,  0.6971,  1.3825,  1.6940,  1.4315,  2.6007,\n",
      "         0.0929,  1.4787,  0.9212,  1.3956,  1.5325,  1.5992,  0.0360,  0.9137,\n",
      "         1.0532,  0.3951,  1.1966,  0.4586,  1.4822,  2.4728,  1.2731,  0.3656,\n",
      "         1.0168,  1.3291,  0.9370,  0.5470,  1.1252,  2.0835,  0.4842,  1.6998,\n",
      "         1.0608,  1.0926,  1.2838,  0.3891,  1.0364,  0.8531,  1.4050,  0.8130,\n",
      "         1.4666,  2.4404,  0.8448,  0.6594,  1.5336,  1.5902,  0.4689,  1.4070,\n",
      "         0.8873,  0.5825,  1.6828,  1.5407,  0.8723,  0.4429,  0.8371,  0.8477,\n",
      "         0.4298,  1.5288,  1.3172,  1.2344,  0.6745,  0.9767,  0.5637,  2.0190,\n",
      "         0.4014,  0.9095,  0.6633,  1.0617,  1.5185,  1.5613,  0.8880,  1.2458,\n",
      "         0.7090,  0.8883,  1.1114,  0.3761,  0.3104,  1.6788,  0.0879,  1.7245,\n",
      "         0.8162,  1.2564,  1.2213,  0.5506,  0.5295,  1.0264,  0.5933,  1.6367,\n",
      "         1.9396,  0.6397,  0.8233,  1.1131,  0.9779,  0.2922,  1.6991,  1.8083,\n",
      "         0.9049,  0.9987,  0.2959,  0.8107,  0.8242,  0.3662,  0.7127,  2.5761,\n",
      "         0.5308,  1.2649,  1.8075,  0.6540,  0.7599,  1.3430,  0.3521,  1.0159,\n",
      "         0.2548,  1.8761,  0.7191,  0.9614,  1.1170,  0.5777,  0.7463,  0.9375,\n",
      "         1.5350,  1.7599,  1.5143,  0.9207,  0.5175,  1.0532,  0.3219,  1.2311,\n",
      "         0.7505,  0.4199, -0.1756,  1.6356,  1.2015,  0.5223,  0.6823,  1.2353,\n",
      "         1.2293,  1.2616,  0.8239,  0.8857,  1.7073,  0.9236,  0.8455,  2.1339,\n",
      "         1.7385,  1.7649,  0.6797,  0.3431,  1.0984,  1.5809,  1.5480,  2.1557,\n",
      "         0.8049,  1.5458,  1.5062,  1.6657,  0.9777,  1.6704,  1.5463,  1.0738,\n",
      "         1.0733,  0.5278,  0.8056,  0.9806,  0.4608,  0.7639,  0.5497,  1.1939,\n",
      "         0.4310,  1.6841,  0.7023,  1.2491,  0.1840,  0.9719,  0.7431,  1.4466,\n",
      "         0.9846,  1.5638,  0.8882,  0.7290,  0.4300,  1.7636,  1.2970,  1.2049,\n",
      "         1.8511,  0.6570,  0.8289,  1.7070,  1.6041,  0.9599,  0.6500,  0.9752,\n",
      "         0.9478,  1.7544,  0.7664,  1.5505,  0.8531,  0.5601,  1.8012,  1.1747,\n",
      "         0.8183,  0.8770,  0.7707,  0.4427,  1.2154,  0.1212,  1.0816,  1.9429,\n",
      "         1.5041,  1.7660,  0.4459,  1.1687,  1.5845,  1.1718,  0.8861,  0.6898,\n",
      "         0.6359,  0.6939,  1.1768,  0.8279,  1.2625,  0.7341,  1.2186,  1.2315,\n",
      "         1.4309,  1.4970,  0.9455,  1.5386,  1.4068,  0.6847,  0.6117,  0.5367,\n",
      "         0.9128,  0.8027, -0.2950,  1.7267,  1.0635,  0.2090,  1.9165,  1.0741,\n",
      "         0.1683,  1.5748,  0.9972,  1.1872,  1.6312,  0.9396,  0.6487,  1.5079,\n",
      "         1.0528,  0.8923,  0.6528,  1.0112,  0.6116,  0.7001,  1.7441,  0.7030,\n",
      "         0.8872,  0.6820,  0.7747,  1.2490,  1.0728,  1.5270,  0.9097,  0.5113,\n",
      "         1.6131,  1.1882,  0.9662,  1.5018,  0.0956,  0.6553,  1.9045,  1.2146,\n",
      "         2.1315,  0.5608,  1.5729,  1.6308,  0.7946,  0.0108,  1.1394,  0.6959,\n",
      "         2.2099,  0.6220,  1.1543,  1.6234,  1.8728,  0.7038,  1.1713,  0.5245,\n",
      "         0.5404,  0.8205,  0.9006,  1.2035,  1.6182,  1.0270,  0.9838,  1.6337,\n",
      "         1.4194,  1.5806,  0.8452,  1.0513,  0.4110,  1.2495,  1.7675,  1.6746,\n",
      "         2.0262,  1.0272,  1.9845,  1.0995,  1.1257,  1.1955,  1.5149,  1.3302,\n",
      "         0.4187,  0.8417,  0.8599,  0.9919,  0.7652,  0.6381,  0.6729,  0.6887,\n",
      "         0.4471,  1.4217,  0.6844,  1.8143,  0.1888,  1.3224,  0.3323,  0.5273,\n",
      "         1.3409,  0.6872,  0.6760,  1.1014,  1.8061,  1.5442,  0.5606,  0.8043],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.7331e-01,  6.9328e-01, -5.4332e-01, -4.9094e-01, -5.9681e-01,\n",
      "        -1.1167e+00, -1.2897e+00, -2.1385e+00, -2.1900e+00, -1.2548e-01,\n",
      "        -4.0664e-01,  1.8843e+00, -2.1090e-01, -7.1462e-01,  6.8806e-01,\n",
      "        -5.3481e-01,  1.9842e-01, -2.3323e+00, -7.5348e-01,  6.2026e-02,\n",
      "        -1.3674e+00,  2.6656e-01,  1.1123e-01, -3.7977e-01, -7.3006e-01,\n",
      "        -2.2903e+00, -2.1408e+00,  1.6817e-01,  8.3484e-01, -3.2949e-01,\n",
      "         1.0379e+00, -1.5573e+00, -3.5388e-01, -1.2814e-02, -3.3265e+00,\n",
      "        -2.4392e+00,  1.7118e-01,  1.8373e+00,  5.4706e-01, -2.0698e+00,\n",
      "         2.0855e-01,  1.5141e-03, -1.3482e+00, -8.2122e-01,  1.2636e+00,\n",
      "        -1.5373e+00, -3.0013e-01, -1.6028e+00,  2.5733e-01, -1.9706e+00,\n",
      "        -9.3467e-01,  1.0324e-01,  8.5883e-01,  1.1537e+00, -4.4217e-01,\n",
      "        -1.8951e+00, -1.1866e+00,  1.4942e-01, -3.4218e-01,  3.6238e-01,\n",
      "         8.9326e-02, -2.0008e+00,  3.7657e-01, -3.7032e-01,  1.1927e+00,\n",
      "        -1.6209e+00,  4.1400e-01,  1.1542e+00, -5.0377e-01,  4.6224e-01,\n",
      "         8.2498e-01,  9.6702e-02, -2.2762e+00,  1.7747e-01, -5.4849e-01,\n",
      "        -7.4414e-01, -4.4813e-01, -1.5469e+00, -7.6424e-02, -1.1557e+00,\n",
      "        -3.1530e-01, -5.3174e-01, -7.1341e-01, -9.5700e-01,  2.3761e-01,\n",
      "         3.0030e-02, -5.1248e-01, -4.7283e-01, -2.1446e+00, -1.7427e+00,\n",
      "         1.2898e+00,  1.3390e-01, -9.6108e-01, -7.6869e-01,  9.6283e-02,\n",
      "         4.3600e-01, -5.3191e-01,  2.3458e-01, -2.1829e+00, -1.7051e+00,\n",
      "         5.5416e-01,  1.3988e-02, -5.3122e-01, -1.7421e-01, -1.1030e-02,\n",
      "         4.0350e-01, -2.0161e+00,  5.8178e-02,  1.0800e+00,  4.7214e-01,\n",
      "        -2.7286e+00,  4.9039e-02, -1.0833e+00,  1.7943e-01, -9.3117e-01,\n",
      "        -1.1333e-01, -4.1838e-01, -1.4403e+00, -1.6853e+00, -1.5563e+00,\n",
      "        -1.5001e+00,  8.3899e-02,  3.6147e-01, -8.0935e-01, -1.8315e+00,\n",
      "        -1.9864e+00, -4.7163e-02,  1.5991e+00, -1.4364e+00, -3.0639e+00,\n",
      "        -6.6671e-01, -1.6262e+00,  1.1080e-01,  5.3716e-02, -1.2856e+00,\n",
      "        -1.1994e-02, -2.2034e-01, -5.5558e-01, -6.2025e-02,  8.2848e-01,\n",
      "         6.8299e-02, -6.9038e-01,  8.2343e-01,  5.6371e-02, -1.7538e+00,\n",
      "        -1.0840e+00,  6.3037e-01, -7.3928e-01,  1.1340e+00, -1.2028e+00,\n",
      "        -1.1306e+00, -5.6341e-01,  3.3098e-01,  3.4169e-01, -6.8762e-01,\n",
      "        -9.5583e-01, -3.0024e-01, -1.1459e+00, -1.0648e+00,  9.8964e-02,\n",
      "         4.3835e-01, -1.0034e+00,  5.1415e-01, -1.1993e+00,  1.0575e+00,\n",
      "         9.2675e-01, -1.2485e+00, -2.2330e-01, -6.8601e-01, -1.1780e+00,\n",
      "        -1.1937e-02,  6.6424e-01, -1.6702e+00, -5.1300e-01, -3.9806e+00,\n",
      "         1.8763e-01, -2.0971e-01, -5.5998e-01,  1.0248e+00, -1.4412e+00,\n",
      "        -4.4657e-01,  1.3231e+00, -2.1730e+00, -5.8747e-01, -1.3539e+00,\n",
      "        -1.7072e+00,  4.2760e-01, -7.7558e-01, -8.9034e-01, -1.3096e+00,\n",
      "         6.6517e-02, -4.5252e-01, -1.3184e+00,  5.9506e-01, -3.1731e-01,\n",
      "        -4.7119e-01, -1.5289e+00,  6.4308e-01,  5.7408e-01,  1.1546e+00,\n",
      "         1.2018e-01,  4.6059e-01, -7.6070e-01,  8.9251e-01, -1.0364e+00,\n",
      "        -7.9013e-02, -3.3489e-01, -9.3375e-01, -1.1812e+00,  7.8901e-01,\n",
      "        -3.9526e+00,  1.1309e+00, -1.2930e+00, -2.4224e+00,  1.0180e+00,\n",
      "         6.6295e-01,  5.9372e-01,  3.4402e-01, -1.4650e+00,  1.0549e+00,\n",
      "         1.8008e-01, -1.2819e-01,  3.0996e-02,  6.3839e-01, -5.7821e-02,\n",
      "        -3.0610e-01,  2.3580e-01,  7.9523e-01,  1.0107e+00, -5.6724e-01,\n",
      "        -1.2340e-01, -6.3464e-01, -1.1001e+00,  9.9514e-01, -1.0980e+00,\n",
      "        -1.2941e+00, -5.7632e-02, -9.2334e-01, -1.1497e-01, -3.5100e-01,\n",
      "        -9.8549e-01, -1.0858e+00, -4.6868e-01, -1.5374e+00, -3.4802e-01,\n",
      "        -1.1220e+00,  7.6085e-01,  2.1282e-01,  1.4020e+00, -4.7252e+00,\n",
      "        -6.5760e-01,  2.4476e-01, -8.6923e-01, -6.8806e-02,  1.7836e+00,\n",
      "        -4.4381e-01, -1.3935e+00,  1.8971e-02, -1.2555e+00,  3.3029e-01,\n",
      "        -5.9311e-01, -3.1636e+00,  6.0777e-01, -6.1356e-02, -1.4223e+00,\n",
      "         9.3742e-02, -7.7406e-01,  6.3842e-01, -3.9727e-01, -7.8629e-01,\n",
      "        -2.7541e-03, -4.5531e-01, -8.3637e-01, -1.0939e+00, -1.6901e-01,\n",
      "         1.5937e+00, -8.2536e-01, -4.9433e-01, -1.2093e+00,  7.1533e-01,\n",
      "        -4.8653e-01,  6.1539e-01, -1.1961e+00, -8.0857e-01, -4.8184e-01,\n",
      "        -7.4990e-01, -5.0300e-01,  1.1777e+00,  8.2062e-02, -2.0093e-01,\n",
      "        -1.7625e+00,  1.5761e-01, -8.4585e-01, -4.3095e-02,  2.9685e-01,\n",
      "        -3.5895e-01,  6.6830e-01,  1.2373e+00,  3.8487e-01, -2.3692e+00,\n",
      "        -6.7367e-02, -1.1297e+00,  4.1486e-01,  3.2493e-01,  2.0235e-01,\n",
      "        -1.1608e+00, -9.2885e-02, -1.2207e-01, -4.2720e-01, -5.6528e-01,\n",
      "         7.4813e-01, -6.4169e-01, -1.7251e+00,  8.3231e-01, -3.6247e-01,\n",
      "         4.8988e-01,  3.0712e-01, -8.2106e-01,  1.6046e-01,  2.4462e-01,\n",
      "        -5.7986e-01,  3.2551e-01, -5.6617e-01,  1.1144e+00,  4.5700e-01,\n",
      "        -8.6295e-01, -3.2000e-01, -4.4162e-01,  1.1858e+00, -2.3230e-01,\n",
      "         7.7091e-01,  3.1990e-01,  1.1713e+00,  2.1258e-01,  3.3401e-01,\n",
      "        -1.5403e+00, -1.5729e+00, -7.5154e-01,  2.4157e-02, -8.8547e-01,\n",
      "         3.9547e-01,  1.6975e-01, -1.5755e+00, -3.2528e+00, -9.2729e-01,\n",
      "        -1.2173e+00, -1.5359e+00, -6.8771e-01,  1.7401e-01,  4.7761e-01,\n",
      "         8.3551e-01, -1.4828e+00,  6.9971e-01,  1.0239e+00, -7.4445e-01,\n",
      "         1.1193e-01,  4.9530e-01,  1.3178e+00, -2.1818e+00,  5.2332e-01,\n",
      "         5.6804e-01, -1.3669e-01, -9.9059e-01, -9.8404e-01,  1.0157e+00,\n",
      "         9.1820e-01, -2.3446e-01,  5.7901e-01, -2.7687e-02,  2.6726e-01,\n",
      "         2.6703e-01, -2.3017e+00, -1.4751e+00,  1.3359e+00,  8.8228e-01,\n",
      "        -2.1913e-01, -6.5973e-02, -2.5641e+00, -1.1000e+00, -4.0014e-01,\n",
      "         5.8670e-01, -1.7573e+00, -1.3425e+00,  7.5941e-01, -2.0506e+00,\n",
      "        -5.0381e-01,  1.0894e+00, -3.2066e-01,  7.6136e-01, -7.6825e-01,\n",
      "        -1.4119e+00, -4.2538e-01,  1.1969e+00, -1.0892e+00,  6.7017e-02,\n",
      "        -8.1932e-01, -1.4118e+00, -1.5784e+00, -1.5129e+00, -1.0100e-02,\n",
      "        -7.7246e-01,  2.3057e-01, -2.3152e-01,  1.1947e+00,  9.2085e-01,\n",
      "        -5.0342e-01, -1.1016e+00, -1.1239e+00,  8.6235e-01, -4.9950e-01,\n",
      "         1.6954e-01, -6.0546e-01,  1.0195e+00, -1.2679e-01, -1.0645e+00,\n",
      "         3.2938e-01, -1.4407e+00, -1.4005e+00,  7.7426e-01, -9.0933e-01,\n",
      "        -2.4603e-01,  3.8881e-01, -6.3830e-01, -1.1644e+00, -7.9705e-01,\n",
      "         3.3433e-01,  2.0560e-01, -1.0261e+00, -6.0530e-01,  7.1656e-01,\n",
      "         2.0968e-02, -1.2406e+00, -1.2252e+00,  3.9752e-01, -3.5806e-01,\n",
      "        -2.2163e+00, -9.3764e-01, -8.6836e-02,  6.8944e-01, -6.0783e-01,\n",
      "         8.4052e-01,  2.4336e-01, -3.7269e-01, -9.7780e-02, -3.3222e-01,\n",
      "        -1.2898e+00, -1.4916e+00,  1.4365e-02,  6.2176e-02, -1.9623e+00,\n",
      "         7.4115e-01, -1.5191e+00, -6.3901e-01, -2.1657e-01, -8.5934e-01,\n",
      "         9.1620e-01,  6.7125e-02,  1.0668e+00,  3.2060e-01,  4.1339e-01,\n",
      "        -1.0762e+00,  1.0339e+00, -1.9628e+00, -1.3244e+00, -5.0325e-02,\n",
      "         1.0774e+00, -8.8657e-01, -4.7170e-01,  2.1688e-01,  2.8697e-01,\n",
      "         5.6151e-01,  9.8311e-01,  6.5150e-01,  1.6576e+00,  2.5759e-01,\n",
      "        -2.8424e+00, -2.2111e-01,  7.7584e-01, -3.0023e-01,  7.5890e-01,\n",
      "         3.2078e-01, -1.6556e+00, -1.3524e+00, -1.1904e-01, -1.0136e-01,\n",
      "         1.8071e-02, -5.0670e-01, -9.9464e-01, -5.0531e-01, -1.6141e+00,\n",
      "         5.3888e-01,  8.1700e-01,  9.4520e-01, -9.8496e-01, -2.4981e-02,\n",
      "         8.1172e-01, -1.6705e+00, -1.2569e+00,  1.2634e-01, -1.8745e+00,\n",
      "        -6.0186e-01, -2.1659e+00, -1.1729e+00,  6.4207e-02, -3.6420e-01,\n",
      "        -1.3220e+00,  8.1578e-01, -2.3625e-01,  7.8958e-01, -3.0473e-01,\n",
      "        -3.9882e-01, -2.2407e+00, -4.6579e+00,  4.3156e-01, -7.1752e-01,\n",
      "         6.1772e-01,  8.7591e-01,  5.9672e-01,  1.4456e+00, -1.7387e+00,\n",
      "        -2.1983e+00,  6.3873e-01, -2.5621e-01, -1.0652e+00, -5.8235e-01,\n",
      "         4.5084e-01,  1.8016e+00,  5.3622e-01, -1.8746e+00,  1.1837e+00,\n",
      "         3.8175e-01, -1.6244e-01,  2.2090e-02, -1.5539e+00, -8.0167e-01,\n",
      "         4.7546e-01, -4.9893e-01, -1.8984e+00, -1.1670e+00, -7.6648e-01,\n",
      "         8.5605e-01, -5.0934e-01,  8.4134e-03, -2.0928e+00, -7.3327e-01,\n",
      "        -2.2903e+00, -2.0389e+00, -1.2464e+00, -1.8478e-01, -5.5472e-01,\n",
      "        -1.4408e+00, -1.1003e+00,  3.0115e-01,  3.7424e-01,  1.0900e+00,\n",
      "        -1.0763e+00,  4.0498e-01,  7.8111e-01,  9.8499e-01,  1.6389e-01,\n",
      "         2.2583e-01, -1.2700e+00, -5.7396e-01, -6.3088e-01,  2.3573e-01,\n",
      "         3.6523e-01,  1.2221e+00, -5.2338e-02, -1.3948e+00, -6.0355e-01,\n",
      "         3.2626e-02,  8.6377e-01, -3.2060e+00,  8.6452e-01,  2.7930e-01,\n",
      "        -9.8484e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2349, -0.1203,  0.6724],\n",
      "          [-0.2405, -0.3981, -0.0352],\n",
      "          [-0.2620, -0.2657, -0.1333]]],\n",
      "\n",
      "\n",
      "        [[[-0.1043,  0.1485, -0.1248],\n",
      "          [-0.1850, -0.7007, -0.2758],\n",
      "          [ 0.1277,  0.3509,  0.2341]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2896,  0.3728,  0.3257],\n",
      "          [ 0.2158,  0.4853,  0.3978],\n",
      "          [ 0.1365,  0.2415,  0.1742]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.7188,  0.2216, -0.0127],\n",
      "          [ 0.4460,  0.4459,  0.1283],\n",
      "          [-0.0543,  0.2768,  0.2730]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7787,  0.1918, -0.0166],\n",
      "          [-0.4846, -0.1182, -0.3507],\n",
      "          [ 0.0193,  0.0967,  0.0183]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2433,  0.2682, -0.3164],\n",
      "          [ 0.3247,  0.6925,  0.1848],\n",
      "          [-0.2899,  0.0812,  0.0761]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.5713,  1.4677,  2.1551,  0.3927,  1.4357,  1.5349,  0.4808,  1.4102,\n",
      "         0.8545,  0.4785,  1.6346,  1.7961,  0.8161,  0.6786,  1.5580,  1.6452,\n",
      "         1.6055,  0.7700,  0.4725,  1.6537,  2.9655,  1.9823,  0.8871,  1.1234,\n",
      "         1.4670,  3.7329,  0.4692,  2.4645,  1.8787,  1.6557,  1.3876,  0.5172,\n",
      "         1.3821,  0.0524,  5.9384,  2.5855,  0.9097,  1.5196,  1.4811,  2.9720,\n",
      "         1.6545,  1.8705,  1.3709,  1.4675,  1.8172,  1.0273,  1.1728,  0.6040,\n",
      "         1.3803,  2.2174,  1.0078,  1.0956,  1.1673,  1.2717,  1.3531, -0.2132,\n",
      "         1.2059,  1.7011,  1.2715,  1.5594,  1.1463,  3.2469,  1.4302,  0.6817,\n",
      "         1.3584, -0.0306,  0.7112,  1.6292,  0.9883,  1.5906,  1.8569,  1.0647,\n",
      "         0.7822,  0.9599,  2.1428,  1.3339,  1.4444,  1.7243,  0.8717,  0.8367,\n",
      "         2.5680,  1.7530,  1.0997,  1.6192,  1.3584,  1.6459,  1.1723,  1.0673,\n",
      "         0.4094,  0.5743,  1.7837,  1.4092,  0.7935,  0.8637,  1.9843,  1.5259,\n",
      "         1.4196,  0.3977,  0.2407,  1.0004,  1.8609,  1.2968,  1.2230,  1.1819,\n",
      "         1.2756,  0.8807,  0.6199,  0.0187,  1.7473,  1.5136,  2.7727,  1.1519,\n",
      "         1.2710,  1.7842,  2.2962,  1.4457,  0.8744,  0.6536,  0.9510,  1.1726,\n",
      "         0.9810,  1.2417,  1.3565,  1.4151,  2.6085, -0.1105,  1.1982,  1.0469,\n",
      "         1.5133,  3.9632,  2.2325,  4.3512,  2.4085,  1.8418,  1.9227,  1.2907,\n",
      "         1.3648,  1.5778,  1.4055,  1.9050,  1.5595,  1.4188,  2.2085,  1.3132,\n",
      "         0.5320,  1.3026,  1.7958,  1.6179,  1.6512,  2.1340,  1.1459,  1.2814,\n",
      "         1.6970,  1.3524,  1.2682,  1.1426,  1.4711,  0.6585,  2.3276,  0.9570,\n",
      "         1.4454,  1.6068,  2.3845,  2.1580,  1.4079,  1.1658,  1.5180,  1.6186,\n",
      "         0.9589,  0.8364,  1.6826,  1.5403,  0.0123,  1.0855,  4.1024,  1.1501,\n",
      "         1.3196,  0.6998,  1.5514,  2.8458,  0.9894,  1.4149,  2.2408,  1.4511,\n",
      "         1.3713,  0.5509,  0.9412,  0.9014,  1.1448,  1.1927,  1.0813,  1.4057,\n",
      "         1.8928,  1.8153,  0.5835,  1.1220,  0.3160,  1.5147,  1.0438,  2.1241,\n",
      "         2.6317,  1.4686,  0.4121,  1.7702,  1.8400,  1.6259,  1.3817,  1.9071,\n",
      "         1.4810,  1.5733,  4.8016,  0.9840,  1.9616,  2.0730,  1.4744,  1.6204,\n",
      "         0.4264,  1.0150,  1.6709,  1.8787,  0.8035,  1.2043,  2.0351,  1.8834,\n",
      "         1.8893,  1.4467,  0.9143,  1.3054,  1.7276,  0.8538,  2.0642,  1.3566,\n",
      "         1.0308,  1.7409,  1.0702,  1.8840,  0.7681,  1.1006,  1.7448,  1.7664,\n",
      "         2.2693,  3.3925,  1.3088,  1.4887,  1.8892,  0.8683,  0.4966,  2.1775,\n",
      "         1.4790,  4.5973,  1.2887,  1.0826,  0.9323,  1.1052,  1.3587,  1.1294,\n",
      "         0.2703,  1.3348,  0.1540,  1.5392,  1.1619,  5.1355,  2.3342,  2.5729,\n",
      "         0.7672,  1.4703,  1.0598,  1.4377,  1.2704,  0.9247,  1.4790,  0.8102,\n",
      "         0.7042,  1.6648,  1.3728,  2.0445,  1.6499,  1.5264, -0.2786,  1.9710,\n",
      "         0.8921,  1.1073,  1.5288,  1.3463,  1.0757,  1.2602,  0.9691,  1.7001,\n",
      "         1.4226,  1.3594,  0.8361,  1.5680,  1.5186,  1.5480,  1.2434,  1.3262,\n",
      "         1.5734,  1.5803,  1.4341,  0.8883,  1.4682,  2.0213,  1.2984,  2.7288,\n",
      "         1.9647,  0.2124,  1.8129,  0.9445,  1.6852,  2.2356,  0.9193,  2.2191,\n",
      "         1.0065,  1.5431,  1.8938,  1.8506,  1.3300,  1.9983,  1.4752,  1.6685,\n",
      "         1.8566,  1.6406,  1.9084,  1.3087,  1.1690,  0.5792,  0.8929,  0.6524,\n",
      "         0.9633,  1.9913,  1.8456,  1.4642,  2.0355,  1.8600,  1.2686,  1.2364,\n",
      "         0.6700,  1.4610,  2.2536,  1.2171,  2.0931,  0.6010,  0.6900,  2.8497,\n",
      "         1.1855,  0.9572,  4.6990,  1.2861,  1.3984,  2.0048,  2.2282,  0.8880,\n",
      "         1.5355,  2.2512,  0.8112,  0.5663,  1.3467,  1.7031,  0.9307,  1.4447,\n",
      "         0.5483,  1.1718,  0.8486,  0.8444,  1.8290,  1.7372,  1.9382,  1.7396,\n",
      "         2.2344,  2.1886,  1.4382,  4.2800,  0.4366,  1.5999,  1.8241,  1.4928,\n",
      "         1.2020,  2.7136,  0.6795,  1.1787,  1.4667,  0.4874,  1.8021,  2.7142,\n",
      "         4.1067,  1.7854,  1.6589,  1.6890,  1.4126,  1.8208,  0.7966,  0.8442,\n",
      "         1.4305,  1.4906,  1.2411,  1.0809,  0.3077,  2.2154,  0.8257,  1.2756,\n",
      "         1.0151,  1.6448,  0.9422,  1.4606,  1.5501,  1.1841,  0.6570,  1.1373,\n",
      "         1.5684,  1.5859,  2.1898,  1.2450,  1.2380,  1.5607,  0.3249,  1.3146,\n",
      "         0.7813,  2.6302,  1.1987,  1.1833,  1.2233,  1.2724,  1.8551,  0.5232,\n",
      "         0.5329,  2.0986,  1.7451,  1.0896,  1.7383,  1.4519,  1.4005,  1.0359,\n",
      "         1.3556,  1.4704,  0.8501,  2.5906,  0.3148,  1.5243,  2.3924,  1.2443,\n",
      "         1.4448,  1.2322,  0.8086,  1.7471,  1.2243,  0.8562,  1.3847,  0.7378,\n",
      "         1.8789,  1.0592,  1.1296,  1.5103,  0.6019,  2.2093, -0.0159,  2.0977,\n",
      "         1.9102,  1.8644,  1.1714,  1.8717,  1.2812,  1.5961,  0.6904,  2.4435,\n",
      "         1.1224,  2.0560,  1.0271,  1.4517,  1.0823,  1.5287,  1.7871,  1.3306,\n",
      "         1.4586,  1.8750,  1.8297,  2.5568,  1.9610,  1.2202,  1.1774,  1.9826,\n",
      "         1.5199,  3.1527,  2.1576,  1.5173,  1.0348,  1.2821,  1.1307,  0.8352,\n",
      "         0.9222,  0.2986,  1.7461,  1.7401,  1.2503,  0.7284,  0.7126,  1.8778,\n",
      "         0.6279,  1.9863,  1.4060,  2.4991,  1.0585,  3.6118,  0.8072,  1.6129,\n",
      "         1.5579,  1.0049, -0.0307,  1.1910,  1.6411,  1.7276,  0.6375,  0.9700,\n",
      "         2.8755,  0.9935,  1.3694,  1.7119,  1.7655,  0.3539,  0.9136,  0.9215,\n",
      "         4.4636,  0.9076,  1.6321,  1.6547,  0.5690,  0.2978,  1.6246,  1.0359,\n",
      "         0.2174,  1.3086,  1.6160,  2.1690,  1.7992,  1.1790,  0.6563,  1.6968,\n",
      "         0.4718,  4.6258,  1.1636,  2.0358,  1.7355,  0.5003,  1.7508,  3.0887,\n",
      "         2.5230,  1.6652,  2.8245,  1.4048,  1.5381,  0.1239,  1.2544,  0.5828,\n",
      "         1.7640,  2.0720,  1.4075,  0.9018,  2.0612,  1.3045,  1.1837,  1.3302,\n",
      "         1.8747,  0.4940,  1.2185,  2.0631,  1.4636,  1.6795,  1.4626,  1.4607,\n",
      "         1.4101,  1.0911,  2.0477,  1.2910,  4.1804,  1.5607,  1.1649,  1.1677],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.6590e+00, -9.0858e-01, -8.3576e-01, -2.7591e-01, -4.1868e-01,\n",
      "        -1.7477e+00,  1.6940e-01, -1.0632e+00,  8.5061e-02, -2.1417e+00,\n",
      "        -7.7957e-01, -2.0237e+00, -2.9724e+00, -1.8915e-01, -2.6021e+00,\n",
      "        -2.4489e+00, -1.5052e+00, -5.6736e-02, -6.7363e-02, -7.5279e-01,\n",
      "         8.1990e-01, -9.5672e-01, -3.7561e-01, -5.4526e-01, -2.1340e+00,\n",
      "        -6.3107e-01,  8.5268e-03, -1.0621e-01, -1.4889e+00, -2.0015e+00,\n",
      "        -9.9222e-01, -2.2887e-01, -5.0668e-01,  3.4145e-02,  5.5697e-01,\n",
      "        -1.5896e+00, -1.2928e+00, -1.9326e+00, -1.3199e+00, -8.9563e-02,\n",
      "        -1.3292e+00, -2.6581e+00, -1.2942e+00, -1.0444e+00, -1.6026e+00,\n",
      "        -6.0293e-01, -7.7825e-01,  1.7821e-01,  2.0901e-01, -2.2302e+00,\n",
      "        -3.2034e-01, -1.0160e+00, -1.8259e+00, -2.8325e-01, -8.8603e-01,\n",
      "         4.2108e-02, -5.4826e-01, -1.0086e+00, -3.9976e-01, -1.0951e+00,\n",
      "         2.1368e-01, -9.6895e-01, -7.7168e-01, -1.2644e-01, -1.9160e+00,\n",
      "         1.6516e-02, -3.0357e-01, -9.1590e-01, -7.6872e-01, -9.6198e-01,\n",
      "        -1.1967e+00, -2.1226e+00, -2.4627e-01, -2.0554e+00, -2.0564e+00,\n",
      "        -3.1109e+00, -7.7440e-01, -2.0349e+00, -5.0382e-01, -2.5049e-01,\n",
      "        -1.4171e+00, -1.5528e+00, -5.1312e-01, -5.7176e-01, -5.1616e-02,\n",
      "        -2.5061e-01, -8.8482e-01, -9.6907e-04, -8.3885e-02, -7.6481e-02,\n",
      "        -1.4754e+00,  3.9420e-02, -2.5357e+00, -5.5279e-01, -1.7944e+00,\n",
      "        -1.4425e+00, -2.3449e+00,  4.4932e-02, -5.5009e-02,  2.9671e-01,\n",
      "        -7.6318e-01, -1.3725e+00, -2.2346e+00,  1.0506e+00, -1.1367e+00,\n",
      "        -1.6006e+00,  5.4554e-02,  9.1172e-02, -1.7897e+00, -5.4171e-01,\n",
      "        -9.9888e-01, -1.0040e+00, -2.1995e+00, -1.7437e+00,  3.4897e-01,\n",
      "        -5.6212e-01, -3.0280e+00, -1.1923e-01, -2.4700e-01, -5.5476e-01,\n",
      "         1.4656e-01, -2.0917e+00, -9.6374e-01, -1.0764e+00, -1.2200e+00,\n",
      "        -6.8169e-02, -4.8268e-01, -1.0560e+00, -3.5696e-02, -9.6321e-01,\n",
      "        -1.1051e+00,  6.7793e-01, -9.3457e-01, -1.5241e+00, -3.2990e-01,\n",
      "        -2.4255e+00, -2.4560e+00, -2.1723e+00, -4.7748e-01, -1.4070e+00,\n",
      "        -1.2425e+00, -5.5495e-01, -1.2938e+00, -1.4929e+00,  1.4806e-01,\n",
      "        -7.8422e-01, -1.2850e+00, -7.7202e-01, -1.2707e+00, -1.3971e-01,\n",
      "        -1.0410e+00, -1.9521e+00, -3.6648e-01, -1.6242e+00, -1.8308e+00,\n",
      "        -2.5117e+00, -2.4449e+00, -3.1520e-01,  1.6498e-01, -3.7308e-01,\n",
      "        -1.1121e+00, -1.0062e+00, -1.7019e+00, -1.2209e+00, -1.8947e+00,\n",
      "         2.8152e-01, -2.8823e+00, -9.6885e-01, -7.1670e-01, -1.1038e+00,\n",
      "        -2.2010e+00, -2.0642e+00,  8.0402e-03, -1.6490e+00, -5.4581e-01,\n",
      "        -2.0154e+00, -3.5472e-01, -7.6210e-01, -1.4431e+00,  3.6722e-01,\n",
      "        -6.5489e-02, -9.6200e-01, -3.5784e-01, -1.1215e+00, -6.9030e-01,\n",
      "        -1.1639e-01, -6.3245e-01, -3.2989e-01, -2.2439e+00, -2.3645e+00,\n",
      "        -1.2833e+00, -9.5087e-01, -2.4001e+00, -1.2873e+00, -2.2865e-01,\n",
      "        -3.7006e-01,  2.8394e-02, -2.5373e+00, -1.7869e+00, -1.5155e+00,\n",
      "        -1.7787e+00, -7.4630e-01, -1.2037e-01, -1.5666e+00, -2.2938e-01,\n",
      "        -8.4439e-01, -2.1325e+00, -1.0009e+00, -2.2606e+00, -1.2910e+00,\n",
      "        -9.8925e-01,  6.8230e-01, -1.0642e+00, -1.6565e+00, -1.3326e+00,\n",
      "        -1.8089e+00, -2.3636e-01,  2.6940e-01, -6.7532e-01, -1.2791e+00,\n",
      "        -3.1563e-01, -2.5856e+00, -1.0128e+00, -7.8642e-01, -1.9603e+00,\n",
      "        -2.4417e+00, -2.6601e-01, -1.6901e-01, -1.7235e+00, -9.4358e-01,\n",
      "        -1.0960e+00, -2.2367e+00, -2.2646e+00, -1.0994e+00, -3.1784e-01,\n",
      "        -2.4799e+00, -2.6270e-01, -1.3914e+00, -1.5970e+00, -1.6834e+00,\n",
      "        -1.2953e+00, -2.1435e+00, -1.1944e+00, -1.0705e+00, -8.8068e-01,\n",
      "         1.3613e-01, -1.4109e-01, -1.2249e+00, -1.3432e+00, -2.5173e+00,\n",
      "        -7.2553e-02, -8.0013e-01, -4.1778e-02, -2.7488e+00, -6.5562e-01,\n",
      "        -1.2894e+00, -1.1682e-01, -1.8090e+00,  3.0260e-02, -1.5317e+00,\n",
      "        -1.6578e+00,  1.9885e-01, -1.3045e+00, -1.7304e+00,  4.4772e-02,\n",
      "        -5.8203e-01, -1.4128e+00, -1.5865e+00, -2.3247e+00, -3.7193e-02,\n",
      "        -1.3660e+00,  8.6191e-01, -4.3174e-01, -7.0065e-01, -1.7758e-01,\n",
      "        -2.2968e+00, -2.1028e+00, -1.4406e+00, -7.5865e-02, -1.4547e+00,\n",
      "        -2.0682e-01, -4.0728e-01, -1.4890e+00, -2.0093e+00, -3.2371e+00,\n",
      "        -9.0416e-01, -3.0227e+00, -1.6729e+00, -9.9757e-01, -8.9050e-01,\n",
      "         2.3742e-01, -1.9623e+00, -1.4380e-01, -1.5377e+00, -5.8138e-01,\n",
      "        -2.1071e+00, -9.1644e-01, -1.6809e+00, -1.3402e+00,  9.1451e-02,\n",
      "        -1.8335e+00, -6.8171e-01, -4.3637e-01, -1.5275e+00, -1.5325e+00,\n",
      "        -1.3490e-01, -1.8779e+00, -1.2358e+00, -1.4994e+00, -1.3651e+00,\n",
      "         1.4035e-01,  8.3559e-02, -2.0916e+00, -1.0961e+00, -1.7028e+00,\n",
      "        -2.4639e+00,  4.0595e-01, -2.1240e-01, -1.4308e+00, -2.7904e+00,\n",
      "        -1.9142e+00, -1.9055e+00, -1.0387e-01, -8.7829e-01, -2.2210e+00,\n",
      "        -4.4856e-01, -3.7266e-01, -1.4107e-01,  1.6472e-01, -1.5470e+00,\n",
      "        -2.4300e+00, -1.0669e+00, -1.6366e+00, -1.2745e+00, -1.0156e+00,\n",
      "        -7.0813e-01, -9.4722e-02, -9.3146e-01, -9.8683e-01, -8.1424e-01,\n",
      "        -4.4517e-01, -2.3248e-01, -5.4871e-02, -7.9714e-01, -2.7314e+00,\n",
      "        -6.4512e-02,  7.4056e-01, -2.4186e+00, -1.1340e+00, -1.2645e+00,\n",
      "        -1.4657e+00,  3.6665e-01, -8.5080e-01, -1.4237e+00, -1.4704e-01,\n",
      "        -6.7984e-01, -1.1537e+00, -1.3706e+00, -6.5700e-02, -8.4495e-01,\n",
      "         5.3539e-01, -2.8072e-02,  5.7379e-01,  6.9969e-02, -9.6012e-01,\n",
      "        -2.2819e+00, -1.2402e+00, -4.9971e-01, -1.3587e+00, -1.3104e+00,\n",
      "        -1.2316e+00,  2.7420e-01, -1.0994e-01, -1.5458e+00, -1.3254e+00,\n",
      "        -2.7103e+00, -1.6174e-01, -1.8462e+00, -3.5721e-01, -2.4628e+00,\n",
      "        -1.8452e+00, -4.0303e-01, -2.4653e+00, -1.8494e+00,  2.4279e-01,\n",
      "         6.8245e-01, -1.3122e+00, -1.4414e+00,  2.1864e-01, -1.5959e+00,\n",
      "        -1.7516e-01,  1.1129e+00, -1.7435e+00,  2.5856e-01, -7.7669e-02,\n",
      "        -2.4708e-01,  6.1506e-02, -6.2719e-01,  2.3752e-01, -5.7857e-01,\n",
      "        -9.5971e-01, -1.3317e+00, -9.2022e-02, -1.1265e+00, -1.2523e+00,\n",
      "        -1.9127e+00, -2.5812e+00, -3.7360e-02, -1.6929e+00,  2.5400e-01,\n",
      "        -1.1963e+00, -3.1407e-01, -7.8846e-01, -7.6050e-01, -2.4173e-01,\n",
      "        -6.4252e-01, -1.0041e-01, -4.4108e-01, -9.0684e-01, -2.4755e+00,\n",
      "        -2.1257e+00, -1.2350e+00, -4.1482e-01,  3.3179e-02, -6.6313e-02,\n",
      "        -1.1265e+00, -2.0435e+00, -5.9456e-01, -6.3342e-01, -1.1961e+00,\n",
      "        -1.4511e+00,  3.0932e-01, -9.0866e-01, -1.4652e-01, -4.0256e-01,\n",
      "        -1.9732e-01, -9.7643e-02, -1.5668e+00, -1.6877e+00, -1.5344e+00,\n",
      "        -2.2130e-01, -1.7550e+00, -1.7138e-01, -1.0066e+00, -4.6799e-01,\n",
      "        -2.9394e-01, -1.1232e-02, -4.0610e-01, -7.5078e-01, -1.1393e+00,\n",
      "        -2.6180e+00, -7.1428e-01, -5.7018e-01, -1.6497e+00, -1.4901e-01,\n",
      "        -2.4899e+00, -1.6047e+00, -8.8933e-01,  1.4020e-01, -1.4387e+00,\n",
      "        -4.1022e-01, -4.0499e-01, -2.0341e-01, -2.8369e-01, -9.5986e-01,\n",
      "        -1.6889e+00, -7.1195e-01, -1.6219e+00, -6.4257e-01, -1.0244e+00,\n",
      "        -1.3307e+00, -3.8570e+00, -8.7866e-01, -7.4646e-01, -1.6403e+00,\n",
      "        -1.9704e-01, -3.9313e-01, -1.6863e+00, -8.3342e-01, -1.5816e+00,\n",
      "        -1.5758e+00,  6.7023e-01, -6.3813e-01, -2.2883e+00, -3.3801e-01,\n",
      "        -2.0443e+00, -6.8295e-01, -4.8177e-01,  3.7771e-01,  1.9965e-02,\n",
      "        -3.4991e+00, -1.5766e+00, -1.9549e+00, -4.8334e-02,  1.2036e-01,\n",
      "        -9.1467e-01,  1.6850e-01, -8.8311e-01, -2.0030e+00, -1.2767e-02,\n",
      "        -3.6553e-01, -3.3701e-01,  1.9184e-01, -1.2344e+00, -7.2513e-01,\n",
      "        -1.1147e-01, -3.2860e-02, -1.7774e+00,  9.7648e-01, -1.0314e+00,\n",
      "        -8.4819e-02, -6.5219e-01, -1.1003e+00,  1.2980e+00, -3.7881e-01,\n",
      "        -2.7072e+00, -1.0578e+00,  8.5089e-01,  6.8780e-01, -1.9343e-01,\n",
      "         1.1358e+00, -1.2587e+00, -2.7133e+00, -1.1599e+00,  2.0405e-01,\n",
      "        -3.4696e-02, -1.2064e+00, -4.5898e-02,  2.5238e-02, -1.5426e+00,\n",
      "        -1.1901e+00, -1.1923e+00, -4.9548e-01, -2.1035e+00, -2.5432e-01,\n",
      "        -1.1826e+00, -2.1233e-01,  1.7253e-01, -2.6839e+00, -1.2148e+00,\n",
      "        -1.7612e+00, -1.9218e-01,  5.0602e-01, -3.3618e-02, -5.7264e-01,\n",
      "        -1.2407e+00,  4.6425e-01, -3.9118e-01, -1.4480e+00,  6.5110e-02,\n",
      "        -2.5291e+00, -1.7483e-01, -8.6233e-01, -1.3129e+00, -1.2431e+00,\n",
      "        -3.1324e-01, -1.5127e+00, -1.9632e+00, -2.2567e+00, -9.0412e-01,\n",
      "        -1.4070e+00, -1.9400e-01, -1.8519e+00, -1.1430e+00, -1.4496e+00,\n",
      "        -9.7808e-01,  7.3138e-01, -5.3609e-01, -1.3424e+00, -2.1927e+00,\n",
      "        -1.2724e+00, -9.6616e-01,  8.4505e-01, -1.9371e+00, -1.4495e+00,\n",
      "        -3.2745e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.7493]],\n",
      "\n",
      "         [[-0.0512]],\n",
      "\n",
      "         [[ 0.1560]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1685]],\n",
      "\n",
      "         [[ 0.2495]],\n",
      "\n",
      "         [[-0.0465]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1231]],\n",
      "\n",
      "         [[ 0.0805]],\n",
      "\n",
      "         [[ 0.0364]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0527]],\n",
      "\n",
      "         [[ 0.1812]],\n",
      "\n",
      "         [[ 0.3591]]],\n",
      "\n",
      "\n",
      "        [[[-0.3389]],\n",
      "\n",
      "         [[ 0.1944]],\n",
      "\n",
      "         [[ 0.3327]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6568]],\n",
      "\n",
      "         [[ 0.2455]],\n",
      "\n",
      "         [[ 0.1234]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2620]],\n",
      "\n",
      "         [[ 0.0244]],\n",
      "\n",
      "         [[-0.0782]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0960]],\n",
      "\n",
      "         [[ 0.0326]],\n",
      "\n",
      "         [[ 0.2033]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2076]],\n",
      "\n",
      "         [[-0.1138]],\n",
      "\n",
      "         [[-0.1343]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1150]],\n",
      "\n",
      "         [[-0.2849]],\n",
      "\n",
      "         [[-0.0544]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2210]],\n",
      "\n",
      "         [[ 0.0612]],\n",
      "\n",
      "         [[-0.1030]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3753]],\n",
      "\n",
      "         [[ 0.0291]],\n",
      "\n",
      "         [[ 0.2168]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1146, -0.2849,  0.1023,  0.0975,  0.1468,  0.1033,  0.0712,  0.0984,\n",
      "         0.0856,  0.1225, -0.2075,  0.1329,  0.1819, -0.0754, -0.0535, -0.3076,\n",
      "        -0.0420, -0.1879,  0.1499,  0.3229, -0.1192, -0.1429,  0.0106, -0.2599],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.3019]],\n",
      "\n",
      "         [[ 0.1470]],\n",
      "\n",
      "         [[-0.3628]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0415]],\n",
      "\n",
      "         [[ 0.0885]],\n",
      "\n",
      "         [[ 0.0180]]],\n",
      "\n",
      "\n",
      "        [[[-0.2242]],\n",
      "\n",
      "         [[ 0.2809]],\n",
      "\n",
      "         [[-0.3613]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1936]],\n",
      "\n",
      "         [[-0.3204]],\n",
      "\n",
      "         [[ 0.0477]]],\n",
      "\n",
      "\n",
      "        [[[-0.0634]],\n",
      "\n",
      "         [[ 0.1766]],\n",
      "\n",
      "         [[-0.0943]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0086]],\n",
      "\n",
      "         [[-0.3473]],\n",
      "\n",
      "         [[ 0.1398]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2821]],\n",
      "\n",
      "         [[ 0.0292]],\n",
      "\n",
      "         [[ 0.3016]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2610]],\n",
      "\n",
      "         [[ 0.3892]],\n",
      "\n",
      "         [[-0.0126]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3533]],\n",
      "\n",
      "         [[ 0.2455]],\n",
      "\n",
      "         [[ 0.1543]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1288]],\n",
      "\n",
      "         [[ 0.5418]],\n",
      "\n",
      "         [[ 0.1036]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3443]],\n",
      "\n",
      "         [[ 0.0365]],\n",
      "\n",
      "         [[ 0.1852]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0292]],\n",
      "\n",
      "         [[ 0.0112]],\n",
      "\n",
      "         [[-0.0053]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-3.8087e-01, -3.9923e-01, -3.0873e-01, -3.9406e-01, -1.9661e-01,\n",
      "        -1.9678e-01,  3.5866e-01, -8.4228e-02, -2.5014e-01, -1.6048e-01,\n",
      "        -4.0076e-01, -3.4584e-01,  3.2436e-01, -3.0533e-01, -5.0644e-02,\n",
      "         3.9313e-02,  2.9653e-01, -7.1788e-02,  4.6074e-02,  2.8949e-01,\n",
      "         9.1458e-02,  1.0668e-01, -1.8233e-01,  3.5081e-01,  4.4167e-01,\n",
      "        -1.3384e-01,  3.1606e-01,  1.0566e-01,  3.9907e-01,  4.0960e-01,\n",
      "        -3.0899e-01, -6.0976e-02, -2.0509e-01, -3.8821e-01,  2.0127e-01,\n",
      "         1.0562e-01, -7.3466e-02, -1.9811e-01, -2.6230e-01, -1.5069e-01,\n",
      "         1.3490e-01,  3.0649e-01, -2.1083e-01,  3.7148e-01, -9.1753e-02,\n",
      "        -3.4300e-01, -3.4266e-01,  1.7534e-01, -9.7830e-02, -7.0748e-02,\n",
      "         3.1099e-01, -2.7111e-01, -8.7760e-02,  4.4293e-02, -8.9699e-02,\n",
      "        -3.1748e-01, -3.7635e-01,  3.4172e-02,  2.2289e-01, -7.0908e-02,\n",
      "        -1.4248e-02, -2.1341e-01, -3.2434e-01,  1.1447e-01,  6.2704e-02,\n",
      "        -7.6689e-02, -4.4786e-01, -4.2902e-01,  6.3395e-02, -2.7849e-01,\n",
      "         1.7986e-02,  3.8846e-01, -3.1665e-01, -9.0204e-02,  4.7824e-01,\n",
      "        -1.8529e-01, -6.1291e-02, -2.8516e-02,  1.2945e-01, -3.5034e-01,\n",
      "        -4.2306e-02, -4.2945e-02, -2.9440e-02,  3.6694e-01,  4.1001e-01,\n",
      "        -4.0749e-01,  1.5025e-01,  1.3260e-01, -1.3142e-02,  1.6200e-01,\n",
      "         4.2831e-01, -3.4884e-01,  3.6306e-01, -6.5894e-02,  4.5766e-01,\n",
      "         3.8840e-02,  2.6859e-01,  1.4934e-01,  7.5451e-02,  4.2160e-01,\n",
      "        -6.1589e-02, -2.0210e-01,  3.3929e-01,  8.0640e-02,  2.9483e-02,\n",
      "         5.3058e-02, -1.0212e-03, -2.8818e-01,  3.5119e-01,  1.0102e-01,\n",
      "        -3.6987e-01, -6.1811e-02, -9.2260e-02,  2.8869e-01, -3.3697e-01,\n",
      "         7.6354e-02, -2.3606e-01, -3.5927e-01,  4.4733e-01, -3.7596e-01,\n",
      "         3.0775e-01, -4.8508e-03, -6.5706e-02, -3.1664e-01, -5.0968e-01,\n",
      "        -3.3653e-01,  2.5232e-01, -4.3350e-01, -3.1238e-02, -4.2841e-01,\n",
      "         4.3927e-02, -2.8562e-01,  1.3763e-01,  3.2187e-01, -3.8470e-01,\n",
      "         2.3639e-01, -1.3323e-01,  2.6537e-01, -2.2703e-01,  4.4217e-01,\n",
      "         4.5182e-02, -2.1959e-01,  8.1929e-02,  4.7112e-01,  3.1244e-01,\n",
      "        -3.6992e-01, -4.3626e-02,  7.9386e-02,  2.5654e-01, -1.8154e-03,\n",
      "         1.9066e-02,  3.3237e-01,  1.4900e-01, -1.2283e-01, -7.5699e-02,\n",
      "         1.0452e-01, -1.5184e-01,  3.4526e-01, -1.5157e-01, -1.7525e-01,\n",
      "        -3.4532e-01, -7.0988e-02, -7.5822e-02, -2.1751e-01, -3.5149e-01,\n",
      "        -7.1415e-02, -2.1496e-01,  3.2076e-01,  4.0699e-01, -2.7639e-02,\n",
      "         2.2053e-01,  2.2255e-01, -3.8696e-01,  1.1483e-01, -3.2061e-01,\n",
      "         3.8413e-01, -1.7153e-01,  2.3670e-01, -2.8785e-01, -3.4053e-01,\n",
      "        -1.5197e-01,  1.3040e-01,  5.0829e-01, -3.3306e-01,  3.6831e-01,\n",
      "        -1.1918e-01, -2.8384e-01, -2.8326e-01,  2.9397e-01,  3.2973e-01,\n",
      "        -1.5992e-01, -1.7986e-02,  1.1723e-01, -3.7249e-01, -3.6695e-01,\n",
      "        -2.1019e-01,  2.0976e-01,  3.1956e-01, -2.2017e-01,  3.7185e-01,\n",
      "        -6.7197e-02, -4.4663e-01,  2.9809e-01, -8.1143e-02,  3.9601e-01,\n",
      "        -3.5168e-01, -3.8513e-01,  4.3603e-02,  4.4567e-01, -3.1077e-01,\n",
      "        -1.2141e-01, -2.7468e-01,  2.1683e-02,  3.8633e-01,  3.0829e-01,\n",
      "         1.6836e-01, -1.9384e-01,  2.3272e-01, -2.5502e-01,  4.2709e-01,\n",
      "        -3.2756e-01, -4.8986e-02, -9.6387e-02,  3.0270e-01,  2.4350e-01,\n",
      "         3.6877e-01,  3.4650e-01,  1.4626e-01,  2.6960e-01,  2.8568e-02,\n",
      "         3.4317e-01,  4.3638e-01,  1.1615e-01, -2.3893e-01, -4.5996e-01,\n",
      "         3.0408e-01, -2.5296e-01, -3.0881e-02, -9.4254e-02,  3.6712e-01,\n",
      "        -2.2283e-01, -1.2542e-01,  2.6517e-02, -1.9844e-01, -2.0041e-01,\n",
      "         3.7136e-01,  3.6180e-01,  3.7685e-01, -5.2648e-01, -9.8534e-02,\n",
      "        -1.0567e-01,  2.0085e-01,  2.5723e-01, -3.7827e-01, -5.3387e-01,\n",
      "         2.7005e-01,  3.6244e-02,  1.6259e-01,  5.0967e-01,  9.5737e-02,\n",
      "        -3.2188e-01, -1.4130e-01,  3.6032e-01, -1.2123e-01,  3.3275e-01,\n",
      "        -3.3017e-01,  2.2025e-01, -3.2632e-01,  2.3311e-01, -3.7162e-01,\n",
      "         9.2031e-02,  3.7061e-01, -1.3776e-01, -2.8905e-01, -2.2576e-01,\n",
      "         2.7594e-01,  1.8703e-01, -6.3632e-02, -2.0095e-01,  2.7569e-01,\n",
      "        -3.7850e-01,  2.5199e-02,  4.1303e-01,  9.1234e-02, -1.8411e-01,\n",
      "        -3.1341e-01,  1.5191e-01,  6.4658e-02,  1.2614e-01,  2.8160e-01,\n",
      "         4.4691e-01, -3.9168e-01, -1.2510e-02,  4.0399e-01, -1.9636e-01,\n",
      "         3.9491e-02,  3.4077e-03,  3.3345e-01, -2.9280e-01,  1.9895e-01,\n",
      "         3.3502e-01,  4.3107e-01, -9.9812e-02,  1.4580e-01,  2.6643e-02,\n",
      "        -2.3790e-01,  4.8192e-01,  1.8140e-02,  4.1339e-01, -4.0563e-01,\n",
      "        -1.7949e-01, -2.1058e-01,  3.0898e-01,  1.5705e-01,  2.7773e-01,\n",
      "        -2.0516e-01, -3.4058e-01, -2.8614e-03,  2.3504e-01, -3.8442e-02,\n",
      "         3.2617e-01,  6.2519e-02, -3.5913e-01, -2.8629e-01,  2.9127e-01,\n",
      "         2.5982e-02, -2.6926e-01, -1.4395e-01, -1.1781e-02, -5.8908e-02,\n",
      "         4.6879e-02, -1.6100e-02, -1.5464e-01,  1.2438e-01, -5.2630e-02,\n",
      "         1.4829e-01,  4.1393e-01, -3.0216e-01,  2.1576e-01,  3.9660e-02,\n",
      "         4.4259e-01, -4.9969e-01,  3.2845e-01,  3.6424e-01,  6.4437e-02,\n",
      "        -1.3856e-01, -3.9802e-01,  1.8887e-01,  3.0148e-02, -2.0601e-01,\n",
      "         2.5171e-01,  3.4810e-01,  1.1554e-01,  2.6396e-01,  1.2112e-01,\n",
      "        -8.6392e-02,  2.8450e-01,  3.7716e-01, -3.6407e-02, -4.2038e-01,\n",
      "        -1.3328e-01, -8.0827e-02,  2.2095e-01,  8.9003e-02,  3.7468e-01,\n",
      "         2.0060e-01,  2.7215e-01,  3.3819e-01,  4.4902e-01,  3.5658e-01,\n",
      "        -1.4953e-01, -2.9023e-01,  1.3151e-01, -5.9817e-02,  6.0942e-02,\n",
      "         2.6077e-01,  2.7412e-01,  4.5614e-01, -3.9494e-01,  3.2202e-01,\n",
      "         1.4074e-01, -4.8485e-02, -4.1657e-02,  9.2554e-02, -3.7861e-01,\n",
      "        -5.1038e-02,  2.2535e-01,  1.2293e-01,  8.3394e-02,  1.4972e-01,\n",
      "        -2.5927e-01, -2.7838e-01,  3.7439e-01,  4.7375e-01,  4.3609e-01,\n",
      "        -8.9138e-02, -2.9544e-02, -2.5076e-04, -7.0429e-02,  1.3866e-01,\n",
      "        -1.7856e-03, -4.3665e-01, -1.4397e-02, -4.3805e-02, -2.2888e-01,\n",
      "         6.2847e-02, -4.6985e-02, -3.6728e-02,  3.9597e-01, -2.8042e-01,\n",
      "         1.0198e-01,  3.8232e-01, -3.1469e-01, -1.6265e-01, -2.8533e-02,\n",
      "        -4.2913e-02, -2.9644e-01,  1.4767e-01, -4.0499e-01,  1.5135e-01,\n",
      "        -3.4262e-02,  2.5466e-01, -2.8975e-01,  4.0000e-01, -4.4278e-01,\n",
      "         7.1797e-02, -4.9987e-02, -7.5809e-03,  3.3281e-01,  2.8755e-01,\n",
      "         8.6401e-02,  1.0403e-01, -3.5745e-01, -2.6328e-01, -3.1958e-01,\n",
      "        -2.1061e-01, -3.5012e-01,  2.4069e-01, -3.6030e-02,  2.2731e-01,\n",
      "         3.1659e-01, -2.0877e-01, -3.5973e-02,  7.2531e-02, -1.3961e-01,\n",
      "        -3.8883e-01,  4.0788e-01,  6.1443e-02,  2.6184e-01,  3.7659e-01,\n",
      "         6.1241e-02,  3.1547e-01,  2.6126e-01, -8.3675e-02, -3.9772e-01,\n",
      "         1.6980e-01, -2.2809e-01,  1.2694e-01,  5.5747e-02,  4.2213e-01,\n",
      "        -2.9220e-01,  8.7412e-02, -4.8024e-02, -3.4649e-01, -2.4474e-01,\n",
      "         2.7972e-01,  2.3886e-02, -3.3854e-01, -3.6677e-01,  3.4780e-01,\n",
      "         3.7074e-01, -2.9721e-01, -1.8301e-01, -2.5466e-01, -5.6624e-02,\n",
      "        -3.9678e-02,  5.5034e-02,  2.3049e-01,  1.2233e-01,  3.4584e-01,\n",
      "        -4.3692e-01, -1.5705e-01,  3.8043e-01,  3.3076e-01,  3.9618e-01,\n",
      "        -6.6405e-02, -2.6842e-01,  2.2485e-01,  2.4816e-01, -8.1286e-02,\n",
      "         2.1762e-01,  3.2953e-01,  1.3430e-01, -3.0059e-01, -2.0810e-01,\n",
      "         2.1355e-01,  1.0655e-01,  2.5207e-01,  4.2521e-01, -3.5422e-01,\n",
      "         3.6358e-01, -1.1022e-01, -8.0313e-02,  4.5291e-01,  4.0226e-01,\n",
      "        -1.0806e-01, -3.9259e-01,  4.4029e-01, -1.7190e-01,  2.7832e-01,\n",
      "         3.2294e-01,  2.6093e-01, -1.4843e-01,  1.2769e-01, -4.0345e-01,\n",
      "         5.0155e-01,  2.6988e-01,  7.3392e-02, -2.1910e-01, -3.8334e-03,\n",
      "        -3.6682e-01, -2.0799e-01, -2.0496e-01, -3.5337e-02, -1.0008e-02,\n",
      "        -3.3752e-01, -1.7025e-02, -1.7126e-01, -1.9314e-01,  1.5738e-01,\n",
      "        -3.6466e-01,  1.6088e-02,  2.6082e-01, -1.8541e-01,  1.0814e-01,\n",
      "         3.8623e-01, -1.5699e-01,  4.2923e-01,  3.3535e-01,  2.6078e-01,\n",
      "         2.8950e-01,  4.4529e-01, -2.0486e-01,  1.6804e-01,  3.8463e-01,\n",
      "         4.4779e-01, -3.7538e-01, -3.6554e-01, -9.8424e-02, -1.7768e-01,\n",
      "         2.9040e-01, -3.4167e-01,  1.6454e-02,  3.6506e-01, -1.6924e-01,\n",
      "         4.5615e-01,  1.2550e-01,  2.2792e-01,  8.5144e-02, -3.8608e-02,\n",
      "         1.1497e-01,  1.8313e-02,  6.9546e-02,  1.6678e-01,  3.9196e-01,\n",
      "         1.6989e-01, -1.8147e-01,  7.1130e-02,  8.3572e-02,  1.4569e-01,\n",
      "        -2.7756e-01,  8.3904e-02, -5.2633e-02,  4.6866e-01,  3.6616e-01,\n",
      "         2.5401e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2270]],\n",
      "\n",
      "         [[-0.0074]],\n",
      "\n",
      "         [[-0.3984]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0438]],\n",
      "\n",
      "         [[ 0.3029]],\n",
      "\n",
      "         [[ 0.7023]]],\n",
      "\n",
      "\n",
      "        [[[-0.1733]],\n",
      "\n",
      "         [[-0.1844]],\n",
      "\n",
      "         [[ 0.1013]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5433]],\n",
      "\n",
      "         [[ 0.1699]],\n",
      "\n",
      "         [[ 0.3316]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0603]],\n",
      "\n",
      "         [[-0.3563]],\n",
      "\n",
      "         [[ 0.2703]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7653]],\n",
      "\n",
      "         [[-0.3398]],\n",
      "\n",
      "         [[ 0.0644]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1869]],\n",
      "\n",
      "         [[-0.3894]],\n",
      "\n",
      "         [[ 0.3303]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9026]],\n",
      "\n",
      "         [[ 0.1098]],\n",
      "\n",
      "         [[ 0.0082]]],\n",
      "\n",
      "\n",
      "        [[[-0.0982]],\n",
      "\n",
      "         [[-0.3782]],\n",
      "\n",
      "         [[ 0.4256]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0769]],\n",
      "\n",
      "         [[-0.2627]],\n",
      "\n",
      "         [[-0.1812]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3289]],\n",
      "\n",
      "         [[ 0.0768]],\n",
      "\n",
      "         [[ 0.3735]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7973]],\n",
      "\n",
      "         [[ 0.2697]],\n",
      "\n",
      "         [[ 0.1781]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.3353, 0.6986, 0.4805, 0.8313, 0.3799, 0.6600, 0.6448, 0.2177, 2.1631,\n",
      "        0.6283, 0.8915, 0.2770, 0.4420, 1.4838, 0.9232, 0.0726, 1.0261, 0.3274,\n",
      "        0.6276, 2.2264, 0.6070, 1.3515, 0.2474, 0.9105, 1.0745, 0.7841, 1.1895,\n",
      "        0.0690, 0.1463, 1.0401, 0.2256, 0.4040, 1.2525, 0.4652, 0.2212, 0.9021,\n",
      "        1.7665, 0.4327, 1.7347, 2.0538, 1.0023, 0.3803, 0.5652, 1.6039, 0.2606,\n",
      "        0.3514, 0.9055, 0.2769, 0.1438, 1.0136, 0.6861, 0.5870, 0.7530, 1.7460,\n",
      "        0.3613, 0.3511, 1.2448, 0.2326, 0.5340, 1.3614, 0.6286, 1.2583, 1.6165,\n",
      "        0.4354, 1.4175, 0.8545, 0.8476, 0.3556, 1.4059, 0.2572, 0.2150, 0.1213,\n",
      "        0.4881, 0.3656, 0.3833, 1.3218, 0.7121, 0.4634, 0.6165, 0.8402, 0.3828,\n",
      "        1.2147, 1.7513, 0.8005, 1.3621, 1.4408, 0.4459, 0.1710, 0.3563, 0.4147,\n",
      "        0.9406, 0.5301, 0.8558, 0.2434, 1.0125, 0.2337], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 4.3331e-01, -2.4663e-01,  2.8039e-01, -6.7978e-01,  3.8713e-01,\n",
      "         4.3240e-01, -5.0340e-01, -1.5638e-01, -5.8312e-01, -7.5148e-01,\n",
      "         3.5317e-01,  6.2096e-01, -1.5212e-02,  6.9455e-01,  7.0529e-02,\n",
      "         1.4180e-01,  4.5069e-01, -4.1563e-01,  2.0731e-01, -1.5873e+00,\n",
      "         4.7214e-02,  5.8634e-02,  2.2359e-01, -3.4270e-01,  8.5372e-01,\n",
      "         2.8694e-01,  4.2066e-01,  3.7220e-01, -5.3668e-01,  1.9222e-01,\n",
      "         2.0981e-01, -2.5554e-01, -3.2923e-02, -5.6123e-01,  3.9508e-01,\n",
      "         3.7318e-01,  5.1124e-01,  1.0768e+00, -1.7614e-01, -5.8940e-02,\n",
      "        -7.7678e-01, -2.3195e-01, -2.3027e-01, -9.2679e-01,  1.5979e-01,\n",
      "         2.8866e-01,  2.0750e-01,  2.9194e-01,  6.3287e-01,  3.3857e-01,\n",
      "         1.4548e-01,  4.5236e-01,  9.3280e-02, -1.1146e+00, -7.9217e-01,\n",
      "         5.3218e-01,  8.4101e-01,  2.4380e-01,  1.5511e-01,  9.8556e-02,\n",
      "         3.3045e-01,  7.6721e-01, -4.9020e-01, -4.4801e-01,  8.7414e-02,\n",
      "        -7.2586e-01,  7.7510e-01,  1.3899e-01, -5.1748e-01,  6.2089e-02,\n",
      "        -3.0718e-01,  1.0851e-01, -2.9765e-01, -1.0439e-03,  7.4233e-01,\n",
      "         2.9949e-01,  5.2635e-02,  2.0114e-01, -3.6921e-01, -7.0241e-02,\n",
      "        -2.1935e-01,  1.3377e-01,  1.2954e-01, -6.5102e-01,  1.0546e+00,\n",
      "        -8.6546e-01,  9.7993e-01,  5.4870e-01,  2.8355e-01, -1.0015e-01,\n",
      "         4.0671e-01, -1.8696e-01, -5.2699e-01,  2.1533e-01, -2.6457e-01,\n",
      "         3.7370e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.7312]],\n",
      "\n",
      "         [[ 0.0761]],\n",
      "\n",
      "         [[-0.3566]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0456]],\n",
      "\n",
      "         [[-0.6378]],\n",
      "\n",
      "         [[ 0.2366]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7761]],\n",
      "\n",
      "         [[ 0.0402]],\n",
      "\n",
      "         [[-0.3549]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2224]],\n",
      "\n",
      "         [[-0.0064]],\n",
      "\n",
      "         [[-0.1527]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3274]],\n",
      "\n",
      "         [[-0.0864]],\n",
      "\n",
      "         [[-0.1491]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0325]],\n",
      "\n",
      "         [[-0.0595]],\n",
      "\n",
      "         [[ 0.4188]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1007]],\n",
      "\n",
      "         [[-0.2875]],\n",
      "\n",
      "         [[-0.4319]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0782]],\n",
      "\n",
      "         [[ 0.4444]],\n",
      "\n",
      "         [[ 0.1382]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2101]],\n",
      "\n",
      "         [[ 0.4671]],\n",
      "\n",
      "         [[ 0.7287]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1333]],\n",
      "\n",
      "         [[ 0.0548]],\n",
      "\n",
      "         [[ 0.1486]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0998]],\n",
      "\n",
      "         [[-0.2307]],\n",
      "\n",
      "         [[-0.2849]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0828]],\n",
      "\n",
      "         [[-0.0309]],\n",
      "\n",
      "         [[-0.2758]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.8640, 1.5275, 0.9756, 1.3331, 1.0930, 0.7870, 1.6155, 0.8115, 0.8075,\n",
      "        1.4194, 0.8442, 1.4234, 0.3169, 1.3379, 1.0341, 0.9084, 1.0552, 0.8904,\n",
      "        0.5332, 1.7061, 1.3593, 1.0706, 2.0027, 0.8568, 1.1356, 0.8121, 1.2458,\n",
      "        1.3068, 1.0949, 0.7832, 1.2579, 0.7526, 1.4301, 2.0552, 1.1855, 0.8300,\n",
      "        0.8151, 0.4699, 0.5649, 0.9290, 0.7610, 1.0352, 1.2928, 0.9917, 0.9774,\n",
      "        0.3008, 0.7452, 1.0000, 0.8500, 0.8231, 1.0794, 1.0005, 1.2090, 0.8237,\n",
      "        0.7415, 0.7876, 0.8358, 1.0285, 0.8980, 1.4530, 0.8157, 1.0968, 0.4835,\n",
      "        1.3719, 0.7195, 1.7544, 0.6967, 1.2324, 1.7596, 1.0765, 1.2857, 1.1555,\n",
      "        1.1745, 0.3307, 1.0961, 1.0312, 1.0600, 0.8123, 1.4372, 0.8643, 1.2420,\n",
      "        0.8649, 0.5263, 1.5761, 1.5473, 0.4409, 1.4232, 1.1028, 0.8074, 1.0104,\n",
      "        0.8243, 0.9585, 0.9818, 1.6347, 0.9180, 1.0140, 1.1814, 1.1954, 1.0239,\n",
      "        1.5815, 0.3577, 1.2967, 0.8256, 1.3644, 1.1138, 0.6900, 0.9918, 1.2156,\n",
      "        0.7853, 0.7521, 0.8985, 0.9900, 0.9206, 1.2678, 1.0226, 1.1756, 1.1819,\n",
      "        0.6000, 0.8944, 0.7988, 0.6856, 0.0601, 1.6542, 1.2668, 1.1041, 0.3544,\n",
      "        2.2329, 1.0738, 1.2874, 1.2472, 1.4340, 1.7837, 0.6250, 0.8276, 0.8370,\n",
      "        0.8103, 1.0671, 0.5914, 1.4871, 1.4052, 1.5109, 0.9403, 1.7350, 1.0605,\n",
      "        0.7576, 1.1970, 0.7084, 0.7292, 1.2504, 0.9361, 1.6702, 1.1177, 0.3520,\n",
      "        0.8032, 0.3977, 0.9729, 1.7955, 0.9956, 1.8892, 0.8073, 0.9216, 1.3956,\n",
      "        1.7161, 1.5197, 0.9756, 1.3069, 1.4505, 0.4979, 1.4410, 1.3663, 1.3433,\n",
      "        1.1996, 0.6064, 0.5229, 0.9770, 1.4127, 1.5355, 1.5072, 0.7564, 1.2556,\n",
      "        0.6445, 1.0646, 0.4539, 0.6561, 1.3319, 1.2544, 0.4963, 1.7906, 0.5918,\n",
      "        0.6752, 1.8518, 0.9504, 0.7289, 1.4179, 0.8636, 0.9108, 1.0300, 1.3363,\n",
      "        0.2281, 1.1458, 1.0086, 1.0040, 1.1893, 1.2930, 1.0806, 0.9560, 0.1275,\n",
      "        1.0347, 0.7961, 1.2572, 0.8988, 0.6324, 1.9174, 0.7879, 0.7146, 0.5124,\n",
      "        1.1088, 1.7754, 0.6807, 1.1237, 0.9071, 0.4555, 0.7501, 1.6490, 0.7130,\n",
      "        1.1638, 1.4679, 1.5122, 0.8746, 0.7488, 1.0767, 1.3658, 0.3149, 0.2447,\n",
      "        1.5026, 1.2308, 1.4468, 1.1970, 0.9555, 0.3619, 0.1490, 1.2556, 0.9502,\n",
      "        1.1967, 1.7553, 1.7615, 1.2608, 2.1254, 0.7563, 0.9940, 0.7622, 1.1347,\n",
      "        1.0616, 0.5929, 0.6154, 0.6221, 1.0908, 1.4561, 1.2719, 0.6742, 0.8287,\n",
      "        1.0294, 1.0526, 1.2424, 0.8327, 1.3317, 1.2180, 2.1457, 0.9098, 1.1255,\n",
      "        1.1551, 1.4273, 1.0981, 1.6045, 1.6044, 0.8728, 2.1360, 0.0816, 1.6384,\n",
      "        1.0855, 1.2973, 1.2390, 0.5181, 0.6974, 1.5371, 1.1981, 0.8857, 2.1658,\n",
      "        0.5590, 0.9345, 1.5412, 1.5946, 1.0274, 0.3425, 1.5531, 0.4561, 1.0980,\n",
      "        1.5046, 0.3706, 1.2245, 1.2016, 1.0607, 1.1315, 1.4699, 0.5503, 1.6530,\n",
      "        1.2637, 1.5422, 0.9186, 1.1290, 1.2912, 1.6034, 1.2121, 1.0843, 0.7378,\n",
      "        0.6653, 0.8791, 0.5038, 1.7455, 1.3433, 1.7879, 1.2523, 1.0695, 0.6128,\n",
      "        1.0337, 0.7910, 1.5545, 1.7243, 1.8410, 1.3313, 1.9480, 1.3338, 1.0715,\n",
      "        1.0719, 1.5875, 1.2896, 1.2035, 0.9898, 1.7234, 1.0527, 0.3544, 0.8356,\n",
      "        1.3000, 1.5211, 1.3378, 1.6216, 1.0875, 1.2708, 1.1522, 1.6642, 1.2286,\n",
      "        1.5089, 1.1302, 0.4007, 0.8182, 0.8621, 1.7231, 1.2238, 0.4516, 1.0960,\n",
      "        1.3938, 1.7017, 1.8325, 1.4646, 1.2329, 1.4090, 1.1242, 0.9389, 1.4727,\n",
      "        1.6611, 1.1254, 0.4626, 0.9344, 0.7057, 1.2921, 1.5627, 0.6345, 1.6675,\n",
      "        1.9299, 0.8622, 0.8199, 0.8903, 0.5733, 0.7872, 0.2880, 0.9473, 0.9304,\n",
      "        0.7761, 1.1706, 0.6677, 0.6870, 0.8269, 1.4977, 1.2495, 0.5698, 1.2675,\n",
      "        1.2557, 1.9227, 0.9574, 0.7521, 0.2175, 0.6119, 0.1337, 1.3397, 1.1167,\n",
      "        0.7921, 0.9735, 1.7635, 1.7517, 1.6119, 1.6568, 1.4540, 0.8790, 1.6314,\n",
      "        1.1207, 1.1161, 0.3547, 1.0836, 1.2603, 1.0988, 0.9460, 1.4717, 0.5531,\n",
      "        1.2153, 0.6465, 1.1626, 1.0821, 0.8177, 1.1895, 1.6238, 0.5943, 0.7887,\n",
      "        0.3239, 1.3134, 1.5999, 1.4130, 1.6525, 0.9776, 1.3690, 1.0130, 1.0430,\n",
      "        0.9102, 1.1426, 1.0883, 0.8219, 0.8487, 1.7413, 1.1464, 1.8586, 1.4088,\n",
      "        0.9461, 1.9000, 0.7761, 1.2370, 0.4300, 0.6081, 1.8537, 1.2926, 0.5581,\n",
      "        1.4069, 1.2028, 1.0089, 0.7061, 1.1029, 1.1251, 1.8105, 1.0809, 2.0580,\n",
      "        0.5965, 1.3951, 1.0513, 0.6308, 0.8653, 1.2090, 1.0271, 1.3221, 1.0192,\n",
      "        1.4702, 1.1540, 0.9494, 0.6002, 0.9409, 1.6360, 0.8932, 0.8733, 1.1297,\n",
      "        1.4553, 1.1134, 1.0984, 1.1149, 0.5548, 0.8314, 0.2829, 1.1503, 1.0077,\n",
      "        0.8183, 0.8647, 0.8310, 0.8782, 1.7819, 1.0444, 1.0679, 0.8240, 1.0410,\n",
      "        1.3419, 1.3208, 1.5134, 1.2468, 0.9401, 0.4305, 0.8485, 0.8040, 0.9202,\n",
      "        1.7918, 0.9295, 1.3589, 1.3790, 1.7973, 0.6560, 1.3501, 0.7797, 1.4468,\n",
      "        1.3584, 1.2409, 0.8358, 0.6011, 0.9091, 1.4752, 0.6302, 0.9137, 1.4361,\n",
      "        0.7362, 0.9894, 1.4011, 0.6709, 1.0192, 1.2003, 0.8593, 0.8335, 1.5927,\n",
      "        1.2877, 1.2561, 1.4353, 1.8637, 1.2550, 1.3318, 1.2584, 1.0586, 0.7798,\n",
      "        1.1340, 1.2648, 0.5827, 0.7496, 0.9913, 1.2920, 0.4447, 1.2485, 1.4304,\n",
      "        1.1930, 1.2359, 0.9090, 0.8507, 0.4099, 1.4239, 0.8261, 0.7463, 1.7616,\n",
      "        2.1357, 1.0596, 1.3251, 0.4002, 1.6669, 2.0235, 0.8168, 0.9936, 1.7478],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.1517e-02,  2.0234e-01, -4.8772e-01, -1.1295e+00, -4.8745e-01,\n",
      "        -8.6618e-01, -5.1218e-01, -1.0667e+00, -1.1789e+00, -1.9636e-03,\n",
      "         4.2390e-02, -1.1450e-01,  8.5923e-01, -1.0575e+00, -1.1381e+00,\n",
      "         1.4475e+00,  3.1862e-01,  1.5838e-01, -3.1609e-01, -6.0148e-01,\n",
      "        -1.5893e-01, -7.3158e-01, -1.3298e-01,  6.5133e-01, -9.7691e-01,\n",
      "        -1.2398e+00, -6.6766e-01, -1.1907e+00, -1.1359e+00, -1.2825e+00,\n",
      "        -5.6952e-01, -1.2375e-02, -2.0838e-01,  1.1774e-01, -4.8028e-01,\n",
      "        -1.5947e-01, -8.3360e-01,  1.8702e-01,  1.0342e+00, -2.0813e+00,\n",
      "         1.4315e+00,  9.2094e-01,  5.7357e-01, -9.9516e-01, -7.5242e-01,\n",
      "         3.6958e-01, -1.0045e-01, -7.8080e-01, -1.7442e+00, -1.1114e+00,\n",
      "        -1.5042e-01, -9.3889e-01,  9.1190e-01,  2.1509e-01,  6.2126e-01,\n",
      "        -1.4528e+00,  4.6145e-01, -5.6885e-01, -1.3471e+00, -2.0719e-01,\n",
      "         6.5074e-01, -1.2197e+00,  2.2881e-01,  3.9602e-01, -1.2866e+00,\n",
      "        -2.4715e-01, -1.4159e+00,  2.3101e-01, -1.6650e+00,  1.1324e-01,\n",
      "        -2.0691e-01, -1.0340e+00, -1.4421e+00, -1.8075e-01, -3.4896e-01,\n",
      "        -1.2364e+00, -5.9783e-01,  5.3846e-02, -1.7149e+00, -7.2632e-01,\n",
      "        -1.5228e+00,  5.5626e-01, -9.2538e-02, -5.9942e-01, -1.0509e+00,\n",
      "        -1.4374e+00,  3.4892e-01, -7.6058e-01, -1.9973e+00, -1.1470e+00,\n",
      "        -1.3173e+00, -1.0622e+00, -4.0492e-01, -5.0797e-02,  7.2651e-01,\n",
      "        -1.5737e+00, -1.0842e+00, -2.9802e-01,  6.0020e-01, -8.7546e-01,\n",
      "         1.0037e+00, -1.1376e+00, -6.9379e-01, -3.1363e-01, -1.5732e+00,\n",
      "        -1.9661e-01, -1.8470e+00, -1.4262e+00, -1.2600e+00, -1.9695e-01,\n",
      "        -1.5210e+00,  4.4997e-01, -6.3914e-01, -2.3272e-01, -1.2976e+00,\n",
      "        -1.3454e+00, -7.9236e-01,  3.9175e-01,  8.0239e-01, -7.3484e-01,\n",
      "        -7.0338e-01, -4.9130e-01,  3.9411e-01, -6.7068e-01, -1.1070e+00,\n",
      "         1.4787e-02,  1.0800e+00, -8.7403e-01, -8.4126e-01, -1.4027e+00,\n",
      "        -4.9767e-02, -1.8357e+00, -2.0054e-01, -1.5879e+00, -1.7303e+00,\n",
      "        -6.2977e-01, -1.6219e+00,  2.7520e-01, -1.2702e+00, -6.3033e-01,\n",
      "         4.7032e-01,  1.1331e-01,  7.6922e-01, -1.4588e+00, -1.1040e+00,\n",
      "         1.0383e+00, -6.3485e-01, -1.2154e+00, -9.4728e-01,  8.6190e-01,\n",
      "        -6.7294e-01, -6.9127e-01,  3.3352e-01, -4.8262e-01,  1.2088e-01,\n",
      "        -1.2648e+00, -9.1767e-02,  4.5727e-01,  9.2811e-02,  7.4818e-01,\n",
      "        -1.2440e+00, -1.3366e+00, -2.4230e+00, -1.1765e-01, -6.3816e-01,\n",
      "         2.1769e-01,  1.9027e-01,  5.8124e-01, -1.2605e+00,  3.4387e-02,\n",
      "        -1.6661e-01,  1.0047e-01, -1.2014e+00, -1.0979e+00,  5.1921e-01,\n",
      "        -6.2279e-01, -8.9547e-01, -1.1439e+00, -6.6403e-01, -8.0991e-01,\n",
      "        -5.1475e-01, -6.4915e-01, -1.8240e-01, -7.3678e-01, -4.0734e-01,\n",
      "        -1.7554e+00,  7.2649e-01, -5.3869e-01,  9.0261e-01,  4.0002e-01,\n",
      "        -3.7022e-01, -1.8845e-01, -1.2962e+00, -3.7207e-01, -6.0356e-01,\n",
      "         6.1237e-01, -2.2524e+00, -2.1112e-01, -1.4086e+00,  5.5833e-01,\n",
      "        -6.0686e-01, -1.9189e+00, -1.3435e+00, -1.7705e+00, -9.0502e-01,\n",
      "        -4.5564e-01, -3.7744e-01, -2.6226e+00,  1.4826e-01, -2.1141e-01,\n",
      "        -1.5220e+00,  4.8747e-01, -8.6171e-01,  3.4935e-01,  6.9563e-01,\n",
      "         4.5266e-01, -4.2837e-01,  9.5928e-02, -1.1185e+00, -1.4664e+00,\n",
      "        -8.5090e-01,  5.1153e-02, -2.3855e-01, -9.5673e-01,  1.4125e+00,\n",
      "        -1.4706e+00, -1.3005e+00, -5.5192e-01, -1.4732e-01, -1.7122e+00,\n",
      "        -6.3577e-01, -1.7345e+00, -8.8728e-02,  7.8818e-01, -2.2483e-01,\n",
      "         3.1995e-01, -1.3403e-01, -1.2201e+00, -9.0458e-01,  6.4372e-01,\n",
      "         4.9442e-01, -1.2164e+00, -3.3524e-01, -1.0912e+00, -8.1989e-01,\n",
      "        -7.5945e-02, -3.9246e-01, -1.0376e-01, -4.9801e-01,  3.2079e-01,\n",
      "        -1.2563e+00, -4.3967e-01, -4.3717e-02,  5.8003e-01,  3.9431e-01,\n",
      "        -5.3899e-01, -7.6260e-01,  9.9420e-02, -1.7765e+00, -4.0983e-01,\n",
      "        -1.5892e-01, -6.8071e-01, -1.7905e+00,  4.2858e-01,  5.3206e-01,\n",
      "        -3.6332e-01, -2.8638e-01, -1.4662e+00, -7.8857e-01,  7.5417e-01,\n",
      "         2.3316e-01, -9.0174e-01, -1.3445e+00, -1.0535e+00,  1.9314e-01,\n",
      "        -4.3783e-01, -9.4366e-02,  4.4085e-01, -6.4434e-01,  1.1536e-01,\n",
      "        -1.0529e+00, -1.5102e+00, -1.6757e+00, -1.8331e-01, -1.4376e+00,\n",
      "        -5.5925e-01,  1.0649e+00,  4.8594e-02,  2.1552e-01,  3.5350e-01,\n",
      "        -1.0780e+00, -3.3129e-01,  1.4296e-01,  6.0958e-01, -5.3131e-01,\n",
      "        -5.7145e-01,  1.2502e-01, -8.0244e-01,  7.9088e-01, -9.4218e-01,\n",
      "         2.4429e-01, -1.6563e+00, -1.0808e+00, -8.8771e-02,  1.1035e+00,\n",
      "        -4.5229e-01,  6.3339e-02, -8.6767e-01,  7.9588e-02, -9.2841e-01,\n",
      "        -1.5975e+00, -2.5305e+00, -9.8928e-01, -2.1040e+00, -5.8718e-02,\n",
      "         8.3210e-02, -1.5718e+00,  2.5969e-01,  3.8569e-01, -1.2628e+00,\n",
      "         2.9596e-01, -9.3998e-01,  5.6488e-02,  4.9096e-01,  5.2851e-01,\n",
      "         9.2857e-01, -1.7203e-02, -2.3480e+00, -9.9216e-01, -5.5294e-02,\n",
      "         1.5478e-01, -1.6700e+00, -6.2769e-01, -8.6434e-01,  2.1390e-02,\n",
      "        -5.6212e-01, -1.0599e+00,  8.2574e-01, -3.6344e-01, -1.6254e+00,\n",
      "         2.3451e-01,  1.0643e+00, -9.5400e-01,  5.7545e-01,  1.5098e-01,\n",
      "        -1.6073e-01, -3.1553e+00, -1.3635e+00,  5.7513e-01, -5.0688e-01,\n",
      "        -3.6072e-01,  4.4175e-01, -9.9479e-01,  3.2935e-02,  3.7789e-01,\n",
      "        -2.4836e-01, -1.3013e+00, -2.0510e-01,  1.7028e-01, -5.1459e-01,\n",
      "         1.0510e+00, -1.0941e-01, -2.7503e-01, -8.9351e-01, -2.6258e-01,\n",
      "        -7.4282e-01,  1.3672e-01, -9.5366e-01,  1.6565e-01, -7.3994e-01,\n",
      "        -8.6018e-01, -9.9367e-01, -4.6927e-01,  1.5099e-01, -6.5358e-01,\n",
      "         8.9137e-02,  1.0468e+00, -1.0939e+00,  1.4217e-01, -1.7021e+00,\n",
      "         3.5731e-01, -1.0585e+00,  8.6105e-01,  8.7425e-01,  5.5679e-03,\n",
      "         1.1024e+00, -1.1244e+00, -1.3990e+00,  1.0642e+00, -1.7604e+00,\n",
      "        -1.3286e+00,  2.2250e-02, -1.6169e-01, -7.0302e-01,  1.0177e+00,\n",
      "         2.2541e-01,  2.1907e-01, -7.1859e-01, -5.3257e-01, -8.0924e-01,\n",
      "         1.0358e+00,  3.2259e-01, -1.4498e-01, -4.4743e-01, -1.2389e+00,\n",
      "         7.7459e-01,  9.0235e-01, -5.0078e-01,  9.9803e-02, -2.2674e+00,\n",
      "         3.6494e-01, -9.3657e-01,  7.0307e-01, -1.8726e-01,  4.3342e-01,\n",
      "         8.9598e-01,  7.8226e-01, -1.2487e+00, -1.2376e+00, -6.2475e-01,\n",
      "        -9.3565e-01, -1.2289e+00, -1.5376e-01, -2.1057e+00,  3.0991e-01,\n",
      "        -6.6309e-01, -1.3606e+00,  1.4014e-01, -3.0298e-01,  7.4122e-01,\n",
      "        -1.9503e+00, -1.7677e+00,  7.4398e-01, -1.2817e+00, -7.2525e-01,\n",
      "        -1.8011e+00, -2.0312e-01, -1.4090e+00, -1.0743e+00, -2.5065e-01,\n",
      "         3.6869e-01, -9.5183e-01, -5.1668e-01, -1.2680e+00,  1.4727e+00,\n",
      "        -1.8473e+00,  3.4950e-01, -1.1085e+00, -3.9998e-02, -7.3188e-01,\n",
      "        -1.3283e+00, -6.4639e-01, -1.8568e+00, -7.2572e-01,  5.3864e-01,\n",
      "         7.5557e-01,  4.4603e-01,  6.7366e-01, -1.2992e-01, -2.0780e+00,\n",
      "         3.2500e-01, -9.2359e-01, -2.2631e+00, -8.2590e-01, -5.9205e-01,\n",
      "        -6.9249e-02,  7.1834e-02, -1.9978e+00,  9.5325e-03, -8.5702e-01,\n",
      "         1.9251e+00,  8.8542e-02, -9.7835e-01, -9.8288e-01, -2.7765e-01,\n",
      "        -1.0933e-01, -1.4865e+00,  5.2728e-01, -1.3854e+00, -1.4155e+00,\n",
      "        -1.7354e+00, -2.8983e-01, -1.8913e-01, -1.0428e+00, -2.1900e-01,\n",
      "         4.8746e-02,  5.7986e-02, -5.4969e-01, -1.1915e+00, -7.7689e-01,\n",
      "         4.4671e-01, -2.2687e+00,  1.2132e+00, -8.4270e-01, -7.3042e-02,\n",
      "        -1.2767e+00, -1.8529e+00, -4.7747e-01,  7.3152e-01, -2.7003e+00,\n",
      "        -1.4357e+00, -1.9505e+00, -2.5545e-01, -1.6113e+00, -7.7196e-01,\n",
      "        -1.0462e+00, -7.5511e-01, -6.2955e-01,  9.3617e-01,  2.6346e-01,\n",
      "        -6.2848e-01, -6.2582e-01, -1.2681e+00, -3.3551e-02, -4.1447e-01,\n",
      "        -1.1907e+00, -2.1449e+00,  5.2533e-01,  2.0656e-01, -1.4205e+00,\n",
      "        -1.5097e+00, -4.1310e-02, -1.4350e-01, -1.9442e+00, -1.1585e+00,\n",
      "        -3.2483e-02,  2.1137e-01, -7.4074e-01, -1.2619e-01, -1.6485e+00,\n",
      "        -6.6970e-01,  7.6585e-01, -1.6620e+00, -1.1538e+00, -4.1008e-01,\n",
      "         3.0738e-01,  7.9681e-01,  8.7881e-01, -1.0503e+00, -7.5622e-01,\n",
      "        -1.4681e+00, -8.7864e-01, -1.1825e+00, -2.4307e+00,  2.6704e-02,\n",
      "        -1.9735e-02, -9.3845e-01,  8.4919e-01, -2.3780e+00,  6.3705e-01,\n",
      "         3.2167e-01,  3.2095e-01, -5.7561e-01, -4.1462e-01, -1.2159e+00,\n",
      "         7.6835e-01,  2.1715e-01, -7.8852e-01, -2.0026e+00, -7.1688e-01,\n",
      "        -2.3085e+00,  5.2737e-01,  7.7514e-01, -9.7155e-01, -5.0614e-01,\n",
      "        -8.9714e-01, -2.1416e-01, -2.3977e+00, -7.9453e-01,  1.0517e+00,\n",
      "         8.8755e-02, -2.7697e-03, -2.2363e-01,  8.7520e-01, -2.3727e+00,\n",
      "        -5.7251e-02], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0501,  0.0567,  0.2420],\n",
      "          [-0.0528, -0.1357, -0.7502],\n",
      "          [-0.0916,  0.5171, -0.4268]]],\n",
      "\n",
      "\n",
      "        [[[-0.2612, -0.1912, -0.4151],\n",
      "          [-0.5236, -0.4136, -0.2900],\n",
      "          [-0.1026, -0.3274, -0.0486]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0194,  0.3108,  0.0508],\n",
      "          [-0.1610,  0.2793,  0.3861],\n",
      "          [ 0.1192,  0.2007,  0.6690]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4084,  0.0440,  0.8246],\n",
      "          [-0.1279,  0.0295,  0.0342],\n",
      "          [ 0.2627,  0.1227, -0.2177]]],\n",
      "\n",
      "\n",
      "        [[[-0.2397,  0.0951,  0.0601],\n",
      "          [-0.1231,  0.6206,  0.5295],\n",
      "          [-0.3785,  0.3641,  0.0187]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2909,  0.4040,  0.1680],\n",
      "          [ 0.0829,  0.0547,  0.0513],\n",
      "          [ 0.4985,  0.5588,  0.3848]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.0359,  2.5139,  1.0405,  2.1880,  0.9633,  1.1946,  0.8801,  1.0378,\n",
      "         0.5415,  0.7763,  1.5865,  1.2782,  1.3465,  1.8666,  1.2928,  1.5222,\n",
      "         1.4024,  1.5558,  1.9252,  1.2496,  1.0618,  1.6765,  1.6499,  1.4997,\n",
      "         0.9005,  1.1911,  1.3488,  1.8990,  1.0895,  1.1649,  1.9067,  1.3657,\n",
      "         1.1837,  1.6639,  2.1282,  1.4172,  3.0813,  1.9792,  2.0011,  1.0856,\n",
      "         2.0019,  2.3283,  2.5183,  0.7473,  1.0878,  1.6038,  1.8797,  1.4874,\n",
      "         0.9068,  1.3183,  1.0701,  1.3980,  1.7031,  1.3501,  1.5978,  2.4401,\n",
      "         1.7988,  1.4292,  1.3678,  0.5401,  1.5697,  1.4231,  1.7091,  1.5977,\n",
      "         1.7458,  2.1022,  0.9861,  2.0736,  1.9279,  1.4678,  1.3273,  0.9178,\n",
      "         0.5397,  1.6957,  1.3104,  0.8577,  1.3051,  2.2364,  1.0797,  1.2150,\n",
      "         1.7556,  1.8816,  1.5264,  1.5183,  2.1851, -0.0372,  1.8599,  1.7052,\n",
      "         0.5766,  0.9233,  2.0965,  1.4622,  1.3100,  1.2206,  2.3256,  1.7395,\n",
      "         0.9573,  1.4451,  1.2349,  1.7539,  1.9443,  0.4596,  1.3641,  0.8332,\n",
      "         0.8282,  1.0750,  1.0980,  1.0867,  0.7771,  1.4070,  0.9117,  1.5732,\n",
      "         1.2486,  1.6751,  0.8731,  2.6546,  0.9875,  1.4390,  1.6965,  1.4098,\n",
      "         1.7786,  1.4358,  1.5288,  1.1521,  1.9030,  1.8352,  2.8427,  1.3161,\n",
      "         0.9479,  0.8059,  0.8111,  3.5778,  0.9326,  0.6423,  0.9295,  0.8488,\n",
      "         2.5961,  1.8272,  1.0020,  1.2741,  2.1791,  1.4974,  1.6533,  1.7137,\n",
      "         1.1887,  1.5221,  1.4238,  0.9861,  1.5665,  2.0657,  1.3368,  1.4688,\n",
      "         1.8862,  1.2742,  1.2835,  1.4429,  1.6871,  1.3288,  0.9401,  1.4635,\n",
      "         1.3723,  1.3038,  2.8197,  2.0256,  1.8661,  1.7973,  1.2600,  1.7266,\n",
      "         1.8966,  1.3700,  0.9882,  1.6910,  1.7842,  1.4593,  1.4189,  1.6853,\n",
      "        -0.0580,  0.9910,  1.1694,  0.7958,  1.8849,  1.1483,  1.7456,  0.9822,\n",
      "         2.0158,  1.1867,  1.4351,  2.2611,  0.6890,  1.0737,  2.6907,  1.3928,\n",
      "         0.1061,  1.4532,  0.8679,  1.5689,  1.4019,  1.8984,  0.7114,  1.3570,\n",
      "         1.6141,  0.5823,  1.8384,  0.5999,  1.3852,  1.5147,  1.8534,  0.9761,\n",
      "         0.7410,  1.0598,  0.4519,  0.9459,  0.5586,  1.6985,  1.5772,  1.8190,\n",
      "         1.3744,  2.5511,  1.0318,  1.5610,  1.5192,  1.9432,  1.3976,  1.0020,\n",
      "         1.6628,  1.1752,  1.4702,  1.5844,  1.2051,  0.6508,  1.9240,  2.5012,\n",
      "         1.0852,  0.4612,  2.4636,  1.8436,  2.1857,  0.6870,  1.4607,  1.8143,\n",
      "         1.4685,  2.1013,  0.8868,  1.3274,  0.4377,  1.4074,  0.8484,  2.3029,\n",
      "         1.4377,  0.8911,  1.0854,  1.0366,  0.8425,  1.6398,  1.6172,  1.1416,\n",
      "         1.2532,  1.4312,  2.6550,  1.6809,  1.1340,  1.3917,  0.8251,  1.4122,\n",
      "         1.0249,  0.8896,  1.6289,  3.8381,  1.5478,  1.5704,  1.9275,  1.0211,\n",
      "         2.1410,  1.5879,  1.0238,  0.8871,  1.6612,  1.6573,  1.3018,  1.8440,\n",
      "         1.5570,  2.8216,  1.2617,  1.6530,  3.5995,  2.4756,  1.6083,  1.2600,\n",
      "         1.6539,  2.0280,  1.1182,  1.2314,  1.8042,  1.8845,  1.5308,  0.0785,\n",
      "         0.7351,  1.5837,  1.2479,  1.7522,  1.4155,  0.8165,  0.9011,  1.2614,\n",
      "         2.8085,  1.3401,  1.7010,  2.1545,  1.2238,  0.9159,  1.0386,  4.9267,\n",
      "         1.7714,  0.8991,  0.6868,  1.4493,  1.4195,  1.9206,  1.6551,  1.1955,\n",
      "         2.0138,  2.0107,  1.4257,  1.1838,  1.7458,  1.7882,  1.5625,  1.5137,\n",
      "         2.4620,  1.7307,  1.0027,  2.8849,  1.1482,  1.4388,  1.3823,  2.1019,\n",
      "         0.8397,  1.8433,  0.8788,  0.9066,  1.5765,  2.2173,  1.2312,  1.6184,\n",
      "         1.0347,  1.2527,  2.1227,  2.2499,  0.7871,  1.6717,  1.0240,  2.2236,\n",
      "         0.7332,  1.5619,  1.1015,  0.9280,  1.1496,  1.2862,  1.8517,  1.7147,\n",
      "         2.3904,  1.3339,  1.5363,  1.9113,  1.0815,  1.1497,  1.6779,  1.2527,\n",
      "         1.1954,  0.3393,  1.8473,  1.1585,  1.0698,  1.5195,  1.2277,  1.4696,\n",
      "         2.6281,  1.0315,  1.0692,  1.5839,  1.4282,  1.1839,  1.6667,  1.6337,\n",
      "         1.5850,  1.7544,  0.9407,  1.5894,  1.4037,  0.5593,  1.0532,  1.5319,\n",
      "         1.7677,  1.4482,  1.8217,  1.7519,  1.2135,  1.9997,  1.4237,  1.2389,\n",
      "         1.7824,  1.7750,  1.4460,  0.9907,  0.9018,  1.8870,  1.5337,  0.9192,\n",
      "         0.0462,  4.5004,  2.8422,  0.9487,  1.6783,  1.6563,  2.0517,  1.8503,\n",
      "         1.3644,  0.4121,  1.4818,  1.8605,  1.5791,  2.4010,  1.2266,  2.1404,\n",
      "         2.0002,  1.1746,  1.9279,  1.3237,  1.2489,  1.4713,  0.7814,  0.5889,\n",
      "         1.5462,  0.9654,  1.7131,  1.6891,  0.9533,  1.0429,  0.6954,  1.2916,\n",
      "         1.4596,  0.9027,  1.0957,  1.4310,  1.9102,  0.6533,  1.5315,  1.2536,\n",
      "         1.0581,  1.4533,  1.0649,  0.4304,  0.9840,  2.0481,  1.8378,  2.3577,\n",
      "         2.2555,  1.2507,  1.6931,  3.1661,  1.6081,  1.9731,  1.8542,  2.0633,\n",
      "         0.8227,  1.7772,  1.5653,  3.7004,  1.1503,  2.1836,  3.8023,  1.1765,\n",
      "         1.3305,  1.2936,  1.5496,  1.7240,  1.7964,  1.4136,  2.0377,  1.0676,\n",
      "         0.8636,  0.8172,  1.5917,  1.2941,  1.5222,  1.7046,  1.7673,  1.6337,\n",
      "         0.9619,  1.8820,  2.0612,  0.4826,  1.4212,  1.2672,  1.4103,  0.6848,\n",
      "         0.7761,  1.2042,  1.6428,  3.7684,  2.0501,  0.8807,  1.1613,  0.6404,\n",
      "         1.3153,  1.0070,  1.8202,  1.2128,  1.8906,  2.0543,  1.5319,  2.0575,\n",
      "         0.6789,  1.0989,  1.4370,  2.7067,  2.8438,  1.0571,  1.7650,  1.2238,\n",
      "         1.1126,  1.5554,  1.2011,  0.7828,  1.2986,  1.5287,  1.2087,  1.5846,\n",
      "         2.5361,  1.4743,  0.9471,  2.0689,  0.3882,  0.3152,  1.3759,  1.5307,\n",
      "         1.4040,  1.8316,  0.9492,  1.3587,  1.4916,  1.1717,  1.6875,  3.1108,\n",
      "         1.3334,  1.5348,  1.2880,  1.7921,  0.6919,  2.2003,  1.5093,  1.2724,\n",
      "         1.4175,  1.4022,  1.5701,  1.4110,  1.1168,  0.6734,  0.4730,  0.8633,\n",
      "         1.0054,  1.8306,  1.5115,  1.1357,  1.5538,  1.0313,  1.3495,  3.9567,\n",
      "         1.0959,  2.2967,  1.8194,  0.3811,  1.2430,  1.8369,  0.8772,  1.6418],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.5522e+00, -3.4078e-01, -2.2587e+00, -1.1842e+00, -1.4779e+00,\n",
      "        -2.2694e+00, -4.5044e-01, -5.4917e-01,  1.0921e-01, -3.3550e-01,\n",
      "        -8.5672e-01, -1.1179e+00, -1.0912e+00, -3.3500e-01, -1.5386e-01,\n",
      "        -1.8877e+00, -9.1872e-01, -1.5784e+00, -1.0701e+00, -3.5007e-02,\n",
      "        -4.6198e-01, -3.8117e-01, -5.8150e-01, -9.9241e-01, -2.0789e-01,\n",
      "        -8.0184e-01, -2.5960e-01, -2.1804e+00, -9.8545e-01, -1.4892e+00,\n",
      "        -9.1757e-01, -9.2714e-01, -7.3930e-01, -8.7230e-01, -2.0637e+00,\n",
      "        -2.7851e+00, -9.0014e-01, -1.8049e+00, -1.9146e+00, -7.1935e-01,\n",
      "        -8.8563e-01, -1.1432e+00, -1.2150e+00, -5.0615e-02, -2.7526e+00,\n",
      "        -1.3666e+00, -1.1697e+00, -9.6675e-01, -2.0396e-01, -1.9122e+00,\n",
      "        -1.0635e+00, -8.6335e-01, -1.8045e+00, -7.8701e-01, -1.3432e+00,\n",
      "        -7.4235e-01, -1.9936e+00, -1.2311e+00, -1.0726e+00,  1.3006e-01,\n",
      "        -1.2706e+00, -7.4101e-01, -9.4868e-01, -7.9133e-01, -1.9713e+00,\n",
      "        -6.8695e-01, -2.5872e+00, -1.0877e+00, -2.7076e-01, -8.7732e-01,\n",
      "        -6.3384e-01, -3.5488e-01, -1.4521e-01, -1.1917e+00, -6.9429e-01,\n",
      "        -1.7668e-01, -8.0948e-01, -1.2272e+00, -1.8112e+00, -1.2789e+00,\n",
      "        -2.7097e+00, -8.8793e-01, -8.4464e-01, -5.3841e-01, -5.4084e-01,\n",
      "         1.1565e-03, -1.2020e+00, -9.7485e-01, -8.7966e-02, -4.1058e-01,\n",
      "        -1.3231e+00, -5.9745e-01, -1.1232e+00, -8.7720e-01, -8.3348e-01,\n",
      "        -6.2462e-01, -5.9435e-01, -2.1226e+00, -6.9739e-01, -1.1636e-01,\n",
      "        -1.2408e+00, -8.0507e-02, -8.0362e-01, -2.6213e-01, -3.0344e-02,\n",
      "        -1.7433e+00, -4.5267e-01,  5.2868e-01, -4.7425e-01, -9.6446e-01,\n",
      "        -7.4527e-01, -1.9560e+00, -1.6767e+00, -2.0314e+00,  6.7869e-01,\n",
      "        -1.3513e-01, -2.9624e-01, -1.3048e+00, -1.9070e+00, -8.0377e-01,\n",
      "        -1.5973e+00, -2.0119e+00, -1.0821e+00, -7.7968e-01, -6.7255e-01,\n",
      "        -1.2587e+00, -2.3503e+00, -3.8626e-01,  6.0509e-03, -2.9454e-02,\n",
      "        -4.2920e-01,  4.5361e-01, -5.8943e-01, -1.8749e+00, -2.2651e-01,\n",
      "        -1.0181e+00, -1.3144e+00, -1.2852e+00, -1.7732e-01, -1.5552e-01,\n",
      "        -1.3771e+00, -1.6684e+00, -1.7052e+00, -1.3386e+00, -1.5956e+00,\n",
      "        -1.8015e+00, -1.0050e+00, -3.4112e-01, -1.0086e+00, -1.9419e+00,\n",
      "        -2.6412e+00, -1.9821e+00, -1.2362e+00, -5.2618e-01, -6.3082e-01,\n",
      "        -5.0273e-01, -2.6014e-01, -9.8227e-01, -1.4754e-02, -1.1423e+00,\n",
      "        -3.4450e-01, -6.5098e-01, -4.0273e-01, -1.4012e+00, -7.4587e-01,\n",
      "        -1.0618e+00, -1.0019e+00, -1.8285e+00, -3.7437e-01, -5.9486e-01,\n",
      "        -4.8586e-01, -2.1715e+00, -2.0528e+00, -2.2895e+00, -1.1457e+00,\n",
      "        -2.8687e+00,  2.9629e-02, -1.0063e-01, -2.5087e+00, -6.3049e-01,\n",
      "        -1.1938e+00, -1.4253e+00, -1.4972e+00, -1.1047e+00, -8.4269e-01,\n",
      "        -1.7271e+00, -1.5782e+00,  6.4960e-01, -2.6090e-01, -7.1011e-01,\n",
      "         7.4556e-01, -9.2653e-01, -2.0277e-02, -2.1607e+00, -1.5064e+00,\n",
      "        -1.3893e+00, -4.7694e-01, -9.4276e-01, -3.2362e-01, -2.1727e-01,\n",
      "        -1.9198e+00, -4.3811e-02, -6.9261e-01, -1.6319e-01, -1.5976e+00,\n",
      "        -4.9654e-01, -1.1268e+00, -7.5766e-01, -8.6524e-01, -4.7801e-01,\n",
      "         7.0663e-02, -6.1848e-01, -2.3701e-01, -1.6553e+00, -1.9749e+00,\n",
      "        -3.2488e+00, -1.1736e+00, -8.9028e-01, -5.1460e-02, -1.2270e+00,\n",
      "        -1.9092e+00, -1.5856e+00, -2.4851e+00, -4.8555e-01, -1.0546e+00,\n",
      "        -6.1737e-02,  1.7869e-01, -7.1609e-01, -1.8080e+00,  8.5824e-02,\n",
      "        -8.0250e-01,  6.1389e-02, -7.9480e-01,  2.5976e-02, -2.2394e-01,\n",
      "        -1.9514e-01, -1.1954e+00, -2.5341e-01, -1.3588e+00, -1.4836e+00,\n",
      "        -1.5244e+00, -3.7993e-01, -7.2350e-01, -6.7702e-01, -4.6410e-02,\n",
      "        -4.2675e-01, -3.6469e-01, -1.4501e+00, -1.0498e+00, -6.7819e-01,\n",
      "        -2.1046e+00,  1.4143e-01, -2.8164e-01, -1.8522e+00, -9.1261e-01,\n",
      "        -8.8293e-01, -8.8344e-01, -3.5679e-01, -5.0632e-01, -1.7377e+00,\n",
      "        -2.3454e+00, -1.1159e+00, -2.4912e-01, -3.5539e-01, -1.2677e+00,\n",
      "        -4.3139e-01, -1.3137e+00,  3.7715e-01, -2.2031e+00, -1.1938e+00,\n",
      "        -9.2851e-01, -2.0833e-01, -5.8188e-01,  3.3050e-01, -3.3971e-01,\n",
      "        -6.3668e-01, -6.3336e-01, -1.6532e+00, -2.0542e-01, -2.8924e+00,\n",
      "        -5.3091e-01,  2.5568e-02, -2.5534e+00, -1.8577e+00,  9.7663e-02,\n",
      "        -6.2566e-03, -1.3502e+00, -3.1501e-01, -7.8627e-01, -1.3719e+00,\n",
      "        -2.0259e+00, -6.4284e-01, -1.7113e+00, -7.7514e-01, -1.1713e+00,\n",
      "        -2.2664e-02, -2.7414e-01, -1.6325e+00, -5.9434e-01, -1.1433e+00,\n",
      "        -1.3905e+00, -3.4511e-01,  1.5391e-01, -6.9627e-01, -1.5456e+00,\n",
      "        -7.1925e-01, -2.4735e+00, -9.0073e-01, -1.2607e+00,  1.4874e-01,\n",
      "         4.8184e-01,  1.8089e-01, -1.8107e+00,  1.0102e+00, -2.1337e-01,\n",
      "        -4.2388e-01, -1.0743e+00, -1.2617e+00,  2.4415e-01,  6.7704e-03,\n",
      "        -1.2064e+00, -3.9117e-01, -8.1338e-01, -9.2646e-01, -1.5227e+00,\n",
      "        -1.3960e+00, -1.0522e+00, -1.2953e+00, -1.2913e-01, -8.3673e-01,\n",
      "         2.1272e-01, -6.8889e-02, -8.4539e-01, -7.6189e-01, -9.3180e-01,\n",
      "         6.5910e-02,  4.5974e-02, -1.4831e+00, -5.5166e-01, -1.8485e-02,\n",
      "        -6.3725e-01, -1.8594e+00, -2.3032e+00, -1.1082e+00, -6.0737e-01,\n",
      "        -1.3308e+00, -1.6136e+00, -1.5838e-01, -4.1857e-01, -9.4313e-01,\n",
      "        -1.5327e+00, -1.1596e+00, -2.0290e-01, -2.0682e+00, -6.5734e-01,\n",
      "        -6.2978e-01,  5.7956e-01, -6.2711e-01, -1.6943e+00, -7.9049e-01,\n",
      "        -1.2083e-01, -3.4330e+00, -7.7334e-02, -1.8466e-01, -3.1442e-01,\n",
      "        -5.5915e-01, -1.7495e+00, -1.1729e+00, -5.3869e-01,  1.1238e-01,\n",
      "         2.2934e-02, -2.5813e+00, -2.6414e+00, -1.4876e+00, -8.7320e-01,\n",
      "        -9.8874e-01, -1.3804e+00, -7.1961e-01, -1.0217e+00, -9.3223e-01,\n",
      "        -1.7600e+00, -1.5965e+00, -2.3657e+00, -5.2112e-01, -8.1099e-01,\n",
      "        -1.4244e+00, -5.3014e-01, -1.9296e+00, -1.9311e+00, -1.0954e-01,\n",
      "        -6.9720e-01, -1.2773e+00,  6.5007e-01, -6.9498e-01, -1.6621e+00,\n",
      "        -1.4518e+00, -1.4389e+00, -1.0892e+00, -9.7447e-01, -9.5101e-01,\n",
      "        -1.9688e+00, -1.5633e+00, -8.2444e-01, -1.3208e+00, -9.5557e-01,\n",
      "        -9.9153e-01, -1.1659e+00, -4.3344e-01, -8.8664e-02,  5.8571e-01,\n",
      "        -2.3990e+00, -1.5280e-02, -1.3363e+00, -1.2976e+00, -1.5764e+00,\n",
      "        -1.2848e+00, -1.6981e+00, -1.6913e-02, -1.1978e+00, -5.6302e-01,\n",
      "        -2.3509e+00, -2.2371e-01, -6.3844e-01, -4.1319e-01, -8.1233e-01,\n",
      "        -9.5023e-01, -4.7645e-01, -9.4404e-01, -1.4324e+00, -1.0603e+00,\n",
      "        -1.6483e+00, -1.6384e-01, -1.1218e+00, -2.3723e-01, -1.4344e+00,\n",
      "        -5.4445e-01, -2.0193e-01, -5.3946e-01, -4.5669e-02, -4.5784e-01,\n",
      "        -1.2834e+00, -2.4643e-01, -4.0454e-01, -8.2802e-01, -2.4063e+00,\n",
      "        -2.9109e-01, -1.0506e+00, -7.6960e-01, -4.4497e-01, -6.5854e-01,\n",
      "        -8.4416e-01,  2.2650e-01, -5.6862e-01, -1.9207e+00, -1.2468e+00,\n",
      "        -1.0703e+00, -9.3834e-01, -9.9406e-01, -1.6320e+00, -6.2503e-01,\n",
      "        -1.3369e+00, -8.3271e-01, -3.6075e+00, -7.2174e-01, -1.0324e+00,\n",
      "         3.9930e-01, -4.2212e-01,  8.2518e-01, -4.4966e-01, -2.2850e-01,\n",
      "        -2.6265e+00, -9.1007e-01, -1.9606e+00, -1.9332e+00, -7.9767e-01,\n",
      "        -2.1039e+00, -4.9861e-01,  7.4961e-01, -7.2544e-01,  6.9791e-01,\n",
      "        -2.3976e-01,  1.6759e-01, -8.1588e-01, -7.3178e-01, -1.6342e+00,\n",
      "        -1.6453e+00, -1.2997e-01, -1.5279e+00, -9.6014e-01, -1.7523e+00,\n",
      "        -8.8342e-01, -3.7224e-01, -9.8170e-01, -1.3671e+00, -2.4608e+00,\n",
      "        -1.8226e-01, -3.8927e-01, -4.7189e-01, -1.3362e+00, -1.7808e-01,\n",
      "        -8.2135e-01,  1.2028e+00, -5.0940e-01, -1.4054e-01, -4.4966e-01,\n",
      "        -4.4924e-01,  8.6474e-02, -2.0290e-01, -1.2084e+00, -1.5972e+00,\n",
      "        -2.1105e+00, -2.3812e+00, -4.4460e-01, -5.1346e-01, -1.7152e+00,\n",
      "        -4.3607e-01, -8.4525e-01, -5.6072e-01, -1.6702e+00, -1.3095e-01,\n",
      "        -4.7511e-02, -1.6854e+00, -3.0689e+00, -1.9354e-01, -2.0444e+00,\n",
      "        -2.1568e+00, -4.7515e-01, -8.3407e-01,  1.3241e-01, -2.8832e-01,\n",
      "        -2.2968e-01, -1.0917e+00, -6.4002e-02, -2.4557e-01, -1.0025e+00,\n",
      "         3.8394e-01, -1.3439e+00, -1.8077e+00, -2.9631e-01, -1.1878e-02,\n",
      "         2.8397e-01, -1.7784e-01, -1.1082e+00, -5.9459e-01, -7.6423e-01,\n",
      "        -1.1618e+00, -1.2950e-01, -7.8114e-01, -5.3116e-01, -1.4953e+00,\n",
      "        -1.2665e+00, -1.7312e+00, -1.8014e+00, -1.9689e+00, -3.0436e-01,\n",
      "        -5.2000e-01, -2.2597e+00, -3.7306e-01, -1.4177e-01, -6.5948e-01,\n",
      "        -1.2421e+00, -1.4370e+00, -1.1707e+00, -7.5979e-01, -1.5922e+00,\n",
      "        -2.9184e+00, -7.5491e-01,  1.3382e-01, -3.5268e-01, -9.4310e-01,\n",
      "        -1.6308e+00, -5.9609e-02, -9.5632e-01, -1.3871e+00, -3.2204e-01,\n",
      "        -1.6180e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0173]],\n",
      "\n",
      "         [[-0.2655]],\n",
      "\n",
      "         [[ 0.0431]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3390]],\n",
      "\n",
      "         [[ 0.0269]],\n",
      "\n",
      "         [[ 0.1311]]],\n",
      "\n",
      "\n",
      "        [[[-0.3005]],\n",
      "\n",
      "         [[ 0.1938]],\n",
      "\n",
      "         [[-0.3425]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0684]],\n",
      "\n",
      "         [[ 0.2259]],\n",
      "\n",
      "         [[ 0.5881]]],\n",
      "\n",
      "\n",
      "        [[[-0.1645]],\n",
      "\n",
      "         [[-0.1192]],\n",
      "\n",
      "         [[-0.0907]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2038]],\n",
      "\n",
      "         [[-0.4885]],\n",
      "\n",
      "         [[-0.3777]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.5818]],\n",
      "\n",
      "         [[ 0.2213]],\n",
      "\n",
      "         [[ 0.6473]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3662]],\n",
      "\n",
      "         [[ 0.1592]],\n",
      "\n",
      "         [[-0.1364]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3004]],\n",
      "\n",
      "         [[-0.2642]],\n",
      "\n",
      "         [[-0.0192]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.8328]],\n",
      "\n",
      "         [[-0.0804]],\n",
      "\n",
      "         [[-0.0417]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1466]],\n",
      "\n",
      "         [[ 0.2564]],\n",
      "\n",
      "         [[-0.1223]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0409]],\n",
      "\n",
      "         [[ 0.0312]],\n",
      "\n",
      "         [[ 0.1233]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1017,  0.0536, -0.1601,  0.0522, -0.0086,  0.0496,  0.1009,  0.1859,\n",
      "         0.2350, -0.0263,  0.1551, -0.0033,  0.1777,  0.1866,  0.0777, -0.0023,\n",
      "        -0.0707,  0.1548,  0.1287, -0.0536, -0.2838,  0.0081,  0.1060, -0.0045],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1279]],\n",
      "\n",
      "         [[ 0.4397]],\n",
      "\n",
      "         [[ 0.0224]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2831]],\n",
      "\n",
      "         [[ 0.1473]],\n",
      "\n",
      "         [[ 0.3414]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0812]],\n",
      "\n",
      "         [[-0.3839]],\n",
      "\n",
      "         [[ 0.0762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4051]],\n",
      "\n",
      "         [[ 0.3739]],\n",
      "\n",
      "         [[ 0.1627]]],\n",
      "\n",
      "\n",
      "        [[[-0.3304]],\n",
      "\n",
      "         [[ 0.6606]],\n",
      "\n",
      "         [[-0.1053]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0383]],\n",
      "\n",
      "         [[-0.5669]],\n",
      "\n",
      "         [[ 0.0559]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2645]],\n",
      "\n",
      "         [[ 0.1153]],\n",
      "\n",
      "         [[-0.1169]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2407]],\n",
      "\n",
      "         [[-0.3754]],\n",
      "\n",
      "         [[-0.5683]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1009]],\n",
      "\n",
      "         [[ 0.0288]],\n",
      "\n",
      "         [[-0.2235]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.8576]],\n",
      "\n",
      "         [[-0.1015]],\n",
      "\n",
      "         [[ 0.6938]]],\n",
      "\n",
      "\n",
      "        [[[-0.0763]],\n",
      "\n",
      "         [[ 0.3960]],\n",
      "\n",
      "         [[-0.2405]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1514]],\n",
      "\n",
      "         [[ 0.0565]],\n",
      "\n",
      "         [[ 0.0104]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 7.1098e-03,  1.2237e-01,  1.0507e-01,  4.9799e-01, -1.6918e-02,\n",
      "         4.0312e-01,  6.9794e-02,  2.6959e-01,  1.1183e-01, -3.4205e-01,\n",
      "        -1.3268e-01, -1.1495e-02, -1.2549e-01, -5.4462e-01,  3.2965e-01,\n",
      "        -1.1244e-01, -3.5067e-01, -3.8429e-01, -3.0331e-01, -2.3262e-01,\n",
      "        -4.0307e-02,  5.3920e-01, -3.8724e-01, -2.4840e-01,  6.3065e-02,\n",
      "        -1.8558e-01,  3.5491e-02,  5.6884e-01, -4.5507e-02,  4.1989e-01,\n",
      "        -1.0507e-01, -5.8472e-01,  2.7422e-03,  3.3822e-01,  2.7327e-02,\n",
      "        -3.3705e-01,  9.6722e-02,  1.6244e-01,  2.7456e-01, -2.3312e-01,\n",
      "         1.8848e-01,  1.8291e-01,  2.9685e-01,  1.7661e-01, -1.2274e-01,\n",
      "        -4.0864e-01, -8.5316e-02,  4.8963e-02, -2.6993e-01,  1.9917e-01,\n",
      "         1.4098e-01,  4.9228e-01,  1.3397e-01,  1.5332e-01, -4.6434e-01,\n",
      "         3.0400e-01,  4.3100e-01, -1.5991e-01,  1.7563e-01, -1.0792e-01,\n",
      "        -2.8303e-01,  5.2330e-02, -3.3047e-01, -1.1707e-01,  3.2095e-01,\n",
      "         5.2743e-01, -1.0771e-01,  3.2225e-01,  5.3141e-01, -4.0495e-01,\n",
      "         4.0969e-01, -1.8551e-01,  1.0643e-01, -3.1455e-01,  2.1039e-02,\n",
      "        -1.4942e-02,  2.8016e-01,  2.0158e-01,  3.7004e-01,  5.6931e-02,\n",
      "         5.6983e-01,  1.1272e-01, -7.3652e-02,  9.5526e-02,  3.9979e-02,\n",
      "        -1.2338e-01,  4.2488e-01,  1.4467e-01,  1.4210e-01, -2.7287e-01,\n",
      "        -5.7184e-02, -3.8049e-01,  1.1397e-01,  2.5179e-01, -2.6631e-01,\n",
      "        -1.7595e-01, -4.0066e-01,  4.8029e-01, -4.0585e-01,  1.7391e-01,\n",
      "         2.0891e-01, -1.9100e-01, -1.2801e-01, -3.6244e-01, -1.3106e-02,\n",
      "        -1.7944e-01,  4.0521e-01,  1.2964e-01, -8.9097e-02, -1.8366e-01,\n",
      "         1.9533e-01, -3.7137e-01,  2.0030e-01,  1.4427e-02,  4.8900e-01,\n",
      "         2.0822e-01, -4.7777e-01, -3.0679e-01, -1.2518e-01, -4.7233e-01,\n",
      "        -3.2208e-01, -1.2533e-01,  1.6016e-01, -1.2007e-01,  1.3903e-01,\n",
      "         4.2279e-01, -4.9558e-02, -4.2698e-01, -4.4670e-01,  3.0155e-01,\n",
      "        -2.0989e-01, -4.2609e-01, -3.9318e-01, -4.5546e-02,  4.1692e-01,\n",
      "        -4.8169e-02, -5.6167e-01,  1.1751e-01,  2.5858e-01,  6.2281e-01,\n",
      "        -1.2040e-01,  4.5028e-01,  3.5697e-01,  5.2949e-01,  1.4935e-01,\n",
      "        -3.7374e-01, -8.7862e-02,  2.1809e-01,  1.1588e-01,  3.0507e-01,\n",
      "         1.8514e-01, -2.1939e-02,  4.5422e-01,  6.6240e-02,  2.5802e-01,\n",
      "        -2.6102e-01,  3.3986e-02,  3.1431e-01, -3.1851e-01, -3.8843e-01,\n",
      "        -8.3059e-02, -3.1192e-01, -5.4506e-02,  1.7080e-01,  6.5269e-01,\n",
      "         1.6482e-01, -2.7196e-01, -3.7513e-01, -1.9561e-01, -2.9618e-01,\n",
      "        -1.2720e-01, -1.7265e-01,  3.5654e-01, -3.2898e-01, -1.2053e-01,\n",
      "         2.6679e-01, -8.2078e-02, -4.5439e-01, -3.4699e-01, -3.3786e-02,\n",
      "        -6.1724e-02, -2.7943e-01, -2.2718e-01, -3.8253e-01,  4.0956e-01,\n",
      "         4.5756e-01, -3.6752e-01,  2.6178e-01, -6.2073e-01,  7.9673e-02,\n",
      "        -7.1121e-02, -4.0409e-01, -1.8726e-01,  6.8028e-02, -1.3287e-01,\n",
      "        -3.4911e-01, -2.2362e-01,  4.0290e-01, -4.2150e-01,  2.1534e-01,\n",
      "         3.1320e-01, -8.5731e-04, -3.6617e-01,  2.0008e-01,  4.8887e-02,\n",
      "         1.1894e-01,  4.2607e-01,  5.3674e-02, -3.5960e-02,  2.6483e-02,\n",
      "         3.9168e-01,  2.4182e-01,  2.4299e-01, -1.2383e-01,  2.6582e-01,\n",
      "         2.9364e-01, -1.1681e-01, -1.5795e-02, -1.6092e-01, -5.9831e-02,\n",
      "         2.8375e-03,  3.1622e-02, -7.4340e-02, -2.8567e-01,  3.0040e-01,\n",
      "         2.0774e-01,  4.7970e-01,  1.8710e-01, -1.8351e-01,  3.7585e-01,\n",
      "         3.1451e-01, -2.9839e-01, -1.2626e-01, -1.2606e-01,  2.4497e-01,\n",
      "        -1.5779e-01,  1.6158e-02, -3.7264e-01,  3.1189e-01, -3.3411e-01,\n",
      "        -2.8614e-01,  5.7395e-01, -3.9705e-02, -5.4076e-01, -4.6181e-01,\n",
      "         3.6667e-01, -3.3654e-01, -2.5739e-01, -2.2063e-01,  2.4335e-01,\n",
      "         2.8934e-01, -1.0428e-01, -7.3958e-02, -1.0902e-01,  3.4871e-01,\n",
      "        -1.3039e-01, -1.1614e-01,  2.1353e-01, -1.5530e-01, -3.1949e-01,\n",
      "         5.3057e-01,  1.6566e-03, -9.0540e-02,  3.5640e-02, -3.2763e-02,\n",
      "         3.8987e-02,  3.9183e-01, -3.7117e-01, -5.2564e-01, -3.2765e-01,\n",
      "         1.3715e-01,  2.6159e-01, -6.3720e-02,  6.1975e-01, -4.2679e-01,\n",
      "         1.7691e-01, -1.2289e-01, -5.1943e-02, -1.5491e-01, -4.2987e-01,\n",
      "         1.7155e-01, -2.5179e-01,  2.0031e-01,  3.0506e-04, -4.2760e-01,\n",
      "        -1.7437e-01,  2.6757e-01, -1.2519e-01, -2.0851e-01,  4.2975e-01,\n",
      "         2.6966e-02, -5.2828e-01,  4.3638e-01, -1.2133e-01, -5.5546e-02,\n",
      "        -4.8434e-01, -3.5359e-01, -6.7154e-03, -2.4117e-01,  3.0418e-01,\n",
      "        -3.5423e-01,  3.3198e-01,  2.5527e-01, -4.9099e-01,  4.6512e-01,\n",
      "        -4.7229e-01,  3.2894e-01,  1.9975e-01,  2.3964e-01,  4.7907e-02,\n",
      "        -1.1429e-01, -1.8462e-01,  5.5062e-01, -2.1682e-01, -6.4180e-02,\n",
      "         1.5632e-01,  1.4896e-02,  3.5440e-01,  3.4837e-02,  3.0172e-01,\n",
      "         1.2383e-01,  4.4193e-02,  3.2905e-01,  2.8343e-01, -8.1879e-02,\n",
      "         2.7934e-01, -3.4355e-01, -1.8735e-01,  5.0056e-01,  3.8178e-01,\n",
      "        -2.0503e-01,  2.6914e-01, -2.3443e-01,  7.9646e-02,  1.0922e-01,\n",
      "        -4.5724e-01, -1.9567e-01,  8.5954e-02,  1.2818e-01,  2.6947e-02,\n",
      "         1.8406e-01,  4.0637e-01, -4.4052e-02, -5.5875e-01,  2.5132e-01,\n",
      "         2.8340e-01, -9.1327e-02,  3.0828e-01, -2.1911e-01,  1.2715e-01,\n",
      "         3.2473e-02,  4.1731e-01, -2.8626e-01,  2.8725e-01, -2.4051e-01,\n",
      "        -2.3237e-01,  5.1011e-01, -2.5142e-01,  1.5321e-01, -2.9089e-01,\n",
      "        -5.6413e-02,  3.3367e-01, -9.2183e-02,  6.7503e-02, -2.1487e-01,\n",
      "         7.5579e-02,  1.2906e-01,  5.2248e-01, -2.0328e-01, -3.2141e-01,\n",
      "         8.7631e-02, -3.8505e-01, -2.1600e-01, -1.1088e-01,  1.0019e-01,\n",
      "         4.3171e-02,  3.2055e-01,  2.3602e-02, -3.2555e-01, -2.7029e-01,\n",
      "        -3.2753e-01, -1.0942e-03,  3.6320e-01, -3.0918e-01,  3.2364e-01,\n",
      "         3.8089e-01,  1.2210e-01, -4.3923e-01, -5.4469e-02, -3.7526e-01,\n",
      "        -2.3952e-01, -7.6765e-02,  7.8229e-02,  1.4944e-01,  4.9943e-01,\n",
      "         3.7611e-01, -3.1473e-01,  1.4665e-01, -1.5702e-01,  3.4325e-01,\n",
      "        -5.8623e-01,  3.2876e-01,  2.3000e-01,  3.7860e-01, -6.2001e-02,\n",
      "        -3.1810e-01, -6.6129e-01, -3.3721e-01, -3.8272e-01, -1.3967e-01,\n",
      "         3.9515e-01,  1.5553e-01, -2.2284e-01, -2.6965e-01,  6.1648e-02,\n",
      "         2.7933e-01,  2.6740e-01, -1.4140e-01, -4.9703e-01,  2.8931e-01,\n",
      "         2.4706e-01,  3.5055e-02, -2.4752e-01,  3.6761e-01, -3.7579e-02,\n",
      "        -5.5143e-01,  3.9343e-01, -1.0312e-01,  1.0822e-01, -1.0685e-01,\n",
      "        -8.9259e-02, -9.2842e-02, -4.1792e-01,  6.8822e-03,  4.4967e-03,\n",
      "        -4.0465e-01, -1.5352e-02, -1.7171e-01, -1.1418e-01, -3.0573e-01,\n",
      "        -3.2757e-01, -2.7643e-01, -6.4230e-01,  1.1273e-01, -1.4248e-01,\n",
      "        -4.6418e-01, -1.9763e-01,  3.7332e-01, -4.4712e-01,  2.0430e-01,\n",
      "         1.1056e-01, -7.3370e-02,  4.7358e-01, -2.2628e-01, -4.7803e-01,\n",
      "         5.5365e-01, -1.8915e-01, -1.5444e-01,  7.5045e-02, -1.9455e-01,\n",
      "         5.0462e-02, -1.9383e-02,  2.4755e-01,  1.1730e-01, -4.6771e-02,\n",
      "        -1.2648e-01, -1.7063e-02, -9.0305e-02,  2.8374e-01, -7.4786e-02,\n",
      "         4.4458e-01, -3.1648e-01, -8.9984e-02,  9.2227e-02,  4.4114e-01,\n",
      "         2.4619e-01, -3.6999e-01, -2.5276e-02, -1.8067e-01, -1.8665e-01,\n",
      "         2.7659e-01, -5.1515e-01, -2.1958e-01, -5.5463e-02, -2.1102e-01,\n",
      "         4.7753e-01,  4.3756e-01,  7.4768e-02, -1.1914e-01,  4.2964e-01,\n",
      "         2.9074e-01,  3.3679e-01, -1.5062e-01,  2.0089e-01, -6.7575e-02,\n",
      "         4.2026e-01,  3.8408e-01, -2.0078e-01, -9.8698e-03, -2.4791e-01,\n",
      "        -3.2734e-01,  1.6744e-01,  5.9850e-02, -5.0646e-03, -4.4976e-01,\n",
      "         3.3893e-01, -2.3268e-01,  2.7673e-01,  2.5182e-01, -3.0869e-01,\n",
      "         2.7249e-01, -1.5606e-02, -5.7617e-02,  1.0301e-01,  3.4020e-01,\n",
      "        -5.0083e-01, -2.6099e-01, -2.7378e-01,  2.4118e-02, -2.8944e-01,\n",
      "        -2.7145e-02, -1.7750e-01,  7.5102e-03, -3.7634e-01,  2.7001e-01,\n",
      "         1.4122e-01,  4.0136e-01, -4.3637e-01, -9.3503e-02,  3.5703e-01,\n",
      "        -3.4876e-01,  4.8174e-01, -1.3005e-01,  5.9169e-03, -5.9179e-01,\n",
      "        -2.0711e-01, -9.7026e-02,  2.8148e-01,  4.9219e-02,  1.3587e-01,\n",
      "         2.5570e-01,  1.2327e-02, -3.6657e-01, -5.3338e-01, -4.5573e-01,\n",
      "        -1.2118e-01,  4.0609e-01,  2.2576e-03, -1.2296e-01,  6.0046e-02,\n",
      "         1.9202e-01,  4.2699e-02,  3.9454e-01,  1.1775e-01, -8.7926e-02,\n",
      "        -4.8443e-01,  4.1572e-01,  1.6832e-01, -2.4795e-01,  1.6521e-01,\n",
      "         2.6180e-01, -1.9976e-01, -3.0076e-01, -1.2680e-02,  5.2779e-01,\n",
      "        -4.0184e-01, -2.5617e-01, -4.5446e-01, -5.5491e-01,  1.7412e-01,\n",
      "         2.2364e-01, -6.1249e-01, -3.9319e-01, -2.2024e-01,  5.2240e-02,\n",
      "         2.4544e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.6193]],\n",
      "\n",
      "         [[-0.1216]],\n",
      "\n",
      "         [[-0.2426]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3658]],\n",
      "\n",
      "         [[ 0.5350]],\n",
      "\n",
      "         [[ 0.4803]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3807]],\n",
      "\n",
      "         [[-0.6097]],\n",
      "\n",
      "         [[-0.1954]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1445]],\n",
      "\n",
      "         [[ 0.1729]],\n",
      "\n",
      "         [[-0.0451]]],\n",
      "\n",
      "\n",
      "        [[[-0.0454]],\n",
      "\n",
      "         [[ 0.5658]],\n",
      "\n",
      "         [[ 0.3759]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2008]],\n",
      "\n",
      "         [[-0.4793]],\n",
      "\n",
      "         [[-0.0714]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3698]],\n",
      "\n",
      "         [[ 0.3361]],\n",
      "\n",
      "         [[ 0.1700]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2616]],\n",
      "\n",
      "         [[ 0.4064]],\n",
      "\n",
      "         [[-0.1952]]],\n",
      "\n",
      "\n",
      "        [[[-0.0088]],\n",
      "\n",
      "         [[ 0.3928]],\n",
      "\n",
      "         [[ 0.2820]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7353]],\n",
      "\n",
      "         [[ 0.2047]],\n",
      "\n",
      "         [[-0.0537]]],\n",
      "\n",
      "\n",
      "        [[[-0.3953]],\n",
      "\n",
      "         [[-0.2206]],\n",
      "\n",
      "         [[ 0.2959]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9481]],\n",
      "\n",
      "         [[ 0.0901]],\n",
      "\n",
      "         [[ 0.4776]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.0635, 0.4874, 0.5579, 0.6413, 0.4375, 0.6711, 0.2335, 0.3786, 1.4203,\n",
      "        0.7136, 0.7354, 0.5364, 0.6638, 1.6529, 0.9452, 0.5525, 1.1329, 0.0315,\n",
      "        0.7302, 2.5495, 0.7399, 1.4425, 0.8829, 0.0637, 0.9679, 0.8909, 0.9285,\n",
      "        0.3454, 0.0109, 1.0510, 0.3942, 0.8949, 1.3764, 0.3099, 0.5941, 0.4454,\n",
      "        1.4114, 0.3322, 1.1735, 1.0959, 0.3980, 0.6530, 0.0893, 1.2343, 0.0128,\n",
      "        0.1382, 0.7839, 0.2812, 0.4400, 0.7928, 0.3692, 0.2609, 0.4919, 1.2674,\n",
      "        0.3518, 0.2344, 0.7348, 0.2978, 0.5287, 1.1558, 0.5224, 0.9687, 1.9021,\n",
      "        0.3877, 1.0051, 0.5264, 0.4550, 0.6571, 1.4736, 0.0971, 0.2022, 0.5320,\n",
      "        0.4843, 0.4236, 0.4805, 1.2637, 0.9748, 0.5679, 0.6404, 0.6452, 0.5167,\n",
      "        1.0644, 1.3932, 0.7717, 0.9078, 1.0482, 0.7320, 0.1598, 0.1735, 0.1949,\n",
      "        0.1520, 0.3822, 0.5856, 0.4630, 0.8141, 0.4878], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.5054,  0.0597,  0.2688, -0.5687,  0.4904,  0.1153, -0.8944, -0.2444,\n",
      "         0.0284, -0.4904,  0.1983,  0.6439,  0.1192,  0.9636,  0.0747,  0.1385,\n",
      "         0.2757, -0.2868,  0.0740, -0.7683, -0.0735, -0.2516, -0.1123, -0.3036,\n",
      "        -0.2007,  0.1006,  0.4998,  0.3854, -0.6111,  0.0809,  0.1175,  0.0441,\n",
      "         0.2278,  0.0538, -0.1009, -0.0799, -0.1899,  0.8399,  0.4554,  0.1498,\n",
      "        -0.0726, -0.2587, -0.1260, -0.2293, -0.0636, -0.1472, -0.5296,  0.0707,\n",
      "         0.2034,  0.1138, -0.2179,  0.7075,  0.0974, -0.3973, -0.6326,  0.2581,\n",
      "         0.3240,  0.1134, -0.1140,  0.3411,  0.3302,  0.0888,  0.2039, -0.8440,\n",
      "         0.7335, -0.7806,  0.5790,  0.4055, -0.7332, -0.1189,  0.0151, -0.3886,\n",
      "        -0.1328,  0.1652,  0.6326,  0.4963, -0.0479, -0.0175, -0.1067,  0.2985,\n",
      "        -0.0486,  0.3798, -0.1922,  0.0724,  0.0142, -0.5326,  0.6015,  0.3231,\n",
      "        -0.4833, -0.1651,  0.1889, -0.7342, -0.0304, -0.0379,  0.0333,  0.1308],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.1823]],\n",
      "\n",
      "         [[-0.2513]],\n",
      "\n",
      "         [[ 0.1163]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0732]],\n",
      "\n",
      "         [[-0.0781]],\n",
      "\n",
      "         [[-0.3756]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3236]],\n",
      "\n",
      "         [[-0.5986]],\n",
      "\n",
      "         [[ 0.4555]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3588]],\n",
      "\n",
      "         [[ 0.3484]],\n",
      "\n",
      "         [[-0.7233]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2187]],\n",
      "\n",
      "         [[-0.0691]],\n",
      "\n",
      "         [[-0.3241]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4241]],\n",
      "\n",
      "         [[ 0.2903]],\n",
      "\n",
      "         [[-0.1177]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.7645]],\n",
      "\n",
      "         [[ 0.2164]],\n",
      "\n",
      "         [[ 0.3030]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2025]],\n",
      "\n",
      "         [[-0.1258]],\n",
      "\n",
      "         [[-0.4223]]],\n",
      "\n",
      "\n",
      "        [[[-0.0051]],\n",
      "\n",
      "         [[-0.3980]],\n",
      "\n",
      "         [[-0.2604]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2856]],\n",
      "\n",
      "         [[ 0.1036]],\n",
      "\n",
      "         [[-0.8787]]],\n",
      "\n",
      "\n",
      "        [[[-0.4128]],\n",
      "\n",
      "         [[ 0.1458]],\n",
      "\n",
      "         [[-0.0820]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2061]],\n",
      "\n",
      "         [[-0.2283]],\n",
      "\n",
      "         [[-0.7614]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.6916,  1.0775,  0.8740,  0.5773,  1.3474,  0.8695,  0.8839,  2.4172,\n",
      "         1.9476,  2.0210,  2.4457,  1.6852,  1.1509,  0.3956,  1.7727,  0.4358,\n",
      "         0.9310,  1.9486,  0.6104,  0.3006,  1.1573,  1.1026,  0.1755,  1.2964,\n",
      "         0.3092,  0.5612,  1.1091,  0.9928,  0.5377,  1.2228,  1.1746,  0.2597,\n",
      "         0.8844,  3.3838,  1.1673,  1.8952,  1.7323,  0.9771,  3.4564,  0.3797,\n",
      "         1.9166,  0.6090,  2.4420,  1.7849,  0.5574,  2.5840,  0.4524,  1.5277,\n",
      "         0.6309,  1.1085,  0.9966,  0.5779,  1.3616,  1.7579,  1.3355,  1.3547,\n",
      "         1.5299,  1.0899,  0.5432,  0.6496,  2.8385,  0.6443,  2.1803,  1.5034,\n",
      "         1.7086,  0.5931,  1.2819,  1.9042,  1.0514,  0.3205,  1.2077,  2.2711,\n",
      "         0.3290,  0.4685,  1.2682,  2.0250,  1.7993,  1.2137,  0.1224,  0.9423,\n",
      "         0.9663,  1.7739,  0.4125,  0.5407,  0.0957,  0.2521,  0.8571,  1.6983,\n",
      "         1.8463,  0.9565,  2.3230,  1.4656,  0.5871,  1.4254,  0.7997,  0.8981,\n",
      "         1.9380,  1.8281,  0.9183,  2.1023,  0.5878,  0.5333,  1.4032,  1.3376,\n",
      "         1.2875,  1.1145,  1.2524,  1.5843,  1.6148,  3.1291,  1.0432,  1.3251,\n",
      "         1.7479,  1.2636,  0.8845,  1.6374,  1.1796,  3.7250,  1.5945,  1.4920,\n",
      "         1.0296,  1.7583,  1.7806,  0.5249,  1.3189,  0.7346,  0.4304,  0.2694,\n",
      "         0.7667,  0.0380,  1.3443,  1.9057,  1.0223,  1.8737,  1.0958,  1.2419,\n",
      "         0.9536,  0.2399,  1.8091,  2.1473,  1.5022,  0.3114,  1.8444,  0.8121,\n",
      "         2.1650,  1.5947,  0.9298,  1.9355,  0.5926,  0.6403,  0.3359,  2.4222,\n",
      "         1.1249,  1.9948,  0.8876,  1.2094,  1.0489,  0.2170,  1.5972,  1.7167,\n",
      "         0.8702,  0.8315, -0.0234,  1.8705,  1.3742,  1.5409,  1.4228,  0.4402,\n",
      "         1.5174,  1.2201,  1.5997,  2.4493,  0.3136,  2.0850,  0.6765,  0.8073,\n",
      "         1.1205,  2.2645,  1.2478,  2.5162,  1.5563,  1.4127,  1.0340,  1.3899,\n",
      "         0.2547,  1.7197,  0.7652,  1.2020,  0.7351,  1.7097,  0.3305,  1.0593,\n",
      "         2.6948,  1.0129,  1.6052,  1.2948,  1.9197,  0.8980,  2.4436,  2.0377,\n",
      "         0.5143,  1.5850,  1.1536,  0.3987,  0.7597,  1.9752,  1.9151,  1.1792,\n",
      "         0.5641,  1.0909,  2.0338,  0.2094,  1.6859,  0.6835,  0.3950,  0.9044,\n",
      "         0.7761,  1.1035,  0.6618,  1.6598,  0.9463,  1.0390,  0.4941,  1.9337,\n",
      "         0.9185,  1.4091,  1.5537,  2.0580,  0.1812,  0.5797,  0.8590,  1.7944,\n",
      "         0.4974,  1.6155,  1.1814,  0.7065,  1.0613,  1.4004,  1.7608,  0.1737,\n",
      "         1.1454,  1.1181,  0.1290,  0.4414,  2.3504,  0.4539,  1.1048,  1.8231,\n",
      "         0.7208,  1.3215,  0.6436,  0.4107,  1.6407,  1.1962,  0.9539,  2.0408,\n",
      "         1.2123,  1.0548,  1.6492,  1.4411,  1.3505,  1.4004,  0.9359,  1.1881,\n",
      "         2.4340,  0.8163,  2.1911,  1.3160,  0.5465,  0.8657,  0.4587,  1.6195,\n",
      "         0.9929,  0.2882,  1.2771,  0.6711,  2.0529,  1.9121,  1.6101,  0.2737,\n",
      "         0.6668,  0.4107,  0.8697,  1.3587,  0.9563,  0.7937,  2.1700,  0.7756,\n",
      "         2.3011,  0.6930,  1.7177,  0.3806,  0.2504, -0.1784,  0.4506,  1.3035,\n",
      "         1.1569,  2.4690,  3.2559,  2.1349,  0.9697,  0.4078,  1.5951,  2.3248,\n",
      "         1.9429,  2.3317,  0.2765,  0.7267,  1.5056,  2.3644,  1.9505,  2.5669,\n",
      "         0.8804,  1.5031,  1.4885,  0.5221,  2.3490,  0.7846,  0.2721,  2.7996,\n",
      "         2.0429,  1.3096,  0.6342,  0.2718,  0.5236,  1.5218,  1.3798,  1.1895,\n",
      "         1.2892,  1.4028,  0.7002,  1.5625,  2.3194,  1.1390,  2.5299,  1.2459,\n",
      "         2.0158,  1.9954,  3.1365,  1.2292,  1.7576,  0.9649,  1.2292,  1.0249,\n",
      "         0.9643,  0.4768,  2.7571,  0.7186,  2.1981,  1.5046,  3.1652,  0.6832,\n",
      "         1.8334,  1.8199,  1.9911,  1.1613,  2.6093,  0.7329,  0.4944,  0.1182,\n",
      "         0.6642,  0.9293,  1.7240,  0.7914,  0.4246,  1.4278,  1.0405,  1.2089,\n",
      "         0.2879,  1.8373,  1.7119,  2.2798,  0.6715,  2.4830,  1.8516,  0.8322,\n",
      "         1.2597,  0.8309,  1.5089,  1.9757,  0.9430,  2.4317,  0.5229,  2.1463,\n",
      "         2.1838,  1.5684,  2.3450,  0.7125,  2.0381,  1.1655,  0.2713,  2.2997,\n",
      "         0.0618,  0.6392,  1.4808,  0.9163,  0.5214,  0.4713,  2.4292,  0.4333,\n",
      "         0.3093,  0.4379,  2.1330,  0.2301,  0.3249,  0.4583,  3.6140,  1.4812,\n",
      "         0.3768,  0.6446,  2.0376, -0.4720,  1.1816,  1.9297,  1.8736,  1.2751,\n",
      "         0.2254,  1.4315,  1.2788,  1.5174,  1.5849,  0.8552,  0.5853,  2.4746,\n",
      "         0.8914,  1.1631,  2.8634,  0.8391,  1.9753,  1.8185,  0.9107,  0.2361,\n",
      "         1.4866,  1.5641,  0.1737,  1.3758,  0.6514,  1.2898,  0.7788,  0.5625,\n",
      "         1.5317,  2.2992,  0.2693,  0.2872,  1.3073,  1.1892,  1.5594,  1.8278,\n",
      "         1.4504,  1.9485,  1.7955,  1.6212,  2.5375,  1.9581,  1.6977,  1.0121,\n",
      "         2.2436,  0.6153,  1.2851,  2.2429,  1.1225,  1.5588,  1.6871,  0.2587,\n",
      "         1.9947,  1.4642,  1.1680,  2.6560,  0.5785,  1.3149,  1.2286,  0.2197,\n",
      "         0.3677,  1.3205,  1.1264,  2.0402,  2.0353,  1.4331,  2.6753,  1.0056,\n",
      "         0.7952,  1.3867,  1.6727,  1.5987,  0.6039,  2.7896,  1.4378,  1.9674,\n",
      "         1.8532,  1.3371,  1.2622,  1.8610,  1.1862,  0.5193,  1.0529,  0.2757,\n",
      "         4.1004,  0.4959,  0.1497,  1.8302,  1.6242,  0.8043,  0.4913,  1.0395,\n",
      "         1.2328,  0.3912,  1.9044,  2.6017,  1.0271,  2.5692,  0.6237,  0.7146,\n",
      "         1.9807,  0.3090,  1.1114,  2.0313,  2.4768,  0.3168,  1.3196,  1.3979,\n",
      "         0.8342,  1.3285,  0.6586,  0.6093,  0.4485,  1.3948,  0.3492,  2.0173,\n",
      "         1.1223,  1.0438,  2.6197,  0.9437,  1.8489,  1.4644,  1.4471,  1.2212,\n",
      "         1.3184,  0.3109,  0.2961,  1.3556,  1.1982,  1.9708,  1.1836,  1.7691,\n",
      "         0.5303,  0.1878,  1.0420,  1.3673,  0.8804,  0.7535,  1.3639,  1.3930,\n",
      "         0.2603,  1.2540,  1.0909,  1.4756,  0.4312,  0.1948,  1.4850,  2.6980,\n",
      "         1.1255,  1.4472,  2.6432,  1.6197,  0.2488,  0.4743, -0.3287,  0.3574,\n",
      "         0.7725,  1.4916,  2.0147,  0.3839,  1.0510,  0.1608,  0.8027,  2.7000],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 4.5054e-01, -3.0704e-01, -2.9146e+00,  1.1545e+00, -1.8653e+00,\n",
      "        -2.5797e-01,  8.6975e-01,  2.1617e-01,  8.3075e-01,  1.4281e+00,\n",
      "        -2.8052e+00, -1.3465e-01,  7.7429e-01, -8.3621e-02, -1.9864e-01,\n",
      "        -2.2555e-01, -2.6039e-01,  1.6982e-01, -1.5054e-01,  6.6774e-02,\n",
      "        -6.1963e-01, -1.6773e+00, -1.6917e-01,  2.2243e-01,  1.3715e-01,\n",
      "         1.3078e+00,  2.3913e+00, -1.2174e+00, -1.9321e-01, -7.6501e-01,\n",
      "        -1.4085e+00, -8.8497e-02,  1.0400e+00,  1.0043e+00, -9.3173e-01,\n",
      "        -1.2306e-01, -4.3468e-01, -5.0065e-01, -1.4340e+00,  7.3104e-02,\n",
      "        -3.3578e-01, -2.6920e-02, -3.8201e-01, -6.7178e-01,  2.2510e-01,\n",
      "        -7.8782e-01, -5.3569e-01, -5.9130e-01, -1.1207e+00, -1.7832e+00,\n",
      "         1.5890e+00,  3.0119e-01,  1.4833e-01,  8.8480e-01,  5.7742e-01,\n",
      "         8.8889e-01, -2.7374e+00, -1.0732e+00,  1.5689e-01,  3.8133e-01,\n",
      "        -3.8956e-01, -3.3295e-01, -1.5753e+00,  6.1971e-01,  2.3374e-03,\n",
      "        -1.4723e-01, -1.3836e+00, -2.1693e-02,  9.6076e-01,  1.2536e-01,\n",
      "         3.1655e-01,  1.4899e+00, -1.4895e-01, -4.9362e-01,  7.4626e-02,\n",
      "         1.5868e+00, -8.3070e-01, -1.5542e+00,  1.6685e-01, -1.2999e+00,\n",
      "         3.2755e-01, -1.7361e-01, -1.2264e-01,  1.7132e-01,  1.9056e-01,\n",
      "         4.9824e-02, -1.0157e-01,  6.1929e-01,  3.8519e-01, -1.1638e+00,\n",
      "         2.0039e+00,  3.4079e-01,  1.1538e-01, -2.2017e-01, -4.5633e-01,\n",
      "        -7.3729e-01, -1.3871e+00,  1.5201e+00, -1.5546e+00,  1.3013e+00,\n",
      "        -1.1971e-01,  1.7050e-01, -8.1271e-01,  1.0418e-01,  6.5895e-01,\n",
      "        -5.6570e-01, -1.2678e+00, -6.9701e-01, -9.3499e-01, -4.8662e-01,\n",
      "        -1.4903e+00, -4.2506e-01,  5.6004e-01, -1.6839e+00, -5.4860e-01,\n",
      "        -6.0154e-01, -1.8132e+00, -1.8948e+00, -7.3878e-01, -2.0381e+00,\n",
      "        -6.9574e-01,  4.0804e-01, -3.2426e+00,  3.0660e-01, -2.5143e-01,\n",
      "        -1.5803e-01, -2.9181e-01, -1.0631e-01, -9.2927e-01,  4.6425e-01,\n",
      "        -1.8744e+00,  1.1056e+00, -3.5046e-01, -4.7847e-01, -2.1321e+00,\n",
      "        -1.6434e+00, -7.3464e-01,  4.2135e-02,  9.2886e-01, -1.6074e-01,\n",
      "        -2.3498e+00, -5.7530e-02, -1.2039e+00, -2.1306e-01, -7.1093e-01,\n",
      "        -7.5353e-02,  3.0921e-02,  8.4607e-01,  6.7589e-02, -8.1210e-02,\n",
      "        -1.1850e-01,  4.0651e-01,  1.2690e+00, -1.1632e+00, -4.1098e-01,\n",
      "        -2.0156e+00, -1.4305e+00,  1.9505e-02, -4.0847e-01,  4.5789e-01,\n",
      "         2.8072e-01,  2.4861e-01, -4.8239e-01,  4.4861e-01, -6.5456e-01,\n",
      "        -1.1432e+00,  9.1108e-01,  5.7260e-02, -3.5164e-01, -4.8547e-01,\n",
      "         1.8374e+00,  9.6807e-02,  5.8594e-02,  1.4006e+00,  1.8420e-01,\n",
      "        -2.5670e-02, -1.9312e+00,  4.2166e-01, -3.9138e-01,  1.4360e+00,\n",
      "         8.7026e-01, -1.7517e+00, -1.6625e+00,  1.1079e+00,  1.1431e-01,\n",
      "        -6.9931e-01, -1.7799e-01,  1.4965e+00,  5.2485e-01,  2.5510e-01,\n",
      "        -3.8372e-04,  1.0573e+00, -1.6878e+00, -1.0794e+00, -5.6830e-02,\n",
      "        -2.8223e+00, -7.9853e-01, -8.6361e-01,  4.2465e-01, -8.2504e-01,\n",
      "         1.3307e-01,  1.0056e+00, -1.0003e+00, -3.2417e-02,  1.2921e-04,\n",
      "        -1.3724e+00,  8.9984e-01, -1.7026e+00, -3.0492e-01,  4.7508e-01,\n",
      "         1.4307e+00, -4.8265e-02,  4.6377e-02,  1.0198e-02,  8.0819e-03,\n",
      "        -6.5087e-01,  1.2862e+00,  3.6518e-01,  6.8924e-02,  2.0926e+00,\n",
      "         6.0820e-01,  1.3579e+00,  1.8830e-01,  1.5265e+00, -2.0380e-02,\n",
      "        -2.3263e+00, -5.2166e-01,  5.6565e-01,  1.5432e-01, -4.6250e-01,\n",
      "         1.1910e+00,  1.8360e+00, -2.7262e-02, -9.5160e-01, -1.4619e+00,\n",
      "        -1.5567e-01, -1.5560e+00, -3.9267e-01, -1.2971e+00,  1.9955e-01,\n",
      "         6.0993e-01,  1.1249e+00,  1.5172e-02,  6.1864e-03, -1.1402e+00,\n",
      "         5.8956e-02, -1.2292e-01,  4.3891e-01,  4.1505e-01, -5.8145e-01,\n",
      "        -1.1634e+00, -1.7347e-01,  9.2890e-01, -1.2276e+00, -8.2223e-01,\n",
      "        -9.1586e-01, -1.7385e+00,  5.7848e-01,  1.3036e-01, -2.0524e+00,\n",
      "         1.7850e+00,  4.9872e-02,  7.5252e-01,  1.1568e+00,  8.1545e-02,\n",
      "         1.3083e+00, -2.4871e+00, -5.7600e-02, -7.7744e-01, -1.1661e+00,\n",
      "        -1.8596e-01,  7.0559e-02, -1.0391e+00, -1.8765e-02,  3.2853e-01,\n",
      "        -5.1723e-01,  1.2171e+00, -1.7975e+00,  1.8577e-01,  1.4486e+00,\n",
      "         6.1609e-02, -1.6331e-02, -6.6213e-01,  9.7907e-01, -7.8022e-01,\n",
      "        -4.0866e-01,  4.1715e-01,  4.1953e-01,  5.7886e-01,  4.3961e-01,\n",
      "         7.5188e-01,  4.4935e-02,  7.9128e-02,  3.0464e-02, -3.2524e-01,\n",
      "        -3.9289e+00,  4.8083e-01, -2.4247e-01, -1.2165e+00,  2.8466e-02,\n",
      "        -1.3753e+00,  1.3345e-01,  6.1354e-01,  8.0982e-01, -2.9199e-01,\n",
      "        -2.5138e-01, -4.7684e-02, -1.5905e-01, -7.5209e-01,  5.5279e-01,\n",
      "         1.4283e+00,  8.1189e-01,  5.8614e-01, -2.2435e-01,  5.2215e-01,\n",
      "         6.3056e-01, -5.9614e-01, -2.9517e-03, -1.9971e-01,  3.3614e-01,\n",
      "        -1.4150e+00, -1.1134e+00, -9.1738e-01, -1.5504e-02,  2.0822e-01,\n",
      "        -3.2378e-01, -1.9477e+00, -9.0906e-01,  1.3791e-01, -6.0083e-01,\n",
      "        -1.2719e+00, -4.7184e-02, -1.7178e-01,  4.9301e-02,  4.4752e-01,\n",
      "        -1.4255e+00,  3.9872e-01, -1.4171e+00,  6.8644e-01, -3.0478e-01,\n",
      "         1.1812e+00,  4.9509e-02, -1.0033e+00,  2.0160e+00,  1.2649e+00,\n",
      "        -2.5287e-01,  1.6129e+00,  7.9048e-03, -9.0906e-01, -5.1018e-01,\n",
      "        -2.6886e-01, -2.1073e-01,  1.5331e+00,  1.3421e+00, -1.9190e+00,\n",
      "        -4.0842e-01,  2.8236e-01, -1.6577e-01, -2.1434e-01,  5.8675e-02,\n",
      "        -1.0118e+00, -1.5168e+00, -1.0052e+00,  3.3637e-01,  2.2190e-01,\n",
      "         9.2257e-01, -9.0055e-01, -1.9940e+00, -4.3251e-02, -4.7887e-01,\n",
      "        -1.2073e+00,  1.1436e-01, -4.4770e-01,  8.9730e-01, -1.8377e-01,\n",
      "        -4.3684e-01,  1.0842e+00,  1.1319e-01, -7.3626e-01, -8.1600e-01,\n",
      "         9.5444e-01, -9.3299e-01, -1.4903e-02,  3.5270e-01,  9.8869e-01,\n",
      "        -8.5685e-01,  7.1139e-01,  1.4268e+00, -1.1049e+00, -1.6742e+00,\n",
      "        -2.9482e-01, -1.7487e-01,  1.9012e-01, -1.4760e-01,  5.7391e-01,\n",
      "         1.8314e-01, -3.1438e-02,  3.1979e-02,  1.3654e-01,  2.7132e-02,\n",
      "        -1.2898e-01,  1.6248e-01,  6.7468e-01,  2.7819e-01, -1.4864e-03,\n",
      "        -4.2312e-01, -1.6215e-01, -1.4980e+00, -2.8032e-01, -6.7893e-02,\n",
      "        -1.6261e+00, -1.0111e-02,  1.4144e+00, -2.3715e+00,  6.4060e-01,\n",
      "        -1.0133e-01, -5.2883e-04,  8.3701e-01,  2.3740e+00,  6.0262e-01,\n",
      "        -5.8504e-01, -7.6977e-01, -1.4352e-01,  1.0128e-01,  1.7874e-01,\n",
      "         8.8905e-01, -1.7413e+00, -5.5214e-01, -3.6222e-01, -2.8524e+00,\n",
      "        -5.6352e-01,  6.8823e-02,  5.2242e-01,  1.5823e+00, -1.3184e-01,\n",
      "        -9.6493e-01, -3.8449e-01, -1.7631e+00,  5.3172e-01,  1.8909e-01,\n",
      "         1.2941e+00,  1.1556e+00,  2.5215e-02, -3.7162e-01, -1.6739e+00,\n",
      "         3.4111e-02,  3.8463e-01, -1.3846e-01, -1.1890e-01,  2.3383e-01,\n",
      "        -1.2363e+00, -2.5424e-01, -4.7837e-01, -1.4383e-01, -9.8174e-01,\n",
      "         3.8340e+00, -1.4242e+00, -5.5127e-02, -4.5815e-01,  1.3412e-01,\n",
      "         1.7508e+00, -3.9936e-01,  1.4331e+00, -1.6787e-02, -2.8107e+00,\n",
      "         1.5015e+00, -1.6701e+00, -2.7289e+00,  5.4403e-02,  1.0954e+00,\n",
      "         7.1567e-01, -1.2260e-02,  2.0624e-01, -6.1318e-01, -1.4112e-01,\n",
      "         4.1051e-01,  1.4982e-01, -1.6065e+00,  1.7722e-01,  3.7378e-01,\n",
      "         4.1266e-01, -1.5217e+00, -2.5057e+00, -7.6312e-01,  4.7353e-02,\n",
      "        -7.2570e-01, -3.5154e-02, -7.1315e-01, -1.5745e+00,  2.8725e-01,\n",
      "        -8.7512e-01, -2.3968e+00,  5.4032e-01, -3.0998e-02, -2.1674e+00,\n",
      "         3.7644e-01, -1.5729e-01, -1.4878e-01,  6.0481e-02, -1.5033e+00,\n",
      "        -5.2649e-01, -3.0834e-01,  6.2310e-02, -1.0046e+00, -1.8622e+00,\n",
      "        -1.0026e-02, -3.7489e-01, -3.4039e-01, -8.0841e-01, -3.0389e-01,\n",
      "        -5.1946e-02, -1.7148e-01, -3.8908e-01, -1.7557e-01, -1.5766e+00,\n",
      "         5.0198e-01,  2.9283e-01, -1.1888e-01,  6.9754e-01, -8.0193e-01,\n",
      "        -1.6027e-01,  1.7093e-02, -1.0062e-01, -6.5551e-02,  1.7041e-01,\n",
      "         5.5075e-01,  6.0509e-02,  3.4505e-01,  2.9322e-01, -1.2820e+00,\n",
      "        -1.7888e+00,  1.8001e+00, -7.3571e-01, -8.3423e-01,  3.3927e-01,\n",
      "        -1.6066e+00,  9.7031e-01, -7.4797e-03, -2.4217e-01, -8.7007e-04,\n",
      "         6.6364e-02,  1.7217e-01,  8.1815e-01,  1.0965e+00, -3.8596e-01,\n",
      "         1.6986e-03,  1.5342e+00, -2.0058e+00, -2.6070e-01,  1.0954e+00,\n",
      "         5.9612e-01,  1.5655e-01,  8.2572e-03,  6.3584e-01, -2.6966e-01,\n",
      "        -1.0648e+00,  4.9975e-01,  1.7489e-02,  3.5970e-01, -1.2510e+00,\n",
      "         4.2310e-01, -2.6975e-02,  7.8929e-01, -1.4820e-01, -1.4275e-01,\n",
      "        -2.3459e-02,  1.6375e-01,  6.6383e-02, -1.4135e-01,  4.9339e-01,\n",
      "        -2.6674e-02, -1.5303e-01,  2.1464e-01,  7.9684e-02, -1.5085e-01,\n",
      "        -6.1081e-02], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.3310,  0.1485,  0.7647,  0.4096,  0.6174],\n",
      "          [-0.2732,  0.2218,  0.2810,  0.2095,  0.0367],\n",
      "          [-0.2780, -0.1908, -0.0061, -0.2271, -0.0825],\n",
      "          [-0.2686, -0.1421, -0.5011, -0.5292, -0.3198],\n",
      "          [ 0.0143, -0.0633, -0.5963, -0.2627, -0.2283]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0369,  0.3937,  0.4930,  0.3416,  0.1035],\n",
      "          [ 0.0896,  0.4098,  0.5026,  0.2908,  0.0966],\n",
      "          [-0.0255,  0.2785,  1.2223,  0.0730, -0.0687],\n",
      "          [ 0.0519,  0.2203,  0.3023,  0.2251,  0.0108],\n",
      "          [-0.1803, -0.0214, -0.0114, -0.1500, -0.2178]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0899,  0.0116,  0.1032,  0.3322,  0.2234],\n",
      "          [ 0.1398,  0.2209,  0.1601,  0.4894,  0.4544],\n",
      "          [ 0.6857,  0.6421, -0.0787,  0.6367,  0.5822],\n",
      "          [ 0.0558,  0.0540, -0.1917,  0.0772,  0.2720],\n",
      "          [ 0.4012,  0.1613,  0.1672,  0.4262,  0.5425]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1016,  0.1313,  0.1799, -0.0171, -0.0225],\n",
      "          [ 0.0491,  0.1192, -0.3232, -0.2309, -0.1456],\n",
      "          [ 0.2092, -0.1287, -2.2248, -0.2254,  0.0635],\n",
      "          [-0.0410, -0.1252, -0.5855, -0.0885,  0.1286],\n",
      "          [-0.2647, -0.3393,  0.0268, -0.0184,  0.3163]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4365,  0.3820,  0.4800,  0.4257,  0.2717],\n",
      "          [ 0.3222,  0.3132,  0.4160,  0.3463,  0.2195],\n",
      "          [ 0.0858,  0.0942,  0.4457,  0.4568,  0.3382],\n",
      "          [ 0.1017,  0.0829,  0.2517,  0.3957,  0.1614],\n",
      "          [ 0.0817,  0.1886,  0.4850,  0.6455,  0.5882]]],\n",
      "\n",
      "\n",
      "        [[[-0.0509,  0.0266,  0.1676, -0.0577,  0.0871],\n",
      "          [-0.4291, -0.0160, -0.2161, -0.2505, -0.0514],\n",
      "          [-0.3364,  0.4595,  1.2613,  0.2237,  0.0514],\n",
      "          [-0.2800, -0.1154,  0.0481, -0.1908, -0.2709],\n",
      "          [-0.1758, -0.3029,  0.1102, -0.0868,  0.0154]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.3251,  0.8247,  1.5211,  1.2325,  1.2846,  1.4675,  1.2760,  0.9602,\n",
      "         0.9375,  1.2966,  1.2669,  1.1829,  1.9602,  1.6743,  1.1485,  1.4330,\n",
      "         0.8045,  1.0166,  0.8729,  0.8696,  1.0324,  2.8149,  1.6297,  0.9613,\n",
      "         1.8554,  1.8598,  2.0599,  0.7434,  1.8558,  3.0381,  1.0015,  2.1897,\n",
      "         1.9608,  2.3354,  0.8287,  1.5757,  1.0287,  0.9270,  1.0487,  0.7398,\n",
      "         0.9199,  0.6744,  1.6299,  1.2696,  2.1112,  1.7105,  1.4636,  0.9536,\n",
      "         0.1690,  0.7853,  1.8725,  1.5210,  1.0084,  0.7598,  1.7169,  1.3059,\n",
      "         1.7705,  0.8507,  1.5318,  1.2713,  1.0628,  1.4118,  1.9687,  1.4976,\n",
      "         0.9194,  1.8837,  2.1874,  2.0977,  2.2874,  1.1736,  0.8550,  1.4703,\n",
      "         1.3465,  1.8319,  1.0244,  1.7260,  0.9722,  4.2118,  1.3955,  1.1608,\n",
      "         0.9574,  0.4511,  2.0147,  0.8899,  1.7665,  2.3006,  1.6405,  1.5996,\n",
      "         0.6351,  0.6412,  1.9763,  1.6481,  1.3690,  1.2042,  1.4061,  0.6251,\n",
      "         0.8449,  1.6497,  1.3233,  0.9098,  1.6241,  2.1554,  0.9592,  0.9866,\n",
      "         0.7674,  1.0141,  0.5279,  0.9432,  0.8697,  1.7629,  0.6192,  1.1878,\n",
      "         0.7274,  2.3780,  0.9377,  0.9567,  0.6069,  0.9987,  0.7575,  1.4981,\n",
      "         1.2836,  1.1283,  2.1784,  1.7173,  0.9009,  0.9469,  2.2315,  0.7537,\n",
      "         1.0709,  1.9018,  0.9189,  0.9307,  0.7654,  0.9205,  0.6006,  0.7486,\n",
      "         1.2718,  1.3010,  1.8615,  1.0315,  0.9106,  0.6515,  0.8464,  0.6436,\n",
      "         1.2553,  0.9119,  0.6830,  2.0278,  1.0665,  0.4460,  0.6241,  0.6859,\n",
      "         0.5312,  0.5646,  1.4150,  1.0961,  0.7764,  1.7277,  1.1690,  1.0544,\n",
      "         0.5275,  2.0100, -0.0137,  1.1951,  0.6940,  0.5058,  1.1087,  1.1626,\n",
      "         0.9056,  0.7537,  1.6215,  0.9136,  1.3344,  1.3717,  2.2439,  0.6901,\n",
      "         0.5273,  0.8454,  0.7191,  2.8642,  1.7942,  0.9097,  2.7477,  1.5998,\n",
      "         1.3969,  0.9224,  0.7823,  0.9911,  2.4287,  1.1803,  1.7775,  1.6371,\n",
      "         1.1578,  1.0468,  0.9366,  0.8753,  0.9803,  0.9542,  1.0644,  0.6234,\n",
      "         0.8871,  0.9479,  0.9260,  1.0389,  0.9217,  1.8935,  1.4315,  0.7111,\n",
      "         1.6021,  1.0751,  1.3601,  1.0092,  0.6658,  1.4949,  0.6809,  0.9224,\n",
      "         0.8569,  1.5546,  1.9143,  1.5071,  2.1355,  1.4128,  1.1946,  1.4695,\n",
      "         1.3639,  0.6358,  0.9188,  1.2128,  1.5685,  0.6701,  1.5319,  1.1636,\n",
      "         0.6076,  0.6348,  0.3698,  1.4028,  2.0404,  0.8100,  1.3929,  1.9175,\n",
      "         1.7954,  1.3727,  1.1049,  0.9222,  1.5832,  1.2291,  0.8253,  1.5346,\n",
      "         0.5531,  0.7944,  0.8782,  0.7293,  1.3987,  0.9722,  0.9117,  1.8848,\n",
      "         0.5943,  1.1928,  0.9727,  1.0206,  2.0634,  1.0137,  0.8128,  0.5721,\n",
      "         1.2398,  0.9584, -0.0304,  0.7106,  0.9916,  0.8309,  0.8984,  0.9215,\n",
      "         0.6020,  2.0021,  2.2090,  1.0871,  0.8427,  0.9778,  0.6364,  0.9752,\n",
      "         2.2512,  0.6695,  1.0623,  0.8610,  0.8655,  1.1335,  1.2603,  0.8341,\n",
      "         1.0655,  1.3164,  0.7323,  0.8738,  0.6610,  1.9834,  1.6017,  2.4794,\n",
      "         1.3439,  1.2168,  0.4357,  0.8176,  0.4597,  0.8244,  1.9295,  1.2133,\n",
      "         0.3932,  0.6598,  1.4610,  0.9566,  0.8171,  0.8571,  0.9339,  1.1047,\n",
      "         0.7789,  0.6349,  0.8922,  1.6098,  1.0178,  0.6415,  1.0595,  0.9633,\n",
      "         1.5896,  0.6375,  0.8939,  1.0921,  1.2895,  0.8298,  0.7627,  0.5894,\n",
      "         0.9060,  1.1023,  0.4640,  1.5004,  1.6982,  1.3064,  1.1907,  1.7019,\n",
      "         0.8519,  1.4020,  1.0943,  1.2126,  0.8869,  1.0159,  0.7451,  2.0975,\n",
      "         0.9326,  1.5260,  2.4422,  1.1873,  2.6595,  1.0587,  1.6449,  2.0497,\n",
      "         1.4352,  0.8941,  0.9165,  1.0184,  1.0688,  1.6934,  1.5586,  0.5182,\n",
      "         0.9184,  0.7309,  1.5032,  2.5281,  1.5726,  1.4603,  0.7754,  1.0360,\n",
      "         0.7940,  0.9562,  0.6722,  0.8501,  1.0758,  1.4530,  0.9233,  0.8111,\n",
      "         1.4140,  0.6837,  0.3853,  0.5721,  1.2063,  1.1757,  1.4547,  1.1173,\n",
      "         1.4829,  0.6437,  0.9988,  0.3031,  0.2626,  0.4666,  0.8298,  1.4195,\n",
      "         0.8546,  0.9116,  1.7286,  0.7128,  1.7068,  1.4369,  0.7451,  0.5885,\n",
      "         1.3434,  2.0565,  0.8391,  1.6707,  1.8765,  1.1066,  1.2741,  0.9575,\n",
      "         1.4736,  1.5892,  0.9149, -0.5651,  1.5695,  0.7947,  1.0025,  0.6141,\n",
      "         2.0410,  0.9544,  1.2527,  1.0596,  0.9273,  0.6880,  2.0434,  0.9254,\n",
      "         1.9064,  1.2558,  0.9860,  0.9839,  3.4040,  1.9705,  0.7066,  1.0441,\n",
      "         0.9451,  0.8552,  1.0359,  0.9905,  0.7167,  2.5717,  1.7163,  1.4640,\n",
      "         1.6157,  2.9149,  1.5191,  1.2544,  1.8607,  1.1768,  0.9445,  1.0456,\n",
      "         0.9749,  0.9951,  0.7071,  0.5053,  1.7238,  1.3953,  0.6459,  1.7829,\n",
      "         1.1612,  1.5071,  0.5614,  1.0721,  0.9545,  1.1899,  1.0958,  1.1022,\n",
      "         1.1407,  1.9677,  1.2227,  2.3423,  1.6743,  1.1765,  1.3015,  1.1346,\n",
      "         1.0945,  0.9452,  1.1263,  1.0362,  0.8683,  0.8688,  0.7205,  1.4532,\n",
      "         1.6646,  1.3214,  2.5246,  0.7096,  0.7836,  1.8175,  0.8187,  0.9327,\n",
      "         1.7084,  0.9152,  0.5868,  1.0616,  1.1400,  1.0957,  1.4266,  1.3378,\n",
      "         2.1073,  1.6816,  1.5990,  1.6026,  0.9393,  0.8802,  1.4035,  0.9379,\n",
      "         0.7159,  1.9346,  0.9549,  1.1830,  1.4711,  0.8997,  0.7527,  1.7016,\n",
      "         1.2371,  1.2779,  0.5502,  0.9407,  1.5785,  2.0797,  1.3018,  0.6562,\n",
      "         1.0988,  0.8217,  1.2215,  1.3804,  1.0527,  1.0629,  1.9079,  1.4069,\n",
      "         1.4862,  0.9130,  0.9944,  1.7512,  0.9430,  0.8711,  1.2703,  0.9213,\n",
      "         1.7497,  1.9146,  0.9089,  0.7603,  1.4527,  1.0906,  1.4780,  1.6605,\n",
      "         0.9945,  1.3138,  1.5774,  1.7384,  1.0724,  2.4292,  0.8080,  0.9863,\n",
      "         0.9492,  1.2790,  0.9637,  1.1864,  1.2771,  1.3806,  1.1631,  1.1335,\n",
      "         0.9869,  0.7974,  1.2956, -0.0099,  1.0394,  1.7617,  1.4674,  2.4829,\n",
      "         1.0034,  1.0754,  1.1444,  1.2929,  1.1132,  1.6477,  1.5510,  1.3437],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.2541, -0.5640, -1.3571, -0.3389,  0.0298, -1.0042, -0.8232, -0.0947,\n",
      "        -0.0408, -0.6351, -0.6333, -0.1871, -1.3319, -1.0503, -0.1610, -0.5089,\n",
      "         0.1502, -0.3250, -0.3524, -0.0508,  0.4730,  0.0343, -0.9260, -0.3561,\n",
      "        -1.1474, -1.5499, -1.1937, -0.2879, -1.2628, -1.0853, -0.2385, -1.3654,\n",
      "        -1.7329, -1.2312, -0.0520, -0.6541, -0.2378, -0.1471, -0.2533,  0.0142,\n",
      "        -0.2317, -0.3137, -0.6012, -0.2210, -1.1061, -0.5348, -0.6149, -0.1460,\n",
      "         0.0129, -0.1025, -1.3949, -2.0728,  0.1675, -0.2367, -1.8648, -0.3795,\n",
      "        -1.1320, -0.4884, -0.9129, -1.5977, -0.0446,  0.0515, -0.2979, -2.0315,\n",
      "        -0.2887, -1.2402, -0.7275, -0.5028, -1.2247, -0.1064,  0.0645,  0.0389,\n",
      "         0.2775, -1.7014, -0.5999, -1.9472, -0.2040, -0.9790, -1.1498, -0.4982,\n",
      "        -0.2336, -0.3468, -1.4546, -0.2987, -1.3820, -1.0449, -0.8202,  0.0753,\n",
      "        -0.1396, -0.1638, -1.5960, -1.0584, -1.3002,  0.0636, -0.5384, -0.3394,\n",
      "        -0.2564, -1.7922, -1.1292, -0.0821, -1.3665, -1.2236,  0.1667, -0.4433,\n",
      "        -0.2914, -0.2531, -0.1341, -0.2285, -0.2854, -0.7423, -0.0728, -0.2890,\n",
      "        -0.2614, -0.0146, -0.9682,  0.0194, -0.1694,  0.2265, -0.2337,  0.1595,\n",
      "         0.3593, -0.5331, -1.2191, -1.1620, -0.1947, -0.9712, -1.8081,  0.0180,\n",
      "        -0.3951, -2.1188, -0.0066, -0.1481, -0.0380, -0.1386, -0.0483, -0.2241,\n",
      "        -1.8664, -0.5821, -0.8585,  0.7420, -0.4596, -0.1502, -0.2118, -0.1640,\n",
      "        -0.2363, -0.3908, -0.1837, -0.9035,  0.5467, -0.0268, -0.1276, -0.1038,\n",
      "        -0.1079, -0.1112, -0.1312,  0.1933, -0.2930, -1.4270, -0.3433, -0.1556,\n",
      "         0.0325, -1.1282,  0.0100, -0.4382, -0.1794, -0.0777, -0.5974, -0.9476,\n",
      "        -0.1527, -0.1159, -0.2299, -0.0578, -1.4952, -0.0989, -1.0543, -0.4500,\n",
      "        -0.1535,  0.0583, -0.4108, -2.4587, -1.3685, -0.0431, -1.0224, -1.1569,\n",
      "        -1.9179,  0.1213, -0.2327, -0.4369, -0.9029, -0.0752, -1.2644, -1.3955,\n",
      "         0.0419, -0.7865, -0.1431, -0.1478, -0.1748, -0.0102, -0.1169, -0.2739,\n",
      "         0.0710, -0.1478,  0.3092,  0.3083, -0.2402, -0.1256, -0.5573,  0.2354,\n",
      "        -1.0698,  0.3388, -0.1136,  0.2239, -0.1386, -1.8730,  0.0115, -0.4360,\n",
      "        -0.2823, -0.3191, -0.9762, -1.9108, -1.2786, -1.2974, -0.1155, -2.1411,\n",
      "         0.3679, -0.0829, -0.4363, -0.1075, -1.5464, -0.1625, -1.4899,  0.1731,\n",
      "        -0.2023, -0.3048, -0.0307, -1.5688, -0.4981, -0.3402, -0.3136, -0.8498,\n",
      "        -1.5956, -1.2233, -0.1494, -0.2749, -0.3190, -0.6853, -0.2474, -2.3823,\n",
      "        -0.2714, -0.3106, -0.7318, -0.1952,  0.3085, -0.5440, -0.5669, -0.5537,\n",
      "         0.0818, -0.3056, -0.5059, -0.1184, -2.4941, -0.2121,  0.1121, -0.2494,\n",
      "         0.0153, -0.3362,  0.0576, -0.1794, -0.4675, -0.3163, -0.2837, -0.1977,\n",
      "        -0.0447, -1.1687, -0.9320, -0.5742, -0.1835, -0.2253, -0.1757, -0.4833,\n",
      "        -1.2374, -0.0855, -0.4450, -0.1079, -0.4416, -0.3311, -0.1208, -0.2537,\n",
      "        -0.0056, -1.5780, -0.1702,  0.1849, -0.1915, -1.9562, -2.2389, -2.7699,\n",
      "         0.1908, -0.4077,  0.0037, -0.3134, -0.1472, -0.3222, -1.3690, -0.1130,\n",
      "        -0.0326, -0.2403, -1.4909, -0.2912, -0.1496, -0.0254, -0.0214,  0.0143,\n",
      "        -0.2579, -0.2017,  0.0070, -1.3706, -0.1516, -0.1175, -0.4899, -0.2349,\n",
      "        -0.1222, -0.1988, -0.2031,  0.0477, -1.5447,  0.4234, -0.1707, -0.2252,\n",
      "         0.0746, -0.2134, -0.0899, -0.8632, -0.6575, -2.1410, -0.0942, -0.2539,\n",
      "        -0.2677, -0.0315, -0.0908, -0.5877, -0.1873, -0.2683, -0.0285, -1.1333,\n",
      "        -0.2734, -1.4048, -2.2449, -0.3950, -1.2733,  0.0421, -0.5576, -2.4166,\n",
      "        -2.0746, -0.3344,  0.1918, -0.0446,  0.0963, -1.1450, -1.3544, -0.0563,\n",
      "        -0.5123, -0.0777, -0.1697, -1.4220, -1.6589, -0.6654, -0.5598, -0.2008,\n",
      "        -0.3633, -0.2823, -0.1366, -0.1206, -0.2147,  0.3085, -0.2448, -0.1734,\n",
      "         0.2210, -0.1457, -0.0889, -0.2795, -0.7902, -0.3249, -1.3279, -0.2047,\n",
      "        -1.2097, -0.0941, -0.0782, -0.1199,  0.0046, -0.2363, -0.5128, -0.8194,\n",
      "        -0.4007, -0.1139, -2.1424, -0.1346, -1.2133, -1.3517, -0.2527, -0.2602,\n",
      "        -0.4512, -1.3525, -0.4438, -1.1329, -1.0585, -0.4325, -0.3907, -0.3910,\n",
      "        -1.0901, -1.3450, -0.1702, -0.0252, -0.2790,  0.3048, -0.1639, -0.1501,\n",
      "        -1.4560, -0.3084, -0.0991, -0.0880, -0.2073, -0.2137, -1.6010, -0.3600,\n",
      "        -1.3577, -0.7236, -0.1055, -0.4042, -3.5038, -0.6136, -0.2256, -0.4901,\n",
      "        -0.4109, -0.1032, -0.5176,  0.1937,  0.0975, -0.2452, -1.4584, -1.6735,\n",
      "        -0.8215, -1.9689, -0.9100, -1.9589, -0.4629, -0.4791, -0.1885, -0.7044,\n",
      "        -0.4198, -0.3845, -0.1638, -0.0359, -0.7262,  0.2064, -0.1111, -1.1134,\n",
      "        -0.3170, -0.6985, -0.0574, -0.4539, -0.1102, -0.4045,  0.3890, -0.4207,\n",
      "        -0.2706, -1.0383, -0.4319, -0.7301, -1.4546, -0.1264, -0.4660, -0.1002,\n",
      "        -0.2647, -0.0404, -0.2960,  0.1109, -0.3458, -0.1674,  0.3006, -0.1548,\n",
      "        -1.4765,  0.1914, -2.9886, -0.0084, -0.2895, -0.6082, -0.2038, -0.1776,\n",
      "        -0.0220, -0.2852, -0.0865,  0.0543,  0.5066, -0.3145, -0.3103, -0.8309,\n",
      "        -1.0559, -1.4994, -1.3325, -0.5568, -0.2949, -0.1829, -0.5337, -0.2141,\n",
      "        -0.2115, -1.3775,  0.3279,  0.1769, -0.6017, -0.2070, -0.4743, -0.5309,\n",
      "        -0.4676, -0.7744,  0.1752, -0.1356, -0.9539, -1.3691,  0.2321, -0.1238,\n",
      "        -0.3449, -0.1271, -0.5784, -0.1155, -0.1892, -0.4223, -0.8876, -0.1726,\n",
      "        -1.2139, -0.2466, -0.3903, -1.6838, -0.0058,  0.0071, -0.5147, -0.0257,\n",
      "        -1.3791, -0.8831, -0.2669,  0.0531, -0.6023, -0.3979, -2.1670, -1.9956,\n",
      "        -0.0567, -0.0325, -1.3344,  0.1405, -0.3146, -1.7736, -0.2792, -0.0266,\n",
      "        -0.6087, -1.3387, -0.2192, -0.3708, -1.0894,  0.3905, -0.7604,  0.0947,\n",
      "        -0.3579, -0.1336, -0.1874,  0.0166, -0.1009, -0.8919, -0.7052, -1.0584,\n",
      "        -0.2975,  0.0932, -0.4931, -1.1956, -0.4559,  0.4802, -1.0905, -0.4267],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.4171]],\n",
      "\n",
      "         [[-0.1254]],\n",
      "\n",
      "         [[-0.5507]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1232]],\n",
      "\n",
      "         [[ 0.2768]],\n",
      "\n",
      "         [[-0.0923]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1833]],\n",
      "\n",
      "         [[-0.0106]],\n",
      "\n",
      "         [[-0.3146]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2486]],\n",
      "\n",
      "         [[-0.0203]],\n",
      "\n",
      "         [[ 0.2167]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0580]],\n",
      "\n",
      "         [[ 0.0558]],\n",
      "\n",
      "         [[-0.1251]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3781]],\n",
      "\n",
      "         [[-0.3665]],\n",
      "\n",
      "         [[-0.0735]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1879]],\n",
      "\n",
      "         [[-0.3723]],\n",
      "\n",
      "         [[ 0.0906]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0910]],\n",
      "\n",
      "         [[ 0.1511]],\n",
      "\n",
      "         [[-0.0489]]],\n",
      "\n",
      "\n",
      "        [[[-0.3260]],\n",
      "\n",
      "         [[-0.2549]],\n",
      "\n",
      "         [[ 0.0591]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1587]],\n",
      "\n",
      "         [[ 0.3646]],\n",
      "\n",
      "         [[ 0.6330]]],\n",
      "\n",
      "\n",
      "        [[[-2.0859]],\n",
      "\n",
      "         [[-0.1995]],\n",
      "\n",
      "         [[ 0.1697]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3847]],\n",
      "\n",
      "         [[-0.4163]],\n",
      "\n",
      "         [[-1.6906]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1212, -0.1762,  0.1441, -0.0538, -0.2180, -0.1656,  0.1546,  0.1435,\n",
      "         0.1099,  0.1562,  0.0099,  0.0056, -0.0982,  0.1732, -0.4030,  0.0307,\n",
      "         0.0853,  0.2440,  0.0762, -0.2482, -0.2146,  0.2883,  0.0066, -0.0835],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.3213]],\n",
      "\n",
      "         [[-0.0328]],\n",
      "\n",
      "         [[ 0.1552]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4594]],\n",
      "\n",
      "         [[-0.1272]],\n",
      "\n",
      "         [[-0.0289]]],\n",
      "\n",
      "\n",
      "        [[[-0.4406]],\n",
      "\n",
      "         [[ 0.2119]],\n",
      "\n",
      "         [[-0.6150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0600]],\n",
      "\n",
      "         [[-0.0188]],\n",
      "\n",
      "         [[-0.2234]]],\n",
      "\n",
      "\n",
      "        [[[-0.0376]],\n",
      "\n",
      "         [[ 0.6262]],\n",
      "\n",
      "         [[ 0.4565]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0616]],\n",
      "\n",
      "         [[ 0.4694]],\n",
      "\n",
      "         [[-0.4517]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1806]],\n",
      "\n",
      "         [[-0.3280]],\n",
      "\n",
      "         [[ 0.4588]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5250]],\n",
      "\n",
      "         [[ 0.0983]],\n",
      "\n",
      "         [[-0.8646]]],\n",
      "\n",
      "\n",
      "        [[[-0.7285]],\n",
      "\n",
      "         [[-0.0451]],\n",
      "\n",
      "         [[ 0.0100]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4724]],\n",
      "\n",
      "         [[-0.1429]],\n",
      "\n",
      "         [[ 0.2186]]],\n",
      "\n",
      "\n",
      "        [[[-0.1213]],\n",
      "\n",
      "         [[-0.0301]],\n",
      "\n",
      "         [[ 0.5323]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0937]],\n",
      "\n",
      "         [[-0.7290]],\n",
      "\n",
      "         [[ 0.2218]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-2.7708e-02, -7.0783e-01,  3.0059e-01,  1.2424e-01, -1.9639e-01,\n",
      "         3.8262e-02,  1.5563e-01,  5.1154e-01,  8.8226e-01,  7.7716e-02,\n",
      "        -1.4135e-01,  7.0979e-01,  2.7956e-01, -3.8584e-03,  4.2458e-01,\n",
      "         3.5584e-01,  6.8483e-01,  5.5640e-01, -3.9041e-01,  1.9432e-01,\n",
      "         6.9659e-01, -4.5332e-01,  5.2460e-01,  4.1454e-01,  5.0863e-02,\n",
      "         2.7772e-02,  6.1521e-01, -2.9810e-01,  2.1849e-01, -4.6136e-01,\n",
      "         3.0927e-01,  3.8680e-03,  2.7159e-01,  2.8567e-01,  5.8231e-01,\n",
      "         6.0398e-02,  1.1512e-01,  3.2020e-01, -3.8795e-02, -7.3236e-03,\n",
      "         4.0243e-01,  2.8678e-01,  9.1157e-01,  3.7698e-01, -1.2847e-02,\n",
      "         1.6983e-01,  3.6472e-01,  6.2654e-01, -7.4531e-01,  3.0718e-01,\n",
      "         4.3359e-01,  5.5302e-01,  2.8268e-01,  6.1074e-01,  6.9665e-01,\n",
      "         2.9436e-01, -5.1831e-01,  1.8409e-01,  7.0903e-03, -1.8721e-01,\n",
      "         3.4721e-01,  6.5899e-01,  9.5164e-02,  8.1215e-02,  2.6485e-01,\n",
      "         6.0896e-01, -4.9044e-01,  4.5771e-01,  4.9216e-01,  6.1181e-01,\n",
      "         5.3587e-01,  1.2935e-01,  3.5145e-01, -2.9140e-01,  5.0333e-01,\n",
      "        -1.2349e-02,  6.8513e-01, -6.0862e-01,  6.1449e-01,  8.2940e-02,\n",
      "         6.0843e-02, -1.0127e-01,  4.2858e-01,  2.8240e-01, -5.2604e-03,\n",
      "         2.3202e-01,  3.7781e-01,  3.0664e-01, -5.8517e-02,  1.7319e-02,\n",
      "         4.5633e-01,  2.1447e-01, -9.7162e-02,  5.0366e-01,  4.0535e-01,\n",
      "         2.1485e-01,  2.0802e-01,  4.4553e-01,  3.2897e-03,  4.4826e-01,\n",
      "         2.5538e-01,  5.1834e-01,  3.6304e-01,  1.0865e-01,  1.7261e-01,\n",
      "         3.1443e-01,  2.0865e-01,  1.0671e-01,  6.2868e-01,  4.6782e-01,\n",
      "         3.6758e-01,  6.2606e-01,  2.7413e-01, -4.8298e-01,  1.3057e-01,\n",
      "         5.2683e-01,  1.9144e-01, -4.4095e-01,  2.6466e-02, -3.1464e-01,\n",
      "         4.0117e-01,  8.6276e-03, -1.9671e-01,  4.7828e-01,  5.1982e-01,\n",
      "        -2.0309e-01, -2.5267e-03,  4.4254e-01,  1.9932e-01, -4.4285e-01,\n",
      "        -3.1880e-02,  4.3659e-01,  2.3619e-01,  3.5098e-01,  2.3067e-01,\n",
      "         1.2571e-01,  3.0823e-01,  2.8080e-01,  3.6338e-01,  7.8237e-01,\n",
      "         2.7027e-01,  5.8791e-01,  2.5453e-01,  7.1563e-02,  1.1679e-01,\n",
      "         3.2981e-01,  3.4808e-01,  3.5925e-01,  6.1669e-01, -4.3487e-02,\n",
      "         4.4333e-01,  7.6127e-01,  1.0607e-01, -7.2279e-02,  2.0833e-01,\n",
      "         5.4381e-01,  3.0653e-01,  2.3729e-01,  6.7053e-02, -4.1319e-02,\n",
      "         3.3767e-01, -2.1619e-01, -6.7193e-01,  3.7197e-01,  1.0320e+00,\n",
      "        -2.2916e-01, -1.4639e-01, -2.7073e-02, -6.7788e-02, -7.8038e-02,\n",
      "         2.3575e-01,  4.4364e-01,  2.3764e-01,  6.7028e-01,  4.3373e-01,\n",
      "         9.5098e-02,  2.0286e-01,  1.3232e-01, -1.2150e-01,  1.8907e-01,\n",
      "         2.3777e-01, -6.2926e-03, -6.0211e-01, -4.8577e-02,  6.0185e-02,\n",
      "         8.2275e-02, -1.1926e-02,  2.5352e-01,  2.5915e-01,  4.2602e-01,\n",
      "         9.3144e-02,  1.4162e-01,  1.2354e-01,  7.6493e-03,  2.4213e-01,\n",
      "        -1.2709e-01,  4.9959e-02, -6.7649e-02,  6.6832e-01,  2.5276e-01,\n",
      "         4.7053e-01,  6.9479e-01,  1.9769e-01,  3.5357e-01,  7.1197e-01,\n",
      "         1.8669e-01,  5.9850e-01,  3.1020e-01, -1.8594e-01,  7.4576e-01,\n",
      "         2.5834e-01,  1.0943e+00, -1.0931e-01,  2.2632e-01,  7.6333e-01,\n",
      "         8.1329e-01, -1.3430e-01,  1.3702e-01, -7.3973e-02,  8.3350e-02,\n",
      "         8.3504e-03,  2.3780e-01,  2.8634e-01,  3.5514e-01,  3.7885e-01,\n",
      "         2.7390e-01,  3.3361e-01,  6.0712e-01, -1.2551e-01, -8.7314e-02,\n",
      "         2.8823e-01,  2.2747e-01,  8.9285e-01, -6.1955e-02,  4.6074e-02,\n",
      "         1.8712e-01, -7.9038e-01,  1.6807e-01,  3.9939e-01,  6.8725e-01,\n",
      "         2.9763e-01,  1.0667e-02,  5.1986e-01,  1.0048e+00,  7.4353e-01,\n",
      "        -1.5064e-01,  4.2990e-01,  8.0126e-02,  5.5724e-01, -1.5747e-01,\n",
      "         5.7381e-02,  9.3412e-01,  9.8525e-01,  2.9085e-01,  3.8775e-02,\n",
      "         7.1355e-01, -2.7534e-02,  4.4563e-01,  3.7407e-01, -2.8240e-01,\n",
      "         2.6771e-01,  4.4365e-01,  4.2334e-01,  2.6965e-01,  4.0384e-01,\n",
      "         3.5856e-01, -3.5608e-01,  3.5971e-01,  2.3285e-01,  2.2906e-01,\n",
      "         5.5996e-01,  3.2509e-01, -1.7563e-01,  1.8495e-01,  1.2313e-01,\n",
      "         4.5331e-02,  5.2385e-01,  2.7324e-01, -7.8560e-02,  1.5843e-01,\n",
      "         6.6020e-02,  3.3189e-01,  4.2869e-01,  6.4672e-01,  4.7425e-02,\n",
      "         4.5264e-01,  3.6270e-01,  3.6330e-01,  4.1989e-01,  3.3016e-02,\n",
      "         6.7266e-01,  4.9089e-01,  3.9554e-02,  1.4769e-01,  4.8880e-01,\n",
      "        -3.6341e-01,  2.9053e-01,  6.1234e-01, -1.8807e-01,  7.2875e-01,\n",
      "        -3.7987e-02,  2.7882e-01,  7.3443e-02,  9.1671e-01,  1.0822e-01,\n",
      "         2.8862e-02,  4.5296e-02, -4.1484e-02,  4.8171e-01,  5.7389e-02,\n",
      "         2.8694e-01,  3.5909e-01,  2.4685e-01,  3.4000e-01,  2.6673e-01,\n",
      "        -7.9052e-02,  2.2930e-01,  3.4596e-01,  4.9119e-01, -4.9139e-01,\n",
      "         2.0235e-01,  6.8601e-02,  5.8566e-01,  1.5533e-01, -3.3588e-02,\n",
      "         4.7207e-01, -1.7846e-01, -2.6952e-01,  3.5267e-01,  2.8744e-01,\n",
      "         2.9081e-01,  2.1113e-01,  2.2775e-01, -8.4830e-02,  6.5279e-02,\n",
      "        -2.1768e-01,  4.1931e-01, -5.1931e-02,  3.8351e-01,  9.9846e-02,\n",
      "         2.7604e-01,  2.3249e-01,  4.2815e-01,  7.4750e-01,  4.2108e-01,\n",
      "         7.6520e-02, -1.7465e-02,  3.5448e-02, -2.8388e-01,  3.8880e-01,\n",
      "         2.7104e-01,  1.4905e-01,  3.6476e-01,  1.3209e+00, -1.3212e-01,\n",
      "         2.8674e-01,  3.4023e-03,  7.2638e-02,  3.0014e-01, -1.8109e-02,\n",
      "        -1.7365e-01,  2.7149e-01,  2.6074e-01,  6.3463e-02,  2.1132e-01,\n",
      "         1.4922e-01,  2.0889e-02,  2.9152e-01,  4.8162e-01,  1.4680e-01,\n",
      "         3.7175e-01,  4.8297e-01,  1.6032e-01,  1.0817e+00,  3.8648e-01,\n",
      "         1.0185e-01,  8.4106e-01, -2.5343e-01, -1.6608e-01,  1.8928e-01,\n",
      "        -2.2365e-01,  3.9350e-01,  1.6569e-01,  1.4607e-01,  2.1365e-01,\n",
      "        -7.4034e-02,  5.6507e-01, -2.0652e-01,  1.6602e-01,  3.3604e-01,\n",
      "         3.5669e-01, -4.3244e-02,  1.7941e-01,  5.9847e-01,  4.0033e-01,\n",
      "         4.8666e-01,  6.5121e-02,  2.5228e-01,  4.9015e-02, -1.8271e-01,\n",
      "         2.5441e-01,  6.2989e-01, -2.4492e-02, -6.8339e-02,  4.9300e-01,\n",
      "         7.2169e-01,  3.0504e-01, -7.6884e-01,  4.3463e-01,  2.7511e-01,\n",
      "        -7.6358e-02,  2.9972e-02,  6.8612e-01,  8.5613e-01,  4.2114e-01,\n",
      "         4.3163e-01,  5.0601e-01,  6.5542e-01,  3.2357e-01,  3.7339e-01,\n",
      "         1.1468e-01,  4.8531e-02, -1.8627e-02,  3.5704e-01, -5.7857e-02,\n",
      "         4.1897e-01, -9.6278e-02,  1.5194e-01, -2.7834e-02, -1.8552e-01,\n",
      "         1.0212e-01,  2.7448e-01,  4.8630e-01,  4.4737e-01,  1.4457e-01,\n",
      "         5.2283e-01,  3.7123e-01, -4.6453e-01,  1.1550e-01,  2.9010e-01,\n",
      "         3.4630e-01, -6.5042e-02,  2.3491e-01,  7.3630e-02, -2.6612e-01,\n",
      "         3.7233e-01,  3.5627e-01,  2.1143e-01,  5.0240e-01,  2.3763e-01,\n",
      "         1.3071e-01, -7.3138e-04,  2.0340e-01,  6.5879e-01,  4.7604e-01,\n",
      "         3.8799e-02,  1.2025e-01,  4.5356e-01,  2.9164e-01,  1.9863e-01,\n",
      "         2.7134e-01,  7.2233e-02,  1.9435e-01, -5.1829e-03, -2.0800e-01,\n",
      "         4.7677e-01, -2.7882e-01,  1.8557e-01,  4.1106e-02,  7.8388e-02,\n",
      "         6.3440e-01,  8.6664e-01,  3.2075e-01,  6.5539e-01,  5.0477e-01,\n",
      "         2.8749e-01,  3.5885e-01,  3.0469e-01,  6.3305e-01,  3.6206e-01,\n",
      "         2.7924e-01, -2.6440e-02, -2.3277e-01,  8.5892e-01,  7.8477e-02,\n",
      "         1.4633e-01,  3.3563e-01,  3.1426e-01,  1.4392e-01,  6.6932e-01,\n",
      "         2.9696e-01,  2.1336e-01,  3.8657e-01,  8.3915e-01, -3.9112e-01,\n",
      "        -1.3595e-01,  5.0797e-01,  1.9713e-01,  2.6233e-01,  2.9424e-01,\n",
      "         6.9295e-01, -7.0673e-02,  5.7609e-01,  1.7779e-01,  1.6783e-01,\n",
      "        -9.1215e-03,  5.9074e-01,  4.2144e-01, -3.0833e-01,  1.6793e-01,\n",
      "        -1.5675e-01,  9.3418e-01,  1.0606e-01,  1.1625e-01,  2.5068e-01,\n",
      "         1.6867e-01, -1.3095e-01,  4.3771e-01,  2.7976e-01, -1.5516e-01,\n",
      "         9.4069e-01, -8.7428e-02, -6.6610e-02,  3.6723e-01,  1.6625e-01,\n",
      "         7.2656e-02,  1.7039e-01,  5.4504e-01,  2.1998e-01,  5.1914e-01,\n",
      "        -5.3977e-02,  2.8237e-01,  5.9457e-01,  1.5980e-01,  1.0818e-01,\n",
      "        -1.2313e-01,  3.2623e-01,  3.3959e-01,  2.6589e-01,  3.9589e-01,\n",
      "         3.4093e-01,  7.1527e-01,  5.0214e-01,  3.7194e-01,  2.1510e-01,\n",
      "         7.0272e-01, -5.1418e-02, -2.5449e-01,  6.1936e-01,  1.6766e-01,\n",
      "         4.0716e-02,  3.3981e-01,  5.0928e-02,  4.6412e-02,  4.6636e-01,\n",
      "         6.9412e-01, -4.8651e-02,  6.1088e-01, -4.1727e-01,  6.7565e-02,\n",
      "         1.9938e-01,  3.8606e-01,  5.1484e-01, -3.5726e-01,  1.0276e+00,\n",
      "        -2.4834e-01,  4.8490e-01,  3.6159e-01,  5.1456e-01,  7.1933e-01,\n",
      "         2.5367e-01, -3.3912e-01,  1.3718e-01, -1.9065e-01, -4.3848e-01,\n",
      "        -4.5031e-02], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2010]],\n",
      "\n",
      "         [[ 0.3707]],\n",
      "\n",
      "         [[-0.5837]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3856]],\n",
      "\n",
      "         [[-0.3603]],\n",
      "\n",
      "         [[-0.1812]]],\n",
      "\n",
      "\n",
      "        [[[-0.0757]],\n",
      "\n",
      "         [[-0.2031]],\n",
      "\n",
      "         [[ 0.1473]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0655]],\n",
      "\n",
      "         [[ 0.2849]],\n",
      "\n",
      "         [[-0.1340]]],\n",
      "\n",
      "\n",
      "        [[[-0.4031]],\n",
      "\n",
      "         [[-0.2372]],\n",
      "\n",
      "         [[-0.0985]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1145]],\n",
      "\n",
      "         [[-0.2293]],\n",
      "\n",
      "         [[-0.3787]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2940]],\n",
      "\n",
      "         [[-0.1960]],\n",
      "\n",
      "         [[-0.1870]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0306]],\n",
      "\n",
      "         [[-0.0867]],\n",
      "\n",
      "         [[-0.4167]]],\n",
      "\n",
      "\n",
      "        [[[-0.1985]],\n",
      "\n",
      "         [[ 0.5421]],\n",
      "\n",
      "         [[-0.5117]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3669]],\n",
      "\n",
      "         [[-0.0548]],\n",
      "\n",
      "         [[ 0.2840]]],\n",
      "\n",
      "\n",
      "        [[[-0.3424]],\n",
      "\n",
      "         [[-0.0802]],\n",
      "\n",
      "         [[-0.9134]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2441]],\n",
      "\n",
      "         [[ 0.4124]],\n",
      "\n",
      "         [[-0.0623]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([4.5616, 5.6523, 5.3773, 4.4226, 5.5093, 7.9647, 4.2155, 5.5176, 3.7097,\n",
      "        4.6604, 7.0313, 5.4195, 4.6905, 5.9320, 4.2538, 4.3590, 8.4805, 4.3354,\n",
      "        4.8157, 5.3595, 4.4597, 4.3507, 4.6766, 4.1843, 4.5297, 4.9866, 5.8841,\n",
      "        7.3257, 7.0708, 7.8455, 5.3269, 6.9409, 4.6113, 5.0161, 3.6934, 6.9688,\n",
      "        5.5610, 5.2208, 5.1559, 5.6877, 3.9819, 4.3252, 6.4565, 5.7599, 4.7881,\n",
      "        4.1155, 4.1214, 4.1553, 5.2172, 3.5662, 6.7074, 4.3801, 4.7058, 6.0324,\n",
      "        5.2478, 6.0304, 4.5550, 6.3094, 4.6199, 4.9137, 3.5187, 7.7648, 5.9150,\n",
      "        3.8570, 8.8791, 5.8316, 6.3268, 4.5329, 4.5968, 6.8103, 4.0565, 5.4177,\n",
      "        4.1389, 5.5451, 3.4609, 6.0929, 3.8547, 4.0360, 4.2310, 5.8441, 5.5221,\n",
      "        6.9052, 4.3969, 6.0646, 4.6280, 6.3051, 5.0454, 5.3384, 3.9466, 6.6751,\n",
      "        4.3379, 4.9574, 4.3273, 4.8291, 6.5181, 3.1842, 6.5038, 5.7643, 4.4820,\n",
      "        5.8083, 3.4654, 8.5184, 7.0489, 4.8953, 4.1805, 5.2488, 3.5301, 3.9114,\n",
      "        5.5982, 6.0139, 3.4687, 4.1371, 4.6275, 3.9717, 5.5851, 4.2180, 4.5653,\n",
      "        4.4257, 4.2063, 4.0379, 4.5946, 5.0983, 4.9674, 4.8241, 4.0977, 4.4278,\n",
      "        4.0926, 9.6334, 3.9033, 4.2567, 4.2128, 3.9945, 7.9825, 3.5299, 5.4787,\n",
      "        4.5971], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0064,  0.0041,  0.0074,  0.0093,  0.0021,  0.0127, -0.0069,  0.0158,\n",
      "         0.0059,  0.0040, -0.0013,  0.0097,  0.0011, -0.0130,  0.0076,  0.0082,\n",
      "        -0.0172, -0.0106,  0.0068, -0.0026,  0.0143, -0.0051, -0.0085,  0.0010,\n",
      "        -0.0006,  0.0150, -0.0020,  0.0231, -0.0170, -0.0226, -0.0052,  0.0073,\n",
      "        -0.0070, -0.0023, -0.0042, -0.0015,  0.0068, -0.0166,  0.0055, -0.0174,\n",
      "        -0.0156,  0.0060,  0.0019,  0.0040, -0.0027, -0.0016,  0.0068,  0.0039,\n",
      "        -0.0166,  0.0188, -0.0046, -0.0128,  0.0114,  0.0048, -0.0153, -0.0332,\n",
      "        -0.0113,  0.0060, -0.0007, -0.0165, -0.0031, -0.0002, -0.0197, -0.0096,\n",
      "         0.0075, -0.0042, -0.0249, -0.0003, -0.0073,  0.0192, -0.0160, -0.0058,\n",
      "        -0.0064, -0.0090, -0.0075,  0.0037,  0.0201, -0.0061,  0.0035, -0.0157,\n",
      "        -0.0003,  0.0134,  0.0032,  0.0103,  0.0089,  0.0095, -0.0068,  0.0140,\n",
      "        -0.0274, -0.0063,  0.0192,  0.0044,  0.0042, -0.0115, -0.0003, -0.0024,\n",
      "         0.0115,  0.0159,  0.0076,  0.0049, -0.0060,  0.0001, -0.0290, -0.0007,\n",
      "         0.0062, -0.0004,  0.0029, -0.0025,  0.0058, -0.0096, -0.0088, -0.0155,\n",
      "        -0.0128,  0.0056,  0.0175,  0.0024, -0.0071, -0.0100, -0.0014, -0.0018,\n",
      "         0.0029,  0.0093, -0.0091,  0.0064,  0.0190,  0.0048,  0.0033, -0.0097,\n",
      "         0.0065,  0.0084,  0.0245, -0.0043, -0.0119, -0.0100, -0.0104,  0.0297],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.1675]],\n",
      "\n",
      "         [[-0.4109]],\n",
      "\n",
      "         [[-0.1492]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1030]],\n",
      "\n",
      "         [[-0.3342]],\n",
      "\n",
      "         [[ 0.2125]]],\n",
      "\n",
      "\n",
      "        [[[-0.4133]],\n",
      "\n",
      "         [[-0.0970]],\n",
      "\n",
      "         [[ 0.1752]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5104]],\n",
      "\n",
      "         [[-0.5196]],\n",
      "\n",
      "         [[-0.1537]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2320]],\n",
      "\n",
      "         [[-0.5035]],\n",
      "\n",
      "         [[-0.1651]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1363]],\n",
      "\n",
      "         [[-0.3377]],\n",
      "\n",
      "         [[-0.0279]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3556]],\n",
      "\n",
      "         [[-0.4990]],\n",
      "\n",
      "         [[-0.0016]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2038]],\n",
      "\n",
      "         [[ 0.4046]],\n",
      "\n",
      "         [[-0.1559]]],\n",
      "\n",
      "\n",
      "        [[[-0.3872]],\n",
      "\n",
      "         [[-0.0813]],\n",
      "\n",
      "         [[-0.0188]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0519]],\n",
      "\n",
      "         [[ 0.1025]],\n",
      "\n",
      "         [[ 0.0812]]],\n",
      "\n",
      "\n",
      "        [[[-0.5422]],\n",
      "\n",
      "         [[ 0.7326]],\n",
      "\n",
      "         [[ 0.1447]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0518]],\n",
      "\n",
      "         [[-0.0496]],\n",
      "\n",
      "         [[-0.0924]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 8.7270e-01,  1.2075e+00,  4.9729e-02,  1.6807e+00,  1.0007e+00,\n",
      "         1.0087e+00,  8.5131e-01,  1.7634e+00,  1.0003e+00,  1.8311e+00,\n",
      "         1.0656e+00,  2.2423e+00,  1.1691e+00,  1.2589e+00,  1.2652e+00,\n",
      "         1.3224e+00,  1.0700e+00,  1.9349e+00,  1.7297e+00,  1.1253e+00,\n",
      "         9.9090e-01,  9.6088e-01,  1.1257e+00,  1.1230e+00,  1.0395e+00,\n",
      "         1.6897e+00,  7.6560e-01,  1.0121e+00,  1.4115e+00,  4.7364e-01,\n",
      "         1.2538e+00,  1.6939e+00,  1.5619e+00,  7.9229e-01,  3.4848e-01,\n",
      "         1.0915e+00,  8.3156e-01,  1.4570e+00,  1.3495e+00,  8.5832e-01,\n",
      "         7.8214e-01,  8.1652e-01,  9.0276e-01,  1.2464e+00,  3.0124e-01,\n",
      "         1.0474e+00,  2.0069e+00,  9.1234e-01,  5.4458e-01,  1.3400e+00,\n",
      "         7.9091e-01,  1.4253e+00,  1.6969e+00,  1.0180e+00,  1.2658e+00,\n",
      "         1.2736e+00,  8.2940e-01,  1.1729e+00,  6.4238e-01,  1.5898e+00,\n",
      "         9.1182e-01,  1.0073e+00,  9.2142e-01,  2.0631e+00,  1.7408e+00,\n",
      "         1.1263e+00,  1.3286e+00,  6.8507e-01,  1.0246e+00,  1.2417e+00,\n",
      "         1.3256e+00,  1.0090e+00,  1.4212e+00,  1.1764e+00,  8.8522e-01,\n",
      "         3.6423e-01,  8.7876e-01,  1.5438e+00,  1.1865e+00,  6.5318e-01,\n",
      "         9.6455e-01,  1.0860e+00,  1.5105e+00,  1.1199e+00,  9.3870e-01,\n",
      "         9.3877e-01,  7.1113e-01,  1.6214e+00,  1.0542e+00,  1.9533e+00,\n",
      "         5.5286e-01,  7.2314e-01,  7.8391e-01,  1.1695e+00,  1.6659e+00,\n",
      "         1.1435e+00,  7.6203e-01,  2.0027e+00,  8.3781e-01,  1.4183e+00,\n",
      "         1.2405e+00,  1.0893e+00,  7.2310e-01,  7.2383e-01,  1.0028e+00,\n",
      "         1.3148e+00,  1.5511e+00,  6.9611e-01,  5.2919e-01,  1.7578e+00,\n",
      "         1.2217e+00,  1.7806e+00,  1.2219e+00,  1.5177e+00,  7.2269e-01,\n",
      "         1.6894e+00,  1.4588e+00,  7.6023e-01,  1.8525e+00,  1.5751e+00,\n",
      "         1.7697e+00,  1.4050e+00,  3.9386e-01,  1.6519e+00,  1.7255e+00,\n",
      "         7.4029e-01,  1.6169e+00,  1.1291e+00,  5.2834e-01,  1.3070e+00,\n",
      "         1.4078e+00,  1.1576e+00,  9.4279e-01,  1.1426e+00,  1.5519e+00,\n",
      "         1.1418e+00,  1.1391e+00,  1.9401e+00,  8.5920e-01,  3.7468e-01,\n",
      "         1.5096e+00,  9.0837e-01,  6.0322e-01,  1.7273e+00,  8.3958e-01,\n",
      "         1.2933e+00,  1.7374e+00,  1.3719e+00,  8.4139e-01,  1.6239e+00,\n",
      "         1.3197e+00,  1.4191e+00,  2.0882e+00,  4.5328e-02,  1.5445e+00,\n",
      "         1.4960e+00,  1.2604e+00,  4.3951e-01,  3.4165e-01,  9.3794e-01,\n",
      "         1.7077e+00,  1.3349e+00,  7.9636e-01,  1.1467e+00,  1.7299e+00,\n",
      "         1.0992e+00,  1.1524e+00,  1.6478e+00,  1.2325e+00,  1.5222e+00,\n",
      "         3.0194e-01,  9.0589e-01,  1.4361e+00,  9.6152e-01,  1.6551e-01,\n",
      "         1.2025e+00,  1.0954e+00,  9.7242e-01,  3.8806e-01,  1.1877e+00,\n",
      "         1.1007e+00,  6.5338e-01,  7.7786e-01,  5.6766e-01,  1.7467e+00,\n",
      "         1.3005e+00,  1.0780e+00,  1.5833e+00,  1.8144e+00,  5.9349e-01,\n",
      "         6.8959e-01,  1.3582e+00,  1.3520e+00,  8.4171e-01,  1.0897e+00,\n",
      "         6.0561e-01,  2.1683e+00,  1.2541e+00,  9.0437e-01,  7.8558e-01,\n",
      "         8.4895e-01,  1.9250e+00,  1.4227e+00,  1.1319e+00,  6.0925e-01,\n",
      "         1.1491e+00,  1.0514e+00,  7.1924e-01,  1.1335e+00,  1.5103e+00,\n",
      "         8.9503e-01,  9.7523e-01,  1.3611e+00,  5.5164e-01,  1.1288e+00,\n",
      "         1.3433e+00,  1.1304e+00,  1.1515e+00,  9.9586e-01,  1.4491e+00,\n",
      "         1.7423e+00,  1.1023e+00,  8.6249e-01,  5.3297e-01,  3.8198e-01,\n",
      "         1.2640e+00,  1.6823e+00,  1.0955e+00,  8.9495e-01,  7.4051e-01,\n",
      "         1.1615e+00,  6.7393e-01,  7.8172e-01,  1.1471e+00,  1.4063e+00,\n",
      "         2.7580e-01,  1.1930e+00,  1.4668e+00,  9.7989e-01,  2.1113e+00,\n",
      "         1.4496e+00,  1.2910e+00,  7.8419e-01,  1.3182e+00,  1.2722e+00,\n",
      "         1.1387e+00,  6.3618e-01,  7.3431e-01,  1.1742e+00,  6.7443e-01,\n",
      "         1.5091e+00,  1.7748e+00,  1.3037e+00,  1.2954e+00,  1.1220e+00,\n",
      "         5.3769e-01,  1.0061e+00,  1.4108e+00,  1.6571e-01,  1.2742e+00,\n",
      "         1.7271e+00,  5.8035e-01,  1.2948e+00,  3.5083e-01,  1.5004e+00,\n",
      "         9.3050e-01,  8.2015e-01,  1.2819e+00,  4.5062e-01,  3.3064e-01,\n",
      "         1.0220e+00,  1.2488e+00,  1.4901e+00,  1.3013e+00,  1.2914e+00,\n",
      "         1.3073e+00,  2.0438e+00,  7.8684e-01,  9.7927e-01,  7.7209e-01,\n",
      "         1.2525e+00,  1.3844e+00,  1.6250e+00,  1.2393e+00,  1.0502e+00,\n",
      "         9.0217e-01,  4.3161e-01,  1.7125e+00,  7.2383e-01,  1.3327e+00,\n",
      "         1.2808e+00,  7.7854e-01,  1.1926e+00,  8.2272e-01,  1.5644e+00,\n",
      "         1.4757e+00,  1.3799e+00,  1.5861e+00,  1.3476e+00,  8.6561e-01,\n",
      "         1.3490e+00,  1.5120e+00,  1.2160e+00,  1.3976e+00,  1.2188e+00,\n",
      "         1.3864e+00,  1.2546e-01,  1.4051e+00,  5.8484e-01,  1.6088e+00,\n",
      "         3.6235e-01,  5.6995e-01,  1.0702e+00,  7.1061e-01,  9.3908e-01,\n",
      "         1.1908e+00,  5.7337e-01,  1.5406e+00,  9.4789e-01,  1.1781e+00,\n",
      "         1.2956e+00,  1.0132e+00,  1.4475e+00,  1.0344e+00,  1.3630e+00,\n",
      "         1.1006e+00,  9.6655e-01,  9.7584e-01,  1.7489e+00,  1.3438e+00,\n",
      "         9.2667e-01,  5.3171e-01,  6.8590e-01,  1.4501e+00,  1.1218e+00,\n",
      "         1.8075e+00,  1.1736e+00,  1.2880e+00,  1.6709e-01,  5.5791e-01,\n",
      "         3.2875e-01,  1.6270e+00,  8.4586e-01,  9.1509e-01,  1.4373e+00,\n",
      "         1.2883e+00,  3.7998e-01,  1.2971e+00,  9.5055e-01,  1.3752e+00,\n",
      "         1.0027e+00,  1.1483e+00,  1.5463e+00,  1.1806e+00,  1.1419e+00,\n",
      "         1.3101e+00,  4.7635e-01,  1.2491e+00,  2.1256e+00,  1.1727e+00,\n",
      "         1.6844e+00,  1.2539e+00,  1.0984e+00,  1.7683e+00,  4.3118e-01,\n",
      "         4.8637e-01,  1.5819e+00,  1.1921e+00,  5.6126e-01,  9.2931e-01,\n",
      "         1.0191e+00,  1.1470e+00,  7.9105e-01,  7.2129e-01,  1.3565e+00,\n",
      "         1.0444e+00,  1.4863e+00,  5.6667e-01,  8.1450e-01,  1.6305e+00,\n",
      "         1.1917e+00,  9.6407e-01,  4.3260e-01,  2.5471e-01,  9.5687e-01,\n",
      "         9.5033e-01,  7.8125e-01,  1.8553e+00,  1.0635e+00,  3.9170e-01,\n",
      "         1.3426e+00,  1.6577e+00,  1.2234e+00,  1.4064e+00,  1.2501e+00,\n",
      "         1.8079e+00,  5.9648e-01,  1.1636e+00,  1.4900e+00,  1.4535e+00,\n",
      "         3.1442e-01,  1.4514e+00,  1.0279e+00,  9.7433e-01,  1.0007e+00,\n",
      "         8.9838e-01,  1.1841e+00,  1.5001e+00,  1.3839e+00,  1.0874e+00,\n",
      "         8.3162e-01,  1.2148e+00,  1.4430e+00,  9.3132e-01,  1.7791e+00,\n",
      "         1.2477e+00,  1.5212e+00,  1.4452e+00,  1.8197e+00,  5.5379e-01,\n",
      "         1.4468e+00,  7.8088e-01,  1.0457e+00,  1.1113e+00,  1.2874e+00,\n",
      "         1.1353e+00,  1.4331e+00,  1.9536e+00,  1.2677e+00,  5.8705e-01,\n",
      "         5.9590e-01,  2.1335e-01,  2.1169e+00,  3.9792e-01,  1.5282e+00,\n",
      "         8.6991e-01,  8.2483e-01,  1.1043e+00,  1.4682e+00,  1.1979e+00,\n",
      "         1.0028e+00,  1.6549e-01,  1.0861e+00,  8.3162e-01,  9.4358e-01,\n",
      "         1.6768e+00,  7.4432e-01,  1.1941e+00,  8.6658e-01,  1.1974e+00,\n",
      "         1.3862e+00,  8.5288e-01,  3.7791e-01,  1.1051e+00,  9.7684e-01,\n",
      "         1.7892e+00,  1.2509e+00,  7.5498e-01,  6.7830e-01,  8.2661e-01,\n",
      "         1.1670e+00,  7.8638e-01,  1.0907e+00,  6.3895e-01,  1.2179e+00,\n",
      "         8.5816e-01,  1.1938e+00,  1.2414e+00,  8.1928e-01,  9.4158e-01,\n",
      "         1.2615e+00,  1.4199e+00,  9.9094e-01,  1.1857e+00,  1.1013e+00,\n",
      "         8.8550e-01,  5.9158e-01,  9.2317e-01,  3.1220e-01,  1.5915e+00,\n",
      "         1.4140e+00,  2.1819e-01,  1.2068e+00,  9.7336e-01,  1.4548e+00,\n",
      "         1.0194e+00,  7.8948e-01,  7.2866e-01,  1.5096e+00,  9.1589e-01,\n",
      "         9.5369e-01,  7.0051e-01,  1.5655e+00,  1.9596e+00,  1.3553e+00,\n",
      "         1.2977e+00,  1.1096e+00,  3.7585e-01,  1.1391e+00,  8.6138e-01,\n",
      "         1.1172e+00,  7.3014e-01,  8.8650e-01,  7.5832e-01,  1.3361e+00,\n",
      "         1.5544e+00,  1.2880e+00,  9.4679e-01,  1.2571e+00,  9.8657e-01,\n",
      "         1.5153e+00,  3.8304e-01,  7.2374e-01,  8.3431e-01,  1.5556e+00,\n",
      "         3.2481e-01,  3.8614e-01,  1.0704e+00,  1.1450e+00,  1.4915e+00,\n",
      "         1.1114e+00,  1.2058e+00,  6.6570e-01,  4.5007e-01,  4.9068e-01,\n",
      "         1.6529e+00,  1.1987e+00,  7.9941e-01,  1.6241e+00,  1.0582e+00,\n",
      "         1.6856e+00,  9.7030e-01,  2.0138e+00,  1.4813e+00,  1.5176e+00,\n",
      "         1.3565e+00,  1.0920e+00,  1.4096e+00,  1.0041e+00,  1.0724e+00,\n",
      "         9.2510e-01,  9.4584e-01,  1.3167e+00,  1.1200e+00,  1.6636e+00,\n",
      "         2.0759e+00,  3.0335e-01,  1.4261e+00,  1.0051e+00,  5.7793e-01,\n",
      "         1.4166e+00,  1.1499e+00,  5.6933e-01,  1.2396e+00,  1.7261e+00,\n",
      "         2.2567e+00,  1.2748e+00,  1.1134e+00,  1.5614e+00,  6.1462e-01,\n",
      "         1.5072e+00,  8.8518e-01,  1.1810e+00,  1.0808e+00,  9.3595e-01,\n",
      "         2.5250e+00,  1.2096e+00,  5.1842e-01,  1.0144e+00,  1.2650e+00,\n",
      "         1.3478e+00,  9.8565e-01,  7.6620e-01,  1.4009e+00,  9.8950e-01,\n",
      "         1.5552e+00,  1.1649e+00,  1.3292e+00,  8.1162e-01,  1.0918e+00,\n",
      "         7.1993e-01,  1.9470e+00,  1.0025e+00,  9.4905e-01,  3.1403e-01,\n",
      "         1.0595e+00,  8.9272e-01,  8.0994e-01,  9.9998e-01,  1.6098e+00,\n",
      "         7.1320e-01,  9.2948e-01,  1.2722e+00,  1.3986e+00,  7.8550e-01,\n",
      "         1.9049e-01,  7.4755e-01,  1.0971e+00,  8.0215e-01,  1.9944e+00,\n",
      "         1.4296e+00,  6.3637e-01,  1.2739e-01,  1.1481e+00,  5.7051e-01,\n",
      "         1.0227e+00,  2.3851e-02,  7.6859e-01,  9.7653e-01,  1.0606e+00,\n",
      "         9.3129e-01,  4.2757e-01,  1.3034e+00,  7.6883e-01,  1.8089e+00,\n",
      "         1.3493e+00,  1.0422e+00,  1.6520e+00,  1.9352e-01,  2.0578e+00,\n",
      "         1.3809e+00,  1.2884e+00,  1.0060e+00,  6.5515e-01,  1.3690e+00,\n",
      "         1.3276e+00,  7.3940e-01,  1.5134e+00,  1.7004e+00,  2.1874e+00,\n",
      "         9.7872e-01,  1.1923e+00,  5.3445e-01,  5.7541e-01,  1.2045e+00,\n",
      "         6.9281e-01,  1.2902e+00,  1.4651e+00,  1.1248e+00,  9.8556e-01,\n",
      "         2.3074e-01,  1.0993e+00,  1.9113e+00,  9.4232e-01,  8.1485e-01,\n",
      "         8.8766e-01,  5.8811e-01,  7.4149e-01,  8.6772e-01,  3.5465e-01,\n",
      "         7.5851e-01,  1.1025e+00,  9.0013e-01,  1.5035e+00,  1.5733e+00,\n",
      "         6.4059e-01,  1.5350e+00,  9.8889e-01,  6.8783e-01,  6.7864e-01,\n",
      "         1.7666e+00,  1.6193e+00,  1.2656e+00,  1.5048e+00,  6.8285e-01,\n",
      "        -1.7959e-04,  8.9224e-01,  1.0528e+00,  1.3346e+00,  9.8046e-01,\n",
      "         1.1688e+00,  9.7648e-01,  6.3065e-01,  1.5476e+00,  1.3195e+00,\n",
      "         7.9947e-01,  9.1884e-01,  8.1329e-01,  9.7801e-01,  1.6908e+00,\n",
      "         1.1080e+00,  7.7191e-01,  1.1103e+00,  9.7847e-01,  1.2693e+00,\n",
      "         1.1500e+00,  1.2507e+00,  1.5456e+00,  8.3043e-01,  1.0398e+00,\n",
      "         2.2271e-01,  1.5210e+00,  6.2689e-01,  4.1511e-01,  1.3749e+00,\n",
      "         1.8889e+00,  1.1907e+00,  6.7749e-01,  6.4169e-01,  1.8015e+00,\n",
      "         6.8418e-01,  8.8376e-01,  1.4980e+00,  9.2838e-01,  1.2221e+00,\n",
      "         3.1822e-01,  2.2986e+00,  1.3367e+00,  1.3534e+00,  1.2735e+00,\n",
      "         8.8658e-01,  1.5362e+00,  1.2799e+00,  1.0876e+00,  1.6791e+00,\n",
      "         1.2585e+00,  5.9464e-01,  1.5107e+00,  1.3713e+00,  1.1272e+00,\n",
      "         1.2914e+00,  1.1439e+00,  9.3388e-01,  9.4105e-01,  1.0447e+00,\n",
      "         3.5028e-01,  1.5763e+00,  1.6330e+00,  1.1926e+00,  9.7721e-01,\n",
      "         9.5211e-01,  1.8428e+00,  9.3151e-01,  7.9229e-01,  7.9109e-01,\n",
      "         1.1794e+00,  7.1769e-01,  9.0372e-01,  8.2635e-01,  1.6896e-01,\n",
      "         1.4997e+00,  7.0423e-01,  1.1135e+00,  1.8800e+00,  1.6171e+00,\n",
      "         1.5436e+00,  7.5100e-01,  7.7378e-01,  1.8912e-01,  1.4072e-01,\n",
      "         1.1769e+00,  1.1827e+00,  1.0963e+00,  1.9944e+00,  4.7555e-01,\n",
      "         1.1952e+00,  1.2526e+00,  1.3827e+00,  8.6357e-01,  1.4816e+00,\n",
      "         2.0837e+00,  1.1729e+00,  1.6689e+00,  1.3851e+00,  4.0597e-01,\n",
      "         1.1603e+00,  1.5314e+00,  1.3895e+00,  1.3209e+00,  1.3735e+00,\n",
      "         1.3632e+00,  3.1472e-01,  1.8104e+00,  4.0624e-01,  1.1545e+00,\n",
      "         1.1047e+00,  1.6023e+00,  9.1519e-01,  1.4910e+00,  1.0512e+00,\n",
      "         1.4289e+00,  1.2338e+00,  9.5600e-01,  1.1313e+00,  1.2000e+00,\n",
      "         8.0479e-01,  1.1635e+00,  2.2497e-01,  5.8116e-01,  3.2901e-01,\n",
      "         1.5857e+00,  2.3316e+00,  9.1543e-01,  2.1350e+00,  4.3938e-01,\n",
      "         2.7228e-01,  1.2380e+00,  1.1545e+00,  1.1397e+00,  1.0760e+00,\n",
      "         9.4147e-01,  9.3559e-01,  1.1520e+00,  8.8786e-01,  1.2237e+00,\n",
      "         7.5897e-01,  1.0231e+00,  1.4327e+00,  1.0460e+00,  3.6979e-01,\n",
      "         6.9445e-01,  4.5037e-01,  1.9815e+00,  6.9548e-01,  1.2346e+00,\n",
      "         8.0436e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 5.1260e-01, -1.6799e-01,  1.2320e+00, -1.6079e+00, -1.6259e+00,\n",
      "        -1.1884e+00, -3.2082e-01, -2.9635e-01,  6.6846e-01, -1.3344e+00,\n",
      "        -1.6317e+00, -3.2561e-01, -2.1357e-01, -1.6486e+00,  2.6631e-01,\n",
      "         5.8713e-01, -4.2818e-02,  2.9735e-01,  5.1674e-01, -2.9792e-01,\n",
      "        -5.7292e-01,  6.5324e-01, -1.5728e+00, -2.6521e+00, -1.0258e+00,\n",
      "        -2.0309e+00, -1.0601e+00, -9.5319e-01, -1.3146e+00, -1.9411e-02,\n",
      "        -1.3980e+00, -2.1326e+00, -1.8629e+00,  1.8184e-01,  1.1075e-01,\n",
      "        -4.4406e-01,  8.3330e-01, -1.0354e+00, -5.7827e-01, -6.8028e-01,\n",
      "        -1.2019e+00, -7.4217e-01, -8.8535e-01, -1.6981e-01, -2.9559e-01,\n",
      "        -1.1908e+00, -7.0556e-01, -1.6504e+00, -4.6363e-01, -3.3688e-01,\n",
      "        -3.4888e-01,  5.1415e-02,  4.9433e-01, -2.2404e+00, -1.3399e-01,\n",
      "        -5.3777e-01, -2.0812e+00,  7.0381e-01,  2.6660e-01,  6.7657e-01,\n",
      "        -1.2130e+00, -1.3375e+00, -8.8479e-01, -6.8155e-02,  5.4831e-01,\n",
      "        -2.6072e-01, -2.1756e+00, -3.6910e-01,  2.7985e-01,  7.8240e-01,\n",
      "        -1.4554e+00, -4.6487e-02,  3.6251e-02, -1.1956e+00, -6.1885e-01,\n",
      "        -5.5821e-01, -3.6810e-01, -1.9123e+00, -1.1978e-01,  7.0650e-01,\n",
      "        -7.2926e-01, -2.3030e-01, -1.3151e+00, -1.4845e+00, -2.7447e-01,\n",
      "        -7.7198e-01, -9.8209e-01, -6.8209e-01,  7.5072e-01,  5.0250e-01,\n",
      "        -1.6727e-02, -6.3994e-01, -1.3362e+00, -8.5020e-01, -1.3062e+00,\n",
      "         4.9871e-01, -5.5527e-01, -1.4983e+00, -9.0762e-01, -7.9705e-01,\n",
      "        -2.9687e-01,  6.4465e-01, -1.5422e+00, -2.2973e+00, -9.0495e-02,\n",
      "        -7.3051e-01, -1.6387e+00, -2.7980e-02, -4.8687e-01, -1.2447e+00,\n",
      "         7.1581e-01, -1.1670e-01,  1.3936e+00,  7.0349e-02, -7.6665e-01,\n",
      "         1.6807e-01, -5.4859e-01, -7.5202e-01, -1.2571e-01, -1.8049e+00,\n",
      "        -1.6342e-01, -1.3334e+00, -6.1966e-01, -1.6754e+00, -1.2809e+00,\n",
      "         6.1351e-02,  1.0279e-01, -2.0293e+00, -2.0434e+00, -1.6249e-01,\n",
      "        -1.9822e+00, -1.0269e+00, -7.2283e-01, -6.6029e-01, -4.1620e-01,\n",
      "        -6.7811e-01,  1.1580e+00, -8.9339e-02,  1.8759e-01,  1.0810e+00,\n",
      "        -2.0948e+00,  3.8238e-01, -2.7853e-01, -2.6749e+00, -7.2443e-01,\n",
      "        -1.1927e-01, -8.4532e-01, -1.0785e+00, -5.1980e-01, -5.5440e-01,\n",
      "        -1.5862e+00, -7.0046e-01, -8.4720e-01,  8.5810e-01, -1.7294e+00,\n",
      "         5.0122e-01, -1.1572e+00, -7.1594e-01,  3.3754e-02, -5.9820e-01,\n",
      "        -1.9005e+00, -1.0897e+00,  1.3969e-02,  3.3059e-01, -2.7016e-01,\n",
      "        -2.1119e+00, -8.9766e-02, -1.3084e+00, -5.4389e-01, -1.7243e-01,\n",
      "        -5.2555e-01, -7.9018e-01, -4.8502e-01, -3.9906e-01, -2.5095e-01,\n",
      "        -2.0520e+00, -8.5697e-01, -1.6184e+00,  4.9909e-03, -1.4150e-01,\n",
      "         9.8344e-01,  5.2476e-01,  1.3103e-01, -2.4299e-01, -1.7736e-01,\n",
      "        -1.0136e+00,  1.1065e-01, -1.1849e-01,  8.4741e-01,  3.7440e-01,\n",
      "        -3.9152e-01, -1.2083e+00, -3.0781e-01,  8.3737e-01, -1.3070e+00,\n",
      "        -4.9122e-01, -1.3032e-01, -1.1922e+00, -7.9747e-01, -2.0761e+00,\n",
      "        -8.4133e-01,  5.6533e-01, -3.9191e-01, -7.8685e-01, -9.7760e-02,\n",
      "        -5.3455e-01, -4.4287e-01, -9.0837e-01, -1.3622e+00, -7.6871e-01,\n",
      "        -1.3401e+00, -7.8520e-01, -8.7941e-01, -1.5356e+00, -1.3085e+00,\n",
      "        -1.2316e-01, -1.1964e+00, -7.1821e-01,  4.3061e-01,  5.7915e-02,\n",
      "        -1.3719e+00, -1.6261e+00, -8.3272e-01,  3.1726e-01,  1.4366e-01,\n",
      "        -3.4624e-01, -1.0325e+00,  3.9986e-01, -1.4823e+00, -5.1569e-01,\n",
      "         4.0742e-01,  9.9288e-01, -1.2525e+00, -1.0676e+00, -7.8783e-01,\n",
      "        -4.0509e-01, -1.1011e-01, -6.6412e-01,  1.7292e-02,  1.6217e-01,\n",
      "        -8.4088e-02,  4.9319e-02,  6.1318e-01, -1.8285e-01, -4.0585e-01,\n",
      "        -1.9537e+00, -1.2392e+00, -1.2975e+00, -1.0693e+00,  6.1211e-01,\n",
      "         9.6487e-01, -1.6198e-01, -8.0192e-01, -5.2037e-01,  7.3328e-01,\n",
      "        -6.4556e-01, -6.8990e-01,  1.1169e-01,  5.6566e-01, -1.7043e+00,\n",
      "        -1.4702e+00, -7.7826e-01, -7.7809e-01, -2.8707e-02, -2.6592e+00,\n",
      "        -5.4458e-01,  5.9252e-01,  1.5148e-01, -6.0214e-01, -5.9842e-01,\n",
      "        -1.7379e+00, -1.9460e+00, -3.5628e-02, -7.8705e-01,  6.5803e-02,\n",
      "        -1.4617e+00, -1.7986e-01,  6.7812e-01, -1.5367e+00, -6.5877e-01,\n",
      "        -1.2550e+00, -1.0100e+00,  7.1912e-01,  8.6396e-02, -6.7534e-01,\n",
      "        -2.0096e+00,  1.6843e-01, -1.4303e+00, -7.4454e-01, -4.4402e-01,\n",
      "        -1.3702e+00, -6.7544e-01, -1.7721e-01,  6.1721e-01, -1.9761e+00,\n",
      "         3.1808e-01, -7.7295e-01, -1.9564e+00,  1.8535e-01, -1.8200e+00,\n",
      "        -1.7367e+00, -1.6402e+00, -1.1948e+00, -5.8819e-01, -8.5204e-01,\n",
      "        -6.7874e-01,  4.5537e-01, -5.6333e-01, -1.0290e+00, -5.0163e-01,\n",
      "         1.0825e-01, -1.0832e+00, -1.0929e+00,  9.8916e-01, -1.0853e+00,\n",
      "        -2.2620e-01,  1.3042e-01, -3.8355e-01, -8.0253e-01,  1.5614e+00,\n",
      "        -1.8930e+00, -8.5539e-01, -6.7695e-01, -8.1212e-01, -1.0104e+00,\n",
      "        -5.3823e-01, -1.9332e+00, -5.2929e-01, -3.4425e-01, -7.7425e-01,\n",
      "         8.3654e-01, -3.6698e-02,  9.5464e-01, -1.4493e+00, -1.5647e+00,\n",
      "        -2.7642e-01, -1.8952e+00, -5.0576e-01, -6.2553e-01, -2.3456e+00,\n",
      "         1.8472e-01,  5.8806e-01, -6.4666e-01, -1.0600e+00, -1.5630e+00,\n",
      "        -2.8099e+00,  4.9760e-02, -3.0852e-01, -1.3092e+00, -5.0234e-01,\n",
      "        -2.6494e-01, -1.8212e+00,  3.5991e-01,  5.9255e-01, -2.2100e+00,\n",
      "        -1.6231e+00, -1.0645e+00, -2.5005e+00, -6.7866e-01,  2.3964e-02,\n",
      "        -1.7769e-01, -7.6697e-01, -7.8418e-01, -8.3982e-01,  1.3315e+00,\n",
      "         3.9723e-02, -1.0155e+00, -9.0861e-01, -1.8950e-01, -8.7878e-01,\n",
      "        -1.7735e+00, -1.6302e+00,  7.2926e-01, -1.0347e+00, -9.9928e-02,\n",
      "        -3.2911e-01,  5.6419e-01, -1.2944e-03,  1.4855e+00, -5.6200e-01,\n",
      "        -2.6475e-01,  3.1908e-01,  6.0887e-01,  9.5677e-01, -6.3751e-01,\n",
      "        -1.3881e+00, -8.2895e-01, -5.0511e-01,  4.3547e-01,  1.0499e+00,\n",
      "         3.4924e-01, -2.8391e-02,  1.1485e+00,  1.7205e-02, -3.1971e-01,\n",
      "        -1.3044e-01, -1.6752e+00, -1.1590e+00, -1.5903e+00, -8.8030e-01,\n",
      "         3.3700e-01,  4.6753e-01, -2.8098e-01, -6.0129e-01, -5.5714e-01,\n",
      "        -1.8317e+00, -1.0848e+00,  1.3951e-01, -2.3293e+00, -1.2373e+00,\n",
      "        -1.3271e+00,  1.1090e+00, -4.2840e-01, -8.2637e-01, -1.6217e+00,\n",
      "        -1.8360e+00, -1.7232e+00, -1.5167e+00, -3.2409e+00,  6.8034e-01,\n",
      "        -8.8759e-01,  8.6731e-01, -1.2327e+00, -7.8057e-01, -1.4741e+00,\n",
      "         2.7973e-01, -6.0160e-01,  1.1038e-01, -2.0580e+00, -2.7640e-01,\n",
      "        -5.8712e-01,  2.5011e-01, -1.3739e-02,  5.3635e-01, -5.9586e-01,\n",
      "        -3.9307e-01,  3.5092e-02, -5.3945e-02, -1.3836e-01, -3.1565e-01,\n",
      "        -1.2777e+00, -2.9114e-01, -9.4630e-01, -1.8880e-01, -1.5313e+00,\n",
      "        -2.4046e+00,  1.6156e-01, -1.1697e+00, -5.6539e-01, -1.1959e+00,\n",
      "         5.8540e-01, -8.6907e-01,  8.6698e-01, -9.6545e-01,  2.0159e+00,\n",
      "        -5.2400e-01, -4.1210e-01, -1.3139e+00, -1.0937e+00,  5.0841e-01,\n",
      "        -1.2049e+00,  1.3382e-01, -4.7121e-01, -5.6864e-01, -1.7319e+00,\n",
      "        -9.2496e-01,  6.9419e-01, -4.4427e-01,  3.7302e-02, -6.9110e-01,\n",
      "        -1.5537e+00,  2.9512e-01, -7.8154e-01, -1.9175e+00, -7.1302e-01,\n",
      "        -1.6793e+00, -1.4898e-01, -6.3782e-01, -5.8201e-01,  1.3040e-01,\n",
      "        -1.3104e+00,  4.9454e-01, -1.1822e+00, -3.3629e-01, -2.2508e+00,\n",
      "        -5.5113e-01, -9.8342e-01, -7.1646e-01,  6.0245e-01,  1.0019e-01,\n",
      "        -1.3251e+00,  4.9921e-01, -6.3044e-01,  6.8936e-01, -4.3243e-01,\n",
      "        -8.8607e-01, -2.0362e-01, -9.5490e-01,  4.5058e-01, -5.8977e-01,\n",
      "         2.4869e-01, -5.0158e-01,  1.2921e+00, -4.1835e-01, -1.3574e+00,\n",
      "        -2.1245e+00, -1.1592e+00, -1.0120e+00,  5.9691e-01, -1.6346e+00,\n",
      "        -1.3874e+00, -1.1347e+00, -7.2193e-01, -9.0738e-01,  3.9985e-01,\n",
      "         1.0690e-01,  3.5482e-01,  1.4319e+00, -1.3781e+00, -1.5432e+00,\n",
      "         6.9066e-01, -5.4705e-01,  1.8810e-01,  4.5244e-01, -8.5519e-02,\n",
      "        -1.7982e+00, -5.1311e-01, -1.1048e+00, -2.1895e+00, -1.1410e+00,\n",
      "         5.4257e-02, -4.7632e-01, -1.3370e+00, -1.4923e+00, -5.3589e-01,\n",
      "        -1.9231e+00, -8.3143e-01, -8.0941e-02, -1.6748e+00, -1.1588e+00,\n",
      "        -1.1978e-01, -6.7823e-01, -1.0236e+00, -1.0177e+00, -1.7694e+00,\n",
      "        -2.1365e+00, -1.4743e-01, -8.3981e-01, -1.8935e-01, -2.1204e-01,\n",
      "        -1.6299e+00, -1.1053e+00,  2.8790e-01, -1.1792e+00, -1.5179e+00,\n",
      "        -6.5029e-02, -3.1928e-01, -1.4547e+00, -7.0755e-01,  9.0378e-02,\n",
      "         4.4594e-01, -7.6643e-01, -1.1462e+00, -2.5882e-01, -2.2338e-01,\n",
      "         1.8972e-01, -6.9177e-01,  2.4391e-01, -9.1925e-01, -9.1474e-01,\n",
      "        -6.1576e-01,  9.7190e-01, -1.7509e+00, -1.0448e+00, -6.7647e-01,\n",
      "        -2.0216e+00, -1.8632e+00, -1.4782e+00,  5.5355e-01, -1.5717e+00,\n",
      "        -1.0056e-01, -4.4690e-01, -8.9947e-01,  8.5565e-01,  1.0571e-01,\n",
      "        -1.2227e+00, -1.8456e+00,  9.3431e-01,  6.0694e-01, -6.1236e-01,\n",
      "        -1.3491e+00,  7.2032e-01, -1.7601e+00, -1.1687e+00, -1.9476e+00,\n",
      "         1.6619e-01,  8.0120e-01, -6.7312e-01, -5.2705e-01, -9.4846e-01,\n",
      "        -1.4871e+00, -2.4181e-01,  2.1929e-01, -2.0471e+00, -1.1323e-01,\n",
      "        -7.9734e-01, -4.1398e-01, -8.0322e-01, -9.6263e-01, -1.8615e+00,\n",
      "        -1.2112e+00, -2.4655e-01,  4.7784e-01,  4.0000e-01,  1.8480e-01,\n",
      "         7.6614e-02, -1.1688e+00, -9.3473e-01, -2.0836e-01,  2.6938e-01,\n",
      "        -9.2245e-01,  1.0008e+00, -1.1136e+00, -1.4828e+00,  1.0831e+00,\n",
      "        -1.0568e+00, -1.5733e+00, -1.8556e+00,  9.6221e-01, -2.4094e-01,\n",
      "         5.5160e-01, -1.0151e+00, -5.6789e-01,  4.3983e-01, -9.2264e-02,\n",
      "        -3.0018e-01, -1.8199e+00, -6.0598e-01,  1.4656e-01,  5.1285e-01,\n",
      "         3.4074e-01, -8.2337e-01,  4.0997e-01,  2.2863e-01, -5.8894e-01,\n",
      "        -1.0396e+00, -8.9904e-01, -5.7814e-01,  2.5317e-01, -4.1646e-01,\n",
      "        -1.1106e-01, -2.4751e-01, -2.0280e+00, -1.8205e+00, -1.6160e+00,\n",
      "        -1.3715e-01, -1.3644e+00, -9.5978e-01,  6.3368e-01,  6.5893e-01,\n",
      "         4.9109e-01,  5.9201e-02, -7.1691e-01,  1.4253e-01,  1.9769e-01,\n",
      "        -9.5165e-01, -1.1790e+00,  1.8402e-01,  2.2580e-01,  3.6523e-01,\n",
      "        -1.3701e+00, -6.8410e-01,  2.1704e-01, -1.5266e-01, -4.5061e-01,\n",
      "        -2.2028e+00, -9.0948e-01, -6.3193e-01, -1.6337e+00,  7.3896e-01,\n",
      "        -2.0703e+00, -1.4291e+00, -7.4544e-01, -7.1196e-01, -1.8020e+00,\n",
      "         1.2004e+00, -1.2001e+00, -1.3890e+00, -3.2345e-01, -5.6926e-01,\n",
      "         6.7141e-01,  1.9333e-01,  2.2905e-02,  3.3618e-01, -1.5800e+00,\n",
      "         7.6657e-01, -1.2818e+00, -9.1962e-02, -1.4131e+00, -8.1167e-01,\n",
      "         2.7513e-01, -1.9082e+00, -2.0490e+00, -9.7634e-01, -1.2529e+00,\n",
      "         3.1285e-01, -2.4382e-01, -1.1077e+00, -1.0439e+00, -2.8920e-01,\n",
      "        -7.2327e-01, -1.0282e+00, -1.1264e+00, -1.0205e+00, -2.4980e-01,\n",
      "        -1.6308e+00,  6.2896e-01, -2.0676e+00, -1.7766e+00,  2.8369e-01,\n",
      "        -1.4720e+00, -1.0245e+00,  9.9100e-01, -1.1850e+00, -1.1281e-01,\n",
      "        -6.3452e-02, -8.1157e-01, -2.1394e+00,  3.9943e-01, -4.7134e-01,\n",
      "        -2.9437e-01,  5.5176e-01, -1.7728e+00, -5.8253e-01, -1.3627e+00,\n",
      "        -1.8583e+00, -2.8513e-01, -4.5371e-01, -7.7764e-01,  2.8174e-01,\n",
      "        -1.5246e+00,  2.0155e+00, -2.4969e+00, -1.7575e-01, -1.1665e+00,\n",
      "        -1.3383e+00,  6.2469e-01, -5.9366e-01, -6.4161e-01,  6.7119e-01,\n",
      "        -1.0191e+00,  7.1177e-01, -3.9316e-01, -2.0484e+00,  7.5774e-01,\n",
      "         3.9323e-02, -6.8239e-01, -1.3473e+00,  4.3199e-01,  1.5474e-01,\n",
      "         2.2597e-01, -6.8460e-01, -8.9155e-01, -3.2386e-01,  8.4443e-02,\n",
      "        -5.3327e-01, -3.1685e-03, -9.7060e-01, -5.9426e-01, -6.4990e-01,\n",
      "        -9.7834e-01,  4.7644e-01,  1.1159e+00, -6.0214e-01, -4.3810e-01,\n",
      "        -7.5007e-01,  7.3161e-01, -1.6703e+00, -2.1753e-01, -2.9285e+00,\n",
      "         3.2937e-01, -1.2861e+00, -1.1950e+00,  1.0130e+00, -8.1615e-01,\n",
      "         7.8288e-01, -9.9150e-01,  3.7180e-01, -1.1647e-01,  1.4744e+00,\n",
      "         4.6079e-01,  4.1683e-01, -1.1384e-01, -1.8282e+00,  6.4415e-02,\n",
      "        -6.0426e-02,  6.7530e-01, -4.6913e-01, -1.5118e-01, -8.0494e-01,\n",
      "        -1.6331e+00, -8.8719e-01,  7.0292e-01, -3.4402e-01, -1.0255e+00,\n",
      "        -9.6030e-02, -1.6490e+00,  9.3895e-01, -2.0200e+00,  2.6464e-01,\n",
      "         8.8263e-01, -2.9762e-01, -1.1191e+00, -8.4191e-01, -1.1931e+00,\n",
      "        -1.1121e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.5806, -0.4190, -0.6817, -0.4799, -0.5918],\n",
      "          [-0.7706, -0.3808, -0.4194, -0.2274, -0.5831],\n",
      "          [-0.1679, -0.3424, -0.3786, -0.4611, -0.6121],\n",
      "          [-0.0772, -0.0306,  0.1081, -0.0576, -0.2590],\n",
      "          [-0.0369,  0.0036,  0.2888,  0.0281, -0.0492]]],\n",
      "\n",
      "\n",
      "        [[[-0.5744, -0.4263, -0.4590, -0.4734, -0.3342],\n",
      "          [-0.1896, -0.1844, -0.1386, -0.1093, -0.0452],\n",
      "          [ 0.0740,  0.2504, -0.2489,  0.1034,  0.5366],\n",
      "          [ 0.3696,  0.7855,  0.0509,  0.0334,  0.4551],\n",
      "          [ 0.3638,  0.3193, -0.0939, -0.3359, -0.2823]]],\n",
      "\n",
      "\n",
      "        [[[-0.3110, -0.2529, -0.3827, -0.2533, -0.0241],\n",
      "          [-0.6371, -0.5916, -0.7797, -0.5812, -0.4094],\n",
      "          [ 0.1245, -0.0292, -0.3154,  0.0681,  0.0024],\n",
      "          [ 0.0361, -0.0917,  0.0846,  0.0747, -0.0675],\n",
      "          [ 0.2280,  0.0803,  0.2874,  0.0781,  0.0262]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2558, -0.2287,  0.3875,  0.2349,  0.6631],\n",
      "          [ 0.5733,  0.7968,  0.4406, -0.0947,  0.2510],\n",
      "          [-0.1901,  0.3662,  0.2209,  0.1052,  0.1243],\n",
      "          [-0.0652,  0.2415, -0.0063,  0.1590,  0.1949],\n",
      "          [-0.0607,  0.1951,  0.1175,  0.2959,  0.5169]]],\n",
      "\n",
      "\n",
      "        [[[-0.1929, -0.0696, -0.1717, -0.1290, -0.0616],\n",
      "          [-0.3496, -0.1115, -0.1444, -0.0358, -0.0941],\n",
      "          [-0.9451,  0.3152, -0.2364, -0.6319, -0.5948],\n",
      "          [-0.7773, -0.0799, -0.0087, -0.7379, -0.8694],\n",
      "          [-0.0433,  0.0474,  0.1115, -0.2230, -0.3015]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3925,  0.3913,  0.6364,  0.0185,  0.3359],\n",
      "          [ 0.4148,  0.3162,  0.4980, -0.2206,  0.1827],\n",
      "          [ 0.3572,  0.2989,  0.4097, -0.1014,  0.2041],\n",
      "          [ 0.2812,  0.1773,  0.3157, -0.0748,  0.2053],\n",
      "          [ 0.4350,  0.3354,  0.3296,  0.0246,  0.2314]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.9122, 1.7527, 1.4516, 2.7159, 1.6922, 2.0078, 1.4474, 2.0254, 1.5758,\n",
      "        3.0603, 0.9722, 1.3260, 1.7474, 0.8231, 1.9691, 1.6613, 1.8414, 2.5444,\n",
      "        2.2254, 1.3682, 1.3740, 0.8414, 1.0455, 2.4459, 1.1667, 2.3419, 1.1471,\n",
      "        1.8831, 1.6357, 1.2442, 1.3945, 2.3081, 1.5881, 1.6333, 1.8406, 1.0819,\n",
      "        1.7645, 2.1260, 1.3166, 1.3680, 1.0043, 1.5296, 1.5011, 2.0716, 1.5870,\n",
      "        1.2614, 1.8670, 1.2255, 1.4678, 1.9575, 1.8291, 1.3399, 1.4561, 0.6859,\n",
      "        1.9826, 1.2788, 0.8871, 1.8885, 1.6916, 2.6020, 1.1485, 1.4303, 1.7223,\n",
      "        2.0928, 0.7780, 2.0789, 2.7872, 0.9758, 1.5378, 1.9746, 2.3870, 1.9531,\n",
      "        0.7296, 1.8425, 1.4995, 1.5702, 1.4976, 2.7118, 1.9606, 1.4255, 1.0409,\n",
      "        1.3705, 1.5964, 2.2869, 0.3476, 1.7287, 1.3812, 2.2287, 1.1210, 2.4490,\n",
      "        2.6465, 1.3061, 1.3774, 1.3617, 1.4721, 1.4441, 1.1185, 1.9535, 2.2239,\n",
      "        1.4457, 1.0479, 1.1944, 1.0289, 0.9511, 2.6357, 1.7352, 2.8886, 1.7745,\n",
      "        1.8209, 1.1534, 1.3585, 0.3630, 2.5084, 1.6532, 1.2836, 2.1097, 1.6942,\n",
      "        1.5320, 2.4780, 2.3494, 1.4280, 0.7275, 1.2607, 1.5174, 2.4657, 1.4607,\n",
      "        1.1963, 1.4227, 0.7614, 1.9524, 0.7071, 0.6004, 1.4276, 1.4842, 1.5354,\n",
      "        1.3293, 2.2830, 2.2655, 1.7553, 1.7767, 1.4172, 1.9747, 1.8803, 2.3996,\n",
      "        0.4590, 1.9583, 1.0564, 1.5106, 1.2248, 1.5444, 1.5357, 2.0829, 1.7779,\n",
      "        1.0721, 0.5813, 1.4526, 1.2402, 1.0068, 1.6856, 2.2043, 3.4201, 0.6424,\n",
      "        2.0128, 1.3325, 1.5845, 1.0583, 1.6290, 1.3945, 1.2508, 2.0855, 1.7199,\n",
      "        1.3162, 1.7051, 0.9214, 1.5576, 1.2796, 1.3423, 1.4123, 1.7248, 2.0179,\n",
      "        1.6782, 1.7565, 1.7687, 1.3778, 1.7483, 1.5372, 1.5753, 1.4901, 0.8663,\n",
      "        2.2051, 0.7713, 1.4651, 1.3733, 1.3224, 0.3955, 1.5717, 2.1567, 0.9178,\n",
      "        1.5117, 0.7016, 0.6543, 1.4947, 2.0275, 1.2355, 1.5631, 1.9373, 1.3778,\n",
      "        1.4315, 1.0457, 0.9290, 1.6224, 1.3408, 1.3305, 1.1817, 1.6647, 1.7923,\n",
      "        1.1947, 1.0826, 2.4316, 2.1797, 1.7007, 1.4693, 1.4026, 1.4663, 1.3927,\n",
      "        1.8564, 1.6488, 1.8699, 1.9175, 1.6075, 1.3811, 1.2809, 1.4187, 1.2725,\n",
      "        1.4709, 1.9328, 1.8713, 1.1075, 1.1353, 1.9005, 1.4241, 1.4082, 2.3821,\n",
      "        1.7265, 1.8832, 1.0228, 1.3374, 1.2439, 0.5776, 0.4985, 1.4324, 2.6847,\n",
      "        0.9849, 2.5203, 2.2793, 1.0361, 0.7723, 1.8271, 2.3647, 3.1887, 3.7978,\n",
      "        1.3413, 1.4629, 2.0838, 4.3193, 1.3063, 1.6570, 1.4209, 0.5124, 1.7572,\n",
      "        1.1134, 1.2997, 1.1767, 1.5804, 1.7742, 1.5052, 1.4777, 2.1445, 0.3323,\n",
      "        1.8486, 0.5672, 1.3370, 2.0850, 1.5688, 1.5895, 1.1597, 1.4945, 1.9805,\n",
      "        1.4545, 1.1649, 1.9394, 1.4138, 2.3777, 1.7751, 2.5553, 1.9839, 1.7349,\n",
      "        1.8129, 1.6839, 1.5789, 1.6004, 1.7038, 1.7269, 1.1144, 1.7933, 2.1453,\n",
      "        1.6349, 1.4787, 1.5408, 1.5174, 2.2025, 1.3793, 0.7670, 1.7909, 2.7005,\n",
      "        1.1954, 2.2419, 1.3069, 1.3512, 2.2601, 1.6910, 1.3790, 1.4774, 1.6738,\n",
      "        1.2934, 2.2950, 0.8448, 1.0167, 1.4014, 1.6759, 2.0650, 1.8911, 2.1132,\n",
      "        0.8738, 1.4920, 1.3718, 0.8932, 1.4470, 1.2319, 2.5555, 2.1495, 2.3174,\n",
      "        1.4033, 1.2923, 2.9710, 2.5932, 1.6221, 2.1076, 1.0811, 1.8763, 1.8673,\n",
      "        0.9355, 2.1742, 1.2623, 0.9568, 1.9510, 1.1803, 1.5661, 1.3649, 1.4936,\n",
      "        2.1043, 1.5740, 1.0651, 1.8521, 1.4390, 1.4196, 1.4469, 1.4674, 1.7128,\n",
      "        1.5834, 0.9986, 0.7320, 2.2570, 0.9443, 1.3028, 1.4346, 1.9607, 2.0722,\n",
      "        2.0108, 2.3451, 1.5666, 2.0059, 1.7642, 1.7688, 1.6565, 0.8172, 1.6855,\n",
      "        1.3396, 1.8901, 1.6388, 1.9471, 1.5039, 1.7684, 1.6593, 1.3319, 2.7226,\n",
      "        1.2337, 1.0889, 2.4561, 2.0266, 1.7286, 2.0570, 1.6237, 1.7310, 1.5458,\n",
      "        0.5906, 1.3665, 2.2307, 1.0342, 1.5831, 1.2980, 1.6851, 1.6987, 1.3129,\n",
      "        2.1147, 1.3996, 3.6133, 2.6065, 2.9137, 1.9556, 1.4222, 1.7528, 1.5008,\n",
      "        1.4015, 1.2653, 1.8536, 1.5077, 1.9530, 0.7147, 1.8758, 2.3054, 1.7150,\n",
      "        2.2873, 1.7958, 1.0403, 1.5433, 1.8823, 2.1131, 2.0340, 1.4610, 2.1963,\n",
      "        1.4100, 1.5705, 1.5564, 0.9049, 3.7021, 1.8355, 1.7937, 2.2461, 1.8259,\n",
      "        1.8736, 1.4582, 1.5943, 1.9666, 1.5293, 1.6681, 1.6252, 1.3260, 1.5107,\n",
      "        2.1999, 1.6278, 1.6362, 1.6446, 1.7201, 0.8482, 1.8798, 1.5947, 1.8783,\n",
      "        1.6455, 1.5128, 2.0212, 1.5372, 1.2440, 2.1671, 1.9204, 1.3541, 2.0041,\n",
      "        1.5993, 1.4196, 1.0555, 1.4761, 1.7231, 1.3637, 1.7913, 3.5884, 1.5352,\n",
      "        1.6071, 0.8756, 1.7124, 0.5824, 1.1479, 1.4927, 2.0103, 2.0225, 1.9857,\n",
      "        2.7364, 1.2811, 1.2746, 2.1422, 1.8895, 1.9499, 1.4402, 1.6183, 3.1187,\n",
      "        1.9718, 2.5619, 1.4103, 1.3429, 1.3912, 1.1509, 0.9823, 1.5318, 1.4934,\n",
      "        1.6440, 2.0219, 2.4830, 1.9278, 1.6345, 1.8446, 1.4146, 1.5205, 1.4243,\n",
      "        1.4174, 2.0300, 1.1534, 0.9567, 1.6395, 1.8777, 2.8836, 1.5189, 2.1994,\n",
      "        1.2666, 1.3976, 1.0582, 1.1649, 1.9270, 1.5754, 1.6630, 1.6140, 2.6479,\n",
      "        2.0366, 1.0734, 1.9702, 1.6938, 3.8916, 2.8433, 2.3149, 1.1658, 1.8550,\n",
      "        2.3168, 3.7570, 1.6170, 2.4050, 1.3117, 0.4879, 2.2690, 1.1532, 1.7598,\n",
      "        1.8466, 1.9481, 2.0080, 1.9184, 1.1090, 1.1685, 1.9589, 1.8796, 1.7886,\n",
      "        2.2885, 1.6214, 1.5011, 0.8806, 2.4013, 1.5127, 2.3809, 1.4768, 3.2803,\n",
      "        1.0647, 1.6542, 2.0198, 2.1948, 1.7470, 2.0867, 0.7719, 2.0610, 1.7765,\n",
      "        1.0587, 1.6430, 2.2463, 2.0187, 1.5046, 2.3278, 2.1375, 2.7077, 0.4969,\n",
      "        1.3516, 1.6788, 1.9913, 1.6711, 2.1488, 1.1566, 1.8234, 1.3014, 1.9066,\n",
      "        1.8010, 1.7564, 1.8130, 2.2061, 1.0796, 0.8944, 0.8123, 1.0844, 2.0459,\n",
      "        2.0722, 2.1475, 1.3518, 1.8204, 2.0604, 1.3770, 1.6413, 2.5344, 1.7099,\n",
      "        1.1446, 1.3723, 1.4229, 1.6032, 2.1474, 0.9660, 1.5049, 1.9241, 0.8590,\n",
      "        1.7530, 1.3375, 1.3050, 2.0592, 1.9107, 1.6922, 2.1855, 1.7210, 1.8397,\n",
      "        0.9702, 1.4978, 1.4700, 2.1521, 2.0088, 1.7624, 1.4167, 1.4781, 1.2180,\n",
      "        2.0831, 1.9135, 0.7194, 0.7862, 0.5308, 2.5236, 2.2952, 1.7991, 0.6192,\n",
      "        0.9281, 1.7364, 1.9870, 2.3413, 2.0856, 1.8235, 0.8820, 1.5641, 0.4103,\n",
      "        0.9424, 1.6358, 1.5342, 1.8547, 1.0069, 1.5519, 2.0903, 1.4573, 1.1481,\n",
      "        1.2914, 1.5816, 1.4688, 1.4428, 1.9954, 1.2091, 0.0259, 2.1748, 1.1549,\n",
      "        1.9764, 2.0522, 1.5937, 2.5177, 1.4176, 1.1392, 1.8908, 2.3281, 1.9942,\n",
      "        1.8996, 1.6631, 2.6580, 0.4905, 1.7106, 1.2254, 2.6030, 1.5531, 1.0837,\n",
      "        0.9799, 1.4991, 2.1618, 1.4283, 2.2906, 2.1135, 1.2363, 1.8657, 0.8403,\n",
      "        0.9400, 1.6822, 0.7377, 1.3443, 1.3348, 2.1708, 1.4687, 0.4828, 2.6790,\n",
      "        0.7669, 1.4165, 1.5999, 1.8537, 1.2005, 1.4645, 2.3893, 3.4182, 2.0072,\n",
      "        1.3903, 2.3524, 0.8698, 3.0586, 1.2705, 1.6431, 2.3258, 2.0253, 1.8564,\n",
      "        1.0506, 1.7936, 3.1020, 2.0186, 0.7036, 1.5202, 0.6229, 3.0479, 1.8243,\n",
      "        2.0007, 1.5272, 1.3049, 2.1111, 1.9553, 1.8171, 3.2052, 1.6529, 1.5879,\n",
      "        1.5916, 2.8006, 2.7583, 2.4316, 1.7408, 1.4599, 1.5659, 1.3632, 2.0079,\n",
      "        1.8712, 1.2424, 1.6835, 2.0437, 1.3675, 1.4709, 1.4474, 1.7920, 1.5942,\n",
      "        2.5386, 0.8345, 1.8770, 1.3579, 2.0630, 2.8475, 1.7630, 1.3194, 1.8516,\n",
      "        2.2530, 1.5257, 1.9930, 1.1261, 1.7418, 1.1757, 1.7496, 1.3522, 2.4411,\n",
      "        2.5350, 2.8223, 1.7699, 1.5900, 1.0554, 1.2723, 2.0852, 1.6110, 2.4958,\n",
      "        1.1667, 2.0149, 1.3534, 1.2906, 1.6728, 1.2882, 1.5246, 1.2855, 1.5849,\n",
      "        1.8514, 1.8157, 3.1421, 1.7785, 1.6941, 2.0710], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.3442e+00, -1.2246e+00, -1.2722e+00, -1.1609e+00, -2.1822e+00,\n",
      "        -8.6610e-01,  1.3856e-01, -1.1584e+00, -2.2432e+00, -1.7560e+00,\n",
      "         4.2226e-01, -7.1551e-01, -3.3209e-01, -3.7005e-01, -1.0347e+00,\n",
      "        -8.4692e-01, -1.3538e+00, -1.5228e+00, -1.5544e+00, -4.7879e-01,\n",
      "        -4.6737e-01, -1.6440e-01, -4.0252e-01, -2.4265e+00, -2.3715e-01,\n",
      "        -1.1422e+00, -1.8037e-01, -1.7725e+00, -3.6185e-01, -9.2300e-01,\n",
      "        -4.7549e-01, -1.3656e+00, -1.0902e+00, -1.0763e+00, -1.0384e+00,\n",
      "        -4.7945e-01, -8.6024e-01, -7.7901e-01, -3.6167e-01, -4.0993e-01,\n",
      "        -6.3726e-01, -2.0000e+00, -1.7301e-01, -1.3080e+00, -1.9031e+00,\n",
      "        -5.3217e-01, -8.3107e-01, -1.3438e+00, -1.1383e+00, -4.0397e-01,\n",
      "        -1.0648e+00, -1.0898e+00, -4.4616e-01, -1.6043e-01, -1.2842e+00,\n",
      "        -4.0978e-01, -4.8365e-01, -1.9574e+00, -1.1637e+00, -1.3289e+00,\n",
      "        -3.8961e-01, -4.8128e-01, -3.5952e+00,  3.6632e-02, -2.4078e-01,\n",
      "        -1.7842e+00, -8.8329e-01, -1.2719e+00, -7.6350e-01, -1.3218e+00,\n",
      "        -1.0498e+00, -6.2052e-01, -1.7579e-01, -1.8481e+00, -8.1086e-01,\n",
      "        -1.3363e+00, -9.3498e-01,  1.9280e-01, -1.2316e+00, -8.2553e-01,\n",
      "        -1.0406e+00, -2.3314e+00, -6.3612e-01, -8.9527e-01, -2.7237e-02,\n",
      "        -1.8100e+00, -1.4292e+00, -1.7333e+00, -4.3487e-01, -1.9802e+00,\n",
      "        -1.1213e+00, -6.4512e-01, -1.5932e+00, -5.9101e-01, -6.0909e-01,\n",
      "        -1.0289e+00, -9.8121e-01, -7.0404e-01, -1.4585e+00, -1.1331e+00,\n",
      "        -5.9593e-01, -3.1693e-01, -5.3435e-01, -4.4639e-01, -1.4602e+00,\n",
      "        -8.2916e-01,  1.9503e-01, -2.4392e+00, -2.1855e+00, -2.2222e-01,\n",
      "        -7.2010e-01, -1.7490e-01, -1.4979e+00, -2.4511e+00, -6.0253e-01,\n",
      "        -1.5305e+00, -2.4446e-01, -1.1229e+00, -1.2978e+00, -8.0934e-01,\n",
      "        -7.7910e-01, -1.4801e-01, -8.2676e-01, -2.2386e-01, -7.4126e-01,\n",
      "        -2.0470e+00, -2.7174e-01, -8.1343e-01, -4.8070e-01, -1.0349e+00,\n",
      "        -1.3994e-01, -1.4621e-01, -1.6901e+00, -1.5711e+00, -6.4722e-01,\n",
      "        -1.9985e+00, -1.3243e+00, -1.2073e+00, -9.9657e-01, -1.2032e+00,\n",
      "        -9.0191e-01, -2.6406e+00, -1.1281e+00, -4.2375e-01, -4.3354e-02,\n",
      "        -1.1254e+00,  8.0928e-03, -2.0691e+00, -5.1813e-01, -1.0920e+00,\n",
      "        -5.7540e-01, -1.6679e+00, -6.3144e-01, -6.5617e-01, -2.6692e-01,\n",
      "        -1.4462e+00,  6.6429e-02, -6.8286e-01, -1.6710e+00, -1.5339e+00,\n",
      "        -8.1005e-01, -1.1830e-01, -1.2099e+00, -1.5828e+00, -4.0237e-01,\n",
      "        -4.2372e-01, -5.4963e-01, -5.4428e-01, -3.7710e+00, -2.0868e+00,\n",
      "        -1.3913e+00, -8.5420e-01, -6.2563e-01, -6.7567e-01, -2.3827e+00,\n",
      "        -2.6695e+00, -3.6129e-01, -3.7895e-01, -1.0944e+00, -9.7308e-01,\n",
      "        -1.2782e+00, -1.5243e+00, -1.2978e+00, -7.0021e-01, -3.0047e-01,\n",
      "        -9.3313e-01, -1.6867e+00, -3.6473e-01, -4.6280e-01, -1.4890e+00,\n",
      "        -2.9668e-01, -8.2498e-01, -1.3533e+00, -8.2437e-01, -8.0954e-02,\n",
      "        -1.2231e+00, -1.3771e+00, -1.1299e-01, -2.2276e-01, -2.0697e-01,\n",
      "        -1.5523e-01, -8.9103e-01, -8.3176e-01, -5.5401e-01, -2.0119e+00,\n",
      "         2.2077e-01, -8.4315e-01, -2.0618e-01, -4.1128e-01, -4.8487e-01,\n",
      "        -1.5445e+00, -1.6139e-01, -2.7352e-01, -1.1829e+00, -9.1690e-01,\n",
      "        -2.0815e+00, -1.0338e-01, -3.6109e-01, -1.0358e+00, -1.5467e+00,\n",
      "        -8.7063e-01, -3.3016e-01, -6.9289e-01, -1.0585e+00, -2.1829e+00,\n",
      "        -9.2312e-01, -1.6369e-01, -1.1204e+00, -1.2689e+00, -1.0787e+00,\n",
      "        -1.6718e+00, -1.5318e+00, -7.7621e-01, -9.1868e-01, -9.3632e-01,\n",
      "        -6.7970e-01, -8.0679e-01, -4.3765e-01, -5.6362e-01, -2.3499e+00,\n",
      "        -8.3763e-01, -7.2690e-01, -1.2453e+00, -8.7086e-01, -1.7352e+00,\n",
      "        -2.9770e-01, -4.9752e-01, -1.6532e+00,  9.6439e-02, -4.8601e-02,\n",
      "        -8.9674e-02, -1.4777e-01, -2.4359e-01,  6.5700e-02, -1.5504e+00,\n",
      "        -1.4194e+00, -2.4555e-01, -1.1011e+00, -1.4549e+00, -8.4205e-01,\n",
      "        -2.4138e+00, -2.0316e+00, -6.3217e-01, -1.1355e+00, -2.6151e+00,\n",
      "        -6.5119e-01, -1.1894e+00, -1.2077e+00, -2.8840e-02, -1.3715e+00,\n",
      "        -8.6295e-01, -6.9809e-01, -6.2337e-01, -9.9723e-02, -1.2794e+00,\n",
      "        -1.9232e-01, -1.9753e+00, -1.6435e+00, -4.1886e-02, -1.3931e+00,\n",
      "         2.8825e-02, -2.1244e-01, -1.6912e+00, -1.1296e+00, -4.2708e-01,\n",
      "        -3.2912e-01, -7.3797e-01, -8.6409e-01, -1.5101e+00, -6.6211e-01,\n",
      "        -6.0661e-01, -1.0056e+00, -1.1848e+00, -1.4008e+00, -1.0285e+00,\n",
      "         2.5294e-01, -3.2734e+00, -8.7597e-01, -6.1152e-01, -1.7355e+00,\n",
      "        -2.0610e+00, -2.0118e+00, -1.8743e+00, -3.2441e-01, -2.1922e+00,\n",
      "        -7.0390e-01, -7.3568e-01, -4.9638e-01, -2.7518e+00, -1.0137e+00,\n",
      "        -1.2868e+00, -6.8938e-01, -1.6854e-01, -8.5276e-01, -5.0975e-01,\n",
      "        -4.2002e-01, -1.6545e+00, -4.5534e-01, -7.9695e-01, -1.3597e+00,\n",
      "        -3.5151e-01, -1.3201e+00, -3.3478e-01, -6.1377e-01, -2.5000e-01,\n",
      "        -1.5190e+00,  1.6079e-01, -3.8333e-01, -3.3497e-01, -4.4720e-01,\n",
      "        -8.2437e-01, -1.6206e+00, -1.8542e+00,  2.4097e-01, -6.2656e-01,\n",
      "        -4.6062e-01, -2.5877e-01, -2.0569e+00, -6.8256e-01, -2.0969e+00,\n",
      "        -1.7879e+00, -1.3009e+00, -2.3772e+00, -6.2820e-01, -8.4945e-01,\n",
      "        -8.5283e-01, -1.6536e+00, -1.4393e+00, -2.2462e-01, -1.4037e+00,\n",
      "        -1.3897e+00, -8.9339e-02, -1.2741e+00, -1.2685e+00, -8.1073e-02,\n",
      "        -1.2637e+00, -8.5042e-01, -1.3580e+00, -3.2262e-01, -9.8574e-01,\n",
      "        -1.4008e+00, -2.7345e-02, -4.5091e-01, -8.8288e-01, -1.1874e+00,\n",
      "        -2.0070e+00, -7.2446e-01, -1.9800e+00, -1.0777e+00, -8.4035e-01,\n",
      "        -3.3649e-02, -1.7561e-01, -9.8927e-01, -6.0380e-01, -2.1018e-01,\n",
      "        -7.2359e-01, -1.5823e+00, -1.5047e+00, -1.7303e+00, -1.1324e+00,\n",
      "        -7.1070e-01, -1.6065e+00, -1.4791e+00, -1.6241e+00, -6.2461e-01,\n",
      "        -3.1261e-01, -2.2185e+00, -4.5334e-01, -1.2729e+00, -1.3871e+00,\n",
      "        -1.1596e+00, -1.3604e+00, -9.6492e-01, -9.6384e-01, -9.3271e-01,\n",
      "        -7.7093e-01, -7.9622e-01, -8.9258e-03, -1.2473e-02,  5.8492e-01,\n",
      "        -1.7750e+00, -1.6609e+00, -2.6397e+00, -1.3574e+00, -1.7476e+00,\n",
      "        -1.2434e-01, -9.3980e-01, -5.8686e-01, -1.1235e-01, -1.1538e+00,\n",
      "        -3.4501e-01, -1.2201e+00, -9.3229e-01, -1.0583e+00, -6.7254e-01,\n",
      "        -2.3147e+00, -7.7608e-01, -5.4991e-01, -1.1530e+00, -1.3319e+00,\n",
      "        -1.9485e+00, -1.2106e+00, -1.0636e+00, -6.0409e-01, -4.6143e-01,\n",
      "        -1.5657e+00, -2.5148e+00, -9.0535e-01,  1.3492e-03, -1.1993e+00,\n",
      "        -1.5029e+00, -2.7376e-02, -1.7205e+00, -1.7144e+00, -2.1379e-01,\n",
      "        -1.8555e+00, -1.4962e+00, -1.1979e+00, -1.3700e+00, -9.4763e-01,\n",
      "        -1.9134e+00, -2.1659e+00, -7.5120e-01, -1.2160e+00, -6.9088e-01,\n",
      "        -1.0272e-01, -1.3192e+00, -1.1297e+00, -1.1611e+00, -1.0580e+00,\n",
      "        -1.2468e+00, -1.8592e+00, -1.4068e+00, -2.1151e+00, -3.3940e-01,\n",
      "        -1.2478e+00, -1.5030e+00, -6.0302e-01, -1.0240e+00, -8.1533e-01,\n",
      "        -2.3692e+00, -8.9628e-01, -1.1041e+00, -3.4538e-01, -6.9191e-02,\n",
      "        -2.1001e+00, -1.1679e+00, -8.5521e-01, -1.6091e+00, -1.2143e+00,\n",
      "        -1.1799e+00, -6.6584e-01, -2.4090e+00, -1.1554e+00, -1.6655e-01,\n",
      "        -6.0638e-01, -1.7851e+00, -9.5926e-02, -1.9419e+00, -7.8344e-01,\n",
      "        -1.8020e+00, -1.4984e+00, -4.7306e-01, -2.0638e+00, -4.6192e-01,\n",
      "        -2.5581e+00, -8.4392e-01, -3.4734e-01, -1.3290e+00, -7.5696e-02,\n",
      "        -5.7586e-01, -2.8793e-01, -1.2929e+00, -1.3477e+00, -1.7606e+00,\n",
      "        -4.0084e-01, -6.3428e-01, -1.1555e+00, -5.9988e-01, -1.9285e+00,\n",
      "        -2.3167e+00, -7.7042e-01, -1.7393e+00, -1.0813e+00, -1.1489e+00,\n",
      "        -3.7756e-01, -4.0699e-01, -1.3384e+00,  5.7438e-01, -1.8502e-01,\n",
      "        -2.7269e-01, -1.1836e+00, -2.4755e+00, -6.7675e-01, -1.7906e+00,\n",
      "        -1.6010e+00, -1.3947e+00, -1.2340e+00, -7.0536e-01, -3.0333e-01,\n",
      "        -6.1160e-01, -1.9503e+00, -8.7319e-01, -1.5746e+00, -7.1749e-01,\n",
      "        -4.8522e-01, -6.8156e-01, -7.6693e-01, -5.8123e-01, -2.0361e-01,\n",
      "        -1.1759e+00, -4.0329e-01, -4.9723e-01,  1.9625e-01, -1.4653e-01,\n",
      "        -2.1663e-01, -7.6319e-01, -1.0950e+00, -1.0216e+00, -7.3355e-01,\n",
      "        -1.4947e+00, -1.8244e+00, -9.1550e-01, -6.4175e-02,  1.3256e-01,\n",
      "        -8.1636e-03, -1.4657e+00, -3.6111e-01, -1.9770e-01, -1.6666e+00,\n",
      "         3.7861e-01, -9.0038e-01, -1.1496e+00, -4.0436e-01, -8.5333e-02,\n",
      "        -1.8957e+00, -1.1628e+00, -9.8398e-01, -4.7949e-01, -1.6866e+00,\n",
      "        -1.3802e+00, -5.9561e-01, -2.2971e+00, -7.0442e-01, -1.3596e+00,\n",
      "        -7.2374e-01, -7.0008e-01, -1.0803e+00, -1.9789e+00, -9.9115e-01,\n",
      "        -3.3983e-01, -8.1686e-01, -6.1674e-01, -1.4451e-01, -4.6521e-01,\n",
      "        -6.4051e-01, -2.3213e-01, -2.9582e+00, -1.6032e+00, -7.4373e-01,\n",
      "        -1.5786e+00, -1.1389e+00, -2.7875e-01, -1.5868e+00, -1.1675e+00,\n",
      "        -5.0278e-01, -8.9638e-01, -5.4633e-01, -1.3894e+00, -5.5245e-01,\n",
      "        -2.1661e+00, -1.6214e+00, -8.9641e-01, -1.8862e-01, -2.3777e+00,\n",
      "        -9.3036e-01, -1.3115e+00, -1.7771e+00, -2.1294e+00,  5.7103e-01,\n",
      "        -9.4275e-01, -4.9937e-01, -1.4099e+00, -8.7334e-01, -1.5062e+00,\n",
      "        -8.0155e-01, -1.1778e+00, -4.4589e-01, -4.7304e-01, -1.9243e-01,\n",
      "        -1.5961e-01, -1.3204e+00, -1.1423e+00, -1.2801e+00, -1.5134e+00,\n",
      "        -1.2446e+00, -1.1954e+00, -8.7546e-01, -1.5124e+00, -1.2618e+00,\n",
      "        -7.1600e-01,  7.2514e-01, -7.5205e-01, -1.4679e+00, -5.5663e-01,\n",
      "        -1.0289e+00, -6.8963e-01, -7.9586e-01, -1.0179e+00, -4.6073e-01,\n",
      "        -1.5328e+00, -5.5027e-01, -2.2776e+00, -1.2882e+00, -7.7634e-01,\n",
      "        -1.6087e+00, -5.9067e-01, -5.2343e-01, -9.1196e-01, -4.3339e-01,\n",
      "        -6.6861e-01, -1.1955e+00, -1.3539e+00, -9.4197e-01, -8.7550e-01,\n",
      "        -2.8849e+00, -9.4541e-01, -8.4864e-01, -1.0838e+00, -1.5560e+00,\n",
      "        -1.3114e+00, -1.6820e-01, -7.5854e-02, -2.3120e+00, -1.3897e+00,\n",
      "        -1.4525e+00, -3.2737e-02,  7.0655e-04, -1.6857e+00, -1.1410e+00,\n",
      "        -1.8021e+00, -1.1039e+00, -3.4167e-02, -3.3400e-01, -1.1313e+00,\n",
      "         4.6662e-02,  1.7146e-01, -1.7675e+00, -7.5126e-01, -1.3329e+00,\n",
      "        -6.9335e-01, -5.1160e-01, -1.0945e+00, -2.0902e+00, -3.4678e-01,\n",
      "        -8.6534e-02, -1.4958e+00, -1.0357e+00, -3.5810e-01, -1.7285e+00,\n",
      "        -4.1970e-01, -1.7847e-02, -9.5028e-01, -3.6289e-01, -1.0160e+00,\n",
      "        -8.9338e-01,  3.8853e-01, -3.4165e-01, -1.0251e+00, -3.4384e-01,\n",
      "        -1.4161e+00, -1.0100e+00, -1.1011e+00, -1.9915e+00, -5.7081e-01,\n",
      "        -2.3394e+00, -2.6519e-01, -1.4519e+00, -1.6668e+00, -8.2902e-02,\n",
      "        -7.4336e-01, -2.6193e-01, -2.5211e-01, -6.9303e-01, -7.0557e-01,\n",
      "        -1.4214e+00, -1.6179e+00, -4.9423e-01, -5.7454e-01, -9.2860e-01,\n",
      "        -1.4454e-01, -1.4619e+00, -5.7384e-01, -1.2574e-02, -6.4825e-01,\n",
      "        -2.1282e-01, -1.7607e+00, -7.7926e-01, -1.6478e-01, -1.3731e+00,\n",
      "        -2.2433e-01, -1.4544e+00, -1.2497e+00, -1.4721e+00, -5.8658e-01,\n",
      "        -7.3076e-01, -9.2610e-01, -8.7442e-01, -1.3140e+00, -1.3754e+00,\n",
      "        -1.0449e+00,  6.5903e-02, -8.6541e-01, -7.8917e-01, -2.3337e+00,\n",
      "        -2.1697e+00, -1.0894e+00, -1.9511e+00, -4.9816e-01, -1.6416e+00,\n",
      "         1.9311e-01, -3.4424e+00, -6.1245e-02, -1.4695e-01, -1.3048e-01,\n",
      "        -6.9819e-01, -1.3974e+00, -2.3723e+00, -1.3566e+00, -7.8811e-01,\n",
      "        -1.1041e+00, -1.4669e+00, -3.5693e-01, -1.3232e+00, -1.2723e+00,\n",
      "        -1.8498e+00, -3.2124e+00, -5.4087e-01, -1.5837e+00, -4.3120e-01,\n",
      "        -7.6538e-01, -2.0878e+00, -1.6504e+00, -2.6030e-01, -1.6825e+00,\n",
      "        -1.0732e+00, -2.6575e-01, -8.6287e-02, -1.3478e+00, -4.0043e-01,\n",
      "        -1.4130e-01, -6.8041e-01, -8.8065e-01, -2.4226e+00, -4.4861e-01,\n",
      "        -4.6414e-01, -2.2165e+00, -1.6557e+00, -7.6417e-01, -1.1787e+00,\n",
      "        -1.2921e+00, -9.9500e-01, -1.0004e+00, -1.7840e+00, -9.7938e-01,\n",
      "        -1.8411e+00, -5.0137e-01, -1.4835e+00,  6.4734e-02, -1.9276e+00,\n",
      "        -7.5131e-01, -1.4054e+00, -1.1840e+00,  2.7083e-01, -1.5285e+00,\n",
      "        -1.3365e+00, -4.6152e-01, -1.0404e+00, -1.2988e+00, -1.5491e+00,\n",
      "        -1.1277e+00, -2.9555e-01, -1.6358e+00, -4.0692e-01, -5.5252e-01,\n",
      "        -1.1447e+00, -8.0873e-01, -1.0520e+00, -4.8533e-01, -2.0933e+00,\n",
      "        -1.3863e+00, -1.7628e+00, -3.8752e-01, -6.6351e-01, -9.1695e-01,\n",
      "        -8.3336e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2049]],\n",
      "\n",
      "         [[ 0.1605]],\n",
      "\n",
      "         [[-0.0784]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3321]],\n",
      "\n",
      "         [[ 0.1581]],\n",
      "\n",
      "         [[ 0.3579]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3677]],\n",
      "\n",
      "         [[ 0.3180]],\n",
      "\n",
      "         [[-0.0419]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4308]],\n",
      "\n",
      "         [[-0.2965]],\n",
      "\n",
      "         [[-0.1441]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2960]],\n",
      "\n",
      "         [[-0.1090]],\n",
      "\n",
      "         [[ 0.1818]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2380]],\n",
      "\n",
      "         [[ 0.0483]],\n",
      "\n",
      "         [[ 0.5803]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.5938]],\n",
      "\n",
      "         [[-0.1349]],\n",
      "\n",
      "         [[ 0.1440]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4146]],\n",
      "\n",
      "         [[-0.3534]],\n",
      "\n",
      "         [[-0.6045]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1712]],\n",
      "\n",
      "         [[-0.4599]],\n",
      "\n",
      "         [[ 0.3052]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3645]],\n",
      "\n",
      "         [[ 0.0626]],\n",
      "\n",
      "         [[ 0.2619]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0134]],\n",
      "\n",
      "         [[-0.4031]],\n",
      "\n",
      "         [[-0.0729]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1771]],\n",
      "\n",
      "         [[ 0.1863]],\n",
      "\n",
      "         [[ 0.7770]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1434,  0.1022,  0.0816,  0.0948,  0.0492,  0.0269,  0.1198, -0.1353,\n",
      "         0.2078, -0.0554,  0.2088,  0.1115,  0.1185,  0.1177,  0.1027,  0.2433,\n",
      "        -0.0858, -0.0486, -0.2275,  0.0537,  0.1132,  0.0131,  0.0524,  0.0318,\n",
      "         0.1886,  0.0886,  0.0446,  0.0768,  0.0632, -0.2968,  0.0632,  0.2654,\n",
      "         0.1900,  0.1645], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2680]],\n",
      "\n",
      "         [[-0.2252]],\n",
      "\n",
      "         [[ 0.1049]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2417]],\n",
      "\n",
      "         [[-0.0422]],\n",
      "\n",
      "         [[-0.2983]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0295]],\n",
      "\n",
      "         [[-0.1320]],\n",
      "\n",
      "         [[-0.4598]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2246]],\n",
      "\n",
      "         [[-0.5865]],\n",
      "\n",
      "         [[-0.5320]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1603]],\n",
      "\n",
      "         [[ 0.1760]],\n",
      "\n",
      "         [[ 0.0729]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1915]],\n",
      "\n",
      "         [[-0.4314]],\n",
      "\n",
      "         [[-0.1600]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4166]],\n",
      "\n",
      "         [[ 0.3665]],\n",
      "\n",
      "         [[-0.6100]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0717]],\n",
      "\n",
      "         [[ 0.2981]],\n",
      "\n",
      "         [[-0.1793]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0663]],\n",
      "\n",
      "         [[ 0.1328]],\n",
      "\n",
      "         [[ 0.1117]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2296]],\n",
      "\n",
      "         [[ 0.1274]],\n",
      "\n",
      "         [[-0.3444]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0195]],\n",
      "\n",
      "         [[-0.2418]],\n",
      "\n",
      "         [[-0.0423]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0437]],\n",
      "\n",
      "         [[-0.2210]],\n",
      "\n",
      "         [[-0.2387]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.2635, -0.2918, -0.2084,  0.5060,  0.2517, -0.1032, -0.0198,  0.4447,\n",
      "         0.1684,  0.3138,  0.3385,  0.1855,  0.5183,  0.1410,  0.2441, -0.3185,\n",
      "        -0.2793,  0.4332,  0.4739, -0.2482, -0.2442, -0.0864, -0.2767,  0.0400,\n",
      "         0.3035, -0.1812,  0.0297, -0.1166,  0.3401,  0.1538,  0.3975,  0.0849,\n",
      "         0.2330,  0.2306,  0.2584, -0.0834, -0.1008,  0.3801,  0.2366,  0.0359,\n",
      "         0.0890,  0.1817,  0.1119,  0.3953, -0.2001,  0.1360,  0.0191,  0.2272,\n",
      "        -0.1654,  0.0881, -0.3000,  0.3410,  0.0743, -0.2872,  0.2472, -0.1932,\n",
      "        -0.2751,  0.4252,  0.0861,  0.0168,  0.5582, -0.2938,  0.5402, -0.2938,\n",
      "        -0.2257, -0.3262, -0.1946, -0.1843, -0.2627,  0.0626, -0.3894,  0.2213,\n",
      "         0.3699, -0.1620, -0.0083, -0.3856, -0.0627, -0.3688,  0.3011,  0.0904,\n",
      "         0.3598,  0.0696,  0.0273, -0.1852, -0.5222, -0.2472,  0.2469,  0.0908,\n",
      "         0.0209,  0.1411,  0.4508,  0.4903,  0.2525,  0.0258, -0.4613,  0.2010,\n",
      "        -0.2217, -0.0017, -0.3684, -0.0573, -0.2326,  0.0367, -0.1005,  0.3988,\n",
      "         0.2428, -0.1577, -0.1247,  0.0414,  0.1280,  0.4064, -0.2660, -0.5502,\n",
      "         0.3382, -0.0161,  0.4413, -0.4096, -0.0284, -0.2795,  0.2166, -0.2136,\n",
      "         0.0462,  0.0540, -0.3386, -0.3473,  0.0630, -0.1552,  0.2129, -0.4141,\n",
      "        -0.2000,  0.1909,  0.0724, -0.5323,  0.1906,  0.3305,  0.1992,  0.2986,\n",
      "         0.0638, -0.4636,  0.1483, -0.0765,  0.2632, -0.0178, -0.0131,  0.1162,\n",
      "        -0.3395,  0.2801,  0.0604, -0.1690, -0.0787, -0.1286, -0.3826, -0.3728,\n",
      "        -0.1565, -0.0770,  0.4000,  0.0933, -0.0373,  0.0768,  0.3086, -0.0196,\n",
      "         0.0416, -0.1337,  0.2960, -0.3708,  0.0161,  0.0988,  0.1774, -0.2613,\n",
      "         0.1034,  0.0241,  0.0366, -0.1044,  0.5020,  0.1930,  0.2049, -0.1339,\n",
      "        -0.4715, -0.0453, -0.1638,  0.0382,  0.4318,  0.3060, -0.2430, -0.3456,\n",
      "        -0.3668, -0.4234,  0.4300, -0.6233,  0.2796, -0.0130, -0.5068, -0.1048,\n",
      "         0.0640,  0.3425, -0.2981, -0.2889, -0.1012,  0.3928,  0.2149, -0.1793,\n",
      "         0.0565, -0.4213, -0.0731, -0.3222, -0.0577,  0.4187, -0.3018,  0.1757,\n",
      "        -0.0216, -0.0603,  0.2303, -0.0865, -0.0092, -0.3099, -0.2937, -0.0664,\n",
      "         0.1919, -0.1948,  0.3388,  0.2477, -0.4754,  0.0789,  0.1134, -0.4246,\n",
      "         0.1616, -0.0494, -0.2611,  0.4030,  0.0538, -0.2584,  0.0009,  0.3241,\n",
      "         0.3689, -0.3810,  0.3524,  0.2354, -0.1037,  0.0295, -0.4114, -0.3405,\n",
      "        -0.1683,  0.0094, -0.0282,  0.2356,  0.0116,  0.0408, -0.4948,  0.3368,\n",
      "        -0.0898, -0.1579, -0.3474, -0.5677, -0.0553,  0.1566,  0.3655,  0.1762,\n",
      "         0.0565,  0.2749, -0.3192, -0.0520, -0.1318,  0.3247, -0.1108, -0.2419,\n",
      "        -0.4951, -0.0961,  0.3132, -0.4948,  0.1163,  0.1045, -0.0132,  0.0923,\n",
      "        -0.3718,  0.0203, -0.2625,  0.2939, -0.2744,  0.3316, -0.2797, -0.3585,\n",
      "        -0.4596, -0.1277, -0.0261,  0.1683, -0.3889,  0.0424,  0.2759,  0.0843,\n",
      "        -0.2983, -0.3186,  0.4790, -0.0062, -0.0541, -0.2394,  0.0842, -0.1847,\n",
      "         0.2483, -0.5906, -0.0900, -0.1217, -0.2406,  0.1410, -0.0013, -0.3639,\n",
      "         0.0026, -0.1997, -0.1386, -0.1825,  0.2993, -0.4925, -0.0681, -0.2030,\n",
      "         0.1577,  0.0863, -0.0188,  0.1723,  0.2579,  0.0263,  0.0620,  0.4038,\n",
      "        -0.5563,  0.0556, -0.3791, -0.3455,  0.0824,  0.4540, -0.2892,  0.2798,\n",
      "        -0.0437, -0.2796,  0.3981,  0.1421,  0.5202,  0.0053, -0.1573,  0.0214,\n",
      "         0.1780,  0.5600, -0.0787, -0.1371,  0.3867,  0.3299, -0.3797, -0.2989,\n",
      "        -0.0289, -0.3704,  0.0592,  0.4523,  0.1094, -0.2353, -0.0440, -0.1477,\n",
      "         0.3030, -0.0503, -0.3224, -0.4648,  0.2516, -0.0794,  0.4861,  0.4611,\n",
      "         0.1583,  0.1371, -0.3154,  0.3998,  0.3242,  0.2026, -0.0590, -0.4620,\n",
      "        -0.4643,  0.0680,  0.4149, -0.3804,  0.0979, -0.0292,  0.5933,  0.2384,\n",
      "        -0.1062,  0.4013,  0.1911,  0.3910, -0.2114,  0.4836,  0.1794, -0.2993,\n",
      "        -0.0050, -0.0094,  0.1564,  0.1123,  0.1598,  0.1467, -0.1224, -0.1722,\n",
      "        -0.2237, -0.3775, -0.3924,  0.2975, -0.0178,  0.7271, -0.2779,  0.4528,\n",
      "         0.0410,  0.1155,  0.0978,  0.0025,  0.0733,  0.1197,  0.0999,  0.0713,\n",
      "        -0.2078, -0.1124,  0.2129, -0.0230,  0.1015,  0.3950, -0.4181,  0.1142,\n",
      "        -0.2580, -0.4107,  0.0588, -0.3680, -0.0877, -0.2709, -0.2967,  0.2038,\n",
      "         0.2082,  0.4317, -0.0550,  0.2306, -0.1224,  0.0850,  0.2486,  0.2324,\n",
      "         0.0321,  0.5342,  0.2476, -0.3580,  0.4522,  0.4312,  0.4584,  0.3394,\n",
      "         0.0812,  0.4157, -0.1708, -0.1393,  0.3234, -0.0905, -0.2949, -0.2527,\n",
      "         0.4964, -0.0983, -0.3208,  0.0033, -0.3025, -0.0956,  0.2943, -0.0444,\n",
      "        -0.1814, -0.0846,  0.1979, -0.1934,  0.0695, -0.2398,  0.2289,  0.4082,\n",
      "         0.0766,  0.0610, -0.0532,  0.0256, -0.0105,  0.0281, -0.4012, -0.1293,\n",
      "         0.1799, -0.1155, -0.0510, -0.1142, -0.2757, -0.1142,  0.2272,  0.2032,\n",
      "        -0.5216,  0.1086, -0.1763, -0.0165, -0.0072,  0.6635, -0.0898, -0.5233,\n",
      "         0.4920, -0.0061, -0.3366, -0.1578, -0.2965,  0.1121,  0.2636, -0.0261,\n",
      "        -0.4109, -0.5449, -0.0776, -0.1315,  0.4399, -0.2809,  0.2541,  0.1158,\n",
      "        -0.3325, -0.1133, -0.2738, -0.1212, -0.1589, -0.0429, -0.0571, -0.1576,\n",
      "        -0.3152, -0.1352,  0.4143,  0.0907,  0.4170,  0.1585, -0.0463, -0.2078,\n",
      "        -0.0813, -0.1007, -0.4025, -0.3638,  0.1034, -0.3105, -0.2030, -0.2027,\n",
      "         0.0980,  0.1667,  0.0499, -0.5212,  0.0458,  0.3409, -0.0726,  0.2636,\n",
      "         0.1618, -0.1828,  0.1657, -0.4355,  0.0665,  0.1137, -0.3367,  0.1243,\n",
      "        -0.2505, -0.0538,  0.2048,  0.2863,  0.1454, -0.0720,  0.0162,  0.3543,\n",
      "         0.4103, -0.4890, -0.2951,  0.5098, -0.0152,  0.2207,  0.0412, -0.1527,\n",
      "         0.3537,  0.0029, -0.1626, -0.2735, -0.1212,  0.4764, -0.1353,  0.6165,\n",
      "         0.1661,  0.4233, -0.1485,  0.2521, -0.0816, -0.6074, -0.1354, -0.1296,\n",
      "         0.3130,  0.0321,  0.2792, -0.1951, -0.1345,  0.1285, -0.3276,  0.1375,\n",
      "         0.2269, -0.0775,  0.1082,  0.5764,  0.1879, -0.0668,  0.2430,  0.0821,\n",
      "         0.0304,  0.0094,  0.1583, -0.0534,  0.3175, -0.4826, -0.3329, -0.2358,\n",
      "         0.3574,  0.0961, -0.1984,  0.0055, -0.3266, -0.0414, -0.0711, -0.0120,\n",
      "        -0.2515,  0.0304, -0.3556, -0.0485,  0.4677,  0.4994,  0.6690, -0.3415,\n",
      "        -0.0138,  0.1906, -0.2681,  0.4795, -0.5409,  0.2093, -0.3391, -0.2828,\n",
      "         0.6640, -0.5488,  0.0114, -0.2281,  0.2640,  0.1354,  0.4431, -0.2620,\n",
      "         0.2254,  0.4609, -0.0689,  0.0877,  0.1193, -0.1422,  0.3171, -0.3674,\n",
      "        -0.0740, -0.3903, -0.1090,  0.2364, -0.1151, -0.2254, -0.2659, -0.2421,\n",
      "        -0.5288, -0.2118, -0.1901,  0.1270, -0.2942, -0.2005, -0.2600,  0.2374,\n",
      "         0.2032,  0.0938, -0.4127, -0.0741,  0.3439, -0.1131,  0.1017, -0.1028,\n",
      "         0.4942, -0.2612,  0.0196, -0.1654,  0.2972,  0.5766,  0.0014, -0.4517,\n",
      "         0.4475,  0.0884, -0.3336,  0.3379, -0.0111, -0.0547, -0.1616,  0.1775,\n",
      "        -0.2051, -0.2429,  0.4398,  0.0764, -0.3502,  0.0698,  0.6598,  0.0191,\n",
      "        -0.1184,  0.2205, -0.1951,  0.6187, -0.0541,  0.0245,  0.4488,  0.1000,\n",
      "         0.1321,  0.2648,  0.0029,  0.0320,  0.4086,  0.2156,  0.1391,  0.1378,\n",
      "        -0.2987,  0.0550, -0.0355,  0.3091, -0.4307, -0.1288,  0.3063,  0.0960,\n",
      "        -0.0869, -0.3692, -0.0077,  0.2058,  0.1931, -0.2335,  0.3730,  0.3107,\n",
      "         0.0232,  0.2397,  0.1508, -0.0627,  0.1552, -0.2568, -0.0979, -0.2152,\n",
      "        -0.1041, -0.0064,  0.1284, -0.2654, -0.0078, -0.2309,  0.0107, -0.1288,\n",
      "        -0.2795,  0.0173, -0.5077,  0.1222,  0.1363,  0.3367,  0.0021, -0.3230,\n",
      "        -0.3497, -0.1192,  0.2950,  0.2008, -0.3210, -0.1877,  0.2807,  0.0088,\n",
      "         0.3592, -0.1102, -0.3613, -0.3048, -0.3436, -0.2123,  0.0734,  0.0595,\n",
      "        -0.2961,  0.0419, -0.3263, -0.2437,  0.0744,  0.0669, -0.0406,  0.4693,\n",
      "         0.1787,  0.3034,  0.1414,  0.0891,  0.2364,  0.6539, -0.0864, -0.0410,\n",
      "        -0.0146, -0.0549, -0.1331, -0.0983,  0.0847,  0.0305,  0.2120,  0.2272,\n",
      "        -0.1478,  0.2272, -0.0291, -0.1696,  0.3794, -0.5612, -0.5302,  0.1584,\n",
      "         0.1002, -0.4080,  0.2313,  0.1118, -0.3177, -0.3104, -0.0583,  0.2390,\n",
      "        -0.2615,  0.5404,  0.1517,  0.0547, -0.1577,  0.2605, -0.2003,  0.0574,\n",
      "         0.4250,  0.0795, -0.2581, -0.0373, -0.0740, -0.4490, -0.2938, -0.2732],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0792]],\n",
      "\n",
      "         [[ 0.0070]],\n",
      "\n",
      "         [[ 0.2084]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3293]],\n",
      "\n",
      "         [[ 0.3123]],\n",
      "\n",
      "         [[-0.0099]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4160]],\n",
      "\n",
      "         [[ 0.2530]],\n",
      "\n",
      "         [[ 0.0303]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3901]],\n",
      "\n",
      "         [[-0.2543]],\n",
      "\n",
      "         [[-0.1773]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1074]],\n",
      "\n",
      "         [[ 0.6235]],\n",
      "\n",
      "         [[ 0.4033]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3019]],\n",
      "\n",
      "         [[-0.1559]],\n",
      "\n",
      "         [[ 0.2266]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1270]],\n",
      "\n",
      "         [[-0.0109]],\n",
      "\n",
      "         [[ 0.6548]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3763]],\n",
      "\n",
      "         [[-0.1378]],\n",
      "\n",
      "         [[-0.0315]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2137]],\n",
      "\n",
      "         [[ 0.1358]],\n",
      "\n",
      "         [[-0.0953]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0044]],\n",
      "\n",
      "         [[-0.0590]],\n",
      "\n",
      "         [[ 0.2447]]],\n",
      "\n",
      "\n",
      "        [[[-0.0842]],\n",
      "\n",
      "         [[ 0.2300]],\n",
      "\n",
      "         [[ 0.2693]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0110]],\n",
      "\n",
      "         [[-0.3993]],\n",
      "\n",
      "         [[ 0.1783]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 9.7573e-01,  4.5341e-01,  1.1281e+00,  1.0664e+00,  2.7585e-01,\n",
      "         5.5286e-01,  7.5158e-01,  3.3786e+00,  1.3011e+00,  2.7803e-01,\n",
      "         5.7739e-01,  7.7843e-01,  1.2007e+00,  4.1927e-01,  8.1692e-01,\n",
      "         2.1987e+00, -2.2803e-02,  9.8660e-01,  1.2494e+00,  7.0940e-01,\n",
      "         1.5144e+00,  6.1653e-01,  9.9120e-01,  1.8832e+00,  1.5465e+00,\n",
      "         1.2030e+00,  4.7841e-01,  3.8090e-01,  1.5391e-02,  2.0054e-01,\n",
      "         6.2302e-01,  2.2221e-01,  1.3788e+00,  7.8715e-01,  1.4627e+00,\n",
      "         3.9425e-01,  4.2794e-01,  7.6390e-01,  1.4248e-01,  8.4386e-01,\n",
      "         1.4626e+00,  9.0286e-01,  2.9334e-01,  3.5579e-01,  7.0178e-01,\n",
      "         1.6243e+00,  1.2812e+00,  2.3218e+00,  1.0382e+00,  1.5048e+00,\n",
      "         4.3762e+00,  3.8701e-01,  1.2092e+00,  2.8068e-01,  9.6995e-01,\n",
      "         6.1786e-01,  6.7805e-01,  6.2294e-01,  1.9874e+00,  7.3692e-01,\n",
      "         7.1857e-01,  4.7300e-01,  2.1314e-01,  1.6128e+00,  7.0748e-02,\n",
      "         3.7668e-01,  8.3726e-01,  4.7914e-01,  1.3991e+00,  2.7223e-01,\n",
      "         1.7837e+00,  1.8518e+00,  2.1382e+00,  6.3761e-01,  1.3162e+00,\n",
      "         5.8242e-01,  1.7088e+00,  2.6572e+00,  9.4888e-01,  1.5637e-01,\n",
      "         5.8280e-01,  4.8239e-01,  1.1841e+00,  1.0252e+00,  8.5668e-01,\n",
      "         1.1436e-01,  1.0907e+00,  7.3260e-01,  1.3456e+00,  6.1974e-01,\n",
      "         1.3143e+00,  1.7688e+00,  1.6666e+00,  1.2897e+00,  5.5690e-01,\n",
      "         1.1884e+00,  5.8598e-02,  3.7888e-01,  1.4704e+00,  4.0793e-01,\n",
      "         1.8127e+00,  4.4612e-01,  3.2474e-01,  6.3148e-01,  7.9228e-01,\n",
      "         4.5033e-01,  1.1824e+00,  1.4185e+00,  7.9140e-01,  1.1310e-01,\n",
      "         2.2531e+00,  1.1270e+00,  1.2679e+00,  1.2768e+00,  7.5048e-01,\n",
      "         1.2758e+00,  3.6960e-01,  1.8550e+00,  1.0081e+00,  8.8893e-01,\n",
      "         9.9148e-01,  1.0276e+00,  1.1345e+00,  1.2484e+00,  1.3321e+00,\n",
      "         1.5388e+00,  1.4195e+00, -2.6660e-06,  1.2630e+00,  1.3075e+00,\n",
      "         1.1703e+00,  1.2442e+00,  3.1474e-01,  1.9933e+00,  2.0780e+00,\n",
      "         1.3706e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1295, -0.2154, -0.0395, -0.0591,  0.3932, -0.1146,  0.0834, -1.9827,\n",
      "        -0.0695,  0.0126,  0.1944,  0.4730, -0.5211,  0.2739,  0.2539,  1.1226,\n",
      "         0.1641,  0.4365, -0.3358,  0.1311, -0.3208, -0.3568, -0.3771,  0.7221,\n",
      "        -0.6252,  1.3305,  0.1536, -0.2595,  0.7062, -0.2497,  0.2041, -0.2990,\n",
      "         0.2523,  0.0568, -0.0371, -0.4387,  0.0643, -0.0487, -0.3997, -0.2859,\n",
      "         0.3024, -0.1747, -0.0369,  0.2493, -0.4063,  1.0315,  0.1493,  0.8317,\n",
      "         0.1195,  0.3887, -0.4868, -0.3197,  0.2688,  0.0564,  0.0620,  0.2873,\n",
      "        -0.2987, -0.1646, -0.6753,  0.8759, -0.3903, -0.2490, -0.0564, -0.1868,\n",
      "         0.2727,  0.0108,  0.1209,  0.0979,  0.4692, -0.6413, -0.8281,  0.4164,\n",
      "         0.9092,  0.2626, -0.0092, -0.0963, -0.0613, -0.0475, -0.0953, -0.1402,\n",
      "         0.3093, -0.3053, -0.6407,  0.2598, -0.1465, -0.4377,  0.0033,  0.0772,\n",
      "         0.3965,  0.7088,  0.1058, -0.1984,  0.0365,  0.3123, -0.0480, -0.5253,\n",
      "        -0.3852,  0.0180, -0.0863,  0.2380,  1.0868,  0.1356,  0.0125,  0.0309,\n",
      "         0.5693,  0.0482, -0.9801, -0.5081, -0.0729, -0.0484,  0.6354, -0.0448,\n",
      "         0.0442, -0.3357,  0.1351,  0.1599,  0.2732, -1.2759,  0.3804,  0.0263,\n",
      "         0.3127,  0.4103,  0.3826, -0.4170, -0.2539,  0.1386,  0.1742,  0.0950,\n",
      "         0.4806,  0.1922, -0.1914, -0.2505, -0.3570,  1.0946,  0.6617,  0.1657],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.1132]],\n",
      "\n",
      "         [[ 0.4451]],\n",
      "\n",
      "         [[ 0.0893]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1535]],\n",
      "\n",
      "         [[-0.1957]],\n",
      "\n",
      "         [[ 0.1326]]],\n",
      "\n",
      "\n",
      "        [[[-0.0974]],\n",
      "\n",
      "         [[ 0.2236]],\n",
      "\n",
      "         [[ 0.2443]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3380]],\n",
      "\n",
      "         [[-0.0906]],\n",
      "\n",
      "         [[-0.4993]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4861]],\n",
      "\n",
      "         [[-0.5166]],\n",
      "\n",
      "         [[ 0.3608]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3674]],\n",
      "\n",
      "         [[-0.2782]],\n",
      "\n",
      "         [[ 0.1725]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.5707]],\n",
      "\n",
      "         [[ 0.7658]],\n",
      "\n",
      "         [[ 0.2240]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2694]],\n",
      "\n",
      "         [[-0.1433]],\n",
      "\n",
      "         [[-0.0773]]],\n",
      "\n",
      "\n",
      "        [[[-0.0291]],\n",
      "\n",
      "         [[ 0.7600]],\n",
      "\n",
      "         [[-0.1348]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4093]],\n",
      "\n",
      "         [[ 0.0019]],\n",
      "\n",
      "         [[-0.3008]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5721]],\n",
      "\n",
      "         [[-0.0372]],\n",
      "\n",
      "         [[-0.4853]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0153]],\n",
      "\n",
      "         [[-0.0773]],\n",
      "\n",
      "         [[ 0.4914]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.2644,  0.6726,  1.4319,  0.2849,  0.7432,  0.7622,  1.2225,  1.9601,\n",
      "         1.0273,  1.0515,  1.0536,  1.5047,  1.6113,  1.3577,  1.6378,  1.4306,\n",
      "         1.3726,  0.1744,  1.2787,  1.0566,  0.3035,  1.1289,  1.4014,  1.4173,\n",
      "         0.9709,  1.2125,  1.6001,  0.4962,  0.9565,  0.2592,  0.7881,  1.4164,\n",
      "         1.1500,  0.9881,  1.1373,  1.0927,  1.5314,  0.5765,  0.5622,  2.3786,\n",
      "         0.7067,  1.5316,  1.8387,  0.2221,  1.1012,  1.0594,  0.3240,  0.7984,\n",
      "         0.9811,  1.0758,  1.4154,  1.5194,  0.7513,  0.4143,  1.2768,  0.7272,\n",
      "         1.3805,  1.4090,  1.0192,  1.2227,  1.1560,  1.1573,  1.2049,  1.7039,\n",
      "         1.2103,  0.9931,  1.3221,  0.8085,  1.5992,  1.7372,  1.2510,  1.0899,\n",
      "         1.1977,  1.0406,  1.8897,  1.1569,  1.3328,  0.5499,  0.9619,  0.5683,\n",
      "         1.8855,  1.9025,  0.4595,  0.9923,  0.5801,  1.7646,  0.9049,  0.9387,\n",
      "         1.1174,  1.0057,  1.2977,  0.2778,  1.0610,  1.4217,  1.3386,  1.5415,\n",
      "         1.2111,  0.9372,  0.2323,  0.7572,  1.6948,  1.2909,  1.0177,  0.8790,\n",
      "         1.2726,  0.7490,  2.1601,  1.2286,  1.0791,  1.4398,  1.2141,  1.3040,\n",
      "         0.8674,  1.0942,  0.8525,  0.7887,  1.6531,  1.4395,  0.9820,  1.7741,\n",
      "         1.2952,  1.6174,  0.5443,  1.0858,  1.4290,  1.3526,  1.4029,  0.6321,\n",
      "         0.8650,  1.7431,  0.6834,  0.8274,  0.3988,  1.3882,  1.7603,  0.5694,\n",
      "         0.7314,  1.0054,  1.1565,  1.4115,  0.7862,  1.0591,  1.3249,  0.6219,\n",
      "         0.3302,  1.2702,  0.9562,  1.0847,  1.6275,  1.3949,  0.7979,  1.0732,\n",
      "         0.9445,  1.1638,  1.4664,  0.3725,  1.0455,  1.7644,  1.3620,  0.8126,\n",
      "         1.4147,  0.7623,  0.7576,  1.8503,  1.6116,  0.7209,  1.5382,  0.9923,\n",
      "         1.0885,  0.8132,  0.4596,  0.7796,  1.3844,  1.1582,  0.9183,  1.2717,\n",
      "         0.7713,  1.6015,  1.5701,  0.9727,  0.1511,  1.3715, -0.1157,  1.6318,\n",
      "         1.5708,  1.2005,  1.4671,  1.4969,  0.5654,  1.0049,  1.4652,  1.0327,\n",
      "         1.4920,  0.8258,  0.8581,  1.2047,  1.3312,  1.4639,  0.9590,  1.7264,\n",
      "         1.4132,  0.9644,  0.3959,  0.5370,  0.4735,  0.5023,  1.6807,  1.6193,\n",
      "         0.9528,  0.5286,  1.2956,  1.6003,  1.3934,  1.0482,  1.1319,  1.6228,\n",
      "         1.8044,  1.0443,  1.2091,  1.9697,  1.7361,  1.9837,  0.8877,  0.2589,\n",
      "         0.8134,  1.5876,  1.2442,  0.8758,  0.9789,  0.5514,  1.7043,  1.3759,\n",
      "         0.7839,  0.8523,  1.1636,  1.1899,  1.0443,  1.0621,  1.3430,  0.8847,\n",
      "         1.5091,  1.4520,  1.2015,  1.3464,  0.3920,  2.1236,  0.6351,  0.9642,\n",
      "         1.4873,  1.2493,  0.7698,  1.0718,  0.4918,  0.9773,  0.6254,  0.6710,\n",
      "         1.3382,  1.8521,  0.7679,  1.6753,  1.0699,  1.1491,  0.4717,  0.8208,\n",
      "         1.1788,  1.1685,  1.4425,  1.4569,  0.2117,  1.2183,  0.7725,  0.6943,\n",
      "         1.5041,  1.3208,  1.6401,  1.2073,  1.3744,  0.9957,  0.7958,  0.9910,\n",
      "         1.0440,  1.2323,  0.7283,  1.5022,  1.2530,  0.5134,  1.1636,  0.9411,\n",
      "         1.5976,  1.1171,  0.9647,  0.2966,  0.4997,  0.7862,  0.6364,  0.4381,\n",
      "         0.9907,  1.0024,  1.0103,  1.3411,  1.0669,  1.2856,  1.4663,  1.6285,\n",
      "         0.9761,  1.2185,  1.4437,  1.6320,  0.6355,  1.3235,  0.9002,  0.1040,\n",
      "         0.6650,  0.3321,  1.4228,  1.5306,  1.5704,  0.9122,  1.3754,  1.3733,\n",
      "         1.2179,  0.8136,  0.7088,  1.2597,  0.9294,  0.0922,  0.8775,  1.0457,\n",
      "         1.3316,  0.7541,  0.8571,  1.2592,  1.3494,  0.0570,  0.6082,  1.2590,\n",
      "         1.4119,  0.7421,  0.6163,  1.3767,  1.4102,  0.9015,  1.4724,  1.1221,\n",
      "         1.6946,  0.5956,  0.7451,  0.3494,  0.4047,  0.7194,  0.7405,  1.2023,\n",
      "         0.5319,  1.0887,  1.5469,  0.8747,  0.3584,  0.5017,  1.1604,  0.9124,\n",
      "         1.7535,  1.1911,  1.3567,  0.8995,  0.7526,  0.9428,  0.2249,  0.8013,\n",
      "         0.3514,  0.9941,  1.0111,  0.7533,  1.3357,  1.2091,  0.7351,  0.7951,\n",
      "         0.6856,  1.2756,  0.9110,  1.2509,  1.1989,  1.3506,  0.1630,  1.2978,\n",
      "         1.9488,  1.1801,  1.8473,  1.2462,  1.0661,  1.3943,  1.2973,  0.8211,\n",
      "         1.8143,  1.6643,  1.3869,  1.3373,  0.3759,  0.8007,  0.6038,  0.2895,\n",
      "         1.2462,  1.1329,  1.4954,  1.0795,  0.3025,  1.1051,  0.8406,  0.3562,\n",
      "         0.6476,  1.5574,  1.5126,  1.0939,  1.6189,  0.7223,  1.2082,  0.8473,\n",
      "         1.5294,  1.8040,  1.8467,  1.4300,  1.2965,  0.7487,  0.6343,  1.5387,\n",
      "         1.1543,  0.8471,  0.2065,  1.2456,  0.9556,  1.1420,  1.0708,  1.0666,\n",
      "         1.1419,  0.8989,  1.2099,  1.1724,  1.2544,  0.6549,  0.8043,  0.9038,\n",
      "         1.6282,  1.6963,  0.4450,  1.2420, -0.1460,  1.9710,  0.7278,  1.2709,\n",
      "         1.5209,  1.3172,  1.6755,  1.0984,  0.9988,  1.3741,  1.1513,  2.1737,\n",
      "         1.2388,  1.3926,  0.8454,  1.0905,  0.7834,  1.2328,  1.2045,  1.0346,\n",
      "         0.8893,  1.0768,  0.3597,  0.7063,  0.5002,  1.2797,  1.4231,  0.4163,\n",
      "         0.8358,  0.7434,  1.4949,  1.4996,  0.5930,  1.5355,  0.9774,  1.5758,\n",
      "         0.8693,  1.3562,  0.8565,  1.4170,  0.8939,  0.9716,  1.4011,  1.1164,\n",
      "         1.4574,  0.9324,  0.8554,  0.3660,  0.8870,  0.4550,  0.6690,  1.1251,\n",
      "         0.9835,  0.7160,  1.5961,  0.9780,  1.1162,  0.0959,  0.8817,  1.3680,\n",
      "         1.3033,  0.5301,  0.9507,  1.2851,  0.6144,  0.4337,  0.2932,  0.9455,\n",
      "         0.8645,  0.1089,  0.7859,  1.3646,  0.0839,  0.8240,  0.8285,  1.1689,\n",
      "         0.8671,  1.9677,  1.6824,  0.6920,  0.3008,  0.4505,  1.7993,  0.8145,\n",
      "         1.2190,  1.0081,  1.0946,  0.8275,  1.7663,  1.1026,  0.7657,  0.3390,\n",
      "         1.7551,  1.4340,  1.2408,  0.9169,  1.4412,  0.4615,  1.5307,  0.2572,\n",
      "         1.0851,  1.2330,  1.4877,  0.9414,  1.2486,  0.9218,  0.7068,  0.3465,\n",
      "         1.1833,  1.1905,  2.0621,  0.9522,  1.0028,  1.0374,  0.4868,  1.0718,\n",
      "         1.6576,  1.1952,  0.7220,  0.7120,  1.5074,  1.2447,  1.5988,  0.9366,\n",
      "         0.3937,  0.5422,  1.0808,  0.7302,  0.5379,  0.5385,  0.7331,  1.3232,\n",
      "         0.3330,  0.9427,  1.2242,  0.9211,  0.7883,  0.9181,  0.5637,  1.0169,\n",
      "         1.5095,  1.2619,  1.1158,  0.9245,  1.1772,  0.5504,  1.2804,  0.7801,\n",
      "         2.1043,  1.3484,  1.3433,  1.1060,  1.0366,  1.1317,  0.7201,  1.0776,\n",
      "         0.9520,  1.0676,  0.7716,  1.2381,  0.7840,  0.5484,  1.0297,  1.2177,\n",
      "         1.6833,  1.3156,  1.1231,  1.3297,  0.4017,  1.8931,  0.7685,  1.0058,\n",
      "         1.7047,  0.9472,  0.6519,  1.0349,  1.6960,  0.8567,  0.7686,  0.8548,\n",
      "         1.2986,  1.7091,  0.9756,  1.3544,  1.1661,  0.8970,  1.5555,  0.9074,\n",
      "         1.2535,  1.3639,  1.1617,  1.8327,  0.8047,  0.7372,  0.3038,  0.6661,\n",
      "         0.7424,  0.9555,  1.5555,  1.0279,  1.1914,  1.4292,  1.1878,  1.0523,\n",
      "         1.4726, -0.0706,  1.0858,  0.9921,  0.7991,  0.9619,  1.2681,  1.0268,\n",
      "         0.9881,  0.6657,  1.4082,  1.1981,  1.3960,  0.6361,  0.8374,  1.3579,\n",
      "         1.2536,  1.1424,  1.7311,  0.6957,  0.9141,  0.9962,  1.6107,  0.9893,\n",
      "         1.0527,  1.3481,  1.1850,  0.9912,  0.9067,  0.7843,  0.7691,  1.0527,\n",
      "         0.7090,  0.9862,  1.5514,  1.3330,  1.0190,  1.2884,  0.7090,  0.9863,\n",
      "         1.2286,  1.5888,  1.0583,  1.1150,  1.4781,  0.6127,  0.8108,  1.5152,\n",
      "         0.9008,  1.3034,  0.7998,  1.1739,  1.3038,  1.2521,  0.6348,  1.2523,\n",
      "         1.2176,  1.1493,  1.0177,  1.2787,  1.7075,  1.4826,  0.7578,  1.2002,\n",
      "         1.3314,  0.8213,  1.1370,  1.2669,  1.2020,  0.6961,  0.9051,  1.5281,\n",
      "         1.0995,  0.9383,  1.0899,  1.3010,  0.9369,  1.2589,  1.5665,  0.9809,\n",
      "         1.1752,  1.1962,  0.8957,  1.1256,  1.1239,  1.3443,  0.3268,  0.8092,\n",
      "         1.2606,  0.5154,  0.7620,  1.4028,  1.6665,  0.6910,  0.3453,  1.1707,\n",
      "         0.7745,  1.7816,  0.8476,  1.5340,  1.4340,  0.5300,  1.5136,  1.1378,\n",
      "         0.7728,  0.9761,  1.4563,  1.0326,  1.1604,  1.2423,  0.8277,  0.8617,\n",
      "         1.0539,  1.3751,  0.7581,  1.3548,  0.7125,  1.2492,  0.4241,  1.1940,\n",
      "         0.5693,  1.4026,  0.9293,  0.9951,  0.6504,  1.3695,  1.1664,  0.9390,\n",
      "         0.9718,  0.9106,  1.2010,  1.0224,  0.8939,  1.5067,  0.9974,  1.2631,\n",
      "         1.0997,  1.2608,  1.1700,  0.9946,  0.9875,  0.8779,  1.2165,  0.9527,\n",
      "         0.7513,  1.1593,  0.6666,  1.5025,  0.7900,  0.9766,  1.8579,  2.8651,\n",
      "         1.1628,  1.1302,  1.2515,  1.7642,  0.8751,  1.4223,  1.1757,  1.4562,\n",
      "         1.1294,  0.7674,  0.9324,  0.9062,  0.9837,  1.2464,  1.1421,  0.9500],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-3.3268e-02, -1.7590e-01,  1.1861e-02,  1.6755e+00,  7.9098e-01,\n",
      "        -1.9520e+00,  1.8430e-01, -3.6509e-01, -1.5379e+00, -2.3401e+00,\n",
      "        -1.4374e+00, -1.5929e+00, -2.0080e+00, -6.9378e-01, -1.4617e+00,\n",
      "        -6.6837e-02, -6.0112e-01, -1.4484e-01, -1.1845e+00, -1.5046e+00,\n",
      "        -3.6945e-01, -8.4374e-01, -1.2936e+00, -1.6351e+00, -9.8441e-01,\n",
      "         5.8620e-01,  5.4138e-01,  1.2272e-01, -6.2224e-01,  8.6758e-01,\n",
      "        -1.3530e+00, -1.9331e+00, -2.2541e-01,  4.7268e-01,  5.4337e-01,\n",
      "         2.5498e-01, -9.1903e-01, -2.9859e-01,  2.1869e-02, -3.8577e-01,\n",
      "        -1.2344e+00, -2.1606e+00,  1.0500e-01, -4.1517e-01, -5.5833e-01,\n",
      "        -1.2454e+00,  1.3498e-01, -7.6058e-01, -7.7229e-01, -2.0375e+00,\n",
      "        -9.8868e-01, -8.0593e-01, -1.1196e+00, -2.6818e-01, -2.5994e+00,\n",
      "        -7.1952e-01, -1.3308e+00, -3.0044e+00, -1.3817e+00, -1.2311e-01,\n",
      "         5.6650e-01, -2.1465e+00, -8.9380e-01, -2.9087e+00, -1.4075e+00,\n",
      "         1.0676e+00, -1.6639e+00, -9.4720e-01, -1.1663e+00, -1.3161e+00,\n",
      "        -9.6731e-01, -1.7293e+00, -1.0972e+00,  1.8968e-01, -3.7694e-01,\n",
      "        -1.7289e+00, -3.6082e-01, -4.6624e-01,  2.8685e-01,  8.9866e-03,\n",
      "         6.3549e-02, -1.0146e-01,  4.7964e-01, -1.9076e+00, -6.6476e-01,\n",
      "        -2.6727e-01,  1.4783e-01, -4.8943e-01, -5.0996e-01, -8.9488e-01,\n",
      "        -9.3696e-01,  9.0844e-01, -2.1043e+00, -1.1376e+00, -5.8904e-01,\n",
      "        -8.4014e-01, -1.7785e+00, -1.7504e+00, -4.3716e-01, -1.7243e+00,\n",
      "        -8.3672e-01, -1.0120e+00, -1.1464e+00, -1.5191e+00, -2.3890e+00,\n",
      "        -1.2895e+00, -8.1624e-01, -1.7472e+00, -1.0047e+00, -5.5730e-01,\n",
      "        -1.6660e+00,  8.3152e-02, -1.4019e+00, -5.1012e-01, -5.0445e-01,\n",
      "        -6.6274e-02, -1.0356e+00, -2.3636e+00, -8.0616e-01, -1.4003e+00,\n",
      "        -8.6620e-01, -9.0135e-01,  9.3366e-01, -1.5733e+00, -9.3105e-01,\n",
      "         7.3524e-01, -8.0844e-01, -2.3039e+00, -3.5329e-01, -3.1064e-01,\n",
      "        -6.4108e-01, -5.4061e-01,  8.6320e-01, -4.6975e-02, -1.7391e+00,\n",
      "        -4.8305e-02, -3.0761e-01, -6.1992e-01, -1.6583e+00, -8.1369e-01,\n",
      "        -1.0928e+00, -5.2319e-01,  1.0078e+00, -2.7639e-01,  8.5595e-01,\n",
      "        -1.1311e+00, -1.4626e+00, -2.0118e+00, -9.8230e-01, -1.4536e+00,\n",
      "        -2.4072e-01, -9.5798e-01, -1.3261e+00,  1.1050e-01, -4.6256e-01,\n",
      "         3.7438e-01, -1.1557e+00, -9.7944e-01,  6.8600e-02, -1.1748e+00,\n",
      "        -1.5786e+00, -2.0600e-01,  1.0201e-01,  3.5179e-01, -2.1291e+00,\n",
      "        -7.9530e-01, -1.4405e+00, -1.4494e+00, -1.6462e+00, -1.4948e+00,\n",
      "         1.6734e+00,  8.9868e-01, -1.0088e+00, -4.9297e-01, -9.8013e-01,\n",
      "        -3.0360e-02, -2.2912e+00, -1.0506e+00, -1.1904e+00, -3.9992e-01,\n",
      "        -1.0682e-02, -3.3169e-01,  1.4098e-01, -1.9263e+00, -3.7876e-01,\n",
      "        -1.9719e+00, -6.6713e-01, -4.6321e-01, -8.3117e-01, -1.2729e+00,\n",
      "        -8.5498e-01, -5.7701e-01, -1.1182e+00, -1.0478e+00, -1.1661e+00,\n",
      "        -1.2090e+00, -1.7246e+00, -1.8698e+00, -2.1834e-01, -1.1288e-01,\n",
      "        -6.3825e-01, -9.6722e-02,  2.5439e-01, -3.6393e-01, -3.5245e-02,\n",
      "         2.5510e-01, -5.4896e-02, -6.0565e-01, -5.2903e-01,  5.4552e-01,\n",
      "        -1.2421e-01, -1.3190e+00, -7.0673e-01, -1.7772e+00, -9.9889e-01,\n",
      "        -1.2783e-01, -3.1931e-01, -1.2890e+00,  3.4450e-01, -2.3245e+00,\n",
      "        -4.2744e-01, -1.3712e-01, -8.6206e-01, -1.8747e-02, -1.1723e+00,\n",
      "        -2.1909e+00, -5.4347e-01,  2.1804e-01, -5.8479e-01, -4.7142e-01,\n",
      "        -1.8969e+00,  6.1433e-01, -1.4288e+00,  1.4424e+00,  9.0832e-01,\n",
      "        -1.8583e+00, -1.6614e+00, -5.9623e-01,  1.7193e-01, -7.2290e-01,\n",
      "        -1.8578e-01, -1.5489e+00,  6.0558e-01, -1.1837e+00,  1.1809e+00,\n",
      "        -8.2264e-02,  5.1260e-01, -1.4549e+00, -6.4125e-01, -2.1699e+00,\n",
      "         5.3199e-01, -7.9247e-01,  1.8674e-01, -1.3992e+00, -1.2404e+00,\n",
      "        -1.8757e-01, -4.0710e-02, -1.0354e+00, -1.4393e-01, -2.5991e+00,\n",
      "        -2.1188e+00, -1.1500e+00, -7.0163e-01, -8.2004e-01, -6.7913e-01,\n",
      "         9.5933e-02, -1.4756e+00, -8.6686e-01,  2.2205e-01, -1.3398e+00,\n",
      "         8.9608e-01,  5.8301e-02, -1.0555e+00, -4.6818e-01, -1.2912e-01,\n",
      "        -1.3371e+00, -2.8602e+00, -1.5541e+00, -6.4940e-01, -3.4633e-01,\n",
      "         4.6182e-01, -1.1063e+00,  3.9983e-01, -7.8053e-01, -2.4520e+00,\n",
      "         3.0360e-02, -8.3756e-01,  9.0287e-02, -4.1936e-01, -9.3437e-01,\n",
      "        -2.0249e+00,  2.8789e-01, -4.0960e-02, -2.5544e-01, -6.8444e-01,\n",
      "        -1.3014e-01, -1.8219e+00,  3.1638e-01,  2.7418e-02, -5.8516e-01,\n",
      "         2.4869e-01, -1.3222e+00, -6.7244e-01, -3.7960e-01, -2.0983e+00,\n",
      "        -6.7617e-01, -1.1047e+00, -7.4492e-01, -1.4908e-01, -1.0978e+00,\n",
      "        -2.3145e-01,  9.5310e-02, -4.6566e-02, -2.8531e-01, -9.2827e-01,\n",
      "        -9.9576e-01, -1.3004e+00, -1.0943e+00, -3.1342e-01, -1.0203e+00,\n",
      "        -1.1775e+00, -1.0326e+00,  1.2933e+00, -1.5590e-01, -2.3263e+00,\n",
      "         8.5014e-01, -1.1365e+00, -9.4070e-01, -1.4031e+00,  6.0645e-01,\n",
      "         6.7298e-01,  1.5702e+00, -1.0821e+00,  8.8671e-01, -1.1749e+00,\n",
      "        -3.0471e-01, -2.4304e+00, -9.4841e-03, -2.7309e-01, -2.1377e+00,\n",
      "        -5.9056e-01, -1.6055e+00, -5.7459e-01,  6.4064e-01, -1.8044e+00,\n",
      "         3.4209e-01,  4.3911e-01, -3.7427e-01, -8.6456e-01,  7.3387e-02,\n",
      "        -4.8002e-01, -3.3471e-01, -4.8352e-01, -9.6652e-01, -1.5438e+00,\n",
      "        -1.1807e+00, -6.9502e-02,  4.3790e-01,  5.6801e-02, -9.5170e-01,\n",
      "        -2.3778e+00, -9.9640e-01, -9.1796e-01, -1.3184e+00, -8.1200e-01,\n",
      "        -9.5041e-01,  2.9761e-02, -4.2054e-01, -5.5308e-01,  1.0829e+00,\n",
      "        -1.1664e+00, -3.3274e-01, -5.0088e-01,  1.3399e+00, -2.4597e-01,\n",
      "         2.5390e-01, -4.3393e-01, -1.2269e+00, -1.0132e+00, -1.2885e+00,\n",
      "        -2.1061e+00,  5.3049e-01, -2.6131e-01,  1.5229e-01, -2.6156e-01,\n",
      "        -1.4480e+00, -4.4471e-01, -7.2432e-01, -5.3203e-01,  3.0936e-01,\n",
      "        -1.6937e+00, -1.0888e+00,  9.8809e-01, -2.0456e+00, -7.4586e-01,\n",
      "        -8.5271e-01,  1.0241e-01,  6.7891e-01,  4.5828e-01,  3.6094e-01,\n",
      "        -1.0843e+00, -1.9686e+00, -1.5354e+00, -2.1217e-01, -1.2802e-01,\n",
      "        -1.4342e+00, -1.1406e+00,  1.4691e-02, -1.3519e+00, -7.7366e-01,\n",
      "        -2.1538e+00, -1.0723e+00, -5.3246e-02, -1.2193e+00, -4.8819e-01,\n",
      "         6.1022e-01, -1.9760e+00, -1.1971e+00, -2.4408e+00, -2.3303e+00,\n",
      "        -1.1535e+00,  2.1351e-02, -1.7477e+00, -1.6721e+00, -2.5930e+00,\n",
      "        -2.2540e+00,  2.7987e-01,  1.3345e-01,  3.0162e-01, -1.5865e+00,\n",
      "        -2.3022e+00,  1.5018e-02, -1.2948e-01,  1.9202e-01, -1.0849e+00,\n",
      "        -1.2229e+00, -1.0265e+00,  1.7712e-01, -5.0885e-01, -2.1258e+00,\n",
      "        -3.3940e-01, -2.3978e+00,  4.0939e-01, -1.2939e+00, -3.0881e-01,\n",
      "        -1.9120e+00, -6.9949e-01, -2.7795e-02, -2.6822e-01,  4.6753e-01,\n",
      "        -1.5345e+00, -1.3974e+00, -2.9862e-01, -1.4382e+00, -9.4281e-01,\n",
      "        -2.3314e-01, -1.4812e+00, -9.9174e-01, -1.6218e+00, -5.2499e-01,\n",
      "         5.5353e-01, -1.3139e+00, -2.0294e+00, -5.5925e-01, -5.4818e-01,\n",
      "        -1.2419e+00,  6.0900e-01, -2.6450e-01,  4.2830e-02, -3.1706e-01,\n",
      "        -5.2047e-01,  1.7202e-01,  6.5810e-01,  2.8008e-01, -4.0727e-01,\n",
      "        -2.7076e+00, -1.6437e+00, -7.5058e-01, -2.9970e-01, -1.0119e+00,\n",
      "        -2.0942e+00, -1.4580e+00, -7.0284e-01,  7.1959e-01, -2.0487e+00,\n",
      "        -7.3203e-01, -1.1521e+00, -1.5686e+00, -5.3992e-01, -5.1273e-01,\n",
      "        -1.2884e+00,  1.1890e-01, -1.2694e+00, -1.0460e+00,  8.1405e-01,\n",
      "         6.5424e-01, -8.5782e-01, -6.1732e-01, -1.8659e+00,  3.4828e-01,\n",
      "        -4.5794e-01,  1.8651e-01,  2.9293e-01,  8.7321e-02, -1.2684e+00,\n",
      "        -9.2644e-02, -5.5042e-01,  9.8326e-01, -1.7303e+00, -6.6825e-01,\n",
      "         1.9702e-01,  9.3463e-01, -1.8563e+00, -5.3480e-01, -3.1972e-01,\n",
      "        -2.2786e+00,  6.5610e-01, -1.1640e+00, -2.6744e-01, -8.8416e-01,\n",
      "        -9.8714e-01, -7.2003e-01, -2.3493e+00,  3.8867e-01,  4.1260e-01,\n",
      "         4.8637e-01,  8.8297e-02,  9.0198e-01,  3.4918e-01, -1.4604e+00,\n",
      "        -7.9607e-01,  6.2829e-01, -1.7583e+00, -1.0667e+00, -3.5093e-01,\n",
      "         1.0583e+00,  7.3668e-01, -1.3661e+00,  5.2320e-02, -1.4600e+00,\n",
      "         4.0266e-01,  4.4442e-01, -1.5757e+00,  4.3384e-01, -9.1606e-01,\n",
      "        -3.6506e-01, -1.6724e+00, -2.0331e+00, -1.3770e+00, -1.1042e+00,\n",
      "        -6.1921e-01, -1.8897e+00,  1.5436e-01,  3.7623e-01, -1.9960e-01,\n",
      "         7.3752e-01,  4.1084e-01, -6.8702e-01, -6.9592e-01, -7.5731e-01,\n",
      "        -4.2366e-01, -1.3324e+00, -6.0504e-01, -6.3023e-01, -1.1289e+00,\n",
      "        -3.1461e-02, -8.3732e-01, -7.9919e-01,  5.0239e-01, -5.1435e-01,\n",
      "         8.4554e-01,  1.5798e+00,  6.8079e-02, -1.9039e-02, -6.4331e-01,\n",
      "         3.3790e-02,  4.6324e-01, -4.0734e-01, -2.0756e+00, -6.1526e-01,\n",
      "         5.2653e-01, -2.6728e-01,  5.5927e-01,  5.6685e-01, -3.4455e-01,\n",
      "        -8.5124e-01, -1.4821e+00, -8.7073e-01, -7.2424e-01, -1.1882e-02,\n",
      "         2.5235e-02, -1.6950e+00, -1.2074e-01, -6.5226e-01, -1.2778e+00,\n",
      "        -2.1887e+00, -1.9096e+00, -1.5635e+00, -6.5038e-01, -1.5447e+00,\n",
      "        -1.2255e+00, -7.7129e-02, -6.9610e-02, -5.0561e-01, -2.5409e-01,\n",
      "        -7.9401e-01, -6.3621e-01, -1.1030e+00, -1.1485e-01, -2.1256e+00,\n",
      "        -8.4514e-01, -2.4545e+00,  9.3436e-02, -7.2700e-01, -1.9379e-01,\n",
      "        -9.8038e-01, -2.3114e-01, -1.4224e+00, -9.8596e-01, -3.7022e-01,\n",
      "        -1.3536e-01, -5.0042e-01,  3.2454e-02,  1.7453e-04, -3.1494e-01,\n",
      "        -1.7223e+00, -4.7284e-01, -8.2414e-01,  4.7193e-01, -4.5314e-01,\n",
      "        -5.6674e-01, -1.7668e+00, -9.2685e-01, -1.8305e+00, -4.1559e-01,\n",
      "         6.2590e-02, -1.4340e+00, -8.2768e-01,  6.4945e-02,  1.0457e+00,\n",
      "        -7.9594e-01,  3.6503e-01, -1.0362e+00, -1.8329e+00, -1.6052e+00,\n",
      "        -7.8742e-01, -6.5040e-01,  4.8240e-01, -1.5325e+00,  3.2347e-01,\n",
      "        -8.3010e-01, -6.7969e-02,  6.2617e-01,  3.5373e-01, -8.2294e-01,\n",
      "        -1.1421e+00,  2.8336e-01, -1.1944e+00, -5.2834e-01,  2.2306e-01,\n",
      "        -5.8932e-01,  2.7642e-01, -1.7062e+00, -1.1254e+00,  4.3205e-01,\n",
      "        -7.4173e-01, -8.1008e-01, -1.1556e+00,  2.8240e-02, -1.6476e+00,\n",
      "        -9.6194e-01, -3.4461e-01, -4.8076e-01, -2.3448e+00, -1.2177e+00,\n",
      "        -9.8751e-02, -1.5662e+00, -1.1318e-01, -8.8839e-01, -1.4450e+00,\n",
      "        -6.7007e-02, -7.9984e-01,  5.9022e-01, -1.6611e+00, -1.8087e+00,\n",
      "        -8.3357e-01, -2.3945e-01, -3.0696e-01, -1.9768e-01, -1.2048e+00,\n",
      "        -9.8219e-01, -1.4212e+00, -6.5521e-01, -1.0856e+00, -1.6080e-01,\n",
      "        -1.0380e+00, -3.7816e-01, -1.1790e+00, -1.8359e+00, -1.9431e-01,\n",
      "        -1.8618e+00, -6.0155e-01,  1.0170e+00, -6.2366e-01, -7.6613e-01,\n",
      "         3.7639e-02, -1.4428e+00, -4.1121e-01, -1.0766e+00, -5.7574e-01,\n",
      "         2.7518e-01, -1.5509e+00,  8.1988e-02, -1.2059e+00, -5.6667e-01,\n",
      "        -7.4889e-01, -1.3619e+00, -1.0220e+00,  1.0766e+00, -1.1175e+00,\n",
      "        -1.9645e+00, -1.4238e+00, -6.4776e-01, -7.8245e-01, -1.0445e+00,\n",
      "        -5.1880e-01, -1.1377e+00, -1.6273e+00, -1.1241e+00,  6.3889e-01,\n",
      "        -3.0815e-01, -1.3154e+00, -1.5748e+00,  2.1362e-01, -3.2107e-01,\n",
      "        -1.0253e+00, -1.2973e+00,  9.6703e-01,  5.2948e-01, -1.3835e-01,\n",
      "        -9.5935e-01, -7.5059e-01,  8.1501e-01,  2.1919e+00, -4.9832e-01,\n",
      "        -6.1469e-01,  4.5163e-01,  2.6349e-01, -1.2300e+00,  1.3085e-01,\n",
      "         8.7739e-02, -1.7148e+00,  2.7190e-01, -7.0368e-01, -2.9178e-01,\n",
      "        -7.4207e-02, -1.1635e+00, -8.8640e-01, -1.4468e+00, -8.4244e-01,\n",
      "        -9.2519e-01, -1.7500e-01, -5.3220e-01, -1.2018e+00, -5.7716e-02,\n",
      "        -1.7154e+00, -4.3951e-01, -3.0162e-01, -6.8980e-01,  5.3415e-01,\n",
      "        -1.3167e+00, -1.1127e+00, -2.3865e-01, -3.9564e-01, -8.4843e-01,\n",
      "        -2.0295e+00, -9.4670e-01, -1.0822e+00, -1.2989e+00,  6.4836e-01,\n",
      "         1.0166e+00, -1.0320e+00, -2.7676e-01,  1.9169e-01, -6.3638e-01,\n",
      "        -1.0247e+00, -1.9073e+00, -6.2187e-01, -1.4112e+00, -6.6216e-01,\n",
      "        -6.6829e-01, -9.4246e-01, -6.3438e-01, -8.5232e-01, -1.1069e+00,\n",
      "         5.2644e-01, -4.4517e-01, -9.3004e-01, -2.2787e-01, -1.6108e-01,\n",
      "         1.3676e+00, -3.9551e-02, -9.4752e-01, -3.8398e-01, -1.7398e+00,\n",
      "        -7.0669e-01, -7.7085e-01, -1.3734e+00, -1.2813e+00, -1.2469e+00,\n",
      "        -4.8462e-01,  3.7244e-01, -1.4314e+00, -1.4383e+00, -4.9700e-01,\n",
      "        -1.3122e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 3.2208e-01, -3.9188e-02, -1.2173e-02, -4.3631e-01, -1.9924e-01],\n",
      "          [-2.1618e-01, -2.1513e-01, -2.6371e-01, -4.1990e-01, -2.4000e-01],\n",
      "          [ 2.7284e-01, -2.9860e-01, -5.8052e-02,  2.8972e-01, -1.4727e-01],\n",
      "          [ 1.6976e-01,  5.7484e-01,  4.7648e-01,  2.7146e-02, -3.7839e-01],\n",
      "          [-4.6247e-01,  3.2698e-01, -2.6806e-01, -1.7860e-01, -8.7771e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.8848e-01,  7.0441e-02, -1.2260e-02, -1.1732e-01,  5.4206e-02],\n",
      "          [-4.1663e-01, -8.0500e-02,  8.0236e-02, -2.2981e-01, -4.6554e-02],\n",
      "          [-5.3974e-01,  7.7034e-02,  5.0442e-02, -6.4946e-01,  4.1573e-01],\n",
      "          [-5.5988e-01, -3.3170e-01, -2.2718e-01, -2.9905e-01, -9.7791e-02],\n",
      "          [ 5.9750e-04,  3.2832e-01,  3.7816e-01,  3.8542e-01,  7.1899e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1289e-01, -5.2830e-01, -1.3393e-02, -2.3608e-01,  1.0070e-04],\n",
      "          [ 9.7352e-04, -1.6837e-01, -2.8028e-01, -1.3970e-01,  1.7971e-01],\n",
      "          [-5.8937e-02,  1.4507e-01, -6.6200e-02, -1.4208e-01, -4.0296e-02],\n",
      "          [ 1.7306e-01, -2.8059e-01,  2.4884e-01, -5.1038e-02, -2.2448e-01],\n",
      "          [ 1.0382e+00,  6.6249e-01,  4.9877e-01,  2.1434e-01, -2.3407e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 7.0797e-01,  7.3912e-01,  3.8428e-01, -3.0201e-02, -1.8924e-01],\n",
      "          [ 1.1079e-01,  3.1944e-01,  6.7110e-01,  1.2899e-01, -1.5255e-01],\n",
      "          [ 2.1284e-01,  4.9342e-01,  3.0397e-01,  1.8474e-01, -7.1550e-02],\n",
      "          [-5.2979e-04,  1.5945e-01,  5.9829e-01,  1.5706e-01,  2.7818e-02],\n",
      "          [-1.4199e-01,  2.6061e-01,  4.2926e-01, -3.9045e-02,  1.7165e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.5981e-02, -1.8327e-02,  5.5769e-01,  7.3011e-02,  4.2670e-01],\n",
      "          [ 7.1796e-02,  5.3039e-02,  5.7934e-01,  2.7546e-01,  5.8621e-01],\n",
      "          [-1.4077e-01, -2.9192e-01, -1.0326e-01, -7.3771e-02, -1.8681e-01],\n",
      "          [-2.9251e-01, -4.3491e-02, -3.3263e-01,  4.6814e-02, -3.6828e-01],\n",
      "          [-4.5160e-01, -3.8970e-01, -2.9631e-01, -4.2229e-01, -5.9988e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.3974e-01,  1.7268e-01, -1.5973e-01, -1.9154e-01, -1.1642e-01],\n",
      "          [ 3.4963e-02, -6.3020e-02,  1.0559e-02, -2.2764e-01,  1.1577e-01],\n",
      "          [ 5.3786e-02,  5.8720e-02, -3.0638e-01, -3.1285e-01,  5.8128e-01],\n",
      "          [ 2.5785e-01,  4.6731e-01, -1.5611e-01,  2.4673e-01,  5.2435e-01],\n",
      "          [ 5.6068e-01,  6.2308e-01, -2.1499e-01, -2.4613e-01, -2.0238e-02]]]],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.7258, 2.4168, 1.2155, 2.1232, 2.2692, 0.9546, 1.5893, 2.3089, 1.0895,\n",
      "        1.3303, 1.8655, 1.4330, 3.5232, 1.3313, 3.1876, 1.3376, 1.6536, 0.9777,\n",
      "        1.9371, 1.0517, 1.4870, 1.7615, 4.0284, 2.0937, 1.1687, 1.4825, 2.3373,\n",
      "        1.4824, 0.3912, 1.6092, 1.3673, 2.7490, 2.1331, 1.9236, 1.7971, 1.4960,\n",
      "        1.3392, 1.5280, 1.7998, 1.2201, 1.0014, 2.4236, 1.6088, 1.9482, 1.9670,\n",
      "        0.8000, 1.8113, 1.4429, 1.1723, 0.7525, 2.0095, 1.9610, 1.6967, 2.4064,\n",
      "        3.1459, 1.7878, 2.6922, 1.1244, 1.3035, 1.0637, 2.3338, 0.8438, 1.9043,\n",
      "        2.9488, 1.4986, 1.5982, 1.1485, 0.9343, 1.5619, 1.1102, 1.7892, 1.2141,\n",
      "        1.6310, 1.3247, 1.0799, 1.1872, 1.0304, 1.3960, 1.6523, 2.3336, 1.6165,\n",
      "        1.7169, 1.3725, 0.4308, 1.9419, 0.8364, 1.9629, 0.6234, 0.9751, 1.1221,\n",
      "        1.3743, 1.3783, 0.8490, 2.0137, 0.9896, 1.1422, 3.2720, 1.5002, 1.1902,\n",
      "        1.4841, 0.9297, 0.9534, 1.4056, 0.8130, 1.1343, 2.7256, 1.8175, 1.2013,\n",
      "        1.2158, 1.3301, 1.2350, 1.5123, 1.6438, 0.9307, 1.5557, 1.7621, 1.1071,\n",
      "        1.2365, 1.7818, 3.5258, 1.8393, 1.1152, 1.9427, 1.6259, 1.1309, 1.9740,\n",
      "        1.5077, 1.3142, 1.2525, 1.4973, 1.3434, 1.0003, 1.0979, 1.4114, 3.5569,\n",
      "        1.5449, 1.5380, 1.6542, 0.8397, 2.3481, 1.6110, 1.8000, 1.5631, 1.5127,\n",
      "        1.6197, 1.1302, 1.3106, 0.7460, 1.6562, 2.6706, 1.4593, 1.0228, 2.1962,\n",
      "        1.5434, 1.3949, 1.5961, 1.6892, 1.0118, 1.2929, 1.2924, 1.9725, 1.4204,\n",
      "        1.5691, 1.1423, 2.6289, 1.6428, 1.1009, 2.4899, 1.5361, 1.1910, 2.3901,\n",
      "        1.5715, 1.4746, 1.7212, 1.1210, 0.9593, 0.1891, 1.3769, 1.0922, 1.3811,\n",
      "        1.8052, 1.3377, 1.5691, 0.6926, 1.2536, 0.6624, 1.6035, 0.9639, 1.3129,\n",
      "        1.5089, 1.1840, 1.2852, 1.2946, 1.6215, 0.3184, 1.4683, 1.3768, 0.8292,\n",
      "        2.0183, 2.4084, 0.9560, 0.3905, 1.4090, 1.6287, 1.3317, 1.6386, 1.8022,\n",
      "        1.3820, 1.3835, 1.7115, 1.8129, 1.0617, 1.5449, 0.7945, 1.0823, 2.5399,\n",
      "        1.4267, 1.2991, 1.8860, 3.0715, 2.4995, 1.4170, 1.3086, 1.6162, 1.0925,\n",
      "        2.7036, 2.5809, 1.7169, 1.8728, 1.9077, 3.5555, 2.1089, 1.3563, 2.4610,\n",
      "        1.0881, 0.8366, 1.6457, 0.9111, 1.0485, 1.5582, 2.0516, 0.5840, 1.7111,\n",
      "        1.1931, 1.5733, 1.3014, 2.0198, 1.0938, 1.6803, 0.8103, 2.0205, 1.4159,\n",
      "        1.9456, 0.5939, 1.6147, 1.2539, 1.1354, 1.7485, 0.9413, 0.7810, 0.8880,\n",
      "        1.5151, 1.6401, 1.1422, 1.1970, 1.1531, 1.0388, 1.9892, 1.6445, 0.5970,\n",
      "        1.8966, 1.8014, 0.9156, 1.6741, 1.5495, 2.5647, 1.2787, 2.1653, 1.7968,\n",
      "        1.4309, 2.3337, 1.6053, 1.2511, 1.4550, 1.7264, 2.0127, 1.1623, 1.3672,\n",
      "        2.3831, 1.5482, 0.8110, 1.6495, 1.6356, 1.4245, 0.9899, 1.5203, 1.0523,\n",
      "        1.7006, 1.1633, 1.3295, 1.9274, 0.9955, 1.3266, 1.3695, 1.1247, 1.1958,\n",
      "        1.9876, 0.9516, 1.7468, 1.0600, 1.1417, 1.6257, 1.1085, 1.4953, 1.2211,\n",
      "        2.6401, 1.6836, 1.7762, 1.0112, 1.5882, 1.1781, 0.9473, 1.8248, 1.2836,\n",
      "        1.3510, 1.2786, 1.5059, 1.8684, 0.6732, 0.7025, 1.5171, 1.7146, 1.4069,\n",
      "        1.7890, 0.7459, 1.4726, 2.7751, 1.6202, 1.6393, 1.0855, 2.0118, 1.0377,\n",
      "        1.0172, 1.6674, 2.1878, 1.6835, 1.9856, 1.3586, 2.4251, 1.0540, 0.9008,\n",
      "        1.4069, 1.5852, 1.4100, 0.1294, 1.2818, 1.5816, 1.8324, 2.1074, 0.6151,\n",
      "        2.5913, 1.9443, 1.4144, 0.8596, 1.1454, 1.5703, 1.4858, 1.4564, 1.8545,\n",
      "        1.7822, 1.8673, 1.3205, 1.1577, 2.9695, 2.2254, 1.8080, 1.6205, 1.7018,\n",
      "        0.6255, 0.4870, 1.5004, 2.0803, 1.6368, 2.2597, 0.8093, 0.9391, 2.1193,\n",
      "        1.9377, 1.1427, 1.3132, 1.4376, 1.2339, 2.0545, 2.4663, 1.3580, 0.4469,\n",
      "        1.7158, 1.7422, 1.7272, 1.9050, 1.4424, 0.8779, 4.3173, 1.3577, 1.3048,\n",
      "        0.8091, 1.2228, 1.8766, 0.7923, 1.4110, 1.3644, 1.4164, 0.7965, 0.8001,\n",
      "        1.6766, 1.4998, 2.1920, 0.9148, 3.8442, 3.1319, 1.3811, 1.6302, 1.5114,\n",
      "        1.6843, 1.1648, 0.4389, 1.7947, 0.7929, 1.7526, 0.6495, 1.3162, 1.2816,\n",
      "        1.6088, 1.7212, 1.1676, 1.3652, 1.5477, 2.2595, 1.0235, 1.9066, 1.2065,\n",
      "        1.9273, 2.0359, 1.3886, 1.5507, 3.1397, 0.6235, 1.8713, 0.9511, 1.9636,\n",
      "        0.8297, 1.0112, 1.2952, 1.8264, 1.0499, 1.3709, 0.7551, 1.1704, 1.0574,\n",
      "        1.1754, 1.5032, 0.5107, 0.8847, 1.1084, 1.1501, 0.8841, 1.6144, 2.1164,\n",
      "        1.4066, 1.1308, 1.3325, 1.4044, 1.6225, 1.8408, 1.1622, 1.1236, 1.0302,\n",
      "        2.1462, 1.6105, 3.2496, 0.9582, 2.7869, 0.6246, 1.8828, 0.3362, 1.2415,\n",
      "        1.5316, 1.6651, 1.3207, 1.3623, 1.2523, 1.4947, 0.8291, 1.3675, 2.1215,\n",
      "        2.1701, 1.2646, 1.1924, 2.7864, 1.7217, 1.4470, 1.4152, 1.6772, 1.9895,\n",
      "        0.8804, 2.3081, 1.9458, 2.5842, 0.7965, 1.6590, 1.9852, 1.9334, 1.1121,\n",
      "        0.8630, 1.7213, 2.3319, 0.8118, 1.2718, 1.6497, 1.2948, 1.4317, 1.8628,\n",
      "        2.5477, 1.5182, 2.0556, 2.3189, 1.4117, 1.1184, 1.7069, 0.9589, 1.2509,\n",
      "        1.6580, 2.9083, 1.4351, 1.2085, 2.1063, 1.7038, 2.6773, 1.1839, 1.1309,\n",
      "        2.6482, 2.1301, 1.0994, 1.8113, 0.8033, 1.7583, 2.9947, 1.4094, 1.8194,\n",
      "        1.9214, 1.3871, 1.2104, 1.0809, 1.4198, 0.8840, 2.2537, 2.0638, 1.2035,\n",
      "        1.3850, 1.3551, 0.5904, 0.8091, 1.4874, 1.5916, 0.5795, 1.6840, 1.0607,\n",
      "        1.3465, 2.2300, 1.2170, 1.3460, 1.7198, 1.1664, 1.4508, 1.4342, 1.5288,\n",
      "        1.2889, 1.3278, 0.7688, 1.6870, 0.5518, 1.4331, 1.1852, 1.9143, 1.6837,\n",
      "        1.4205, 1.5899, 1.6785, 1.4803, 2.1016, 2.3068, 0.9023, 1.9238, 0.5887,\n",
      "        1.3834, 1.2265, 0.6433, 0.8427, 1.1207, 1.2844, 1.1681, 1.5274, 1.2792,\n",
      "        2.1329, 1.7232, 1.3637, 1.6713, 1.7803, 1.4784, 1.2347, 1.7670, 1.0640,\n",
      "        1.7621, 0.8333, 2.1360, 1.0514, 1.4274, 2.0012, 1.4531, 1.8458, 1.4982,\n",
      "        1.0524, 1.4570, 1.5896, 2.8356, 2.1822, 1.4337, 1.6063, 1.5603, 1.2269,\n",
      "        2.2908, 0.9577, 1.0058, 0.9892, 1.2213, 1.9676, 1.2196, 1.4504, 1.7721,\n",
      "        1.8539, 1.7204, 2.3235, 1.0694, 1.3872, 0.9430, 1.3904, 0.9752, 1.6764,\n",
      "        1.1405, 1.9127, 1.3141, 1.4703, 2.3760, 1.9205, 1.5126, 1.5376, 0.9748,\n",
      "        0.1666, 2.5508, 1.7034, 1.4107, 1.8624, 1.1237, 1.1647, 1.5976, 2.4389,\n",
      "        0.3420, 0.7034, 1.7742, 1.0969, 1.3940, 1.7695, 1.0176, 1.1771, 1.4703,\n",
      "        2.1537, 0.7249, 1.8621, 1.0024, 0.9786, 1.3256, 1.6753, 2.2828, 1.6613,\n",
      "        0.9631, 1.5076, 1.1365, 1.5690, 1.3387, 1.8151, 1.5511, 1.9536, 1.6909,\n",
      "        0.6735, 0.9929, 1.8259, 2.1932, 2.2704, 2.0088, 0.9002, 1.8316, 0.7999,\n",
      "        1.5288, 1.3837, 1.1201, 1.5584, 1.3231, 1.7072, 1.1933, 1.0492, 1.3822,\n",
      "        1.1199, 2.3162, 1.1807, 1.3126, 0.6086, 1.4255, 1.4090, 2.2239, 0.9515,\n",
      "        1.4843, 1.1704, 1.0751, 1.2794, 0.6197, 0.8755, 1.5442, 1.0717, 1.6037,\n",
      "        1.8192, 1.1311, 1.3466, 1.1483, 1.6764, 1.7120, 2.0243, 1.1983, 2.1158,\n",
      "        1.9047, 2.2028, 0.5205, 1.2995, 1.9947, 1.7462, 1.5357, 1.2003, 1.9848,\n",
      "        1.7409, 3.4175, 2.0386, 1.4819, 1.2072, 0.8443, 1.4429, 1.7933, 1.5875,\n",
      "        1.4349, 1.2016, 2.0216, 1.1329, 1.7196, 1.6945, 1.3337, 1.3879, 1.1273,\n",
      "        1.9617, 1.3893, 1.8742, 1.1266, 1.6212, 1.1555, 0.6585, 1.5038, 1.3807,\n",
      "        1.6632, 1.5788, 2.1890, 1.3348, 1.3875, 1.9817, 1.1530, 0.9100, 2.3938,\n",
      "        1.8842, 1.6953, 1.7359, 1.2616, 1.8898, 1.7168, 1.7801, 1.7920, 1.1397,\n",
      "        1.2270, 0.9982, 1.2213, 1.8340, 1.1676, 1.3678, 1.8463, 0.3062, 1.9308,\n",
      "        1.5665, 1.1197, 1.5494, 1.3061, 1.1069, 1.9752, 0.2561, 2.5859, 0.5466,\n",
      "        2.6449, 2.2276, 1.2903, 2.3150, 1.8669, 1.1400], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-8.6157e-01, -2.6447e+00, -3.8672e-01,  1.6936e-01, -1.1903e+00,\n",
      "        -4.5486e-01, -1.3731e+00,  2.9929e-01, -1.1235e+00, -2.1489e+00,\n",
      "        -2.8498e+00, -3.1634e-01, -6.6901e-02, -9.2524e-01,  2.9194e-01,\n",
      "        -8.3256e-01, -1.1565e+00, -2.2042e+00, -6.7071e-01, -4.3392e-01,\n",
      "        -1.9068e+00, -8.8025e-01, -1.7946e+00, -1.1732e-01, -4.3612e-01,\n",
      "        -6.6362e-01, -3.2229e-01, -1.5151e+00, -9.6365e-02, -1.4361e+00,\n",
      "        -2.1902e-01, -2.8269e+00, -1.4709e+00,  2.2540e-01, -1.8067e+00,\n",
      "        -1.0093e+00, -1.0520e+00, -2.2158e+00, -1.9772e+00,  4.4294e-01,\n",
      "        -9.3512e-01, -9.9639e-01, -9.3531e-01, -1.5868e+00, -1.4101e+00,\n",
      "        -1.3914e+00, -1.5739e+00, -8.6569e-01, -1.4420e+00, -2.9048e-01,\n",
      "        -1.0789e+00, -1.9708e+00, -1.7553e+00, -1.6084e+00, -3.2474e-01,\n",
      "        -1.3120e+00, -6.6571e-01, -5.3955e-02, -3.0062e-01, -6.1551e-01,\n",
      "        -1.9658e+00,  9.5796e-02, -1.1052e+00, -4.5608e-01, -1.0360e+00,\n",
      "        -1.1041e+00, -7.6299e-01, -5.7346e-01,  3.9696e-01, -8.2937e-02,\n",
      "        -1.0610e+00, -3.2437e-01, -6.7761e-01, -1.9023e+00, -6.6434e-01,\n",
      "        -2.5554e-01, -1.2327e+00, -3.9665e-01, -2.6456e+00, -1.2155e+00,\n",
      "        -6.2838e-01, -1.2187e+00, -1.2042e+00, -8.0711e-02, -1.5082e+00,\n",
      "         7.2588e-01, -7.8426e-01, -9.7552e-02, -2.7110e-01, -5.8572e-01,\n",
      "        -9.1552e-01, -9.0955e-01, -5.0891e-01, -1.0899e+00, -3.1744e-01,\n",
      "        -4.8980e-01, -1.6885e+00, -7.1950e-01, -1.1978e+00, -2.0138e+00,\n",
      "        -4.3836e-01,  1.1506e-01, -6.2935e-01, -2.3723e-01, -5.1538e-01,\n",
      "        -1.6544e+00, -8.5307e-01,  5.9829e-01, -2.7301e+00, -7.3699e-01,\n",
      "        -7.0061e-01, -4.1655e-01, -1.5320e+00, -3.4038e-01, -1.3389e+00,\n",
      "        -1.8298e+00, -8.0583e-02,  3.7114e-01, -1.3401e+00,  1.0122e+00,\n",
      "        -1.6505e+00, -4.1283e-01, -1.8697e+00, -2.9277e+00, -7.0453e-01,\n",
      "        -1.0649e+00, -5.5584e-01, -1.0300e+00, -4.6411e-01, -8.1135e-01,\n",
      "        -2.3424e+00, -1.2806e+00, -2.3428e+00, -8.0795e-01, -3.5383e-01,\n",
      "        -2.1829e+00, -1.4085e+00, -9.8737e-01, -3.3887e-01,  1.4020e-01,\n",
      "        -8.4321e-01, -6.7275e-01, -2.0820e+00, -8.9474e-01, -1.2208e+00,\n",
      "        -5.3562e-01, -1.6066e+00, -4.9116e-01, -6.8957e-01, -1.2172e+00,\n",
      "        -2.3401e+00, -7.3689e-01, -1.4048e+00, -1.0770e+00, -8.5556e-01,\n",
      "        -1.2644e+00, -2.2285e+00, -6.0740e-01, -8.0398e-01, -2.4797e+00,\n",
      "         1.9274e-03, -1.5326e+00, -9.9671e-01, -5.4397e-01, -6.6875e-01,\n",
      "        -1.6205e+00, -3.3039e-01, -2.6170e+00, -4.0889e-01, -7.5280e-01,\n",
      "        -1.6864e+00, -7.7468e-01, -7.5845e-01, -1.1004e+00, -3.4652e-01,\n",
      "        -3.5435e-01, -1.2066e-02, -9.0345e-01, -5.4963e-01, -6.8117e-01,\n",
      "        -1.2780e+00, -3.5671e+00, -1.3252e+00, -1.5154e-01, -7.1152e-01,\n",
      "        -2.1733e-01,  5.7436e-03, -4.1127e-01, -2.7974e+00, -2.4968e+00,\n",
      "         6.9105e-01, -1.0469e+00, -7.1616e-01, -1.5397e+00, -5.2759e-02,\n",
      "        -5.4805e-01, -2.6083e-01,  2.6115e-02, -5.6830e-01, -1.6240e+00,\n",
      "        -6.3695e-01, -2.0031e-01, -1.2319e+00, -1.7493e+00, -2.5473e+00,\n",
      "        -1.1112e+00, -1.4518e+00, -2.4858e+00, -5.0087e-01, -1.4625e+00,\n",
      "        -6.6740e-01, -4.3312e-01, -7.8652e-01, -2.6909e-01, -6.6455e-01,\n",
      "        -4.1486e-01, -1.0859e-01, -1.4375e+00, -1.1578e+00, -8.6885e-01,\n",
      "        -1.5725e+00, -2.2518e-01, -7.0000e-01, -9.3048e-01, -7.3163e-01,\n",
      "        -7.2068e-01, -2.1630e-02, -1.1361e+00, -1.4386e+00, -1.2801e+00,\n",
      "        -2.8672e-01, -1.3217e+00, -1.2131e+00, -3.4775e+00, -1.1998e+00,\n",
      "        -2.7751e-01,  3.0096e-01, -1.4582e+00, -7.8001e-01, -3.2250e-01,\n",
      "        -4.0792e-01, -4.4949e-02, -1.6974e+00, -4.1582e-01, -3.3109e-01,\n",
      "        -5.9754e-01, -1.7980e+00, -1.7870e-01, -7.2957e-01,  4.4463e-01,\n",
      "        -1.2383e+00, -6.9363e-01, -2.8748e-01,  8.3210e-02, -2.2112e+00,\n",
      "        -1.7122e-01, -6.7386e-01, -1.4417e+00, -3.9579e-01, -2.9352e-01,\n",
      "         8.5014e-02, -1.2717e+00,  1.2458e-01, -2.3514e+00, -6.3719e-01,\n",
      "        -7.6995e-01, -1.5170e-01, -1.1479e+00, -1.4090e+00,  1.9035e-01,\n",
      "        -1.5613e+00, -1.8029e+00,  2.2929e-01, -4.2050e-01, -1.9246e+00,\n",
      "        -6.2525e-01, -7.5599e-01, -8.1279e-01, -2.2585e+00, -1.1032e+00,\n",
      "        -1.6997e+00, -2.1230e+00, -9.4460e-01, -4.1665e-01, -1.4258e+00,\n",
      "        -6.6134e-01, -8.4022e-01, -7.9564e-01, -1.5951e+00, -1.4515e+00,\n",
      "         1.3861e-01, -1.7718e+00, -1.3434e+00, -1.7170e+00, -3.2280e+00,\n",
      "        -1.7016e+00, -4.8298e-01, -1.3074e+00, -7.1354e-01, -1.9888e+00,\n",
      "        -1.3848e+00, -3.6215e-01, -1.2580e+00, -7.9609e-02, -8.0929e-02,\n",
      "        -7.8778e-01, -1.3667e+00, -3.8703e-01, -1.7717e+00,  1.9351e-01,\n",
      "        -6.0450e-01, -1.2027e+00, -4.9452e-01, -1.8301e+00, -3.1754e-01,\n",
      "        -9.9980e-01,  1.5329e-01, -1.4010e+00, -4.9347e-01, -1.9545e+00,\n",
      "        -7.9732e-01, -2.6005e-01, -7.6797e-01, -2.7313e-01, -7.5806e-01,\n",
      "        -8.7495e-01, -2.0442e+00, -1.9112e+00, -2.3320e-01, -6.6245e-02,\n",
      "        -1.3729e+00, -1.7041e+00, -4.4295e-01, -1.3469e+00, -3.1917e-01,\n",
      "        -1.8103e+00, -4.2741e-01, -8.6618e-01, -5.8633e-02, -2.7734e-01,\n",
      "        -1.2610e+00, -2.5522e+00, -2.3526e+00, -1.1022e+00, -9.0653e-01,\n",
      "        -7.4528e-01, -2.0458e+00, -7.7136e-01, -7.1105e-01, -6.6550e-02,\n",
      "        -2.7777e-01, -1.3878e+00, -2.4587e+00, -7.5421e-01, -2.0751e-02,\n",
      "        -1.2410e+00, -1.2222e+00, -1.2767e+00, -1.3562e+00, -1.3855e-01,\n",
      "        -4.2427e-01, -1.2954e+00, -1.9843e+00, -3.2285e-01, -1.6686e+00,\n",
      "        -1.2633e+00,  3.0810e-01, -7.3933e-01, -3.5801e-03, -2.0566e+00,\n",
      "        -1.0993e+00, -1.2828e+00, -5.4003e-01, -9.0710e-01, -2.0385e+00,\n",
      "        -1.4176e+00, -1.1851e+00, -8.9721e-01, -1.8614e-01, -7.0815e-02,\n",
      "        -9.0552e-01, -1.6190e+00, -1.7212e+00, -1.3183e+00, -2.6269e-01,\n",
      "        -1.2376e+00, -1.2736e+00, -1.2525e+00, -2.9665e-01, -2.2405e+00,\n",
      "        -8.7357e-01,  2.4195e-01, -6.8870e-01, -4.2196e-01, -7.2340e-01,\n",
      "        -8.0910e-02, -1.4709e+00, -1.2071e+00, -1.2198e+00, -9.1207e-01,\n",
      "        -1.3136e+00, -3.1803e-02, -7.7553e-01, -1.3574e+00, -1.8934e+00,\n",
      "         4.6469e-02, -7.9741e-01, -1.5548e+00, -4.6423e-01, -6.1294e-01,\n",
      "        -6.2066e-01, -6.7612e-01, -2.1345e-01, -2.8037e+00, -1.2212e+00,\n",
      "        -1.1877e+00, -1.1390e+00, -1.8857e-01, -1.8872e-01, -2.6959e-01,\n",
      "        -5.2034e-01, -1.6116e+00, -2.2142e+00, -9.4492e-01, -2.3735e-01,\n",
      "        -3.5528e-03, -2.0416e+00, -2.0304e-01, -1.7786e+00, -5.9647e-01,\n",
      "        -7.7988e-01, -5.1865e-02, -5.1623e-01, -1.5177e+00, -6.6739e-01,\n",
      "        -6.5271e-01, -1.4789e-01, -1.6193e+00, -1.1945e+00, -3.5360e-01,\n",
      "        -7.6304e-01, -6.8822e-01, -1.1433e+00, -3.6394e+00, -1.7930e+00,\n",
      "        -3.4625e-01, -1.6421e-01,  1.8014e-01, -2.4305e-01, -1.1311e+00,\n",
      "        -5.1566e-01, -5.2811e-01, -1.0058e+00, -1.4758e+00, -3.4201e-01,\n",
      "        -5.7833e-01, -8.6864e-02, -1.0287e+00, -3.1189e-01, -8.3467e-01,\n",
      "        -5.6525e-01,  1.4303e-01, -1.1426e-01, -9.4496e-01, -1.6820e+00,\n",
      "        -2.6842e-01, -1.5310e+00, -1.4724e+00, -7.6641e-01, -3.9334e-01,\n",
      "        -2.2671e+00, -1.7765e+00, -1.4284e+00, -1.1568e+00,  7.5495e-02,\n",
      "        -1.4607e-02, -1.6299e+00, -1.5243e+00, -2.2899e+00,  7.1588e-01,\n",
      "        -3.8346e-01, -3.1570e-01,  1.2291e+00, -1.3495e+00, -4.5946e-02,\n",
      "        -1.9998e+00, -2.8629e-01, -8.6146e-01, -4.1600e-01, -2.0844e+00,\n",
      "        -1.0254e+00, -1.5298e+00, -2.9318e-01, -6.6902e-01, -1.3541e+00,\n",
      "        -9.6308e-01, -1.3906e+00, -1.2142e+00, -8.7676e-01, -1.6621e+00,\n",
      "        -1.1990e+00, -2.3382e+00, -3.7505e-01, -2.0271e+00,  2.0867e-01,\n",
      "        -1.1499e+00, -9.4589e-01, -3.3612e-01, -2.8140e+00, -1.5348e+00,\n",
      "        -1.5916e+00, -1.7726e+00, -5.6159e-01, -1.2799e-01, -1.2215e+00,\n",
      "        -1.2186e-01, -3.9702e-01, -1.3861e+00, -1.0602e+00, -3.2432e-01,\n",
      "        -6.7407e-01, -6.8741e-01, -1.2410e-01, -1.0289e+00, -1.2863e+00,\n",
      "        -1.1104e-01, -1.8194e+00, -5.2471e-01, -1.0459e+00, -3.2848e-01,\n",
      "        -1.7476e+00, -1.0950e+00,  2.3777e-01, -4.4763e-01, -6.4648e-01,\n",
      "        -2.4838e+00, -1.2764e+00, -3.6396e-01, -3.5947e-01, -1.0203e+00,\n",
      "         8.5194e-02, -1.6346e+00, -9.8385e-01, -1.6078e+00, -3.1925e-01,\n",
      "        -1.1432e+00, -7.5683e-01, -8.6263e-01, -1.6881e+00, -1.5737e+00,\n",
      "        -9.7995e-01, -6.7108e-01, -4.0223e-01, -1.9662e+00, -2.9895e-01,\n",
      "        -1.8857e+00, -8.6727e-01, -4.0440e-01, -2.1806e+00, -1.0428e+00,\n",
      "        -1.4185e-01, -9.3026e-02, -2.2250e+00, -1.2362e+00, -1.8527e-01,\n",
      "        -1.1386e+00,  3.4066e-01, -1.7447e+00, -1.6302e+00, -5.6249e-01,\n",
      "        -1.7869e+00, -1.7853e+00, -1.1136e+00, -1.9815e+00, -1.0531e+00,\n",
      "        -2.4018e+00, -1.6447e+00, -5.4952e-01, -2.1946e-01, -1.0501e+00,\n",
      "        -1.7086e-01, -1.0878e+00, -5.4691e-01, -6.0296e-01, -1.4423e+00,\n",
      "        -5.8045e-01, -3.4327e+00, -1.3767e+00, -1.3466e+00, -3.1136e-01,\n",
      "        -1.1741e+00, -6.7549e-01, -1.4276e+00, -2.1428e-01, -1.2063e+00,\n",
      "        -2.8107e-01, -1.8838e-01, -3.0729e-01, -1.6570e+00, -4.1545e-01,\n",
      "        -8.4662e-01, -1.1099e+00, -4.0243e-01, -9.1827e-01, -2.0070e+00,\n",
      "        -9.6684e-01, -2.3513e+00, -2.4872e+00,  3.6620e-02,  5.4425e-01,\n",
      "        -9.7244e-01,  1.4160e-01, -2.4201e+00, -5.9607e-01, -1.4727e+00,\n",
      "        -5.4457e-01, -5.4960e-01, -1.4389e+00, -8.9130e-01, -1.3843e+00,\n",
      "        -7.7147e-01, -5.4823e-01, -1.2443e+00, -1.5827e+00, -1.1373e+00,\n",
      "        -1.6913e-01, -9.3393e-01,  2.3421e-01, -5.4734e-01, -2.1398e+00,\n",
      "         2.2864e-01, -1.1165e+00, -9.5997e-01,  2.6757e-01, -8.3993e-01,\n",
      "        -1.7401e+00, -3.9774e-01, -1.9746e+00, -1.5943e+00, -3.3655e+00,\n",
      "        -1.9460e+00, -1.7157e+00,  4.4000e-02, -1.5303e+00,  2.7849e-01,\n",
      "         3.0321e-02, -4.1282e-01, -1.3930e+00,  7.8082e-01, -1.3980e+00,\n",
      "        -1.7322e+00, -1.4242e+00, -1.3100e+00, -1.3378e+00, -7.2218e-01,\n",
      "        -1.4030e+00, -1.9276e+00, -1.9784e-02, -8.5587e-01, -1.1037e+00,\n",
      "         9.3464e-02, -1.3229e+00, -8.5503e-01, -1.7241e+00, -1.2632e+00,\n",
      "         8.8282e-02, -1.6085e-01, -2.7631e-01,  3.0137e-01, -3.3199e-01,\n",
      "        -1.0674e+00, -1.2473e+00, -1.3179e+00, -3.0869e-01, -6.0704e-01,\n",
      "        -1.3932e+00, -1.6841e-01, -1.1012e+00, -3.2992e+00, -2.0425e-01,\n",
      "        -4.5415e-01, -1.2129e+00, -1.6206e+00, -2.3780e+00, -3.8688e-01,\n",
      "        -8.2025e-01, -1.0522e+00, -8.4007e-01, -1.9073e+00, -1.0814e+00,\n",
      "        -6.6780e-01, -1.3428e+00, -1.0138e+00, -4.6041e-01, -7.1338e-01,\n",
      "        -3.6866e-01, -1.4987e+00, -3.5224e-02, -1.5256e+00, -2.0634e-01,\n",
      "        -5.4427e-01, -3.2383e-01, -1.1779e+00, -2.6064e+00, -3.0465e-01,\n",
      "        -1.0308e+00, -9.2326e-01, -1.0144e+00, -4.6532e-02, -9.7729e-01,\n",
      "        -1.0530e+00, -1.4654e+00, -1.2319e+00, -2.2540e+00, -2.3944e-01,\n",
      "        -1.9236e-01, -2.1782e-01, -2.8549e+00, -1.6954e+00, -5.8092e-01,\n",
      "         6.6918e-01, -6.3416e-01, -1.3177e+00, -6.1809e-01,  4.6457e-01,\n",
      "        -4.4417e-01, -9.5802e-01, -2.4929e+00, -1.2293e+00, -1.4469e+00,\n",
      "        -8.6168e-01, -5.9385e-02, -5.8408e-01, -1.7842e+00, -1.2287e+00,\n",
      "        -1.7128e+00, -5.7945e-01, -1.4713e+00, -1.2206e+00, -1.3695e+00,\n",
      "        -4.6310e-02, -1.1387e+00, -1.6561e+00, -1.9061e-01, -2.4536e+00,\n",
      "        -9.2089e-01, -1.5789e+00, -9.9625e-01, -1.8152e-01, -1.5700e+00,\n",
      "        -9.3814e-01, -1.3155e+00, -3.7629e-01, -1.4225e+00,  3.2358e-01,\n",
      "        -2.1599e+00, -7.2020e-01, -9.8322e-01, -2.4080e+00, -1.1150e+00,\n",
      "        -1.9868e+00, -2.5469e+00, -1.5823e+00, -2.7080e+00, -9.5530e-02,\n",
      "        -1.4612e+00, -1.5090e+00, -1.3809e+00, -7.1279e-01, -2.1611e+00,\n",
      "        -7.6466e-01, -1.2639e-01, -1.6468e+00, -1.0145e+00, -7.0951e-01,\n",
      "        -1.9108e+00,  3.9312e-01, -4.6184e-01, -6.4673e-01, -1.5630e+00,\n",
      "        -5.7039e-01,  1.2482e-01, -1.1663e+00, -1.3524e+00, -1.2335e+00,\n",
      "        -2.3731e+00,  6.1923e-02, -5.5897e-01, -1.0283e+00, -1.4323e+00,\n",
      "        -1.1055e+00, -1.1101e+00, -9.7949e-01, -8.1937e-01, -7.5013e-01,\n",
      "        -1.0433e+00, -7.8401e-01, -1.4729e+00, -4.2658e-01, -3.2884e-02,\n",
      "        -1.7787e+00, -1.0989e+00, -9.7901e-01, -1.1255e-01, -1.9710e+00,\n",
      "        -4.3336e-01, -7.2602e-01,  7.4369e-01, -1.4760e+00, -1.2180e-01,\n",
      "        -6.7433e-01, -1.3049e+00,  5.1153e-01, -9.0689e-01, -2.8690e-01,\n",
      "        -5.5468e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2079]],\n",
      "\n",
      "         [[-0.2434]],\n",
      "\n",
      "         [[ 0.2486]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3852]],\n",
      "\n",
      "         [[ 0.0823]],\n",
      "\n",
      "         [[-0.4610]]],\n",
      "\n",
      "\n",
      "        [[[-0.1325]],\n",
      "\n",
      "         [[ 0.4086]],\n",
      "\n",
      "         [[ 0.0934]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2904]],\n",
      "\n",
      "         [[ 0.4558]],\n",
      "\n",
      "         [[ 0.3188]]],\n",
      "\n",
      "\n",
      "        [[[-0.0267]],\n",
      "\n",
      "         [[-0.3797]],\n",
      "\n",
      "         [[ 0.2086]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4457]],\n",
      "\n",
      "         [[ 0.3850]],\n",
      "\n",
      "         [[-0.8254]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0189]],\n",
      "\n",
      "         [[ 0.0261]],\n",
      "\n",
      "         [[ 0.0012]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0640]],\n",
      "\n",
      "         [[-0.4123]],\n",
      "\n",
      "         [[-0.6124]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0901]],\n",
      "\n",
      "         [[-0.0752]],\n",
      "\n",
      "         [[ 0.0364]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2077]],\n",
      "\n",
      "         [[-0.2879]],\n",
      "\n",
      "         [[-0.0067]]],\n",
      "\n",
      "\n",
      "        [[[-0.3157]],\n",
      "\n",
      "         [[ 0.5441]],\n",
      "\n",
      "         [[-0.1325]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1272]],\n",
      "\n",
      "         [[-0.1640]],\n",
      "\n",
      "         [[ 0.1359]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1747, -0.0328,  0.1146, -0.1570, -0.2309, -0.2203, -0.2702, -0.1058,\n",
      "        -0.1026, -0.1901, -0.2799,  0.0797,  0.1147,  0.1041, -0.0756, -0.1360,\n",
      "        -0.2120, -0.1683,  0.1404,  0.1787, -0.1868,  0.0577, -0.0637,  0.2032,\n",
      "        -0.0845,  0.2003, -0.2635,  0.0727, -0.2059, -0.1619,  0.1552,  0.2328,\n",
      "        -0.1100,  0.0901], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2225]],\n",
      "\n",
      "         [[ 0.1155]],\n",
      "\n",
      "         [[ 0.1122]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.8195]],\n",
      "\n",
      "         [[-0.1283]],\n",
      "\n",
      "         [[ 0.1676]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0319]],\n",
      "\n",
      "         [[ 0.1610]],\n",
      "\n",
      "         [[ 0.2203]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3393]],\n",
      "\n",
      "         [[-0.0904]],\n",
      "\n",
      "         [[ 0.2236]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1237]],\n",
      "\n",
      "         [[ 0.0268]],\n",
      "\n",
      "         [[-0.3949]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1088]],\n",
      "\n",
      "         [[ 0.2057]],\n",
      "\n",
      "         [[-0.4174]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1200]],\n",
      "\n",
      "         [[-0.1830]],\n",
      "\n",
      "         [[-0.1153]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5229]],\n",
      "\n",
      "         [[-0.0814]],\n",
      "\n",
      "         [[-0.1682]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2634]],\n",
      "\n",
      "         [[ 0.4029]],\n",
      "\n",
      "         [[ 0.2575]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0194]],\n",
      "\n",
      "         [[-0.0406]],\n",
      "\n",
      "         [[-0.0679]]],\n",
      "\n",
      "\n",
      "        [[[-0.1789]],\n",
      "\n",
      "         [[ 0.2372]],\n",
      "\n",
      "         [[ 0.3023]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0779]],\n",
      "\n",
      "         [[ 0.1248]],\n",
      "\n",
      "         [[ 0.3834]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.4491,  0.4155,  0.0313, -0.1434,  0.0884,  0.0725,  0.2438, -0.0264,\n",
      "        -0.3392, -0.2537, -0.1314, -0.2645, -0.2585, -0.1765, -0.2680, -0.3350,\n",
      "        -0.1619,  0.3052, -0.0863,  0.0915,  0.0149, -0.3222, -0.0099, -0.2780,\n",
      "        -0.0827, -0.5269,  0.4652,  0.0788,  0.0229, -0.4139,  0.0585, -0.2669,\n",
      "        -0.0802,  0.2566,  0.2376, -0.3246,  0.0067,  0.1100,  0.0427,  0.2670,\n",
      "        -0.4327, -0.3915, -0.0596, -0.0555, -0.4062,  0.1805,  0.5173, -0.0567,\n",
      "         0.3182, -0.3400,  0.2464,  0.0926,  0.4379, -0.2110, -0.1924, -0.2041,\n",
      "        -0.1169,  0.3617,  0.3522, -0.2106, -0.1060,  0.5713,  0.2705, -0.3618,\n",
      "        -0.4395,  0.3586, -0.0507, -0.2045,  0.7023,  0.0607,  0.3830,  0.3535,\n",
      "        -0.3394, -0.2924, -0.0853,  0.3749,  0.1253, -0.1464, -0.0825,  0.1453,\n",
      "         0.3241, -0.4254, -0.0946, -0.0976, -0.0910, -0.0130, -0.0385, -0.1924,\n",
      "        -0.1694, -0.3883,  0.0696,  0.0118, -0.1731, -0.3353, -0.5998,  0.1856,\n",
      "        -0.3600,  0.0317, -0.0257, -0.3343, -0.1769,  0.3149, -0.3140, -0.1951,\n",
      "        -0.0697, -0.0177,  0.1506,  0.4020, -0.1992, -0.1795, -0.0717,  0.1255,\n",
      "        -0.1658,  0.2236,  0.1601,  0.0087,  0.2714,  0.0199,  0.0694, -0.5165,\n",
      "         0.2744,  0.2352,  0.3224, -0.2682,  0.1841,  0.3837, -0.5152, -0.4628,\n",
      "         0.0343,  0.1214,  0.0771, -0.1177, -0.1039, -0.4161, -0.4150, -0.1061,\n",
      "        -0.1928,  0.1936, -0.3719,  0.2850,  0.3713,  0.0068, -0.0653,  0.0061,\n",
      "         0.0183, -0.2792, -0.2612, -0.2646, -0.3159, -0.3693, -0.1677, -0.3762,\n",
      "         0.4150, -0.2906,  0.1986, -0.4675,  0.0843,  0.1081, -0.2718,  0.2390,\n",
      "         0.4746, -0.0977,  0.2027,  0.0820, -0.1334, -0.3395,  0.1750,  0.3216,\n",
      "         0.3389, -0.4216, -0.0227,  0.0640, -0.5256, -0.1776,  0.2261, -0.2758,\n",
      "        -0.1144, -0.3226, -0.1180,  0.0356,  0.4044, -0.3197, -0.3840,  0.0359,\n",
      "        -0.3567,  0.2241,  0.1861, -0.4390,  0.0119, -0.5275,  0.0071, -0.4859,\n",
      "         0.2110, -0.2152, -0.2587, -0.3840,  0.3000,  0.2975, -0.3218,  0.3279,\n",
      "         0.1909, -0.2738,  0.1219,  0.4713,  0.4245,  0.3388,  0.4368,  0.2784,\n",
      "         0.0957,  0.2255, -0.3752,  0.2266,  0.2918, -0.2275,  0.0867,  0.3071,\n",
      "         0.3568,  0.1032,  0.1957,  0.2049,  0.4634,  0.4239,  0.0616, -0.3623,\n",
      "        -0.3319, -0.2081,  0.4259,  0.3404,  0.2448,  0.3940, -0.2173,  0.0405,\n",
      "         0.3338, -0.1042, -0.0074, -0.2435, -0.0533, -0.1484,  0.0499,  0.3148,\n",
      "         0.2481,  0.0481, -0.0190,  0.0461, -0.0259,  0.4335, -0.0145,  0.2755,\n",
      "         0.1861,  0.3134,  0.2173, -0.2288,  0.1226, -0.0275, -0.4421, -0.1854,\n",
      "         0.3587, -0.1735, -0.4747, -0.0714,  0.2803, -0.2449,  0.2172,  0.1608,\n",
      "         0.4905, -0.1751,  0.5093,  0.3035, -0.3152, -0.0273,  0.4326, -0.2101,\n",
      "         0.4449,  0.0847, -0.3061,  0.5704, -0.4187,  0.2621, -0.5131, -0.1632,\n",
      "         0.3388,  0.1629, -0.4156,  0.3488, -0.3309,  0.1477, -0.2025, -0.2947,\n",
      "         0.0934,  0.0146,  0.4429, -0.2746, -0.4128, -0.1911,  0.0742, -0.0274,\n",
      "        -0.5049,  0.0887, -0.0625,  0.0803, -0.1175, -0.4067,  0.3322,  0.0480,\n",
      "         0.3145, -0.1177, -0.3594, -0.0164, -0.1052, -0.0479, -0.2998, -0.0162,\n",
      "        -0.0313, -0.3306,  0.3379, -0.1792,  0.2168,  0.0683,  0.0148,  0.2440,\n",
      "         0.5914,  0.0012,  0.3602, -0.1192, -0.1688, -0.5574, -0.1057,  0.3682,\n",
      "        -0.0208, -0.0407, -0.1433, -0.1804, -0.2754, -0.3797, -0.3858,  0.2644,\n",
      "        -0.1332, -0.2578, -0.0298, -0.5013, -0.3692,  0.3899,  0.0057, -0.3934,\n",
      "         0.3225,  0.3091,  0.3021,  0.3482,  0.0891, -0.3275, -0.2349,  0.0417,\n",
      "        -0.4399, -0.1563, -0.2591, -0.3121, -0.0393,  0.4181, -0.1034, -0.1488,\n",
      "         0.3979,  0.0604, -0.3236,  0.4000, -0.0587,  0.3916, -0.1771,  0.2198,\n",
      "         0.1371, -0.2601,  0.5147, -0.2306, -0.3244, -0.1812, -0.3845, -0.2711,\n",
      "        -0.3806,  0.2242,  0.1229, -0.1436, -0.1450,  0.1687,  0.2887,  0.0057,\n",
      "        -0.5393,  0.2225,  0.0691, -0.0885, -0.3401, -0.0407, -0.3114, -0.0354,\n",
      "         0.3403, -0.0749, -0.2902, -0.3506,  0.2226,  0.3338,  0.3470,  0.4533,\n",
      "         0.0764, -0.0963, -0.0090, -0.4413,  0.1816,  0.3582,  0.0585,  0.1752,\n",
      "         0.1027,  0.0219,  0.0252, -0.3802, -0.1217,  0.3481,  0.0961, -0.1451,\n",
      "        -0.0951, -0.4379, -0.3380, -0.3552, -0.1680, -0.2667, -0.1378, -0.1400,\n",
      "        -0.2892,  0.0839,  0.2777, -0.4925,  0.0518,  0.1540, -0.3899,  0.0965,\n",
      "         0.2840, -0.0641, -0.0662,  0.1005,  0.1252, -0.0886, -0.1685,  0.4012,\n",
      "        -0.3993,  0.0878,  0.3277, -0.2835, -0.1872, -0.3116, -0.4086, -0.0622,\n",
      "        -0.2228,  0.1338,  0.4048,  0.4489, -0.1497,  0.1322, -0.4205,  0.2377,\n",
      "        -0.0371,  0.0581,  0.5688,  0.2951, -0.0784, -0.3104,  0.2308, -0.1845,\n",
      "        -0.4606, -0.0349, -0.3231, -0.3254,  0.2790, -0.1068, -0.0801, -0.2855,\n",
      "         0.2196,  0.2941,  0.3231,  0.2906, -0.0350,  0.2270,  0.2232, -0.2905,\n",
      "        -0.2340, -0.3476, -0.2557,  0.1411,  0.2946,  0.1449,  0.0717,  0.3090,\n",
      "         0.0383,  0.3848,  0.0553,  0.0423, -0.3828, -0.1711,  0.3634,  0.5510,\n",
      "        -0.1869, -0.0628, -0.4026,  0.1835, -0.1506,  0.0199,  0.1020,  0.2080,\n",
      "         0.3368,  0.3924, -0.0558,  0.1880,  0.3198, -0.3164,  0.2741,  0.3296,\n",
      "        -0.2248, -0.3105,  0.1133, -0.4307, -0.2826, -0.2934, -0.3334, -0.2146,\n",
      "        -0.1507, -0.1233, -0.4322,  0.0289, -0.1358,  0.0779, -0.4712, -0.2554,\n",
      "        -0.2941, -0.2510,  0.1398,  0.1627, -0.4288,  0.5723, -0.2493, -0.4626,\n",
      "         0.3218, -0.1598,  0.2506, -0.4145,  0.4174,  0.0615, -0.4468, -0.3455,\n",
      "        -0.0167, -0.3866, -0.1780, -0.0363, -0.3661, -0.5277,  0.0491, -0.3083,\n",
      "        -0.0826, -0.3881, -0.2963,  0.1583,  0.2699, -0.3860, -0.1829,  0.0103,\n",
      "        -0.2697, -0.3933,  0.2755, -0.1395,  0.0411, -0.0413, -0.1590, -0.0718,\n",
      "         0.3092, -0.4042,  0.1924, -0.0622, -0.1688,  0.1293, -0.3464, -0.0248,\n",
      "        -0.3031,  0.0351, -0.2248,  0.1155, -0.3347,  0.3443, -0.3936,  0.1669,\n",
      "        -0.0188, -0.3526, -0.1425,  0.4510,  0.0478,  0.0539,  0.3282, -0.0588,\n",
      "         0.4141,  0.1335,  0.2284,  0.3007,  0.3696, -0.1093,  0.2161,  0.2718,\n",
      "        -0.0567,  0.2701, -0.0796, -0.4848, -0.4536,  0.4990,  0.3497, -0.1774,\n",
      "         0.2807,  0.4550, -0.3152,  0.1118, -0.0413,  0.3396,  0.3121, -0.3660,\n",
      "        -0.4436, -0.1379, -0.3023, -0.2175, -0.1630, -0.2300, -0.1733, -0.0480,\n",
      "         0.2185, -0.2442,  0.1088,  0.5177,  0.1309,  0.0318,  0.4921,  0.3796,\n",
      "         0.2657,  0.2677, -0.2798, -0.1980, -0.2494,  0.0939, -0.3856,  0.0254,\n",
      "        -0.2263,  0.1934,  0.3753,  0.4577,  0.3789, -0.0873,  0.0377,  0.1908,\n",
      "         0.1549, -0.0946, -0.0824,  0.2804,  0.2127,  0.1453, -0.0811,  0.1562,\n",
      "        -0.0531, -0.2558,  0.1248,  0.1496,  0.3472,  0.0241, -0.1929,  0.0959,\n",
      "        -0.1129, -0.1151,  0.3939,  0.2078, -0.1607, -0.0787, -0.0918, -0.2500,\n",
      "         0.0758,  0.0182, -0.0294,  0.1811, -0.1728, -0.1128,  0.2864,  0.2419,\n",
      "        -0.1935,  0.3145,  0.4626,  0.0161,  0.3664, -0.1114,  0.3923, -0.1886,\n",
      "        -0.1555,  0.0627, -0.1513, -0.2958, -0.1182, -0.1178, -0.3933,  0.3927,\n",
      "         0.4775,  0.0449,  0.2831, -0.3278, -0.0109,  0.2843,  0.1701, -0.4966,\n",
      "         0.2786, -0.1291,  0.0659, -0.2952,  0.5004,  0.2488, -0.5233,  0.2613,\n",
      "         0.2427,  0.0490,  0.2067, -0.4232,  0.1180,  0.3207,  0.0372, -0.2708,\n",
      "        -0.1739,  0.2223, -0.1460, -0.0420, -0.2492, -0.0809, -0.3863,  0.0844,\n",
      "        -0.2680,  0.1930,  0.0601,  0.3763, -0.4209, -0.0302,  0.5414, -0.4905,\n",
      "         0.0871,  0.2357,  0.2412,  0.5342, -0.1107, -0.3490, -0.2081,  0.4268,\n",
      "         0.1952, -0.0927,  0.3082, -0.0965, -0.1437,  0.4290, -0.2362,  0.3819,\n",
      "        -0.5044,  0.2328,  0.2377,  0.2524, -0.3354, -0.2964,  0.4000,  0.2602,\n",
      "        -0.1611, -0.1692,  0.1759, -0.2146, -0.1909, -0.3282, -0.4084, -0.2398,\n",
      "         0.1753,  0.3022, -0.1377,  0.1165, -0.3426, -0.4454,  0.2081,  0.4172,\n",
      "         0.1746,  0.0668, -0.2843, -0.0971, -0.1763,  0.4787,  0.0131,  0.0063,\n",
      "        -0.1456,  0.1091,  0.3461,  0.0083, -0.1273,  0.0560,  0.4932, -0.1204,\n",
      "        -0.2950, -0.2048,  0.1043,  0.3874,  0.4026, -0.3241,  0.0288,  0.1186,\n",
      "         0.3064,  0.2302, -0.2259, -0.2094,  0.3426, -0.1746,  0.0441, -0.1299,\n",
      "        -0.0644, -0.2869,  0.2044,  0.3950,  0.3307, -0.3570,  0.4086,  0.0803],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1679]],\n",
      "\n",
      "         [[-0.1364]],\n",
      "\n",
      "         [[ 0.4053]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2894]],\n",
      "\n",
      "         [[ 0.7407]],\n",
      "\n",
      "         [[-0.0188]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2746]],\n",
      "\n",
      "         [[ 0.4518]],\n",
      "\n",
      "         [[-0.2106]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2868]],\n",
      "\n",
      "         [[-0.9237]],\n",
      "\n",
      "         [[-0.0190]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6480]],\n",
      "\n",
      "         [[ 0.5029]],\n",
      "\n",
      "         [[ 0.3879]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0925]],\n",
      "\n",
      "         [[ 0.1992]],\n",
      "\n",
      "         [[-0.0426]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1376]],\n",
      "\n",
      "         [[ 0.2966]],\n",
      "\n",
      "         [[ 0.2097]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0943]],\n",
      "\n",
      "         [[ 0.6595]],\n",
      "\n",
      "         [[ 0.6320]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2963]],\n",
      "\n",
      "         [[-0.4016]],\n",
      "\n",
      "         [[-0.2503]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1080]],\n",
      "\n",
      "         [[ 0.0272]],\n",
      "\n",
      "         [[-0.2573]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2489]],\n",
      "\n",
      "         [[ 0.1416]],\n",
      "\n",
      "         [[ 0.2878]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2797]],\n",
      "\n",
      "         [[-0.3780]],\n",
      "\n",
      "         [[-0.5347]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 9.3476e-01,  5.4389e-01,  1.0940e+00,  1.1899e+00,  1.8176e-02,\n",
      "         3.0636e-01,  1.1768e+00,  3.0667e+00,  6.8874e-01,  2.5252e-01,\n",
      "         5.1750e-01,  2.4269e-01,  1.3248e+00,  1.9765e-01,  7.0771e-01,\n",
      "         1.9653e+00,  3.3680e-01,  6.0196e-01,  1.0840e+00,  5.3695e-02,\n",
      "         1.0624e+00,  2.8229e-01,  1.0227e+00,  1.7169e+00,  1.2774e+00,\n",
      "         7.6813e-01,  4.0190e-01, -6.9893e-03,  3.4167e-01,  4.8806e-01,\n",
      "         2.9259e-01,  7.1022e-02,  1.6245e+00,  7.2023e-01,  1.7620e+00,\n",
      "         1.2904e-01,  2.0983e-01,  7.1070e-01,  7.0007e-01,  7.5274e-01,\n",
      "         1.6669e+00,  7.7633e-01,  1.0396e-02,  2.9674e-01,  4.3528e-01,\n",
      "         1.4884e+00,  9.4164e-01,  1.8620e+00,  9.5651e-01,  1.2726e+00,\n",
      "         4.4405e+00,  5.5076e-01,  7.9797e-01,  2.1236e-01,  6.6842e-01,\n",
      "         2.6600e-01,  3.0943e-01,  1.1488e-01,  2.2858e+00,  3.5433e-01,\n",
      "         8.1507e-01,  1.7093e-01,  2.3819e-01,  1.5311e+00,  2.4329e-02,\n",
      "         3.7908e-01,  6.4837e-01,  8.0808e-01,  1.4367e+00,  4.2030e-02,\n",
      "         1.3723e+00,  1.5047e+00,  1.9865e+00,  7.0830e-01,  1.1570e+00,\n",
      "         1.1822e-01,  1.7164e+00,  2.4246e+00,  7.4871e-01,  2.3074e-01,\n",
      "         7.1678e-01, -8.1680e-04,  1.0044e+00,  9.7671e-01,  7.8725e-01,\n",
      "         3.4109e-02,  9.5132e-01,  3.3636e-01,  8.8738e-01,  2.4440e-01,\n",
      "         1.2618e+00,  1.6106e+00,  1.7927e+00,  7.6872e-01,  2.0195e-01,\n",
      "         1.2371e+00,  3.4364e-01,  1.1179e-01,  6.9562e-01,  3.0572e-01,\n",
      "         1.8582e+00,  1.6983e-01,  1.9119e-01,  8.4918e-01,  1.0436e+00,\n",
      "         5.6056e-01,  1.2337e+00,  1.2105e+00,  4.9614e-01,  6.7566e-01,\n",
      "         2.0177e+00,  8.1555e-01,  1.0869e+00,  7.1997e-01,  2.6634e-01,\n",
      "         1.3135e+00,  6.0536e-01,  1.4955e+00,  9.6803e-01,  1.0362e+00,\n",
      "         9.0752e-01,  1.0701e+00,  7.9530e-01,  9.8945e-01,  1.1999e+00,\n",
      "         1.3409e+00,  1.5297e+00,  1.6166e-01,  9.3932e-01,  5.7622e-01,\n",
      "         9.3359e-01,  1.0680e+00,  2.4009e-01,  1.8575e+00,  2.3133e+00,\n",
      "         1.3351e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.2171, -0.2402, -0.1822, -0.1986,  0.0959,  0.3024, -0.0873, -1.4001,\n",
      "        -0.4315, -0.1446,  0.5442,  0.6324, -0.3051,  0.0954,  0.1911,  0.8169,\n",
      "         0.2524,  0.2758, -0.3388,  0.4341, -0.4448, -0.2448, -0.4131,  0.5037,\n",
      "         0.1250,  1.3832, -0.3377,  0.1288,  0.4628, -0.4995,  0.0877,  0.0036,\n",
      "        -0.1405, -0.1637,  0.2384, -0.3831,  0.1865, -0.2611, -0.2290, -0.1610,\n",
      "         0.0718, -0.2486, -0.1913,  0.3246, -0.2274,  0.5166,  0.5516,  0.9411,\n",
      "         0.0081,  0.0091, -0.5343, -0.3575,  0.3506, -0.2474, -0.4176,  0.4622,\n",
      "        -0.1236, -0.0074, -0.5844,  0.4534, -0.2811, -0.2428,  0.2729, -0.3494,\n",
      "         0.2176,  0.2218,  0.2831,  0.0334,  0.5590, -0.1892, -0.5130,  0.3185,\n",
      "         1.5336,  0.0167,  0.3949,  0.0608, -0.2679,  0.1695, -0.1827, -0.0760,\n",
      "         0.3606, -0.1114, -0.3409,  0.1753, -0.1845, -0.0851,  0.3813, -0.3214,\n",
      "         0.2946,  0.5982,  0.3219,  0.0720,  0.1244,  0.5245, -0.3758, -0.0762,\n",
      "        -0.2433,  0.1761, -0.3161, -0.0688,  0.7764, -0.0835,  0.1676, -0.3134,\n",
      "         0.5541,  0.0506, -0.6530, -0.0175, -0.0268, -0.1552,  1.1014,  0.0535,\n",
      "        -0.0772, -0.0684,  0.2138,  0.2946, -0.0653, -0.8895,  0.2762, -0.1274,\n",
      "         0.1263,  0.2451,  0.5044, -0.0439, -0.4009,  0.0421, -0.0634,  0.3547,\n",
      "         0.6121,  0.6460, -0.2111, -0.9123,  0.0762,  1.2340,  0.7319, -0.0433],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.4331]],\n",
      "\n",
      "         [[-0.0199]],\n",
      "\n",
      "         [[-0.7181]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4362]],\n",
      "\n",
      "         [[-0.4305]],\n",
      "\n",
      "         [[-0.5828]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2066]],\n",
      "\n",
      "         [[-0.4972]],\n",
      "\n",
      "         [[-0.6314]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2014]],\n",
      "\n",
      "         [[ 0.4671]],\n",
      "\n",
      "         [[ 0.2031]]],\n",
      "\n",
      "\n",
      "        [[[-0.2003]],\n",
      "\n",
      "         [[ 0.3577]],\n",
      "\n",
      "         [[ 0.0619]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2586]],\n",
      "\n",
      "         [[ 0.1912]],\n",
      "\n",
      "         [[ 0.3196]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2001]],\n",
      "\n",
      "         [[-0.3206]],\n",
      "\n",
      "         [[ 0.3791]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4262]],\n",
      "\n",
      "         [[-0.0036]],\n",
      "\n",
      "         [[-0.1393]]],\n",
      "\n",
      "\n",
      "        [[[-0.0524]],\n",
      "\n",
      "         [[ 0.3184]],\n",
      "\n",
      "         [[ 0.3013]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0455]],\n",
      "\n",
      "         [[-0.5432]],\n",
      "\n",
      "         [[ 0.2864]]],\n",
      "\n",
      "\n",
      "        [[[-0.1572]],\n",
      "\n",
      "         [[-0.0337]],\n",
      "\n",
      "         [[ 0.3882]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6343]],\n",
      "\n",
      "         [[-0.3948]],\n",
      "\n",
      "         [[-0.1579]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.5250,  1.2042,  1.3274,  1.5109,  0.7168,  1.0057,  0.9897,  1.0267,\n",
      "         1.4939,  1.0720,  1.2479,  0.6853,  0.8924,  0.8531,  0.5981,  1.6015,\n",
      "         1.0850,  0.8344,  0.9152,  0.8365,  0.8959,  1.2536,  1.3000,  1.0505,\n",
      "         1.2025,  0.2987,  0.9924,  1.8926,  0.6912,  0.4982,  1.1951,  0.6309,\n",
      "         0.4141,  0.9080,  1.3807,  1.2316,  0.5792,  1.7165,  0.9058,  1.1749,\n",
      "         0.8435,  0.6929,  0.2836,  0.6990,  0.7212,  1.5882,  0.8504,  0.9289,\n",
      "         1.0078,  0.6150,  1.0653,  1.3951,  0.4961,  1.2727,  1.4041,  0.9558,\n",
      "         1.1146,  0.9798,  0.7991,  1.3703,  1.7261,  0.5790,  1.3451,  0.5509,\n",
      "         1.4798,  1.1178,  1.2071,  1.1609,  0.5849,  1.3365,  1.0043,  1.2982,\n",
      "         2.3142,  0.6521,  0.6884,  0.6623,  1.2569,  0.8708,  0.8833,  1.2772,\n",
      "         0.9893,  1.5205,  1.5451,  1.4388,  1.4061,  0.7758,  1.0529,  0.9924,\n",
      "         1.0342,  0.8989,  1.2585,  0.8320,  1.1890,  0.3017,  1.4804,  1.5114,\n",
      "         0.6545,  1.1595,  0.6879,  1.1433,  0.8438,  1.3241,  0.4379,  1.4024,\n",
      "         1.0020,  0.1397,  1.4711,  1.3757,  0.2539,  1.8104,  1.2226,  0.7154,\n",
      "         1.2211,  1.2201,  1.2089,  1.3281,  1.4530,  0.4098,  0.4866,  1.2142,\n",
      "         1.8352,  1.2427,  1.0091,  1.3777,  0.9970,  0.9297,  1.0619,  1.2523,\n",
      "         1.1587,  0.7334,  1.3127,  1.2175,  1.0726,  0.9300,  0.9722,  1.9488,\n",
      "         0.8911,  1.2909,  0.6044,  1.2640,  0.4696,  0.6704,  1.0579,  1.0885,\n",
      "         0.9354,  1.4700,  1.1808,  0.4402,  1.0494,  1.9905,  0.3962,  0.1731,\n",
      "         1.4793,  0.9774,  0.6309,  0.9553,  0.6140,  1.0629,  1.3778,  1.0924,\n",
      "         0.8689,  1.3059,  0.6320,  0.4848,  1.5411,  1.1603,  1.8731,  1.1060,\n",
      "         0.8938,  1.0765,  1.1965,  1.0318,  1.3893,  1.2535,  1.1058,  1.3432,\n",
      "         1.9114,  0.4670,  1.6232,  1.3240,  1.6415,  0.9720,  1.2532,  1.9487,\n",
      "         0.8934,  1.2955,  0.9091,  0.9848,  0.2669,  0.8634,  0.7878,  1.0280,\n",
      "         2.1024,  1.2100,  0.9963,  1.0661,  0.8437,  1.3140,  1.0828,  1.5614,\n",
      "         1.6053,  1.1802,  0.6061,  0.8679,  1.5415,  0.6676,  1.8416,  1.5613,\n",
      "         1.0680,  1.0252,  1.0791,  1.7231,  2.0825,  1.9830,  1.5526,  1.6433,\n",
      "         1.0576,  1.0164,  0.2947,  1.0492,  0.5473,  1.5669,  1.1305,  1.1276,\n",
      "         0.5792, -0.0429,  0.7232,  1.0939,  1.8720,  1.7323,  0.4750,  0.2174,\n",
      "         1.3182,  1.5755,  1.1693,  1.2442,  0.9766,  1.6006,  1.0454,  1.2863,\n",
      "         1.2915,  1.6658,  1.4004,  0.5766,  1.3045,  1.2121,  0.4637,  0.7745,\n",
      "         1.2710,  1.0537,  1.2111,  0.8848,  0.6733,  1.2159,  1.3314,  1.6068,\n",
      "         1.5387,  0.8320,  0.7950,  1.1413,  0.7989,  1.0991,  0.6208,  1.4000,\n",
      "         1.5214,  1.0489,  0.5311,  0.6254,  1.8020,  1.4282,  0.6905,  1.8805,\n",
      "         1.7282,  1.2179,  1.3177,  1.7865,  1.5063,  0.8897,  0.7933,  0.7040,\n",
      "         1.1724,  0.7853,  1.0705,  1.1913,  0.5901,  0.6285,  1.3405,  1.2810,\n",
      "         1.3275,  2.0960,  0.9047,  1.6199,  1.6393,  1.1073,  1.7440,  1.3230,\n",
      "         0.9181,  1.4706,  0.4128,  1.4786,  0.7322,  1.9548,  1.2988,  0.9989,\n",
      "         1.0629,  0.8308,  1.3569,  1.2478,  1.0868,  0.6431,  1.2465,  0.7233,\n",
      "         1.3247,  1.8499,  1.6896,  1.4020,  1.7888,  1.1571,  1.2435,  0.7029,\n",
      "         1.0648,  1.1926,  1.1234,  1.1759,  1.6157,  0.9396,  1.0758,  1.3245,\n",
      "         1.3897,  1.0798,  1.1306,  0.2446,  1.6455,  1.1189,  1.0059,  0.5577,\n",
      "         1.0211,  1.2312,  0.7712,  1.3458,  0.7417,  0.6269,  1.4950,  1.4527,\n",
      "         1.3520,  0.9653,  0.8980,  0.9971,  1.0375,  1.4960,  1.2982,  1.3219,\n",
      "         1.2904,  1.4808,  1.7757,  1.1895,  1.2898,  1.0874,  0.9409,  1.0313,\n",
      "         1.6442,  1.6170,  1.4979,  0.9810,  0.6144,  1.1083,  1.1470,  1.0897,\n",
      "         0.9133,  1.4060,  1.1170,  0.8156,  1.2569,  0.9807,  0.6467,  0.8199,\n",
      "         1.2369,  0.9691,  1.0272,  0.7413,  1.1004,  1.6307,  0.6539,  1.3046,\n",
      "         1.1620,  1.1694,  0.2255,  1.6725,  1.2765,  1.0989,  0.4055,  1.5747,\n",
      "         1.1932,  1.9033,  1.6864,  1.0749,  1.2876,  1.2069,  1.7328,  1.0483,\n",
      "         0.2773,  1.0251,  1.1605,  0.1604,  1.5318,  1.5160,  0.1849,  1.2057,\n",
      "         1.8954,  1.0951,  1.7491,  0.8699,  0.7478,  1.5056,  1.0810,  0.2824,\n",
      "         1.1987,  1.3619,  1.6577,  0.4752,  1.5169,  1.0877,  1.0771,  1.1295,\n",
      "         0.9591,  1.6894,  1.6098,  0.7561,  0.4731,  1.8548,  1.1915,  0.7435,\n",
      "         1.3012,  1.0479,  1.9177,  0.8195,  1.0168,  0.8889,  1.5046,  0.6958,\n",
      "         1.6760,  1.2887,  0.6914,  1.5820,  1.4253,  1.3224,  0.9827,  0.8215,\n",
      "         1.4136,  1.0431,  2.0381,  1.5080,  1.0435,  1.0612,  1.1936,  1.6494,\n",
      "         0.8770,  1.2293,  1.2737,  1.3642,  1.2757,  1.2705,  0.5825,  0.7819,\n",
      "         0.9667,  0.7924,  1.3444,  0.9391,  1.2890,  1.1107,  1.2478,  0.7309,\n",
      "         1.8566,  0.6796,  0.9408,  1.2820,  0.9153,  1.3993,  0.3205,  0.7845,\n",
      "         0.6685,  1.2751,  0.9163,  1.1329,  1.6541,  1.4698,  1.6812,  0.1816,\n",
      "         2.3201,  1.5683,  1.0569,  1.6416,  1.1215,  1.0517,  1.5714,  1.0955,\n",
      "         0.2771,  0.7595,  1.3047,  0.9507,  0.7981,  0.6787,  1.2828,  1.3250,\n",
      "         1.4123,  0.7141,  0.5692,  1.4304,  1.0548,  0.9516,  0.7123,  1.0627,\n",
      "         0.8419,  0.9440,  0.8939,  0.8154,  1.2227,  1.2111,  1.1509,  0.8720,\n",
      "         0.5643,  0.8002,  1.1262,  1.1479,  0.6250,  0.9984,  1.3786,  1.0065,\n",
      "         1.5836,  1.0007,  1.6970,  0.6972,  0.8890,  1.1149,  1.5202,  0.9143,\n",
      "         0.5517,  1.1220,  1.0281,  1.4321,  1.3503,  0.7680,  1.1413,  1.3771,\n",
      "         1.2992,  1.3459,  0.6361,  1.8227,  0.2183,  1.2677,  0.8713,  0.8829,\n",
      "         0.3459,  1.0346,  1.4292,  0.5791,  1.2963,  1.1166,  1.0222,  1.6963,\n",
      "         1.2717,  1.3737,  0.7292,  0.9279,  1.9438,  1.4138,  1.2651,  1.2173,\n",
      "         0.8783,  0.8120,  1.7075,  1.3558,  1.0945,  1.5872,  1.1266,  0.9828,\n",
      "         1.0408,  1.5017,  0.7581,  1.1503,  1.8915,  1.4957,  0.7522,  0.9865,\n",
      "         0.7665,  1.1278,  1.4882,  0.8220,  0.9586,  1.2680,  1.7365,  1.3041,\n",
      "         0.8690,  1.1900,  1.2020,  0.9747,  1.0993,  0.6378,  1.0653,  1.5791,\n",
      "         0.9348,  1.0810,  1.4414,  0.9126,  1.1707,  0.4450,  1.2804,  1.3083,\n",
      "         1.1256,  0.5550,  1.0285,  1.1207,  0.5024,  1.4316,  1.1468,  1.0756,\n",
      "         1.1636,  0.7196,  1.0721,  1.2505,  1.0279,  0.7218,  1.7124,  0.8289,\n",
      "         1.1354,  0.7625,  1.2126,  0.7673,  0.8890,  1.0360,  0.6788,  0.8769,\n",
      "         1.0321,  2.1583,  1.3309,  1.1232,  0.6624,  1.5405,  1.2449,  1.4636,\n",
      "         1.1689,  0.9107,  1.6321,  1.0193,  1.4300,  1.4508,  1.7617,  0.7276,\n",
      "         1.2891,  0.4698,  0.7960,  1.0339,  0.1954,  1.3784,  1.7252,  1.2748,\n",
      "         1.2635,  1.4451,  1.3029,  0.7746,  1.5755,  1.1174,  1.3359,  0.6294,\n",
      "         0.9015,  0.9972,  0.4068,  1.2436,  0.2929,  1.0054,  1.4272,  1.0806,\n",
      "         0.7516,  1.1763,  1.1529,  0.4443,  0.6717,  0.8284,  1.1239,  1.7749,\n",
      "         0.8423,  1.4601,  0.5882,  0.6915,  2.2595,  0.9917,  1.5004,  1.2865,\n",
      "         1.0019,  0.4193,  1.1988,  1.7135,  1.3633,  0.9616,  1.2333,  1.1895,\n",
      "         0.9978,  1.3307,  0.5179,  0.8581,  0.8405,  1.3791,  0.7564,  1.1122,\n",
      "         0.9793,  1.1267,  1.3783,  1.4104,  0.5939,  1.4477,  0.5698,  2.1547,\n",
      "         1.0378,  1.1982,  1.7245,  1.0091,  1.4124,  1.6992,  1.4057,  0.6747,\n",
      "         0.5425,  0.2225,  0.9040,  1.3345,  1.0274,  1.6974,  1.2582,  0.8210,\n",
      "         1.4805,  1.4719,  1.3357,  1.0602,  0.8067,  1.1190,  1.1986,  1.3069,\n",
      "         0.4084,  1.1277,  0.9719,  1.1198,  0.9116,  0.6320,  1.2675,  1.4379,\n",
      "         1.1289,  0.8767,  1.2491,  1.0047,  0.5334,  1.1899,  1.0106,  1.1600,\n",
      "         1.4621,  1.6690,  1.1596,  1.0024,  0.8283,  1.0035,  0.6168,  1.4364,\n",
      "         0.7787,  0.9542,  1.1139,  1.3916,  1.8142,  1.1264,  1.4531,  1.9189,\n",
      "         1.7701,  1.7230,  1.7732,  0.5034,  1.8056,  1.1926,  2.2949,  1.2971,\n",
      "         1.2273,  0.7276,  1.2635,  1.0570,  0.7480,  1.5815,  1.0375,  1.6328,\n",
      "         1.1818,  1.2052,  0.8737,  2.0565,  1.5698,  1.2057,  1.0710,  1.0588,\n",
      "         0.8238,  0.6879,  1.1413,  1.3361,  1.2984,  1.0413,  0.9911,  0.0495,\n",
      "         0.7825,  1.3701,  1.6643,  1.3209,  1.1258,  1.3081,  1.3510,  1.5420,\n",
      "         1.4345,  0.9280,  1.6750,  1.2683,  1.6707,  0.7639,  1.0063,  0.9248],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.8526e-01, -3.5176e+00, -8.4192e-01, -1.6522e+00, -1.2668e+00,\n",
      "        -1.1466e+00, -4.0821e-01, -1.0820e+00, -5.2251e-01, -1.0337e+00,\n",
      "        -8.1100e-01,  6.0036e-01, -1.2248e+00, -1.1463e+00, -7.1306e-01,\n",
      "        -1.1871e-01, -1.2432e+00, -3.1639e-01, -1.3297e+00, -4.0822e-01,\n",
      "        -1.1380e+00, -5.1049e-02, -2.2170e+00,  9.8019e-01, -1.5880e+00,\n",
      "        -1.7597e+00, -8.0058e-01,  9.2052e-02, -1.7711e+00, -1.3883e+00,\n",
      "        -1.5691e+00, -5.1074e-01, -2.2636e-01, -1.5636e+00, -8.9291e-01,\n",
      "        -1.3060e+00, -2.5676e-02, -6.7685e-01, -1.0819e+00, -1.1016e+00,\n",
      "         1.0409e+00, -3.1256e-01, -8.3464e-01, -7.9349e-01, -2.6963e+00,\n",
      "        -3.4021e-01, -1.2600e+00, -1.7121e-01, -1.6185e+00,  8.9154e-02,\n",
      "        -1.1786e+00, -9.9078e-01,  2.8497e-01, -1.0096e-01, -1.6276e+00,\n",
      "        -1.3187e+00, -9.4364e-01, -1.2665e+00, -1.6409e+00, -8.9866e-01,\n",
      "         5.4162e-01, -4.7156e-02, -4.7633e-01, -1.5210e-03, -1.5350e+00,\n",
      "        -1.1812e+00, -4.3350e-01, -5.3422e-01,  6.0738e-01, -1.1471e+00,\n",
      "        -7.2887e-01, -1.1571e-01,  3.8372e-01, -1.6485e-01,  1.3479e-01,\n",
      "        -1.5665e+00, -1.0906e+00, -1.8414e+00, -8.3568e-01, -1.0884e+00,\n",
      "        -1.0257e+00, -4.8925e-01, -8.3083e-01, -1.2733e+00, -1.1505e+00,\n",
      "        -2.4082e+00, -1.8550e+00, -5.1025e-01, -1.6248e+00,  1.4688e+00,\n",
      "        -1.6048e+00, -3.5765e-01, -9.8368e-01, -3.3694e-01, -1.0054e+00,\n",
      "        -1.4724e+00, -4.0400e-02, -5.7119e-01,  6.3871e-03, -9.6640e-01,\n",
      "        -2.1980e+00, -6.8575e-01, -1.1901e+00, -7.6819e-01, -1.8941e+00,\n",
      "         5.5797e-02, -1.1014e+00, -1.8274e+00, -2.6429e-01, -3.2392e-01,\n",
      "        -2.1421e+00, -6.9196e-01,  9.6054e-02, -6.2401e-01, -9.0112e-01,\n",
      "        -3.0601e-01, -2.6539e-03,  6.8685e-01,  3.4311e-01, -1.3549e-01,\n",
      "        -5.8617e-01,  1.7915e-01, -1.2094e+00, -2.3878e-01, -1.4694e+00,\n",
      "        -1.4529e+00, -1.9414e+00, -9.1075e-01, -9.5676e-01, -3.5169e-01,\n",
      "        -1.2357e+00, -1.3596e+00, -1.7621e+00,  2.3905e-03, -8.7250e-01,\n",
      "         4.6401e-01, -4.2376e-01, -9.8777e-01, -8.5813e-01, -4.8051e-01,\n",
      "        -9.6762e-01, -6.9946e-01, -1.8894e+00, -2.1891e+00, -4.4054e-01,\n",
      "         1.1544e-01, -1.5240e+00, -5.6975e-01, -2.0719e+00,  6.3794e-01,\n",
      "         3.3305e-01,  1.9092e+00, -1.4579e+00, -1.6879e+00, -1.7703e+00,\n",
      "        -8.3900e-01,  1.6857e-01, -8.6712e-01, -1.1650e+00, -2.0977e-01,\n",
      "         9.1530e-01, -7.1313e-01,  7.5589e-01,  4.2062e-01, -1.5742e+00,\n",
      "        -2.8750e-01,  6.4812e-02,  1.7286e-02, -1.6342e+00, -1.1443e+00,\n",
      "        -1.2372e+00, -1.6495e-01, -1.5763e+00, -7.9874e-01, -2.1167e+00,\n",
      "         3.1802e-02,  1.6272e-01, -8.0010e-01, -6.4022e-01, -2.0744e+00,\n",
      "        -6.1328e-01,  5.3287e-01, -1.3208e+00, -4.6139e-01, -7.9267e-01,\n",
      "        -1.4345e+00,  8.7828e-02, -4.3251e-01,  1.3081e-02, -8.5500e-01,\n",
      "        -4.5912e-01, -1.4730e+00,  3.3483e-02,  1.2793e-01, -8.0443e-01,\n",
      "        -2.2037e+00, -8.1428e-01, -2.0085e+00, -1.6187e+00,  4.8084e-01,\n",
      "        -2.4013e+00,  2.7164e-01, -1.0496e+00, -8.4164e-01, -1.4309e+00,\n",
      "        -2.5598e-01, -4.9637e-01, -9.3408e-01, -1.4708e+00, -8.6733e-01,\n",
      "         6.5519e-01, -1.2464e+00,  5.0538e-01, -6.1117e-01, -1.5287e+00,\n",
      "        -1.8445e+00, -1.2204e+00, -9.2535e-01,  8.2761e-01, -1.5068e+00,\n",
      "        -3.6660e-01, -4.5094e-01, -2.3763e+00, -1.3648e+00,  3.5224e-01,\n",
      "        -1.3527e+00, -6.0913e-01, -2.5971e+00, -1.0905e+00,  8.2664e-02,\n",
      "        -4.7759e-01,  6.1712e-01,  1.1686e+00, -2.0442e+00, -2.0025e-01,\n",
      "        -3.3049e-01, -1.5721e+00, -5.3054e-01, -7.3025e-01, -1.0440e+00,\n",
      "        -1.1919e+00,  1.2732e+00, -1.4712e+00,  4.6883e-01, -7.1220e-01,\n",
      "        -9.6102e-01, -1.6883e+00, -2.0803e+00, -9.7856e-01, -1.3453e+00,\n",
      "        -1.2219e+00, -3.0346e-01,  2.1037e-01, -9.2823e-01, -2.0673e-01,\n",
      "        -5.8803e-01, -1.3981e+00, -1.1574e+00, -7.9985e-01, -1.0249e+00,\n",
      "        -1.7835e+00, -1.2053e+00, -3.9877e-01, -1.6229e+00, -1.1535e+00,\n",
      "        -1.2052e+00, -2.7131e-01, -2.2629e+00, -1.1120e+00, -1.1837e+00,\n",
      "        -1.7073e+00, -1.9839e+00, -8.1025e-01, -6.8033e-01, -9.0735e-01,\n",
      "        -1.5784e-01, -1.3296e+00,  7.4053e-01, -8.9269e-01, -1.7883e+00,\n",
      "        -1.5549e+00, -4.8562e-01, -1.3999e+00, -3.7346e-01,  5.8873e-01,\n",
      "         2.8816e-01, -2.6803e-02,  1.3978e-01, -5.4500e-01, -1.2479e-01,\n",
      "        -1.6660e+00,  7.2271e-02,  2.9866e-01, -2.4185e+00, -8.1233e-01,\n",
      "        -7.7864e-01,  1.0663e+00, -6.9934e-01, -8.7753e-01, -2.3100e+00,\n",
      "        -3.0059e-01, -1.8526e+00, -1.4153e+00, -1.9200e+00, -4.9107e-01,\n",
      "        -1.5456e+00, -8.9659e-01, -6.9381e-01,  6.3680e-01, -8.4481e-02,\n",
      "        -1.4655e+00,  1.1803e+00, -1.1398e+00, -1.1024e+00, -1.1594e+00,\n",
      "        -7.3207e-01, -4.2834e-02, -6.9054e-01, -2.0537e+00, -1.3785e+00,\n",
      "        -1.2220e+00, -1.9297e+00, -1.5835e+00, -1.4865e+00,  1.0909e-03,\n",
      "        -1.9443e+00, -2.0755e+00,  3.8873e-01, -1.0174e+00,  1.9756e-01,\n",
      "        -1.5707e+00,  5.8114e-01, -1.0049e+00, -1.3877e+00, -3.9610e-01,\n",
      "        -2.7209e-01, -1.5045e+00, -5.2787e-01,  2.8372e-01, -1.5369e+00,\n",
      "        -5.3145e-01,  5.4806e-02, -2.0497e+00, -5.9255e-01, -5.1222e-01,\n",
      "        -1.4781e+00, -1.0738e+00, -5.9690e-01,  2.0768e-02, -1.0730e+00,\n",
      "        -3.7705e-01,  6.0697e-01, -2.3359e+00, -2.4266e-01, -1.9296e-01,\n",
      "        -1.6226e+00, -2.6140e+00, -1.8515e-01,  2.5797e-01, -1.0517e+00,\n",
      "        -2.3845e+00, -1.7930e+00, -1.8612e+00, -2.0330e+00, -1.2721e-01,\n",
      "        -1.5710e+00,  3.6628e-01,  8.4013e-01, -1.1023e+00, -2.8249e-01,\n",
      "        -2.1596e+00, -5.8261e-01, -1.8944e+00, -1.6469e+00, -1.6986e+00,\n",
      "        -1.8009e+00, -8.0419e-01, -1.7984e+00, -7.7617e-01, -5.8894e-01,\n",
      "        -2.0445e+00, -1.4514e+00,  4.3565e-02, -2.8932e+00, -2.3518e+00,\n",
      "        -1.0435e+00, -1.3959e-01, -8.0998e-01, -7.6125e-01, -6.2994e-01,\n",
      "         9.3644e-01, -6.2524e-01, -9.9073e-01, -1.4159e+00,  5.3037e-01,\n",
      "        -1.9913e+00, -4.0339e-01, -3.5393e-01, -2.0972e+00, -1.0774e+00,\n",
      "        -2.2091e-01, -1.1475e+00, -1.2692e+00, -1.9232e-02, -1.1357e-01,\n",
      "        -1.2294e+00,  4.8176e-01,  7.0921e-01, -5.9512e-01, -5.2018e-02,\n",
      "        -3.1571e-01, -1.0746e+00, -3.0050e-01, -4.2583e-01, -1.3657e+00,\n",
      "         5.4141e-01, -2.3332e+00, -9.0110e-02, -2.7070e+00, -4.6396e-02,\n",
      "        -3.3256e-01, -1.3943e+00, -9.2840e-01, -6.7923e-01, -2.3032e+00,\n",
      "        -1.3222e+00, -3.3716e-02,  5.6058e-01, -2.2605e+00, -1.0686e+00,\n",
      "        -1.5424e+00,  1.1689e+00, -1.8670e+00, -8.2354e-01, -1.2844e+00,\n",
      "        -3.3220e-01, -1.8435e+00, -1.1942e-01, -1.1177e+00, -1.1937e+00,\n",
      "        -4.8739e-01, -3.9900e-02, -1.8743e+00, -1.0734e+00, -4.1297e-01,\n",
      "        -4.5279e-01, -7.0163e-01, -3.7363e-01, -1.8865e+00, -4.8033e-01,\n",
      "        -1.1664e+00, -1.2130e+00, -4.6437e-02, -1.4406e+00, -1.5336e+00,\n",
      "        -4.4398e-01, -4.9019e-01, -7.1349e-01, -2.7200e-01, -9.7054e-01,\n",
      "        -6.5799e-01, -2.9760e-01,  1.8582e-01, -1.2230e+00, -7.6431e-01,\n",
      "        -5.1751e-01, -1.2698e+00, -2.7832e-01, -3.8701e-01, -1.0526e+00,\n",
      "        -1.6464e+00,  5.0618e-01, -9.7326e-01, -9.3186e-01, -1.2632e+00,\n",
      "        -2.3450e-01,  1.2406e+00, -1.3761e+00,  3.4497e-01, -1.8694e-01,\n",
      "         2.3388e-02, -8.3370e-01, -8.1772e-01, -5.8650e-01, -1.5139e+00,\n",
      "         1.3396e+00, -1.4113e+00, -7.7928e-02, -5.8727e-02, -5.5391e-01,\n",
      "        -1.2807e+00, -5.1186e-01, -1.0547e+00, -6.0848e-01,  2.0664e-02,\n",
      "         1.1545e+00, -1.4380e-01, -1.1274e+00, -1.3851e+00,  2.3418e-01,\n",
      "        -5.6861e-01, -1.6170e+00, -1.1515e+00, -6.2103e-01,  1.6730e-01,\n",
      "        -1.6744e+00, -1.4788e+00, -4.1691e-02,  6.0526e-01, -2.3189e+00,\n",
      "        -1.2833e+00, -1.6753e-01,  4.0485e-01, -1.2036e+00, -2.7876e+00,\n",
      "        -5.6866e-01, -1.0563e+00, -1.2763e+00, -1.6001e+00, -1.0672e+00,\n",
      "         8.7821e-01, -1.9774e+00, -1.5240e+00, -7.5512e-01,  6.5557e-01,\n",
      "        -6.5749e-01, -1.1331e+00, -9.1665e-01, -1.5856e+00, -8.8172e-02,\n",
      "        -1.9813e+00, -6.7525e-01, -4.8350e-01, -1.2478e+00, -5.0260e-01,\n",
      "        -6.8816e-01, -2.1980e-01, -8.2027e-01, -7.3830e-01, -6.4509e-01,\n",
      "        -2.1061e+00, -2.0355e+00, -2.1039e+00, -1.0156e+00, -6.8810e-01,\n",
      "        -3.0042e-01, -7.0170e-02, -1.1521e+00,  7.7874e-03, -9.8616e-01,\n",
      "        -1.2339e+00,  4.4421e-01,  2.0140e-01, -1.1911e+00, -1.8886e+00,\n",
      "        -4.8141e-01, -1.2492e+00, -1.8432e+00, -6.3457e-01, -2.3499e-01,\n",
      "        -7.8769e-01,  2.9722e-01, -1.1494e-01, -1.3738e+00, -1.5470e-01,\n",
      "        -2.8635e-01, -1.5013e+00, -3.3271e+00, -1.6584e+00, -1.6076e+00,\n",
      "         1.2965e+00, -7.8776e-02,  1.1384e+00, -1.3337e+00, -1.0029e+00,\n",
      "        -4.4470e-01, -7.2288e-01, -4.0242e-01, -2.3966e+00, -1.1059e+00,\n",
      "        -2.2180e+00, -7.3122e-01, -2.1302e+00, -1.7685e+00,  9.5590e-01,\n",
      "        -8.8224e-01, -1.0941e+00, -1.4244e+00, -6.4303e-01, -8.7899e-02,\n",
      "        -4.0780e-01, -4.6362e-01, -6.8321e-01, -2.1810e+00,  2.2405e-01,\n",
      "        -1.1812e+00, -1.7323e+00, -4.6583e-01, -1.8078e+00,  1.1560e+00,\n",
      "        -1.5135e+00, -7.8155e-01, -1.4042e+00, -9.4845e-01, -1.2059e+00,\n",
      "        -1.3901e-01, -4.5724e-01, -1.4532e+00, -1.3814e+00,  4.1780e-02,\n",
      "        -6.0904e-02, -1.4421e+00,  1.0725e+00, -1.3021e+00, -2.0111e+00,\n",
      "         3.9072e-01,  5.2442e-01, -2.9526e-01, -2.0659e+00, -6.8337e-01,\n",
      "         3.4042e-01, -8.8758e-01, -6.9404e-01,  6.7981e-01, -1.3897e+00,\n",
      "        -9.9111e-01, -1.4574e+00, -6.9095e-01,  4.2912e-01, -4.2914e-01,\n",
      "         9.9626e-01, -9.0560e-01, -1.4494e+00,  4.4349e-01, -1.4613e+00,\n",
      "        -4.0377e-01,  1.3860e-02, -5.0162e-01, -2.3498e+00, -7.3178e-01,\n",
      "         5.0123e-01,  3.8571e-01, -7.6911e-01, -1.2370e+00,  5.7468e-02,\n",
      "        -1.4790e+00, -5.2663e-01,  1.2516e-01, -2.5281e-01,  3.0623e-01,\n",
      "         4.5206e-01, -6.2892e-01,  6.2479e-02, -2.3451e+00, -7.0633e-01,\n",
      "        -1.9732e+00, -1.7993e+00, -2.0096e+00, -8.8515e-01,  6.8438e-01,\n",
      "        -1.5339e+00, -9.3398e-01,  3.2957e-01, -7.6611e-02, -4.3169e-01,\n",
      "        -7.6576e-01, -1.6437e-01, -1.0202e+00,  3.5925e-01, -1.4762e+00,\n",
      "        -3.3337e-01, -9.5237e-01, -1.4841e+00,  2.3498e-01, -3.8772e-01,\n",
      "        -3.4846e-01, -5.4992e-01,  6.1612e-01, -1.7571e+00,  3.9654e-01,\n",
      "        -5.9148e-01, -6.2122e-01, -1.0579e+00, -7.9453e-02,  2.4604e-01,\n",
      "        -1.2240e+00, -1.7139e+00,  2.0029e-01, -1.2838e+00, -3.0459e-01,\n",
      "        -1.3044e+00, -2.1351e-01, -4.1504e-01, -2.2734e+00, -5.2424e-01,\n",
      "        -2.0893e+00, -1.2419e+00, -7.7332e-01,  2.4445e-01, -3.2867e-01,\n",
      "         3.7996e-02, -5.9728e-02, -2.3654e-01, -6.5702e-01,  1.6413e-01,\n",
      "         6.0798e-01,  1.3854e-02, -8.9636e-01, -5.7694e-01, -5.7210e-01,\n",
      "        -1.5210e-02, -1.9126e-01, -2.1271e+00, -1.3705e+00, -2.0358e-01,\n",
      "         3.1451e-01, -2.5658e+00, -9.1441e-01, -3.1424e-01, -4.6741e-02,\n",
      "        -8.0036e-02, -2.3441e-01, -7.4657e-01, -1.3529e+00, -1.3541e+00,\n",
      "         6.7130e-01, -1.7799e-01, -7.8250e-01, -9.2183e-01, -9.1824e-01,\n",
      "        -6.4929e-01, -9.9269e-01,  3.3767e-01, -1.1664e+00, -1.0497e+00,\n",
      "        -8.4653e-01, -2.1659e+00, -1.0557e-01, -9.0296e-01, -2.6256e+00,\n",
      "        -1.4559e-01, -8.2279e-01, -1.0391e+00, -2.0278e+00, -1.0203e+00,\n",
      "        -1.0459e+00, -9.7524e-01, -1.2572e+00,  1.0005e+00, -7.6349e-01,\n",
      "        -1.7415e+00,  2.1586e-01, -1.4461e+00,  1.8597e-03, -9.8999e-01,\n",
      "        -1.8588e-01, -1.1924e+00, -1.6410e+00,  3.4916e-01, -1.1753e+00,\n",
      "        -1.3165e+00, -6.1782e-01, -1.1367e+00, -1.4913e-01, -8.7974e-01,\n",
      "        -1.1595e+00, -1.8999e+00,  7.6881e-02, -1.6439e+00, -2.7668e+00,\n",
      "        -4.3836e-01,  8.5776e-03, -5.3222e-01, -2.3584e+00, -1.0878e-01,\n",
      "        -1.9475e+00, -1.3387e+00,  2.0057e-01, -4.6314e-01, -1.2133e+00,\n",
      "        -1.7449e+00, -2.2510e+00, -8.0083e-01, -1.6157e+00, -1.2116e-01,\n",
      "        -4.4103e-01, -7.1738e-01, -2.7139e-01, -8.2251e-01, -1.4047e+00,\n",
      "        -8.3060e-01, -6.1273e-01, -1.1389e+00, -4.7367e-01, -8.0515e-01,\n",
      "        -8.8531e-01, -6.2771e-01, -1.2761e+00, -4.5103e-01,  1.5225e+00,\n",
      "        -1.9252e+00, -1.4037e+00, -1.7530e+00, -1.3332e+00, -3.4021e-01,\n",
      "        -1.8508e+00, -3.5118e-01, -1.1832e+00, -2.9210e-01, -2.0271e+00,\n",
      "        -2.0575e+00, -1.4093e+00, -5.3435e-01, -6.0896e-01, -1.6436e+00,\n",
      "         1.9976e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-1.4347e-01,  1.2867e-02, -5.1722e-02,  3.8900e-02, -1.8823e-02],\n",
      "          [-1.1528e-01, -1.0046e-01, -4.5821e-01, -4.3166e-01, -6.3074e-01],\n",
      "          [-1.5186e-01, -1.8507e-01, -1.9570e-01, -5.9169e-01, -4.3108e-01],\n",
      "          [ 1.9081e-01, -2.5734e-01, -3.7396e-01, -5.4725e-01, -5.4738e-01],\n",
      "          [-5.4862e-03,  7.8000e-02, -6.5785e-01, -4.5223e-01, -4.3942e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3247e-01, -8.7613e-03,  4.4352e-01, -1.6909e-01, -6.2573e-02],\n",
      "          [ 2.5751e-01, -2.2748e-01, -8.7561e-02, -1.4809e-01,  1.1510e-01],\n",
      "          [-1.3020e-01,  2.2607e-01,  5.4335e-01,  6.2316e-01, -2.4316e-01],\n",
      "          [-1.2623e-01, -7.6118e-02,  1.7794e-01,  5.8631e-01, -3.7247e-01],\n",
      "          [-2.0681e-01, -2.8747e-01, -1.6867e-01,  5.2980e-01,  3.0624e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7289e-01,  7.4837e-01,  5.5655e-01,  3.3139e-01,  1.5667e-01],\n",
      "          [-3.7284e-01,  5.1357e-01,  5.8196e-01,  2.6481e-01, -7.4086e-02],\n",
      "          [ 3.6548e-01, -1.0668e-01, -1.2068e-01, -1.1736e-01,  7.0538e-02],\n",
      "          [ 1.5711e-02, -1.0543e-01, -1.8245e-01,  1.1030e-01,  2.5547e-01],\n",
      "          [ 6.0222e-02, -1.8867e-02,  1.5820e-01, -3.8346e-01, -4.7289e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.9932e-01,  3.0960e-01,  2.0293e-01,  7.7164e-02,  2.6732e-01],\n",
      "          [ 2.4554e-01,  2.6440e-01, -1.5053e-01,  2.1738e-01,  5.0616e-01],\n",
      "          [ 7.5534e-01,  4.0139e-01, -2.3257e-01, -2.5701e-01,  6.7547e-02],\n",
      "          [ 3.2420e-01,  5.8303e-01,  2.7542e-01,  2.5423e-01,  2.6618e-01],\n",
      "          [ 3.3675e-02,  1.7382e-01,  5.5232e-01,  6.5275e-01,  5.1851e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2067e-01, -1.2846e-01,  2.8848e-02,  2.1041e-01,  2.8924e-01],\n",
      "          [ 6.9827e-02, -1.3233e-01,  3.2094e-02,  1.7851e-01,  1.5867e-01],\n",
      "          [-4.4307e-02, -1.8135e-01,  1.8522e-04,  4.0859e-01,  1.5645e-01],\n",
      "          [-3.0000e-01, -4.9858e-02,  9.1334e-01,  5.5640e-01,  1.8207e-01],\n",
      "          [-2.5723e-01, -3.6185e-02,  5.6588e-01,  5.7992e-01, -1.4637e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.3216e-02, -2.6285e-01, -1.6575e-01, -1.4479e-01,  4.8072e-01],\n",
      "          [-5.0308e-01, -2.5383e-01,  9.5315e-02,  4.8365e-01,  4.3667e-01],\n",
      "          [-3.0129e-01, -2.1158e-01, -6.8776e-02,  2.4926e-01,  6.9565e-01],\n",
      "          [ 3.1746e-02, -4.2812e-01, -3.1040e-01, -2.1577e-01,  2.7836e-01],\n",
      "          [ 4.6350e-01,  1.7530e-01, -8.2179e-02,  2.7933e-02,  5.9030e-01]]]],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.8648,  3.0439,  1.4380,  3.0232,  1.2664,  1.1526,  1.7208,  1.4788,\n",
      "         1.7249,  1.1299,  1.1923,  1.3149,  1.3259,  2.0694,  1.1493,  1.9521,\n",
      "         1.6132,  1.1948,  2.9751,  1.6093,  1.2129,  1.8228,  0.6540,  1.4929,\n",
      "         0.8150,  0.5130,  1.4567,  1.4367,  1.2208,  1.0086,  1.6151,  1.5612,\n",
      "         1.2844,  0.8730,  0.5051,  1.2514,  1.9116,  1.6458,  1.4134,  0.7784,\n",
      "         1.3788,  1.1420,  1.7993,  1.6098,  0.3390,  1.4327,  1.1061,  1.0975,\n",
      "         0.7695,  1.7309,  1.4264,  0.9503,  1.5892,  1.6861,  1.5539,  1.3361,\n",
      "         1.3125,  0.5819,  0.9230,  1.3736,  0.2453,  1.9722,  1.5077,  1.9590,\n",
      "         1.4520,  1.3414,  1.6761,  1.9675,  2.1754,  1.2685,  1.2833,  1.5959,\n",
      "         1.3216,  1.5427,  1.8614,  1.1289,  1.6189,  1.6029,  1.7377,  1.6601,\n",
      "         1.3303,  1.3617,  0.9434,  1.4777,  2.0274,  2.1437,  1.0860,  1.3800,\n",
      "         0.4465,  0.7045,  1.2899,  1.3666,  1.1316,  0.8910,  0.4248,  2.2593,\n",
      "         2.0411,  1.0513,  1.8531,  1.6950,  1.4694,  1.4258,  0.9594,  1.3354,\n",
      "         0.9718,  1.7414,  1.1154,  1.0395,  1.1268,  1.2217,  0.9074,  1.0655,\n",
      "         0.8276,  0.9368,  1.5059,  0.7108,  0.8810,  1.5826,  1.3988,  1.3651,\n",
      "         1.0595,  1.8176,  1.6050,  0.9683,  0.8684,  2.0792,  0.6008,  0.6050,\n",
      "         1.0593,  1.9076,  0.9539,  1.0485,  1.2841,  1.3118,  0.4621,  1.2798,\n",
      "         1.2959,  0.8866,  1.6179,  1.0548,  2.4346,  1.7282,  1.6539,  0.6809,\n",
      "         1.2066,  1.5316,  1.6298,  0.8415,  0.8542,  1.9613,  1.4489,  2.6493,\n",
      "         0.3941,  0.5710,  0.7933,  1.0792,  1.3182,  1.3638,  0.8355,  1.3361,\n",
      "         2.2835,  1.3922,  1.9506,  2.0839,  2.1647,  0.8591,  1.7142,  1.5904,\n",
      "         1.9909,  1.9998,  1.1642,  1.3638,  1.5377,  1.5796,  1.1288,  1.6757,\n",
      "         1.0719,  0.8315,  1.2467,  0.9457, -0.1582,  1.6201,  1.0087,  1.1644,\n",
      "         1.7048,  1.3825,  1.8349,  1.5422,  2.1112,  1.1002,  1.5207,  2.3144,\n",
      "         1.7835,  1.5176,  1.5868,  0.7296,  1.1463,  1.3001,  1.5285,  1.7497,\n",
      "         2.2353,  1.7876,  1.2577,  1.4051,  1.2311,  2.2598,  0.9799,  0.7081,\n",
      "         0.6967,  1.4181,  2.0008,  2.0035,  0.7568,  1.9996,  1.6960,  2.5409,\n",
      "         0.8831,  2.1408,  1.7788,  0.7457,  1.9678,  1.5900,  0.9275,  1.5721,\n",
      "         1.7109,  2.0820,  1.5040,  0.9228,  1.1489,  2.3803,  1.8718,  1.4941,\n",
      "         1.2953,  3.3524,  1.1327,  1.5426,  0.9649,  1.4717,  1.6764,  1.0046,\n",
      "         1.6430,  2.2475,  1.5476,  1.5901,  1.8458,  0.6757,  0.6363,  0.9417,\n",
      "         1.4222,  2.0099,  2.3786,  0.9259,  1.2766,  1.3705,  1.6722,  1.0596,\n",
      "         1.9591,  0.6892,  1.2223,  1.5266,  1.3779,  1.4345,  1.5336,  1.3605,\n",
      "         1.4076,  0.7798,  1.3196,  1.3619,  3.2695,  0.4646,  0.9101,  3.4047,\n",
      "         2.3006,  1.4388,  2.8395,  1.4264,  1.7917,  1.4779,  2.0838,  1.1674,\n",
      "         1.1857,  0.6911,  2.0625,  1.3326,  1.7680,  1.3854,  0.9829,  2.2952,\n",
      "         1.3570,  2.0491,  0.7528,  1.4158,  1.2520,  1.2790,  1.6004,  1.4175,\n",
      "         2.3265,  1.3470,  1.5547,  2.0861,  2.2572,  2.8464,  1.7878,  0.4469,\n",
      "         1.1694,  1.0109,  1.1762,  1.0664,  1.4311,  1.0556,  0.8834,  1.9132,\n",
      "         2.1987,  1.8216,  1.5411,  1.1935,  1.1121,  1.1995,  0.4295,  1.0744,\n",
      "         1.3368,  2.5465,  1.3330,  1.0009,  1.6526,  2.8087,  0.7227,  1.4144,\n",
      "         0.8498,  1.9531,  1.4463,  1.6409,  1.3710,  0.8747,  1.6310,  2.6369,\n",
      "         0.8778,  1.4004,  1.8443,  0.7369,  1.7314,  1.3783,  3.1902,  0.8580,\n",
      "         0.9852,  0.3952,  1.7478,  1.6434,  1.0192,  0.5467,  0.9165,  2.2544,\n",
      "         0.1821,  1.3357,  1.7587,  0.5906,  1.3638,  1.1135,  1.9975,  1.4557,\n",
      "         2.5983,  1.5211,  1.0517,  2.2999,  2.3602,  1.6092,  1.9666,  1.3988,\n",
      "         1.6122,  1.6988,  0.0688,  2.2049,  1.0057,  0.9978,  1.4685,  0.8356,\n",
      "         1.4413,  1.0378,  0.8391,  1.8516,  0.5324,  0.7749,  1.9463,  3.5785,\n",
      "         0.4722,  2.3873,  1.5408,  0.9892,  1.1969,  1.9135,  1.5345,  1.6947,\n",
      "         2.0299,  3.7294,  1.9355,  0.7197,  0.7501,  1.4370,  1.4380,  1.1642,\n",
      "         1.5823,  1.2429,  0.9222,  1.7083,  1.3759,  1.0644,  1.4329,  2.2841,\n",
      "         1.3830,  2.0036,  1.1600,  1.0597,  1.7398,  2.0565,  1.4995,  1.7195,\n",
      "         1.3884,  0.9627,  0.7120,  1.4900,  1.6281,  0.6904,  1.4016,  1.7050,\n",
      "         0.8349,  0.9850,  1.4729,  1.5832,  1.0613,  1.3505,  1.1833,  2.3500,\n",
      "         1.8860,  1.1911,  2.7120,  1.5220,  2.2236,  1.9630,  1.8761,  1.2985,\n",
      "         1.5553,  2.2812,  2.2212,  0.9659,  1.1420,  2.1007,  3.5534,  1.2381,\n",
      "         3.7799,  1.7516,  3.6635,  2.1854,  1.9805,  0.6786,  1.3861,  1.1561,\n",
      "         1.5479,  1.3963,  1.6333,  0.6290,  1.3548,  1.1079,  1.8124,  1.0992,\n",
      "         1.1402,  1.5530,  1.0566,  1.6946,  1.4639,  1.0333,  2.3771,  1.7263,\n",
      "         1.5780,  1.1373,  0.5845,  0.9256,  1.8655,  0.6132,  1.7236,  1.7453,\n",
      "         1.1158,  0.3231,  0.7503,  1.6846,  0.4642,  1.5430,  0.7088,  1.5323,\n",
      "        -0.0915,  1.9472,  1.1033,  1.4112,  1.3539,  1.8681,  1.6390,  1.2265,\n",
      "         1.8870,  0.9688,  3.0639,  1.5495,  1.4821,  1.4617,  0.9551,  1.9970,\n",
      "         1.2156,  1.4567,  0.9654,  1.9618,  1.2415,  0.8588,  1.5280,  1.2431,\n",
      "         1.6312,  1.4576,  1.4831,  1.7546,  0.8448,  1.4774,  0.7284,  0.4089,\n",
      "         1.4214,  2.0635,  1.1598,  1.7474,  1.8180,  1.6641,  0.9196,  1.7509,\n",
      "         1.0566,  1.8695,  1.6096,  1.0658,  1.2232,  3.2554,  1.5641,  0.8817,\n",
      "         1.5789,  0.5654,  1.3852,  1.5646,  2.5174,  1.0116,  0.5804,  1.3489,\n",
      "         1.2902,  1.9837,  2.1745,  3.2305,  1.7430,  0.8940,  1.5578,  1.9381,\n",
      "         1.8970,  1.3952,  0.5289,  1.9153,  1.5897,  0.5321,  0.7535,  1.8268,\n",
      "         1.6220,  1.9078,  1.2671,  0.9121,  1.1742,  1.5404,  1.5232,  0.5075,\n",
      "         1.0005,  0.8520,  1.5443,  1.5973,  2.0226,  1.5341,  1.4022,  0.6696,\n",
      "         1.2475,  0.9136,  0.5580,  1.0919,  3.3987,  1.3351,  0.8363,  1.1566,\n",
      "         1.6615,  0.6266,  1.5278,  0.8862,  1.1377,  1.2848,  1.3426,  1.3988,\n",
      "         1.6242,  1.6064,  1.7086,  1.3706,  1.1541,  1.2012,  1.8426,  1.9751,\n",
      "         1.2699,  1.4230,  1.4776,  1.5108,  1.2704,  1.2391,  0.9906,  3.3239,\n",
      "         1.0106,  1.0953,  1.6130,  1.1296,  1.7487,  1.2408,  2.2039,  1.3989,\n",
      "         2.0651,  1.9762,  1.1236,  1.3729,  1.3708,  1.2350,  1.0138,  1.5165,\n",
      "         0.8129,  0.9135,  0.0952,  1.2346,  1.3024,  1.2331,  1.8302,  1.3438,\n",
      "         1.5664,  2.2139,  1.2926,  1.2450,  0.7779,  1.2184,  0.7406,  1.2471,\n",
      "         1.0514,  1.6722,  1.4452,  0.8578,  1.2926,  1.0686,  1.5899,  1.9138,\n",
      "         1.8583,  1.8346,  1.5300,  0.6413,  2.6178,  1.4634,  2.0670,  0.9857,\n",
      "         2.8339,  3.1623,  0.9185,  1.3527,  2.5356,  1.4228,  1.4140,  1.8152,\n",
      "         0.7742,  1.2381,  2.3117,  1.0845,  1.7509,  0.5673,  1.3178,  1.4787,\n",
      "         2.0878,  1.5100,  2.3745,  1.7399,  1.6861,  1.1803,  1.0395,  1.1258,\n",
      "         1.6960,  1.4459,  1.4403,  1.1535,  1.2492,  1.2194,  1.8554,  1.8448,\n",
      "         0.9717,  1.4022,  0.6478,  1.6110,  1.1669,  1.0432,  1.3514,  0.9930,\n",
      "         1.1772,  0.3459,  2.2988,  1.8199,  1.4328,  1.5360,  1.1713,  1.4105,\n",
      "         2.6436,  2.4653,  1.7306,  1.6575,  1.5165,  1.2655,  1.3112,  1.4293,\n",
      "         2.5011,  1.8790,  1.5885,  1.7994,  2.8721,  0.7729,  0.5915,  1.8253,\n",
      "         1.2662,  1.3735,  1.6380,  1.6173,  1.2921,  1.6212,  1.2613,  1.5642,\n",
      "         1.1086,  1.2258,  1.6197,  1.5065,  2.0070,  1.1638,  1.3854,  1.5744,\n",
      "         0.7211,  1.7461,  1.4961,  1.5631,  1.8231,  1.0235,  0.5503,  1.8261,\n",
      "         1.4186,  1.0648,  1.1923,  1.1931,  1.3997,  1.6880,  1.1617,  0.9804,\n",
      "         0.8530,  1.2737,  1.5262,  1.3784,  1.1700,  0.5045,  1.2373,  1.6130,\n",
      "         1.0503,  1.9899,  1.6679,  0.5915, -0.2087,  1.2648,  2.6646,  2.1192,\n",
      "         1.3749,  2.5005,  1.6175,  1.3906,  1.8149,  1.1911,  0.9322,  0.9546,\n",
      "         0.7440,  2.0524,  0.8197,  1.1136,  1.3220,  3.2338,  1.9286,  2.6085,\n",
      "         1.6903,  1.5874,  0.9254,  0.8227,  1.6809,  1.0252,  1.3728,  1.5528,\n",
      "         2.5573,  1.0231,  2.1735,  0.6332,  1.3984,  1.7497,  1.2945,  1.9079,\n",
      "         0.5332,  1.4861,  3.2933,  1.8475,  1.8645,  0.9866,  1.1203,  1.4099,\n",
      "         0.8140,  0.7701,  1.6483,  1.4860,  1.2366,  1.2809,  1.7094,  1.4909],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-7.4243e-01, -1.3616e+00, -3.9289e-01, -5.5837e-01, -6.9486e-01,\n",
      "        -1.6401e+00, -1.5531e+00,  1.1889e-01, -5.6085e-01, -5.3827e-01,\n",
      "        -4.3905e-01, -1.3580e+00, -1.0801e+00, -2.5333e+00, -1.0890e+00,\n",
      "        -2.9147e-01, -3.3667e+00, -1.0260e+00, -1.6107e+00, -2.3571e+00,\n",
      "        -1.2315e+00, -1.4046e+00, -2.2618e-01, -1.0345e+00, -1.1567e-01,\n",
      "        -3.0380e-01, -7.0265e-01, -6.4525e-01, -6.3532e-01, -4.6386e-01,\n",
      "        -5.0082e-01, -1.0471e+00, -1.6901e+00, -1.5128e-01, -1.2719e-01,\n",
      "        -2.6935e+00, -1.8282e+00, -1.9105e+00, -6.0619e-01, -2.7450e-01,\n",
      "        -1.6804e+00, -2.8032e+00, -1.1076e+00, -1.3196e+00, -6.6889e-02,\n",
      "        -6.6536e-01, -3.4305e-01, -2.4543e-01, -6.7387e-02, -2.0326e+00,\n",
      "        -4.4884e-01, -4.9459e-01, -1.6217e+00, -1.4990e+00, -4.3721e-01,\n",
      "        -7.2281e-01, -3.5360e-01, -1.6116e-01, -1.7975e+00, -2.3793e+00,\n",
      "        -3.5633e-01, -1.0162e+00, -1.5195e+00, -1.2526e+00, -5.3888e-01,\n",
      "        -6.4595e-01, -8.0581e-01, -1.3391e+00, -1.8152e+00, -3.3532e-01,\n",
      "        -2.7728e+00, -7.6265e-02, -2.2920e-02, -1.1092e+00, -7.4416e-01,\n",
      "        -1.5113e+00, -6.0918e-01, -2.7237e+00, -8.1125e-01, -1.4653e+00,\n",
      "        -1.8451e+00, -5.0114e-01, -1.9881e-01, -6.7779e-01, -9.4908e-01,\n",
      "        -7.0951e-01, -3.5295e-01, -1.6616e+00, -1.2156e-01,  5.3292e-01,\n",
      "         8.2466e-01, -2.3991e+00,  2.9346e-01, -1.4203e-01, -1.4826e-01,\n",
      "        -3.3939e-01, -2.1290e+00, -1.2248e+00, -2.1006e+00, -2.8408e+00,\n",
      "        -6.9717e-01, -5.7226e-01, -6.0722e-01, -5.4908e-01, -1.0528e-01,\n",
      "        -1.2120e+00, -2.7346e-01, -1.5684e-01, -3.0174e-01, -1.3433e-01,\n",
      "        -1.3304e-01, -1.9070e+00, -5.0250e-01, -3.5532e-01, -1.0695e+00,\n",
      "        -3.2097e-01, -1.2121e-01, -1.8923e+00, -8.6643e-01, -3.2772e-01,\n",
      "         1.3745e-02, -1.0389e+00, -1.5177e+00, -1.0881e+00, -4.4683e-01,\n",
      "        -1.3489e+00, -8.5527e-02, -1.0496e-01, -7.7043e-02, -7.5537e-01,\n",
      "        -4.5422e-01, -5.7902e-02, -1.4308e-01, -5.4477e-01, -1.1463e-01,\n",
      "        -6.8366e-02, -5.4492e-01,  9.9503e-02, -8.3101e-01, -2.1328e-01,\n",
      "        -1.4196e+00, -1.0771e+00, -7.7319e-01,  7.4729e-02, -8.1697e-01,\n",
      "         1.5820e-01, -6.5170e-01, -3.1394e-01, -2.8839e-01, -1.2762e+00,\n",
      "        -1.5391e+00, -1.0771e+00, -1.9621e-01, -1.6547e-01, -1.5651e-01,\n",
      "        -3.0076e-01, -1.6667e+00, -2.2156e+00, -5.6456e-01, -6.7137e-01,\n",
      "        -1.1002e+00, -1.8710e+00, -1.4134e+00, -1.7211e+00, -1.5079e+00,\n",
      "        -2.9304e-01, -9.3305e-01, -9.9249e-01, -3.1611e+00, -7.1415e-01,\n",
      "        -6.4589e-01, -6.7273e-01, -6.4228e-01, -7.8218e-01, -8.7428e-01,\n",
      "        -4.4801e-01, -3.3936e-01, -2.7914e-01, -1.1559e-01, -3.2021e-01,\n",
      "         7.5620e-01, -1.4946e+00, -3.0834e+00, -2.0960e-01, -2.0996e+00,\n",
      "        -2.6075e-01, -8.3074e-01, -8.7379e-01, -1.3353e+00, -4.2458e-01,\n",
      "        -3.3430e+00, -9.7588e-01, -9.3743e-01, -1.1945e+00, -1.8749e+00,\n",
      "         7.4006e-04, -4.5125e-01, -6.1522e-01, -1.1120e+00, -8.8564e-01,\n",
      "        -1.2524e+00,  1.9111e-01, -1.8345e+00, -1.1713e+00,  1.2644e-02,\n",
      "        -1.0510e+00, -2.2899e-01,  3.3405e-01, -1.6281e-01, -2.6170e+00,\n",
      "        -1.6540e+00, -4.6668e-01, -1.3011e-01, -6.1316e-01, -6.8192e-01,\n",
      "        -4.8805e-02, -2.7796e-01, -1.0176e+00, -2.0274e+00, -1.9184e+00,\n",
      "        -1.1308e+00, -1.1007e+00, -5.4134e-01, -2.1938e+00, -3.4052e-01,\n",
      "        -1.8729e+00, -1.3799e+00, -9.5038e-01, -1.1817e+00, -4.1534e-01,\n",
      "        -2.1337e+00, -1.3564e+00, -1.0765e+00, -5.7329e-02, -1.2317e+00,\n",
      "        -1.6065e+00, -1.3252e+00, -7.2028e-01, -3.4272e+00,  1.9025e-01,\n",
      "        -9.3841e-01, -5.6182e-01, -5.3779e-01, -8.1514e-01, -1.3930e+00,\n",
      "         9.6642e-04, -2.3222e-01, -6.2988e-01, -3.1408e+00, -8.6182e-01,\n",
      "        -1.9654e+00, -4.8713e-01, -6.8767e-01, -2.6628e-01, -1.4752e+00,\n",
      "        -2.1187e+00, -7.0464e-01, -8.8000e-02, -6.0637e-01, -9.1810e-01,\n",
      "        -1.3987e+00, -1.2815e+00, -9.4379e-01, -1.8724e+00, -2.0620e+00,\n",
      "        -1.6002e-01, -2.2987e+00, -8.8885e-01,  2.2636e-01, -1.5018e-02,\n",
      "        -2.8538e-01,  5.2539e-01, -4.4727e-01, -9.2553e-01, -1.5581e+00,\n",
      "        -9.5690e-02,  2.8886e-02, -1.5830e+00, -5.9646e-01, -2.2489e+00,\n",
      "         7.7724e-01, -1.8181e-01, -1.7569e+00, -1.5664e+00, -1.4538e+00,\n",
      "        -5.1767e-01, -1.9356e-01, -1.1659e+00, -1.1077e+00, -1.3543e+00,\n",
      "        -2.4830e-01, -1.5599e+00, -2.7406e-01, -7.0193e-02, -7.2429e-01,\n",
      "        -6.6252e-01, -1.9521e+00, -3.7506e-01, -1.7347e+00, -4.3695e-01,\n",
      "        -1.2316e+00,  3.7342e-01, -1.1771e+00, -1.6070e-01, -1.3470e+00,\n",
      "        -3.6037e-01, -2.2058e+00, -5.7172e-01, -1.8598e+00, -1.0934e+00,\n",
      "        -1.2650e-01, -2.0739e+00, -2.1539e+00, -1.4234e-01, -1.6349e-01,\n",
      "        -1.9442e-01, -6.1567e-01, -1.2546e+00,  1.1804e-01, -5.8627e-01,\n",
      "        -2.2324e-01, -8.1223e-01, -4.6928e-01, -1.5205e+00, -1.4080e+00,\n",
      "        -6.2350e-01, -1.0127e-01, -1.3035e+00, -2.6831e-01, -1.1068e+00,\n",
      "        -2.8469e-01, -1.7476e+00, -7.1302e-01,  3.4859e-01, -1.2236e+00,\n",
      "        -1.0593e+00, -1.9261e-02, -6.3620e-01, -1.2873e+00, -2.5693e-02,\n",
      "        -1.8388e+00, -1.1173e+00, -2.4618e-01, -9.6167e-02, -3.8836e-01,\n",
      "        -2.7349e-01, -1.8607e+00, -9.8037e-01, -6.2255e-01, -1.1194e-01,\n",
      "        -3.9527e-01, -1.2945e+00, -6.8683e-02, -7.8460e-01, -1.2475e+00,\n",
      "        -6.1802e-02, -3.9214e-01, -4.4092e-01, -1.7875e+00, -8.6795e-01,\n",
      "        -2.0039e-01, -4.8875e-01, -3.3962e-01, -1.6102e+00, -1.7808e+00,\n",
      "        -1.2787e+00, -8.0066e-02, -1.2089e+00,  4.5484e-01, -5.2968e-01,\n",
      "         1.2749e-02, -8.0126e-01,  1.1959e-01, -3.3540e-01, -2.7232e-01,\n",
      "        -3.5027e-01, -1.8231e+00, -1.9271e+00, -1.8014e-01, -1.4854e+00,\n",
      "        -1.0439e-01,  1.0143e+00, -1.6440e+00, -3.1413e-01, -1.0970e-01,\n",
      "        -6.1632e-01, -1.5028e+00, -3.7107e-01, -3.8204e-01, -3.5214e-01,\n",
      "        -1.1023e+00, -1.2203e+00, -1.4341e+00,  3.9925e-01, -1.8647e-01,\n",
      "        -3.7613e-01, -4.6482e-01, -6.8643e-01, -2.0390e+00, -3.9484e-01,\n",
      "        -1.5493e+00, -1.0949e+00,  6.8056e-02, -1.1697e+00, -2.1949e+00,\n",
      "        -9.0794e-02, -1.3742e+00, -8.4171e-01, -3.2325e-01, -1.3055e+00,\n",
      "         2.2596e-02, -2.3574e+00, -1.6444e+00, -1.2328e+00, -3.9465e-01,\n",
      "        -1.5958e+00, -9.8468e-01, -5.9088e-01, -1.9744e-01, -5.4430e-01,\n",
      "        -1.1358e+00,  1.8671e-01, -4.0036e-01, -5.5418e-01, -4.0847e-01,\n",
      "         6.8668e-01, -1.7357e+00, -1.7584e+00, -4.6146e-01,  4.2485e-01,\n",
      "         4.6039e-02, -1.6359e+00, -4.3797e-01, -3.5684e-01,  5.6184e-01,\n",
      "        -1.5367e+00, -1.0828e+00, -1.0120e+00, -2.7282e-01, -1.8889e+00,\n",
      "        -2.7433e+00, -1.6771e+00, -1.3759e+00, -3.6954e-01, -2.9775e+00,\n",
      "        -1.1739e+00, -1.8948e+00, -2.6076e+00,  7.3507e-01, -1.4212e+00,\n",
      "        -1.7932e-01, -4.8002e-01, -1.0390e-02,  3.8763e-02, -5.8837e-01,\n",
      "         2.6101e-02, -2.0078e+00, -2.8395e+00, -1.1008e+00,  6.5636e-01,\n",
      "        -7.7350e-01, -1.7498e+00, -1.6920e+00, -1.9454e+00, -5.1491e-01,\n",
      "        -1.5500e+00, -2.3954e-01, -8.0689e-01, -2.5402e-01, -3.6318e-01,\n",
      "        -7.4428e-01, -1.4991e+00, -1.0234e+00, -1.7423e-01, -9.1744e-02,\n",
      "        -2.4468e-01, -1.1442e+00, -8.7178e-03, -1.8931e+00, -1.2208e+00,\n",
      "        -3.9047e-01, -5.8664e-02, -4.3566e-01, -1.1460e+00, -6.3396e-02,\n",
      "        -1.4367e+00, -8.8416e-02, -2.1114e+00,  5.9423e-02, -1.0944e+00,\n",
      "        -4.1132e-02,  1.6626e-01, -5.0672e-01, -5.3613e-01, -1.9242e+00,\n",
      "        -6.8438e-01, -1.0509e+00, -2.7134e+00,  6.4344e-01, -9.1563e-01,\n",
      "        -1.5868e+00, -2.2357e+00,  1.6024e-01, -2.4461e+00,  4.0567e-02,\n",
      "        -4.8595e-01, -4.0344e-01,  1.9408e-01, -5.4307e-01,  1.7755e-01,\n",
      "        -1.6430e+00, -2.2650e+00, -1.6606e+00, -9.9539e-01, -9.7404e-01,\n",
      "        -9.9397e-01, -7.0449e-01, -7.3265e-01, -1.3074e-01, -3.2478e+00,\n",
      "        -7.7345e-01, -6.6958e-01, -1.1918e+00, -1.3261e+00, -1.2366e+00,\n",
      "        -1.2019e+00, -4.0947e-01, -8.7507e-02, -5.0666e-01, -1.0143e+00,\n",
      "        -3.9752e-01, -3.4284e-01, -6.6801e-01, -7.4102e-01, -7.6213e-01,\n",
      "        -2.1480e-01, -1.0421e+00, -5.8920e-02, -1.3308e+00, -3.6211e-01,\n",
      "        -4.7379e-01, -4.6950e-01, -2.7850e-01, -5.6026e-01, -5.5226e-01,\n",
      "        -2.5492e+00, -1.5001e+00,  4.0984e-01, -1.0430e+00, -1.8198e-01,\n",
      "        -8.6017e-01, -1.2347e+00, -1.4335e+00, -2.4546e-01,  9.1525e-01,\n",
      "        -1.0991e+00, -6.6126e-01,  5.0207e-01,  3.0809e-02, -6.2727e-01,\n",
      "        -2.1399e+00, -1.1532e+00, -3.2119e-01, -8.0768e-01, -2.8149e-01,\n",
      "        -9.3877e-01, -3.3020e-01, -1.8243e-01, -5.0616e-01, -5.1952e-01,\n",
      "        -9.7956e-01, -9.5054e-01, -1.3404e+00, -6.0954e-01, -1.5728e+00,\n",
      "        -2.8662e-02, -4.0347e-01, -1.0371e+00, -3.0136e-01, -2.1890e-01,\n",
      "        -2.0563e-01, -3.7178e-01,  2.0686e-01, -1.0483e-01, -1.5421e+00,\n",
      "        -4.3736e-01, -7.0926e-01, -2.9098e-01, -9.0639e-01, -7.9190e-01,\n",
      "         1.2270e-01, -1.0502e+00, -9.5645e-01, -9.4516e-01, -2.0160e+00,\n",
      "        -1.3588e+00, -1.3021e+00, -8.6680e-01, -1.4600e+00, -1.7436e+00,\n",
      "        -1.2684e+00, -1.3968e+00, -1.7416e+00, -9.6879e-01, -7.0332e-01,\n",
      "        -1.4609e+00, -1.0423e+00,  3.2605e-01,  8.1459e-02, -1.6115e+00,\n",
      "        -1.3574e+00, -4.0719e-01, -2.1572e+00, -1.7841e-01, -1.0130e+00,\n",
      "        -7.8394e-01,  7.7317e-02, -2.5095e+00, -5.5991e-01, -6.2770e-01,\n",
      "        -2.3474e-01, -6.2527e-01, -3.4408e-01, -9.0120e-01, -1.2819e-01,\n",
      "        -2.6036e-01, -1.6443e-02, -9.1533e-01, -1.3227e+00, -4.1740e-01,\n",
      "        -1.2947e+00, -1.1820e+00, -2.2991e+00, -1.0518e+00, -5.8643e-01,\n",
      "         7.9471e-02, -1.4409e+00, -4.3327e-01,  1.4583e-01, -2.9079e-01,\n",
      "        -3.7646e-01, -1.3254e+00,  5.9395e-02, -1.9805e-01, -5.3069e-01,\n",
      "         8.0962e-01, -1.2968e-01, -1.6727e+00, -4.7485e-01, -1.6958e+00,\n",
      "        -1.8526e+00, -2.9173e-01, -2.8953e+00, -2.7557e-01,  1.6398e-01,\n",
      "        -1.6342e-01,  5.0097e-02,  8.0798e-02, -1.5800e-01, -1.0902e+00,\n",
      "        -9.2627e-02, -5.8807e-02, -1.2794e+00, -8.8038e-01, -6.9907e-01,\n",
      "        -6.7604e-01, -1.7058e+00, -3.4169e-01, -1.7791e+00, -2.5809e-01,\n",
      "        -8.5958e-01, -3.1269e-01, -1.9701e+00, -9.9673e-01, -6.9886e-01,\n",
      "        -2.1678e+00, -9.8779e-01, -1.9779e+00, -1.0167e+00, -1.1193e+00,\n",
      "        -1.0795e+00, -5.1971e-01, -2.7358e+00, -2.3547e+00, -1.2639e-01,\n",
      "        -3.0511e-01,  6.9726e-02, -1.6443e+00, -2.1070e-02, -1.1968e+00,\n",
      "        -2.4515e-01, -4.8470e-01, -2.0741e-01,  5.6799e-01, -6.0588e-01,\n",
      "        -5.9270e-02, -1.6171e+00,  3.8541e-02, -8.8464e-01, -1.1941e+00,\n",
      "        -1.7262e+00, -1.1299e+00, -2.9354e-01, -1.4687e+00, -5.9571e-01,\n",
      "        -9.6436e-01, -1.2581e+00, -5.4284e-01, -1.5606e+00, -6.1009e-01,\n",
      "        -1.5516e+00, -2.9387e-02,  1.5100e-01,  2.9839e-02,  1.3805e-02,\n",
      "        -1.3746e+00, -6.6482e-01, -2.1321e-01, -2.8743e+00, -1.0018e+00,\n",
      "        -9.2891e-01, -1.5249e+00, -2.2377e+00, -5.6813e-01,  2.0962e-01,\n",
      "        -1.8932e+00, -1.2565e+00, -5.1574e-01, -4.9938e-01, -1.1363e+00,\n",
      "        -2.0725e+00, -1.2196e+00, -1.3515e+00, -2.6816e-01,  9.9649e-02,\n",
      "         2.3668e-01, -8.1410e-02, -4.6359e-01, -4.7493e-01,  5.1956e-02,\n",
      "        -2.1839e-01, -4.1246e-01, -2.6561e-01, -3.4798e-01, -1.1296e+00,\n",
      "        -1.0178e+00,  1.2992e-02, -2.6605e+00, -8.1696e-01, -2.3485e+00,\n",
      "        -1.4164e-01, -3.3247e-01,  2.0930e-01, -5.4898e-01, -1.5976e+00,\n",
      "        -1.5374e+00, -6.7618e-01,  4.5386e-02, -6.2341e-01,  9.7523e-01,\n",
      "        -1.1116e+00, -1.3965e+00, -1.6923e+00, -1.6376e-01,  5.4644e-02,\n",
      "        -7.8243e-01, -4.6571e-01,  4.8728e-01, -1.5739e+00, -1.1485e+00,\n",
      "        -1.8106e+00, -1.6760e+00, -2.6134e-01, -2.0237e-01, -3.7065e-01,\n",
      "        -2.5079e-01, -1.0143e-01, -9.1310e-01, -1.7529e-01, -1.2210e+00,\n",
      "        -1.6616e+00,  6.7641e-01,  7.0846e-01,  2.4344e-03, -1.0995e+00,\n",
      "        -3.1218e+00, -7.5929e-01,  2.5360e-01, -7.8018e-01,  1.7870e-01,\n",
      "        -5.9930e-01, -1.1246e+00, -2.1000e+00, -2.3274e+00, -1.6155e+00,\n",
      "        -3.0753e-01, -1.9872e+00, -1.2811e+00, -2.2326e+00, -9.1742e-01,\n",
      "        -1.4027e-01, -1.2263e+00,  5.7794e-01, -2.0637e+00, -1.3365e+00,\n",
      "        -2.2652e-01, -3.9119e-01,  5.6062e-03, -1.1097e+00, -2.3160e-01,\n",
      "        -1.3453e+00, -3.4506e-01, -2.5769e-01, -2.3274e+00, -1.8137e+00,\n",
      "        -1.8935e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1274]],\n",
      "\n",
      "         [[-0.1697]],\n",
      "\n",
      "         [[ 0.4380]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2342]],\n",
      "\n",
      "         [[ 0.0382]],\n",
      "\n",
      "         [[-0.1104]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0822]],\n",
      "\n",
      "         [[-0.2599]],\n",
      "\n",
      "         [[ 0.1228]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1567]],\n",
      "\n",
      "         [[-0.0957]],\n",
      "\n",
      "         [[ 0.0910]]],\n",
      "\n",
      "\n",
      "        [[[-0.2934]],\n",
      "\n",
      "         [[-0.1407]],\n",
      "\n",
      "         [[ 0.6362]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0333]],\n",
      "\n",
      "         [[ 0.5906]],\n",
      "\n",
      "         [[-0.2996]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0870]],\n",
      "\n",
      "         [[ 0.5723]],\n",
      "\n",
      "         [[ 0.0232]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3324]],\n",
      "\n",
      "         [[ 0.3806]],\n",
      "\n",
      "         [[-0.3571]]],\n",
      "\n",
      "\n",
      "        [[[-0.3799]],\n",
      "\n",
      "         [[ 0.1384]],\n",
      "\n",
      "         [[-0.0477]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5944]],\n",
      "\n",
      "         [[-0.3855]],\n",
      "\n",
      "         [[-0.3119]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0460]],\n",
      "\n",
      "         [[ 0.3209]],\n",
      "\n",
      "         [[ 0.5294]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0899]],\n",
      "\n",
      "         [[ 0.2571]],\n",
      "\n",
      "         [[-0.1694]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.2216, -0.1436,  0.1554, -0.1709,  0.0520, -0.0070, -0.2079, -0.1251,\n",
      "         0.2201,  0.1324,  0.1307, -0.1908,  0.2705,  0.0441,  0.0759,  0.3161,\n",
      "         0.1699,  0.0270, -0.1991,  0.1491, -0.1817,  0.2603,  0.3378,  0.0973,\n",
      "        -0.0564, -0.0121,  0.0614, -0.1407, -0.1602,  0.0772,  0.0413,  0.0675,\n",
      "         0.2218,  0.1127], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2637]],\n",
      "\n",
      "         [[ 0.0527]],\n",
      "\n",
      "         [[-0.2207]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0022]],\n",
      "\n",
      "         [[-0.2411]],\n",
      "\n",
      "         [[-0.1861]]],\n",
      "\n",
      "\n",
      "        [[[-0.1217]],\n",
      "\n",
      "         [[ 0.0607]],\n",
      "\n",
      "         [[-0.0188]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1731]],\n",
      "\n",
      "         [[-0.2618]],\n",
      "\n",
      "         [[-0.0934]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1126]],\n",
      "\n",
      "         [[-0.0280]],\n",
      "\n",
      "         [[-0.1735]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3848]],\n",
      "\n",
      "         [[-0.3370]],\n",
      "\n",
      "         [[ 0.0608]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3246]],\n",
      "\n",
      "         [[-0.0315]],\n",
      "\n",
      "         [[ 0.2902]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2834]],\n",
      "\n",
      "         [[ 0.1268]],\n",
      "\n",
      "         [[ 0.2560]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0661]],\n",
      "\n",
      "         [[ 0.0288]],\n",
      "\n",
      "         [[-0.0642]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4281]],\n",
      "\n",
      "         [[ 0.0563]],\n",
      "\n",
      "         [[-0.3980]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3561]],\n",
      "\n",
      "         [[ 0.0276]],\n",
      "\n",
      "         [[ 0.2846]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1652]],\n",
      "\n",
      "         [[ 0.0393]],\n",
      "\n",
      "         [[ 0.1520]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1927, -0.2863, -0.1096, -0.3248,  0.2587, -0.1740,  0.1058,  0.2893,\n",
      "         0.3886,  0.3642, -0.1174,  0.0704,  0.1535, -0.0449, -0.1221, -0.5277,\n",
      "         0.3262, -0.1403,  0.3828,  0.3072,  0.2864, -0.0065,  0.1700, -0.1186,\n",
      "         0.3019, -0.3440, -0.2782, -0.0558, -0.3468, -0.3494,  0.2040, -0.3856,\n",
      "         0.3089, -0.3171, -0.2609, -0.3122,  0.2387,  0.2639, -0.0932, -0.2980,\n",
      "         0.2511,  0.1689,  0.3768,  0.1497, -0.2523, -0.3311, -0.3801,  0.0299,\n",
      "        -0.2607, -0.3120, -0.0495,  0.1678,  0.3400,  0.3881, -0.0792, -0.2242,\n",
      "        -0.2750, -0.0966,  0.3150, -0.2240,  0.0240,  0.5123,  0.3491, -0.1059,\n",
      "        -0.3463, -0.2966, -0.3405,  0.3017,  0.3621, -0.0240, -0.3877, -0.3248,\n",
      "         0.0213,  0.4058,  0.0491,  0.1055,  0.2143, -0.1271,  0.3387, -0.2638,\n",
      "        -0.0646,  0.0193, -0.3152, -0.3342,  0.2624, -0.0625,  0.0050,  0.0738,\n",
      "        -0.2650, -0.2991,  0.4310, -0.0010,  0.2383, -0.2859, -0.2435,  0.1398,\n",
      "         0.2926, -0.1699,  0.2555, -0.0977,  0.0701, -0.2965, -0.1832, -0.3423,\n",
      "         0.3224,  0.3428, -0.2180,  0.1228, -0.3110,  0.2527,  0.0170,  0.0034,\n",
      "        -0.1416, -0.3563,  0.3143, -0.3191,  0.0974,  0.2229,  0.3246, -0.1045,\n",
      "        -0.2211, -0.0884,  0.3449, -0.1459, -0.3013,  0.4306,  0.2956, -0.2054,\n",
      "         0.3038, -0.0573, -0.3560,  0.0845,  0.4876, -0.2845, -0.2731,  0.1750,\n",
      "        -0.2401,  0.1516, -0.1684,  0.4055,  0.1135, -0.2695,  0.2112,  0.2506,\n",
      "        -0.1024,  0.1485, -0.0473, -0.3444,  0.2573, -0.1330,  0.2325,  0.1987,\n",
      "         0.1839,  0.2765, -0.2502, -0.3867,  0.3752,  0.3954,  0.3342, -0.2964,\n",
      "         0.1347,  0.3046,  0.3251,  0.3118,  0.3571, -0.0148,  0.4625, -0.2823,\n",
      "        -0.4051, -0.3080, -0.2787, -0.3478, -0.3065, -0.2887, -0.3507,  0.0172,\n",
      "        -0.1413, -0.1642,  0.4183,  0.3609, -0.2624,  0.2727, -0.2371,  0.3649,\n",
      "        -0.2856, -0.3853, -0.0487, -0.3568,  0.3006,  0.3402, -0.3566, -0.3739,\n",
      "        -0.3504,  0.4010, -0.0278,  0.0855, -0.3355, -0.2050, -0.0098,  0.2576,\n",
      "        -0.1699, -0.0313, -0.0289,  0.1890,  0.2338,  0.2702, -0.2284,  0.3223,\n",
      "         0.0789,  0.0747, -0.4314, -0.1831, -0.1999, -0.2236, -0.1482, -0.3633,\n",
      "         0.3017,  0.4201,  0.2770, -0.1192,  0.3500, -0.3694,  0.0654, -0.2831,\n",
      "         0.1660, -0.1026,  0.0389,  0.2705, -0.2002,  0.0192,  0.3252, -0.2758,\n",
      "        -0.3738, -0.2817,  0.4287, -0.1191,  0.0845, -0.3573, -0.2963,  0.4093,\n",
      "        -0.3133,  0.4760, -0.2579, -0.3673, -0.2822, -0.2735, -0.1256,  0.2228,\n",
      "        -0.4091,  0.4072, -0.2904, -0.2728,  0.2678,  0.1040,  0.1422, -0.5010,\n",
      "        -0.4233, -0.3494,  0.4075, -0.3832, -0.3074, -0.1207, -0.2938, -0.1617,\n",
      "         0.1000, -0.4010, -0.2313, -0.3047, -0.4311, -0.3357, -0.1479, -0.4335,\n",
      "        -0.3168,  0.3466,  0.2923, -0.3912, -0.1950, -0.1263, -0.0083, -0.2325,\n",
      "         0.3246, -0.4055, -0.3653,  0.0295, -0.4507, -0.0624,  0.0248, -0.2974,\n",
      "         0.2629,  0.2939,  0.3968, -0.2790, -0.2824, -0.0055, -0.2851, -0.3720,\n",
      "         0.2353,  0.2152, -0.2586, -0.1418,  0.4283, -0.2807, -0.0900, -0.2465,\n",
      "         0.2683, -0.0440,  0.0966, -0.3097,  0.2933, -0.2293,  0.0293,  0.2546,\n",
      "        -0.2479, -0.4263,  0.3901,  0.0422, -0.2724, -0.1104,  0.4206,  0.2228,\n",
      "         0.3931, -0.2639, -0.2501,  0.3818,  0.4253,  0.2864, -0.2803, -0.2315,\n",
      "        -0.2476, -0.0009,  0.2351, -0.1776,  0.4317,  0.0425,  0.3101,  0.3011,\n",
      "         0.3793, -0.2020,  0.3681,  0.0544, -0.1830, -0.3545,  0.0149, -0.2294,\n",
      "         0.0715, -0.3671,  0.3898, -0.3764, -0.0185,  0.2472,  0.1010,  0.0748,\n",
      "         0.3795, -0.3112,  0.2976, -0.1645, -0.2861, -0.3684, -0.2933, -0.2720,\n",
      "        -0.2654, -0.0936,  0.3558, -0.2382,  0.3649,  0.3291,  0.4035, -0.0608,\n",
      "         0.2737,  0.2481,  0.2320,  0.0060,  0.3852,  0.0755,  0.3098, -0.1559,\n",
      "         0.0972,  0.3470, -0.3524,  0.1161,  0.3570, -0.0118,  0.3155,  0.2547,\n",
      "         0.3860, -0.3579,  0.2549,  0.2565, -0.1407, -0.0147, -0.3844, -0.2529,\n",
      "         0.2207, -0.3202,  0.2379,  0.1106,  0.2347,  0.0611, -0.2551, -0.2120,\n",
      "         0.4613,  0.4038,  0.3878, -0.3721, -0.2062, -0.3351, -0.2035,  0.3080,\n",
      "        -0.3274,  0.2441, -0.0057, -0.1096, -0.3179, -0.2025, -0.0121, -0.1913,\n",
      "        -0.0632,  0.3438,  0.1395,  0.1724, -0.1130,  0.0789, -0.3063,  0.1917,\n",
      "         0.0590,  0.3290,  0.3000, -0.0501, -0.2773,  0.0986, -0.3623,  0.2296,\n",
      "         0.0941,  0.1336, -0.1375, -0.1052,  0.1727, -0.2589,  0.1090,  0.4370,\n",
      "         0.2923,  0.1741,  0.0036, -0.2705,  0.0553, -0.3382,  0.0748, -0.3586,\n",
      "        -0.1963,  0.3400, -0.3833,  0.3458,  0.4319,  0.1564,  0.3866,  0.3336,\n",
      "         0.2788,  0.3614, -0.3376, -0.0916,  0.0072,  0.4516, -0.0071,  0.2388,\n",
      "        -0.3035, -0.3514,  0.0262,  0.2870,  0.1738,  0.1313, -0.2400,  0.1167,\n",
      "        -0.3558,  0.3303, -0.1464, -0.3283, -0.1574, -0.0182, -0.0192, -0.0354,\n",
      "        -0.0571, -0.3427, -0.3291,  0.2822,  0.0218,  0.0605, -0.2584, -0.2192,\n",
      "        -0.3433,  0.2543,  0.1282,  0.3125, -0.2847,  0.0223,  0.3875, -0.0759,\n",
      "        -0.3733,  0.3164, -0.4417, -0.1189,  0.0083, -0.4513,  0.3717,  0.1040,\n",
      "         0.2975, -0.0606, -0.3647,  0.4405, -0.3162, -0.2882,  0.3742,  0.3847,\n",
      "         0.2546, -0.3808, -0.3509, -0.3041,  0.2233,  0.3804, -0.3239,  0.1732,\n",
      "        -0.0250,  0.2408, -0.0586,  0.4307, -0.3423,  0.3489,  0.2486,  0.0532,\n",
      "         0.0653, -0.0465,  0.2892, -0.3066,  0.0534,  0.2357, -0.2286, -0.2215,\n",
      "        -0.4097, -0.3364,  0.1712, -0.4518,  0.0038,  0.2190, -0.2580,  0.2204,\n",
      "         0.3066,  0.4585,  0.3618, -0.3119,  0.4800, -0.3882,  0.1460,  0.1107,\n",
      "        -0.2523, -0.1837, -0.0628,  0.3505,  0.3888,  0.0908,  0.1618,  0.3989,\n",
      "         0.3711,  0.2309, -0.1737,  0.4379,  0.0300, -0.1074, -0.2566, -0.2608,\n",
      "        -0.2289,  0.3549,  0.3268,  0.3162, -0.2238, -0.2701,  0.3379, -0.2776,\n",
      "        -0.3016, -0.1149, -0.1034,  0.0789, -0.3339, -0.2278, -0.2499,  0.3358,\n",
      "         0.4260,  0.3662,  0.2021,  0.1226, -0.0618, -0.2621,  0.3496, -0.2590,\n",
      "         0.1711, -0.2845,  0.2518, -0.3258,  0.1171, -0.3942,  0.3556,  0.3485,\n",
      "        -0.1960, -0.2176, -0.2208, -0.2743,  0.3325,  0.2765, -0.2287, -0.3133,\n",
      "         0.4441,  0.0877,  0.2156,  0.4146, -0.2280,  0.1868, -0.2775,  0.4135,\n",
      "         0.4693,  0.0097,  0.2545, -0.3151,  0.3745, -0.3979,  0.0467, -0.2336,\n",
      "         0.1790,  0.3762, -0.2509, -0.0116, -0.2638, -0.1070,  0.2442,  0.1296,\n",
      "        -0.3415,  0.2992, -0.1931,  0.0499, -0.2679,  0.4256,  0.4357, -0.1956,\n",
      "        -0.3644,  0.4415, -0.3509, -0.3731, -0.1045, -0.2886,  0.0663, -0.3194,\n",
      "        -0.2332,  0.3833,  0.1461, -0.0738,  0.3155, -0.3399, -0.3039, -0.0486,\n",
      "         0.2207, -0.2903,  0.3724, -0.1420, -0.3391,  0.3193,  0.4943,  0.3995,\n",
      "        -0.0450,  0.3615,  0.3002, -0.0598,  0.2920, -0.2880,  0.4078,  0.0622,\n",
      "         0.1107,  0.3927, -0.0657, -0.3250,  0.0137,  0.0413,  0.2946,  0.0027,\n",
      "        -0.3225, -0.2883,  0.2977, -0.2787, -0.0951,  0.3193,  0.1453,  0.2593,\n",
      "         0.2795, -0.1075, -0.2022, -0.3704, -0.3437,  0.3948,  0.3232, -0.1190,\n",
      "        -0.0961,  0.3602,  0.2733,  0.3088,  0.1782, -0.0354, -0.1832,  0.0287,\n",
      "        -0.1650,  0.3081, -0.2901, -0.2325,  0.1707,  0.2574,  0.2625,  0.0698,\n",
      "        -0.1206,  0.3396, -0.0391,  0.2814, -0.2758, -0.1626,  0.2849,  0.3725,\n",
      "         0.3664, -0.3163,  0.4043, -0.2251,  0.2818, -0.3200,  0.2869, -0.0206,\n",
      "        -0.0813, -0.2031, -0.0878,  0.4695,  0.2900,  0.4108,  0.2218,  0.2081,\n",
      "        -0.2893,  0.3137, -0.0767,  0.2031, -0.1353, -0.3665,  0.1655, -0.3795,\n",
      "         0.1794,  0.3712,  0.1321, -0.0428, -0.3532, -0.1823,  0.1456, -0.4011,\n",
      "        -0.0923, -0.2643,  0.2004,  0.1178, -0.0670, -0.2982, -0.3563,  0.4354,\n",
      "         0.2830,  0.2380, -0.2723, -0.1393, -0.1818, -0.2434,  0.2684, -0.1310,\n",
      "        -0.1244, -0.3211,  0.3548,  0.4097, -0.3646,  0.0132, -0.0089, -0.0741,\n",
      "        -0.3451,  0.3846, -0.3127, -0.0480, -0.2058,  0.0025,  0.1137, -0.0227,\n",
      "        -0.3026, -0.2255, -0.1824, -0.1910,  0.0779,  0.3533, -0.0854, -0.3674,\n",
      "         0.2065,  0.3767, -0.3071, -0.2598, -0.1681, -0.2585,  0.2535, -0.0938,\n",
      "        -0.2921, -0.2615, -0.3136,  0.2371,  0.3824,  0.0489, -0.3458,  0.0345,\n",
      "         0.3545,  0.1356,  0.1858, -0.1024,  0.1529,  0.3339, -0.1369,  0.3652],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 4.6756e-01]],\n",
      "\n",
      "         [[-2.7559e-01]],\n",
      "\n",
      "         [[-7.6441e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.4268e-01]],\n",
      "\n",
      "         [[-5.3274e-01]],\n",
      "\n",
      "         [[ 2.9282e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.2407e-01]],\n",
      "\n",
      "         [[ 7.9248e-02]],\n",
      "\n",
      "         [[-1.2704e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.5611e-01]],\n",
      "\n",
      "         [[ 3.6071e-01]],\n",
      "\n",
      "         [[ 4.3679e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.6980e-02]],\n",
      "\n",
      "         [[ 2.6505e-01]],\n",
      "\n",
      "         [[-6.5741e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5908e-01]],\n",
      "\n",
      "         [[ 2.7166e-01]],\n",
      "\n",
      "         [[ 3.9454e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.8581e-01]],\n",
      "\n",
      "         [[ 1.2889e-02]],\n",
      "\n",
      "         [[-5.0607e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.8847e-02]],\n",
      "\n",
      "         [[ 1.4616e-01]],\n",
      "\n",
      "         [[ 6.0959e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.0380e-01]],\n",
      "\n",
      "         [[ 2.4344e-02]],\n",
      "\n",
      "         [[-3.7408e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.4434e-02]],\n",
      "\n",
      "         [[-6.4784e-01]],\n",
      "\n",
      "         [[ 9.8336e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.8026e-01]],\n",
      "\n",
      "         [[-1.6025e-02]],\n",
      "\n",
      "         [[-3.4898e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.9731e-01]],\n",
      "\n",
      "         [[-1.8433e-01]],\n",
      "\n",
      "         [[-6.6835e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.5046,  0.3217,  0.6185,  1.5159,  0.0307,  0.0289,  0.6081,  2.6967,\n",
      "         0.6754,  0.3230,  0.1398,  0.6173,  1.2153,  0.1679,  0.8455,  2.3731,\n",
      "         0.0419,  0.5146,  0.5202,  0.0834,  0.8954,  0.6754,  0.8870,  1.2973,\n",
      "         1.0586,  0.9057,  0.3502,  0.3560,  0.3938, -0.0055,  0.2238,  0.5867,\n",
      "         0.8274,  0.1715,  1.3185,  0.0558,  0.0188,  0.6162,  0.8483,  0.5948,\n",
      "         1.3469,  0.9840, -0.0252,  0.5256,  0.6508,  1.4836,  1.1846,  1.7225,\n",
      "         0.5996,  0.6461,  3.2097,  0.4757,  1.0125,  0.3736,  0.3348,  0.1587,\n",
      "         0.3330,  0.1576,  1.6166,  0.5680,  0.7780, -0.0048,  0.1283,  1.8116,\n",
      "        -0.1013,  0.6175,  0.4066,  0.6591,  1.0712,  0.3569,  1.1761,  1.0342,\n",
      "         1.8902,  0.5046,  1.2008,  0.1325,  1.3487,  2.2990,  0.4939,  0.1322,\n",
      "         0.4671,  0.0331,  0.8088,  0.7303,  0.2029,  0.0204,  0.9042,  0.4739,\n",
      "         1.2772,  0.1155,  1.4715,  0.8809,  1.4020,  1.2365,  0.0385,  1.0837,\n",
      "         0.0897, -0.0053,  0.3457,  0.1891,  1.8490,  0.1875,  0.0226,  0.9394,\n",
      "         0.8256,  0.4694,  1.5872,  1.1199,  0.4637,  0.5479,  1.9467,  1.1105,\n",
      "         0.9784,  1.0405,  0.1334,  0.6739,  0.4934,  1.9014,  1.1763,  0.8154,\n",
      "         0.6620,  0.7512,  0.6923,  1.0584,  1.3869,  0.7427,  1.0598,  0.0090,\n",
      "         0.9708,  0.3232,  0.7968,  0.8582,  0.2327,  1.6955,  2.2666,  0.6899],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.0683, -0.3138, -0.0753, -0.4909,  0.1004,  0.3748, -0.0966, -1.0935,\n",
      "        -0.1689,  0.1639,  0.3639,  0.6794, -0.3803,  0.2396, -0.0523,  0.9164,\n",
      "         0.2543,  0.2251, -0.3449,  0.3384, -0.3492,  0.1380, -0.2718,  0.3042,\n",
      "         0.0460,  1.1926, -0.0857,  0.0762,  0.3562, -0.6038, -0.1647, -0.1143,\n",
      "        -0.1042, -0.1518,  0.0416, -0.0592,  0.2266, -0.4668, -0.2097, -0.3821,\n",
      "        -0.0445,  0.0750, -0.3321,  0.6123, -0.0772,  0.5704,  0.1272,  0.5546,\n",
      "         0.3248,  0.0908, -0.0613,  0.1327,  0.2920,  0.1871,  0.0756,  0.5015,\n",
      "         0.0447, -0.2052,  0.1779,  0.2356, -0.1350, -0.3601,  0.0122, -0.3357,\n",
      "        -0.1958,  0.2456,  0.5445, -0.0525,  0.4661, -0.3329, -0.3032,  0.3136,\n",
      "         0.7415,  0.2531,  0.2989, -0.3686, -0.5845,  0.2397, -0.0119, -0.2414,\n",
      "        -0.1530, -0.3987, -0.3945,  0.2439, -0.0672,  0.0745,  0.3022, -0.1295,\n",
      "         0.1935,  0.4238,  0.3020, -0.0588,  0.1027,  0.1631, -0.5157, -0.2245,\n",
      "        -0.2244,  0.2257, -0.1321,  0.1041,  0.3758, -0.1798,  0.2534, -0.0055,\n",
      "         0.2419,  0.4051, -0.4442,  0.1119,  0.0417,  0.0110,  0.9879,  0.0306,\n",
      "        -0.0935, -0.1121,  0.1464, -0.0113,  0.3660, -0.9146,  0.1905, -0.1486,\n",
      "        -0.1075,  0.2665,  0.3931, -0.1481, -0.3240,  0.2102, -0.0599,  0.1104,\n",
      "         0.2992,  0.4130, -0.2642, -0.2576, -0.0407,  0.6391,  0.4181, -0.0822],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2031]],\n",
      "\n",
      "         [[-0.2204]],\n",
      "\n",
      "         [[ 0.2012]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7483]],\n",
      "\n",
      "         [[-0.1852]],\n",
      "\n",
      "         [[-0.0325]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1596]],\n",
      "\n",
      "         [[-0.5260]],\n",
      "\n",
      "         [[-0.3673]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1592]],\n",
      "\n",
      "         [[-0.3848]],\n",
      "\n",
      "         [[-0.0329]]],\n",
      "\n",
      "\n",
      "        [[[-0.1597]],\n",
      "\n",
      "         [[ 0.1109]],\n",
      "\n",
      "         [[-0.1083]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1771]],\n",
      "\n",
      "         [[ 0.6427]],\n",
      "\n",
      "         [[-0.1758]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3380]],\n",
      "\n",
      "         [[ 0.7171]],\n",
      "\n",
      "         [[ 0.1719]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1285]],\n",
      "\n",
      "         [[-0.4150]],\n",
      "\n",
      "         [[-0.4686]]],\n",
      "\n",
      "\n",
      "        [[[-0.3604]],\n",
      "\n",
      "         [[ 0.5154]],\n",
      "\n",
      "         [[-0.0441]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2010]],\n",
      "\n",
      "         [[-0.1923]],\n",
      "\n",
      "         [[ 0.3828]]],\n",
      "\n",
      "\n",
      "        [[[-0.8763]],\n",
      "\n",
      "         [[ 0.3853]],\n",
      "\n",
      "         [[ 0.0457]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1218]],\n",
      "\n",
      "         [[-0.0449]],\n",
      "\n",
      "         [[ 0.0846]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.2867,  1.4567,  1.3250,  1.2701,  1.2899,  1.0177,  1.2510,  1.1846,\n",
      "         0.7130,  1.3263,  0.8787,  1.2295,  1.6420,  0.8695,  0.2977,  1.1101,\n",
      "         0.9717,  0.8440,  1.1027,  0.8025,  1.4822,  1.4607,  0.7815,  0.8045,\n",
      "         1.0367,  1.1623,  1.3000,  1.2174,  1.2098,  0.9823,  0.6378,  1.2854,\n",
      "         1.0565,  1.4021,  1.1620,  1.3745,  0.9299,  1.2757,  1.2643,  1.9313,\n",
      "         1.3008,  1.2591,  0.3884,  1.1536,  1.3080,  1.4182,  1.0038,  1.3702,\n",
      "         1.5216,  1.0588,  0.4533,  0.8039,  2.0377,  0.7488,  1.1664,  0.9936,\n",
      "         0.7718,  1.4192,  1.3461,  0.9877,  1.1657,  1.3393,  0.9654,  1.5048,\n",
      "         1.5292,  0.7356,  1.7121,  1.0091,  1.1694,  0.9878,  1.1773,  1.1446,\n",
      "         1.1628,  0.9870,  1.0808,  1.6156,  1.1987,  0.8369,  1.1940,  1.1883,\n",
      "         0.9493,  1.1737,  1.1530,  0.7400,  1.4855,  0.3315,  1.2157,  1.4146,\n",
      "         1.3209,  1.0445,  2.4187,  1.2804,  1.3820,  0.9497,  0.6787,  1.0242,\n",
      "         0.7221,  1.3205,  1.4759,  0.9604,  1.1663,  0.8769,  1.0889,  1.6284,\n",
      "         1.2543,  0.7426,  0.9053,  0.9542,  0.9824,  1.0150,  0.8354,  1.0893,\n",
      "         1.3304,  0.6165,  1.1874,  1.5593,  0.2803,  0.4211,  0.9429,  1.2313,\n",
      "         0.9032,  1.3304,  0.7456,  1.1473,  0.8828,  1.6842,  1.1034,  1.4778,\n",
      "         1.4888,  0.5447,  1.1754,  1.2952,  1.1748,  1.0565,  1.3292,  1.3043,\n",
      "         1.5103,  1.5044,  0.9733,  1.1878,  0.8213,  1.3173,  1.5504,  1.3668,\n",
      "         1.4063,  1.4074,  1.4683,  1.3765,  1.6280,  1.0148,  0.5041,  0.9236,\n",
      "         0.9008,  1.3990,  1.4740,  1.2810,  1.2357,  1.0736,  0.5273,  0.6115,\n",
      "         0.6299,  0.9428,  0.9019,  1.4943,  1.5805,  0.9865,  1.0714,  2.0580,\n",
      "         1.2282,  0.9690,  1.5733,  0.9767,  1.7913,  0.9762,  0.9970,  1.6611,\n",
      "         1.1437,  1.1476,  1.5993,  0.8994,  0.6582,  1.2368,  0.9016,  1.4666,\n",
      "         1.1945,  1.5407,  0.9913,  0.6933,  0.9551,  1.4197,  1.6410,  1.1950,\n",
      "         1.1375,  1.1884,  2.1199,  1.2609,  0.6885,  1.1419,  1.7168,  1.6752,\n",
      "         1.1995,  1.0247,  1.1676,  0.1280,  1.5081,  0.8745,  1.4918,  0.6502,\n",
      "         1.7209,  1.7517,  1.0036,  0.9575,  1.5776,  1.0752,  0.8073,  1.5073,\n",
      "         1.6555,  1.2887,  1.2326,  1.0439,  1.3784,  1.1970,  1.4727,  0.9887,\n",
      "         1.6920,  1.0496,  1.0630,  1.2040,  1.0168,  1.3445,  1.2451,  1.3690,\n",
      "         1.8490,  1.1931,  1.0910,  0.7598,  1.4430,  1.2472,  1.1035,  1.0356,\n",
      "         1.3676,  1.2065,  1.5552,  0.3929,  1.9522,  0.9196,  1.9060,  1.1821,\n",
      "         1.4392,  1.2734,  1.3674,  1.2567,  0.6988,  0.9019,  1.0794,  1.3001,\n",
      "         1.3856,  1.0182,  1.4546,  1.0659,  0.8897,  0.9567,  1.2376,  1.2717,\n",
      "         0.6320,  1.0321,  0.6419,  1.2634,  1.4500,  1.0642,  1.5744,  0.7212,\n",
      "         1.5216,  0.6936,  1.2407,  1.1462,  1.4673,  1.3294,  1.6484,  0.9711,\n",
      "         1.1329,  1.1362,  0.6240,  0.6627,  1.0218,  1.0448,  1.0080,  1.2512,\n",
      "         1.1426,  1.1600,  1.8767,  1.5844,  1.3701,  0.9123,  1.5136,  0.5592,\n",
      "         0.4596,  0.9469,  1.0507,  0.7619,  1.3043,  1.5495,  1.3524,  0.9026,\n",
      "         1.5138,  0.0715,  0.9745,  1.9616,  1.0553,  1.3059,  0.5110,  1.9722,\n",
      "         1.0646,  0.5032,  1.3309,  1.0067,  0.8956,  0.4418,  1.1005,  1.2023,\n",
      "         1.2625,  0.9410,  1.1153,  1.4293,  1.1048,  1.1191,  1.2137,  1.2103,\n",
      "         1.0647,  1.2718,  0.0642,  1.6892,  1.0945,  0.8125,  1.3146,  1.5271,\n",
      "         0.4141,  1.1129,  0.9692,  1.0579,  1.5773,  1.4636,  0.5538,  0.9013,\n",
      "         0.9867,  0.8349,  1.7351,  0.8639,  0.2988,  1.0124,  1.3231,  0.6776,\n",
      "         1.2089,  1.9538,  0.6039,  1.5479,  1.0265,  1.0128,  1.0885,  1.6581,\n",
      "         1.1549,  1.3899,  1.2687,  1.3848,  1.6711,  1.8698,  1.5718,  0.8669,\n",
      "         0.9780,  1.1874,  0.2430,  1.1592,  0.7881,  1.7175,  0.9221,  0.9948,\n",
      "         2.1721,  1.0366,  1.5394,  1.0683,  1.3867,  1.0871,  0.6403,  1.3004,\n",
      "         1.6812,  1.0642,  1.1706,  1.7172,  0.7906,  1.5189,  0.9425,  0.8637,\n",
      "         1.2175,  0.4818,  0.7395,  1.0628,  1.5384,  1.2087,  1.3932,  0.5936,\n",
      "         0.1850,  1.1895,  1.8215,  0.8288,  0.6696,  1.1775,  1.5209,  0.8777,\n",
      "         1.0778,  0.6342,  0.9796,  0.6258,  1.0595,  1.1489,  1.2234,  0.9279,\n",
      "         0.8449,  0.9302,  1.2930,  0.7589,  0.6402,  1.1570,  0.7786,  1.0815,\n",
      "         0.8903,  1.4175,  1.1870,  1.4211,  1.4709,  1.0728,  0.4944,  1.0363,\n",
      "         1.2578,  1.2733,  1.3339,  0.6355,  1.7323,  1.9745,  0.7370,  0.7911,\n",
      "         0.8528,  1.0455,  0.9429,  1.0788,  1.0061,  1.1185,  1.2009,  1.1372,\n",
      "         1.0189,  1.1415,  0.9539,  1.0237,  1.4533,  1.4503,  1.6312,  1.1901,\n",
      "         1.4089,  1.1166,  0.8629,  0.8077,  1.4323,  0.9562,  1.4968,  1.0885,\n",
      "         0.3981,  0.8761,  1.1530,  1.7718,  1.2581,  1.3967,  0.8303,  1.4064,\n",
      "         1.3935,  0.2301,  1.4943,  1.0188,  1.0656,  1.2834,  0.5912,  1.6556,\n",
      "         1.5265,  1.3996,  1.2944,  1.1582,  0.8426,  1.5699,  1.1925,  1.4286,\n",
      "         1.2267,  0.9598,  1.3081,  1.5368,  0.4358,  1.1242,  0.9557,  1.0754,\n",
      "         0.7571,  0.9293,  0.5934,  0.6455,  1.1382,  1.0301,  1.2245,  1.2146,\n",
      "         1.6327,  0.8939,  1.2954,  1.6331,  1.4798,  1.2989,  1.8882,  1.4874,\n",
      "         0.1517,  1.3662,  1.7150,  0.7945,  1.1625,  1.2395,  1.8625,  1.3634,\n",
      "         1.3217,  0.8539,  2.5675,  0.9318,  1.2060,  0.5793,  1.1430,  1.6999,\n",
      "         1.0744,  1.6625,  1.3161,  0.9163,  0.8638,  1.1633,  1.5498,  0.7375,\n",
      "         1.4148,  1.1025,  0.8909,  1.0002,  1.2688,  0.1847,  1.5205,  1.4652,\n",
      "         1.1205,  1.6223,  1.1382,  1.0508,  0.7334,  1.2941,  1.0407,  1.1531,\n",
      "         0.9489,  1.6553,  0.6702,  1.5533,  1.3598,  0.8009,  1.4703,  0.7151,\n",
      "         1.7266,  1.2028,  1.2391,  1.1091,  1.4261,  0.9346,  0.8166,  0.8686,\n",
      "         1.8874,  0.8550,  1.1521,  1.1961,  1.3282,  0.8457,  1.3097,  0.6434,\n",
      "         0.7337,  0.7807,  1.1294,  0.8029,  0.9976,  1.0743,  1.0730,  1.7561,\n",
      "         1.1681,  0.6300,  1.3530,  1.3570,  1.1256,  1.0245,  1.2778,  0.8364,\n",
      "         0.8399,  1.0672,  1.0900,  0.6507,  1.3987,  1.3388,  1.0409,  1.0037,\n",
      "         0.8757,  1.5311,  0.9869,  0.6017,  1.1983,  0.5066,  1.2319,  1.3432,\n",
      "         1.1804,  1.3758,  1.2760,  1.1480,  0.4626,  0.8815,  1.5625,  1.1962,\n",
      "         0.9983,  0.3228,  0.7952,  1.9244,  0.7800,  1.5532,  1.0856,  1.1667,\n",
      "         0.9765,  0.7470,  1.4589,  1.3404,  1.1052,  1.7702,  1.0430,  1.2908,\n",
      "         0.5199,  1.1044,  0.8707,  1.2040,  1.0151,  1.0035,  1.1627,  1.0691,\n",
      "         1.4365,  1.3987,  0.5394,  1.2426,  0.9782,  1.0512,  0.8458,  2.0611,\n",
      "         1.3549,  1.1214,  1.0950,  1.4356,  0.5006,  1.8940,  0.7542,  0.9991,\n",
      "         1.3033,  1.0703,  1.3441,  1.2187,  1.9999,  1.6539,  0.8881,  1.0040,\n",
      "         2.0649,  1.7551,  1.4889,  1.0386,  1.0740,  1.4602,  1.2561,  1.7449,\n",
      "         1.7478,  0.8288,  1.2136,  1.0048,  0.8385,  0.5265,  0.8338,  0.9664,\n",
      "         1.1342,  1.0251,  0.8244,  1.0035,  1.4651,  1.3871,  1.1570,  1.1297,\n",
      "         1.0114,  1.0129,  0.9666,  1.0223,  1.0991,  0.3044,  1.1814,  1.4204,\n",
      "         1.4682,  1.2902,  1.3389,  0.9891,  1.2520,  1.0419,  1.2728,  1.1535,\n",
      "         1.0840,  0.9662,  0.7335,  1.0696,  1.1033,  1.3331,  1.8616,  0.6904,\n",
      "         1.2189,  1.3306,  1.2265,  1.3673,  1.1500,  1.4957,  1.0484,  1.2249,\n",
      "         1.2583,  0.9389,  0.7233,  1.8320,  1.3815,  1.2205,  1.2441,  1.4668,\n",
      "         0.6901,  1.0007,  1.0537,  1.9392,  1.8339,  0.8868,  0.8786,  1.1167,\n",
      "         0.8071,  0.9135,  0.7910,  1.5407,  1.5135,  0.8069,  0.7734,  0.9410,\n",
      "         1.4514,  1.0719,  0.8850,  1.9328,  1.3669, -0.0354,  0.9180,  0.4036,\n",
      "         1.2424,  0.8086,  0.6660,  0.9471,  1.2264,  1.0282,  1.2692,  1.7019,\n",
      "         1.4697,  1.7362,  1.0299,  0.7837,  1.2988,  0.7868,  1.2007,  1.1521,\n",
      "         1.2817,  1.3125,  0.5476,  0.4902,  1.3436,  0.9827,  0.7643,  1.1503,\n",
      "         1.0629,  1.2791,  1.6334,  0.9982,  0.9147,  1.3291,  0.5213,  1.4922,\n",
      "         1.7035,  1.8354,  0.4501,  1.0944,  0.5176,  0.9967,  0.6051,  1.0412,\n",
      "         1.4507,  1.4039,  0.5313,  1.6941,  0.9317,  1.2789,  1.4408,  1.1062,\n",
      "         0.9394,  1.8079,  1.1126,  1.2170,  0.4081,  1.0584,  1.3096,  0.9523,\n",
      "         0.7155,  0.8957,  1.3188,  0.9089,  1.0172,  1.5670,  1.5333,  1.1731],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.5966, -0.1473, -1.4309, -1.0632, -1.7498, -1.0070, -0.9840, -1.2876,\n",
      "        -1.1075, -1.2225, -1.3728, -1.4715, -0.5022, -1.3866, -0.4916, -2.3194,\n",
      "        -0.6019, -2.1025, -0.5268, -0.5056, -1.3862, -0.8802, -1.1203, -1.1666,\n",
      "        -1.3077, -1.2512, -0.3036, -1.5148, -0.1906,  0.2206, -1.7049, -0.9721,\n",
      "        -1.7404, -0.3192, -1.2497, -1.5668, -2.1274, -0.8867,  0.1592, -1.1335,\n",
      "        -0.9141, -0.8455,  0.0349, -0.8848, -1.5845, -0.4298, -1.3369, -0.9691,\n",
      "         0.4703, -0.7195, -0.4141, -1.2234, -3.1068, -1.6649, -1.0161, -0.4241,\n",
      "        -0.5159, -1.5247, -0.0854, -1.5812, -1.4342, -0.7753, -0.4291, -0.0434,\n",
      "        -0.5201,  0.1194, -1.4325, -1.8076, -2.1844, -0.7916, -0.0245, -1.3858,\n",
      "        -0.9931, -0.8892, -2.4251, -0.9079, -0.5509, -2.5525, -1.3297, -0.8113,\n",
      "        -1.4719, -0.9838, -1.7519,  1.2204, -1.0053,  0.5663, -1.1443, -0.1788,\n",
      "        -1.2905, -0.0304,  0.2077, -1.3162, -2.1955, -1.8349,  0.1102, -0.7986,\n",
      "        -1.0194, -2.1844, -1.7480, -0.3607, -0.9676, -0.5114, -1.1940, -1.0840,\n",
      "        -2.2328, -1.0474, -0.6692, -1.4574, -1.1849, -0.3150, -1.0349, -1.3381,\n",
      "        -1.0134, -0.8453, -1.8561,  0.0206,  0.4407,  0.8556, -1.0130, -1.5610,\n",
      "        -1.0859, -1.3566, -0.6478, -0.8613, -0.6796, -1.6191, -1.2572, -0.2932,\n",
      "        -0.6267, -0.8047, -1.6638, -1.6993, -1.0066, -0.7695, -0.9481, -1.5665,\n",
      "        -1.0440,  0.8569, -0.0935, -0.9866, -1.8926, -1.8616, -1.2220, -1.1716,\n",
      "        -0.8523, -0.7164, -1.8122, -1.0375, -0.8989, -0.9208, -0.6974, -0.5856,\n",
      "        -1.8415, -0.5594, -1.6016, -1.2240, -0.6395, -0.5780, -2.0833, -0.1822,\n",
      "        -0.3208,  1.1227, -1.3200, -0.6801, -0.5481, -1.1810, -0.9144,  0.0639,\n",
      "        -1.4749, -1.2719, -0.8739, -1.4053, -1.2512, -0.8595, -0.7777, -0.8885,\n",
      "        -2.5375, -0.4714, -0.8811, -1.3403,  0.5252, -1.7410, -2.0293, -1.8780,\n",
      "        -1.8519, -1.0464, -0.5155, -1.5424, -0.9463, -1.4969, -1.6450, -1.0382,\n",
      "        -0.6360, -1.2320, -1.6516, -0.5784, -0.4012, -1.0323, -2.3575, -0.9903,\n",
      "        -1.4959, -1.2680, -0.1147, -0.1273, -1.4266,  0.5124, -0.6762,  0.1710,\n",
      "        -0.6356, -1.4353, -0.7294, -0.3931, -0.6544, -0.4953, -0.6330, -0.8080,\n",
      "        -0.5595, -2.0054,  0.8992, -0.6669, -0.2735, -0.6078, -1.0867, -0.5937,\n",
      "        -0.9161, -1.0159, -0.2027, -1.3138, -1.3700, -0.9645, -1.1064, -0.6770,\n",
      "        -0.2533, -1.3164, -0.5224, -1.6597, -1.0459, -1.9564, -0.6485,  0.1062,\n",
      "        -2.5002, -1.2672, -2.1599, -0.3652, -0.4851, -0.9473, -0.4850, -1.2855,\n",
      "        -0.2604, -2.1474, -0.2730, -1.2842, -0.3363, -1.4078, -0.9555, -1.4959,\n",
      "        -0.9634, -0.6904, -0.5276, -1.4142, -0.6514, -0.3435, -1.9888, -0.9470,\n",
      "        -0.7980,  0.1703,  0.4447, -0.4829, -1.8814, -1.1134, -1.4604, -0.9763,\n",
      "        -0.4810,  0.2021, -2.1773, -1.8658, -0.9663, -1.6506, -1.1444, -1.9562,\n",
      "        -0.0356, -0.9471, -0.7145, -0.1392, -0.7829, -0.7656, -1.5223, -1.5934,\n",
      "        -2.5900,  0.0431, -0.3716, -0.6358, -0.6335,  0.5930, -1.8762,  1.4091,\n",
      "        -0.3155, -0.9609, -1.4241, -0.4488, -2.1395, -0.7839, -1.2966, -0.7886,\n",
      "        -0.9818, -0.1641, -2.7295,  0.4850, -1.1291, -0.5324, -1.8693, -0.2408,\n",
      "        -1.0733, -2.3546, -1.3579, -1.0112, -1.2028, -1.4246, -2.0912, -2.2514,\n",
      "        -1.5049, -1.3464, -1.2270, -0.2508, -1.5949, -1.6643, -0.8388, -0.7713,\n",
      "        -1.7930, -0.7123,  0.8044, -0.7733, -1.5641, -0.8800, -1.4881, -1.6613,\n",
      "         0.3209, -1.0149, -1.0710, -0.6387, -0.0982, -1.1449, -2.0630, -1.0720,\n",
      "        -0.7453, -1.0454, -0.7824, -0.9780, -0.3320, -1.1592,  0.2244, -1.9356,\n",
      "        -1.0535,  0.4271, -1.5564, -1.8705,  0.5800, -2.3199, -1.2326, -1.0960,\n",
      "        -1.5113, -0.2715, -1.2160, -0.3287, -0.1117, -0.3256, -0.6025, -0.6771,\n",
      "        -1.5770, -1.0123,  0.5061, -1.0129, -1.2719,  0.1293, -1.1725, -0.8336,\n",
      "        -0.2260, -1.2595, -2.6199, -0.3913, -1.4746, -0.5781, -0.7151, -1.6888,\n",
      "        -1.8636, -0.3247, -1.0327, -1.5083, -0.8396, -0.9097, -0.4917, -1.2150,\n",
      "        -0.9978, -0.2165, -1.4467, -2.0977, -1.6629, -1.1707, -1.5735, -0.0280,\n",
      "        -1.4255, -1.3736, -0.4613, -1.6427, -1.4459, -1.7749, -1.1403,  0.4876,\n",
      "         0.3350, -0.5126, -1.1693, -0.2754, -0.9159, -0.4110, -1.3328,  0.3750,\n",
      "        -1.0184, -0.9872, -0.5426, -0.0383, -1.6036, -0.7679, -0.9634, -2.2795,\n",
      "         0.4004,  0.2247, -2.0069, -1.5805, -0.6601, -1.4839,  0.8862, -1.6042,\n",
      "        -1.3209, -0.7366,  0.0851,  0.4118, -0.1809, -1.0198, -1.1934, -0.9645,\n",
      "        -0.6847, -1.1035,  0.0052, -0.8171, -0.8115, -0.3006,  0.3435, -1.2845,\n",
      "        -0.5227, -1.4633, -2.3968, -2.4911, -0.4667, -0.5293, -2.4069, -1.6404,\n",
      "        -0.5925, -1.3614, -0.0142,  0.4442, -2.4357,  0.2782, -0.2068, -0.1562,\n",
      "        -0.8518, -0.2670, -0.8544, -0.6412, -1.0380, -2.0453, -0.5338, -1.2256,\n",
      "         0.1899,  0.1515, -0.3117, -1.7530, -1.3333, -0.9358, -0.9563, -1.5652,\n",
      "        -2.6018, -1.9159, -0.5771, -0.7104, -1.6929, -0.9397, -2.7884, -0.5249,\n",
      "        -1.1959, -0.3540, -2.0312,  0.3432,  0.6486, -1.8331, -1.2990,  0.5588,\n",
      "        -0.0542, -0.0204, -0.4725, -0.8431, -1.5240, -1.3646, -1.8455, -1.9377,\n",
      "        -0.1935, -1.0065,  0.0264, -1.8115, -1.5327, -1.5355, -0.5838, -0.9343,\n",
      "         0.6888, -0.9405, -1.8885, -1.2279, -1.2258, -1.0508, -0.3027, -0.9568,\n",
      "        -1.0491, -0.3453,  0.4041, -1.3584, -2.4969,  0.5766, -1.7210,  0.0306,\n",
      "        -1.1559, -0.7261, -2.1037, -0.2537, -0.4273, -1.3670, -0.0609, -1.4680,\n",
      "        -0.8233, -1.2854, -0.6397, -1.0003, -1.1349, -1.5709,  0.5295, -1.2127,\n",
      "        -1.5787, -1.4756,  0.1449,  0.5102,  0.5087, -0.5538, -0.0050, -0.6386,\n",
      "        -1.1845, -0.2396,  0.2986, -0.4117, -2.2946, -0.5701, -0.6407, -1.2131,\n",
      "        -1.0170, -1.3659, -1.5581, -1.4272, -1.2957, -1.0969, -2.1657, -1.9839,\n",
      "        -0.7817,  0.1026, -1.5944, -1.9662, -1.7749, -0.8826, -1.4898, -1.5233,\n",
      "        -0.1483, -1.4270, -1.3894, -1.4956, -2.1519, -0.5191, -2.0507, -1.3055,\n",
      "        -1.0445, -0.7594, -0.7552,  0.7033, -1.2197, -0.8218, -1.1837, -0.5846,\n",
      "        -0.5380, -1.3605,  0.4773, -1.3294, -0.0308, -1.5224, -1.9006, -0.2314,\n",
      "        -0.7719, -0.0536, -0.9613,  0.9804, -1.1868,  0.9651, -1.0997, -1.0914,\n",
      "        -1.9802, -0.6583, -0.7361, -1.3127, -0.9107, -1.6065, -0.4391, -0.9210,\n",
      "        -1.4804,  0.1451, -0.9737, -0.3444, -0.6942, -1.2268, -1.1533, -1.7217,\n",
      "        -0.6888, -1.5419, -0.7886, -0.9157, -0.8453, -0.3945, -0.7493, -1.4543,\n",
      "         0.5300, -1.1136, -0.7898, -0.9394, -0.1972, -2.1364, -1.1534, -0.6139,\n",
      "        -1.9250, -1.3130,  0.4436, -0.7152, -1.0947, -0.5813, -1.9848,  0.6233,\n",
      "         0.7885, -2.0073, -1.2375,  0.1016, -0.2135, -0.3072, -0.6038, -1.1345,\n",
      "        -0.8669, -0.5713, -1.7209, -0.6560, -0.4292, -0.4569, -0.2998, -1.1906,\n",
      "        -0.3298, -0.9376, -1.8951, -0.7486,  0.6564, -1.0332, -2.5836, -2.1350,\n",
      "        -0.6155, -1.2588, -0.8353, -1.2378, -0.8700, -1.0518, -0.6918, -1.7321,\n",
      "        -1.5071, -1.2803, -0.9649, -1.7154, -0.6527, -1.6214,  0.0969, -0.2582,\n",
      "        -0.9691, -1.5713,  0.2177, -0.2881, -1.0906, -0.1834, -1.4129, -0.5107,\n",
      "        -1.5636, -1.6354, -1.1986, -2.2819, -1.2913, -1.9317, -1.1945, -0.5172,\n",
      "        -0.2035, -0.2352, -1.1776, -1.9237,  0.0845, -0.7505,  0.4248, -2.1096,\n",
      "        -0.7491, -1.7077, -1.8204, -2.1830, -1.2122, -1.8644, -0.9674, -1.2707,\n",
      "        -0.0226, -1.3032, -1.3489, -1.5039, -1.2789, -0.5183, -0.6629,  0.3414,\n",
      "        -1.1528, -0.6095, -1.3634, -0.0319, -0.2812, -1.4322, -0.7814, -1.3714,\n",
      "        -2.0406, -0.7967, -2.0870, -1.1673, -1.0265,  0.1120, -1.2253, -1.7375,\n",
      "        -0.7700, -1.1328, -1.2254, -0.4619, -1.1280,  0.5681, -0.5414, -1.3455,\n",
      "        -1.0305, -0.2296, -2.8184, -0.5727, -0.3812, -2.0772, -0.5503,  0.3729,\n",
      "        -0.5348, -2.3083, -0.7532, -1.4726, -1.2946, -1.4757, -0.8671, -1.2641,\n",
      "        -1.0455, -2.0154, -0.4217,  0.0569, -1.4347,  0.1366, -2.2158, -0.6659,\n",
      "        -1.6484, -1.2102, -1.3283, -1.0494, -0.3199, -0.1702, -0.9022, -0.9284,\n",
      "        -1.5056, -1.3429, -0.0806, -1.2358, -0.0130, -0.3873, -0.7541, -1.0245,\n",
      "        -1.3945, -1.7338, -1.5861, -0.8093, -0.9566, -1.0878, -1.2804, -0.6551,\n",
      "        -0.8353, -0.2738, -0.6793, -0.7694, -0.2364, -1.0935, -0.7712, -1.5800,\n",
      "         1.0409, -1.2229, -1.4948, -0.1553, -0.1217, -0.8397, -1.1898,  0.1578],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 1.5157e-01,  2.4037e-02, -1.2658e-01, -8.6128e-02, -1.4662e-01],\n",
      "          [-1.5569e-01, -1.5780e-01, -2.3720e-01, -8.4021e-03,  1.7821e-01],\n",
      "          [ 1.6365e-01,  4.8340e-01,  8.5557e-01,  7.5536e-01,  5.5202e-01],\n",
      "          [ 6.9747e-02,  3.5047e-02,  2.7061e-02, -3.1392e-02, -1.4819e-01],\n",
      "          [-6.4703e-02, -2.2545e-02, -1.4776e-01,  8.9805e-02, -3.8617e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7792e-01,  2.3259e-01,  1.2213e-01, -1.4587e-01,  6.8096e-02],\n",
      "          [ 4.7625e-01, -1.7491e-01,  6.1439e-01, -2.7578e-01, -2.7891e-01],\n",
      "          [ 5.8265e-01,  2.3269e-01,  8.3152e-01,  1.2405e-01,  6.4317e-02],\n",
      "          [ 2.8190e-01,  1.0319e-01,  6.5501e-01,  4.0574e-01,  1.6136e-01],\n",
      "          [-3.0162e-01, -4.3672e-02, -1.9914e-01,  6.4631e-02, -6.5971e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7856e-01,  1.0117e-01, -3.5883e-01,  2.6284e-01,  5.0037e-02],\n",
      "          [ 6.0570e-01,  5.4925e-01, -4.5584e-01, -3.5223e-01, -2.1607e-02],\n",
      "          [ 8.5155e-01,  2.9395e-01, -2.7463e-01, -1.8109e-01,  1.1784e-01],\n",
      "          [-2.4072e-02,  2.7734e-01, -2.8495e-01,  1.2913e-01, -2.8731e-01],\n",
      "          [-2.6553e-02,  1.9621e-01, -3.2023e-01, -2.6309e-01, -1.9539e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.5775e-04,  4.6929e-01,  2.8175e-01, -2.3102e-01, -1.4383e-01],\n",
      "          [-1.7463e-01,  5.3380e-01, -3.5761e-01, -4.7352e-01, -6.5205e-01],\n",
      "          [ 5.7560e-02,  3.0495e-02, -2.4082e-01,  4.5685e-03, -2.3429e-01],\n",
      "          [-4.0118e-01, -3.5767e-01, -3.8972e-01, -4.3213e-01, -1.7284e-01],\n",
      "          [-3.2047e-01, -1.1731e-01,  7.4728e-02,  8.7912e-02, -6.2774e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.9657e-01, -9.0898e-02, -1.0804e-01, -2.2607e-01,  5.3328e-01],\n",
      "          [-2.1128e-01, -6.4966e-01, -4.6192e-01,  3.0659e-01, -1.7046e-01],\n",
      "          [ 1.4504e-01,  2.6134e-01,  8.4438e-02,  3.0451e-01,  3.9685e-02],\n",
      "          [-7.6532e-01,  2.4592e-01,  2.6071e-01, -3.6177e-01, -8.1483e-01],\n",
      "          [-3.2174e-01, -1.6848e-01,  1.7937e-01,  3.7062e-01, -2.4445e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7365e-01, -3.0539e-01, -2.9767e-02,  4.0313e-01,  5.1923e-01],\n",
      "          [ 3.9817e-01, -3.1167e-01, -2.8643e-01,  6.4989e-01,  2.2365e-01],\n",
      "          [ 2.8914e-01, -2.4120e-01,  1.1024e-02,  7.1023e-01, -2.0053e-01],\n",
      "          [ 2.1225e-01, -6.6964e-02,  3.7979e-02,  3.0819e-01, -4.8741e-01],\n",
      "          [ 1.8365e-01, -2.5555e-01,  7.4663e-03,  1.7223e-01, -9.3337e-02]]]],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.5492, 2.5739, 1.6060, 2.3209, 1.3743, 1.8372, 1.4262, 0.6565, 0.8688,\n",
      "        0.2760, 1.7021, 2.3827, 1.0543, 1.4744, 0.8370, 0.9104, 1.8203, 1.2298,\n",
      "        1.8315, 1.0733, 1.4291, 1.4247, 0.8842, 1.6173, 1.8739, 1.2790, 0.6464,\n",
      "        1.6313, 0.8404, 1.3036, 0.9518, 1.2467, 0.1377, 0.9758, 0.9886, 0.9885,\n",
      "        0.5299, 1.2495, 1.9608, 1.9147, 1.8339, 3.6291, 1.9945, 1.6323, 1.1909,\n",
      "        1.1942, 1.6321, 0.7822, 2.2888, 1.3249, 1.9417, 1.6757, 3.7978, 1.3718,\n",
      "        1.0763, 1.0182, 1.0035, 1.2525, 1.2625, 1.2462, 1.2704, 0.9680, 1.5184,\n",
      "        1.5217, 1.3611, 1.6087, 1.7986, 1.6848, 1.3188, 1.8359, 0.7225, 1.1674,\n",
      "        1.3515, 1.1229, 1.8276, 1.5440, 1.7863, 1.0358, 1.6659, 1.8958, 1.0731,\n",
      "        1.6534, 0.9973, 2.0219, 1.3338, 1.5051, 1.1416, 1.5196, 1.3707, 1.2212,\n",
      "        2.6434, 2.3800, 1.1913, 0.7339, 1.7013, 1.5816, 0.9745, 1.4251, 2.9923,\n",
      "        1.4926, 1.1693, 1.8462, 1.2647, 1.2742, 0.9380, 0.5470, 1.6189, 1.1360,\n",
      "        1.3085, 1.6116, 1.2557, 0.8751, 0.7626, 1.0444, 1.0457, 1.6296, 1.7926,\n",
      "        1.7061, 1.1778, 1.0196, 0.9288, 0.7851, 1.5057, 1.6920, 1.7971, 2.5857,\n",
      "        0.3707, 1.6119, 1.3143, 0.7145, 1.0394, 3.4092, 1.3782, 1.5096, 1.7299,\n",
      "        0.4918, 0.7969, 1.7267, 1.8017, 1.4466, 0.6231, 0.8501, 1.3118, 0.8507,\n",
      "        1.4639, 1.3956, 1.2759, 1.5748, 1.7564, 1.4484, 1.4392, 1.5844, 1.6833,\n",
      "        1.3153, 1.2668, 1.4808, 1.2013, 1.6174, 1.4618, 1.9449, 1.8071, 2.1498,\n",
      "        1.0748, 1.0546, 1.5630, 0.7962, 1.2751, 1.6132, 0.6266, 1.1472, 1.5718,\n",
      "        0.9709, 0.9780, 1.4274, 1.5081, 1.3897, 1.3699, 1.8613, 1.4109, 0.9102,\n",
      "        1.1922, 1.0386, 0.8968, 1.7639, 1.5796, 1.4061, 1.6454, 1.2786, 1.4196,\n",
      "        1.8780, 1.0607, 1.3521, 1.6022, 1.3786, 1.1725, 1.2996, 1.9145, 1.2159,\n",
      "        1.2420, 0.0948, 1.1938, 1.3497, 0.9915, 2.9458, 0.9564, 1.2644, 1.2425,\n",
      "        1.4696, 1.2119, 2.4267, 1.3768, 1.6423, 1.0267, 0.8820, 1.7045, 0.7918,\n",
      "        1.5287, 0.8209, 2.0940, 1.2561, 1.3182, 1.5210, 1.8636, 1.0485, 1.5062,\n",
      "        1.7036, 1.7183, 2.5949, 1.9340, 1.2625, 0.5536, 1.3650, 1.1467, 0.9772,\n",
      "        2.0900, 1.5580, 1.0065, 0.2734, 1.5102, 1.5192, 1.5197, 1.2934, 0.3118,\n",
      "        1.6692, 1.2559, 1.4916, 1.4153, 1.3200, 1.6104, 2.1058, 1.0255, 1.0716,\n",
      "        2.2576, 0.8061, 0.9481, 0.8561, 1.4180, 1.3258, 1.4007, 1.4016, 1.2919,\n",
      "        1.3263, 2.1535, 1.9717, 1.5070, 1.4609, 1.2068, 1.5827, 1.3848, 1.2035,\n",
      "        2.5996, 1.6743, 1.0521, 1.6811, 0.7622, 2.1807, 1.3195, 1.1992, 1.5194,\n",
      "        1.0740, 1.4351, 1.1005, 1.4007, 1.1445, 1.6418, 1.4416, 0.8857, 1.1977,\n",
      "        0.9028, 1.7134, 1.6584, 0.8740, 2.2991, 1.3330, 0.8599, 2.6248, 1.5769,\n",
      "        1.5688, 1.4044, 1.3703, 1.5584, 1.2591, 2.3186, 0.8481, 0.5552, 1.5927,\n",
      "        1.0815, 1.7553, 1.1965, 1.2680, 1.1959, 1.0482, 1.8060, 0.7459, 1.3235,\n",
      "        1.2005, 1.4368, 1.1329, 1.5069, 0.5767, 0.9341, 0.8197, 1.1502, 1.2147,\n",
      "        1.4314, 1.5016, 1.9443, 1.2069, 0.7782, 1.3619, 1.7875, 1.0783, 0.8041,\n",
      "        1.3694, 1.6926, 1.3808, 1.6208, 0.9304, 1.4440, 1.0022, 0.8060, 1.3546,\n",
      "        0.4967, 1.5241, 1.1004, 1.6666, 1.2460, 1.2273, 1.0785, 1.5158, 1.5464,\n",
      "        0.7172, 1.5999, 0.9857, 1.5277, 2.1266, 1.7796, 0.8790, 1.5807, 1.0094,\n",
      "        1.2260, 1.4662, 1.4146, 1.8302, 1.8375, 1.2964, 1.5526, 1.7926, 0.0610,\n",
      "        0.3782, 1.3549, 0.8984, 1.6022, 1.9932, 1.2256, 1.2374, 1.0921, 1.5823,\n",
      "        1.5914, 1.5905, 0.7884, 1.3899, 1.3942, 2.0313, 1.0821, 1.3931, 1.5756,\n",
      "        2.2213, 1.4199, 1.0022, 1.7426, 1.6538, 1.6370, 1.9890, 0.9225, 1.3641,\n",
      "        0.6828, 1.1672, 0.2248, 1.3269, 1.1002, 1.4717, 1.4233, 1.3847, 1.4465,\n",
      "        0.8919, 1.2393, 2.0485, 1.9369, 1.2449, 0.9876, 1.6685, 1.3735, 1.5158,\n",
      "        1.6280, 1.9292, 1.6051, 1.1241, 1.2406, 2.0611, 2.3004, 1.0591, 1.6880,\n",
      "        1.4233, 1.3395, 0.1899, 1.4873, 1.4877, 1.3247, 1.4322, 1.8506, 1.0349,\n",
      "        0.6210, 0.9483, 1.8724, 1.9432, 1.4170, 0.2343, 1.6163, 1.0943, 1.3970,\n",
      "        1.8071, 1.0701, 1.7315, 1.1458, 1.7673, 1.5998, 1.3871, 1.4614, 0.3101,\n",
      "        1.8380, 1.4018, 1.0726, 1.3775, 0.8004, 0.8222, 1.3041, 1.7732, 1.4429,\n",
      "        1.7912, 1.3470, 1.8635, 1.7452, 1.0085, 0.8436, 0.7231, 1.5418, 1.2808,\n",
      "        1.5735, 1.2318, 1.3030, 1.9056, 1.7199, 2.1175, 2.0470, 0.9454, 1.0064,\n",
      "        1.7945, 1.7072, 0.9218, 1.4515, 1.3017, 1.3996, 1.4889, 1.2331, 1.7292,\n",
      "        1.1630, 1.0804, 1.6485, 1.7540, 1.6260, 2.0469, 2.0343, 0.7833, 0.6360,\n",
      "        1.0871, 1.7807, 1.9590, 1.6735, 1.4377, 0.6790, 1.5718, 1.2617, 0.4180,\n",
      "        1.1748, 1.2373, 1.8454, 1.8480, 2.7182, 0.9940, 0.8175, 1.9213, 1.5437,\n",
      "        1.6476, 1.0537, 0.7921, 1.4872, 0.5788, 0.9774, 1.3281, 1.3732, 1.7091,\n",
      "        1.8433, 1.3877, 1.4623, 1.5900, 1.1636, 1.3694, 0.9385, 1.1073, 1.5307,\n",
      "        1.2275, 0.7828, 1.1414, 1.6472, 0.6692, 1.1580, 1.0390, 1.1262, 1.4930,\n",
      "        1.2981, 1.3421, 2.1402, 1.4329, 0.5676, 3.9635, 1.5269, 1.7112, 1.7308,\n",
      "        1.0566, 1.7190, 1.4894, 1.5257, 1.2414, 0.2835, 1.1811, 0.5680, 1.7837,\n",
      "        0.9966, 1.3419, 1.6582, 1.7837, 1.2291, 1.4353, 1.6098, 1.7571, 0.8000,\n",
      "        0.1255, 2.2421, 0.9164, 1.6395, 0.9515, 0.7966, 1.3224, 1.2241, 1.0469,\n",
      "        2.0486, 1.7084, 1.2208, 1.3276, 1.4589, 1.7920, 1.1135, 1.5971, 1.3355,\n",
      "        1.4738, 0.9956, 2.1624, 1.4134, 1.4175, 1.5338, 1.3849, 1.3696, 1.2678,\n",
      "        1.3025, 1.1351, 1.9709, 1.0130, 1.4015, 2.2416, 1.5241, 1.0874, 0.8018,\n",
      "        2.2094, 1.4113, 1.9907, 0.4101, 1.1875, 0.9430, 1.2452, 1.5826, 1.8838,\n",
      "        1.4359, 1.3115, 1.0194, 1.0782, 1.7341, 1.4971, 1.0731, 1.3280, 1.6191,\n",
      "        1.0721, 1.5716, 1.8309, 1.9467, 1.1393, 1.3729, 1.9072, 1.8975, 1.3127,\n",
      "        1.2225, 1.2217, 1.5655, 2.0898, 1.1896, 0.6853, 1.4759, 0.4634, 1.5027,\n",
      "        1.0378, 1.2067, 2.1781, 2.1304, 1.4445, 1.4080, 2.3559, 1.2088, 3.9826,\n",
      "        1.7531, 1.0353, 1.6862, 0.9790, 1.2708, 1.8216, 1.7059, 1.4627, 1.2592,\n",
      "        1.5627, 2.4224, 1.6753, 2.2553, 1.1034, 1.5561, 1.0294, 1.8389, 1.4072,\n",
      "        1.1576, 1.3762, 1.8196, 1.0981, 1.3617, 0.6952, 1.3993, 0.8077, 1.4459,\n",
      "        0.9389, 2.2123, 1.2502, 1.5858, 1.3634, 1.6295, 1.3718, 1.1816, 1.3919,\n",
      "        0.9637, 0.2313, 1.1131, 1.3282, 0.9899, 1.4403, 1.6855, 1.7599, 1.5177,\n",
      "        1.6323, 1.5868, 1.8546, 0.9567, 0.5807, 1.1935, 1.3522, 0.5770, 1.5879,\n",
      "        0.7136, 0.6040, 1.2484, 1.3289, 1.6365, 0.6353, 1.3688, 1.7865, 1.5281,\n",
      "        1.0450, 1.1437, 1.0507, 0.9471, 1.5011, 1.1395, 2.2235, 1.5795, 1.6387,\n",
      "        1.2964, 1.6782, 0.5731, 0.9984, 2.4777, 1.4844, 1.0706, 1.7497, 1.2629,\n",
      "        1.6035, 1.1001, 1.7504, 0.6976, 1.2605, 1.5747, 2.1997, 1.3942, 1.5129,\n",
      "        1.0618, 1.5679, 1.2802, 0.8615, 1.4969, 0.8737, 1.4813, 1.0792, 1.4980,\n",
      "        1.1860, 1.7892, 1.8017, 1.2859, 1.4374, 0.9354, 1.3397, 0.8537, 1.1797,\n",
      "        1.1010, 0.3094, 0.6891, 2.3797, 1.1499, 1.4246, 1.3294, 1.3661, 1.3008,\n",
      "        1.2647, 1.5657, 1.7412, 1.9196, 0.7149, 1.6910, 1.8151, 0.9021, 1.6354,\n",
      "        1.4757, 1.1099, 0.7869, 2.8609, 1.4860, 1.2577, 1.5529, 1.6148, 1.2767,\n",
      "        1.1257, 1.7185, 3.0117, 1.5490, 0.6808, 1.5897, 1.3020, 1.2704, 0.8686,\n",
      "        3.4323, 0.6850, 0.3881, 1.4575, 0.9229, 1.2487, 2.1785, 1.2795, 1.7173,\n",
      "        0.7800, 1.4806, 1.4130, 1.4175, 1.4146, 1.6619, 1.5730, 2.1019, 1.3682,\n",
      "        0.3305, 1.6860, 0.9954, 0.9363, 0.8462, 2.1381], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.3598e+00, -2.4926e+00, -9.8221e-01, -1.0272e+00, -4.8982e-01,\n",
      "        -1.0435e+00, -5.0417e-01, -1.0580e-01, -4.4153e-01, -1.5198e-01,\n",
      "        -5.4491e-01, -2.9864e-01, -1.1650e-01, -1.5260e+00, -3.2860e-01,\n",
      "        -2.6851e-01, -2.0095e+00, -6.9251e-01, -1.2741e+00, -2.2044e+00,\n",
      "        -9.1643e-01, -1.5365e+00, -1.3531e-01, -1.8024e+00, -1.0635e+00,\n",
      "        -5.5229e-01,  6.8883e-02, -2.9719e+00, -3.2780e+00, -7.5725e-01,\n",
      "        -3.9716e-01, -3.8581e-01, -6.4001e-02, -5.0869e-01, -2.7973e-01,\n",
      "         2.1606e-01, -1.1174e-01, -6.8171e-01, -9.0462e-02, -1.2587e+00,\n",
      "        -1.2347e+00, -1.4166e-02, -1.7450e+00, -1.7845e+00, -2.0461e-01,\n",
      "        -5.8954e-01, -3.2398e+00, -1.4200e-01, -2.2778e+00, -8.6252e-01,\n",
      "        -1.5872e+00, -8.3132e-01, -4.9670e-01, -4.9876e-01, -1.2558e+00,\n",
      "        -5.0961e-01, -4.5486e-01, -8.3804e-01, -7.7009e-01, -2.5217e+00,\n",
      "        -6.1256e-01, -3.4067e-01, -1.6052e-01, -9.3159e-01, -6.3955e-01,\n",
      "        -2.6215e+00, -1.0605e+00, -1.9623e-01,  2.6269e-01, -1.2769e+00,\n",
      "        -3.3302e-01, -8.8372e-01, -4.5386e-01, -1.0414e+00,  5.4621e-02,\n",
      "        -9.6537e-01, -1.0578e+00, -9.4301e-02, -1.5828e+00, -1.1361e+00,\n",
      "        -6.1715e-01, -9.4210e-01, -1.0383e+00, -1.4250e+00, -6.8557e-01,\n",
      "        -3.1796e+00, -1.4456e-01, -8.5059e-01, -5.4797e-01, -7.9660e-01,\n",
      "        -4.9578e-01, -1.0884e+00,  1.7281e-01,  8.8930e-02, -2.0895e+00,\n",
      "        -2.1419e+00, -2.0646e+00, -5.1680e-01,  8.5269e-02, -1.1280e+00,\n",
      "        -7.6752e-01, -8.8851e-01, -3.3794e-01, -1.6685e-01, -2.3131e-01,\n",
      "        -1.9219e-02, -7.4155e-01, -3.5196e-01, -2.1320e+00, -1.8852e+00,\n",
      "        -4.3904e-01, -3.7956e-01, -2.4660e-01, -5.4841e-01, -1.5011e-01,\n",
      "        -9.0415e-01, -9.4359e-01, -1.1685e+00, -5.6323e-01, -2.5220e-01,\n",
      "        -2.8522e-01, -4.5762e-02, -9.4433e-01, -1.2116e-01, -8.5671e-01,\n",
      "        -1.9434e-01, -1.6356e-01,  5.0115e-02, -1.9742e-01, -3.6225e-01,\n",
      "        -8.9067e-01,  3.2805e-01, -6.2127e-01, -7.4273e-01, -6.4390e-01,\n",
      "        -3.0496e-02, -1.6768e-01, -1.1381e+00, -1.0900e+00, -6.1826e-01,\n",
      "        -2.9697e-01, -5.2225e-01, -4.1593e-01, -2.3673e-01, -1.0640e+00,\n",
      "        -5.1753e-01,  3.2016e-01, -9.9252e-01, -2.2677e-01, -9.4320e-01,\n",
      "        -7.0484e-01, -1.5207e+00, -2.2540e+00, -7.4540e-01, -5.8339e-01,\n",
      "        -1.2654e+00, -5.4918e-01, -1.5389e+00, -8.0795e-01, -1.4218e+00,\n",
      "        -1.4550e+00, -1.8825e+00, -1.9024e-01, -6.6529e-01, -1.9463e+00,\n",
      "        -6.7970e-01, -9.4987e-01, -4.4895e-01, -3.8504e-01, -3.8523e-01,\n",
      "        -2.0421e+00, -4.0140e+00, -7.8278e-02, -6.4241e-01, -1.1553e+00,\n",
      "        -1.2787e+00, -1.7742e-01, -1.7440e+00, -7.0018e-01, -3.0380e-01,\n",
      "        -9.4191e-01, -2.3142e-01, -1.1440e-01, -6.2662e-01, -5.2734e-01,\n",
      "        -6.1063e-01, -1.0720e+00, -6.7297e-01, -9.5652e-01, -6.3486e-01,\n",
      "        -6.8219e-02, -3.8547e-01, -1.5271e+00, -3.4377e-01, -3.7506e-01,\n",
      "        -5.5814e-01, -1.0360e+00, -5.9557e-03, -3.3594e-02, -2.1811e-03,\n",
      "        -2.7325e-01, -2.2810e+00, -2.6535e-01,  7.0331e-01, -2.2058e-01,\n",
      "        -6.1106e-01, -5.9209e-01, -1.3093e+00, -2.5431e-01, -2.5302e-01,\n",
      "        -1.0807e+00, -1.8504e+00, -4.2699e-01, -5.2287e-01, -1.1028e+00,\n",
      "         6.1725e-01, -6.4924e-01,  1.4916e-01, -1.4035e+00, -2.9407e+00,\n",
      "         2.0371e-01, -2.5659e-01, -5.2028e-01, -2.3023e+00, -1.0916e+00,\n",
      "        -1.7368e+00, -1.2502e+00, -9.9665e-01, -1.1422e+00, -6.7063e-01,\n",
      "        -2.8976e-01, -9.1635e-01, -3.8943e-01, -1.2194e-01, -1.5550e+00,\n",
      "        -5.7403e-01, -5.5794e-01, -1.0861e-01, -9.4326e-01, -1.8101e+00,\n",
      "        -6.0324e-01, -2.0826e+00,  1.3983e-03, -1.1316e+00, -5.5420e-01,\n",
      "        -5.6827e-01, -3.2325e-01, -6.1136e-01, -1.8807e+00, -1.2978e+00,\n",
      "        -6.1122e-01, -1.3301e+00, -1.6406e+00, -1.3013e-01, -3.4709e-01,\n",
      "        -5.6765e-01, -1.6787e-01, -2.7609e-01, -4.9057e-01, -9.9494e-01,\n",
      "        -6.5149e-01, -9.3847e-01, -3.3103e-01, -8.6103e-01, -3.8078e-01,\n",
      "        -5.1458e-01, -1.2158e+00, -1.6034e+00,  2.1855e-01, -2.9917e-01,\n",
      "        -4.7517e-01, -8.3350e-01, -6.5556e-01, -1.7836e+00, -1.2293e-01,\n",
      "        -1.3447e+00, -2.8427e-01, -2.5673e-02, -4.5689e-01, -4.0571e-01,\n",
      "        -1.6572e+00, -2.7008e-01, -1.3278e+00, -8.1833e-01, -1.9865e+00,\n",
      "        -1.0220e+00, -1.8544e-02, -4.0031e-01, -3.0943e-01, -8.6126e-01,\n",
      "        -8.9507e-01, -2.9524e-01, -2.8083e-01, -8.5634e-01, -2.8778e-01,\n",
      "        -1.0365e+00, -1.4349e+00, -1.6201e+00, -9.2604e-01, -8.4637e-01,\n",
      "        -8.7394e-01, -3.8090e-02,  2.2858e-02, -3.5469e-01, -3.5612e-02,\n",
      "        -1.6602e+00, -2.1829e-01, -8.3192e-01, -5.0533e-01, -5.2500e-01,\n",
      "        -3.7743e-01, -4.9311e-01, -6.9942e-01, -2.3798e-01, -5.8764e-01,\n",
      "        -6.0863e-01, -3.1662e-01, -5.0805e-01, -5.1330e-01, -3.6100e-01,\n",
      "        -1.0519e-01, -1.2694e-01,  3.1868e-01, -7.2566e-01, -6.8354e-01,\n",
      "        -7.9717e-01, -2.0260e+00, -6.4027e-01, -3.3937e-01, -7.6361e-01,\n",
      "        -1.6373e+00, -6.7471e-01, -2.0050e-01, -6.5736e-01, -1.7548e+00,\n",
      "        -3.9331e-01, -7.1134e-01, -6.4137e-01, -1.1347e+00, -4.5768e-01,\n",
      "        -4.4069e-01, -6.4099e-01, -1.3309e-01, -7.4594e-01, -4.6588e-01,\n",
      "        -5.9493e-01, -4.1522e+00, -5.6050e-01,  5.7120e-01, -1.1808e+00,\n",
      "        -5.4503e-01, -1.7344e-01, -1.4943e+00, -3.8402e-01, -5.8809e-01,\n",
      "        -6.5237e-01, -8.6994e-01, -2.1116e-01, -1.1713e+00, -1.4444e-01,\n",
      "        -1.5540e+00, -6.4180e-01, -2.5317e+00, -1.1484e+00, -1.8061e+00,\n",
      "        -4.2383e-01, -2.0871e+00, -2.0344e+00,  1.6501e+00, -7.2329e-02,\n",
      "        -6.8951e-01, -6.3215e-01, -2.8279e+00, -2.0235e+00, -2.1850e+00,\n",
      "        -6.0000e-01, -4.9296e-01, -2.2321e+00,  2.0719e-01, -2.3563e+00,\n",
      "        -2.3425e-01, -9.1237e-01, -7.5594e-01, -8.4565e-01, -1.9405e-01,\n",
      "        -5.5838e-01, -6.3841e-01, -1.0792e+00, -5.1009e-01, -2.7641e-01,\n",
      "        -2.9125e+00, -2.0150e+00, -1.4353e+00, -1.3693e+00, -2.3818e-01,\n",
      "        -2.8655e-01, -1.3609e-01, -4.8445e-01, -1.0866e-01, -7.8982e-01,\n",
      "        -4.8821e-01, -1.9238e+00, -3.7308e-01, -1.2093e+00, -1.2066e+00,\n",
      "        -4.2320e-01, -5.0637e-01, -1.0296e+00, -1.6641e+00, -9.0208e-01,\n",
      "        -9.2036e-01, -1.6157e+00, -6.2309e-01, -2.9975e-01, -5.1709e-01,\n",
      "        -1.7455e+00, -1.1107e+00, -5.3341e-01, -1.8472e-01, -1.5906e+00,\n",
      "        -1.2312e+00, -5.0308e-01, -1.4823e+00, -2.4919e-01, -7.9216e-01,\n",
      "        -1.4227e-01, -1.2904e+00, -7.0046e-01, -7.2634e-01, -3.2853e-01,\n",
      "        -1.9455e+00, -6.4548e-01, -2.6843e-01, -6.5992e-01, -1.3624e+00,\n",
      "        -1.3633e+00, -4.3901e-01,  4.7369e-01, -1.0787e+00, -4.5115e-01,\n",
      "        -1.4109e+00, -1.4660e+00, -8.2888e-01, -1.1690e+00, -4.6373e-01,\n",
      "        -7.5484e-01, -8.5012e-01, -1.7582e-01, -8.8466e-01, -6.0797e-02,\n",
      "        -4.8278e-01, -7.0583e-01, -4.9948e-01, -4.4611e-01, -1.4490e-01,\n",
      "         1.3123e-01, -4.9010e-01, -3.4932e-01, -5.1748e-01, -1.4456e+00,\n",
      "         1.9902e-01, -1.3237e+00, -2.8214e-01,  1.2774e+00, -1.1246e+00,\n",
      "        -1.2526e-01, -9.4348e-01, -4.0536e-01, -4.6926e-01, -2.7657e-01,\n",
      "        -1.0414e+00, -8.4682e-01, -7.8187e-01, -1.7973e+00, -9.5624e-01,\n",
      "         3.6930e-01, -4.1163e-01, -8.0954e-01, -1.8787e+00, -2.1450e-01,\n",
      "        -6.0088e-01, -4.1367e-01, -8.9819e-01, -1.1556e+00, -4.4209e-01,\n",
      "        -8.7283e-01, -8.2639e-01, -1.7653e-01, -1.0039e+00, -1.1862e+00,\n",
      "        -4.5578e-01, -1.4939e+00, -1.8744e+00,  6.0916e-04, -1.4014e-01,\n",
      "        -6.9868e-01, -1.1131e+00, -1.7630e+00, -1.0470e+00, -1.1150e+00,\n",
      "        -2.1219e-01, -2.9230e+00, -2.4994e-01, -3.0042e-02, -3.5560e-01,\n",
      "        -5.1561e-01, -1.3531e+00, -3.8672e-01, -2.7096e-01,  2.3035e-01,\n",
      "        -2.1029e-01,  3.7815e-01, -1.3670e+00, -1.7070e-02, -2.7903e-01,\n",
      "        -2.8277e-01, -4.3181e-01, -2.3299e-01, -2.7278e-01, -6.2001e-01,\n",
      "        -6.6171e-01, -1.9982e+00, -1.2635e+00, -2.1716e+00, -4.8484e-01,\n",
      "        -8.5360e-01, -4.8723e-01, -6.0655e-01, -5.6007e-01, -5.0693e-01,\n",
      "         9.1956e-03, -9.1167e-01, -1.2975e-01, -5.1758e-01, -1.1064e+00,\n",
      "        -3.1627e-01, -2.3229e-01, -3.2089e-01, -3.4960e-01, -1.5836e+00,\n",
      "        -8.8862e-01, -7.6162e-01, -1.2270e+00,  1.4817e-02, -2.6258e-01,\n",
      "         1.2153e-01, -5.9489e-01, -1.4694e+00, -1.4816e+00, -3.4147e-01,\n",
      "        -1.9599e+00, -1.2948e+00, -1.4067e+00, -1.5558e+00,  7.8319e-02,\n",
      "        -9.9022e-02,  7.9397e-03, -1.5825e+00, -1.6376e+00, -1.0333e+00,\n",
      "         2.4998e-01, -4.1932e-01, -2.1161e-01, -3.6557e-01, -7.4468e-01,\n",
      "        -9.2362e-01, -2.5202e-01,  7.8122e-02, -1.5569e+00, -2.6895e-01,\n",
      "        -1.1575e+00, -6.0243e-01, -1.2754e-01, -2.8678e+00, -7.7522e-01,\n",
      "        -6.3511e-01, -1.4664e+00, -3.0341e+00, -7.6292e-01, -1.0381e+00,\n",
      "        -6.7674e-01, -9.0355e-01,  4.1536e-02, -6.0056e-01, -1.1773e+00,\n",
      "        -9.2195e-01, -3.8385e-01, -1.7403e+00, -7.3098e-01, -7.9736e-01,\n",
      "        -2.7616e-01, -1.3956e+00, -1.9248e+00, -8.7436e-01, -5.6972e-01,\n",
      "        -4.5077e-01, -3.1044e-01,  4.3632e-01, -5.4186e-01, -7.9641e-01,\n",
      "        -1.6137e+00, -4.4573e-01, -2.6431e+00, -1.4413e+00, -5.6264e-01,\n",
      "        -2.3624e+00, -1.3182e-01, -6.1633e-01, -1.4363e-01, -3.8424e-01,\n",
      "        -1.6995e+00, -3.4731e-01, -2.0817e+00, -6.3782e-01, -6.7236e-01,\n",
      "        -6.2884e-02, -2.7205e+00, -1.0881e+00, -5.0730e-01, -4.2510e-01,\n",
      "        -1.3273e+00,  1.6451e-01, -6.5638e-01, -4.7672e-01, -1.1357e+00,\n",
      "        -4.5183e-01, -5.9813e-01, -1.4674e+00, -1.5646e+00, -9.2314e-01,\n",
      "        -4.8015e-01, -5.7185e-01, -1.6377e+00, -8.1752e-01, -4.8075e-01,\n",
      "         2.1552e-01, -5.7620e-01, -3.6658e-01, -7.1064e-01, -1.0095e+00,\n",
      "        -5.6265e-01, -1.1268e+00, -1.3975e+00, -6.3850e-01, -1.5180e+00,\n",
      "        -1.2909e+00, -1.8553e-01, -1.2896e+00, -8.3769e-01,  2.2283e-02,\n",
      "        -9.0311e-01, -3.5120e-01, -2.3190e+00, -1.4753e+00, -1.0313e+00,\n",
      "        -6.8683e-01, -1.5039e+00, -8.6197e-01, -1.2672e+00, -1.1622e+00,\n",
      "        -8.6391e-01, -3.9476e-01, -5.3229e-01, -3.2681e-01, -9.8260e-01,\n",
      "        -1.9081e-01, -5.7636e-01, -1.7076e+00, -1.3558e+00, -2.7874e-01,\n",
      "        -3.4773e-01, -2.9066e-01, -8.5990e-01, -3.5780e-01, -8.7703e-01,\n",
      "        -6.8559e-01, -1.7867e+00, -1.8114e+00, -2.0082e+00, -4.2623e-01,\n",
      "        -1.9895e+00, -1.3073e+00, -7.8617e-01, -1.0112e+00, -3.2246e-01,\n",
      "        -7.9973e-03, -4.7389e-01, -1.9251e+00, -3.3241e-01, -1.1989e+00,\n",
      "        -1.8045e+00, -1.5979e+00, -1.2177e+00, -7.8255e-01, -6.7275e-01,\n",
      "        -2.1488e+00, -4.3161e-01, -1.8284e-01, -5.0649e-01, -1.4502e+00,\n",
      "        -9.5611e-02, -9.9739e-01, -2.1082e-01,  8.6786e-01, -6.5681e-01,\n",
      "        -8.7970e-01, -2.0032e+00,  2.3801e-01, -9.6254e-01, -1.1168e+00,\n",
      "        -7.3919e-01, -1.2851e+00, -3.7546e-01,  1.9956e-01, -1.6061e-01,\n",
      "        -3.7039e-01, -3.5413e+00, -6.0310e-01, -9.8071e-01, -1.6257e+00,\n",
      "        -7.1951e-01, -1.8186e+00, -9.6028e-02, -1.5808e+00, -4.9936e-01,\n",
      "        -4.7701e-01,  1.8877e-01, -1.4987e+00, -7.0606e-01, -1.0100e+00,\n",
      "         4.2156e-01, -1.7295e+00, -6.1088e-02, -1.1761e+00, -6.0275e-01,\n",
      "        -1.5887e+00, -4.2364e-01, -1.2522e+00, -2.3421e-01, -4.6382e-01,\n",
      "        -6.1062e-01, -7.4596e-01, -1.5509e+00,  3.1203e-01, -1.8091e+00,\n",
      "        -1.1294e+00, -1.7352e+00, -8.2876e-01, -4.2707e-01, -1.8584e+00,\n",
      "        -2.3650e+00, -3.1408e+00,  4.6326e-01, -7.6571e-01, -1.4226e-01,\n",
      "        -6.8443e-01, -9.9441e-01, -1.4109e-01, -2.5472e-01, -2.0179e+00,\n",
      "        -1.3778e-01, -5.3355e-01, -1.3259e+00, -1.0099e+00, -1.6195e+00,\n",
      "        -9.8878e-01, -5.5096e-01, -2.3364e-01, -2.0487e+00, -9.8694e-02,\n",
      "        -1.0320e+00, -8.3119e-01,  3.2969e-01, -9.9655e-01, -1.4627e+00,\n",
      "        -4.0004e-01, -1.6313e-01, -1.0909e+00, -2.0161e+00, -8.2102e-01,\n",
      "        -2.2705e+00, -1.3130e+00, -5.1080e-01, -4.9095e-01, -4.9166e-01,\n",
      "         7.7198e-01, -1.3812e+00, -1.9900e-01, -5.3646e-01, -2.9497e+00,\n",
      "        -2.0292e+00, -1.2097e-01, -9.8158e-02, -3.8654e-01, -5.6325e-02,\n",
      "        -2.9649e-01, -2.8601e-01, -1.1976e+00, -1.9504e+00, -7.3726e-01,\n",
      "        -7.9612e-01, -9.8397e-01, -1.7269e+00, -8.6237e-01,  2.0653e-02,\n",
      "        -1.3283e+00, -2.4158e-01, -1.4890e+00, -2.0067e+00, -1.4469e+00,\n",
      "        -3.4255e-02, -2.0939e+00, -3.8236e-01, -4.1843e-01, -2.3742e-01,\n",
      "        -1.0112e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0165]],\n",
      "\n",
      "         [[ 0.2257]],\n",
      "\n",
      "         [[-0.1459]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2921]],\n",
      "\n",
      "         [[ 0.1041]],\n",
      "\n",
      "         [[-0.3399]]],\n",
      "\n",
      "\n",
      "        [[[-0.0092]],\n",
      "\n",
      "         [[ 0.1319]],\n",
      "\n",
      "         [[ 0.2663]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0958]],\n",
      "\n",
      "         [[-0.3165]],\n",
      "\n",
      "         [[ 0.5180]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3413]],\n",
      "\n",
      "         [[-0.0646]],\n",
      "\n",
      "         [[ 0.2925]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1224]],\n",
      "\n",
      "         [[-0.1945]],\n",
      "\n",
      "         [[ 0.3693]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0632]],\n",
      "\n",
      "         [[-0.0631]],\n",
      "\n",
      "         [[-0.1944]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1225]],\n",
      "\n",
      "         [[-0.2003]],\n",
      "\n",
      "         [[-0.6341]]],\n",
      "\n",
      "\n",
      "        [[[-0.0009]],\n",
      "\n",
      "         [[ 0.1470]],\n",
      "\n",
      "         [[-0.1124]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0649]],\n",
      "\n",
      "         [[ 0.1590]],\n",
      "\n",
      "         [[-0.3431]]],\n",
      "\n",
      "\n",
      "        [[[-0.0499]],\n",
      "\n",
      "         [[ 0.1210]],\n",
      "\n",
      "         [[-0.3559]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0957]],\n",
      "\n",
      "         [[ 0.0086]],\n",
      "\n",
      "         [[-0.2148]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.0961,  0.2108,  0.1624,  0.0619,  0.0724,  0.0700, -0.0903,  0.0015,\n",
      "        -0.3903,  0.0746,  0.1026,  0.0928,  0.0181, -0.3658,  0.1394,  0.1126,\n",
      "         0.2294, -0.2513,  0.2210, -0.0419, -0.2487, -0.3151, -0.2417, -0.0953,\n",
      "        -0.0237, -0.0417,  0.0986,  0.2731,  0.1324, -0.2247,  0.0441,  0.1295,\n",
      "         0.1448,  0.2279], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2316]],\n",
      "\n",
      "         [[-0.3198]],\n",
      "\n",
      "         [[-0.1764]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1647]],\n",
      "\n",
      "         [[-0.1326]],\n",
      "\n",
      "         [[-0.6719]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2723]],\n",
      "\n",
      "         [[ 0.4836]],\n",
      "\n",
      "         [[ 0.0487]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4695]],\n",
      "\n",
      "         [[ 0.3383]],\n",
      "\n",
      "         [[ 0.0195]]],\n",
      "\n",
      "\n",
      "        [[[-0.0373]],\n",
      "\n",
      "         [[ 0.2093]],\n",
      "\n",
      "         [[ 0.1431]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0671]],\n",
      "\n",
      "         [[-0.2836]],\n",
      "\n",
      "         [[-0.1128]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0364]],\n",
      "\n",
      "         [[ 0.0467]],\n",
      "\n",
      "         [[ 0.0517]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1027]],\n",
      "\n",
      "         [[-0.1647]],\n",
      "\n",
      "         [[ 0.0277]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0841]],\n",
      "\n",
      "         [[-0.2638]],\n",
      "\n",
      "         [[-0.3056]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1117]],\n",
      "\n",
      "         [[ 0.1355]],\n",
      "\n",
      "         [[-0.0404]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1493]],\n",
      "\n",
      "         [[ 0.2379]],\n",
      "\n",
      "         [[ 0.1758]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4174]],\n",
      "\n",
      "         [[ 0.5065]],\n",
      "\n",
      "         [[ 0.3092]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.4950,  0.4677,  0.2786,  0.1919, -0.4764,  0.3066,  0.2655,  0.2620,\n",
      "        -0.3573, -0.0558,  0.3057, -0.1911,  0.2492, -0.0554, -0.0851, -0.3353,\n",
      "         0.1523, -0.5159,  0.3324, -0.1858, -0.1323, -0.3510, -0.3302,  0.3621,\n",
      "         0.2079,  0.1115, -0.1584,  0.0697, -0.0012,  0.3866, -0.0504, -0.4350,\n",
      "        -0.4157, -0.3029,  0.3689,  0.0457, -0.3101,  0.1478,  0.4104, -0.2712,\n",
      "        -0.0439, -0.1498, -0.0936,  0.0174, -0.3500, -0.2139, -0.1887, -0.2587,\n",
      "        -0.0714,  0.0826,  0.2746,  0.4928, -0.0526, -0.4245,  0.1231, -0.1071,\n",
      "        -0.3132,  0.1318, -0.2774, -0.0273, -0.2601, -0.0971,  0.3921,  0.4248,\n",
      "        -0.0446,  0.3738, -0.0790,  0.3415,  0.1157, -0.0289,  0.1465,  0.3205,\n",
      "         0.2723,  0.2526,  0.4112, -0.3331,  0.0306,  0.2362,  0.1583, -0.3623,\n",
      "         0.1865, -0.0359,  0.1909,  0.3711, -0.3118, -0.3141, -0.1893, -0.2465,\n",
      "        -0.3322, -0.3398,  0.3097,  0.2790,  0.4775,  0.3943,  0.0144, -0.2066,\n",
      "        -0.1280,  0.2412, -0.4242,  0.1184,  0.3647,  0.3475, -0.1979,  0.3008,\n",
      "         0.2704, -0.3655,  0.1088, -0.1705,  0.2452,  0.4428, -0.1299, -0.3525,\n",
      "        -0.1448, -0.4563,  0.3044, -0.1293,  0.2523,  0.3102, -0.3807, -0.4143,\n",
      "        -0.0535, -0.4283, -0.3144,  0.3066,  0.4957, -0.3087, -0.3571,  0.4310,\n",
      "        -0.1629, -0.2269,  0.1779, -0.3642, -0.3953,  0.3064,  0.5041,  0.4503,\n",
      "         0.1858, -0.0073,  0.3067, -0.1412, -0.1108,  0.2291, -0.3056,  0.0177,\n",
      "        -0.2197,  0.0102,  0.2909,  0.1049,  0.0171, -0.3339, -0.3209,  0.1527,\n",
      "         0.2754, -0.3556, -0.1279, -0.4570, -0.0516, -0.0427,  0.0949,  0.2970,\n",
      "        -0.4114, -0.4550, -0.2742,  0.0678, -0.4434,  0.2022,  0.1295,  0.1000,\n",
      "        -0.0772,  0.1439,  0.0831,  0.3161,  0.1661,  0.3558, -0.1021, -0.3242,\n",
      "        -0.1424, -0.1296, -0.2902, -0.2967, -0.3632,  0.4354,  0.4632, -0.4056,\n",
      "         0.3800,  0.1447, -0.2797, -0.3390, -0.0854, -0.1994,  0.0763, -0.0235,\n",
      "        -0.1352,  0.5359,  0.0550, -0.1263,  0.5373,  0.1279, -0.3694, -0.3825,\n",
      "        -0.3716,  0.1271,  0.1247, -0.3295,  0.0920, -0.4311,  0.2083, -0.2480,\n",
      "         0.1556,  0.3873,  0.2663,  0.2955,  0.0702, -0.3129,  0.1376,  0.0580,\n",
      "        -0.1080,  0.1938,  0.2420,  0.3481,  0.3864,  0.3483,  0.3029,  0.3265,\n",
      "        -0.0954, -0.1225, -0.4441, -0.2099,  0.0299, -0.4303, -0.1670,  0.0522,\n",
      "        -0.1871,  0.4047, -0.4093,  0.3650,  0.1950,  0.3284,  0.1525,  0.0556,\n",
      "        -0.3805,  0.5360, -0.3182, -0.2150,  0.0402, -0.0814, -0.1612,  0.3303,\n",
      "         0.2850, -0.2515, -0.1037,  0.2288, -0.0511, -0.5606,  0.2893, -0.3998,\n",
      "         0.2965,  0.1769,  0.0594, -0.2040, -0.3034,  0.1737,  0.4091,  0.3771,\n",
      "        -0.0060,  0.3934, -0.4094,  0.0809,  0.1900,  0.6311, -0.4098, -0.2636,\n",
      "        -0.4681, -0.4342, -0.3720, -0.3291, -0.5021,  0.3901,  0.2940, -0.1975,\n",
      "        -0.3908, -0.0592, -0.1333,  0.3275,  0.0982, -0.4291,  0.3917, -0.4314,\n",
      "        -0.1918,  0.0262,  0.1729, -0.0656,  0.0023, -0.0134, -0.3874,  0.4556,\n",
      "         0.4142,  0.0125, -0.2010, -0.3284, -0.2718,  0.2365, -0.0935, -0.1429,\n",
      "        -0.3738,  0.1016,  0.1322,  0.2934,  0.1481, -0.0602, -0.4296, -0.1798,\n",
      "         0.1881, -0.5147, -0.4452,  0.1093,  0.4485, -0.4434,  0.1885, -0.1502,\n",
      "        -0.3804,  0.0041,  0.3756, -0.3613, -0.2010,  0.3524,  0.5444, -0.0963,\n",
      "         0.1139,  0.2694, -0.2946,  0.0659, -0.2670, -0.1595, -0.0245,  0.0156,\n",
      "         0.2637, -0.2238, -0.1986,  0.2801, -0.4557, -0.3285, -0.3480, -0.0538,\n",
      "         0.0084,  0.4944, -0.0347,  0.4378, -0.2717, -0.1812, -0.2626,  0.2525,\n",
      "         0.3723, -0.1702,  0.1897,  0.3464,  0.1348, -0.3114,  0.5148,  0.2637,\n",
      "         0.3956, -0.2516, -0.2037,  0.1381,  0.1167, -0.0182, -0.1232, -0.2308,\n",
      "         0.2701, -0.5082, -0.3729, -0.2855, -0.1572, -0.1384,  0.0362,  0.1578,\n",
      "        -0.1947,  0.0048,  0.3404, -0.1692,  0.0251,  0.4655,  0.4122,  0.4087,\n",
      "         0.1351,  0.1762,  0.3888,  0.1838,  0.4126, -0.4114, -0.3676, -0.4599,\n",
      "         0.2460,  0.2474,  0.0324,  0.2638, -0.0335,  0.0627,  0.3087,  0.0665,\n",
      "         0.0763,  0.4606, -0.0577,  0.1893,  0.1825,  0.3469,  0.3122, -0.0680,\n",
      "         0.1438,  0.0732, -0.2932,  0.3065,  0.3115,  0.2712, -0.2539, -0.0040,\n",
      "         0.3093,  0.1515,  0.0035,  0.0979, -0.2473, -0.0565,  0.2831, -0.2230,\n",
      "        -0.3227, -0.1636, -0.0674, -0.2693, -0.0244, -0.0440,  0.0793,  0.3760,\n",
      "        -0.4343,  0.2965,  0.1215,  0.1910, -0.0402, -0.1402, -0.1806, -0.2439,\n",
      "        -0.0913,  0.0679,  0.0979,  0.2942, -0.0208,  0.4204,  0.3968,  0.0754,\n",
      "        -0.2401, -0.1552,  0.4174, -0.1497,  0.0967, -0.1430,  0.0097,  0.2922,\n",
      "        -0.3908,  0.0351,  0.3589,  0.0867,  0.4476,  0.1773,  0.4804,  0.0785,\n",
      "        -0.1377, -0.1611, -0.1122,  0.2352, -0.2911, -0.3798, -0.1079, -0.2676,\n",
      "         0.4444,  0.2283,  0.3326,  0.1331, -0.3132, -0.4851, -0.3335,  0.0818,\n",
      "        -0.0061,  0.1197, -0.2007, -0.4401,  0.2779,  0.1136, -0.0077,  0.0608,\n",
      "        -0.0456,  0.2538,  0.2960,  0.0413,  0.3584,  0.2027, -0.3617, -0.3658,\n",
      "        -0.0746,  0.1012, -0.5418,  0.2278, -0.2404,  0.5031,  0.0050, -0.5455,\n",
      "        -0.1277,  0.1057,  0.3984, -0.2863,  0.3924,  0.2579, -0.4577,  0.7002,\n",
      "        -0.2848,  0.1003,  0.1701, -0.0923,  0.3951,  0.1238, -0.2568, -0.1172,\n",
      "        -0.0513, -0.2501,  0.1343,  0.3665,  0.2264,  0.3764, -0.4103,  0.3925,\n",
      "        -0.3152,  0.0049,  0.4990,  0.1993, -0.3668,  0.2969,  0.0421, -0.1589,\n",
      "         0.1898,  0.1573, -0.2766, -0.4749, -0.3802, -0.3410, -0.0232,  0.4086,\n",
      "        -0.3749, -0.3706, -0.2686,  0.2230, -0.0426, -0.0186, -0.4425, -0.3465,\n",
      "         0.3822,  0.0466, -0.0731, -0.1063,  0.4978,  0.3439, -0.0747, -0.2809,\n",
      "         0.4347,  0.0406,  0.3032,  0.1918,  0.5222,  0.1830,  0.4558, -0.1644,\n",
      "        -0.2848, -0.4220,  0.1692, -0.0673,  0.0050,  0.2439, -0.4128, -0.3072,\n",
      "         0.3416,  0.0254, -0.3889, -0.0145, -0.0858,  0.1379,  0.5121, -0.3313,\n",
      "        -0.1693, -0.3426, -0.4191, -0.6191,  0.1243, -0.4258, -0.1737,  0.2597,\n",
      "        -0.1691,  0.1290, -0.0428, -0.0064,  0.4776, -0.1987,  0.0909,  0.2675,\n",
      "         0.1928, -0.0705, -0.1891,  0.3747, -0.1212,  0.0861, -0.2613, -0.2022,\n",
      "        -0.1210, -0.1321, -0.1909,  0.1363,  0.0010, -0.4059, -0.2744, -0.3715,\n",
      "         0.0407, -0.0721, -0.0349, -0.1076,  0.2453,  0.0127,  0.2007,  0.1208,\n",
      "         0.3044,  0.3246,  0.1340, -0.4372,  0.0813, -0.0635, -0.2482,  0.4044,\n",
      "         0.2444,  0.3543,  0.1960,  0.3811, -0.3229, -0.1921,  0.2836, -0.4203,\n",
      "        -0.1320,  0.0970,  0.2264,  0.1690, -0.3783,  0.4266,  0.5215, -0.3110,\n",
      "        -0.1104,  0.4949,  0.0124, -0.1618,  0.1726, -0.2220,  0.0244,  0.1916,\n",
      "         0.1314, -0.4776,  0.0129,  0.2732,  0.0967, -0.2822, -0.0528,  0.0560,\n",
      "        -0.3264,  0.0765, -0.2005,  0.0124,  0.2086,  0.5037,  0.2421, -0.1577,\n",
      "        -0.4044, -0.4688, -0.4906, -0.1712,  0.3683,  0.4238,  0.2835, -0.3268,\n",
      "         0.0433, -0.5093,  0.0912,  0.2765,  0.2544,  0.3444, -0.4255, -0.1381,\n",
      "        -0.3528, -0.2996,  0.3098, -0.1770, -0.0275,  0.0294, -0.3108,  0.1537,\n",
      "         0.0765, -0.0225, -0.2453,  0.1625,  0.0020,  0.1192, -0.1795, -0.0951,\n",
      "        -0.0685, -0.4214, -0.3946,  0.1568, -0.4479,  0.0201,  0.0730, -0.2292,\n",
      "        -0.2925, -0.2579,  0.0421, -0.3036, -0.1446, -0.4623,  0.3162,  0.2922,\n",
      "        -0.3175,  0.0009,  0.4193, -0.3284, -0.1093,  0.0917, -0.0495,  0.3112,\n",
      "        -0.3263,  0.3720,  0.4643,  0.0542, -0.2311,  0.1481,  0.5171, -0.3617,\n",
      "         0.2162,  0.3905, -0.1054,  0.4537, -0.2416,  0.2825,  0.4145,  0.0546,\n",
      "         0.3684,  0.3579,  0.5812, -0.2658,  0.4575,  0.4004,  0.1805, -0.4812,\n",
      "         0.3587, -0.3800, -0.2239,  0.0637,  0.3096, -0.4375, -0.2700,  0.3773,\n",
      "        -0.1389, -0.1961, -0.1076, -0.3676,  0.0997,  0.3421,  0.0390,  0.4192,\n",
      "         0.3291,  0.0355,  0.3257, -0.1229,  0.4480, -0.4494, -0.4765,  0.1080,\n",
      "         0.1299, -0.0854,  0.3248,  0.3749, -0.0960,  0.5121, -0.1831, -0.1469,\n",
      "        -0.3622, -0.2178, -0.3246,  0.0642,  0.1027,  0.0493,  0.4168, -0.5263,\n",
      "        -0.2199,  0.0857, -0.2919,  0.3030, -0.3388, -0.1199,  0.1006, -0.5405,\n",
      "        -0.0621, -0.2612,  0.2240, -0.4808,  0.0787, -0.1271,  0.1655, -0.2242,\n",
      "        -0.0292,  0.3579, -0.1754,  0.2771, -0.2024,  0.2332, -0.0421,  0.3657],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0270]],\n",
      "\n",
      "         [[-0.4322]],\n",
      "\n",
      "         [[ 0.1925]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3131]],\n",
      "\n",
      "         [[-0.0689]],\n",
      "\n",
      "         [[ 0.3189]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1564]],\n",
      "\n",
      "         [[ 0.0103]],\n",
      "\n",
      "         [[-0.4762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0780]],\n",
      "\n",
      "         [[-0.3330]],\n",
      "\n",
      "         [[ 0.1416]]],\n",
      "\n",
      "\n",
      "        [[[-0.3995]],\n",
      "\n",
      "         [[-0.0751]],\n",
      "\n",
      "         [[ 0.1495]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1353]],\n",
      "\n",
      "         [[-0.0545]],\n",
      "\n",
      "         [[ 0.1803]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1290]],\n",
      "\n",
      "         [[ 0.1918]],\n",
      "\n",
      "         [[-0.5109]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0477]],\n",
      "\n",
      "         [[ 0.4048]],\n",
      "\n",
      "         [[-0.0288]]],\n",
      "\n",
      "\n",
      "        [[[-0.3488]],\n",
      "\n",
      "         [[ 0.5111]],\n",
      "\n",
      "         [[ 0.3677]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0051]],\n",
      "\n",
      "         [[-0.1555]],\n",
      "\n",
      "         [[ 0.1849]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0735]],\n",
      "\n",
      "         [[ 0.0373]],\n",
      "\n",
      "         [[ 0.2231]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1527]],\n",
      "\n",
      "         [[ 0.1250]],\n",
      "\n",
      "         [[-0.1235]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 4.5011e-01,  2.4767e-01,  4.9249e-01,  4.8855e-01, -3.8320e-02,\n",
      "         1.0744e-01,  7.9595e-01,  2.2801e+00,  8.1720e-01,  2.5805e-01,\n",
      "         4.3362e-02,  7.8135e-01,  1.4947e+00, -5.9461e-03,  7.3155e-01,\n",
      "         1.9961e+00,  1.0885e-01,  5.6716e-01,  3.7158e-01,  2.0651e-01,\n",
      "         1.0198e+00,  4.2194e-01,  7.2262e-01,  1.5474e+00,  1.4501e+00,\n",
      "         1.3194e+00,  2.1543e-01,  9.0874e-03,  1.3348e-01,  4.8049e-01,\n",
      "         3.0237e-01,  5.4883e-02,  1.2757e+00,  5.1831e-01,  1.1856e+00,\n",
      "         6.5644e-02,  9.7591e-02,  8.9707e-01,  5.8166e-01,  7.4611e-01,\n",
      "         1.6878e+00,  6.2483e-01, -2.5964e-03,  2.7862e-01,  2.0912e-01,\n",
      "         1.2533e+00,  9.6156e-01,  1.6500e+00,  4.6354e-01,  1.0323e+00,\n",
      "         2.7566e+00,  3.0865e-01,  4.2426e-01, -3.6518e-02,  6.3000e-01,\n",
      "        -2.7889e-02,  3.5428e-01,  5.2169e-01,  1.8057e+00,  3.1787e-01,\n",
      "         6.9442e-01,  4.6489e-01,  1.9187e-02,  1.3723e+00,  2.0616e-02,\n",
      "         4.6133e-01,  2.1024e-01,  5.2582e-01,  1.0856e+00,  4.9626e-02,\n",
      "         1.1869e+00,  1.6431e+00,  1.6889e+00,  7.1863e-01,  1.1145e+00,\n",
      "         2.5730e-01,  1.0186e+00,  1.8416e+00,  6.2236e-01,  1.6519e-01,\n",
      "         8.0673e-02,  5.7404e-02,  7.3587e-01,  6.1627e-01,  1.9380e-01,\n",
      "         2.9450e-01,  8.4837e-01,  8.5820e-02,  7.8193e-01,  2.2683e-01,\n",
      "         1.2586e+00,  1.2987e+00,  1.4292e+00,  9.0918e-01,  2.0930e-01,\n",
      "         1.3166e+00,  4.4716e-03,  1.2069e-01,  5.9571e-01,  5.4878e-03,\n",
      "         1.9004e+00,  1.1012e-01,  3.7939e-01,  6.4806e-01,  8.1784e-01,\n",
      "         3.9568e-01,  9.1638e-01,  1.4627e+00,  5.2621e-01, -3.7819e-02,\n",
      "         1.7926e+00,  1.2550e+00,  9.4100e-01,  7.1517e-01,  1.7848e-01,\n",
      "         9.1158e-01,  6.3169e-01,  1.4908e+00,  6.9431e-01,  6.0606e-01,\n",
      "         5.9102e-01,  6.8344e-01,  9.1219e-01,  1.1973e+00,  1.0152e+00,\n",
      "         7.4897e-01,  1.0892e+00, -4.1840e-02,  6.7422e-01,  4.8229e-01,\n",
      "         8.5352e-01,  1.2193e+00,  5.3824e-02,  1.4742e+00,  1.9349e+00,\n",
      "         5.7552e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-2.9729e-01,  3.5248e-02, -1.0028e-01,  1.7586e-01,  2.7354e-01,\n",
      "        -6.9224e-03, -3.0029e-01, -6.2253e-01, -1.7277e-01,  5.1664e-01,\n",
      "         2.0355e-01,  3.8534e-01, -4.5753e-01, -2.7328e-01,  1.2386e-02,\n",
      "         5.5892e-01,  2.5329e-01,  1.8550e-01, -6.2350e-01,  1.4309e-01,\n",
      "        -1.2741e-01, -1.0260e-01, -2.5874e-01,  2.0578e-01,  1.0123e-02,\n",
      "         5.7837e-01, -3.8735e-02,  5.1979e-02,  2.4088e-01, -6.5356e-02,\n",
      "         4.3172e-01,  2.3035e-01,  2.5216e-01, -2.9742e-01,  7.9666e-02,\n",
      "        -2.4222e-01,  2.0997e-01, -1.1528e-01, -3.9787e-01, -1.8922e-01,\n",
      "         1.4575e-01, -1.2272e-01,  6.2039e-02, -8.0696e-02, -3.3808e-01,\n",
      "         5.6784e-01,  4.5018e-01,  2.6858e-01, -7.5788e-02,  1.2016e-01,\n",
      "         5.6755e-04,  6.0777e-02,  2.8249e-01, -9.4733e-02,  2.1248e-02,\n",
      "         1.1418e-01,  1.0907e-01, -3.6238e-03, -1.5934e-01,  4.1794e-01,\n",
      "         4.7769e-02, -3.0243e-01,  1.0082e-01, -2.6974e-01,  1.5344e-02,\n",
      "        -6.7701e-02, -1.6999e-02,  9.9004e-02,  2.9156e-01, -3.0548e-01,\n",
      "        -3.3699e-01, -1.1515e-01,  6.7616e-01, -1.4162e-01,  1.4626e-01,\n",
      "        -8.9183e-02, -2.7985e-01, -1.9547e-01, -2.5757e-01, -2.4224e-01,\n",
      "        -2.7106e-02, -2.1373e-02,  1.6201e-01,  1.3165e-01, -1.9519e-01,\n",
      "        -1.9739e-01,  1.9373e-01, -1.7341e-01,  1.7313e-01,  2.7114e-01,\n",
      "         1.1386e-01, -9.3038e-02, -4.0035e-01,  2.9957e-01, -1.5399e-01,\n",
      "        -2.9928e-01, -1.8421e-01,  1.9587e-01, -4.8510e-01,  1.2254e-01,\n",
      "         1.5194e-01,  6.0122e-02, -4.6943e-02, -1.7794e-02,  1.3100e-01,\n",
      "        -2.2828e-01, -4.8675e-02, -2.2881e-02, -3.0409e-01,  2.3360e-01,\n",
      "        -2.3271e-01,  8.1022e-02,  4.3929e-02,  1.4582e-01,  9.6873e-02,\n",
      "         1.9674e-01, -4.2828e-01, -3.1130e-01, -1.1887e-01,  1.4480e-01,\n",
      "         1.8768e-01,  3.0338e-01,  2.5202e-02, -2.4988e-01, -6.6563e-02,\n",
      "        -6.7053e-03, -1.5924e-01,  4.0975e-02,  4.2456e-01, -1.0918e-02,\n",
      "        -3.8551e-02, -5.4050e-01,  8.3561e-02,  4.0451e-01,  5.3253e-01,\n",
      "        -1.6804e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2952]],\n",
      "\n",
      "         [[ 0.5389]],\n",
      "\n",
      "         [[-0.0252]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2491]],\n",
      "\n",
      "         [[ 0.3659]],\n",
      "\n",
      "         [[-0.0430]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0024]],\n",
      "\n",
      "         [[ 0.2328]],\n",
      "\n",
      "         [[-0.8486]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0055]],\n",
      "\n",
      "         [[-0.2327]],\n",
      "\n",
      "         [[-0.4243]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0731]],\n",
      "\n",
      "         [[ 0.1158]],\n",
      "\n",
      "         [[ 0.4392]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0917]],\n",
      "\n",
      "         [[ 0.0956]],\n",
      "\n",
      "         [[ 0.0624]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3102]],\n",
      "\n",
      "         [[-0.2387]],\n",
      "\n",
      "         [[ 0.4025]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4233]],\n",
      "\n",
      "         [[ 0.2925]],\n",
      "\n",
      "         [[ 0.6895]]],\n",
      "\n",
      "\n",
      "        [[[-0.2783]],\n",
      "\n",
      "         [[ 0.4824]],\n",
      "\n",
      "         [[-0.4505]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1989]],\n",
      "\n",
      "         [[ 0.0569]],\n",
      "\n",
      "         [[-0.4589]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4463]],\n",
      "\n",
      "         [[-0.2665]],\n",
      "\n",
      "         [[-0.3807]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2415]],\n",
      "\n",
      "         [[-0.2632]],\n",
      "\n",
      "         [[-0.0503]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.4081e+00,  3.6847e-01,  1.2946e+00,  7.7268e-01,  1.1007e+00,\n",
      "         1.0648e+00, -1.5231e+00,  1.0924e+00,  9.2311e-01,  1.0839e+00,\n",
      "         9.3334e-01,  1.1857e+00,  6.9961e-01,  1.4288e+00,  1.3041e+00,\n",
      "         1.1787e+00,  1.1219e+00,  1.3777e+00,  1.7840e-01,  1.1963e+00,\n",
      "         1.2081e+00,  1.0755e+00,  1.0592e+00,  8.0327e-01,  9.8694e-01,\n",
      "         2.1899e+00,  8.3518e-01,  1.0350e+00,  1.2003e+00,  9.3052e-01,\n",
      "         6.0741e-01,  1.1698e+00,  9.8720e-01,  1.3818e+00,  1.1166e+00,\n",
      "         9.5394e-01,  3.8944e-01,  4.6324e-01,  1.4554e+00,  1.2336e+00,\n",
      "         1.3386e+00,  3.3411e-01,  1.1089e+00,  1.2297e+00,  1.4666e+00,\n",
      "         1.2931e+00,  1.1003e+00,  1.0495e+00,  8.3182e-01,  1.5331e+00,\n",
      "         8.8822e-01,  1.2151e+00,  7.0541e-01,  1.6406e+00,  1.0713e+00,\n",
      "         1.1035e+00,  9.0025e-01,  1.2019e+00,  1.0645e+00,  1.2309e+00,\n",
      "         1.0567e+00,  1.6750e+00,  1.1032e+00,  1.0161e+00,  1.1548e+00,\n",
      "         1.4034e+00, -1.3554e-03,  1.2246e+00,  4.0678e-01,  1.0674e+00,\n",
      "         1.0840e+00,  1.0953e+00,  1.2810e+00,  9.3338e-02,  8.4660e-01,\n",
      "         1.1656e+00,  1.1941e+00,  1.2151e+00,  1.3125e+00,  2.6227e+00,\n",
      "         1.1984e+00,  1.1688e+00,  9.3681e-01,  1.1586e+00,  9.5094e-01,\n",
      "         1.2259e+00,  1.0876e+00,  1.3606e+00,  6.3046e-01,  1.8342e+00,\n",
      "         1.1152e+00,  5.3410e-01,  1.2835e+00,  1.0331e+00,  1.0930e+00,\n",
      "         1.2441e+00,  1.4986e+00,  1.3104e+00,  9.5952e-01,  1.2462e+00,\n",
      "         9.7563e-01,  1.1751e+00,  1.2042e+00,  1.0090e+00,  1.2358e+00,\n",
      "         2.0618e+00,  1.0689e+00,  1.0603e+00,  1.5091e+00,  1.5187e+00,\n",
      "         1.3222e+00, -9.4574e-02,  9.6254e-01,  2.0440e+00,  9.6559e-01,\n",
      "         1.2073e+00,  1.1608e+00,  1.2539e+00,  1.2097e+00,  1.2438e+00,\n",
      "         2.4588e+00,  1.4346e+00,  1.2467e+00,  1.5656e+00,  1.1711e+00,\n",
      "         1.0381e+00,  1.1226e+00,  6.1994e-01,  1.1753e+00,  1.8629e-01,\n",
      "         1.0348e+00,  4.1959e-01,  1.6507e+00,  2.6446e-01,  1.2247e+00,\n",
      "         1.3687e+00,  1.2369e+00,  1.8791e+00,  1.7056e+00,  1.9242e+00,\n",
      "         1.8647e+00,  1.1725e+00,  1.2657e+00,  1.1833e+00,  9.5730e-01,\n",
      "         1.1021e+00,  8.3071e-01,  1.1109e+00,  2.2277e+00,  1.5886e+00,\n",
      "         2.6495e-01,  1.0394e+00,  1.3258e+00,  1.2396e+00,  1.1189e+00,\n",
      "         1.1540e+00,  1.2852e+00,  1.0300e+00,  1.3561e+00,  1.2593e+00,\n",
      "         1.0802e+00,  1.5132e+00,  1.4396e+00,  1.2934e+00,  2.1338e+00,\n",
      "         1.7387e+00,  1.2703e+00,  9.9287e-01,  1.2941e+00,  1.1861e+00,\n",
      "         8.0983e-01,  4.9073e-01,  1.3671e+00,  1.8843e+00,  1.0634e+00,\n",
      "         1.2386e+00,  1.0717e+00,  1.1273e+00,  1.5781e+00,  2.0566e+00,\n",
      "         1.2245e+00,  9.0576e-01,  1.0660e+00,  1.5331e+00,  1.1763e+00,\n",
      "         1.1209e+00,  3.4851e-01,  9.9190e-01,  9.9505e-01,  1.2527e+00,\n",
      "         1.3381e+00,  1.0622e+00,  9.9921e-01,  1.2683e+00,  1.1359e+00,\n",
      "         1.0945e+00,  1.1856e+00,  1.2780e+00,  1.5284e+00,  9.7196e-01,\n",
      "         1.1603e+00,  4.5412e-01,  1.0643e+00,  2.4454e+00,  1.2034e+00,\n",
      "         1.5184e+00,  1.1144e+00,  1.1694e+00,  1.2184e+00,  1.4596e+00,\n",
      "         1.1674e+00,  1.0560e+00,  1.1228e+00,  1.7141e+00,  1.3064e+00,\n",
      "         1.1489e+00,  1.0737e+00,  1.0306e+00,  1.0785e+00,  1.2801e+00,\n",
      "         1.0341e+00,  8.7730e-01,  1.4151e+00,  1.1453e+00,  2.9763e+00,\n",
      "         1.2472e+00,  1.2338e+00,  9.2858e-01,  1.4652e+00,  1.2017e+00,\n",
      "         1.1318e+00,  1.1863e+00,  1.2205e+00,  1.0214e+00,  1.1857e+00,\n",
      "         1.0787e+00,  1.0761e+00,  1.5281e+00,  1.2993e+00,  9.9029e-01,\n",
      "         1.2189e+00,  1.1367e+00,  1.3323e+00,  1.2387e+00,  2.4507e-01,\n",
      "         1.5922e+00,  9.5321e-01, -1.2013e+00,  1.4946e+00,  1.0750e+00,\n",
      "         1.1995e+00,  1.2504e+00,  9.6455e-01,  1.1514e+00,  1.1725e+00,\n",
      "         1.4443e+00,  1.0876e+00,  1.0399e+00,  1.2439e+00,  2.1596e-01,\n",
      "         2.8325e+00,  1.1540e+00,  1.3990e+00,  1.0634e+00,  1.3944e+00,\n",
      "         9.9605e-01,  1.6322e+00,  9.0483e-01,  1.2655e+00,  1.0615e+00,\n",
      "         9.8610e-01,  1.1304e+00,  9.3544e-01,  2.9105e-01,  1.2249e+00,\n",
      "         7.3876e-01,  1.1786e+00,  1.1535e+00,  2.4329e+00,  3.3406e-01,\n",
      "        -1.4830e-01,  1.0134e+00,  1.3054e+00,  5.7212e-01,  1.1403e+00,\n",
      "         1.1485e+00,  1.2279e+00,  1.3227e+00,  1.1371e+00,  1.0744e+00,\n",
      "         1.3844e+00,  1.2106e+00,  1.2358e+00,  4.8890e-03,  2.1374e-01,\n",
      "         1.3412e+00,  9.9424e-01,  1.1968e+00,  1.1061e+00,  1.1775e+00,\n",
      "         1.7043e+00,  1.1488e+00,  1.4638e+00,  9.6337e-01,  1.2730e+00,\n",
      "         1.2402e+00,  1.1253e+00,  6.5265e-01,  9.1104e-01,  1.2326e+00,\n",
      "         1.1930e+00,  1.8487e-01,  7.4315e-01,  1.2187e+00,  1.0558e+00,\n",
      "         2.3086e+00,  1.3346e+00,  2.1922e+00,  1.3399e+00,  7.6682e-01,\n",
      "         1.1268e+00,  9.6378e-01,  9.7802e-01,  1.8223e+00,  8.0295e-01,\n",
      "         9.5114e-01,  1.3833e+00,  1.0709e+00,  2.5598e-01,  8.6493e-01,\n",
      "         2.7847e+00,  9.7941e-01,  4.7951e-01,  3.1233e-01,  1.0729e+00,\n",
      "         9.9028e-01,  1.0335e+00,  1.1165e+00,  1.7459e+00,  1.1519e+00,\n",
      "         9.7915e-01,  1.0753e+00,  2.4300e+00,  1.2061e+00,  1.1032e+00,\n",
      "         2.2532e+00,  1.2625e+00,  1.2852e+00,  1.1278e+00,  9.6278e-01,\n",
      "         7.4321e-01,  9.9609e-01,  1.0695e+00,  9.2671e-01,  1.2110e+00,\n",
      "         9.9609e-01,  1.0689e+00,  1.1781e+00,  2.6159e+00,  1.0353e+00,\n",
      "         1.0067e+00,  1.2244e+00,  1.8942e+00,  7.2337e-01,  1.4350e+00,\n",
      "         1.1165e+00,  1.1631e+00,  1.0485e+00,  9.5115e-01,  1.0099e+00,\n",
      "         3.1136e+00,  1.1198e+00,  1.2519e+00,  1.0887e+00,  3.6372e-01,\n",
      "         4.0982e-01,  1.0632e+00,  1.7068e+00,  1.9990e+00,  1.1047e+00,\n",
      "         1.2035e+00,  1.2304e+00,  1.0592e+00,  1.1054e+00,  1.2332e+00,\n",
      "         1.3385e+00,  1.3543e+00,  1.0354e+00,  5.9752e-01,  1.1113e+00,\n",
      "         1.3452e+00,  1.2521e+00,  1.5210e+00,  8.8374e-01,  1.0547e+00,\n",
      "         9.9032e-01,  1.1781e+00,  1.9460e+00,  1.3219e+00,  1.0933e+00,\n",
      "         3.2314e-01,  1.3501e+00,  3.4691e-01,  1.1406e+00,  1.2018e+00,\n",
      "         1.0013e+00,  1.4029e+00,  2.3519e+00,  1.1936e+00,  1.9868e+00,\n",
      "         1.0646e+00,  9.7023e-01,  1.1277e+00,  5.9305e-01,  1.1143e+00,\n",
      "         1.0229e+00,  2.2476e+00,  8.2671e-01,  1.6853e+00,  1.8940e+00,\n",
      "         1.9532e+00,  1.1460e+00,  5.0777e-01,  1.0218e+00,  1.4422e+00,\n",
      "         1.4323e+00,  1.0734e+00,  1.0254e+00,  1.0600e+00,  2.2428e+00,\n",
      "         1.0411e+00,  1.2563e+00,  2.9528e-01, -4.7604e-01,  1.6596e+00,\n",
      "         1.7730e+00,  9.7142e-01,  1.5568e+00,  1.3534e+00,  2.5989e+00,\n",
      "         2.1436e-01,  2.5878e+00,  1.3286e+00,  1.1868e+00,  5.2013e-01,\n",
      "         1.0307e+00,  1.6593e+00,  1.1887e+00,  1.0420e+00,  1.0600e+00,\n",
      "         1.7600e+00,  4.8619e-01,  1.1707e+00,  1.4570e+00,  6.3501e-01,\n",
      "         1.7926e+00,  1.2510e+00,  1.1227e+00,  1.0568e+00,  1.2066e+00,\n",
      "         8.9097e-01,  8.6064e-01,  1.0627e+00,  1.5778e+00,  9.7094e-01,\n",
      "         1.1229e+00,  1.4649e+00,  1.0824e+00,  1.3391e+00,  1.2387e+00,\n",
      "         1.1106e+00,  8.5569e-01,  1.0654e+00,  1.0097e+00,  1.0956e+00,\n",
      "         1.1595e+00,  1.5405e+00,  1.1377e+00,  1.3551e+00, -1.0686e+00,\n",
      "         1.3971e+00,  6.0322e-01,  1.0164e+00,  1.2139e+00,  1.4515e+00,\n",
      "         1.2065e+00,  1.2772e+00,  1.1404e+00,  1.0492e+00,  5.5288e-01,\n",
      "         1.5994e+00,  1.3715e+00,  1.1704e+00,  1.1666e+00,  4.4885e-01,\n",
      "         4.4062e-01,  1.2579e+00,  1.3794e+00,  1.1012e+00,  6.4985e-01,\n",
      "         1.3977e+00,  1.1658e+00,  2.2233e+00,  1.7002e+00,  1.1334e+00,\n",
      "         1.0695e+00,  1.1382e+00,  1.4205e+00,  1.0747e+00,  9.1383e-01,\n",
      "         1.1004e+00,  9.7027e-01,  1.1826e+00,  2.2790e+00,  1.4004e+00,\n",
      "         1.1645e+00,  9.3085e-01,  9.8903e-01,  1.1207e+00,  1.7005e+00,\n",
      "         9.6578e-01,  8.2335e-01,  1.0252e+00,  1.2660e+00,  9.3296e-01,\n",
      "         8.6061e-01,  1.1150e+00,  1.3430e+00,  1.2840e+00,  1.3115e+00,\n",
      "         1.1603e+00,  1.7332e+00,  1.1758e+00,  1.1414e+00,  1.0760e+00,\n",
      "         7.5825e-01,  3.3442e-01,  1.1354e+00,  9.9990e-01,  1.1367e+00,\n",
      "         1.1542e+00,  9.1167e-01,  1.6725e+00,  1.0152e+00,  8.9777e-01,\n",
      "         1.1081e+00,  1.0480e+00,  1.1377e+00,  1.9194e+00,  1.4322e+00,\n",
      "         1.1240e+00,  1.2864e+00,  1.0613e+00,  1.0809e+00,  1.1788e+00,\n",
      "         1.1388e+00,  1.1653e+00,  1.0341e+00,  2.8459e-01,  1.2151e+00,\n",
      "         1.0887e+00,  1.1674e+00,  1.1967e+00,  1.3215e+00,  1.4336e+00,\n",
      "         1.0311e+00,  1.3599e+00,  3.3907e-01,  1.1678e+00,  9.6039e-01,\n",
      "         1.2518e+00,  1.1879e+00,  1.0729e+00,  1.4899e+00,  8.8592e-01,\n",
      "         1.0942e+00,  1.0885e+00,  1.3133e+00,  1.2311e+00,  2.5351e+00,\n",
      "         6.6687e-01,  1.3244e+00,  1.1069e+00,  1.2691e+00,  1.1312e+00,\n",
      "         1.1081e+00,  1.3840e+00,  7.7498e-01,  1.0269e+00,  1.4476e+00,\n",
      "         1.5316e+00,  2.4681e-01,  2.2385e+00,  4.7561e-01,  1.0722e+00,\n",
      "         1.0862e+00,  1.1445e+00,  9.6960e-01,  1.0108e+00,  1.1030e+00,\n",
      "         1.4097e+00,  1.0009e+00,  1.5987e+00,  2.0400e+00,  1.1682e+00,\n",
      "         1.1587e+00,  9.7030e-01,  1.0851e+00,  1.2474e+00,  1.0204e+00,\n",
      "         8.0083e-01,  1.2041e+00,  1.0941e+00,  1.3157e+00,  4.5868e-01,\n",
      "         1.0460e+00,  1.2047e+00,  1.4670e+00,  1.1703e+00,  1.0060e+00,\n",
      "         4.7929e-01,  1.1635e+00,  1.1660e+00,  1.2215e+00,  9.7623e-01,\n",
      "         1.2410e+00,  1.1810e+00,  1.0647e+00,  1.5769e+00,  1.0379e+00,\n",
      "         2.6942e-01,  1.1016e+00,  1.7173e+00,  1.3429e+00,  1.5014e+00,\n",
      "         1.3746e+00,  7.7039e-01,  5.8114e-01,  9.8930e-01,  1.1004e+00,\n",
      "         1.5081e+00,  1.1535e+00,  2.6227e+00,  9.7420e-01,  1.4122e+00,\n",
      "         2.3106e+00,  6.1589e-01,  1.0708e+00,  3.8811e+00,  8.0589e-01,\n",
      "         1.2987e+00,  1.3644e+00,  9.9864e-01,  7.7125e-01,  1.4276e+00,\n",
      "         1.5457e+00,  9.5677e-01,  1.3493e+00,  1.4747e+00,  1.1965e+00,\n",
      "         1.2095e+00,  1.1317e+00,  1.0159e+00,  1.0436e+00,  8.1649e-01,\n",
      "         3.7126e-01,  1.2992e+00,  1.1439e+00,  1.1824e+00,  1.1343e+00,\n",
      "         1.2565e+00,  9.2577e-01,  3.6397e-01,  1.1324e+00,  6.1823e-01,\n",
      "         1.1947e+00,  1.0643e+00,  1.1101e+00,  1.3974e+00,  1.1391e+00,\n",
      "         9.2187e-01,  1.3655e+00,  1.3088e+00,  1.5171e+00,  9.0379e-01,\n",
      "         1.0723e+00,  1.1661e+00,  1.2752e+00,  9.6394e-01,  1.5824e+00,\n",
      "         1.1328e+00,  2.1756e+00,  1.4461e+00,  1.3196e+00,  1.3016e+00,\n",
      "         2.4502e+00,  1.8087e+00,  1.1207e+00,  1.0654e+00,  1.0659e+00,\n",
      "         1.1852e+00,  1.0652e+00,  1.7194e+00,  5.1840e-01,  9.3373e-01,\n",
      "         6.8826e-01,  1.0870e+00,  8.1770e-01,  9.6500e-01,  2.1662e+00,\n",
      "         7.8875e-01,  9.6272e-01,  9.8203e-01,  1.1920e+00,  1.0138e+00,\n",
      "         1.3701e+00,  1.1669e+00,  1.2411e+00,  1.0124e+00,  1.1746e+00,\n",
      "         2.2277e+00,  1.1130e+00,  2.4394e+00,  1.1881e+00,  1.1768e+00,\n",
      "         1.0651e+00,  1.1301e+00,  1.5347e+00,  1.2497e+00,  9.5357e-01,\n",
      "         8.7974e-01,  1.4371e+00,  2.0917e-01,  1.1106e+00,  1.0937e+00,\n",
      "         1.0699e+00,  1.0804e+00,  9.2484e-01,  1.2919e+00,  2.0256e+00,\n",
      "         1.7367e+00,  1.2239e+00,  1.2252e+00,  1.1372e+00,  1.2620e+00,\n",
      "         1.3903e+00,  3.1677e-01,  1.1868e+00,  1.1672e+00,  1.0110e+00,\n",
      "         1.3474e+00,  1.5283e+00,  1.4352e+00,  4.3453e-01,  8.8454e-01,\n",
      "         1.7280e+00,  9.7662e-01,  1.1291e+00,  1.1675e+00,  1.0926e+00,\n",
      "         1.2149e+00,  2.3091e-01,  1.0485e+00,  1.1540e+00,  1.1426e+00,\n",
      "         1.2808e+00,  9.8465e-01,  1.0489e+00,  9.3219e-01,  1.2280e+00,\n",
      "         1.0651e+00,  2.7399e+00,  9.9553e-01,  1.1969e+00,  1.4711e+00,\n",
      "         1.2363e+00,  1.7037e+00,  7.7773e-07,  8.6637e-01,  1.4792e+00,\n",
      "         2.1595e+00,  1.1688e+00,  2.3395e+00,  1.1912e+00,  1.1626e+00,\n",
      "         1.2206e+00,  1.1206e+00,  9.1469e-01,  1.2160e+00,  1.1240e+00,\n",
      "         1.2845e+00,  2.6224e+00,  1.1095e+00,  2.0514e+00,  9.8260e-01,\n",
      "         1.0965e+00,  1.3798e+00,  1.2009e+00,  1.2515e+00,  1.1091e+00,\n",
      "         8.8686e-01,  1.2652e+00,  1.2190e+00,  1.1088e+00,  1.1176e+00,\n",
      "         1.1509e+00,  1.2889e+00,  1.0679e+00,  4.5509e-01,  1.0974e+00,\n",
      "         2.0008e+00,  9.8668e-01,  1.2507e+00,  9.6303e-01,  1.3069e+00,\n",
      "         1.4682e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.1147e+00,  4.3556e+00, -1.9055e+00,  1.2227e+00, -1.8222e+00,\n",
      "        -1.8030e+00, -9.7608e-01, -1.8347e+00, -8.5876e-01, -2.1728e+00,\n",
      "        -1.7335e+00, -2.0084e+00, -7.1520e-02, -1.8831e+00, -1.1081e+00,\n",
      "        -1.5533e+00, -1.8816e+00, -1.8827e+00, -8.3256e-01, -1.4206e+00,\n",
      "        -1.7156e+00, -2.0080e+00, -2.2861e+00,  2.1953e+00, -2.0374e+00,\n",
      "        -8.4164e-01, -8.4801e-01, -1.7428e+00, -1.6999e+00, -1.7038e+00,\n",
      "         7.2121e-01, -1.9753e+00, -1.5670e+00, -1.5886e+00, -1.8601e+00,\n",
      "        -2.3634e+00,  1.8226e-01, -4.8541e-01, -1.1990e+00, -1.4111e+00,\n",
      "        -1.4062e+00,  5.1585e-02, -1.8756e+00, -1.8526e+00, -1.3620e+00,\n",
      "        -1.4324e+00, -2.5268e+00, -1.5522e+00, -1.5614e+00, -1.4962e+00,\n",
      "        -5.1231e-01, -2.5890e+00, -6.5974e-01, -5.9762e-01, -1.8366e+00,\n",
      "        -2.0836e+00, -1.2839e+00, -1.7885e+00, -1.4500e+00, -1.7309e+00,\n",
      "        -1.8648e+00, -1.0829e+00, -2.1228e+00, -2.3675e+00, -1.9292e+00,\n",
      "        -2.9990e+00, -6.8082e-03, -1.7844e+00, -1.3177e-01, -1.6236e+00,\n",
      "        -1.9381e+00, -2.4365e+00, -1.4414e+00,  3.2563e-02, -1.5738e+00,\n",
      "         4.2724e-01, -1.7449e+00, -1.7827e+00,  1.1328e-01, -9.4874e-01,\n",
      "        -2.8525e+00, -2.2167e+00, -1.4006e+00, -1.9698e+00, -2.0161e+00,\n",
      "        -1.8918e+00, -1.8546e+00, -2.0016e+00, -6.8131e-01, -1.8093e+00,\n",
      "         2.3128e-01,  8.6732e-01, -1.8133e+00, -2.0301e+00, -1.9110e+00,\n",
      "        -1.9890e+00, -8.2468e-01, -2.2098e+00, -1.5736e+00,  9.1326e-01,\n",
      "        -2.2103e+00, -1.5589e+00, -1.5978e+00, -1.8671e+00, -1.5420e+00,\n",
      "        -1.0074e+00, -1.4263e+00, -1.9784e+00, -1.8003e+00, -7.4525e-01,\n",
      "        -9.6906e-01, -4.3347e-02, -2.0276e+00, -1.4570e+00, -1.4343e+00,\n",
      "        -1.5535e+00, -1.6025e+00, -1.9938e+00, -2.6745e+00, -1.7629e+00,\n",
      "        -1.3129e+00, -1.7221e+00, -1.6761e+00, -2.0269e+00, -1.8610e+00,\n",
      "        -1.6402e+00, -1.7756e+00,  7.9226e-01, -1.6502e+00,  3.8601e-01,\n",
      "        -1.8880e+00,  2.3941e-01, -1.2330e+00, -4.4473e-01, -1.1500e-01,\n",
      "         1.6165e+00, -1.3677e+00, -6.3280e-01, -9.0068e-01, -1.6124e+00,\n",
      "         1.3662e-01, -1.5745e+00, -1.7844e+00, -1.8484e+00, -1.4419e+00,\n",
      "        -1.7288e+00,  7.9893e-01, -1.5849e+00, -6.2164e-01,  1.2279e+00,\n",
      "         5.0684e-01, -1.9873e+00, -1.0682e+00, -1.8556e+00, -1.4388e+00,\n",
      "        -9.2706e-01, -1.4753e+00, -1.8988e+00, -7.6121e-01, -1.9751e+00,\n",
      "        -2.1627e+00, -1.1001e+00, -1.8560e+00, -1.2993e+00,  1.3892e-01,\n",
      "         7.5148e-01, -1.4686e+00, -1.6070e+00, -2.1481e+00, -2.4850e+00,\n",
      "        -2.5814e-01, -9.0351e-02, -1.9899e+00,  1.4070e+00, -1.5197e+00,\n",
      "        -1.6890e+00, -2.1437e+00, -1.2861e+00, -1.1788e+00, -8.6670e-01,\n",
      "        -2.4373e+00, -2.0206e+00, -1.6251e+00, -1.4811e+00, -2.0662e+00,\n",
      "        -2.7552e+00,  3.9911e-01, -1.2455e+00, -1.9811e+00, -1.5953e+00,\n",
      "        -1.4642e+00, -1.7397e+00, -1.7449e+00, -2.8080e+00, -1.6780e+00,\n",
      "        -2.0839e+00, -1.4892e+00, -1.5216e+00, -1.1516e+00, -1.8915e+00,\n",
      "        -2.2537e+00, -9.7436e-02, -1.7888e+00,  4.2988e-01, -1.7477e+00,\n",
      "        -6.1321e-01, -2.1919e+00, -1.4342e+00, -1.8114e+00, -1.5486e+00,\n",
      "        -1.7812e+00, -2.1109e+00, -1.6164e+00,  7.6851e-01,  1.1484e+00,\n",
      "        -1.7282e+00, -1.0309e+00, -1.8709e+00, -1.6656e+00, -8.1543e-01,\n",
      "        -1.9870e+00, -1.6327e+00,  1.0877e+00, -1.8303e+00, -5.0252e-01,\n",
      "        -1.5998e+00, -1.9291e+00, -2.2440e+00, -2.3563e+00, -1.6707e+00,\n",
      "        -1.8129e+00,  9.9707e-01, -1.8159e+00, -1.5116e+00, -1.9612e+00,\n",
      "        -1.9172e+00, -1.6959e+00, -2.2484e+00, -1.8775e+00, -1.6282e+00,\n",
      "        -2.0935e+00, -1.6864e+00, -1.5751e+00, -1.6178e+00,  7.0898e-02,\n",
      "        -1.2772e+00, -1.7774e+00, -1.6484e+00, -1.3536e+00, -2.2391e+00,\n",
      "        -1.5305e+00, -1.5837e+00, -1.5707e+00, -1.6759e+00, -1.6612e+00,\n",
      "        -1.6817e+00, -1.6429e+00, -1.8346e+00, -2.8786e+00,  1.9002e-01,\n",
      "        -5.3619e-01, -2.1060e+00, -2.0177e+00, -1.3350e+00, -1.9593e+00,\n",
      "        -1.8624e+00, -1.6818e+00, -1.5233e+00, -1.9604e+00, -1.8881e+00,\n",
      "        -1.9104e+00, -1.5862e+00, -1.7791e+00,  1.7909e-01, -1.6402e+00,\n",
      "        -1.4731e-01, -2.3406e+00, -1.7260e+00, -1.5438e-02,  7.3059e-03,\n",
      "        -6.5230e-02, -1.8812e+00, -8.7945e-01,  9.1382e-01, -1.7076e+00,\n",
      "        -1.8023e+00, -1.8093e+00, -2.5165e+00, -1.6633e+00, -2.0439e+00,\n",
      "        -2.3145e+00, -1.9609e+00, -2.4046e+00,  3.3682e-02,  3.2406e-01,\n",
      "        -1.7462e+00, -1.7457e+00, -1.7477e+00, -1.9671e+00, -1.5104e+00,\n",
      "        -1.3452e+00,  6.3649e-01, -1.5334e+00, -1.0149e+00, -1.9454e+00,\n",
      "        -1.3926e+00, -1.7439e+00,  5.9702e-01, -2.0860e+00, -2.5617e+00,\n",
      "        -2.3087e+00,  1.3705e-01,  2.0200e-01, -1.6704e+00, -2.3362e+00,\n",
      "        -1.0377e-02, -1.7669e+00, -3.9070e-01, -1.2728e+00,  1.2043e+00,\n",
      "        -2.9497e-01, -1.9183e+00, -1.9527e+00, -1.2894e+00,  5.2275e-01,\n",
      "         1.0220e+00, -1.4901e+00, -1.4389e+00,  2.0932e-01, -1.9746e+00,\n",
      "         3.2850e-01, -2.3561e+00, -1.0006e-01,  3.3211e-01, -2.1930e+00,\n",
      "        -1.7830e+00, -1.9173e+00, -1.2827e+00,  1.2059e+00, -1.7563e+00,\n",
      "        -2.1002e+00, -1.8460e+00, -2.5139e+00, -2.1039e+00, -1.9621e+00,\n",
      "        -1.2618e+00, -1.7041e+00, -1.6171e+00, -1.9810e+00, -1.9434e+00,\n",
      "         5.2372e-01, -2.3044e+00, -2.0404e+00, -1.3580e+00, -1.3177e+00,\n",
      "        -1.2536e+00, -1.4358e+00, -1.5825e+00,  3.6960e-01, -1.6505e+00,\n",
      "        -1.9101e+00, -1.8967e+00, -2.6977e+00,  1.1735e-01, -1.8742e+00,\n",
      "        -2.0065e+00, -2.4564e+00, -1.3876e+00, -1.5193e+00, -1.7649e+00,\n",
      "        -1.8040e+00, -1.9007e+00,  3.0788e-01, -1.9784e+00,  1.0932e-01,\n",
      "         4.7574e-01, -2.0126e+00, -1.6121e-01,  6.6128e-02, -1.8502e+00,\n",
      "        -1.9805e+00,  1.1239e+00, -1.9386e+00, -1.9846e+00, -2.6512e+00,\n",
      "        -1.8500e+00, -1.1891e+00, -2.2538e+00, -6.5326e-01, -1.7218e+00,\n",
      "        -1.9391e+00, -1.5890e+00, -2.6806e+00,  2.6167e+00, -2.3136e+00,\n",
      "        -2.0578e+00, -1.2364e+00, -2.4041e-01, -1.2743e+00, -1.9865e+00,\n",
      "        -1.4275e-01, -1.9953e+00, -5.0312e-02, -1.6345e+00, -1.7595e+00,\n",
      "        -1.9895e+00, -1.8679e+00, -3.7503e-01, -1.8314e+00, -8.2438e-01,\n",
      "        -1.7519e+00, -2.2554e+00, -2.0916e+00,  9.7975e-01, -2.0799e+00,\n",
      "        -1.8455e+00, -2.4906e+00, -3.6746e-01, -3.6089e+00, -7.7711e-01,\n",
      "        -1.2677e+00, -1.4208e+00,  5.7656e-01, -1.7641e+00, -4.5046e-01,\n",
      "        -9.1348e-01, -1.9688e+00, -1.5183e+00, -8.9119e-01, -7.4088e-01,\n",
      "        -1.5047e+00, -2.0538e+00,  8.3997e-02,  2.3748e-01, -1.3485e+00,\n",
      "         4.7528e-01, -1.8088e+00, -6.0940e-01, -2.0088e+00, -3.1790e-01,\n",
      "         3.1863e-01,  6.2457e-01, -1.8539e+00, -1.9339e+00, -8.6517e-02,\n",
      "        -1.5173e+00, -8.9625e-01, -1.7391e+00, -2.0115e+00, -1.8669e+00,\n",
      "        -1.7215e+00,  1.6661e-02, -1.8121e+00, -2.2266e+00,  6.4397e-01,\n",
      "        -2.1622e-01,  1.5035e+00, -2.1172e+00, -1.7162e+00, -1.8441e+00,\n",
      "        -1.8754e+00, -1.5422e+00, -1.9811e+00, -1.7291e+00, -1.9799e+00,\n",
      "        -1.4359e+00, -1.8894e+00, -1.7838e+00, -1.6142e+00,  5.1596e-01,\n",
      "        -1.6717e+00, -1.9057e+00, -2.5036e+00, -2.2055e+00, -1.7793e+00,\n",
      "        -1.8225e+00, -9.2012e-01, -1.9926e+00, -1.9550e+00, -1.5247e+00,\n",
      "        -1.7612e+00,  1.0520e-01, -1.8362e+00, -2.1271e+00, -6.1559e-01,\n",
      "        -5.9227e-01, -1.6465e+00, -1.7824e+00, -1.5140e+00,  5.7300e-01,\n",
      "        -1.3806e+00, -2.0063e+00, -1.6092e+00, -1.8144e+00, -6.0138e-03,\n",
      "         8.8448e-01, -2.6604e+00, -1.8549e+00, -1.6328e+00, -7.1712e-01,\n",
      "        -2.0938e+00, -1.6216e+00, -9.5393e-01, -1.5222e+00, -1.6504e+00,\n",
      "        -1.4939e+00, -1.8729e+00, -2.3248e+00, -1.6627e+00, -1.9994e+00,\n",
      "        -1.6415e+00, -1.7740e+00, -1.7666e+00, -1.2726e+00, -1.7585e+00,\n",
      "        -1.7207e+00, -1.8861e+00, -1.7793e+00, -1.8488e+00,  3.0606e-01,\n",
      "        -2.0129e+00,  1.3285e+00, -1.7463e+00, -1.7836e+00, -2.1319e+00,\n",
      "        -1.6499e+00, -1.8492e+00, -1.8080e+00, -1.2883e+00, -9.2010e-01,\n",
      "        -1.7022e+00, -1.0351e+00, -2.0722e+00, -1.9972e+00,  4.2082e-01,\n",
      "         7.9858e-01, -1.5935e-01, -1.7517e+00, -1.9403e+00, -1.6469e+00,\n",
      "        -1.8559e+00, -1.8488e+00, -1.1344e+00, -1.7714e+00, -1.8933e+00,\n",
      "        -2.2609e+00, -7.9901e-01, -2.0838e+00, -1.5410e+00, -2.0804e+00,\n",
      "        -1.3667e+00, -2.3982e+00, -1.8028e+00, -1.9017e+00, -1.7978e+00,\n",
      "        -1.8698e+00, -1.7083e+00, -1.9136e+00,  1.0718e-01, -2.0075e+00,\n",
      "        -1.3971e+00, -2.1082e+00, -1.7442e+00, -1.7828e+00, -1.7262e+00,\n",
      "        -1.8382e+00, -1.2947e+00,  8.0847e-03, -2.1440e+00, -1.9253e+00,\n",
      "        -1.7497e+00, -1.6875e+00, -1.7403e+00,  9.1427e-01, -1.8923e+00,\n",
      "        -2.4023e+00, -1.5149e+00, -1.8713e+00, -1.9049e+00, -1.0073e+00,\n",
      "        -2.8920e-01, -1.0191e+00, -1.8185e+00, -1.7700e+00, -1.9816e+00,\n",
      "        -2.2052e+00, -2.7753e-01, -5.2466e-01, -1.4485e+00, -4.5539e-01,\n",
      "        -9.9435e-01, -1.9753e-01, -7.1434e-01,  1.6271e+00, -1.6763e+00,\n",
      "        -1.8389e+00, -1.9001e+00, -1.7017e+00, -1.5581e+00, -2.0791e+00,\n",
      "        -1.7887e+00, -1.6835e+00, -2.9528e-01,  2.4400e-01, -2.0268e+00,\n",
      "        -1.6308e+00, -1.1761e+00, -1.6026e+00, -1.2419e+00, -1.3615e+00,\n",
      "         5.6968e-01, -1.9916e+00, -1.7770e+00, -1.9810e+00,  7.5672e-01,\n",
      "        -2.1953e+00, -2.5197e+00, -3.2295e-02, -1.5904e+00, -1.8120e+00,\n",
      "         7.8783e-01, -1.8806e+00, -2.1323e+00, -1.3820e+00, -1.9200e+00,\n",
      "        -1.7230e+00, -1.9890e+00, -1.9592e+00, -1.9013e+00, -2.3385e+00,\n",
      "         1.2241e+00, -2.1211e+00,  4.0152e-01, -1.0490e+00, -1.6780e+00,\n",
      "        -1.5569e+00, -1.6056e+00,  6.2978e-01, -1.5781e+00, -2.0788e+00,\n",
      "        -1.6818e+00, -1.6616e+00, -5.9321e-01, -1.7880e+00, -1.8317e+00,\n",
      "         9.0547e-01, -9.6552e-01, -1.9295e+00,  9.6751e-01, -1.9347e+00,\n",
      "        -1.7255e+00, -3.1077e+00, -2.3784e+00, -1.2832e+00, -1.6166e+00,\n",
      "        -1.8233e+00, -1.9868e+00, -1.8212e+00, -2.2213e+00, -1.9886e+00,\n",
      "        -2.1093e+00, -2.0404e+00, -1.9990e+00, -1.8353e+00, -4.6892e-01,\n",
      "         9.9501e-02, -1.7868e+00, -1.9459e+00, -1.5701e+00, -2.1383e+00,\n",
      "        -2.0263e+00, -1.7172e+00,  1.5526e-01, -2.0413e+00,  7.8668e-01,\n",
      "        -1.3703e+00, -1.8305e+00, -1.9341e+00, -1.0890e+00, -1.8695e+00,\n",
      "        -1.6810e+00, -1.5474e+00, -2.1535e+00, -1.3169e+00, -1.7763e+00,\n",
      "        -2.1341e+00, -1.9335e+00, -2.0372e+00, -1.5615e+00, -1.5828e+00,\n",
      "        -1.9328e+00,  9.6556e-01, -1.3778e+00, -1.3997e+00, -1.5587e+00,\n",
      "        -3.3877e-01,  4.3488e-01, -1.3044e+00, -1.9394e+00, -2.0747e+00,\n",
      "        -1.7082e+00, -1.8044e+00, -1.2263e+00, -8.9139e-02, -1.4040e+00,\n",
      "         5.8472e-01, -1.4861e+00, -1.3009e+00, -1.6772e+00, -4.8707e-01,\n",
      "         5.9866e-01, -1.0381e+00, -2.0422e+00, -1.0683e+00, -2.5724e+00,\n",
      "        -8.4384e-02,  1.3548e+00, -1.8508e+00, -1.6352e+00, -2.0193e+00,\n",
      "        -1.7327e+00, -1.8285e+00, -7.4547e-01, -1.1700e+00, -1.7505e+00,\n",
      "         9.1431e-01, -2.5744e+00, -2.4945e+00, -1.0181e+00, -1.4749e+00,\n",
      "        -2.0212e+00, -2.0324e+00,  1.2514e-01, -1.4962e+00, -1.2680e+00,\n",
      "        -1.8049e+00, -5.6626e-01, -2.0406e+00, -2.2140e+00, -5.3026e-01,\n",
      "        -7.7080e-01, -2.1230e+00, -1.9636e+00, -1.7623e+00, -1.7230e+00,\n",
      "        -1.6928e+00,  7.4596e-02, -2.0803e+00, -1.8382e+00, -1.8260e+00,\n",
      "        -1.2367e+00, -1.9026e+00, -1.6775e+00,  1.6159e-01, -1.7653e+00,\n",
      "        -1.2342e+00, -1.4301e+00, -1.8316e+00, -1.6825e+00, -1.9599e+00,\n",
      "        -1.8997e+00, -6.3237e-02, -1.9429e+00, -1.5800e+00, -1.6872e+00,\n",
      "        -1.6996e+00, -1.5705e+00, -2.1748e+00, -2.0292e+00, -3.5322e-01,\n",
      "        -8.3005e-01, -5.8023e-01, -2.2192e+00, -1.8914e+00, -1.8111e+00,\n",
      "        -1.2093e+00, -4.3280e-01, -6.1754e-04, -3.6239e-02, -5.1432e-01,\n",
      "        -2.8426e+00, -2.3480e+00, -4.9624e-02, -1.5096e+00, -1.4119e+00,\n",
      "        -1.4248e+00, -1.8483e+00, -2.1110e+00, -1.8543e+00, -1.4862e+00,\n",
      "        -1.3650e+00, -1.8455e-01, -1.8167e+00,  3.8558e-02, -1.0342e+00,\n",
      "        -1.8674e+00,  1.0313e+00, -1.4982e+00, -1.6128e+00, -2.0343e+00,\n",
      "        -1.7257e+00, -8.3523e-01, -1.9363e+00, -1.8788e+00, -1.4625e+00,\n",
      "        -1.8300e+00, -2.5074e+00, -2.3457e+00, -4.3640e-02, -1.7558e+00,\n",
      "        -1.1962e+00, -1.4266e+00, -2.0190e+00,  1.1166e+00, -1.9366e+00,\n",
      "        -1.9115e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2849,  0.0303,  0.0673,  0.0368, -0.1224],\n",
      "          [-0.6960, -0.4140, -0.0947, -0.2484, -0.3957],\n",
      "          [-0.7545, -0.4449,  0.0591, -0.0877, -0.3608],\n",
      "          [-0.3928, -0.0636, -0.2319, -0.2374, -0.7538],\n",
      "          [ 0.1256, -0.0605, -0.1936, -0.4100, -0.5213]]],\n",
      "\n",
      "\n",
      "        [[[-0.2555, -0.2084, -0.6095,  0.3854,  0.4320],\n",
      "          [-0.2721, -0.1704, -0.5957,  0.3788,  0.4442],\n",
      "          [ 0.5090,  0.2809, -0.0143, -0.5390, -0.4844],\n",
      "          [-0.1404,  0.2073,  0.4681, -0.2680, -0.2930],\n",
      "          [-0.2464,  0.1334,  0.5343, -0.2971, -0.3197]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6318,  0.4979,  0.4663,  0.3616,  0.4601],\n",
      "          [ 0.5364,  0.1408,  0.4435,  0.1723,  0.2229],\n",
      "          [-0.0152,  0.3512,  0.0170,  0.3100, -0.1918],\n",
      "          [ 0.4798,  0.3270,  0.3087,  0.3250,  0.6135],\n",
      "          [ 0.0622,  0.0027, -0.0576, -0.0484, -0.0090]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0357, -0.0782,  0.1645,  0.1213,  0.1645],\n",
      "          [-0.4007, -0.1863, -0.5037, -0.2896, -0.1227],\n",
      "          [-0.0196, -0.2564, -0.4771, -0.5385, -0.4789],\n",
      "          [-0.1300, -0.2074, -0.1539, -0.2257, -0.2397],\n",
      "          [-0.4486, -0.5768, -0.6834, -0.6529, -0.4622]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5198,  0.4393,  0.3451,  0.3549,  0.2508],\n",
      "          [-0.2554,  0.4573, -0.5773,  0.3676, -0.7984],\n",
      "          [ 0.1152,  0.3818,  0.0255,  0.0422, -0.2676],\n",
      "          [-0.2803,  0.0901, -0.2671,  0.2650, -0.1787],\n",
      "          [ 0.0025,  0.5742,  0.0199,  0.3683, -0.0626]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0629, -0.1064, -0.1260, -0.4064,  0.2519],\n",
      "          [ 0.0461, -0.1063, -0.1585,  0.0890, -0.0178],\n",
      "          [-0.1611, -0.0410, -0.4453, -0.7027, -0.3042],\n",
      "          [-0.2097, -0.7212, -0.3990, -0.2092, -0.1784],\n",
      "          [-0.1128, -0.4507, -0.2222, -0.8827, -0.4951]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.6021e+00,  4.4995e+00,  1.0460e+00,  1.6909e+00,  6.9724e-01,\n",
      "         1.0064e+00,  8.2358e-01,  6.9418e-01,  1.5425e+00,  7.7520e-01,\n",
      "         6.9300e-01,  9.5645e-01,  1.6503e+00,  8.8623e-01,  1.0454e+00,\n",
      "         8.1499e-01,  1.0961e+00,  1.1274e+00,  2.0093e+00,  3.2614e-01,\n",
      "         9.4685e-01,  1.3053e+00,  9.4268e-01,  2.5573e+00,  1.0794e+00,\n",
      "         2.3106e+00,  1.6090e+00,  7.3466e-01,  8.9112e-01,  8.7563e-01,\n",
      "         2.4188e+00,  1.2829e+00,  5.5889e-01,  9.1861e-01,  1.0278e+00,\n",
      "         1.9541e+00,  1.8866e+00,  1.3272e+00,  1.0704e+00,  1.3981e+00,\n",
      "         1.0606e+00,  1.9594e+00,  7.1786e-01,  1.0212e+00,  1.5339e+00,\n",
      "         1.1464e+00,  1.0327e+00,  1.0668e+00,  1.3790e+00,  1.4498e+00,\n",
      "         1.3608e+00,  9.9899e-01,  1.0933e+00,  1.3348e+00,  8.4655e-01,\n",
      "         1.2618e+00,  9.5788e-01,  1.4376e+00,  6.0216e-01,  7.5654e-01,\n",
      "         9.0748e-01,  1.3170e+00,  9.2821e-01,  5.9866e-01,  8.6432e-01,\n",
      "         1.0292e+00,  6.0292e-04,  6.3067e-01,  2.0240e+00,  9.7440e-01,\n",
      "         1.1051e+00,  8.6491e-01,  7.5225e-01, -6.9105e-02,  9.0254e-01,\n",
      "         1.4239e+00,  9.6321e-01,  1.1717e+00,  3.6120e-01,  1.8531e+00,\n",
      "         9.9028e-01,  1.0080e+00,  1.2489e+00,  1.0414e+00,  1.1039e+00,\n",
      "         1.3635e+00,  9.4825e-01,  6.3503e-01,  9.1237e-01,  1.5048e+00,\n",
      "         2.1207e+00,  2.0103e+00,  1.0255e+00,  9.9276e-01,  9.8933e-01,\n",
      "         8.4703e-01,  1.2464e+00,  9.5120e-01,  1.1416e+00,  2.1985e+00,\n",
      "         1.1020e+00,  8.4788e-01,  8.9668e-01,  1.0238e+00,  7.3876e-01,\n",
      "         2.3424e+00,  8.9128e-01,  8.8561e-01,  1.1311e+00,  7.8339e-01,\n",
      "         1.5808e+00,  9.3857e-01,  8.0832e-01,  1.2344e+00,  9.8393e-01,\n",
      "         5.8539e-01,  1.0844e+00,  9.0040e-01,  1.1043e+00,  1.0493e+00,\n",
      "         1.9714e+00,  7.4218e-01,  1.1041e+00,  1.3240e+00,  9.0690e-01,\n",
      "         8.8358e-01,  1.2624e+00,  8.9778e-01,  1.0414e+00,  2.4120e+00,\n",
      "         8.9404e-01,  2.2378e+00,  9.7485e-01,  3.1207e+00,  3.4796e-01,\n",
      "         2.4029e+00,  9.3205e-01,  9.0814e-01,  1.9477e+00,  1.8797e+00,\n",
      "         1.8053e+00,  9.8828e-01,  7.1644e-01,  1.2462e+00,  4.8652e-01,\n",
      "         7.0568e-01,  1.9027e+00,  9.3803e-01,  1.8574e+00,  1.8837e+00,\n",
      "         9.1663e-01,  3.6006e-01,  1.2056e+00,  1.0263e+00,  1.0694e+00,\n",
      "         9.3871e-01,  1.0518e+00,  7.3499e-01,  1.3283e+00,  1.1825e+00,\n",
      "         6.2925e-01,  2.0104e+00,  1.0644e+00,  1.3425e+00,  2.2240e+00,\n",
      "         2.7219e+00,  9.5324e-01,  1.2437e+00,  6.3716e-01,  7.0327e-01,\n",
      "         6.7843e-01,  1.3545e+00,  7.0447e-01,  1.4653e+00,  7.2436e-01,\n",
      "         8.7268e-01,  1.1225e+00,  9.8044e-01,  1.4820e+00,  1.3485e+00,\n",
      "         8.9347e-01,  9.3840e-01,  8.5792e-01,  6.0555e-01,  1.1226e+00,\n",
      "         5.5905e-01,  2.5324e+00,  9.3701e-01,  1.1186e+00,  1.2922e+00,\n",
      "         1.1797e+00,  9.5650e-01,  4.1691e-01,  1.1701e+00,  1.1107e+00,\n",
      "         8.5270e-01,  6.0381e-01,  9.2603e-01,  1.2554e+00,  1.0416e+00,\n",
      "         1.1308e+00,  1.1537e+00,  1.0934e+00,  3.2570e+00,  1.1534e+00,\n",
      "         1.2641e+00,  1.0445e+00,  1.1877e+00,  1.2745e+00,  1.0882e+00,\n",
      "         5.4746e-01,  5.8227e-01,  6.7770e-01,  2.3644e+00,  1.9872e+00,\n",
      "         1.1366e+00,  1.9761e+00,  1.2440e+00,  1.0427e+00,  1.0614e+00,\n",
      "         6.8132e-01,  7.0637e-01,  1.5274e+00,  7.7021e-01,  2.8829e+00,\n",
      "         9.1397e-01,  1.3183e+00,  1.1812e+00,  9.3580e-01,  1.2601e+00,\n",
      "         4.2398e-01,  2.0187e+00,  1.1823e+00,  8.5904e-01,  8.9324e-01,\n",
      "         1.0033e+00,  1.0644e+00,  1.2706e+00,  9.7173e-01,  8.2635e-01,\n",
      "         8.8408e-01,  5.2241e-01,  8.0034e-01,  1.1339e+00,  5.8501e-01,\n",
      "         9.6662e-01,  6.8856e-01,  1.1053e+00,  8.4977e-01,  7.1448e-01,\n",
      "         9.2713e-01,  1.0091e+00,  8.1994e-01,  9.9167e-01,  8.7123e-01,\n",
      "         1.7050e+00,  9.9429e-01,  9.7272e-01,  9.7858e-01,  2.0988e+00,\n",
      "         1.3295e+00,  9.3561e-01,  9.3692e-01,  6.1948e-01,  8.0584e-01,\n",
      "         1.1204e+00,  1.1382e+00,  7.1786e-01,  1.1501e+00,  9.5172e-02,\n",
      "         1.1142e+00,  8.4005e-01,  7.6031e-01,  2.0978e+00,  9.6750e-01,\n",
      "         1.1650e+00,  6.7937e-01,  8.8327e-01,  1.9616e+00,  1.5605e+00,\n",
      "         3.9519e-01,  1.2421e+00,  1.5414e+00,  2.1098e+00,  1.0638e+00,\n",
      "         1.1418e+00,  1.0309e+00,  1.0909e+00,  9.4124e-01,  8.5360e-01,\n",
      "         1.2936e+00,  1.2753e+00,  5.1308e-01, -1.0623e-04,  1.2267e+00,\n",
      "         1.4360e+00,  9.9751e-01,  8.6124e-01,  1.1400e+00,  9.8749e-01,\n",
      "         5.8532e-01,  2.7873e+00,  8.4048e-01,  1.2652e+00,  8.0794e-01,\n",
      "         5.3758e-01,  6.4048e-01,  1.5768e+00,  1.1242e+00,  1.2323e+00,\n",
      "         6.8019e-01,  1.7898e+00,  2.6154e+00,  8.6654e-01,  9.4470e-01,\n",
      "         1.1164e+00,  4.2721e-01,  1.3381e+00,  1.0641e+00,  1.4171e+00,\n",
      "         2.3932e+00,  1.0441e+00,  8.2260e-01,  1.4449e+00,  1.2456e+00,\n",
      "         1.6751e+00,  1.0281e+00,  1.1336e+00,  2.1849e+00,  8.4576e-01,\n",
      "         1.6388e+00,  7.3055e-01,  1.0734e+00,  1.4890e+00,  5.5420e-01,\n",
      "         6.0447e-01,  1.0631e+00,  7.3590e-01,  2.7855e+00,  7.4746e-01,\n",
      "         1.1143e+00,  6.7710e-01,  1.6541e+00,  1.3349e+00,  8.3722e-01,\n",
      "         2.1707e+00,  4.3732e-01,  5.8071e-01,  6.5443e-01,  5.9234e-01,\n",
      "         1.9085e+00,  9.5910e-01,  1.1128e+00,  1.0319e+00,  7.7197e-01,\n",
      "         7.4272e-01,  1.0654e+00,  9.0314e-01,  1.6519e+00,  1.0586e+00,\n",
      "         1.0353e+00,  9.8078e-01,  1.4524e+00,  1.6919e+00,  1.7407e+00,\n",
      "         8.6375e-01,  1.1981e+00,  1.2147e+00,  3.8983e-01,  1.0600e+00,\n",
      "         1.5820e+00,  1.3911e+00,  2.6679e+00,  1.0543e+00,  1.1269e+00,\n",
      "         2.2299e+00,  1.0374e+00,  1.0764e+00,  2.4010e+00,  1.0564e+00,\n",
      "         1.1182e+00,  2.4082e+00,  8.2163e-01,  8.2518e-01,  1.4381e+00,\n",
      "         7.6560e-01,  1.1247e+00,  1.3200e+00,  2.2041e+00,  6.9446e-01,\n",
      "         9.6804e-01,  5.9802e-01,  6.1344e-01,  2.6501e+00,  5.1543e-01,\n",
      "         1.1178e+00,  1.5272e+00,  1.4826e+00,  1.2395e+00,  9.6620e-01,\n",
      "         8.4039e-01,  9.4041e-01,  9.9964e-01,  4.8473e-01,  1.1627e+00,\n",
      "         9.5555e-01,  9.2053e-01,  2.3476e+00,  3.7174e-01,  2.1550e+00,\n",
      "         8.1538e-01,  8.6631e-01,  1.2418e+00,  2.3160e+00,  1.2933e+00,\n",
      "         1.1990e+00,  1.5349e+00,  1.7916e+00,  8.4059e-01,  1.4627e+00,\n",
      "         1.9929e+00,  4.9049e-01,  2.2971e+00,  9.5632e-01,  2.1374e-02,\n",
      "         1.3126e+00,  1.2328e+00,  9.7593e-01,  1.1686e+00,  1.9906e+00,\n",
      "         9.2028e-01,  4.7019e-01,  1.6239e+00,  2.4655e+00,  7.3994e-01,\n",
      "         1.8561e+00,  8.5478e-01,  1.1302e+00,  1.5694e+00,  1.5366e+00,\n",
      "         1.7480e+00,  2.3785e+00,  1.1787e+00,  9.5384e-01,  1.2665e+00,\n",
      "         9.3090e-01,  1.1861e+00,  8.4583e-01,  9.1173e-01,  1.0064e+00,\n",
      "         1.2570e+00,  1.8311e+00,  7.2898e-01,  1.3166e+00,  1.6723e+00,\n",
      "         1.6287e+00,  1.2921e+00,  1.4544e+00,  7.7536e-01,  9.8588e-01,\n",
      "         8.1124e-01, -7.6279e-04,  9.5091e-01,  1.5178e+00,  4.9674e-01,\n",
      "         7.0986e-01,  1.4918e+00,  1.3355e+00,  7.9542e-01,  2.5563e+00,\n",
      "         1.0343e+00,  1.1253e+00,  8.6191e-01,  1.2063e+00,  1.0697e+00,\n",
      "         7.2089e-01,  8.4657e-01,  8.5479e-01,  7.1662e-01,  5.7445e-01,\n",
      "         2.1034e+00,  1.8567e+00,  8.4246e-01,  8.2382e-01,  1.5470e+00,\n",
      "         1.1673e+00,  1.2874e+00,  1.0376e+00,  9.5189e-01,  2.8346e+00,\n",
      "         1.1690e+00,  6.3968e-01,  5.8437e-01,  9.4749e-01,  1.1870e+00,\n",
      "         1.5256e+00,  9.9195e-01,  8.3537e-01,  8.4277e-01,  1.6595e+00,\n",
      "         7.7585e-01,  1.1007e+00,  1.9811e+00,  9.2064e-01,  5.8189e-01,\n",
      "         1.1579e+00,  1.0555e+00,  9.5396e-01,  1.0118e+00,  1.0739e+00,\n",
      "         1.2182e+00,  1.4238e+00,  1.5486e+00,  2.1515e+00,  1.1180e+00,\n",
      "         1.0128e+00,  9.2773e-01,  7.9830e-01,  6.6388e-01,  2.0381e+00,\n",
      "         9.4476e-01,  1.8251e+00,  9.7864e-01,  1.0586e+00,  1.2158e+00,\n",
      "         8.8469e-01,  1.1142e+00,  6.9732e-01,  1.1144e+00,  6.1830e-01,\n",
      "         7.0414e-01,  1.8783e+00,  9.0526e-01,  9.8346e-01,  1.7060e+00,\n",
      "         2.4162e+00,  1.3201e+00,  7.9111e-01,  7.6463e-01,  1.1508e+00,\n",
      "         9.3176e-01,  5.5096e-01,  1.1084e+00,  8.2840e-01,  8.8787e-01,\n",
      "         1.1807e+00,  1.1959e+00,  1.3691e+00,  1.3742e+00,  1.0723e+00,\n",
      "         1.0884e+00,  1.1211e+00,  1.0972e+00,  1.0600e+00,  1.0456e+00,\n",
      "         1.1938e+00,  7.6355e-01,  1.1056e+00,  2.9041e+00,  6.5636e-01,\n",
      "         8.6419e-01,  1.0200e+00,  1.0033e+00,  1.0410e+00,  1.5025e+00,\n",
      "         9.3158e-01,  9.7454e-01,  1.4127e+00,  1.1016e+00,  1.0209e+00,\n",
      "         1.0947e+00,  8.4217e-01,  8.0445e-01,  7.5053e-01,  3.5021e-01,\n",
      "         1.0212e+00,  1.2614e+00,  1.0795e+00,  7.8712e-01,  1.6282e+00,\n",
      "         1.8987e+00,  1.4378e+00,  7.2570e-01,  7.1206e-01,  8.1946e-01,\n",
      "         7.0769e-03,  8.6979e-01,  1.6834e+00,  8.1431e-01,  4.7147e-01,\n",
      "         1.2059e+00,  2.1774e+00,  1.1708e+00,  1.6064e+00,  7.4034e-01,\n",
      "         1.0949e+00,  8.2206e-01,  1.0957e+00,  8.0058e-01,  9.0638e-01,\n",
      "         1.0212e+00,  9.9425e-01,  9.4825e-01,  1.9468e+00,  7.0889e-01,\n",
      "         1.1113e+00,  1.2046e+00,  1.0662e+00,  1.2292e+00,  9.1889e-01,\n",
      "         1.5393e+00,  1.0243e+00,  1.2660e+00,  9.8286e-01,  1.6455e+00,\n",
      "         8.6457e-01,  1.1585e+00,  2.3505e+00,  6.2441e-01,  1.2266e+00,\n",
      "         1.4249e+00,  1.0042e+00,  8.2676e-01,  1.3036e+00,  1.2359e+00,\n",
      "         4.3487e-01,  9.5684e-01,  6.6462e-01,  1.3054e+00,  1.0765e+00,\n",
      "         4.2027e-01,  1.0206e+00,  1.3496e+00,  7.9259e-01,  9.9042e-01,\n",
      "         1.0708e+00,  5.2901e-01,  2.8500e+00,  8.2447e-01,  6.7838e-01,\n",
      "         8.6324e-01,  6.6913e-01,  2.0181e+00,  8.7829e-01,  1.0879e+00,\n",
      "         2.5937e+00,  1.6520e+00,  8.8004e-01,  2.0167e+00,  1.3891e+00,\n",
      "         1.1277e+00,  7.4982e-01,  1.1275e+00,  1.4759e+00,  1.2036e+00,\n",
      "         1.9436e+00,  8.1517e-01,  7.3904e-01,  1.1794e+00,  1.2360e+00,\n",
      "         1.3502e+00,  1.0436e+00,  9.7443e-01,  5.7280e-01,  1.4774e+00,\n",
      "         1.6317e+00,  1.0314e+00,  7.4629e-01,  9.9536e-01,  9.2208e-01,\n",
      "         1.2387e+00,  1.4277e+00,  1.4573e+00,  9.0185e-01,  1.6420e+00,\n",
      "         1.1422e+00,  1.2029e+00,  3.7862e-01,  5.1079e-01,  5.9667e-01,\n",
      "         2.4832e-01,  1.1796e+00,  1.2119e+00,  6.8932e-01,  1.1681e+00,\n",
      "         1.1402e+00,  1.3164e+00,  1.0321e+00,  1.3473e+00,  1.6130e+00,\n",
      "         7.2089e-01,  2.6850e+00,  1.3489e+00,  9.6390e-01,  1.1533e+00,\n",
      "         8.9308e-01,  2.0322e+00,  8.8192e-01,  1.0375e+00,  1.0778e+00,\n",
      "         3.0448e-01,  4.0799e-01,  4.6820e-01,  1.5170e+00,  8.6674e-01,\n",
      "         1.1820e+00,  8.8741e-01,  2.0273e+00,  9.7159e-01,  9.2294e-01,\n",
      "         2.0766e+00,  1.2486e+00,  8.7583e-01,  9.4822e-01,  1.1070e+00,\n",
      "         1.1177e+00,  1.9594e+00,  9.2772e-01,  6.0828e-01,  1.0137e+00,\n",
      "         1.4877e+00,  1.0864e+00,  2.4076e+00,  1.1658e+00,  9.7576e-01,\n",
      "         1.8563e+00,  1.4211e+00,  9.4649e-01,  4.7154e-01,  5.7732e-01,\n",
      "         6.0858e-01,  1.0283e+00,  1.1251e+00,  1.7425e+00,  1.1903e+00,\n",
      "         6.5806e-01,  1.2808e+00,  5.9160e-01,  1.1805e+00,  1.6600e+00,\n",
      "         9.8824e-01,  1.0483e+00,  8.4783e-01,  8.5792e-01,  6.4621e-01,\n",
      "         1.2161e+00,  1.5887e+00,  8.4408e-01,  3.7338e-01,  1.1963e+00,\n",
      "         2.7622e-01,  1.8497e+00,  1.1833e+00,  2.1577e+00,  6.9369e-01,\n",
      "         1.1478e+00,  5.3288e-01,  9.5443e-01,  1.4284e+00,  1.0113e+00,\n",
      "         6.1022e-01,  1.6958e+00,  9.0191e-01,  1.0450e+00,  1.3289e+00,\n",
      "         8.1178e-01,  5.4956e-01,  6.6353e-01,  1.1538e+00,  1.1987e+00,\n",
      "         1.5804e+00,  2.3976e+00,  5.4614e-01,  8.4764e-01,  1.1749e+00,\n",
      "         1.0186e+00,  1.8352e+00,  4.7361e-05,  1.3821e+00, -3.2858e-02,\n",
      "         1.7152e+00,  7.8443e-01,  1.1207e+00,  1.0618e+00,  9.9307e-01,\n",
      "         8.9926e-01,  1.0157e+00,  9.5643e-01,  7.4214e-01,  1.0296e+00,\n",
      "         9.1871e-01,  1.7289e+00,  9.0962e-01,  1.1225e+00,  1.4067e+00,\n",
      "         1.1219e+00,  2.0774e+00,  1.0148e+00,  1.1883e+00,  1.0691e+00,\n",
      "         1.8472e+00,  1.1548e+00,  1.5142e+00,  6.2975e-01,  3.2715e-01,\n",
      "         9.4675e-01,  1.0821e+00,  1.1577e+00,  2.5412e-01,  4.6088e-01,\n",
      "         1.1273e+00,  9.1381e-01,  1.1843e+00,  2.5005e+00,  1.2595e+00,\n",
      "         4.9289e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.6846, -5.0443,  1.8234, -1.2571,  1.1231,  0.5849,  0.5760,  1.1064,\n",
      "         0.6799,  0.7678,  1.2601,  0.6648,  0.3486,  1.5761,  1.1011,  1.7621,\n",
      "         0.6850,  0.9767,  1.7666,  1.5914,  1.3745,  1.3605,  1.2222, -1.5808,\n",
      "         1.7883, -0.8662, -1.1948,  1.2992,  1.0923,  0.0637, -0.9362,  2.1988,\n",
      "         1.1150,  2.1194,  1.0931, -2.9386, -1.5070, -0.9300,  0.7884,  3.7061,\n",
      "         0.7442, -1.9296,  1.6945,  1.5266,  0.4872,  0.2665,  0.7681,  0.2239,\n",
      "         0.5729,  1.2740,  2.3091,  0.7171, -1.4906,  0.9276,  1.1215,  1.9354,\n",
      "         2.3314,  1.4999,  0.7999,  2.3987,  0.6343,  1.1225,  1.2848,  0.6115,\n",
      "         1.4094,  0.0103, -1.2774, -0.2388, -0.8370,  1.3737,  1.5381,  0.8702,\n",
      "         1.5003,  0.3599,  0.8791, -0.7000,  0.6917,  1.2602, -1.0682,  0.5801,\n",
      "         0.8510,  2.2199, -1.2839,  0.6041,  1.6344,  1.3720,  2.6816,  1.8117,\n",
      "        -1.5401,  0.8962, -1.0433, -2.2723,  1.2198,  1.5514,  0.9058,  2.1748,\n",
      "         2.5775,  1.7647,  1.3114, -1.6700,  1.1314,  1.3232,  1.3117,  1.3381,\n",
      "         1.1986, -0.0168,  1.5688,  0.3085,  2.2850,  1.4022,  1.1582, -1.5532,\n",
      "         1.3478,  0.4818,  1.1862,  0.9296,  0.5118,  1.4361, -0.6558,  1.6023,\n",
      "         0.8685,  0.7001,  1.9366,  1.4043,  0.4976,  0.9157,  0.9704,  0.0497,\n",
      "         2.2680, -2.3381,  1.0998, -1.7755,  0.3199, -1.1863,  1.6253, -1.1538,\n",
      "         1.6073,  0.2358, -0.3445,  0.6708, -0.9573,  0.8971,  1.2226,  1.9740,\n",
      "         0.5920,  1.6041, -0.9337,  1.2408,  0.1685, -1.0798, -0.9789,  0.5881,\n",
      "         2.9589,  2.0653, -0.2215,  0.5632,  0.6960,  0.6197,  1.9338,  2.2857,\n",
      "         0.3483, -0.5725,  1.8208, -0.3640, -0.8962, -1.4479,  0.1979,  1.3392,\n",
      "         1.3318,  0.2876,  1.8973, -0.6796,  1.2991,  2.6571,  1.6780,  0.9787,\n",
      "         1.9164,  1.2311,  1.1527,  0.3814,  0.2255, -0.0364,  1.1215,  1.4665,\n",
      "         1.3546,  1.9123, -1.2589,  2.0122,  0.6194,  3.2186,  1.5725,  0.5006,\n",
      "         0.9667,  0.4846,  1.5400,  1.0957,  0.8709,  0.9794,  3.0758, -0.0428,\n",
      "         1.0737,  1.0202,  1.4207, -1.2825,  1.3264,  1.0182,  1.6461,  0.8287,\n",
      "         1.0525,  1.1115,  1.5862,  0.6730,  1.1730, -1.6355, -2.0416,  1.8879,\n",
      "        -1.7669,  1.7852,  2.0837,  1.4305,  1.7237, -0.0453, -0.4105,  1.0937,\n",
      "        -0.2573,  0.7137,  0.6988,  1.2520,  1.5639,  1.9801,  0.5716, -0.7182,\n",
      "         0.7536, -0.6113,  1.0048,  0.7789,  1.9300,  1.9613,  1.0573,  1.5325,\n",
      "         1.4378,  2.2160,  0.8369,  0.0415, -1.4369,  0.8852,  0.6568,  1.2778,\n",
      "         0.5316,  1.7484,  0.2725,  1.2341,  1.2907,  1.7690,  0.3029,  1.9587,\n",
      "         1.1272,  0.5560,  0.3513, -1.7856, -0.4775,  1.5982,  1.9038,  0.7670,\n",
      "         0.7190,  1.3831,  0.6327,  0.8040, -0.2584, -1.1037,  1.6285,  1.4378,\n",
      "         2.0274, -2.3339,  1.3336,  0.8725, -0.0213,  1.6371, -1.1069, -1.0433,\n",
      "        -1.3841,  1.4685,  3.1000, -1.7873,  1.3162,  0.8590,  0.8681,  1.9612,\n",
      "         1.0530,  1.0175,  1.3159,  1.7186,  0.3728, -1.2784, -0.1616,  1.8486,\n",
      "         1.2935,  0.6445,  0.6873,  1.1150,  1.0373, -0.7769,  0.7249, -0.6859,\n",
      "         2.1418, -1.0307,  0.9068, -0.8717,  0.7527,  0.3302,  0.2041, -1.3418,\n",
      "        -1.9529,  2.2370,  0.1050,  0.4162,  0.6747,  0.2155,  0.2066,  2.9666,\n",
      "        -1.1273,  0.8976,  0.4154,  0.6785, -0.3117, -1.9191,  2.4483,  0.8977,\n",
      "        -1.3758,  0.6308, -1.1572,  0.5037,  0.8535, -1.0385,  0.3979,  0.4937,\n",
      "         2.1319,  2.9037, -1.8582,  1.6205,  1.6732,  1.0371,  1.2726,  1.2433,\n",
      "         0.8523,  0.5284,  2.0818,  1.2216,  2.0777,  0.4231, -1.4299,  0.7416,\n",
      "         1.2611, -0.2008,  1.1715,  1.5758,  1.2995,  0.9725, -0.7075,  0.6516,\n",
      "         1.1989,  1.3193,  1.5989,  0.9820,  2.2711,  2.2563,  0.6910,  1.3553,\n",
      "         1.8090,  2.0756, -0.0814,  0.8202, -1.9019,  1.2283, -1.1805, -1.3873,\n",
      "        -0.0209,  1.1693, -0.8862,  1.0750,  1.8999, -1.3112,  1.2017,  0.7421,\n",
      "         0.7109,  1.0232,  3.6203,  1.3061, -1.0206, -0.0207,  1.4860,  2.5949,\n",
      "        -0.7586, -2.5715,  0.1491,  0.6836, -1.5842, -0.9466,  0.7211,  1.5666,\n",
      "         1.2076,  1.7816,  2.6110,  1.2101,  1.2432,  1.5365,  1.1144, -0.3918,\n",
      "         0.4006, -0.4101,  0.7825,  1.2947,  0.2621, -1.1212,  0.8734,  0.7317,\n",
      "         1.8646, -1.2561,  0.2169,  0.9286,  0.4728,  0.9266, -1.5447, -0.0524,\n",
      "         0.3627,  2.1407,  0.3837,  0.2091,  1.2192,  0.9074,  0.3219,  0.9724,\n",
      "        -0.2326, -2.7775,  0.1497,  0.1421,  0.5720,  3.1931,  1.0006, -0.5415,\n",
      "        -1.1160, -0.7699,  1.7145,  1.3147,  2.5570,  1.4394,  1.3969,  1.4492,\n",
      "         0.5660,  1.6055,  1.7277,  0.3360,  0.0926,  1.7857, -1.1461, -0.5504,\n",
      "        -0.5887,  0.8358,  0.8071,  1.1698,  0.5586, -0.7182,  1.1231,  1.3900,\n",
      "         0.8434,  1.7085,  2.6810,  1.6034,  0.8297, -1.6882,  1.6160,  1.1531,\n",
      "        -0.7278,  1.4338,  1.3129,  2.4060,  0.7474,  1.0654,  0.7557,  1.6824,\n",
      "         0.7317, -0.8107,  0.7217,  1.0706,  0.9072,  1.4235,  2.4150,  0.5594,\n",
      "        -0.1454, -1.1680,  0.5750,  1.4981,  0.6521,  1.8075,  1.4205, -0.9738,\n",
      "         0.5287,  0.4010,  2.5932, -1.9353,  0.6404,  0.6965, -0.4332,  1.2680,\n",
      "         2.2006,  1.7987,  0.7695,  1.0991,  2.0861,  0.5815,  0.9076,  1.3511,\n",
      "         2.1166, -0.2184,  1.8226,  1.2517, -0.2211,  1.2590,  0.1141, -1.4106,\n",
      "         1.2391,  0.5646,  0.8351,  2.0183,  0.4300,  1.3867,  2.3822,  1.8942,\n",
      "         2.2952,  0.7409,  1.8871,  0.5791,  1.4101,  1.3406, -1.3306, -1.7679,\n",
      "         1.5301,  1.6173,  0.2665,  1.2207,  0.5739,  0.8333,  2.9977,  1.4818,\n",
      "        -0.0979,  0.1521,  2.2887,  0.3749,  0.8379,  0.8743, -0.5108,  2.0576,\n",
      "         1.0928,  1.7379,  0.2961,  2.4046,  2.0367,  0.9853, -2.4425,  1.0415,\n",
      "         1.2190,  1.2032,  1.2166,  0.9521,  1.4007,  1.6990,  1.9264,  0.7357,\n",
      "         0.5992,  1.8569,  0.7206,  0.7883,  0.9568,  1.2699,  0.2612,  0.1237,\n",
      "         1.8287,  0.7320,  0.9694,  0.0664, -1.2075,  2.4981,  0.8045,  0.8311,\n",
      "         1.2754, -0.1635,  1.3135,  0.7443,  2.1396,  2.4902,  1.0747, -1.4410,\n",
      "         0.4888, -1.4860,  1.9798,  0.9772,  0.9870,  1.6689,  1.0187,  0.6954,\n",
      "         1.9536,  1.1339,  3.1307,  0.0215,  1.0430,  1.4712,  1.4924,  1.0679,\n",
      "         2.5946,  2.4918, -1.2851,  0.6513,  1.9595,  0.8855, -1.3056,  0.7826,\n",
      "        -0.0234, -1.4028,  1.7645,  1.9974, -1.3009,  1.4402,  0.2100,  3.3943,\n",
      "         0.7172,  0.2969,  0.7296,  2.4615,  1.6075,  1.3370,  0.4995,  1.8224,\n",
      "         0.1843,  0.8124,  0.2329,  1.3963, -0.1270, -1.7974,  1.0824, -0.0758,\n",
      "         1.6112,  0.5145,  0.0505,  1.9634,  1.3193, -1.2716, -2.0724,  0.9465,\n",
      "        -0.2528, -0.0908,  1.6721,  0.0697,  1.3766, -1.3329,  1.1761, -3.2498,\n",
      "        -1.1475,  1.2991,  2.1745,  2.0036,  1.0061,  1.3534,  1.1967,  0.5810,\n",
      "        -1.6846, -0.6705,  1.6336,  0.8804,  1.3761,  0.9462,  0.4955,  1.0630,\n",
      "        -0.1482,  2.5505, -0.8318,  1.7371,  1.4558,  1.3308,  0.4221,  1.7126,\n",
      "         1.8958,  1.5067,  2.3748, -0.0770,  0.8133,  0.7742,  1.8867,  1.8718,\n",
      "        -0.7410,  2.4449,  1.4919, -1.7367,  1.5293,  1.7845,  0.0933, -0.1318,\n",
      "        -0.9205,  0.6265,  1.3232,  0.8955,  0.5533,  0.0143, -0.0528,  0.6458,\n",
      "         0.0751, -1.0705,  0.7856, -2.1976,  1.5190, -0.3230, -1.8393, -0.4325,\n",
      "         1.0479,  1.1214,  0.7070,  1.3303, -1.7346,  0.6800,  0.7055,  1.7238,\n",
      "         0.7624,  2.2498, -0.4733,  1.1196,  0.9769, -1.8373,  0.4548,  1.7069,\n",
      "         2.4657,  0.6791, -0.3503,  0.8553, -0.2117,  3.0567,  1.5794,  1.1481,\n",
      "         0.0458,  0.9874,  0.8213, -0.1050,  1.6600,  0.7162,  1.6548,  0.8560,\n",
      "         1.8059,  2.1108, -0.4442,  1.1102,  0.1401,  1.7681,  1.6331,  1.6804,\n",
      "         1.5002, -1.7725,  0.6060,  3.7479,  0.4369,  1.3927,  1.3448,  0.2186,\n",
      "         1.3459, -0.3864,  0.9763,  0.2923,  1.3939,  0.4851, -0.0401, -0.2966,\n",
      "         1.4296,  1.9306,  1.8637, -0.5899,  1.1335,  1.0622,  1.5549,  1.7201,\n",
      "        -0.4415, -0.2331,  0.2944, -0.5707,  1.3826,  0.2664, -0.0501,  1.7986,\n",
      "         2.1802,  2.4128,  1.7233,  1.3254,  0.7149, -0.4927,  3.6835, -0.2829,\n",
      "         1.0383, -0.7006, -0.8892,  0.6322, -1.1151,  1.6800,  1.2787,  1.1938,\n",
      "         0.0654,  0.9526,  1.3171, -0.7708,  2.0656,  1.1353,  1.2383,  2.3441,\n",
      "        -0.6410, -0.1502,  0.5654,  1.9209, -0.1600, -1.6724,  1.5949,  2.0255],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0031]],\n",
      "\n",
      "         [[-0.0550]],\n",
      "\n",
      "         [[-0.0697]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0280]],\n",
      "\n",
      "         [[-0.0465]],\n",
      "\n",
      "         [[-0.0090]]],\n",
      "\n",
      "\n",
      "        [[[-0.0236]],\n",
      "\n",
      "         [[-0.0318]],\n",
      "\n",
      "         [[-0.0384]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0516]],\n",
      "\n",
      "         [[-0.0296]],\n",
      "\n",
      "         [[-0.0128]]],\n",
      "\n",
      "\n",
      "        [[[-0.0264]],\n",
      "\n",
      "         [[-0.0183]],\n",
      "\n",
      "         [[-0.0440]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0222]],\n",
      "\n",
      "         [[-0.0374]],\n",
      "\n",
      "         [[ 0.0074]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0404]],\n",
      "\n",
      "         [[-0.0501]],\n",
      "\n",
      "         [[-0.0153]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0028]],\n",
      "\n",
      "         [[-0.0314]],\n",
      "\n",
      "         [[-0.0479]]],\n",
      "\n",
      "\n",
      "        [[[-0.0418]],\n",
      "\n",
      "         [[-0.0422]],\n",
      "\n",
      "         [[-0.0495]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0201]],\n",
      "\n",
      "         [[-0.0387]],\n",
      "\n",
      "         [[-0.0124]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0501]],\n",
      "\n",
      "         [[-0.0143]],\n",
      "\n",
      "         [[-0.0167]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0038]],\n",
      "\n",
      "         [[-0.0567]],\n",
      "\n",
      "         [[-0.0534]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0341, -0.0308, -0.0251, -0.0266, -0.0237, -0.0396, -0.0485, -0.0293,\n",
      "        -0.0423, -0.0261, -0.0391, -0.0297, -0.0263, -0.0374, -0.0386, -0.0287,\n",
      "        -0.0264, -0.0273, -0.0313, -0.0315, -0.0362, -0.0325, -0.0346, -0.0250,\n",
      "        -0.0360, -0.0405, -0.0323, -0.0217, -0.0317, -0.0389, -0.0401, -0.0308,\n",
      "        -0.0280, -0.0325], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0062]],\n",
      "\n",
      "         [[ 0.0141]],\n",
      "\n",
      "         [[-0.0792]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0365]],\n",
      "\n",
      "         [[-0.0134]],\n",
      "\n",
      "         [[-0.0265]]],\n",
      "\n",
      "\n",
      "        [[[-0.1384]],\n",
      "\n",
      "         [[-0.1034]],\n",
      "\n",
      "         [[-0.1847]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0491]],\n",
      "\n",
      "         [[-0.0975]],\n",
      "\n",
      "         [[-0.0752]]],\n",
      "\n",
      "\n",
      "        [[[-0.0138]],\n",
      "\n",
      "         [[-0.0212]],\n",
      "\n",
      "         [[ 0.0127]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0129]],\n",
      "\n",
      "         [[-0.0007]],\n",
      "\n",
      "         [[-0.0280]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0034]],\n",
      "\n",
      "         [[-0.0158]],\n",
      "\n",
      "         [[ 0.0070]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0180]],\n",
      "\n",
      "         [[-0.0239]],\n",
      "\n",
      "         [[-0.0465]]],\n",
      "\n",
      "\n",
      "        [[[-0.0499]],\n",
      "\n",
      "         [[-0.0243]],\n",
      "\n",
      "         [[ 0.0063]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0077]],\n",
      "\n",
      "         [[-0.0331]],\n",
      "\n",
      "         [[-0.0469]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0240]],\n",
      "\n",
      "         [[-0.0491]],\n",
      "\n",
      "         [[-0.0222]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0095]],\n",
      "\n",
      "         [[-0.0148]],\n",
      "\n",
      "         [[-0.0038]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 3.6612e-01,  6.8375e-01,  1.6584e-01,  2.8680e-01, -1.1994e-01,\n",
      "         2.0567e-02, -2.4630e-01, -2.0131e-01,  1.4985e-01, -1.4756e-01,\n",
      "        -2.6505e-01,  7.2397e-03,  2.5369e-01,  8.2565e-02,  5.6971e-02,\n",
      "        -1.0713e-01,  1.2102e-01,  9.5687e-02,  2.9145e-01, -4.9989e-01,\n",
      "        -5.4797e-02,  3.8999e-01, -8.7092e-02, -1.7389e-01,  1.7172e-01,\n",
      "         2.4978e-01,  3.0160e-01,  2.8653e-02, -1.4614e-01, -1.1223e-01,\n",
      "         5.5432e-01,  5.3971e-01, -3.2491e-01,  1.4887e-01,  7.3278e-02,\n",
      "         4.4916e-01,  1.7409e-01, -7.0403e-02, -2.5454e-02,  6.4781e-01,\n",
      "        -4.5591e-02,  1.8912e-01, -1.7229e-01,  1.0026e-01,  1.4872e-01,\n",
      "         3.2052e-02,  1.5900e-01, -1.8380e-02,  9.0060e-02,  1.6507e-01,\n",
      "         3.1740e-01,  6.0711e-02, -4.7958e-02, -1.8011e-02,  1.0984e-02,\n",
      "         3.6636e-01,  4.3546e-01,  3.4316e-01, -4.4559e-01,  2.2581e-02,\n",
      "        -1.1932e-01,  2.1084e-01, -7.1270e-02, -2.7084e-01,  3.7612e-02,\n",
      "         1.1918e-01, -1.3838e+00, -4.2094e-01,  3.2820e-01,  5.8883e-02,\n",
      "         1.4361e-01, -1.1297e-01, -1.2148e-01, -1.4211e+00, -9.1637e-02,\n",
      "        -9.1243e-02,  7.1525e-02,  3.3622e-01, -1.1567e+00,  2.2662e-01,\n",
      "         9.1288e-02,  1.1763e-01,  7.9693e-02,  9.9201e-02,  1.1428e-01,\n",
      "         4.2698e-01,  5.2420e-01, -2.4740e-01, -2.9309e-01,  2.0207e-01,\n",
      "        -8.9555e-03, -6.7999e-02,  9.9289e-02,  7.1058e-02,  5.9598e-02,\n",
      "        -1.0973e-02,  5.3047e-01,  1.1456e-01,  1.7701e-01,  3.3508e-01,\n",
      "         2.2841e-01, -1.5960e-01, -9.4270e-02,  1.7204e-01, -2.3234e-01,\n",
      "         3.9408e-01, -1.8281e-01, -1.1475e-01,  3.7432e-01, -1.9375e-01,\n",
      "         3.9262e-01, -8.0334e-01, -1.3814e-02, -1.1700e-01,  1.4152e-01,\n",
      "        -3.5154e-01, -1.2605e-02,  1.1469e-01,  1.4286e-01,  1.1254e-01,\n",
      "         4.6499e-01, -1.3809e-01,  1.2156e-01,  2.2276e-01,  4.2171e-02,\n",
      "        -9.9323e-02,  2.7415e-01, -4.2047e-01,  3.9463e-01,  2.0774e-01,\n",
      "        -1.2188e-01,  5.3517e-01, -4.6813e-01,  4.0991e-01, -5.8548e-01,\n",
      "         6.4345e-01,  1.1113e-02, -3.1134e-01,  1.9963e-01,  3.2570e-01,\n",
      "         2.1436e-01, -1.6837e-01, -7.0607e-02,  3.5183e-01, -4.1630e-01,\n",
      "        -1.5613e-01,  1.3886e-01,  5.1603e-02,  3.1031e-01,  3.1805e-01,\n",
      "        -5.8089e-01, -3.8024e-01,  3.2639e-01,  5.1743e-02,  6.3185e-02,\n",
      "        -2.4420e-01, -2.3469e-02, -1.3099e-01,  3.3770e-01,  5.9292e-01,\n",
      "        -2.2699e-01, -6.1660e-02,  4.0019e-02,  3.1673e-01,  4.5256e-01,\n",
      "         4.3529e-01, -8.6793e-02,  8.8479e-02, -2.0340e-01, -1.5282e-01,\n",
      "        -4.3548e-01, -3.6001e-01, -6.0022e-04, -5.6807e-03, -5.1324e-02,\n",
      "        -1.0168e-01,  1.8609e-01,  4.9384e-02,  2.8554e-01, -1.2777e-01,\n",
      "         1.6770e-01,  7.7938e-02, -8.6731e-02, -1.9334e-01,  1.8440e-01,\n",
      "        -1.2770e-01,  6.9485e-01, -2.2793e-02, -5.2783e-02,  4.9566e-01,\n",
      "         1.5408e-01, -5.4411e-02, -5.4656e-01,  1.3381e-01,  1.1986e-01,\n",
      "         3.5446e-02, -2.9573e-01,  3.7067e-02,  4.9801e-01,  9.8751e-02,\n",
      "         2.0387e-01, -1.0487e-01,  1.2929e-01,  6.6686e-01, -6.4272e-02,\n",
      "         2.2906e-01,  1.6772e-01,  2.1853e-01,  3.0282e-01,  2.4939e-01,\n",
      "        -2.7256e-01, -4.1288e-01, -2.9848e-01,  1.6649e-01,  4.6359e-01,\n",
      "         2.3867e-01,  3.2459e-01,  3.3384e-01,  1.6946e-01,  2.1802e-02,\n",
      "        -2.0523e-01, -3.3318e-01, -5.5860e-02, -1.3801e-01,  6.5997e-01,\n",
      "         1.2933e-02,  2.5965e-01,  3.4637e-01,  1.6146e-01,  3.6849e-01,\n",
      "        -4.4109e-01,  4.4831e-01,  2.7105e-01, -2.2810e-01, -4.5907e-02,\n",
      "        -1.5023e-02,  1.8555e-01,  3.2788e-01,  6.2986e-02, -5.3387e-02,\n",
      "         6.4116e-02,  4.7747e-02, -9.8105e-02,  2.1263e-01, -1.0624e+00,\n",
      "         2.2539e-02, -4.3886e-01,  2.3282e-01, -1.6915e-01, -1.2648e-01,\n",
      "        -1.0106e-01,  5.8833e-04, -2.1137e-01,  5.3285e-02, -2.5448e-01,\n",
      "         6.6013e-01,  1.6772e-01,  9.5988e-02, -8.5713e-02,  2.2366e-01,\n",
      "        -2.2479e-01, -4.1643e-02,  3.2708e-01, -5.3023e-01, -4.5375e-02,\n",
      "         7.2499e-02, -6.5544e-02, -3.7589e-01,  7.7566e-02, -1.1163e+00,\n",
      "         4.2534e-01,  1.0778e-01, -1.3036e-01,  5.2947e-01,  1.0129e-01,\n",
      "        -1.9177e-01, -3.6810e-01, -1.7217e-03, -8.1934e-02, -1.1529e-01,\n",
      "        -1.3583e+00,  2.1726e-01,  6.8815e-01,  6.6623e-01,  1.4728e-01,\n",
      "         2.8421e-01,  1.7418e-01,  1.4542e-01, -1.0884e-01, -1.1119e-01,\n",
      "         3.6583e-01,  3.2577e-01, -4.0551e-01, -1.6208e+00, -3.5991e-01,\n",
      "         3.6684e-01,  1.1588e-01, -1.3491e-01,  2.1728e-01,  1.1485e-01,\n",
      "        -4.6868e-01,  8.7942e-01, -1.4568e-01, -1.5620e-01,  2.7949e-02,\n",
      "        -6.1613e-01, -3.5445e-01, -1.6881e-01,  9.7807e-02,  2.7672e-01,\n",
      "        -1.4743e-01,  8.4794e-02,  4.6307e-01,  4.5391e-02, -6.1010e-03,\n",
      "        -1.6416e-01, -5.1391e-01, -2.6364e-02,  3.1978e-02,  5.8239e-01,\n",
      "         5.3065e-01, -1.8780e-02, -2.0800e-01,  8.2474e-02, -3.6456e-01,\n",
      "        -5.2211e-01,  2.7357e-01,  1.4150e-01,  4.9724e-01, -2.4861e-01,\n",
      "        -3.1223e-01, -9.2069e-02, -2.9875e-01, -7.9788e-02, -4.0351e-01,\n",
      "        -4.1783e-01,  3.1780e-01,  8.3696e-02,  4.0820e-01,  7.7448e-03,\n",
      "         2.3746e-01, -1.5929e-01,  4.4458e-01,  4.6383e-01, -3.8220e-02,\n",
      "         5.1647e-01, -7.5840e-02, -2.4887e-01,  1.7870e-01, -1.6366e-01,\n",
      "         1.5315e-01,  1.5978e-02,  1.2078e-01, -1.5553e-01, -2.3835e-01,\n",
      "        -2.6459e-01,  1.6471e-01, -7.9780e-02, -2.9544e-01,  3.8745e-02,\n",
      "         1.2151e-01,  2.2271e-01,  4.1652e-01,  1.0525e-01,  5.9096e-01,\n",
      "        -7.6014e-02,  1.8353e-01,  3.8591e-01, -2.4823e-01,  1.9136e-01,\n",
      "        -9.3277e-02,  3.1090e-01,  1.5419e-01,  5.2590e-02, -6.4602e-01,\n",
      "         1.2338e-01,  1.6758e-01, -1.1480e-01,  3.3344e-01,  5.7758e-02,\n",
      "         2.4219e-01,  8.1637e-01, -8.1809e-02, -1.3058e-01,  5.1162e-01,\n",
      "        -1.4605e-01,  2.2389e-01,  3.5788e-01,  1.8730e-01, -2.6906e-01,\n",
      "        -8.3023e-02,  2.0864e-01, -4.2095e-01,  9.3238e-02, -3.7102e-01,\n",
      "         1.6886e-01,  1.7798e-01, -7.3032e-03, -1.1436e-01,  1.5001e-01,\n",
      "        -3.5346e-01,  2.0281e-01, -2.9061e-01, -2.8177e-01,  1.3616e-01,\n",
      "         3.0562e-02, -2.7099e-02,  3.8886e-01, -6.0137e-01,  2.6954e-01,\n",
      "        -2.0076e-01, -1.3166e-02,  3.7773e-01,  4.1907e-01,  2.1614e-01,\n",
      "         1.2155e-01,  6.5352e-02,  3.8471e-01, -1.4295e-01,  2.5690e-01,\n",
      "         4.1633e-01, -4.6814e-01,  3.4996e-01,  1.8228e-02, -8.9896e-01,\n",
      "         4.4042e-01,  1.9861e-01, -2.0702e-01, -2.2458e-02,  5.5403e-01,\n",
      "        -2.8372e-02, -3.0347e-01, -4.6502e-03,  6.1746e-01, -7.3007e-01,\n",
      "         2.3347e-01, -1.2305e-01,  4.2977e-01,  2.2617e-01, -9.6195e-02,\n",
      "        -7.8658e-02,  3.2761e-01,  2.2241e-01, -4.2387e-03,  2.0516e-01,\n",
      "         4.2864e-03,  1.4737e-01, -8.9560e-02, -1.0679e-01,  5.9047e-02,\n",
      "        -1.8612e-02,  1.4227e-01, -2.5031e-01,  2.1758e-01,  9.0073e-02,\n",
      "        -1.9719e-01, -3.5130e-01,  3.8600e-01, -1.8675e-01,  2.8111e-02,\n",
      "        -2.9075e-01, -1.3415e+00, -3.4038e-03,  1.3161e-01, -3.7207e-01,\n",
      "         1.3655e-01,  4.3631e-01,  4.3436e-01, -2.1949e-01,  3.1074e-01,\n",
      "        -2.9978e-02,  1.2468e-01, -3.0764e-01,  2.8523e-01,  1.9425e-01,\n",
      "         2.5339e-01, -1.3031e-01, -2.4287e-02, -1.4485e-01, -3.1048e-01,\n",
      "         4.7132e-01,  1.1293e-01, -8.5800e-02, -7.9473e-02,  4.3063e-01,\n",
      "         2.4861e-01,  4.7347e-01, -7.0885e-03, -3.8579e-02,  4.9254e-01,\n",
      "        -1.7528e-01, -3.0187e-01, -2.8311e-01,  8.9757e-02, -9.0629e-02,\n",
      "        -1.4828e-01,  2.1778e-02, -2.7573e-02,  2.9075e-01, -1.4955e-01,\n",
      "        -3.2079e-02,  1.7785e-01,  1.1326e-01, -1.0243e-01,  1.2746e-01,\n",
      "         2.9837e-01,  1.4688e-01,  8.7839e-02,  1.0927e-01,  3.9309e-02,\n",
      "         2.9510e-01,  5.6954e-01,  4.2498e-01,  2.1006e-01,  3.6801e-01,\n",
      "         9.7737e-02,  5.1326e-02, -2.1648e-01, -1.9106e-01,  2.4160e-02,\n",
      "         1.4368e-02,  7.3795e-02, -4.3013e-02,  1.6458e-01,  2.0079e-01,\n",
      "        -1.7850e-04,  2.9653e-01, -6.4610e-02,  4.6873e-01, -5.0025e-01,\n",
      "        -1.7596e-01,  1.9123e-01, -4.7820e-02,  1.2601e-01,  3.5364e-02,\n",
      "         4.2284e-01, -5.8140e-02, -5.5351e-02, -1.4867e-01,  2.9878e-01,\n",
      "        -2.8244e-02, -4.1218e-01,  4.0077e-01,  6.0785e-02,  2.3468e-02,\n",
      "         2.8797e-01,  2.7743e-01,  4.6086e-01,  1.6933e-01,  2.4494e-01,\n",
      "         3.7504e-01,  5.6785e-01,  1.1463e-01,  2.6867e-02,  3.3572e-02,\n",
      "         2.0564e-01,  1.3544e-01,  1.6714e-01,  2.9058e-01, -1.9596e-01,\n",
      "         1.9753e-02,  2.8295e-02,  8.2659e-02,  1.2872e-01,  2.8160e-01,\n",
      "         1.7093e-01, -6.0207e-02,  2.8785e-02,  3.0534e-02,  7.5829e-02,\n",
      "         1.3000e-01, -1.2447e-01, -1.6500e-01, -3.4984e-01, -4.5204e-01,\n",
      "         5.6054e-02,  1.7176e-01,  1.2033e-03, -1.8795e-01, -1.1746e-01,\n",
      "         4.1154e-01,  5.4952e-01, -1.9253e-01, -1.7693e-01, -1.7658e-02,\n",
      "        -1.3281e+00, -2.2150e-01,  1.6022e-01,  2.8029e-01, -2.5120e-01,\n",
      "         2.4428e-02,  1.7822e-01, -6.3783e-01,  1.0351e-01,  7.1795e-02,\n",
      "         1.7586e-01, -3.9054e-02,  8.4432e-02, -2.3017e-02,  1.8671e-02,\n",
      "         3.3803e-01,  1.6643e-02,  1.9817e-01,  2.9703e-01, -9.9528e-02,\n",
      "         1.1063e-01,  1.4871e-01, -4.0178e-03,  4.3754e-01,  3.8189e-01,\n",
      "        -4.0948e-02,  5.4438e-03,  9.9410e-02,  9.8120e-02, -2.8516e-02,\n",
      "        -7.7595e-02,  2.0424e-01,  3.0670e-01, -1.6993e-01,  2.5765e-01,\n",
      "        -2.5059e-01,  5.3927e-02, -8.6662e-02,  4.0945e-01,  2.9669e-01,\n",
      "        -5.6322e-01, -3.6174e-02,  1.9596e-01,  3.2953e-01,  3.8899e-02,\n",
      "        -7.6418e-01,  8.0909e-02, -1.9261e-01, -3.7065e-01,  1.9977e-02,\n",
      "         1.4277e-01, -4.8535e-01,  8.8564e-01, -1.4630e-01, -2.9238e-01,\n",
      "        -3.1419e-02, -2.3245e-01,  1.5795e-01, -5.1549e-02,  3.1289e-01,\n",
      "         5.8480e-01, -4.8078e-02, -5.0579e-02,  1.1620e-01,  2.3543e-01,\n",
      "        -7.4821e-03, -1.5739e-01,  3.7377e-01,  2.2707e-01,  1.8990e-01,\n",
      "         7.2850e-02, -3.0202e-01, -3.6931e-02,  4.3590e-01,  3.5669e-01,\n",
      "         3.9194e-01,  2.0580e-01,  9.5452e-02, -3.2899e-01,  1.4964e-01,\n",
      "        -4.5197e-02,  1.1230e-01, -1.1728e-01,  8.7987e-02, -3.1232e-02,\n",
      "         3.3048e-01,  5.4789e-01,  5.1843e-02,  4.2318e-01,  1.8852e-01,\n",
      "         4.8688e-02,  1.7873e-01, -4.1761e-01, -4.1392e-01,  6.7002e-03,\n",
      "        -3.6937e-01,  2.4504e-01,  6.0460e-01, -3.1409e-01,  2.1800e-01,\n",
      "         2.8088e-01,  4.6087e-01,  2.3713e-01,  1.3673e-01,  7.5001e-01,\n",
      "        -1.8316e-01,  4.8339e-01,  7.2208e-02,  7.1821e-02,  1.5288e-01,\n",
      "        -5.6613e-01,  2.6586e-01, -1.6533e-01,  1.1966e-01,  1.6603e-01,\n",
      "        -5.5817e-01, -5.3828e-01, -9.0954e-01,  2.4002e-02, -1.5400e-01,\n",
      "        -5.3955e-01, -2.5177e-01,  4.5269e-02, -9.8284e-02, -5.5246e-01,\n",
      "        -2.4421e-02,  3.0754e-02,  9.2286e-03,  7.3542e-02,  2.6631e-01,\n",
      "        -2.5623e-01,  8.0779e-02,  7.3678e-02, -3.9751e-01,  1.2621e-01,\n",
      "         1.1909e-01,  1.9182e-01,  5.1430e-01,  9.9953e-02,  7.4391e-03,\n",
      "        -1.1911e-01,  3.2112e-01,  1.6935e-01, -1.6853e-01, -3.9056e-01,\n",
      "        -3.4584e-01,  7.5720e-02, -3.6661e-01,  6.1031e-01,  9.3944e-02,\n",
      "        -2.2565e-01, -2.3771e-01, -2.9003e-01,  2.7826e-01,  1.8974e-01,\n",
      "        -2.4536e-02,  4.5177e-02,  1.7205e-02, -1.1699e-01, -1.6476e-01,\n",
      "         3.2206e-01,  8.6812e-03, -8.1243e-02, -5.0927e-01,  2.6004e-01,\n",
      "        -2.5712e-01,  7.0733e-01,  1.1141e-01,  5.7028e-01, -2.4627e-01,\n",
      "         6.8226e-01, -4.0818e-01,  7.6545e-03,  3.6838e-01,  7.5617e-02,\n",
      "        -3.1700e-01,  2.0881e-01,  6.4512e-02,  7.0490e-02,  3.2689e-01,\n",
      "        -1.9727e-01, -3.4364e-01, -2.1152e-01,  1.6032e-01,  2.4164e-01,\n",
      "         5.3437e-01,  3.9459e-01, -3.3906e-01, -2.5225e-01,  1.0620e-03,\n",
      "         2.2063e-01,  1.7624e-01, -1.6363e+00, -2.4522e-02, -1.9423e+00,\n",
      "         4.2513e-01, -5.9132e-02, -3.8019e-01,  1.2293e-01,  1.1463e-02,\n",
      "         4.8353e-01,  7.8138e-02,  1.3828e-01, -1.4010e-01,  2.8258e-02,\n",
      "         2.8006e-01, -1.0608e-01, -9.9885e-03, -4.0087e-01,  1.1630e-01,\n",
      "         1.3848e-01,  4.4464e-01,  1.1695e-01,  2.7491e-01,  1.1159e-01,\n",
      "         3.2747e-02,  8.0290e-02,  5.5737e-01, -5.3913e-01, -3.6041e-01,\n",
      "         4.0004e-02,  1.8689e-01,  3.2658e-01, -1.2494e+00, -5.3122e-01,\n",
      "        -2.6185e-01, -1.7902e-01,  2.2106e-01,  5.9019e-01,  3.1853e-01,\n",
      "        -6.3621e-03], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0365]],\n",
      "\n",
      "         [[-0.9594]],\n",
      "\n",
      "         [[-0.1931]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2747]],\n",
      "\n",
      "         [[-0.7265]],\n",
      "\n",
      "         [[-0.2421]]],\n",
      "\n",
      "\n",
      "        [[[-0.4858]],\n",
      "\n",
      "         [[ 0.1321]],\n",
      "\n",
      "         [[-0.4711]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5531]],\n",
      "\n",
      "         [[ 0.3489]],\n",
      "\n",
      "         [[-0.6315]]],\n",
      "\n",
      "\n",
      "        [[[-0.7072]],\n",
      "\n",
      "         [[-0.1125]],\n",
      "\n",
      "         [[ 0.3304]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2048]],\n",
      "\n",
      "         [[ 0.1716]],\n",
      "\n",
      "         [[ 0.1277]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1073]],\n",
      "\n",
      "         [[ 1.0892]],\n",
      "\n",
      "         [[ 0.2501]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4482]],\n",
      "\n",
      "         [[ 0.4930]],\n",
      "\n",
      "         [[-0.2869]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2454]],\n",
      "\n",
      "         [[-0.0394]],\n",
      "\n",
      "         [[-0.3405]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0726]],\n",
      "\n",
      "         [[-0.1034]],\n",
      "\n",
      "         [[ 0.1369]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7241]],\n",
      "\n",
      "         [[-0.4652]],\n",
      "\n",
      "         [[-0.4110]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1820]],\n",
      "\n",
      "         [[-0.6857]],\n",
      "\n",
      "         [[ 0.1354]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([3.8345, 7.2581, 4.4648, 5.3195, 4.5764, 4.7719, 7.6228, 4.5455, 6.7417,\n",
      "        6.2109, 3.7648, 4.3929, 8.2965, 4.3256, 5.2627, 4.1802, 3.9577, 4.3239,\n",
      "        4.0789, 3.8290, 3.5721, 5.0706, 4.2582, 4.2595, 5.9773, 4.4557, 3.9206,\n",
      "        4.5081, 3.7411, 4.7430, 5.9193, 5.8960, 4.1558, 3.8329, 4.1578, 4.4492,\n",
      "        3.4152, 3.7978, 7.2615, 3.7719, 3.7618, 7.4679, 4.3082, 7.0377, 6.5850,\n",
      "        4.6135, 3.8137, 3.7360, 3.8432, 4.5059, 3.1065, 4.6513, 3.8419, 4.1864,\n",
      "        4.1704, 3.8134, 4.5271, 4.8536, 3.9109, 4.0842, 3.8233, 4.7277, 4.1747,\n",
      "        4.4080, 3.6680, 4.4933, 4.4910, 4.0485, 4.7673, 4.7232, 6.0956, 3.7973,\n",
      "        7.6534, 4.2953, 4.7861, 4.1175, 4.8727, 4.7248, 4.3173, 5.1105, 4.4190,\n",
      "        4.6031, 4.8778, 4.7783, 4.4014, 3.3198, 4.1918, 4.4824, 4.0543, 4.8807,\n",
      "        4.2661, 4.3255, 5.1396, 8.1649, 6.6943, 3.7932, 4.5494, 4.0644, 3.3655,\n",
      "        5.0144, 3.9267, 4.3000, 2.6939, 4.7289, 4.1325, 4.7882, 4.9788, 3.8583,\n",
      "        4.1822, 4.2405, 4.8373, 3.8571, 4.9027, 3.4027, 5.1846, 7.8796, 4.6611,\n",
      "        4.1848, 4.9457, 4.2913, 4.2406, 4.7578, 5.3624, 4.3648, 3.5259, 4.3014,\n",
      "        4.8141, 5.0368, 3.8598, 4.1498, 6.8944, 4.1139, 4.8313, 5.9158, 4.3627,\n",
      "        4.1543, 4.2963, 3.5330, 4.2726, 5.1545, 3.4300, 5.5235, 4.4958, 4.4167,\n",
      "        5.0935, 5.0264, 3.6911, 4.1543, 4.1886, 5.1603, 4.0730, 5.7967, 5.5952,\n",
      "        6.1898, 3.9701, 4.6740, 4.5273, 3.3742, 7.4882, 3.7410, 4.5940, 4.8930,\n",
      "        4.8466, 4.7537, 4.4806, 4.8296, 4.0667, 4.0121, 3.9265, 4.8237, 3.9352,\n",
      "        4.5249, 4.6264, 3.4555, 6.4360, 4.5639, 4.3393, 4.3558, 5.7772, 4.7241,\n",
      "        4.0010, 4.6423, 5.1517, 4.2304, 3.9152, 4.7133, 4.3306, 6.9342, 3.8582,\n",
      "        5.1603, 4.0946, 4.6992, 4.7665, 4.4589, 4.2079, 3.9324, 5.4621, 5.1450,\n",
      "        3.8372, 4.1372, 4.3016, 4.0348, 5.3105, 5.6001, 4.7858, 6.2111, 4.1780,\n",
      "        4.2105, 4.1057, 4.5579, 5.8377, 4.1482, 4.5973, 4.0572, 5.3692, 4.1040,\n",
      "        4.9445, 4.6342, 3.6194, 4.3959, 5.6129, 4.1924, 5.9007, 4.5342, 4.8065,\n",
      "        4.0721, 4.0474, 3.4250, 4.2725, 3.6194, 4.7551, 4.0083],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.9088e-03,  6.0768e-03, -1.2763e-03, -4.7418e-04, -1.2651e-03,\n",
      "        -2.5908e-03, -1.1253e-02,  2.1444e-03, -3.5803e-03,  8.0940e-03,\n",
      "        -3.4058e-03,  1.1407e-02, -8.6072e-03,  3.5788e-03,  1.2180e-03,\n",
      "         6.0820e-04,  2.5135e-04,  3.7789e-03, -1.7474e-03, -7.4757e-03,\n",
      "        -2.1157e-03,  5.8688e-03,  6.6660e-03, -7.6368e-03,  1.7423e-03,\n",
      "         4.6727e-03,  3.5506e-03, -7.0888e-03, -3.5752e-03, -1.2572e-04,\n",
      "        -3.1633e-03, -1.4880e-03,  1.3959e-03, -2.4770e-03,  3.6427e-04,\n",
      "        -6.2935e-03, -3.0188e-03, -1.0819e-04,  4.6192e-03, -3.7814e-03,\n",
      "        -3.2826e-03,  1.5568e-03, -3.3022e-03,  4.9077e-04,  1.5785e-03,\n",
      "        -8.3013e-03,  6.9219e-06, -5.4292e-03,  6.1746e-03, -4.5483e-03,\n",
      "         4.0077e-03,  3.5113e-03, -3.9522e-03, -4.5119e-03,  2.0936e-05,\n",
      "        -9.7319e-04, -2.9523e-03,  6.9419e-03, -5.5023e-05,  3.5057e-03,\n",
      "        -2.5551e-03,  3.7577e-03, -1.7151e-03, -7.6802e-03,  1.2592e-03,\n",
      "        -1.4908e-03, -5.5830e-03,  6.8761e-04,  2.7539e-03, -1.5274e-03,\n",
      "        -1.1294e-02, -3.0033e-03, -2.0372e-02,  4.3409e-03, -4.1261e-03,\n",
      "        -1.8631e-03, -3.1073e-03,  3.0091e-03,  5.5499e-03, -4.3053e-03,\n",
      "        -3.9043e-03,  3.2130e-03, -2.6998e-03,  1.6366e-05,  9.8151e-03,\n",
      "        -1.6255e-03,  3.1628e-03,  4.2113e-03, -6.7115e-03,  2.2542e-03,\n",
      "         2.4725e-03,  3.0360e-03, -1.0435e-03, -1.7653e-02, -3.5317e-04,\n",
      "        -1.1127e-03,  1.2714e-03,  2.9741e-03,  5.3129e-03,  7.6850e-03,\n",
      "         2.9337e-03, -8.6363e-03,  3.0549e-03, -1.1940e-03,  3.3943e-05,\n",
      "        -1.1920e-03,  5.6055e-03, -3.2039e-03,  8.4937e-04,  3.5215e-03,\n",
      "        -1.0378e-03, -4.8356e-03, -7.4100e-03, -1.4574e-03, -4.5811e-03,\n",
      "         1.3851e-02,  3.5295e-03, -7.3588e-03, -1.0417e-03, -1.4317e-03,\n",
      "        -6.4577e-03, -1.3487e-03,  1.0317e-02, -1.6312e-04,  5.0258e-03,\n",
      "         1.6946e-03,  2.2185e-03,  5.5419e-03,  2.3511e-03, -1.0895e-03,\n",
      "         6.7429e-04, -4.1557e-03, -6.0282e-04,  7.5830e-03, -1.7899e-03,\n",
      "         6.6874e-03,  9.6159e-04, -8.6676e-04, -2.0139e-03,  1.7274e-03,\n",
      "        -5.9710e-03,  5.0245e-03, -4.2164e-03,  7.1016e-03, -9.8919e-03,\n",
      "         7.4239e-03,  4.8240e-03,  1.2627e-02, -3.3644e-04,  3.4418e-04,\n",
      "        -1.5836e-03, -3.0242e-03,  4.6852e-03, -8.4696e-03,  3.3602e-03,\n",
      "         2.2825e-04, -7.4506e-03,  1.1621e-03,  1.5986e-02,  6.3384e-04,\n",
      "         3.8481e-03,  3.4488e-03, -2.2724e-03, -8.2744e-03, -1.2013e-03,\n",
      "         4.2981e-03,  1.0303e-03, -7.6720e-03,  5.6253e-04, -1.1173e-02,\n",
      "         2.3640e-03, -2.0676e-04,  1.7991e-03, -1.9630e-04,  2.7472e-03,\n",
      "         4.5489e-03, -3.2097e-03, -2.9584e-03, -3.6885e-03, -1.8404e-04,\n",
      "        -2.2867e-03, -7.8494e-03,  4.2475e-03, -5.1743e-03, -2.0306e-03,\n",
      "         1.1008e-03,  6.7341e-05,  4.9516e-03,  7.7475e-04,  5.0883e-03,\n",
      "        -1.2681e-03,  9.6213e-03, -2.8638e-04,  4.7650e-03,  4.5096e-03,\n",
      "         1.0143e-03,  1.3324e-03, -1.1393e-02, -2.1222e-03, -2.0461e-03,\n",
      "         1.5484e-03,  8.6468e-03, -2.9582e-03, -6.5198e-03,  5.0115e-04,\n",
      "        -9.6265e-03, -8.7247e-04, -1.0488e-03,  3.9470e-05, -7.7526e-03,\n",
      "        -9.3293e-03,  1.1128e-03, -4.6159e-04, -1.1401e-03, -1.6279e-03,\n",
      "         1.4143e-03,  3.9700e-03,  5.3183e-03, -1.4216e-02, -4.5649e-03,\n",
      "        -3.3995e-03,  3.1491e-03, -1.3079e-03,  5.0651e-03, -8.7576e-04,\n",
      "        -2.3698e-03, -1.8569e-03, -1.6794e-03, -3.0673e-03,  4.0028e-03,\n",
      "         1.1550e-04, -2.5682e-03], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.4648]],\n",
      "\n",
      "         [[-0.2398]],\n",
      "\n",
      "         [[ 0.1537]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0953]],\n",
      "\n",
      "         [[ 0.2033]],\n",
      "\n",
      "         [[ 0.2915]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6004]],\n",
      "\n",
      "         [[-0.4349]],\n",
      "\n",
      "         [[ 0.2759]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1218]],\n",
      "\n",
      "         [[-0.0486]],\n",
      "\n",
      "         [[-0.0715]]],\n",
      "\n",
      "\n",
      "        [[[-0.1522]],\n",
      "\n",
      "         [[ 0.0527]],\n",
      "\n",
      "         [[-0.0691]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3941]],\n",
      "\n",
      "         [[ 0.6448]],\n",
      "\n",
      "         [[-0.3797]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2093]],\n",
      "\n",
      "         [[ 0.5822]],\n",
      "\n",
      "         [[ 0.3004]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5581]],\n",
      "\n",
      "         [[-0.1264]],\n",
      "\n",
      "         [[-0.0911]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1122]],\n",
      "\n",
      "         [[ 0.6957]],\n",
      "\n",
      "         [[ 0.5668]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5820]],\n",
      "\n",
      "         [[-0.2444]],\n",
      "\n",
      "         [[ 0.4136]]],\n",
      "\n",
      "\n",
      "        [[[-0.5902]],\n",
      "\n",
      "         [[ 0.2855]],\n",
      "\n",
      "         [[-0.0457]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7896]],\n",
      "\n",
      "         [[-0.1559]],\n",
      "\n",
      "         [[-0.4030]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.4167, 0.5433, 0.2056,  ..., 0.1994, 0.4823, 0.5531], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.9456,  0.0833, -0.0480,  ..., -0.3554, -0.1537, -0.0217],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.3864, -0.2431, -0.0398,  0.0874,  0.5341],\n",
      "          [-0.4767, -0.0806,  0.1543,  0.1140,  0.2792],\n",
      "          [-0.2745, -0.2484, -0.3492,  0.0094,  0.2213],\n",
      "          [-0.2888, -0.2005, -0.4775, -0.2208, -0.2493],\n",
      "          [-0.2529, -0.1875, -0.4468, -0.4521, -0.3894]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3615,  0.3507,  0.0238, -0.2199, -0.0188],\n",
      "          [ 0.1984,  0.3764, -0.1003, -0.3189,  0.1535],\n",
      "          [ 0.0552,  0.1492,  0.1002,  0.4469,  0.3861],\n",
      "          [-0.0364, -0.0680,  0.1463,  0.6050,  0.8261],\n",
      "          [-0.3055, -0.2016, -0.0773,  0.3639,  0.5091]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4101,  0.3094,  0.0878, -0.3506, -0.6822],\n",
      "          [ 0.1525, -0.2172, -0.4856, -0.6414, -0.8172],\n",
      "          [ 0.5453,  0.2219, -0.0618, -0.3466, -0.3073],\n",
      "          [ 0.2570,  0.0038, -0.0418, -0.0126,  0.0608],\n",
      "          [-0.2250, -0.3192, -0.3151, -0.0823,  0.0679]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0045,  0.1962,  0.3198,  0.1953,  0.1992],\n",
      "          [-0.0775, -0.1985, -0.0801, -0.2445, -0.1321],\n",
      "          [-0.4570, -0.5783, -0.8290, -0.6417, -0.3242],\n",
      "          [-0.4307, -0.4120, -0.3972, -0.3574, -0.2105],\n",
      "          [-0.1467,  0.0407,  0.1490,  0.1521,  0.0928]]],\n",
      "\n",
      "\n",
      "        [[[-0.0248,  0.0480,  0.4761,  0.4806,  0.5347],\n",
      "          [-0.5852, -0.2975,  0.1913,  0.2670,  0.3476],\n",
      "          [-0.2735,  0.0875,  0.1977,  0.1224,  0.2134],\n",
      "          [ 0.1719,  0.2976,  0.0148, -0.3172, -0.1393],\n",
      "          [-0.0517, -0.1592, -0.6479, -0.7780, -0.2468]]],\n",
      "\n",
      "\n",
      "        [[[-0.1670, -0.4478,  0.0902, -0.1894, -0.6595],\n",
      "          [ 0.5959, -0.0349, -0.0349,  0.0957,  0.0063],\n",
      "          [ 0.8259,  0.1775, -0.7412, -0.0432,  0.2861],\n",
      "          [ 0.2003,  0.0797,  0.0428, -0.1638, -0.2842],\n",
      "          [-0.3857, -0.3981,  0.0321, -0.0681,  0.0208]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.9074, 1.5307, 2.5887,  ..., 0.9957, 2.2776, 1.6158], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.8760, -1.6301, -1.0675,  ..., -0.5727, -1.3384, -1.0466],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2094]],\n",
      "\n",
      "         [[-0.0559]],\n",
      "\n",
      "         [[-0.5298]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0867]],\n",
      "\n",
      "         [[-0.3735]],\n",
      "\n",
      "         [[ 0.1208]]],\n",
      "\n",
      "\n",
      "        [[[-0.0921]],\n",
      "\n",
      "         [[-0.2032]],\n",
      "\n",
      "         [[-0.2987]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1627]],\n",
      "\n",
      "         [[-0.1345]],\n",
      "\n",
      "         [[ 0.0680]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0951]],\n",
      "\n",
      "         [[-0.0418]],\n",
      "\n",
      "         [[ 0.1862]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1621]],\n",
      "\n",
      "         [[-0.4275]],\n",
      "\n",
      "         [[-0.1425]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1014]],\n",
      "\n",
      "         [[-0.0610]],\n",
      "\n",
      "         [[-0.2644]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0349]],\n",
      "\n",
      "         [[ 0.0658]],\n",
      "\n",
      "         [[ 0.0893]]],\n",
      "\n",
      "\n",
      "        [[[-0.2371]],\n",
      "\n",
      "         [[-0.2100]],\n",
      "\n",
      "         [[-0.1188]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1743]],\n",
      "\n",
      "         [[-0.1624]],\n",
      "\n",
      "         [[-0.5517]]],\n",
      "\n",
      "\n",
      "        [[[-0.2271]],\n",
      "\n",
      "         [[-0.1750]],\n",
      "\n",
      "         [[-0.5038]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3834]],\n",
      "\n",
      "         [[-0.0470]],\n",
      "\n",
      "         [[-0.0650]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1947,  0.2348, -0.1465, -0.2037, -0.2989, -0.2614, -0.2185,  0.2087,\n",
      "         0.0883,  0.2517,  0.3724,  0.2249,  0.1053,  0.1677, -0.1032, -0.0644,\n",
      "         0.0504, -0.3389, -0.2049, -0.2084,  0.0506,  0.1781,  0.2445,  0.0136,\n",
      "         0.1348,  0.0881,  0.1701,  0.0569, -0.3205,  0.0766,  0.0907,  0.0842,\n",
      "        -0.0945,  0.2451,  0.0667,  0.1276,  0.1155,  0.3003, -0.1976, -0.2452,\n",
      "         0.1478,  0.2748,  0.0344, -0.1187,  0.2645, -0.1146,  0.0493,  0.3982,\n",
      "         0.3034, -0.1636, -0.2630,  0.2294,  0.0451, -0.2649,  0.0966, -0.1725,\n",
      "         0.0027, -0.2459], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1990]],\n",
      "\n",
      "         [[ 0.1916]],\n",
      "\n",
      "         [[-0.2359]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0396]],\n",
      "\n",
      "         [[ 0.1397]],\n",
      "\n",
      "         [[ 0.0160]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1235]],\n",
      "\n",
      "         [[ 0.0202]],\n",
      "\n",
      "         [[ 0.1472]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0006]],\n",
      "\n",
      "         [[ 0.1959]],\n",
      "\n",
      "         [[ 0.0668]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1433]],\n",
      "\n",
      "         [[ 0.2120]],\n",
      "\n",
      "         [[-0.0146]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0606]],\n",
      "\n",
      "         [[ 0.2631]],\n",
      "\n",
      "         [[-0.0286]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2661]],\n",
      "\n",
      "         [[-0.2881]],\n",
      "\n",
      "         [[ 0.1592]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0271]],\n",
      "\n",
      "         [[-0.2971]],\n",
      "\n",
      "         [[-0.3322]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0300]],\n",
      "\n",
      "         [[ 0.1634]],\n",
      "\n",
      "         [[ 0.1446]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4956]],\n",
      "\n",
      "         [[-0.2156]],\n",
      "\n",
      "         [[-0.2112]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0965]],\n",
      "\n",
      "         [[ 0.4933]],\n",
      "\n",
      "         [[ 0.4077]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3853]],\n",
      "\n",
      "         [[-0.0819]],\n",
      "\n",
      "         [[-0.0932]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.2763,  0.1615, -0.0041,  ..., -0.2668,  0.3851, -0.0727],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0618]],\n",
      "\n",
      "         [[-0.1931]],\n",
      "\n",
      "         [[-0.5543]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3436]],\n",
      "\n",
      "         [[ 0.9668]],\n",
      "\n",
      "         [[-0.3389]]],\n",
      "\n",
      "\n",
      "        [[[-0.0488]],\n",
      "\n",
      "         [[ 0.0428]],\n",
      "\n",
      "         [[-0.0037]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0754]],\n",
      "\n",
      "         [[ 0.2199]],\n",
      "\n",
      "         [[ 0.2015]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1389]],\n",
      "\n",
      "         [[-0.0875]],\n",
      "\n",
      "         [[ 0.2809]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0141]],\n",
      "\n",
      "         [[-0.1686]],\n",
      "\n",
      "         [[ 0.4198]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0701]],\n",
      "\n",
      "         [[ 0.4179]],\n",
      "\n",
      "         [[ 0.5776]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0125]],\n",
      "\n",
      "         [[-0.5508]],\n",
      "\n",
      "         [[ 0.0740]]],\n",
      "\n",
      "\n",
      "        [[[-0.0317]],\n",
      "\n",
      "         [[-0.0663]],\n",
      "\n",
      "         [[-0.4852]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1216]],\n",
      "\n",
      "         [[ 0.2965]],\n",
      "\n",
      "         [[-0.2521]]],\n",
      "\n",
      "\n",
      "        [[[-0.1487]],\n",
      "\n",
      "         [[-0.4564]],\n",
      "\n",
      "         [[-1.3446]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0103]],\n",
      "\n",
      "         [[ 0.6399]],\n",
      "\n",
      "         [[-0.2400]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.2199, 0.5690, 1.0472, 0.7839, 0.4594, 1.2693, 0.2449, 0.9192, 0.3230,\n",
      "        0.4928, 1.0565, 0.8028, 0.4316, 0.9917, 0.5232, 1.7099, 0.9985, 0.5334,\n",
      "        0.5290, 1.0028, 0.8384, 0.4980, 0.6197, 0.5343, 0.0802, 0.5179, 1.0722,\n",
      "        2.2824, 0.5611, 0.6320, 0.3422, 0.4144, 1.0001, 0.9727, 0.6104, 0.6280,\n",
      "        1.1179, 0.9183, 0.3499, 0.5954, 1.0880, 0.2676, 1.3029, 0.5852, 0.6263,\n",
      "        0.8153, 0.4276, 1.0108, 0.8740, 0.5737, 0.7751, 1.5134, 0.7126, 0.4911,\n",
      "        0.7212, 0.7204, 1.0898, 0.3433, 2.5373, 0.6275, 1.0503, 1.0460, 0.7280,\n",
      "        0.6141, 1.1803, 0.6683, 1.1660, 0.7889, 0.4266, 1.0630, 0.3824, 0.7201,\n",
      "        0.0673, 1.0456, 0.2273, 1.1401, 0.3060, 0.6460, 0.7789, 0.4022, 1.2263,\n",
      "        0.6476, 0.7206, 0.6310, 0.4651, 0.9288, 0.4111, 0.5925, 0.6536, 0.4244,\n",
      "        1.2694, 0.9312, 0.5203, 0.5850, 0.2685, 0.5340, 0.5368, 0.7093, 1.1326,\n",
      "        0.6961, 0.8380, 0.7496, 0.6686, 0.4805, 0.3947, 1.9537, 0.2964, 0.8695,\n",
      "        0.6178, 1.3013, 0.5702, 0.7676, 0.3401, 1.1998, 2.4194, 0.5421, 1.4516,\n",
      "        0.8789, 0.0824, 0.6863, 0.6089, 0.6856, 1.0418, 0.5761, 1.8909, 0.9654,\n",
      "        0.9188, 0.3161, 0.4805, 0.9856, 0.5192, 1.6403, 0.7512, 0.4608, 0.4781,\n",
      "        1.7529, 0.9529, 1.1679, 1.1084, 0.7892, 0.9853, 0.4387, 0.6601, 0.4272,\n",
      "        0.6838, 0.7751, 0.8848, 0.8312, 1.1026, 0.5197, 0.4710, 0.7026, 0.3575,\n",
      "        0.2984, 1.2990, 0.7324, 0.8894, 0.9259, 0.4351, 0.4955, 0.1499, 0.4692,\n",
      "        0.6131, 0.4403, 0.5062, 3.3781, 0.7110, 2.2697, 2.2031, 0.3349, 0.4844,\n",
      "        0.8165, 0.4142, 0.8269, 0.2626, 0.5023, 0.2607, 2.0287, 0.5780, 0.5534,\n",
      "        1.0884, 0.3091, 0.5150, 0.7014, 1.1357, 1.4002, 2.5634, 0.3135, 0.6588,\n",
      "        0.7266, 1.3590, 0.5922, 1.0724, 1.4461, 0.7082, 1.8922, 0.3579, 0.5650,\n",
      "        0.4518, 1.2894, 0.3940, 0.9012, 0.3490, 0.1193, 0.6368, 0.6064, 1.3705,\n",
      "        1.1488, 0.5538, 1.3928, 0.4707, 1.4341, 0.5407, 0.9118, 0.4355, 0.5324,\n",
      "        1.2736, 0.9614, 1.0450, 0.1738, 0.6406, 0.6900, 3.7395, 0.7197, 1.7112,\n",
      "        0.6234, 0.8809, 1.0884, 2.9034, 1.1427, 0.7462, 2.4972],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.8369e-01, -3.2386e-01,  1.2599e-01, -2.9419e-01,  6.5726e-02,\n",
      "         7.2703e-01, -1.1032e-01, -1.4818e-01, -2.2762e-01,  4.6923e-01,\n",
      "        -7.6037e-02, -1.6947e-01,  1.5869e-01,  3.6050e-02,  6.7864e-02,\n",
      "         5.5154e-01, -1.9837e-01, -3.9943e-01, -5.0005e-02,  8.2239e-02,\n",
      "        -5.3477e-01,  2.7307e-01,  7.0717e-02, -3.4553e-01,  6.6912e-02,\n",
      "        -1.6240e-01, -3.8260e-01,  4.2966e-01, -1.8313e-01, -5.9779e-03,\n",
      "         2.3061e-01,  4.4918e-01,  4.1025e-01,  1.9316e-01,  1.0863e-01,\n",
      "        -3.6758e-01,  2.4894e-01, -1.6893e-01,  2.7163e-01, -2.9491e-03,\n",
      "        -2.2993e-01, -5.8201e-01, -4.6145e-02, -6.3336e-02, -3.3043e-01,\n",
      "         3.8314e-01, -3.3993e-01, -5.4393e-01, -1.1807e-01, -1.4297e-02,\n",
      "         7.0726e-02, -1.6085e-01,  1.3439e-01,  4.8741e-02, -5.8398e-01,\n",
      "         6.1125e-02,  2.9355e-01, -2.3496e-02,  5.3634e-02, -1.7666e-01,\n",
      "         2.0440e-01,  2.2545e-01, -1.8260e-02,  4.1901e-01,  1.6982e-02,\n",
      "         2.9479e-01,  8.4695e-02, -1.8850e-01, -1.4347e-01, -4.0684e-01,\n",
      "         2.6454e-01,  5.2951e-01,  2.3353e-01, -2.6513e-01,  2.6277e-01,\n",
      "        -2.7947e-01,  5.2513e-02,  6.6742e-02, -1.7465e-01,  4.2148e-02,\n",
      "        -3.5843e-01,  1.2051e-01,  2.2778e-01,  4.4414e-01,  3.4128e-01,\n",
      "        -4.4133e-01,  3.1377e-01,  1.8432e-01, -1.9840e-01, -2.9101e-01,\n",
      "         3.2238e-01,  1.6686e-02, -4.4955e-02,  3.1052e-01, -3.5149e-01,\n",
      "         5.6449e-01, -5.9506e-01,  3.8654e-01, -4.5845e-01, -6.1975e-01,\n",
      "         1.6274e-01, -4.3751e-03,  1.8187e-02,  1.7431e-01, -2.2774e-02,\n",
      "         6.9083e-01, -1.3544e-01,  7.2895e-02, -4.9474e-01, -5.8542e-01,\n",
      "        -1.7407e-01, -6.7890e-01,  2.6685e-01, -4.1400e-01, -9.0804e-01,\n",
      "        -1.5863e-02,  5.0574e-01, -2.0104e-01, -1.7885e-01,  2.6312e-01,\n",
      "        -3.5857e-01,  6.4470e-02, -4.3758e-01, -1.4889e-01, -1.3068e-01,\n",
      "        -5.8048e-01, -6.8096e-02, -1.5005e-01, -5.6986e-02, -3.4290e-01,\n",
      "        -1.4205e-01,  7.5005e-01, -3.5535e-02,  1.5928e-01, -4.1488e-01,\n",
      "         2.8359e-02,  1.8733e-01, -1.7711e-01,  4.4398e-01,  4.1594e-01,\n",
      "        -8.5614e-02,  2.0745e-01, -4.9739e-01,  1.6314e-01,  3.8110e-01,\n",
      "         3.7758e-02,  3.4152e-01, -1.7317e-01,  4.6394e-01,  1.9017e-01,\n",
      "        -4.7708e-02,  2.5240e-01,  2.0997e-01, -2.1008e-02, -2.0613e-01,\n",
      "        -9.7520e-02, -1.0952e-01, -1.0879e-01,  5.4114e-01,  1.9603e-01,\n",
      "        -2.3581e-02, -1.2576e-01,  2.1565e-01, -2.5698e-01,  4.1333e-01,\n",
      "         1.4473e+00,  1.8813e-01,  4.3754e-01,  5.4280e-01,  4.0756e-04,\n",
      "        -6.1428e-01,  5.0033e-01, -3.4205e-01,  2.6389e-01, -4.5252e-01,\n",
      "         3.3919e-01,  1.4192e-01, -1.1683e+00, -2.7700e-01,  3.4764e-01,\n",
      "         3.6648e-01, -5.1519e-02,  5.3456e-01, -1.9961e-01, -4.8955e-01,\n",
      "         4.8794e-01,  7.7886e-01, -5.1126e-02, -1.5684e-01, -7.7263e-02,\n",
      "        -3.6661e-02,  2.0697e-01, -7.9303e-01,  1.1334e+00,  2.5355e-01,\n",
      "         1.4437e-01,  1.3101e-01,  2.8942e-01,  4.4753e-01,  5.6174e-01,\n",
      "         7.9278e-03,  3.7409e-01, -8.0130e-02, -1.2522e-01, -2.4503e-01,\n",
      "         9.6095e-06,  3.8363e-02, -5.0665e-02, -3.7722e-02, -3.4238e-01,\n",
      "         2.1441e-01, -6.9820e-01, -1.0932e-01, -3.9427e-01,  3.8718e-02,\n",
      "         9.8544e-03,  1.7711e-02, -2.6872e-01,  5.7065e-02,  3.3642e-01,\n",
      "         1.9978e-01,  1.9627e-01,  1.5264e+00,  4.6519e-01,  1.3644e+00,\n",
      "        -2.9630e-01,  4.2887e-01, -5.0112e-01, -3.2005e-01, -8.2282e-01,\n",
      "        -1.1491e-01, -2.7485e-02], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.5659]],\n",
      "\n",
      "         [[ 0.1355]],\n",
      "\n",
      "         [[-0.1312]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2303]],\n",
      "\n",
      "         [[ 0.3105]],\n",
      "\n",
      "         [[ 0.8550]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0790]],\n",
      "\n",
      "         [[-0.1824]],\n",
      "\n",
      "         [[-0.5830]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1180]],\n",
      "\n",
      "         [[-0.0684]],\n",
      "\n",
      "         [[ 0.1190]]],\n",
      "\n",
      "\n",
      "        [[[-0.6721]],\n",
      "\n",
      "         [[ 0.2257]],\n",
      "\n",
      "         [[ 0.2398]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4408]],\n",
      "\n",
      "         [[ 0.0267]],\n",
      "\n",
      "         [[-0.8964]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.7732]],\n",
      "\n",
      "         [[-0.3911]],\n",
      "\n",
      "         [[ 0.7523]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0424]],\n",
      "\n",
      "         [[ 0.5349]],\n",
      "\n",
      "         [[ 0.3043]]],\n",
      "\n",
      "\n",
      "        [[[-0.1522]],\n",
      "\n",
      "         [[ 0.3879]],\n",
      "\n",
      "         [[-0.2767]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1446]],\n",
      "\n",
      "         [[-0.3228]],\n",
      "\n",
      "         [[ 0.2598]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2760]],\n",
      "\n",
      "         [[-0.1910]],\n",
      "\n",
      "         [[ 0.1627]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1439]],\n",
      "\n",
      "         [[ 0.5995]],\n",
      "\n",
      "         [[-0.5781]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.4929, 1.1495, 0.7358,  ..., 1.4529, 1.0582, 1.5006], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.2604, -2.0720, -0.3016,  ..., -1.9693, -0.7467, -1.5616],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2158,  0.0201,  0.0423,  0.3155,  0.3246],\n",
      "          [-0.3361, -0.1620,  0.1542,  0.5714,  0.5075],\n",
      "          [-0.4990, -0.2532,  0.2042,  0.1012,  0.0566],\n",
      "          [-0.4702, -0.4713, -0.3849, -0.2401, -0.1711],\n",
      "          [-0.4405, -0.5619, -0.6460, -0.6387, -0.4923]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1444,  0.0873, -0.0694,  0.0545, -0.1749],\n",
      "          [ 0.1991,  0.3866,  0.6402,  0.6525,  0.0723],\n",
      "          [ 0.0268,  0.2627,  0.6864,  0.4848,  0.2980],\n",
      "          [-0.2053,  0.0595,  0.1621,  0.0841,  0.2147],\n",
      "          [ 0.0217,  0.0674,  0.2153,  0.2760,  0.3106]]],\n",
      "\n",
      "\n",
      "        [[[-0.2546, -0.0536, -0.1552, -0.0629,  0.2872],\n",
      "          [-0.3733, -0.3557, -0.1573,  0.3611,  0.3602],\n",
      "          [-0.5700, -0.5289, -0.5129,  0.0843, -0.0202],\n",
      "          [ 0.3361,  0.2146, -0.0372, -0.1804, -0.4215],\n",
      "          [ 0.4466,  0.1311, -0.1541, -0.5694, -0.7342]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1006,  0.0050,  0.2900,  0.0186,  0.0091],\n",
      "          [-0.0757,  0.0054,  0.1448,  0.0953,  0.0744],\n",
      "          [ 0.0368,  0.2145,  0.4475,  0.4736,  0.4293],\n",
      "          [ 0.0062,  0.1951,  0.3917,  0.3607,  0.3294],\n",
      "          [ 0.0379,  0.2814,  0.4863,  0.5268,  0.4820]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9367,  0.6746,  0.5054,  0.3433,  0.3274],\n",
      "          [-0.2127, -0.2493, -0.0647, -0.0236,  0.1023],\n",
      "          [-0.1551, -0.1754, -0.0295, -0.0859, -0.1780],\n",
      "          [-0.2032, -0.2696, -0.2869, -0.2936, -0.3582],\n",
      "          [-0.2990, -0.3152, -0.1595, -0.0573, -0.1523]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1419,  0.3419,  0.6649,  0.3805, -0.0983],\n",
      "          [-0.1188,  0.0163,  0.4492,  0.4134,  0.1393],\n",
      "          [-0.2527, -0.0083,  0.5120,  0.7747,  0.5646],\n",
      "          [-0.1257, -0.1386,  0.1008,  0.0293,  0.2592],\n",
      "          [-0.0913, -0.0575,  0.1615,  0.0599,  0.1396]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.4616, 1.7746, 2.2953,  ..., 1.9623, 0.9930, 1.4085], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.7109, -1.3919, -1.7535,  ..., -0.6316, -2.5682, -1.2144],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1198]],\n",
      "\n",
      "         [[ 0.0743]],\n",
      "\n",
      "         [[-0.0837]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1783]],\n",
      "\n",
      "         [[ 0.1881]],\n",
      "\n",
      "         [[ 0.1463]]],\n",
      "\n",
      "\n",
      "        [[[-0.1404]],\n",
      "\n",
      "         [[-0.1339]],\n",
      "\n",
      "         [[ 0.2929]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3103]],\n",
      "\n",
      "         [[ 0.1311]],\n",
      "\n",
      "         [[ 0.1377]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1124]],\n",
      "\n",
      "         [[ 0.0353]],\n",
      "\n",
      "         [[ 0.2617]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1008]],\n",
      "\n",
      "         [[ 0.0366]],\n",
      "\n",
      "         [[ 0.2889]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1210]],\n",
      "\n",
      "         [[ 0.1229]],\n",
      "\n",
      "         [[-0.0611]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0204]],\n",
      "\n",
      "         [[ 0.2290]],\n",
      "\n",
      "         [[ 0.1590]]],\n",
      "\n",
      "\n",
      "        [[[-0.0562]],\n",
      "\n",
      "         [[ 0.4549]],\n",
      "\n",
      "         [[ 0.3980]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2415]],\n",
      "\n",
      "         [[ 0.0615]],\n",
      "\n",
      "         [[ 0.1789]]],\n",
      "\n",
      "\n",
      "        [[[-0.0979]],\n",
      "\n",
      "         [[-0.0503]],\n",
      "\n",
      "         [[-0.1371]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1192]],\n",
      "\n",
      "         [[ 0.0934]],\n",
      "\n",
      "         [[-0.0693]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1507, -0.1714,  0.0972,  0.3279, -0.0445,  0.1852, -0.2080,  0.2701,\n",
      "         0.1870, -0.1785,  0.2056, -0.2218, -0.1493, -0.1651,  0.3614, -0.0017,\n",
      "         0.0029, -0.2187, -0.1411, -0.1736, -0.1649, -0.2078,  0.1581,  0.4698,\n",
      "        -0.1712,  0.3539, -0.1685,  0.1456,  0.1704, -0.1534, -0.0773,  0.0777,\n",
      "         0.2683,  0.2463,  0.3407,  0.1856, -0.1557, -0.1725,  0.1649, -0.2606,\n",
      "        -0.1780, -0.1009, -0.1627,  0.4258, -0.1682, -0.1901,  0.0805, -0.2556,\n",
      "         0.1565,  0.1438, -0.0948,  0.1391,  0.4015,  0.0695,  0.1617, -0.1461,\n",
      "        -0.0578, -0.1220], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0087]],\n",
      "\n",
      "         [[ 0.0890]],\n",
      "\n",
      "         [[ 0.3636]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0289]],\n",
      "\n",
      "         [[-0.4160]],\n",
      "\n",
      "         [[-0.1927]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0266]],\n",
      "\n",
      "         [[ 0.3095]],\n",
      "\n",
      "         [[ 0.1708]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1914]],\n",
      "\n",
      "         [[ 0.6459]],\n",
      "\n",
      "         [[-0.1494]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0479]],\n",
      "\n",
      "         [[ 0.1429]],\n",
      "\n",
      "         [[ 0.0732]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0009]],\n",
      "\n",
      "         [[ 0.0816]],\n",
      "\n",
      "         [[-0.1097]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0080]],\n",
      "\n",
      "         [[-0.0912]],\n",
      "\n",
      "         [[-0.2811]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0364]],\n",
      "\n",
      "         [[-0.1939]],\n",
      "\n",
      "         [[-0.0334]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0136]],\n",
      "\n",
      "         [[-0.0152]],\n",
      "\n",
      "         [[ 0.2466]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0381]],\n",
      "\n",
      "         [[ 0.1987]],\n",
      "\n",
      "         [[-0.0217]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0758]],\n",
      "\n",
      "         [[ 0.1565]],\n",
      "\n",
      "         [[-0.2775]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0485]],\n",
      "\n",
      "         [[ 0.0648]],\n",
      "\n",
      "         [[-0.0707]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.0784,  0.2528,  0.1069,  ..., -0.1263,  0.1381, -0.0493],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1561]],\n",
      "\n",
      "         [[-0.5947]],\n",
      "\n",
      "         [[-0.2221]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0143]],\n",
      "\n",
      "         [[-0.4501]],\n",
      "\n",
      "         [[-0.0848]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4095]],\n",
      "\n",
      "         [[ 0.0916]],\n",
      "\n",
      "         [[ 0.2990]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0871]],\n",
      "\n",
      "         [[ 0.2778]],\n",
      "\n",
      "         [[ 0.1173]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3482]],\n",
      "\n",
      "         [[ 0.1107]],\n",
      "\n",
      "         [[ 0.0821]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0216]],\n",
      "\n",
      "         [[ 0.4131]],\n",
      "\n",
      "         [[ 0.1827]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0821]],\n",
      "\n",
      "         [[ 0.3118]],\n",
      "\n",
      "         [[ 0.2309]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1149]],\n",
      "\n",
      "         [[ 0.3168]],\n",
      "\n",
      "         [[ 0.0550]]],\n",
      "\n",
      "\n",
      "        [[[-0.2077]],\n",
      "\n",
      "         [[-0.5060]],\n",
      "\n",
      "         [[-0.3700]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0164]],\n",
      "\n",
      "         [[-0.6656]],\n",
      "\n",
      "         [[-0.0424]]],\n",
      "\n",
      "\n",
      "        [[[-0.3690]],\n",
      "\n",
      "         [[-0.6485]],\n",
      "\n",
      "         [[-0.2387]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0555]],\n",
      "\n",
      "         [[-0.4540]],\n",
      "\n",
      "         [[-0.1661]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.5145, 0.2522, 1.0166, 0.7517, 0.5137, 1.1430, 0.3491, 0.8903, 0.5303,\n",
      "        0.5941, 0.9277, 0.9925, 0.0650, 0.9045, 0.4804, 1.4903, 1.0493, 1.4986,\n",
      "        0.6648, 1.0023, 0.6054, 0.6619, 0.6457, 0.8666, 0.0531, 0.6079, 1.1318,\n",
      "        2.4306, 0.8277, 0.7696, 0.7098, 0.5373, 0.7900, 0.6537, 0.8121, 0.8412,\n",
      "        1.2602, 0.8543, 0.5779, 0.5423, 1.4915, 0.1125, 1.3291, 0.1201, 0.3432,\n",
      "        0.9403, 0.5732, 0.9117, 0.7074, 0.4176, 0.5920, 0.9479, 0.5055, 0.6267,\n",
      "        0.9253, 0.6347, 0.9760, 0.2845, 2.1157, 0.7115, 1.1975, 0.7305, 1.0619,\n",
      "        0.6059, 0.8225, 1.0085, 1.2265, 0.6323, 0.3031, 1.3579, 0.1445, 1.0164,\n",
      "        0.1023, 1.1136, 0.3805, 1.3580, 0.4506, 0.9824, 0.5927, 0.7774, 1.3146,\n",
      "        0.9024, 0.6056, 0.8011, 0.5257, 0.6296, 0.9305, 0.4242, 0.5691, 0.5250,\n",
      "        0.8848, 0.6080, 0.7478, 0.3581, 0.4852, 0.6860, 1.1430, 0.9328, 1.0615,\n",
      "        0.5639, 0.5514, 1.2327, 0.8697, 0.6716, 0.8249, 2.1529, 0.1953, 0.8000,\n",
      "        0.9206, 0.8739, 0.6767, 1.1421, 0.6775, 1.7354, 1.7610, 0.4149, 1.5785,\n",
      "        0.8500, 0.6535, 0.7183, 0.7721, 0.5486, 0.8154, 0.5858, 1.4806, 0.8069,\n",
      "        0.6133, 0.5682, 0.4115, 0.7765, 0.5853, 1.3567, 0.4216, 0.7864, 0.3833,\n",
      "        1.7457, 0.9907, 1.1088, 1.0050, 0.6639, 1.0471, 0.3388, 0.4849, 0.7314,\n",
      "        0.7374, 0.2469, 1.1784, 0.4912, 0.9083, 0.5201, 0.4955, 0.2651, 0.3925,\n",
      "        0.2756, 1.5055, 0.7908, 0.9967, 0.9646, 0.5354, 0.5984, 0.1413, 0.6221,\n",
      "        0.3166, 0.5928, 0.4020, 3.2540, 0.6896, 1.9551, 2.3296, 0.2836, 0.8386,\n",
      "        0.9409, 0.5532, 0.7628, 0.4822, 0.6779, 0.3758, 1.9632, 0.4209, 0.5253,\n",
      "        0.7345, 0.4205, 0.3393, 0.5954, 1.3507, 1.5998, 2.6607, 0.4253, 1.0650,\n",
      "        0.4602, 0.8312, 0.5556, 1.3775, 1.2178, 0.6404, 1.7903, 0.3574, 0.4939,\n",
      "        0.3829, 1.4193, 0.7048, 0.9831, 0.7341, 0.3106, 0.4924, 0.4760, 1.5126,\n",
      "        0.8756, 0.7298, 1.4433, 0.2474, 1.0770, 0.7387, 0.9083, 0.3824, 0.3638,\n",
      "        1.5423, 0.8133, 1.0705, 0.3705, 0.9056, 0.4808, 3.3530, 0.6406, 2.1799,\n",
      "        0.5062, 1.1811, 1.1128, 2.4977, 1.2117, 0.8323, 2.5574],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 4.0764e-01, -3.1487e-01,  2.1226e-01,  1.2838e-01,  9.2116e-02,\n",
      "         3.6397e-01,  3.2561e-02, -9.9481e-02, -3.3026e-01,  4.7984e-01,\n",
      "        -8.9250e-02, -6.4765e-02,  2.1601e-01,  2.4089e-01,  1.0271e-01,\n",
      "         2.1021e-01, -4.0512e-01,  5.9129e-02, -1.0519e-01,  1.3131e-01,\n",
      "        -7.1481e-01,  8.3470e-02,  4.1040e-01, -2.3631e-01,  1.2970e-02,\n",
      "         9.7125e-02, -2.5265e-01,  7.2183e-02, -2.9864e-01,  8.1927e-02,\n",
      "         2.0041e-01,  4.2481e-01,  2.7437e-01,  2.5861e-01, -2.2205e-01,\n",
      "        -2.5675e-01,  2.2887e-01, -3.4106e-01,  9.3658e-02, -1.1399e-02,\n",
      "        -3.5055e-02, -5.4251e-01, -5.4625e-01, -1.7012e-01, -3.3116e-01,\n",
      "         8.1751e-02, -4.9513e-03, -2.8722e-01,  3.5913e-01,  8.4916e-04,\n",
      "         4.2172e-02, -1.4882e-01,  2.1993e-02, -1.1164e-01, -4.1518e-01,\n",
      "         1.3459e-01,  7.8063e-02, -7.4034e-02,  7.9580e-01, -2.5167e-02,\n",
      "         1.9312e-02,  1.9045e-01, -1.0257e-01,  3.0079e-01, -9.2464e-02,\n",
      "         1.2701e-01,  1.1270e-01, -1.6377e-03, -2.6705e-02, -1.6809e-01,\n",
      "         2.1007e-01,  5.1497e-01,  2.8655e-01, -1.5120e-01,  6.0263e-02,\n",
      "        -3.3920e-01,  7.5537e-02,  2.4075e-01, -8.6042e-02,  9.9222e-02,\n",
      "         3.2768e-03,  1.4161e-01,  9.6816e-02,  6.7676e-01,  3.8030e-01,\n",
      "        -6.5918e-01,  1.3856e-01,  3.6179e-01,  8.6373e-02, -1.8063e-01,\n",
      "         5.9413e-02, -1.3182e-01, -8.6123e-02,  1.1283e-01, -2.6044e-01,\n",
      "         1.1464e-01, -1.5108e-01,  3.3198e-01, -2.3851e-01, -6.4553e-01,\n",
      "         2.0028e-01,  7.0167e-02, -9.6989e-03, -2.0879e-01, -1.2160e-01,\n",
      "         7.5734e-01, -6.6544e-02, -9.5930e-02, -3.2462e-01, -2.6268e-01,\n",
      "        -2.7124e-01, -3.3843e-01,  1.0111e-01, -3.1472e-01, -7.6795e-01,\n",
      "        -7.7078e-02,  6.3259e-01,  4.1744e-02, -4.1386e-02,  6.1226e-02,\n",
      "        -3.2911e-01,  1.6478e-01, -3.2218e-01, -4.5063e-01, -1.9686e-01,\n",
      "        -4.5649e-01,  2.0162e-01,  2.8023e-02, -2.4157e-01, -2.1173e-01,\n",
      "        -1.3598e-01,  4.2381e-01, -1.1895e-02,  4.9736e-02, -4.7093e-01,\n",
      "        -4.3379e-01,  2.4922e-01, -2.1664e-01,  2.3870e-01,  2.9566e-01,\n",
      "         1.0454e-01,  2.2949e-01, -2.6768e-01,  1.2373e-01,  5.1009e-01,\n",
      "         3.6778e-02,  4.2280e-01, -1.8480e-01,  3.2603e-01,  7.8312e-03,\n",
      "         2.5029e-02,  1.0544e-01,  1.5329e-01, -3.6315e-02, -3.5307e-01,\n",
      "         1.6535e-01, -6.7264e-02,  1.7128e-02,  6.3332e-01,  3.2577e-01,\n",
      "         2.5539e-02,  8.0419e-03,  9.8425e-02, -3.2597e-01,  4.1846e-01,\n",
      "         1.0058e+00,  1.0451e-01, -2.3445e-02,  7.5853e-01, -1.8655e-01,\n",
      "        -3.7398e-01,  2.0739e-01, -2.6173e-01,  2.2577e-01, -4.9993e-01,\n",
      "         3.6377e-01,  1.5717e-01, -1.0361e+00, -5.4607e-02,  2.2464e-01,\n",
      "         4.8078e-01,  1.2187e-01,  4.2872e-02, -7.9522e-02, -2.2494e-01,\n",
      "         1.2189e-01,  8.8546e-01,  4.7485e-02,  1.3907e-01, -7.8206e-02,\n",
      "        -1.9848e-02,  1.6382e-01, -2.2594e-01,  8.6217e-01, -1.6054e-01,\n",
      "         1.2214e-01, -1.6235e-03,  1.9795e-01,  3.3244e-01,  4.4511e-01,\n",
      "         1.7430e-01,  3.7750e-01,  2.2191e-01, -1.5722e-02, -3.5617e-01,\n",
      "        -7.1427e-02,  2.8830e-01,  1.2440e-01, -2.1433e-01, -1.8404e-01,\n",
      "         9.7537e-02, -2.4943e-01,  6.4407e-02, -2.2170e-01,  1.1048e-01,\n",
      "        -8.9306e-03,  1.5636e-01, -2.9326e-02,  2.5948e-01,  4.6478e-01,\n",
      "         9.8080e-02,  4.0139e-01,  1.2629e+00,  2.5610e-01,  1.1091e+00,\n",
      "        -7.0675e-02,  3.9023e-01, -4.1363e-01, -7.0028e-01, -8.7123e-01,\n",
      "        -1.2924e-01,  4.2475e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.3355]],\n",
      "\n",
      "         [[-0.3996]],\n",
      "\n",
      "         [[-0.6631]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0739]],\n",
      "\n",
      "         [[ 0.1587]],\n",
      "\n",
      "         [[ 0.2224]]],\n",
      "\n",
      "\n",
      "        [[[-0.2989]],\n",
      "\n",
      "         [[-0.0604]],\n",
      "\n",
      "         [[-0.2550]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4115]],\n",
      "\n",
      "         [[-0.0847]],\n",
      "\n",
      "         [[-0.2663]]],\n",
      "\n",
      "\n",
      "        [[[-0.0250]],\n",
      "\n",
      "         [[ 0.1678]],\n",
      "\n",
      "         [[-0.0684]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1388]],\n",
      "\n",
      "         [[ 0.4132]],\n",
      "\n",
      "         [[ 0.4316]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3332]],\n",
      "\n",
      "         [[ 0.3696]],\n",
      "\n",
      "         [[ 0.2736]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2189]],\n",
      "\n",
      "         [[-0.0978]],\n",
      "\n",
      "         [[ 0.3679]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0531]],\n",
      "\n",
      "         [[ 0.0412]],\n",
      "\n",
      "         [[ 0.0604]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5421]],\n",
      "\n",
      "         [[-0.0482]],\n",
      "\n",
      "         [[ 0.1038]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4612]],\n",
      "\n",
      "         [[-0.0815]],\n",
      "\n",
      "         [[-0.0997]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3725]],\n",
      "\n",
      "         [[-0.0592]],\n",
      "\n",
      "         [[ 0.0339]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.2878, 1.2386, 0.6126,  ..., 1.1543, 0.7405, 1.3881], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.3651, -1.3728,  0.1855,  ...,  0.2378, -0.3744, -1.5985],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.3414,  0.3520,  0.2841,  0.4600,  0.4805],\n",
      "          [ 0.3824,  0.4351,  0.4305,  0.4026,  0.4536],\n",
      "          [ 0.3591,  0.4182,  0.4341,  0.4592,  0.5768],\n",
      "          [ 0.2745,  0.1681,  0.1626,  0.0329,  0.1490],\n",
      "          [ 0.1066,  0.0561,  0.0386,  0.0300,  0.0619]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3867,  0.3416,  0.2446,  0.6390,  0.8058],\n",
      "          [-0.3474, -0.2222, -0.1334, -0.6333, -0.2879],\n",
      "          [-0.1503, -0.0273,  0.1538,  0.2498,  0.1511],\n",
      "          [ 0.0497,  0.3132,  0.1700, -0.1969, -0.1998],\n",
      "          [ 0.3816,  0.2099, -0.0744, -0.3376, -0.3439]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1746, -0.2368, -0.4075, -0.2810,  0.0467],\n",
      "          [ 0.0342, -0.3155, -0.3838, -0.1444,  0.0551],\n",
      "          [-0.7150, -0.7888, -0.4981, -0.3019, -0.4225],\n",
      "          [-0.1876, -0.2157, -0.2189, -0.0974, -0.3489],\n",
      "          [-0.2237, -0.2974, -0.3235, -0.3052, -0.4289]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2042,  0.0423,  0.2333,  0.1653,  0.0629],\n",
      "          [-0.3976, -0.1502,  0.1113, -0.0873, -0.0191],\n",
      "          [-0.3360, -0.2588, -0.2297, -0.1486, -0.2931],\n",
      "          [-0.1224, -0.1410, -0.4576, -0.2712, -0.3355],\n",
      "          [-0.2081, -0.3903, -0.6131, -0.6855, -0.6082]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6691,  0.2050, -0.1979, -0.4068, -0.7537],\n",
      "          [ 0.7676,  0.2440, -0.2554, -0.0287, -0.5064],\n",
      "          [ 0.5335,  0.2721, -0.1571,  0.1175,  0.0448],\n",
      "          [ 0.4371,  0.1799,  0.0647,  0.1158,  0.1485],\n",
      "          [ 0.3178, -0.0347, -0.2804, -0.1433, -0.1323]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5127,  0.3590,  0.2018,  0.0748,  0.1361],\n",
      "          [ 0.6170,  0.4842,  0.1028,  0.0941,  0.1980],\n",
      "          [ 0.3174,  0.6349,  0.2964, -0.0248,  0.1361],\n",
      "          [ 0.2071,  0.6051,  0.3895,  0.0172,  0.1234],\n",
      "          [ 0.2336,  0.4037,  0.2708,  0.0501, -0.0104]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([2.6739, 1.6225, 1.8132,  ..., 1.7611, 2.3736, 1.3348], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.5650, -1.2950, -1.6776,  ..., -1.3243, -1.4076, -1.5961],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0938]],\n",
      "\n",
      "         [[-0.0521]],\n",
      "\n",
      "         [[ 0.1288]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0568]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[ 0.0309]]],\n",
      "\n",
      "\n",
      "        [[[-0.8317]],\n",
      "\n",
      "         [[-0.3402]],\n",
      "\n",
      "         [[-0.1056]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1767]],\n",
      "\n",
      "         [[-0.1911]],\n",
      "\n",
      "         [[ 0.1495]]],\n",
      "\n",
      "\n",
      "        [[[-0.2284]],\n",
      "\n",
      "         [[ 0.5239]],\n",
      "\n",
      "         [[-0.2496]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3984]],\n",
      "\n",
      "         [[ 0.1113]],\n",
      "\n",
      "         [[ 0.2686]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.5170]],\n",
      "\n",
      "         [[-0.6110]],\n",
      "\n",
      "         [[-0.4389]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0015]],\n",
      "\n",
      "         [[ 0.1495]],\n",
      "\n",
      "         [[-0.3259]]],\n",
      "\n",
      "\n",
      "        [[[-0.1620]],\n",
      "\n",
      "         [[-0.4450]],\n",
      "\n",
      "         [[ 0.1444]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1110]],\n",
      "\n",
      "         [[-0.4252]],\n",
      "\n",
      "         [[ 0.4283]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0919]],\n",
      "\n",
      "         [[ 0.4400]],\n",
      "\n",
      "         [[-0.1443]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5592]],\n",
      "\n",
      "         [[-0.0133]],\n",
      "\n",
      "         [[-0.0448]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.2565,  0.0659,  0.0518, -0.0071, -0.0619, -0.2060, -0.1134,  0.0115,\n",
      "        -0.1799,  0.2066, -0.0785,  0.1763, -0.2895,  0.0478, -0.2040,  0.1889,\n",
      "         0.1602,  0.1435, -0.2035,  0.0686, -0.1509, -0.0497, -0.1824, -0.2457,\n",
      "        -0.2229, -0.2049,  0.2840, -0.1637,  0.0732,  0.4344,  0.4721, -0.1493,\n",
      "         0.1590, -0.2354, -0.0601,  0.3633, -0.2170, -0.0754, -0.1168, -0.1313,\n",
      "         0.1677,  0.2001, -0.2298,  0.1675,  0.4193, -0.1481,  0.3631,  0.0684,\n",
      "        -0.1568, -0.0338, -0.2017, -0.1906,  0.5234, -0.2425,  0.5814,  0.2658,\n",
      "        -0.1110,  0.0039], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 4.5739e-03]],\n",
      "\n",
      "         [[-1.2980e-02]],\n",
      "\n",
      "         [[-1.0673e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4216e-01]],\n",
      "\n",
      "         [[-4.2220e-02]],\n",
      "\n",
      "         [[-1.1003e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5434e-02]],\n",
      "\n",
      "         [[ 2.7495e-01]],\n",
      "\n",
      "         [[ 7.9111e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3535e-01]],\n",
      "\n",
      "         [[-8.9952e-02]],\n",
      "\n",
      "         [[-1.0522e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9807e-03]],\n",
      "\n",
      "         [[-2.4106e-02]],\n",
      "\n",
      "         [[ 8.1028e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4932e-04]],\n",
      "\n",
      "         [[ 8.1771e-02]],\n",
      "\n",
      "         [[ 6.0873e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.5524e-01]],\n",
      "\n",
      "         [[ 2.7193e-01]],\n",
      "\n",
      "         [[-2.0835e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.0293e-02]],\n",
      "\n",
      "         [[-3.1364e-02]],\n",
      "\n",
      "         [[-4.2653e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1741e-04]],\n",
      "\n",
      "         [[ 1.0202e-01]],\n",
      "\n",
      "         [[-9.0942e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2227e-01]],\n",
      "\n",
      "         [[ 1.7167e-01]],\n",
      "\n",
      "         [[ 2.6101e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.1270e-02]],\n",
      "\n",
      "         [[-6.0261e-02]],\n",
      "\n",
      "         [[-9.5022e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.6911e-02]],\n",
      "\n",
      "         [[ 1.7002e-02]],\n",
      "\n",
      "         [[-1.8512e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1290,  0.1490,  0.1044,  ..., -0.1161,  0.2639, -0.1349],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.1384]],\n",
      "\n",
      "         [[ 0.0797]],\n",
      "\n",
      "         [[ 0.1219]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0067]],\n",
      "\n",
      "         [[ 0.1574]],\n",
      "\n",
      "         [[-0.0846]]],\n",
      "\n",
      "\n",
      "        [[[-0.0103]],\n",
      "\n",
      "         [[-0.0264]],\n",
      "\n",
      "         [[ 0.4313]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1827]],\n",
      "\n",
      "         [[ 0.2627]],\n",
      "\n",
      "         [[ 0.0270]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0128]],\n",
      "\n",
      "         [[-0.0297]],\n",
      "\n",
      "         [[ 0.1419]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0090]],\n",
      "\n",
      "         [[ 0.3444]],\n",
      "\n",
      "         [[ 0.0526]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1020]],\n",
      "\n",
      "         [[ 0.4584]],\n",
      "\n",
      "         [[ 0.0551]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1447]],\n",
      "\n",
      "         [[ 0.9969]],\n",
      "\n",
      "         [[ 0.0890]]],\n",
      "\n",
      "\n",
      "        [[[-0.0918]],\n",
      "\n",
      "         [[-0.0999]],\n",
      "\n",
      "         [[ 0.3950]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0858]],\n",
      "\n",
      "         [[ 0.3163]],\n",
      "\n",
      "         [[ 0.0430]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0635]],\n",
      "\n",
      "         [[ 0.0865]],\n",
      "\n",
      "         [[ 0.7972]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0415]],\n",
      "\n",
      "         [[ 0.1647]],\n",
      "\n",
      "         [[-0.0046]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.2458, 0.1996, 1.1627, 0.9036, 0.4891, 1.2203, 0.2510, 0.7094, 0.4562,\n",
      "        0.3945, 1.1089, 1.0239, 0.4685, 0.8320, 0.3367, 1.1895, 1.6268, 1.5755,\n",
      "        0.6865, 0.9704, 1.4527, 0.6711, 0.6065, 0.7618, 0.3406, 0.6452, 0.6879,\n",
      "        1.5699, 1.0714, 1.0015, 0.6490, 0.6047, 0.6602, 0.7449, 0.6642, 1.0712,\n",
      "        1.4611, 0.5701, 0.2209, 0.8773, 1.4761, 0.2406, 1.5326, 0.1122, 0.5512,\n",
      "        0.8457, 0.8803, 1.1395, 1.1684, 0.6356, 0.8417, 1.3805, 0.6778, 0.4738,\n",
      "        0.7183, 0.7292, 0.7309, 0.6755, 2.1026, 1.2213, 1.1640, 0.6588, 0.8814,\n",
      "        0.8608, 0.7749, 0.6446, 1.2504, 0.9955, 0.7843, 1.1705, 0.4961, 1.3052,\n",
      "        0.1158, 0.9135, 0.8371, 1.1986, 0.3375, 0.7884, 0.4920, 0.3366, 1.1024,\n",
      "        0.7406, 0.9290, 0.9287, 0.8141, 0.8871, 0.5642, 0.9739, 0.8126, 0.3216,\n",
      "        1.5682, 0.6561, 0.6955, 0.6542, 0.1608, 0.7108, 0.6375, 0.8347, 0.6456,\n",
      "        0.7280, 0.8254, 1.1148, 0.6397, 0.6980, 1.0516, 1.8549, 0.5649, 0.7460,\n",
      "        0.7065, 0.6609, 0.5941, 1.0744, 0.3737, 1.4542, 2.5236, 0.3062, 1.4157,\n",
      "        1.0061, 0.9354, 0.9984, 1.0712, 0.4839, 0.7972, 0.7531, 1.9388, 1.1243,\n",
      "        0.5889, 0.6183, 1.0137, 1.1197, 0.2201, 1.1835, 0.6468, 0.8363, 0.9231,\n",
      "        1.6434, 0.9515, 1.7785, 1.0910, 1.1472, 1.0957, 0.8748, 0.5800, 0.8655,\n",
      "        0.6032, 0.4773, 1.1396, 0.8817, 1.3070, 0.7789, 0.5492, 0.5567, 0.2937,\n",
      "        0.4720, 1.4043, 0.9626, 0.5517, 0.9471, 0.2621, 0.4952, 0.7362, 0.5563,\n",
      "        0.7590, 0.5098, 0.5998, 3.0387, 1.0090, 1.9198, 2.6664, 0.1539, 1.0543,\n",
      "        0.8855, 0.6128, 1.0444, 0.3858, 0.4561, 0.8418, 2.1917, 0.5489, 0.8260,\n",
      "        0.9861, 0.4361, 0.6877, 0.8352, 1.4883, 1.6244, 2.6260, 0.4093, 0.6697,\n",
      "        0.4486, 1.2795, 0.6287, 1.1691, 1.3642, 0.9403, 1.9436, 0.4911, 0.8468,\n",
      "        0.5720, 1.6948, 0.7452, 0.7915, 0.8122, 0.1664, 0.6150, 0.3236, 1.6577,\n",
      "        0.7355, 0.6710, 1.2914, 0.3306, 1.5962, 0.4545, 0.7738, 0.5001, 0.6859,\n",
      "        0.7018, 0.6194, 1.2002, 0.5273, 0.5949, 0.6601, 3.0835, 0.7205, 2.0013,\n",
      "        1.0994, 1.3302, 1.0272, 2.6209, 1.2987, 0.8092, 2.4422],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.6997e-01, -2.2258e-01, -8.9140e-02, -1.6139e-01,  9.3048e-03,\n",
      "         4.8192e-01,  1.3459e-01, -2.1495e-01, -2.6125e-02,  4.5052e-01,\n",
      "         1.8242e-02,  1.5130e-01,  2.2871e-01, -1.3825e-01,  1.3906e-01,\n",
      "         2.9891e-01, -4.0950e-01, -2.1706e-01,  2.3919e-01, -7.7932e-03,\n",
      "        -5.9794e-01,  1.8614e-01,  1.4697e-01, -3.1433e-01,  2.6114e-01,\n",
      "         3.1143e-02, -2.3633e-01, -2.8914e-01,  1.7970e-01,  3.1349e-01,\n",
      "         3.9333e-01,  5.6051e-01,  1.4352e-01,  1.2718e-01, -1.6923e-01,\n",
      "        -2.2613e-01,  2.7929e-01,  1.3227e-01,  2.4983e-01, -2.7624e-01,\n",
      "        -2.3855e-01, -5.6280e-01, -1.7320e-01, -7.4068e-02, -2.6818e-01,\n",
      "        -1.2301e-01, -8.2379e-02, -2.9287e-01, -1.3293e-01, -2.5181e-02,\n",
      "         8.0306e-02, -1.5050e-01,  5.4810e-02, -1.1927e-01, -2.0030e-01,\n",
      "         1.5737e-01,  3.3701e-01,  2.5977e-02,  4.9763e-01,  1.8813e-01,\n",
      "         2.9673e-01,  1.6976e-01, -1.6741e-01,  2.2049e-01, -3.7683e-01,\n",
      "        -9.9001e-02,  1.0168e-01, -7.1727e-03,  9.7532e-02,  1.8017e-01,\n",
      "         2.6380e-01,  3.1533e-01,  1.8754e-01, -3.6324e-01,  3.9592e-01,\n",
      "        -2.0988e-01,  1.7821e-01,  3.2180e-02,  1.0104e-01,  1.0683e-01,\n",
      "        -3.5113e-01,  9.5777e-02,  1.0302e-01,  3.8062e-01,  2.5176e-01,\n",
      "        -5.0415e-01,  3.3268e-05,  1.8325e-01,  1.7522e-01, -5.0975e-02,\n",
      "         1.8494e-01, -8.0658e-03, -2.6068e-01,  2.0565e-02, -4.5316e-01,\n",
      "         2.5273e-01, -3.2796e-01,  5.2807e-01, -3.4565e-01, -5.3823e-01,\n",
      "         3.6501e-01,  8.8603e-02,  1.1126e-01, -6.8553e-02, -2.9008e-01,\n",
      "         8.6033e-01, -2.6810e-01,  2.4226e-01, -4.0560e-01, -3.1700e-01,\n",
      "        -2.5831e-01, -4.5191e-01,  1.4508e-01, -2.7473e-01, -1.0107e+00,\n",
      "        -1.7869e-01,  7.7137e-01, -1.4446e-02, -2.4097e-02,  5.7741e-02,\n",
      "        -4.9431e-02, -4.1305e-02, -5.0807e-01, -8.5036e-02, -5.6418e-02,\n",
      "        -3.9055e-01,  6.9344e-03, -1.0605e-01, -1.3477e-01, -3.7827e-01,\n",
      "        -4.3399e-01,  5.6158e-01, -1.9505e-01, -4.2509e-02, -2.3847e-01,\n",
      "        -4.4639e-01, -5.3569e-02, -1.3431e-01,  2.2391e-01,  3.8466e-01,\n",
      "        -4.0212e-01,  2.3155e-01, -3.9108e-01, -6.1239e-03,  7.0089e-01,\n",
      "        -1.0511e-01,  3.4704e-01,  1.4360e-01,  2.7370e-01,  7.1667e-02,\n",
      "        -7.5546e-02,  1.4170e-01,  3.0112e-01, -2.3489e-01, -3.3299e-01,\n",
      "         8.4250e-02, -5.4649e-01, -1.8860e-02,  7.9626e-01,  1.4713e-01,\n",
      "         9.3282e-04,  2.0926e-01,  4.7622e-02, -2.8380e-01,  1.7833e-01,\n",
      "         6.2199e-01,  1.6666e-02, -1.8874e-02,  6.1394e-01, -2.4800e-01,\n",
      "        -1.7585e-01,  3.6976e-01, -2.3314e-01,  3.6598e-01, -2.6915e-01,\n",
      "         4.5987e-01,  1.4735e-01, -1.0538e+00, -2.1199e-01,  1.2957e-01,\n",
      "         2.5306e-01, -3.8229e-01,  2.1218e-01, -2.4753e-01, -2.2489e-01,\n",
      "         3.1389e-01,  6.6669e-01, -1.0856e-01, -2.7621e-01, -1.7696e-01,\n",
      "        -3.0866e-02, -1.9565e-01, -2.9156e-01,  9.2836e-01,  1.3913e-01,\n",
      "         5.8437e-02,  2.6794e-01,  4.7874e-02,  2.4206e-01,  4.5178e-01,\n",
      "         4.4269e-02,  4.4474e-01,  2.8834e-01, -1.1461e-01, -7.0145e-01,\n",
      "        -1.4930e-03,  4.6036e-01, -1.4071e-01,  2.7812e-01, -2.1186e-01,\n",
      "         1.9539e-01, -3.0086e-01,  2.1337e-01, -1.8198e-01,  2.5543e-02,\n",
      "        -4.1667e-01,  7.5193e-02, -3.0216e-01,  1.9579e-02,  1.4375e-01,\n",
      "         3.7706e-01,  2.8707e-01,  1.1039e+00,  2.4025e-01,  8.7183e-01,\n",
      "        -1.3603e-01,  2.2096e-01, -3.7616e-01, -2.3023e-01, -4.8236e-01,\n",
      "        -1.8671e-01,  1.4312e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-5.7873e-01]],\n",
      "\n",
      "         [[ 4.6299e-01]],\n",
      "\n",
      "         [[ 1.4223e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0166e-01]],\n",
      "\n",
      "         [[-4.9207e-02]],\n",
      "\n",
      "         [[-4.1139e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7348e-01]],\n",
      "\n",
      "         [[-3.3968e-02]],\n",
      "\n",
      "         [[-3.3301e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.9807e-01]],\n",
      "\n",
      "         [[-3.0386e-01]],\n",
      "\n",
      "         [[-5.4522e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3518e-02]],\n",
      "\n",
      "         [[ 1.0562e-02]],\n",
      "\n",
      "         [[ 2.6211e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3804e-01]],\n",
      "\n",
      "         [[ 2.7516e-02]],\n",
      "\n",
      "         [[-1.1379e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.8651e-02]],\n",
      "\n",
      "         [[-1.2274e-01]],\n",
      "\n",
      "         [[-1.3826e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.9649e-01]],\n",
      "\n",
      "         [[ 7.2493e-02]],\n",
      "\n",
      "         [[ 5.2290e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9540e-02]],\n",
      "\n",
      "         [[-2.4012e-04]],\n",
      "\n",
      "         [[-8.7506e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4832e-01]],\n",
      "\n",
      "         [[ 9.3016e-02]],\n",
      "\n",
      "         [[ 3.3783e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1560e-04]],\n",
      "\n",
      "         [[ 1.2672e-01]],\n",
      "\n",
      "         [[ 2.6011e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1440e-01]],\n",
      "\n",
      "         [[ 8.8763e-03]],\n",
      "\n",
      "         [[ 9.7053e-02]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.4041,  0.5300,  0.6748,  ...,  1.0713,  0.9301,  1.2840],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.3216, -0.5200, -1.0951,  ..., -0.0899, -0.7467, -1.7224],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2317,  0.2368,  0.0924, -0.3713,  0.0673],\n",
      "          [ 0.2628,  0.0486,  0.1467, -0.5649,  0.1089],\n",
      "          [ 0.3053, -0.0068,  0.2835, -0.6711,  0.0591],\n",
      "          [ 0.2869,  0.1357,  0.0174, -0.8068,  0.1557],\n",
      "          [ 0.3223,  0.1337, -0.0530, -0.9840, -0.1886]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2519,  0.2667,  0.4280, -0.1896,  0.1608],\n",
      "          [ 0.2482,  0.0649,  0.5284, -0.0490, -0.1381],\n",
      "          [ 0.3740, -0.0200,  0.5673, -0.3381, -0.4381],\n",
      "          [ 0.6107,  0.2083,  0.0660, -0.4806, -0.4399],\n",
      "          [ 0.4425,  0.0899, -0.5328, -0.5588, -0.4670]]],\n",
      "\n",
      "\n",
      "        [[[-0.3244, -0.2854, -0.2005, -0.2640, -0.2603],\n",
      "          [-0.4049, -0.2554,  0.0995, -0.3276, -0.1935],\n",
      "          [-0.2367, -0.1700,  0.1467, -0.1518,  0.0048],\n",
      "          [-0.2898, -0.3410,  0.0048, -0.2136,  0.0555],\n",
      "          [-0.5131, -0.4897, -0.1315, -0.1752,  0.0235]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0063,  0.5538,  0.4148,  0.4567,  0.1802],\n",
      "          [ 0.1376,  0.8084,  0.3817,  0.2688, -0.0177],\n",
      "          [ 0.1092,  0.4653,  0.0367, -0.0877, -0.1695],\n",
      "          [ 0.2144,  0.4465, -0.0165, -0.1316, -0.0902],\n",
      "          [ 0.2721,  0.2921, -0.2102, -0.1704, -0.1422]]],\n",
      "\n",
      "\n",
      "        [[[-0.0808, -0.1280, -0.0393,  0.3079,  0.3050],\n",
      "          [-0.1297, -0.0777, -0.0916,  0.4105,  0.4077],\n",
      "          [-0.0690, -0.0693,  0.0319,  0.4074,  0.4247],\n",
      "          [-0.1342, -0.0547,  0.1430,  0.3427,  0.5275],\n",
      "          [-0.1569, -0.0953,  0.0439,  0.2268,  0.4661]]],\n",
      "\n",
      "\n",
      "        [[[-0.0360, -0.2447,  0.0043,  0.0896, -0.0444],\n",
      "          [-0.1438, -0.3776,  0.2572,  0.2550, -0.0562],\n",
      "          [-0.2652, -0.3482,  0.2521,  0.3918,  0.1307],\n",
      "          [-0.2629, -0.4513,  0.2601,  0.4137,  0.2623],\n",
      "          [-0.2359, -0.4934,  0.4091,  0.4667,  0.4348]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.4683, 1.8204, 1.4528,  ..., 1.4664, 1.3333, 2.1545], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.4689, -1.2282, -2.8940,  ..., -2.1293, -0.7121, -0.3041],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1766]],\n",
      "\n",
      "         [[ 0.0815]],\n",
      "\n",
      "         [[-0.0247]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2343]],\n",
      "\n",
      "         [[ 0.0181]],\n",
      "\n",
      "         [[-0.1848]]],\n",
      "\n",
      "\n",
      "        [[[-0.0622]],\n",
      "\n",
      "         [[-0.0318]],\n",
      "\n",
      "         [[-0.0089]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1219]],\n",
      "\n",
      "         [[ 0.0902]],\n",
      "\n",
      "         [[ 0.0222]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6131]],\n",
      "\n",
      "         [[ 0.1239]],\n",
      "\n",
      "         [[-0.1272]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2907]],\n",
      "\n",
      "         [[-0.6211]],\n",
      "\n",
      "         [[ 0.2572]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.4999]],\n",
      "\n",
      "         [[ 0.2331]],\n",
      "\n",
      "         [[-0.0293]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1548]],\n",
      "\n",
      "         [[-0.2301]],\n",
      "\n",
      "         [[-0.0197]]],\n",
      "\n",
      "\n",
      "        [[[-0.0539]],\n",
      "\n",
      "         [[-0.0491]],\n",
      "\n",
      "         [[ 0.1901]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1449]],\n",
      "\n",
      "         [[ 0.1265]],\n",
      "\n",
      "         [[-0.3522]]],\n",
      "\n",
      "\n",
      "        [[[-0.1003]],\n",
      "\n",
      "         [[ 0.0879]],\n",
      "\n",
      "         [[ 0.1555]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1087]],\n",
      "\n",
      "         [[ 0.1073]],\n",
      "\n",
      "         [[-0.1537]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1575, -0.1334,  0.2181, -0.1629,  0.0043, -0.2420, -0.2077,  0.0466,\n",
      "        -0.2034, -0.1351,  0.1940, -0.1764, -0.1703, -0.0349, -0.1353, -0.1688,\n",
      "        -0.1680,  0.1753,  0.3612, -0.1980,  0.1885,  0.0539,  0.5340, -0.2036,\n",
      "         0.4333, -0.0580,  0.1682,  0.1715, -0.1417, -0.1848,  0.2179, -0.1792,\n",
      "        -0.1900, -0.1280, -0.0986,  0.0266, -0.1628, -0.2128,  0.2663, -0.1546,\n",
      "         0.2656,  0.2195, -0.1637,  0.5121, -0.1204,  0.0808, -0.1323,  0.2300,\n",
      "         0.5138, -0.2044,  0.1504, -0.1253,  0.2339,  0.2895, -0.1372,  0.0424,\n",
      "        -0.1731, -0.1267], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0858]],\n",
      "\n",
      "         [[ 0.0452]],\n",
      "\n",
      "         [[-0.0404]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1270]],\n",
      "\n",
      "         [[-0.0935]],\n",
      "\n",
      "         [[-0.0251]]],\n",
      "\n",
      "\n",
      "        [[[-0.0968]],\n",
      "\n",
      "         [[-0.0966]],\n",
      "\n",
      "         [[-0.0501]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0154]],\n",
      "\n",
      "         [[-0.2418]],\n",
      "\n",
      "         [[-0.1062]]],\n",
      "\n",
      "\n",
      "        [[[-0.0728]],\n",
      "\n",
      "         [[ 0.0235]],\n",
      "\n",
      "         [[-0.0454]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0715]],\n",
      "\n",
      "         [[-0.0137]],\n",
      "\n",
      "         [[ 0.0066]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0405]],\n",
      "\n",
      "         [[-0.1457]],\n",
      "\n",
      "         [[-0.1140]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0960]],\n",
      "\n",
      "         [[-0.0134]],\n",
      "\n",
      "         [[ 0.0612]]],\n",
      "\n",
      "\n",
      "        [[[-0.1335]],\n",
      "\n",
      "         [[ 0.1218]],\n",
      "\n",
      "         [[-0.1124]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0010]],\n",
      "\n",
      "         [[-0.1116]],\n",
      "\n",
      "         [[-0.2048]]],\n",
      "\n",
      "\n",
      "        [[[-0.1128]],\n",
      "\n",
      "         [[-0.0292]],\n",
      "\n",
      "         [[-0.1135]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0279]],\n",
      "\n",
      "         [[ 0.1319]],\n",
      "\n",
      "         [[ 0.0513]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1705, -0.0984, -0.1816,  ..., -0.1005, -0.1406, -0.1079],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0281]],\n",
      "\n",
      "         [[-0.0406]],\n",
      "\n",
      "         [[-0.1099]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0342]],\n",
      "\n",
      "         [[ 0.0296]],\n",
      "\n",
      "         [[-0.0225]]],\n",
      "\n",
      "\n",
      "        [[[-0.0281]],\n",
      "\n",
      "         [[-0.5442]],\n",
      "\n",
      "         [[-0.0830]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0813]],\n",
      "\n",
      "         [[-0.0078]],\n",
      "\n",
      "         [[-0.0498]]],\n",
      "\n",
      "\n",
      "        [[[-0.0140]],\n",
      "\n",
      "         [[-0.0480]],\n",
      "\n",
      "         [[ 0.1210]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0093]],\n",
      "\n",
      "         [[ 0.0197]],\n",
      "\n",
      "         [[-0.0011]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0791]],\n",
      "\n",
      "         [[ 0.0428]],\n",
      "\n",
      "         [[-0.0240]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0529]],\n",
      "\n",
      "         [[-0.1276]],\n",
      "\n",
      "         [[-0.0399]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0365]],\n",
      "\n",
      "         [[ 0.3413]],\n",
      "\n",
      "         [[ 0.0535]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0264]],\n",
      "\n",
      "         [[-0.0852]],\n",
      "\n",
      "         [[-0.0249]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0449]],\n",
      "\n",
      "         [[ 0.2096]],\n",
      "\n",
      "         [[-0.0062]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0713]],\n",
      "\n",
      "         [[ 0.0942]],\n",
      "\n",
      "         [[ 0.0768]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.4811, 0.3849, 1.0901, 0.9978, 0.7786, 0.9293, 0.0965, 1.1104, 0.7353,\n",
      "        0.5433, 1.3755, 1.1015, 0.2907, 0.6145, 0.6053, 1.8024, 1.6859, 0.9623,\n",
      "        1.2007, 1.1307, 1.3536, 0.8059, 0.6597, 0.7868, 0.5547, 0.6750, 0.7978,\n",
      "        1.4193, 0.8275, 0.8480, 0.8181, 0.7497, 0.6615, 1.3491, 0.7611, 1.1328,\n",
      "        0.8905, 0.6724, 0.2924, 0.9660, 1.3659, 0.0608, 1.2872, 0.0739, 0.6554,\n",
      "        0.7207, 1.1294, 0.8417, 1.0628, 0.7383, 1.1238, 1.0769, 0.6061, 0.5625,\n",
      "        0.9440, 0.6858, 1.3544, 0.9298, 1.5997, 1.6492, 0.9701, 0.3472, 0.7087,\n",
      "        1.1371, 1.0325, 0.6428, 1.1911, 0.6569, 0.6930, 1.2380, 0.7844, 0.8299,\n",
      "        0.4947, 0.7089, 0.7704, 1.0980, 0.5942, 0.9769, 0.7199, 0.5404, 1.1495,\n",
      "        0.9102, 0.7369, 0.7070, 0.7375, 0.8544, 0.7893, 0.6655, 1.1315, 0.7377,\n",
      "        1.2618, 0.7957, 0.8614, 0.6741, 0.4285, 0.8648, 1.2802, 0.9711, 0.6440,\n",
      "        0.6521, 1.0443, 1.3621, 0.6710, 0.8761, 0.7259, 1.6296, 0.8139, 0.7374,\n",
      "        1.1501, 1.2262, 0.5658, 1.0472, 0.6045, 1.4459, 2.0997, 0.2386, 1.6878,\n",
      "        0.8351, 0.7115, 0.6381, 0.9206, 0.8174, 0.7460, 0.9875, 1.8232, 1.2108,\n",
      "        0.9610, 0.6235, 0.6721, 0.9110, 0.7231, 1.5465, 0.6180, 0.6037, 0.7275,\n",
      "        1.3780, 1.2683, 0.9892, 1.2589, 0.7803, 1.2452, 0.4228, 0.5065, 0.9137,\n",
      "        0.7168, 0.7476, 1.2455, 0.9889, 1.4029, 0.8436, 0.4084, 0.6697, 0.6654,\n",
      "        0.5356, 1.7673, 0.8389, 0.9421, 0.7006, 0.2197, 0.8105, 0.5268, 0.5481,\n",
      "        0.5210, 0.6629, 0.6145, 2.5912, 1.1250, 1.7033, 2.3311, 0.2547, 0.9378,\n",
      "        0.7534, 0.4819, 0.7519, 0.3848, 0.5147, 0.5280, 2.0972, 0.6457, 0.7644,\n",
      "        0.9301, 0.6827, 0.5679, 1.3620, 1.5173, 1.4199, 2.6012, 0.3195, 0.6788,\n",
      "        0.6455, 0.8033, 0.6221, 0.9511, 1.0865, 0.6975, 1.4508, 0.3425, 0.6445,\n",
      "        0.7641, 1.4324, 0.9016, 0.6148, 0.6476, 0.3096, 0.7979, 0.2519, 1.5208,\n",
      "        0.8379, 0.8206, 1.1684, 0.2906, 1.3831, 0.6414, 0.9999, 0.4549, 0.8280,\n",
      "        0.6973, 0.8987, 1.5073, 0.8517, 0.6850, 0.5533, 2.8371, 0.9348, 2.1575,\n",
      "        0.6787, 1.2475, 0.7718, 1.9250, 1.0434, 0.8364, 2.1209],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1456, -0.2360,  0.2469, -0.1389,  0.0858,  0.6117,  0.2168, -0.3076,\n",
      "         0.0208,  0.5053, -0.1147,  0.0716,  0.3450, -0.3359, -0.0926,  0.3124,\n",
      "        -0.0090, -0.2220, -0.1267, -0.1558, -0.5339,  0.0659, -0.0954, -0.1155,\n",
      "         0.4704, -0.0666,  0.2724,  0.0793, -0.0182, -0.0353,  0.3371,  0.2241,\n",
      "        -0.0262, -0.0602, -0.0113, -0.3266,  0.5255,  0.1455,  0.0983, -0.0448,\n",
      "         0.0461, -0.3400, -0.1610, -0.0338, -0.1976,  0.1354, -0.0531, -0.4608,\n",
      "        -0.2669, -0.1132, -0.1149,  0.1277, -0.0419,  0.0621, -0.0795,  0.0521,\n",
      "        -0.0796, -0.0415,  0.6795,  0.1161, -0.0990,  0.0428, -0.0806,  0.2314,\n",
      "        -0.0547, -0.0692,  0.2466,  0.2361, -0.3032, -0.1066,  0.1317,  0.0198,\n",
      "         0.1933, -0.6687,  0.1186, -0.3935,  0.3625,  0.2361,  0.0541,  0.1173,\n",
      "         0.0329, -0.1243,  0.0758,  0.3328,  0.1553, -0.3900, -0.0254,  0.2899,\n",
      "         0.2487,  0.0675, -0.0903, -0.1005, -0.2294, -0.0051, -0.3640,  0.0418,\n",
      "        -0.4680,  0.4333, -0.5470, -0.4671, -0.3160,  0.1870,  0.2545,  0.2410,\n",
      "        -0.2570,  0.7422, -0.3011,  0.1747, -0.2062, -0.2083, -0.0283, -0.3239,\n",
      "         0.1790, -0.0570, -0.7931, -0.2621,  0.7266,  0.0451, -0.2398, -0.1062,\n",
      "        -0.2298,  0.0740, -0.4763,  0.0951, -0.1165, -0.1911,  0.1962, -0.1673,\n",
      "        -0.2998,  0.0624, -0.3615,  0.3339,  0.0815, -0.0106, -0.2597, -0.1630,\n",
      "        -0.1717,  0.0231,  0.3824,  0.2519, -0.2413,  0.0390, -0.2143, -0.0017,\n",
      "         0.7705,  0.0033,  0.0982,  0.0401, -0.0165, -0.0035, -0.1011,  0.1391,\n",
      "         0.3350, -0.2361, -0.1537, -0.0760, -0.1213,  0.1715,  0.7558,  0.0263,\n",
      "        -0.3900,  0.0761,  0.1852, -0.2595,  0.2831,  0.4919, -0.0607, -0.0584,\n",
      "         0.6569, -0.2345, -0.2897,  0.2679,  0.0849,  0.0936, -0.4187,  0.4214,\n",
      "        -0.0037, -0.6377,  0.0270,  0.2686,  0.0550, -0.5186,  0.1987, -0.0263,\n",
      "        -0.2363,  0.2510,  0.6513, -0.0388, -0.4396, -0.0594,  0.0646, -0.2482,\n",
      "        -0.3902,  0.5007, -0.0141,  0.2900,  0.3608,  0.1013,  0.1569,  0.2351,\n",
      "        -0.2168,  0.3918,  0.2728, -0.3957, -0.3026, -0.0171,  0.1721, -0.2269,\n",
      "         0.3755, -0.4548,  0.0584, -0.2640,  0.2293, -0.2432, -0.1498, -0.6121,\n",
      "         0.1125, -0.2369, -0.0871,  0.3221, -0.0494,  0.4228,  0.9864,  0.0982,\n",
      "         0.4956, -0.1853, -0.0235, -0.2569, -0.3413, -0.3765, -0.0067,  0.1393],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.3099]],\n",
      "\n",
      "         [[ 0.5437]],\n",
      "\n",
      "         [[ 0.4455]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4596]],\n",
      "\n",
      "         [[ 0.3031]],\n",
      "\n",
      "         [[-0.2496]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3939]],\n",
      "\n",
      "         [[ 0.1976]],\n",
      "\n",
      "         [[ 0.1033]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1753]],\n",
      "\n",
      "         [[-0.2945]],\n",
      "\n",
      "         [[ 0.4401]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2859]],\n",
      "\n",
      "         [[ 0.2340]],\n",
      "\n",
      "         [[-0.3657]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1611]],\n",
      "\n",
      "         [[-0.0520]],\n",
      "\n",
      "         [[ 0.6214]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0546]],\n",
      "\n",
      "         [[ 0.2850]],\n",
      "\n",
      "         [[ 0.0509]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2249]],\n",
      "\n",
      "         [[-0.0563]],\n",
      "\n",
      "         [[-0.1481]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1520]],\n",
      "\n",
      "         [[-0.2026]],\n",
      "\n",
      "         [[ 0.1004]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1259]],\n",
      "\n",
      "         [[ 0.0202]],\n",
      "\n",
      "         [[ 0.4855]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1525]],\n",
      "\n",
      "         [[ 0.6022]],\n",
      "\n",
      "         [[-0.0474]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0088]],\n",
      "\n",
      "         [[ 0.3292]],\n",
      "\n",
      "         [[-0.0461]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.0124, 1.2033, 0.9982,  ..., 1.3437, 1.3133, 0.6170], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-2.0730, -1.9057, -1.0840,  ..., -0.3151, -1.0378, -0.6526],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-5.6722e-01, -6.7875e-01, -5.9369e-01, -4.6809e-01, -2.7016e-01],\n",
      "          [-7.0184e-01, -8.8398e-01, -6.1062e-01, -4.9299e-01, -2.9032e-01],\n",
      "          [-6.1048e-02, -1.7478e-01, -7.5024e-02, -5.1802e-03,  8.7105e-02],\n",
      "          [ 1.6963e-04, -1.3049e-01, -2.9732e-02,  2.0351e-02,  6.4006e-02],\n",
      "          [ 1.1053e-01,  1.4638e-01,  3.8163e-01,  9.4889e-02,  1.7747e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5742e-01,  4.2883e-01,  2.5747e-01,  5.6368e-03, -6.9278e-02],\n",
      "          [ 1.3707e-01,  2.4832e-01,  2.9848e-01, -6.5051e-02, -1.7498e-01],\n",
      "          [-7.4902e-02, -1.8534e-01, -3.7714e-01, -7.2731e-01, -6.5481e-01],\n",
      "          [-8.5592e-02, -4.1484e-01, -6.4972e-01, -4.5718e-01, -2.1221e-01],\n",
      "          [ 1.0642e-01,  2.1237e-01,  2.1932e-01,  1.3097e-01,  3.3743e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2461e-01,  2.8922e-01,  4.3710e-01,  3.7549e-01,  5.1248e-02],\n",
      "          [ 2.6223e-01,  2.4647e-01,  1.6301e-01,  1.6742e-01,  5.1715e-02],\n",
      "          [ 6.4856e-02, -2.8079e-01, -4.5691e-01, -7.3043e-02, -6.0586e-02],\n",
      "          [ 1.9907e-01,  3.4253e-01,  4.6303e-02,  3.8816e-01,  3.8779e-01],\n",
      "          [ 5.8820e-02,  4.5986e-01,  2.3064e-01,  3.0772e-01,  3.7894e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.0103e-01,  1.6212e-01,  1.9456e-01,  2.2577e-01,  1.1937e-01],\n",
      "          [ 3.6364e-01,  4.7478e-01,  2.9653e-01,  2.8772e-01,  1.2302e-01],\n",
      "          [ 7.7771e-01,  6.2748e-01,  5.1345e-01,  6.2944e-01,  4.4720e-01],\n",
      "          [ 2.0607e-01,  3.4073e-01,  2.6679e-01,  1.8048e-01,  2.8273e-01],\n",
      "          [ 3.3986e-02,  4.4027e-02, -9.2880e-03,  1.6890e-02,  1.3747e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.4291e-02,  1.6062e-02, -2.4388e-01,  2.0838e-02,  3.4023e-01],\n",
      "          [-3.8322e-01, -2.5415e-02, -2.6581e-01, -7.1918e-02,  3.6425e-01],\n",
      "          [-2.8030e-01, -6.3143e-02, -3.4834e-01, -2.5564e-01,  3.9954e-01],\n",
      "          [-5.4921e-02, -2.4657e-01, -3.3308e-01, -3.1990e-01,  4.7791e-01],\n",
      "          [ 1.1347e-01, -3.2704e-01, -2.6642e-01, -4.2279e-01,  2.0942e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1123e-01,  2.9220e-01, -4.2488e-02, -4.5874e-01, -6.1891e-01],\n",
      "          [-1.1403e-01,  6.6149e-01,  2.9956e-01, -1.9232e-01, -4.6380e-01],\n",
      "          [-1.1185e-01,  6.2882e-01,  1.4939e-01, -3.3648e-01, -2.1327e-01],\n",
      "          [-5.8871e-02,  3.2630e-01,  5.8102e-02, -3.2385e-01,  1.5134e-02],\n",
      "          [-6.0126e-02,  1.0865e-01, -1.6500e-01, -3.2578e-01, -1.4670e-01]]]],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.1750, 0.9290, 1.2838,  ..., 1.6131, 1.5584, 1.5319], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.6885, -0.9094, -0.6389,  ..., -0.8997, -0.9031, -1.0774],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.3482]],\n",
      "\n",
      "         [[ 0.1632]],\n",
      "\n",
      "         [[ 0.2239]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2664]],\n",
      "\n",
      "         [[ 0.0216]],\n",
      "\n",
      "         [[-0.1079]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0597]],\n",
      "\n",
      "         [[ 0.5942]],\n",
      "\n",
      "         [[ 0.0926]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3192]],\n",
      "\n",
      "         [[-0.0127]],\n",
      "\n",
      "         [[-0.0644]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1614]],\n",
      "\n",
      "         [[ 0.1480]],\n",
      "\n",
      "         [[ 0.2667]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0244]],\n",
      "\n",
      "         [[ 0.1822]],\n",
      "\n",
      "         [[ 0.0875]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1539]],\n",
      "\n",
      "         [[-0.0540]],\n",
      "\n",
      "         [[-0.0878]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0324]],\n",
      "\n",
      "         [[ 0.2212]],\n",
      "\n",
      "         [[-0.2318]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3198]],\n",
      "\n",
      "         [[ 0.1022]],\n",
      "\n",
      "         [[ 0.1656]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2525]],\n",
      "\n",
      "         [[ 0.4253]],\n",
      "\n",
      "         [[-0.1470]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0024]],\n",
      "\n",
      "         [[ 0.1227]],\n",
      "\n",
      "         [[ 0.0096]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1670]],\n",
      "\n",
      "         [[ 0.0852]],\n",
      "\n",
      "         [[-0.1651]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1738, -0.1521, -0.0506, -0.0433, -0.4420,  0.0843,  0.1048,  0.3335,\n",
      "        -0.1129,  0.2411,  0.4111,  0.0121, -0.1662, -0.2023, -0.4860,  0.0236,\n",
      "        -0.0215, -0.0931,  0.0258, -0.0324,  0.4015, -0.2507, -0.1167,  0.3515,\n",
      "        -0.1848, -0.1413,  0.1689,  0.3625,  0.2107,  0.2924, -0.0978,  0.0236,\n",
      "        -0.0254,  0.0990, -0.2916, -0.3838,  0.4075,  0.4328,  0.0327, -0.2570,\n",
      "        -0.0628, -0.0871,  0.2320, -0.1775, -0.2893, -0.1246,  0.0041,  0.3291,\n",
      "         0.0230,  0.1850, -0.1870,  0.1868,  0.1639,  0.0430, -0.1888, -0.0062,\n",
      "        -0.2823, -0.2097], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0108]],\n",
      "\n",
      "         [[-0.3499]],\n",
      "\n",
      "         [[-0.1757]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0956]],\n",
      "\n",
      "         [[-0.2416]],\n",
      "\n",
      "         [[-0.1342]]],\n",
      "\n",
      "\n",
      "        [[[-0.2032]],\n",
      "\n",
      "         [[-0.0411]],\n",
      "\n",
      "         [[-0.0727]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0249]],\n",
      "\n",
      "         [[-0.0102]],\n",
      "\n",
      "         [[-0.0370]]],\n",
      "\n",
      "\n",
      "        [[[-0.2308]],\n",
      "\n",
      "         [[-0.0045]],\n",
      "\n",
      "         [[-0.1224]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1106]],\n",
      "\n",
      "         [[ 0.0446]],\n",
      "\n",
      "         [[ 0.0706]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0949]],\n",
      "\n",
      "         [[-0.0829]],\n",
      "\n",
      "         [[-0.1808]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1648]],\n",
      "\n",
      "         [[-0.0672]],\n",
      "\n",
      "         [[ 0.1355]]],\n",
      "\n",
      "\n",
      "        [[[-0.0635]],\n",
      "\n",
      "         [[ 0.1354]],\n",
      "\n",
      "         [[ 0.1281]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2383]],\n",
      "\n",
      "         [[ 0.1368]],\n",
      "\n",
      "         [[-0.0096]]],\n",
      "\n",
      "\n",
      "        [[[-0.0478]],\n",
      "\n",
      "         [[ 0.0261]],\n",
      "\n",
      "         [[-0.2105]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0422]],\n",
      "\n",
      "         [[-0.1408]],\n",
      "\n",
      "         [[-0.1623]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1399, -0.0817, -0.1208,  ..., -0.0866,  0.0688,  0.1654],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0707]],\n",
      "\n",
      "         [[ 0.0181]],\n",
      "\n",
      "         [[-0.1806]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0890]],\n",
      "\n",
      "         [[-0.1666]],\n",
      "\n",
      "         [[-0.1152]]],\n",
      "\n",
      "\n",
      "        [[[-0.1445]],\n",
      "\n",
      "         [[-0.0311]],\n",
      "\n",
      "         [[ 0.1317]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0347]],\n",
      "\n",
      "         [[-0.0252]],\n",
      "\n",
      "         [[ 0.0060]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1845]],\n",
      "\n",
      "         [[ 0.0339]],\n",
      "\n",
      "         [[ 0.0200]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0632]],\n",
      "\n",
      "         [[ 0.3929]],\n",
      "\n",
      "         [[-0.1974]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1405]],\n",
      "\n",
      "         [[-0.0441]],\n",
      "\n",
      "         [[ 0.0180]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0552]],\n",
      "\n",
      "         [[-0.1617]],\n",
      "\n",
      "         [[-0.0906]]],\n",
      "\n",
      "\n",
      "        [[[-0.0045]],\n",
      "\n",
      "         [[ 0.0058]],\n",
      "\n",
      "         [[-0.1347]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0291]],\n",
      "\n",
      "         [[-0.2441]],\n",
      "\n",
      "         [[ 0.1196]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1354]],\n",
      "\n",
      "         [[ 0.1476]],\n",
      "\n",
      "         [[-0.0552]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0362]],\n",
      "\n",
      "         [[-0.0497]],\n",
      "\n",
      "         [[ 0.4287]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.2865, 0.2723, 1.0755, 1.3668, 0.7227, 1.1413, 0.2615, 1.0763, 0.4866,\n",
      "        0.6045, 1.2885, 0.6561, 0.2402, 0.7760, 0.6000, 1.6059, 0.4974, 1.2074,\n",
      "        0.4754, 1.1910, 1.4507, 0.6948, 0.3875, 0.6130, 0.6143, 1.1257, 1.0412,\n",
      "        1.6400, 1.4078, 0.9932, 0.5424, 0.7683, 0.9488, 0.7303, 0.6530, 1.0549,\n",
      "        0.6754, 0.9111, 0.3665, 1.0507, 1.5326, 0.1089, 1.3713, 0.2195, 0.2896,\n",
      "        1.1216, 0.9524, 0.8864, 1.0915, 0.6674, 1.2024, 0.8490, 0.5571, 0.5419,\n",
      "        0.8811, 0.4216, 0.8314, 0.8554, 1.6116, 0.4502, 1.0717, 0.9912, 0.7064,\n",
      "        1.1966, 0.7580, 0.7518, 1.1341, 1.1880, 1.0151, 0.8521, 0.5134, 0.8808,\n",
      "        0.3172, 0.6423, 0.9349, 1.0594, 0.7669, 1.1240, 0.8016, 1.0811, 1.4332,\n",
      "        0.8703, 0.8218, 0.9252, 1.1440, 1.5932, 0.8676, 0.6337, 0.7669, 0.3325,\n",
      "        1.2946, 1.0400, 0.6563, 0.4936, 0.3680, 0.8809, 1.0651, 0.8024, 0.7466,\n",
      "        0.7866, 1.3930, 1.1696, 0.9371, 0.6007, 0.8186, 1.6938, 0.7228, 1.0011,\n",
      "        0.7645, 0.9271, 0.2726, 1.3316, 0.6785, 1.3014, 1.9551, 0.2448, 1.3496,\n",
      "        0.9148, 0.9862, 0.6314, 1.0801, 0.6524, 0.7763, 0.6667, 1.6089, 1.1315,\n",
      "        0.5522, 0.9205, 1.0680, 1.5065, 0.3393, 1.0972, 1.0093, 0.6132, 0.9415,\n",
      "        1.5221, 1.2948, 0.8678, 1.1562, 0.6834, 1.0909, 0.4016, 0.4993, 0.8784,\n",
      "        0.6916, 0.2754, 1.2651, 0.9075, 1.0898, 0.6058, 0.6494, 0.9427, 0.6029,\n",
      "        0.4639, 1.2275, 0.8747, 1.1417, 1.0842, 0.3801, 1.2269, 0.9634, 0.9288,\n",
      "        0.3439, 0.6204, 0.6070, 1.8416, 1.0132, 1.8673, 2.1029, 0.4806, 1.0658,\n",
      "        0.9211, 1.0521, 1.0979, 0.0844, 0.6285, 0.5737, 1.6360, 0.6648, 1.1190,\n",
      "        1.2505, 1.0186, 0.9191, 0.8586, 1.5823, 1.5517, 1.9686, 0.2371, 0.4043,\n",
      "        0.7124, 0.9998, 0.8420, 1.3478, 1.2657, 0.6095, 1.3124, 0.6140, 0.8381,\n",
      "        1.1822, 1.3994, 1.0560, 0.6685, 0.7492, 0.3999, 1.0868, 0.3577, 1.1997,\n",
      "        1.0568, 1.5291, 1.0469, 0.3007, 1.5173, 0.6843, 1.0008, 0.7631, 0.7009,\n",
      "        0.7302, 1.0698, 1.0810, 0.6133, 0.8692, 0.5253, 2.3577, 0.9843, 1.6132,\n",
      "        0.8361, 0.9816, 1.7586, 1.6998, 0.8902, 1.0343, 2.0088],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1141, -0.3250, -0.1768,  0.0304,  0.0050,  0.3177,  0.0996, -0.0306,\n",
      "        -0.0380,  0.4070, -0.2821,  0.0527,  0.2901,  0.1663, -0.0392,  0.1788,\n",
      "        -0.0785, -0.1052,  0.0359,  0.3251, -0.1810,  0.0569,  0.0117, -0.2406,\n",
      "         0.1504,  0.0925, -0.0537,  0.2889, -0.0788,  0.0932,  0.0925, -0.0526,\n",
      "         0.4138,  0.1855,  0.2837,  0.0320,  0.0760,  0.0388,  0.1105,  0.0424,\n",
      "         0.0771, -0.3865, -0.1708, -0.2407, -0.2799,  0.0239, -0.0832, -0.4786,\n",
      "         0.3263, -0.1762, -0.0589, -0.0794, -0.0677, -0.1625,  0.0688, -0.0082,\n",
      "         0.2594, -0.0614,  0.4872, -0.1490,  0.0235,  0.0320,  0.0075,  0.1457,\n",
      "         0.0042,  0.2166,  0.3573, -0.1652, -0.1867,  0.2258,  0.1837,  0.2862,\n",
      "         0.1944, -0.1434,  0.1906, -0.3455, -0.0290,  0.1411, -0.0186,  0.1541,\n",
      "        -0.0359,  0.1159,  0.1307,  0.1298,  0.1713,  0.1237, -0.1127,  0.2619,\n",
      "        -0.0741, -0.0657,  0.1695,  0.0362, -0.0518, -0.0609, -0.1511,  0.1060,\n",
      "        -0.2346,  0.2829, -0.3122, -0.2642,  0.2138, -0.3030,  0.0080, -0.0592,\n",
      "         0.2602,  0.4017, -0.0975, -0.1595, -0.1612, -0.0512, -0.1466, -0.0840,\n",
      "         0.0998,  0.4957, -0.3657, -0.2126,  0.2563,  0.1155, -0.2223, -0.0229,\n",
      "        -0.1668,  0.0693, -0.2602,  0.0111, -0.1706, -0.3173,  0.1834, -0.0788,\n",
      "        -0.3720, -0.1618, -0.0222,  0.4046, -0.1869,  0.0399, -0.0193,  0.0479,\n",
      "         0.2832, -0.3650,  0.1209,  0.3033, -0.0189,  0.1085, -0.0837, -0.0667,\n",
      "         0.5109,  0.0816,  0.0733, -0.1912, -0.0154, -0.0538, -0.0746,  0.0926,\n",
      "         0.1220,  0.0185, -0.3205,  0.0578,  0.2083,  0.0638,  0.7161,  0.1905,\n",
      "         0.0505,  0.1201,  0.0522, -0.2230,  0.3684,  0.3486, -0.1144, -0.0345,\n",
      "         0.4170, -0.2293, -0.3797,  0.2152, -0.0935,  0.1801, -0.3730,  0.2751,\n",
      "         0.1187, -0.7426, -0.1097,  0.0643,  0.1732, -0.0187,  0.1914,  0.0920,\n",
      "        -0.3173, -0.1199,  0.5814, -0.0966, -0.1593,  0.0923, -0.0791,  0.2693,\n",
      "        -0.4532,  0.2148,  0.1259,  0.1334,  0.1332,  0.1475,  0.0532,  0.2907,\n",
      "         0.1395,  0.3763, -0.0924, -0.1480,  0.0527,  0.0758,  0.2490, -0.0296,\n",
      "         0.1852, -0.5785,  0.1265, -0.1539,  0.0381, -0.3709,  0.1229,  0.1874,\n",
      "         0.0539,  0.2166, -0.1494,  0.1171,  0.2611,  0.3271,  0.9083,  0.1934,\n",
      "         0.7440, -0.1514,  0.0938, -0.1711, -0.4468, -0.3588, -0.1616,  0.5201],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.9273]],\n",
      "\n",
      "         [[-0.2384]],\n",
      "\n",
      "         [[-0.0125]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.8166]],\n",
      "\n",
      "         [[-0.4203]],\n",
      "\n",
      "         [[-0.5599]]],\n",
      "\n",
      "\n",
      "        [[[-0.2727]],\n",
      "\n",
      "         [[-0.0233]],\n",
      "\n",
      "         [[ 0.1579]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3200]],\n",
      "\n",
      "         [[-0.2896]],\n",
      "\n",
      "         [[-0.2688]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3092]],\n",
      "\n",
      "         [[-0.2804]],\n",
      "\n",
      "         [[-0.2231]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1172]],\n",
      "\n",
      "         [[-0.0260]],\n",
      "\n",
      "         [[ 0.3567]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2452]],\n",
      "\n",
      "         [[ 0.0526]],\n",
      "\n",
      "         [[-0.1727]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0082]],\n",
      "\n",
      "         [[ 0.2020]],\n",
      "\n",
      "         [[ 0.2688]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3405]],\n",
      "\n",
      "         [[-0.4711]],\n",
      "\n",
      "         [[-0.1148]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3982]],\n",
      "\n",
      "         [[ 0.1431]],\n",
      "\n",
      "         [[ 0.5696]]],\n",
      "\n",
      "\n",
      "        [[[-0.3497]],\n",
      "\n",
      "         [[-0.3407]],\n",
      "\n",
      "         [[ 0.1526]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1263]],\n",
      "\n",
      "         [[-0.4587]],\n",
      "\n",
      "         [[-0.0701]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.8573, 1.2710, 0.7046,  ..., 0.3313, 1.0790, 0.8897], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.8482, -0.4096,  2.0439,  ..., -1.5648, -1.7109, -0.4901],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2958, -0.5406,  0.1978],\n",
      "          [-0.0161,  0.3204,  0.5708],\n",
      "          [ 0.2965,  0.0877,  0.3998]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5988,  0.2042,  0.1439],\n",
      "          [ 0.4213, -0.0015, -0.2467],\n",
      "          [ 0.1872, -0.1674, -0.4597]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1917, -0.3329,  0.1718],\n",
      "          [ 0.2582, -1.1154, -0.1191],\n",
      "          [ 0.4783,  0.0615,  0.0497]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2063, -0.1896,  0.5322],\n",
      "          [-0.2906, -0.1862,  0.7013],\n",
      "          [ 0.3219,  0.2333, -0.0111]]],\n",
      "\n",
      "\n",
      "        [[[-0.2607, -0.2275, -0.1445],\n",
      "          [-0.1946, -0.2495,  0.0515],\n",
      "          [ 0.5797,  0.5403,  0.2248]]],\n",
      "\n",
      "\n",
      "        [[[-0.2142,  0.1612, -0.1244],\n",
      "          [-0.1070,  1.1565, -0.1132],\n",
      "          [-0.1449, -0.2929, -0.2255]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.1135, 0.8316, 1.8292,  ..., 1.2518, 1.5873, 1.6285], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.6613, -0.3425, -1.2501,  ..., -0.8933,  0.4461, -0.5608],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0324]],\n",
      "\n",
      "         [[-0.2398]],\n",
      "\n",
      "         [[ 0.1026]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1032]],\n",
      "\n",
      "         [[-0.1613]],\n",
      "\n",
      "         [[-0.2614]]],\n",
      "\n",
      "\n",
      "        [[[-0.0106]],\n",
      "\n",
      "         [[-0.0103]],\n",
      "\n",
      "         [[-0.1646]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3530]],\n",
      "\n",
      "         [[-0.1869]],\n",
      "\n",
      "         [[-0.1036]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0387]],\n",
      "\n",
      "         [[ 0.0468]],\n",
      "\n",
      "         [[-0.1180]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0104]],\n",
      "\n",
      "         [[-0.1228]],\n",
      "\n",
      "         [[-0.0975]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1277]],\n",
      "\n",
      "         [[-0.0405]],\n",
      "\n",
      "         [[-0.0551]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4168]],\n",
      "\n",
      "         [[-0.3375]],\n",
      "\n",
      "         [[-0.0715]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2718]],\n",
      "\n",
      "         [[ 0.1723]],\n",
      "\n",
      "         [[-0.2344]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2844]],\n",
      "\n",
      "         [[ 0.1805]],\n",
      "\n",
      "         [[-0.0327]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1552]],\n",
      "\n",
      "         [[-0.0186]],\n",
      "\n",
      "         [[-0.1588]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0359]],\n",
      "\n",
      "         [[-0.0509]],\n",
      "\n",
      "         [[-0.1334]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1506, -0.2055, -0.0899,  0.0307, -0.1137, -0.0171, -0.1273, -0.1076,\n",
      "        -0.1253, -0.2087, -0.0855, -0.1785,  0.1285, -0.0251, -0.0736, -0.2184,\n",
      "        -0.2286, -0.1514, -0.2164, -0.0696,  0.0373, -0.2186,  0.1425, -0.0455,\n",
      "        -0.0224, -0.0903, -0.2243, -0.0664, -0.0038, -0.1077, -0.2051, -0.1706,\n",
      "        -0.2337, -0.1769, -0.1740, -0.2049, -0.0312, -0.1672, -0.1580, -0.2116,\n",
      "        -0.2103, -0.1538, -0.1511, -0.2611, -0.1327, -0.1914, -0.1146, -0.1086,\n",
      "        -0.2367, -0.1717,  0.3633, -0.2278, -0.0901, -0.2132, -0.1628, -0.2377,\n",
      "         0.4883, -0.1471], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0508]],\n",
      "\n",
      "         [[ 0.0941]],\n",
      "\n",
      "         [[-0.1741]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2204]],\n",
      "\n",
      "         [[ 0.5609]],\n",
      "\n",
      "         [[-0.0867]]],\n",
      "\n",
      "\n",
      "        [[[-0.1064]],\n",
      "\n",
      "         [[ 0.0562]],\n",
      "\n",
      "         [[ 0.0226]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1769]],\n",
      "\n",
      "         [[ 0.1720]],\n",
      "\n",
      "         [[-0.1792]]],\n",
      "\n",
      "\n",
      "        [[[-0.1799]],\n",
      "\n",
      "         [[-0.0301]],\n",
      "\n",
      "         [[-0.0371]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3057]],\n",
      "\n",
      "         [[ 0.2747]],\n",
      "\n",
      "         [[-0.0027]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0061]],\n",
      "\n",
      "         [[-0.0103]],\n",
      "\n",
      "         [[-0.0460]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0027]],\n",
      "\n",
      "         [[ 0.0878]],\n",
      "\n",
      "         [[ 0.1350]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1394]],\n",
      "\n",
      "         [[-0.2841]],\n",
      "\n",
      "         [[-0.1276]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1826]],\n",
      "\n",
      "         [[-0.3179]],\n",
      "\n",
      "         [[ 0.0516]]],\n",
      "\n",
      "\n",
      "        [[[-0.1237]],\n",
      "\n",
      "         [[ 0.1437]],\n",
      "\n",
      "         [[-0.0463]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0605]],\n",
      "\n",
      "         [[ 0.2645]],\n",
      "\n",
      "         [[-0.2760]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1586,  0.2266,  0.0664,  ...,  0.2989, -0.0107,  0.0654],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0824]],\n",
      "\n",
      "         [[-0.2124]],\n",
      "\n",
      "         [[-0.1835]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1925]],\n",
      "\n",
      "         [[ 0.1487]],\n",
      "\n",
      "         [[ 0.7304]]],\n",
      "\n",
      "\n",
      "        [[[-0.0502]],\n",
      "\n",
      "         [[ 0.0534]],\n",
      "\n",
      "         [[ 0.4441]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2993]],\n",
      "\n",
      "         [[-0.0523]],\n",
      "\n",
      "         [[ 0.4969]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1248]],\n",
      "\n",
      "         [[-0.1045]],\n",
      "\n",
      "         [[ 0.0280]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3195]],\n",
      "\n",
      "         [[-0.2548]],\n",
      "\n",
      "         [[ 0.1655]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3282]],\n",
      "\n",
      "         [[-0.3286]],\n",
      "\n",
      "         [[-0.2718]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4217]],\n",
      "\n",
      "         [[ 0.7852]],\n",
      "\n",
      "         [[ 0.3234]]],\n",
      "\n",
      "\n",
      "        [[[-0.1763]],\n",
      "\n",
      "         [[ 0.0300]],\n",
      "\n",
      "         [[-0.1309]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2472]],\n",
      "\n",
      "         [[ 0.5644]],\n",
      "\n",
      "         [[-0.1688]]],\n",
      "\n",
      "\n",
      "        [[[-0.3486]],\n",
      "\n",
      "         [[ 0.3181]],\n",
      "\n",
      "         [[ 0.0781]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0476]],\n",
      "\n",
      "         [[-0.5467]],\n",
      "\n",
      "         [[-0.1345]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([2.5896, 3.0877, 2.7142, 3.1338, 2.7814, 3.2969, 3.8900, 5.0709, 3.4372,\n",
      "        2.5931, 2.8177, 2.3164, 3.0514, 2.5725, 2.5334, 4.5563, 3.1106, 3.0258,\n",
      "        2.4954, 2.7771, 2.5900, 2.9895, 2.7262, 2.9276, 2.4124, 4.1262, 3.5623,\n",
      "        2.9349, 2.5312, 2.7186, 2.3948, 2.4783, 4.6279, 2.5900, 2.8736, 2.6256,\n",
      "        2.6528, 2.8240, 2.9661, 3.2271, 3.4621, 2.6293, 4.5420, 3.6506, 3.8513,\n",
      "        3.2320, 2.7507, 2.4646, 2.7330, 2.9580, 2.4240, 4.1585, 2.6126, 3.1679,\n",
      "        3.6837, 2.3867, 2.4350, 2.4510, 3.5158, 2.0738, 2.5257, 3.2398, 3.4388,\n",
      "        4.9039, 3.1998, 3.0314, 1.9947, 2.5344, 2.4375, 2.9714, 3.9351, 3.5644,\n",
      "        2.9149, 3.3351, 3.4152, 3.1698, 2.7388, 2.7151, 2.2302, 2.7024, 2.3762,\n",
      "        2.6569, 2.3158, 2.2500, 3.3475, 2.5944, 3.3971, 2.8085, 4.3087, 2.2949,\n",
      "        3.2528, 2.6341, 3.3011, 2.4267, 2.9225, 2.4523, 2.4756, 2.1716, 2.7459,\n",
      "        4.6295, 2.5848, 2.8360, 2.3852, 2.8590, 2.6125, 2.5185, 2.4330, 3.5473,\n",
      "        2.6233, 2.1945, 2.8624, 2.9334, 2.6106, 3.1840, 2.1898, 3.5981, 2.3794,\n",
      "        2.8750, 2.9485, 2.5540, 2.5346, 2.9952, 3.9585, 2.7636, 2.4282, 2.2224,\n",
      "        3.5900, 2.3576, 3.3095, 2.8523, 3.8792, 3.4302, 4.5816, 2.3567, 2.8841,\n",
      "        3.6568, 2.4790, 2.8104, 2.3792, 2.1233, 2.5625, 2.8089, 2.6421, 2.6680,\n",
      "        2.5382, 2.2317, 2.5680, 2.6491, 2.7382, 2.8087, 2.4162, 2.2388, 3.0562,\n",
      "        3.4965, 2.6696, 2.9174, 2.6074, 4.1946, 3.2047, 2.7208, 2.6074, 2.8726,\n",
      "        2.6571, 3.0036, 2.5660, 4.0129, 2.8975, 2.8570, 3.1196, 2.8101, 2.3467,\n",
      "        2.3802, 2.8321, 2.2957, 2.6490, 3.8424, 2.9941, 2.3099, 2.5503, 2.2577,\n",
      "        3.0574, 2.5909, 2.9767, 2.4735, 2.2504, 2.6907, 2.5530, 2.2796, 2.9388,\n",
      "        3.5206, 2.4973, 2.5186, 2.8488, 2.5282, 3.4402, 2.8133, 2.3253, 3.4582,\n",
      "        2.5167, 3.7337, 2.2918, 2.8863, 3.0651, 2.7165, 3.2799, 3.0215, 2.6348,\n",
      "        2.8163, 2.1030, 2.5911, 3.0692, 2.3454, 2.5198, 2.3033, 2.5712, 2.8043,\n",
      "        1.8912, 2.6808, 2.7305, 2.6617, 4.5913, 2.6629, 2.5513, 2.9218, 5.4407,\n",
      "        3.2988, 2.4401, 2.6710, 2.4044, 2.2670, 3.1204, 3.0481, 2.5875, 2.5651,\n",
      "        3.4531, 2.5079, 3.7412, 2.6750, 2.7623, 2.6079, 3.6565, 2.7706, 2.8233,\n",
      "        2.8715, 2.7768, 2.0917, 4.1966, 3.1738, 4.0999, 2.5526, 3.1172, 3.6377,\n",
      "        2.6402, 3.9858, 3.2272, 3.0032, 2.5179, 2.9966, 2.7025, 3.6519, 4.1291,\n",
      "        2.3548, 3.1095, 2.3621, 2.2869, 3.8473, 1.8555, 2.8971, 2.9541, 3.1078,\n",
      "        2.6588, 2.5977, 2.6661, 3.0516, 2.5494, 2.4012, 2.7558, 2.6850, 3.8683,\n",
      "        2.4588, 3.0638, 2.2764, 2.3637, 2.1925, 2.9793, 2.5398, 2.4953, 2.8610,\n",
      "        2.6592, 2.4272, 2.5956, 1.9767, 2.4595, 2.3826, 2.5443, 3.2283, 2.4742,\n",
      "        3.3991, 2.8299, 2.7155, 2.7015, 2.5856, 2.1791, 2.7048, 3.2601, 2.8507,\n",
      "        3.0446, 2.2800, 2.0969, 2.2018, 2.3250, 3.1106, 2.5385, 2.5375, 2.3180,\n",
      "        2.7679, 4.0867, 2.9585, 3.7007, 3.5609, 2.2741, 3.4381, 2.3084, 2.4022,\n",
      "        2.5679, 3.6312, 3.1440, 2.3387, 2.7684, 2.2838, 2.2516, 2.5120, 2.5218,\n",
      "        2.5656, 2.3675, 2.8664, 2.8226, 2.2982, 2.5753, 3.5756, 3.0373, 2.9878,\n",
      "        2.5863, 4.7117, 3.0820, 4.4544, 2.5569, 3.0035, 3.7435, 1.8211, 2.4918,\n",
      "        2.9438, 2.3239, 3.3745, 2.6031, 4.2809, 2.1270, 2.4859, 2.6851, 2.6303,\n",
      "        3.2125, 2.7898, 3.8890, 2.3721, 2.4861, 2.8676, 2.4005, 2.5018, 2.5477,\n",
      "        2.6949, 2.1374, 2.7822, 2.5380, 2.6385, 2.5932, 2.3265, 2.7595, 2.7972,\n",
      "        2.5912, 3.0146, 2.3034, 2.9144, 2.9497, 2.6555], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 3.9508e-03,  1.0141e-02,  3.9746e-03, -5.0023e-03, -2.7442e-03,\n",
      "         3.6878e-04,  1.9768e-02, -1.9759e-02, -1.3330e-02,  6.8568e-04,\n",
      "        -3.7653e-03, -7.4412e-03, -3.4711e-03, -3.4816e-03, -1.9206e-02,\n",
      "         2.0291e-02,  4.1694e-03,  1.2035e-02,  2.6758e-02,  1.3297e-02,\n",
      "         4.7637e-03,  2.3972e-02,  3.9868e-03, -6.5050e-04, -1.9531e-02,\n",
      "         2.0495e-02, -7.5388e-03, -6.0413e-03,  5.2257e-03, -3.9096e-03,\n",
      "         1.2994e-02, -1.6780e-02, -1.8693e-02, -9.9458e-03,  4.0377e-03,\n",
      "         1.9498e-03,  1.1998e-03,  1.9510e-03,  1.1805e-02, -1.5162e-02,\n",
      "        -5.1687e-04, -9.1575e-03,  2.5887e-02,  1.8407e-02, -1.2194e-02,\n",
      "         7.8052e-03,  1.0617e-02, -3.1864e-02, -3.9760e-03,  3.2741e-03,\n",
      "        -1.0803e-02, -8.1942e-03, -1.9726e-02, -5.8594e-04,  7.8230e-03,\n",
      "         2.2252e-02,  9.2961e-04,  1.7341e-02, -8.9316e-03, -1.4528e-04,\n",
      "         1.0240e-02, -9.4469e-05,  1.6361e-02,  2.9882e-02, -3.7280e-02,\n",
      "         2.5421e-03, -1.2248e-03,  7.2394e-03, -1.4881e-02,  5.2351e-03,\n",
      "        -2.0320e-02,  8.3474e-03,  1.6474e-03, -7.8141e-03,  2.1426e-03,\n",
      "         1.3426e-02,  1.5845e-03, -5.3464e-03,  8.4109e-03, -2.9574e-02,\n",
      "        -8.1857e-04,  7.7995e-03,  4.2511e-03,  1.8874e-02,  1.0006e-02,\n",
      "        -4.6106e-02,  1.2070e-02,  1.0198e-02,  1.9438e-02,  4.4503e-03,\n",
      "         4.1639e-03,  9.4391e-03,  9.3837e-03, -3.4759e-03,  6.2467e-03,\n",
      "         2.5227e-03,  4.9277e-03, -9.0794e-05, -1.1940e-02,  1.1638e-02,\n",
      "         8.7408e-04,  2.3884e-03,  2.6532e-05, -1.4721e-02,  6.5120e-04,\n",
      "        -1.3223e-03,  1.1390e-02,  6.6968e-03, -1.0401e-03,  1.6233e-02,\n",
      "        -8.5163e-04,  4.4831e-03, -1.3434e-03,  6.7333e-03, -2.7540e-03,\n",
      "         1.2415e-02,  2.6049e-03,  1.7721e-02, -7.3834e-04, -9.7462e-03,\n",
      "         3.5696e-02, -6.6597e-03,  2.6584e-02,  1.4048e-02, -1.6963e-03,\n",
      "         1.4173e-02, -3.1617e-02,  6.4901e-03,  1.0604e-02,  5.9036e-03,\n",
      "         3.0138e-02, -5.2119e-02,  1.8401e-02,  3.7395e-03, -1.6622e-03,\n",
      "         2.1431e-02,  1.6903e-02,  1.8792e-03,  5.5986e-03, -7.4826e-03,\n",
      "        -1.5867e-02,  1.1024e-02, -9.9583e-03, -2.2407e-02,  1.3235e-02,\n",
      "        -7.3434e-03, -6.8039e-03,  7.1710e-03, -6.0684e-04,  7.1972e-03,\n",
      "         1.0609e-03, -1.1200e-03, -4.1967e-02, -1.2186e-03, -1.1624e-02,\n",
      "         2.6570e-03, -1.1538e-02, -1.5016e-02,  8.9699e-04, -8.9203e-03,\n",
      "        -2.0710e-04, -8.0527e-03,  3.4461e-03, -1.5188e-02,  1.6080e-02,\n",
      "         9.4232e-03, -3.8832e-03,  1.1497e-02, -2.4854e-02,  6.4209e-03,\n",
      "        -3.3199e-03, -4.2330e-03, -2.7193e-03,  5.6717e-03, -9.6144e-03,\n",
      "         2.5881e-02, -1.1973e-02, -2.6432e-03,  7.2947e-03, -1.7061e-02,\n",
      "         1.1891e-02, -9.4430e-03, -2.7094e-03, -1.8915e-02,  6.2530e-03,\n",
      "         1.3967e-03, -5.6412e-03,  2.8229e-03,  2.8801e-03, -1.7940e-02,\n",
      "         5.0740e-03, -2.1406e-02, -2.0071e-02, -8.1169e-03,  1.1065e-02,\n",
      "        -6.1063e-03, -7.6470e-03,  1.0383e-02, -1.6816e-02, -1.4567e-02,\n",
      "        -2.1772e-02,  1.0839e-02, -1.3955e-02,  6.1099e-03,  4.5563e-03,\n",
      "         6.8367e-03, -1.6255e-02, -7.4331e-03,  9.1212e-03,  1.1198e-03,\n",
      "        -7.9351e-04, -4.2231e-03,  2.4467e-04, -1.2612e-02, -5.3801e-03,\n",
      "        -4.3909e-03,  3.3652e-03, -1.1791e-02,  2.5318e-02,  2.9879e-03,\n",
      "        -1.9151e-02, -1.7128e-02, -2.5920e-02,  2.5016e-02, -1.8985e-02,\n",
      "         1.7052e-02, -1.1509e-03,  1.1041e-02, -5.6564e-03, -1.3421e-02,\n",
      "         4.1759e-03, -1.6445e-04,  1.4498e-02, -2.7963e-02,  3.7170e-02,\n",
      "        -4.8394e-03,  1.3786e-02,  2.7920e-03, -2.5919e-03,  2.2265e-03,\n",
      "         1.6623e-02,  1.5474e-02, -7.6636e-03, -2.9533e-03, -6.9541e-03,\n",
      "         3.6495e-03, -2.2111e-02, -2.1965e-02, -1.7116e-02,  1.7641e-04,\n",
      "         2.6021e-04,  1.7627e-02,  7.4892e-03, -1.9759e-02, -1.8814e-03,\n",
      "         1.5076e-03, -3.8600e-02,  4.5192e-03,  1.6158e-02, -6.3814e-03,\n",
      "        -3.5877e-03, -4.7459e-03,  1.8742e-02, -2.2442e-02, -6.1440e-03,\n",
      "         2.2946e-02, -6.8338e-03,  2.4929e-02, -8.4540e-03,  1.8680e-02,\n",
      "        -1.4036e-02,  2.2278e-04, -5.6298e-03,  1.7360e-02,  2.8934e-02,\n",
      "         1.4672e-02, -3.5009e-03, -8.7550e-03, -1.1070e-02, -3.8534e-03,\n",
      "         4.6908e-03,  5.7962e-03, -4.7715e-03,  4.3346e-03, -1.6418e-02,\n",
      "        -1.6775e-02, -4.5603e-03, -5.3546e-05, -6.4399e-03, -8.7398e-03,\n",
      "         1.4222e-02,  2.0809e-03,  6.3705e-03, -7.3853e-03,  3.0634e-03,\n",
      "         3.6798e-03,  1.4292e-02,  2.1090e-02, -9.7677e-03,  1.0736e-02,\n",
      "         6.5858e-03, -7.3861e-03, -7.8059e-03, -9.6732e-03, -1.4668e-02,\n",
      "        -1.6362e-02,  2.1398e-02, -3.2892e-03,  6.4096e-03,  1.5622e-03,\n",
      "         4.8529e-03, -3.0208e-02,  6.2256e-03, -1.6565e-03,  1.5828e-02,\n",
      "        -2.5027e-02, -4.8895e-03, -3.3542e-03, -9.4226e-03,  1.5914e-02,\n",
      "        -2.4131e-03,  1.1657e-02, -7.7305e-03, -1.9755e-03, -2.8574e-02,\n",
      "        -1.2538e-02,  6.8249e-03, -1.3350e-02,  1.1277e-02, -3.3087e-03,\n",
      "         5.3039e-03,  2.2627e-03,  6.8699e-03, -7.2311e-04,  1.3081e-03,\n",
      "        -2.2628e-03,  1.6129e-03,  9.1222e-03, -2.3909e-03,  1.8675e-02,\n",
      "        -2.0237e-04, -4.7040e-03, -1.0232e-02, -1.9495e-02,  2.0039e-03,\n",
      "         2.0579e-02, -1.7047e-03, -6.1396e-03, -1.9405e-02,  7.9545e-03,\n",
      "        -2.9242e-02,  1.4399e-02, -2.2989e-02,  2.1244e-03,  4.4724e-03,\n",
      "        -3.6513e-02, -2.2566e-02,  5.0105e-03, -4.6269e-03,  3.4755e-03,\n",
      "        -2.5776e-02, -3.0695e-03, -8.8384e-03, -4.5518e-03,  1.0044e-02,\n",
      "        -3.0332e-03,  3.1271e-03, -4.3899e-03, -2.4751e-02, -4.1411e-03,\n",
      "        -1.2401e-02, -3.6660e-03,  1.0234e-03,  1.4969e-03, -9.9564e-03,\n",
      "         5.6711e-03,  9.9795e-03,  4.4312e-03,  2.9703e-03, -1.3526e-02,\n",
      "        -1.6587e-03, -7.7606e-03, -6.0258e-03, -1.6973e-02], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2466]],\n",
      "\n",
      "         [[-0.0257]],\n",
      "\n",
      "         [[-0.4864]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0190]],\n",
      "\n",
      "         [[-0.0547]],\n",
      "\n",
      "         [[ 0.1859]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6291]],\n",
      "\n",
      "         [[ 0.1066]],\n",
      "\n",
      "         [[-0.3190]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6983]],\n",
      "\n",
      "         [[ 0.3029]],\n",
      "\n",
      "         [[ 0.3600]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2520]],\n",
      "\n",
      "         [[-0.2209]],\n",
      "\n",
      "         [[-0.0101]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1628]],\n",
      "\n",
      "         [[-0.0224]],\n",
      "\n",
      "         [[-0.1925]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.4460]],\n",
      "\n",
      "         [[ 0.2797]],\n",
      "\n",
      "         [[ 0.0830]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1353]],\n",
      "\n",
      "         [[-0.3275]],\n",
      "\n",
      "         [[ 0.5852]]],\n",
      "\n",
      "\n",
      "        [[[-0.0106]],\n",
      "\n",
      "         [[ 0.0060]],\n",
      "\n",
      "         [[ 0.4406]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3845]],\n",
      "\n",
      "         [[-0.4494]],\n",
      "\n",
      "         [[-0.2107]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2841]],\n",
      "\n",
      "         [[ 0.3753]],\n",
      "\n",
      "         [[ 0.1731]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0171]],\n",
      "\n",
      "         [[-0.2466]],\n",
      "\n",
      "         [[ 0.4090]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.2690, 0.2904, 0.9692,  ..., 0.9354, 0.7248, 0.2104], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.6259, -1.3668, -1.0518,  ..., -1.3122,  0.3711, -1.2397],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.5709, -0.7467, -0.2563],\n",
      "          [-0.2984, -0.4870, -0.0851],\n",
      "          [ 0.1885,  0.2579,  0.2329]]],\n",
      "\n",
      "\n",
      "        [[[-0.3624, -0.2971, -0.7744],\n",
      "          [ 0.0099,  0.2115, -0.0987],\n",
      "          [ 0.0058,  0.4247, -0.0189]]],\n",
      "\n",
      "\n",
      "        [[[-0.1106, -0.1950,  0.0100],\n",
      "          [-0.3048,  0.9501, -0.1415],\n",
      "          [ 0.2079, -0.2062, -0.0534]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3269, -0.0110,  0.0520],\n",
      "          [ 0.7417,  0.4086,  0.4175],\n",
      "          [-0.2245, -0.3341,  0.0431]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5562,  0.2142, -0.5030],\n",
      "          [ 0.3635, -0.1634, -0.1352],\n",
      "          [ 0.0894,  0.2835, -0.2646]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3243, -0.2739, -0.1645],\n",
      "          [ 0.6706, -0.0652, -0.1329],\n",
      "          [ 0.4380, -0.0396, -0.3212]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.8375, 1.3501, 1.6037,  ..., 0.4898, 0.0381, 1.1902], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.2390, -0.6759, -1.1940,  ..., -0.3447,  0.0968, -0.6362],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0271]],\n",
      "\n",
      "         [[ 0.3624]],\n",
      "\n",
      "         [[ 0.2270]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0687]],\n",
      "\n",
      "         [[-0.2708]],\n",
      "\n",
      "         [[-0.2023]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0109]],\n",
      "\n",
      "         [[ 0.3366]],\n",
      "\n",
      "         [[ 0.2218]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0815]],\n",
      "\n",
      "         [[-0.2891]],\n",
      "\n",
      "         [[-0.1860]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0633]],\n",
      "\n",
      "         [[-0.0095]],\n",
      "\n",
      "         [[-0.0061]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0133]],\n",
      "\n",
      "         [[-0.0764]],\n",
      "\n",
      "         [[-0.0692]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.4327]],\n",
      "\n",
      "         [[ 0.2261]],\n",
      "\n",
      "         [[-0.2349]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2909]],\n",
      "\n",
      "         [[-0.0049]],\n",
      "\n",
      "         [[-0.1225]]],\n",
      "\n",
      "\n",
      "        [[[-0.0262]],\n",
      "\n",
      "         [[ 0.2524]],\n",
      "\n",
      "         [[ 0.8784]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2076]],\n",
      "\n",
      "         [[-0.7285]],\n",
      "\n",
      "         [[-0.1622]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1289]],\n",
      "\n",
      "         [[ 0.0340]],\n",
      "\n",
      "         [[ 0.2557]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0851]],\n",
      "\n",
      "         [[ 0.1154]],\n",
      "\n",
      "         [[ 0.0438]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.2713, -0.2439, -0.0962, -0.2287, -0.3601, -0.3444, -0.3093, -0.2850,\n",
      "         0.0774, -0.2143, -0.1865, -0.4176, -0.5706, -0.4823, -0.4299,  0.0017,\n",
      "        -0.3094,  0.1292,  0.2385, -0.1070, -0.2528, -0.0527, -0.4041, -0.2273,\n",
      "        -0.4834, -0.2161,  0.1218, -0.4790, -0.4856, -0.2370,  0.0780, -0.0275,\n",
      "        -0.4651, -0.0929, -0.1432, -0.3695, -0.1504, -0.2826, -0.2801, -0.3153,\n",
      "        -0.1693, -0.1372,  0.0922, -0.4474,  0.0462,  0.0890,  0.2096,  0.1348,\n",
      "        -0.1962, -0.5120, -0.3711, -0.1259, -0.0938, -0.5398, -0.3871, -0.3235,\n",
      "        -0.2680, -0.1836, -0.1026, -0.1910, -0.0820,  0.1185,  0.5140, -0.2653,\n",
      "        -0.2610, -0.1798, -0.2767, -0.3890, -0.3856, -0.3358,  0.0253, -0.1889,\n",
      "        -0.3362,  0.0464, -0.4962, -0.4001,  0.0014, -0.2672, -0.1097,  0.0529,\n",
      "         0.0026, -0.5458, -0.2416, -0.1651, -0.3005, -0.3353, -0.3477, -0.3434,\n",
      "        -0.3752, -0.4451,  0.4295, -0.2596, -0.3501, -0.1007, -0.3958, -0.0055],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2153]],\n",
      "\n",
      "         [[-0.1440]],\n",
      "\n",
      "         [[ 0.1705]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4309]],\n",
      "\n",
      "         [[ 0.2960]],\n",
      "\n",
      "         [[-0.0033]]],\n",
      "\n",
      "\n",
      "        [[[-0.0669]],\n",
      "\n",
      "         [[ 0.0026]],\n",
      "\n",
      "         [[-0.0024]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0074]],\n",
      "\n",
      "         [[-0.0243]],\n",
      "\n",
      "         [[-0.0234]]],\n",
      "\n",
      "\n",
      "        [[[-0.2984]],\n",
      "\n",
      "         [[-0.2607]],\n",
      "\n",
      "         [[-0.0536]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1743]],\n",
      "\n",
      "         [[-0.2281]],\n",
      "\n",
      "         [[ 0.0021]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1859]],\n",
      "\n",
      "         [[-0.3121]],\n",
      "\n",
      "         [[-0.1140]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2474]],\n",
      "\n",
      "         [[-0.2674]],\n",
      "\n",
      "         [[ 0.1266]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0305]],\n",
      "\n",
      "         [[ 0.1751]],\n",
      "\n",
      "         [[ 0.1157]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1027]],\n",
      "\n",
      "         [[ 0.1542]],\n",
      "\n",
      "         [[ 0.1629]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0675]],\n",
      "\n",
      "         [[ 0.0148]],\n",
      "\n",
      "         [[ 0.0991]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0222]],\n",
      "\n",
      "         [[-0.2121]],\n",
      "\n",
      "         [[-0.3377]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.3535, -0.0853,  0.1002,  ...,  0.0292, -0.1596, -0.1960],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2721]],\n",
      "\n",
      "         [[-0.0264]],\n",
      "\n",
      "         [[-0.0499]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0405]],\n",
      "\n",
      "         [[ 0.0089]],\n",
      "\n",
      "         [[ 0.0420]]],\n",
      "\n",
      "\n",
      "        [[[-0.0855]],\n",
      "\n",
      "         [[ 0.0995]],\n",
      "\n",
      "         [[-0.5223]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0480]],\n",
      "\n",
      "         [[ 0.0416]],\n",
      "\n",
      "         [[ 0.1635]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3934]],\n",
      "\n",
      "         [[-0.0100]],\n",
      "\n",
      "         [[-0.4884]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[ 0.0441]],\n",
      "\n",
      "         [[-0.0615]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1922]],\n",
      "\n",
      "         [[ 0.0157]],\n",
      "\n",
      "         [[ 0.2624]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2013]],\n",
      "\n",
      "         [[ 0.0534]],\n",
      "\n",
      "         [[-0.0231]]],\n",
      "\n",
      "\n",
      "        [[[-0.3642]],\n",
      "\n",
      "         [[ 0.0436]],\n",
      "\n",
      "         [[ 0.0934]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3331]],\n",
      "\n",
      "         [[-0.0489]],\n",
      "\n",
      "         [[ 0.0709]]],\n",
      "\n",
      "\n",
      "        [[[-0.0299]],\n",
      "\n",
      "         [[-0.0032]],\n",
      "\n",
      "         [[ 0.1249]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0779]],\n",
      "\n",
      "         [[-0.0684]],\n",
      "\n",
      "         [[-0.1789]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.9279, 1.0970, 0.9460, 0.6609, 0.8145, 1.1637, 1.2544, 1.5234, 0.7077,\n",
      "        1.4031, 0.8886, 1.4538, 1.2818, 1.4344, 1.2054, 1.2850, 0.6589, 0.9600,\n",
      "        0.7968, 0.9121, 1.1671, 1.3887, 1.4926, 0.8435, 1.3998, 1.0552, 0.6414,\n",
      "        1.2762, 1.7035, 1.3136, 1.3556, 1.5852, 2.4995, 1.2534, 0.9143, 0.8639,\n",
      "        0.7777, 1.0196, 1.0448, 1.4114, 1.0267, 0.8530, 1.5692, 0.8275, 1.0749,\n",
      "        1.1107, 1.3267, 0.9282, 0.7138, 1.3153, 1.1668, 1.1249, 1.4476, 0.9257,\n",
      "        0.9556, 1.1477, 1.0441, 0.7865, 1.5082, 1.1508, 1.3467, 1.1699, 0.8916,\n",
      "        2.0742, 1.2096, 0.5864, 1.2972, 1.4120, 1.8253, 0.7768, 0.7767, 0.9320,\n",
      "        1.2377, 1.8804, 1.5501, 0.8445, 0.7636, 1.8394, 0.9738, 1.0639, 0.6442,\n",
      "        1.2227, 0.8467, 1.0125, 2.1756, 1.0238, 1.0208, 1.8343, 1.3042, 1.5606,\n",
      "        1.2671, 1.0784, 1.6492, 1.4531, 1.4755, 0.5156, 0.7475, 1.0817, 1.4780,\n",
      "        1.3913, 0.8079, 0.8034, 0.8049, 1.7758, 1.2637, 0.6928, 2.0413, 1.2133,\n",
      "        1.2542, 1.9248, 1.2020, 1.0563, 1.6321, 0.2883, 0.7389, 0.8930, 0.7863,\n",
      "        0.9436, 0.9472, 0.7804, 0.8657, 1.1251, 1.1743, 1.0829, 0.5634, 1.2223,\n",
      "        0.7618, 1.1055, 1.2914, 1.2872, 1.3798, 1.3416, 1.3241, 1.0499, 0.9632,\n",
      "        1.0110, 1.2426, 1.1283, 1.0804, 1.2629, 1.3088, 1.0919, 1.5236, 0.7805,\n",
      "        0.8179, 0.7428, 1.7883, 0.7757, 0.6756, 1.8349, 0.8139, 1.2825, 1.0926,\n",
      "        0.8884, 1.0670, 0.9309, 1.0725, 1.3307, 1.1027, 1.2614, 0.7236, 1.3659,\n",
      "        0.3291, 0.9341, 1.4759, 1.3850, 1.0446, 1.3849, 1.1048, 1.7572, 0.5572,\n",
      "        1.0908, 1.1182, 0.8343, 0.9580, 1.7719, 1.3129, 1.1877, 1.3267, 1.1528,\n",
      "        0.3722, 1.5028, 1.0968, 0.9381, 1.3883, 1.0178, 1.1215, 1.5332, 1.0203,\n",
      "        0.5333, 1.5232, 1.5974, 0.8588, 1.2133, 1.1028, 0.7409, 0.6751, 0.4713,\n",
      "        0.8181, 1.0766, 1.5462, 0.5580, 0.6770, 0.8150, 1.0775, 0.8564, 0.7922,\n",
      "        1.2088, 0.9287, 1.3754, 0.5964, 1.0041, 1.3856, 1.7316, 1.3842, 1.7527,\n",
      "        1.3305, 1.0926, 0.8998, 0.5994, 1.3287, 1.4413, 1.1733, 1.0470, 1.7116,\n",
      "        1.3500, 2.2306, 1.3136, 1.0223, 1.6973, 0.9595, 1.4356, 0.7740, 1.3091,\n",
      "        0.7295, 1.7282, 0.7245, 1.3534, 1.0112, 0.9498, 1.3439, 1.0953, 0.7641,\n",
      "        1.1786, 0.8449, 0.9349, 1.3825, 1.0738, 1.0077, 0.8877, 0.7815, 1.2092,\n",
      "        0.5296, 0.9094, 1.2389, 1.3634, 1.5283, 0.9671, 1.2239, 0.8227, 1.0934,\n",
      "        1.1324, 1.0160, 1.4439, 1.1980, 0.9763, 0.9840, 0.7187, 1.1560, 0.7971,\n",
      "        1.0999, 1.2843, 1.2342, 1.6473, 1.2439, 1.5233, 1.1755, 0.9209, 0.9724,\n",
      "        0.8707, 0.6795, 1.0690, 0.6686, 1.5839, 0.7706, 1.3258, 1.3581, 0.7805,\n",
      "        1.1641, 0.9010, 1.2930, 1.0355, 1.1146, 1.1812, 1.0239, 1.6647, 1.0585,\n",
      "        1.1256, 1.1989, 1.3632, 1.2669, 1.4188, 1.1668, 0.7194, 1.1859, 1.4856,\n",
      "        0.9036, 1.2469, 0.8247, 0.9113, 0.7042, 1.2982, 0.7054, 1.0415, 1.1069,\n",
      "        1.0605, 1.2875, 1.5017, 1.5059, 0.5442, 0.9763, 1.3371, 1.2517, 0.8802,\n",
      "        1.0937, 0.9185, 0.7146, 1.1579, 0.5890, 1.1391, 1.5265, 1.4060, 1.7283,\n",
      "        1.5130, 1.0951, 0.9254, 1.2788, 1.1425, 0.8069, 1.2028, 0.9184, 1.6542,\n",
      "        1.5598, 1.3895, 1.0537, 1.7125, 0.7003, 0.9792, 1.3197, 0.9386, 1.1377,\n",
      "        1.7656, 1.6538, 0.8852, 1.4135, 1.4239, 1.3838, 1.1391, 0.8981, 0.6132,\n",
      "        1.1224, 0.9962, 0.8561, 1.2386, 1.3882, 1.4946, 1.0851, 1.3115, 1.0983,\n",
      "        1.0378, 1.0462, 1.0029, 1.0727, 0.6014, 0.8275, 1.3730, 1.1987, 1.0658,\n",
      "        1.6794, 1.2284, 0.8457, 0.9017, 0.8411, 0.8640], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1250, -0.1698,  0.0839,  0.0154,  0.1509, -0.0214, -0.4088,  0.4671,\n",
      "        -0.1230,  0.0050,  0.0324, -0.0393,  0.0280,  0.0599,  0.0261, -0.2798,\n",
      "         0.0745,  0.0290, -0.0688, -0.1738,  0.0105,  0.0199,  0.2489,  0.0522,\n",
      "         0.0441, -0.1902,  0.0400,  0.0743,  0.0519, -0.0132, -0.2557,  0.0217,\n",
      "         0.4423, -0.0407,  0.2065,  0.0844, -0.1528,  0.0970, -0.0215,  0.2935,\n",
      "        -0.0610, -0.1046, -0.3567, -0.0972,  0.4131, -0.0827,  0.0913,  0.0189,\n",
      "         0.1065, -0.0009, -0.1383, -0.0544,  0.0534, -0.1130,  0.0230,  0.0156,\n",
      "         0.0411,  0.0189,  0.3009, -0.0675, -0.0704,  0.0731, -0.0769, -0.3633,\n",
      "        -0.1326, -0.0713,  0.0606,  0.1871, -0.1425,  0.0469,  0.2486, -0.2699,\n",
      "        -0.0028,  0.1360,  0.3519,  0.1367, -0.0721,  0.2498,  0.0494,  0.1206,\n",
      "        -0.0458, -0.1965,  0.0959, -0.1305, -0.3627,  0.1290, -0.2395,  0.2463,\n",
      "        -0.0829,  0.2989,  0.0217, -0.1681, -0.1117, -0.0514,  0.0421, -0.2525,\n",
      "         0.0716,  0.1695, -0.0328, -0.4577, -0.0618, -0.1670,  0.1186,  0.0353,\n",
      "         0.3074, -0.2505, -0.1975, -0.3462,  0.1338,  0.0629, -0.0954, -0.1204,\n",
      "        -0.1493, -0.0437, -0.1269, -0.0698, -0.0507,  0.0899,  0.2677, -0.1866,\n",
      "        -0.0547,  0.1182, -0.1932,  0.1260, -0.1314,  0.0219,  0.1714,  0.0946,\n",
      "        -0.0677,  0.2159, -0.2738,  0.0665, -0.3083,  0.0166, -0.1878, -0.1995,\n",
      "         0.1508, -0.1214,  0.2245, -0.0067, -0.1635, -0.1175, -0.0760, -0.0252,\n",
      "         0.0551, -0.2242, -0.1403,  0.0833, -0.0719, -0.1247,  0.0053,  0.0207,\n",
      "         0.2134,  0.0568, -0.0396,  0.0777,  0.1269,  0.4760,  0.0452,  0.0413,\n",
      "         0.0645, -0.1191,  0.0381, -0.1431,  0.2049, -0.1258, -0.0376,  0.1104,\n",
      "         0.2667, -0.2327,  0.0906,  0.1104,  0.2063, -0.0748, -0.0818, -0.3405,\n",
      "         0.2652,  0.1867,  0.1520, -0.0346, -0.0561, -0.1178, -0.0096, -0.1239,\n",
      "         0.0717,  0.2003, -0.1136, -0.2006,  0.1140,  0.0106,  0.1149, -0.0224,\n",
      "         0.1279, -0.0374, -0.0717,  0.0191,  0.0330,  0.0793,  0.1107, -0.0670,\n",
      "         0.1429,  0.1258, -0.0396, -0.0407, -0.0283,  0.1860,  0.0061,  0.0540,\n",
      "        -0.0532,  0.0168, -0.0048, -0.0800,  0.1157,  0.0317, -0.1316, -0.0284,\n",
      "         0.0880, -0.1185, -0.0123, -0.1066,  0.4732, -0.2394,  0.0310,  0.1365,\n",
      "         0.4084, -0.1614,  0.3430, -0.0030,  0.0754,  0.0289, -0.0620, -0.1682,\n",
      "        -0.0721,  0.1150, -0.1854, -0.0487,  0.0251, -0.1450,  0.0678, -0.0946,\n",
      "        -0.2330,  0.1065, -0.1946, -0.1625, -0.0093,  0.0729,  0.3102, -0.1728,\n",
      "         0.1834,  0.0358, -0.0848, -0.1342, -0.0628,  0.2905,  0.2795,  0.1032,\n",
      "        -0.0146,  0.0065,  0.1854, -0.0997, -0.1154, -0.1554, -0.0162, -0.1905,\n",
      "        -0.0585, -0.2871, -0.0186,  0.0556,  0.0364,  0.0245,  0.0950,  0.0728,\n",
      "         0.1980,  0.0655, -0.0365,  0.0726, -0.2191,  0.1107,  0.0290, -0.0529,\n",
      "        -0.1503,  0.0284,  0.0084, -0.2229,  0.1116,  0.0368, -0.0287, -0.0646,\n",
      "         0.0483,  0.0058,  0.1830,  0.0449,  0.1029, -0.1596, -0.0083, -0.2048,\n",
      "         0.0541, -0.1678, -0.1923, -0.2246,  0.2923,  0.1474, -0.0811, -0.1605,\n",
      "         0.4559, -0.2432, -0.1272,  0.1648, -0.0140,  0.1996, -0.0196,  0.1278,\n",
      "         0.0748, -0.0995, -0.0755, -0.0287,  0.0130,  0.0609,  0.3314,  0.0461,\n",
      "         0.0941,  0.0187, -0.2310, -0.0503,  0.2042,  0.0428,  0.0836, -0.0092,\n",
      "         0.1889, -0.1539, -0.1298, -0.0461, -0.1156, -0.1598,  0.0632, -0.0053,\n",
      "         0.0674,  0.0045, -0.0644, -0.2383,  0.0079,  0.1617,  0.0692,  0.4667,\n",
      "         0.0719, -0.3921,  0.0117,  0.1583,  0.1623, -0.1373,  0.1427,  0.0449,\n",
      "        -0.0874,  0.0963,  0.3436,  0.7234, -0.1911,  0.0591,  0.0155, -0.0219,\n",
      "        -0.0935, -0.0688, -0.1336, -0.0465,  0.1401,  0.0764,  0.1720,  0.0327,\n",
      "         0.0073, -0.1579, -0.0570, -0.0671,  0.2052, -0.1074, -0.0237,  0.0576,\n",
      "         0.0618,  0.1073,  0.0585,  0.0411, -0.0407,  0.1406,  0.0992, -0.0657],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-6.9626e-02]],\n",
      "\n",
      "         [[-3.1823e-01]],\n",
      "\n",
      "         [[-3.3999e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.5134e-01]],\n",
      "\n",
      "         [[ 1.5862e-01]],\n",
      "\n",
      "         [[ 6.1799e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0002e-01]],\n",
      "\n",
      "         [[-3.5462e-01]],\n",
      "\n",
      "         [[ 6.4965e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6554e-01]],\n",
      "\n",
      "         [[ 1.4206e-02]],\n",
      "\n",
      "         [[-4.3554e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.0881e-05]],\n",
      "\n",
      "         [[-3.4733e-01]],\n",
      "\n",
      "         [[-1.9738e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.4145e-01]],\n",
      "\n",
      "         [[ 4.2743e-01]],\n",
      "\n",
      "         [[-1.2566e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-9.9851e-02]],\n",
      "\n",
      "         [[-1.8620e-01]],\n",
      "\n",
      "         [[-4.1752e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6351e-01]],\n",
      "\n",
      "         [[ 1.6203e-01]],\n",
      "\n",
      "         [[ 6.5260e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.9793e-03]],\n",
      "\n",
      "         [[ 1.4189e-01]],\n",
      "\n",
      "         [[ 1.9905e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9565e-01]],\n",
      "\n",
      "         [[-3.9192e-01]],\n",
      "\n",
      "         [[-4.4701e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7270e-01]],\n",
      "\n",
      "         [[ 7.8616e-02]],\n",
      "\n",
      "         [[-2.8540e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6355e-01]],\n",
      "\n",
      "         [[-4.6530e-01]],\n",
      "\n",
      "         [[ 2.7193e-02]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([2.4375, 1.9648, 1.9626,  ..., 1.7318, 2.5792, 1.9120], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.6092, -1.4798, -1.4352,  ..., -1.0939, -1.6917, -1.1456],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[-0.0080, -0.1457,  0.1493,  ...,  0.0110,  0.4380,  0.1287],\n",
      "        [-0.1346, -0.0375,  0.1453,  ...,  0.1736,  0.3782,  0.1983],\n",
      "        [ 0.1456, -0.0198,  0.0219,  ...,  0.2053, -0.3688, -0.0665],\n",
      "        [-0.0052,  0.0265,  0.1382,  ..., -0.2390, -0.0391, -0.0172],\n",
      "        [-0.0041,  0.3498, -0.3715,  ..., -0.0695, -0.2938,  0.0835],\n",
      "        [-0.1107, -0.1503, -0.0489,  ...,  0.0206,  0.0917, -0.3171]],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0106, -0.3744,  0.1853,  0.0447, -0.1606, -0.0113], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Model\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Epoch : [1] loss : 0.411\n",
      "Epoch : [2] loss : 0.283\n",
      "Epoch : [3] loss : 0.235\n",
      "Epoch : [4] loss : 0.201\n",
      "Epoch : [5] loss : 0.170\n",
      "Epoch : [6] loss : 0.143\n",
      "Epoch : [7] loss : 0.117\n",
      "Epoch : [8] loss : 0.101\n",
      "Epoch : [9] loss : 0.088\n",
      "Epoch : [10] loss : 0.080\n",
      "Epoch : [11] loss : 0.070\n",
      "Epoch : [12] loss : 0.068\n",
      "Epoch : [13] loss : 0.060\n",
      "Epoch : [14] loss : 0.061\n",
      "Epoch : [15] loss : 0.057\n",
      "Epoch : [16] loss : 0.051\n",
      "Epoch : [17] loss : 0.048\n",
      "Epoch : [18] loss : 0.046\n",
      "Epoch : [19] loss : 0.045\n",
      "Epoch : [20] loss : 0.041\n",
      "Epoch : [21] loss : 0.044\n",
      "Epoch : [22] loss : 0.039\n",
      "Epoch : [23] loss : 0.038\n",
      "Epoch : [24] loss : 0.038\n",
      "Epoch : [25] loss : 0.036\n",
      "Epoch : [26] loss : 0.032\n",
      "Epoch : [27] loss : 0.035\n",
      "Epoch : [28] loss : 0.032\n",
      "Epoch : [29] loss : 0.033\n",
      "Epoch : [30] loss : 0.030\n",
      "Epoch : [31] loss : 0.031\n",
      "Epoch : [32] loss : 0.029\n",
      "Epoch : [33] loss : 0.028\n",
      "Epoch : [34] loss : 0.027\n",
      "Epoch : [35] loss : 0.029\n",
      "Epoch : [36] loss : 0.025\n",
      "Epoch : [37] loss : 0.029\n",
      "Epoch : [38] loss : 0.025\n",
      "Epoch : [39] loss : 0.025\n",
      "Epoch : [40] loss : 0.022\n",
      "Epoch : [41] loss : 0.027\n",
      "Epoch : [42] loss : 0.019\n",
      "Epoch : [43] loss : 0.025\n",
      "Epoch : [44] loss : 0.022\n",
      "Epoch : [45] loss : 0.023\n",
      "Epoch : [46] loss : 0.022\n",
      "Epoch : [47] loss : 0.022\n",
      "Epoch : [48] loss : 0.023\n",
      "Epoch : [49] loss : 0.021\n",
      "Epoch : [50] loss : 0.022\n",
      "Epoch : [51] loss : 0.021\n",
      "Epoch : [52] loss : 0.024\n",
      "Epoch : [53] loss : 0.017\n",
      "Epoch : [54] loss : 0.022\n",
      "Epoch : [55] loss : 0.017\n",
      "Epoch : [56] loss : 0.021\n",
      "Epoch : [57] loss : 0.018\n",
      "Epoch : [58] loss : 0.018\n",
      "Epoch : [59] loss : 0.017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.5368, -0.6808, -0.0870],\n",
      "          [ 0.6540, -0.7600, -0.2464],\n",
      "          [ 0.0642, -0.1118, -0.0608]],\n",
      "\n",
      "         [[ 1.7103, -1.5260, -0.0064],\n",
      "          [ 1.4832, -1.5028, -0.1453],\n",
      "          [ 0.3136,  0.0279,  0.0375]],\n",
      "\n",
      "         [[ 0.3485, -0.3677,  0.0527],\n",
      "          [ 0.4317, -0.5252, -0.0842],\n",
      "          [ 0.1171, -0.0133,  0.0747]]],\n",
      "\n",
      "\n",
      "        [[[-0.2980, -0.1653,  0.0898],\n",
      "          [-2.6686, -0.6113,  0.1154],\n",
      "          [-0.4084, -0.3195, -0.1100]],\n",
      "\n",
      "         [[ 0.0566, -0.0992,  0.0504],\n",
      "          [-1.2460, -0.3579, -0.0223],\n",
      "          [-0.1198, -0.2101, -0.1843]],\n",
      "\n",
      "         [[ 0.2138,  0.2986,  0.1574],\n",
      "          [-0.1266,  0.2489,  0.1259],\n",
      "          [ 0.0501,  0.1011, -0.0770]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9603,  1.4169,  0.4512],\n",
      "          [ 1.2235,  1.8256,  0.5172],\n",
      "          [ 0.4063,  0.5216,  0.1552]],\n",
      "\n",
      "         [[-0.7521, -0.9672, -0.3949],\n",
      "          [-0.8794, -1.0583, -0.3714],\n",
      "          [-0.3233, -0.3539, -0.0538]],\n",
      "\n",
      "         [[-0.3550, -0.3831, -0.0644],\n",
      "          [-0.3935, -0.4587,  0.0123],\n",
      "          [-0.0612,  0.0339,  0.0925]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1573, -0.0457, -0.0586],\n",
      "          [-0.5326, -0.4825, -0.0860],\n",
      "          [ 0.6433,  0.4140,  0.1272]],\n",
      "\n",
      "         [[-0.1107, -0.1178,  0.0590],\n",
      "          [-2.4464, -2.2839, -0.0836],\n",
      "          [ 2.5029,  2.4519,  0.2107]],\n",
      "\n",
      "         [[-0.1079, -0.0768, -0.0251],\n",
      "          [-0.2625, -0.2963, -0.0894],\n",
      "          [ 0.3379,  0.2304,  0.1097]]],\n",
      "\n",
      "\n",
      "        [[[-0.6306, -0.0401, -0.1556],\n",
      "          [-0.2246,  0.6733,  0.1815],\n",
      "          [-0.4654,  0.1610,  0.1418]],\n",
      "\n",
      "         [[-2.7963, -0.1426, -0.0257],\n",
      "          [ 0.0103,  2.7607,  0.2919],\n",
      "          [-0.2651,  0.3272,  0.1929]],\n",
      "\n",
      "         [[-0.3124,  0.1347, -0.0448],\n",
      "          [-0.1200,  0.3584,  0.1409],\n",
      "          [-0.3126,  0.1195,  0.0483]]],\n",
      "\n",
      "\n",
      "        [[[-0.7445, -0.4160,  0.1662],\n",
      "          [-0.3208, -0.2266,  0.0967],\n",
      "          [-0.0336, -0.0893, -0.0569]],\n",
      "\n",
      "         [[-1.7761, -1.2401,  0.0385],\n",
      "          [-0.8837, -0.6683,  0.2266],\n",
      "          [-0.0986,  0.0732,  0.1328]],\n",
      "\n",
      "         [[-0.9195, -0.7135, -0.1041],\n",
      "          [-0.2851, -0.2692,  0.0468],\n",
      "          [ 0.0112, -0.0370,  0.0823]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.7484,  2.8908, 10.4698,  2.9541,  2.7427,  4.6135,  2.3387,  2.8891,\n",
      "         3.7947,  3.0664,  2.1704,  9.3195,  0.8796,  1.1377,  9.0967,  8.0259,\n",
      "         0.4583,  4.0346,  4.3865,  3.5840,  1.3182,  1.3069,  7.9114,  4.1424,\n",
      "         1.9186,  4.7158,  2.2578,  0.4864,  6.9049,  3.3527,  2.1365,  3.4830,\n",
      "         0.4948,  3.6279, 11.1920,  1.8260,  5.9992,  3.3339,  3.3388,  3.7746],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([  0.6093,  -3.5574,   1.8906,  -3.7405,  -5.5349,   0.2088,  -3.5221,\n",
      "          2.7672,  -6.0578,   3.0797,   2.4825,   0.7086,   1.8430,   1.8400,\n",
      "          0.1989,   3.2643,  -0.2910,  -5.6002,   2.0390,   3.2007,   2.1585,\n",
      "          1.2725, -13.3381,   1.7772,   2.0559,   9.5640,   2.3210,  -0.5220,\n",
      "          1.9665,   7.5792,  -2.1411,   2.3816,   6.7497,   8.2739,  -2.1472,\n",
      "          2.7829, -11.4704,   2.2966,   2.4197,   8.3567], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 1.4344e-01,  1.8635e-01,  2.4451e-01],\n",
      "          [ 1.6412e-01, -2.1252e+00,  2.6387e-01],\n",
      "          [ 6.7252e-02,  2.1160e-01,  1.8468e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.4828e-02,  9.9250e-02, -3.5436e-01],\n",
      "          [ 3.4773e-01,  1.1629e+00, -3.7406e-01],\n",
      "          [-2.0343e-01, -2.3410e-01, -2.6693e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0248e-02,  3.8625e-01, -4.1588e-01],\n",
      "          [ 5.0652e-01,  1.8519e+00, -7.9545e-01],\n",
      "          [-4.3711e-01, -7.7850e-01,  6.4481e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0129e-01, -3.6060e-02, -2.3639e-01],\n",
      "          [ 9.6274e-02,  1.3234e+00, -1.2980e-01],\n",
      "          [ 3.8935e-03,  1.1041e-01, -2.6135e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.4001e-01, -4.7177e-02, -6.1273e-02],\n",
      "          [-3.5199e-01,  9.0756e-01, -6.9117e-02],\n",
      "          [-3.2557e-01,  3.2864e-01, -1.0485e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6363e-02,  2.1561e-01, -1.0961e-01],\n",
      "          [-1.9573e-01,  1.4202e+00, -1.5755e-01],\n",
      "          [-2.0043e-01, -1.6392e-01, -2.4729e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7146e-01,  8.2766e-02, -2.6354e-01],\n",
      "          [ 1.3765e-01,  1.1781e+00, -1.1394e-01],\n",
      "          [-1.0846e-01, -2.2232e-02,  5.3913e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5387e-01, -6.8656e-02, -4.7328e-01],\n",
      "          [ 4.3839e-02,  1.5940e+00, -8.2589e-02],\n",
      "          [-6.3190e-02, -3.1267e-01, -3.1760e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6583e-02,  8.1821e-02,  6.0371e-02],\n",
      "          [ 1.0402e-01,  6.9881e-01,  7.4496e-02],\n",
      "          [-4.4099e-01, -4.0212e-01, -2.5066e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.8775e-01, -2.4386e-01, -1.1155e-01],\n",
      "          [-2.2607e-01, -8.7724e-01,  1.7728e-01],\n",
      "          [ 1.9409e-01,  3.2806e-01,  3.2802e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.3333e-01, -3.6993e-01,  4.0897e-02],\n",
      "          [ 1.0693e+00, -2.0997e-01,  1.0114e-02],\n",
      "          [-9.2108e-02, -1.0592e-02,  4.7415e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.5221e-01, -5.5730e-01,  3.0699e-01],\n",
      "          [-7.6631e-01, -5.8570e-01,  2.2670e-01],\n",
      "          [-1.4387e-01, -1.6626e-01,  2.5492e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0450e-01, -3.6724e-01, -2.5984e-01],\n",
      "          [-8.7045e-01,  9.7768e-01,  1.0540e-01],\n",
      "          [-1.0393e-01,  5.0405e-02, -1.4790e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.8842e-02, -1.2560e+00,  1.3723e-01],\n",
      "          [ 3.7117e-01,  4.1105e-01,  3.6201e-01],\n",
      "          [-1.8545e-01, -1.2147e-01, -8.4838e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.5314e-02, -4.1730e-01, -1.8739e-02],\n",
      "          [-1.5475e-01, -8.7231e-01,  2.0451e-01],\n",
      "          [ 4.2285e-01,  4.2754e-01,  1.8377e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.0849e-03, -1.9453e-01,  9.9768e-02],\n",
      "          [-5.1336e-02, -8.3352e-01,  1.3213e-01],\n",
      "          [ 6.7379e-01,  4.0704e-01,  5.8358e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1415e-01,  2.4437e-01, -2.1969e-01],\n",
      "          [ 9.4102e-02,  2.2092e+00, -3.6889e-01],\n",
      "          [-2.2657e-01, -4.1944e-01, -1.5624e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7401e-01,  4.9819e-01, -1.4058e-02],\n",
      "          [ 1.3173e-01,  1.4965e+00,  6.6261e-02],\n",
      "          [-3.0794e-01, -1.8235e-01,  1.4378e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.6391e-02,  1.6871e-01, -1.1671e-01],\n",
      "          [ 2.4360e-01,  1.8714e+00, -4.5618e-01],\n",
      "          [-2.4506e-01, -5.6436e-01, -1.1473e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.9133e-01, -4.6548e-01,  2.8162e-02],\n",
      "          [-1.8830e-01, -8.9450e-01,  4.4503e-01],\n",
      "          [ 2.7906e-01,  5.3974e-01,  2.9089e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1753e-01,  4.2073e-01,  2.5831e-01],\n",
      "          [ 2.5429e-01, -1.8242e+00,  1.5150e-01],\n",
      "          [ 3.0529e-02,  1.6469e-01,  3.3599e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8884e-01,  5.4854e-01, -2.3604e-01],\n",
      "          [ 2.2296e-01,  1.7798e+00, -7.0245e-01],\n",
      "          [-5.1353e-01, -7.4511e-01,  3.3267e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4381e-01, -4.9288e-03, -2.8965e-01],\n",
      "          [ 9.1781e-01,  1.0041e+00, -2.8249e-01],\n",
      "          [ 2.3139e-01, -1.8600e-01,  6.9250e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0807e-01,  4.8396e-01, -1.3909e-01],\n",
      "          [ 3.3898e-01,  1.7882e+00, -6.3393e-01],\n",
      "          [-4.3754e-01, -7.4221e-01, -1.4650e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.1248e-01, -5.7856e-01,  2.9610e-01],\n",
      "          [-4.0673e-01, -5.4961e-01,  3.5140e-01],\n",
      "          [ 3.5763e-01,  3.9119e-01,  1.7602e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5732e-01, -1.2616e+00,  1.2334e+00],\n",
      "          [-4.0501e-01, -1.9964e+00,  2.6389e+00],\n",
      "          [-2.9780e-03, -4.5032e-01,  3.3835e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0050e-01, -4.0824e-01, -3.0610e-01],\n",
      "          [-3.3454e-02,  1.1908e+00, -1.4153e-01],\n",
      "          [-5.5960e-02,  1.4867e-01,  7.9171e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.4041e-01, -4.9178e-02, -1.3188e-01],\n",
      "          [ 4.4076e-01,  2.2514e+00, -4.2880e-04],\n",
      "          [-6.9417e-02, -2.8976e-01, -1.0102e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.7321e-02, -1.3530e-01,  1.0329e-01],\n",
      "          [-7.6960e-01, -2.4888e+00,  1.3436e-02],\n",
      "          [-1.9974e-02, -1.8504e-01, -6.4531e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3393e-01,  2.5797e+00,  2.8118e-01],\n",
      "          [-8.6010e-01, -2.1612e+00, -2.3228e-01],\n",
      "          [ 1.6056e-01, -5.5515e-01, -1.0423e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1871e-02, -1.9771e-01, -2.1519e-01],\n",
      "          [-8.2764e-02, -9.6529e-01, -1.5117e-01],\n",
      "          [ 3.9321e-01,  3.8242e-01,  3.3979e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.8296e-01,  1.4372e-01, -6.4654e-02],\n",
      "          [-3.3477e+00,  2.3384e-01,  8.3135e-02],\n",
      "          [ 1.2886e-01,  8.2071e-02,  1.2023e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1331e-01, -1.6244e-01,  9.8574e-02],\n",
      "          [-3.5333e-01,  8.5668e-01,  1.1997e-01],\n",
      "          [-6.6791e-01, -7.0580e-01, -1.9162e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9846e-01, -8.9668e-01,  3.4672e-01],\n",
      "          [ 2.8215e+00, -2.1831e+00, -3.1055e-01],\n",
      "          [ 2.7875e-01, -4.9030e-01,  1.6778e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7452e-01, -5.5981e-01,  3.9449e-02],\n",
      "          [-5.8880e-01, -7.4364e-01, -2.3503e-01],\n",
      "          [-2.8119e-01, -5.7755e-01, -1.2261e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9264e-02, -3.0799e-01, -2.7329e-01],\n",
      "          [-2.4764e-01,  1.3555e+00, -3.6759e-02],\n",
      "          [ 3.0653e-02, -2.7758e-01, -4.5984e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6128e-01,  4.4097e-01, -2.2317e-01],\n",
      "          [ 2.4532e-01,  1.2411e+00, -1.3181e-01],\n",
      "          [-5.2134e-01, -5.1158e-01, -7.1867e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.3605e-01, -3.1490e+00,  6.9793e-02],\n",
      "          [ 2.2246e-01,  2.2780e-01,  1.0091e-01],\n",
      "          [ 4.9002e-02,  8.2183e-02,  1.0114e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3341e-01, -1.5309e-01,  1.2900e-01],\n",
      "          [ 1.7212e-01, -1.9078e+00,  1.2756e-01],\n",
      "          [ 2.3078e-01, -1.0922e-01,  2.1562e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5957e-01,  2.5972e+00,  8.1402e-01],\n",
      "          [-6.5828e-01, -2.0320e+00, -7.0412e-01],\n",
      "          [ 1.6806e-01, -3.9093e-01, -4.8759e-02]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.8602, 1.3377, 3.6865, 0.8446, 0.6683, 1.2184, 0.7911, 3.8617, 0.6198,\n",
      "        1.1387, 2.1287, 5.7308, 1.9553, 1.0549, 4.1896, 2.6930, 3.0791, 0.9358,\n",
      "        2.7710, 1.3827, 2.0865, 3.1704, 1.1006, 3.6237, 1.2325, 5.2301, 2.3014,\n",
      "        1.9805, 4.6206, 4.2926, 0.4686, 2.3842, 0.3539, 4.2445, 7.4062, 3.1619,\n",
      "        1.1593, 2.8204, 1.8483, 3.6243], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.5428,  0.7610,  2.0564,  0.3448, -0.0566,  2.1935, -0.1555,  1.6256,\n",
      "        -0.8678,  0.7580, -0.7398, -4.6322,  0.9472,  1.4315, -0.2153, -1.2338,\n",
      "         3.2020, -0.0962,  1.5911,  1.9580,  1.8551,  2.6107, -3.2687,  1.9318,\n",
      "         1.6696,  1.9740,  0.5626,  2.5201,  0.6479,  1.7125,  2.1195,  1.9323,\n",
      "         0.0301,  1.7435, -4.0312,  1.3971, -0.4048,  1.7651,  1.1693,  1.7590],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 1.5152e-01]],\n",
      "\n",
      "         [[-6.6037e-01]],\n",
      "\n",
      "         [[ 8.3015e-02]],\n",
      "\n",
      "         [[-9.0090e-01]],\n",
      "\n",
      "         [[ 7.0211e-02]],\n",
      "\n",
      "         [[-7.0225e-02]],\n",
      "\n",
      "         [[ 9.5700e-02]],\n",
      "\n",
      "         [[ 1.6162e-01]],\n",
      "\n",
      "         [[ 3.1965e-01]],\n",
      "\n",
      "         [[-1.1947e-01]],\n",
      "\n",
      "         [[-2.0156e-01]],\n",
      "\n",
      "         [[ 1.1033e-01]],\n",
      "\n",
      "         [[-3.6383e-03]],\n",
      "\n",
      "         [[ 1.2869e-01]],\n",
      "\n",
      "         [[-1.0917e-01]],\n",
      "\n",
      "         [[-1.8701e-01]],\n",
      "\n",
      "         [[-6.3617e-01]],\n",
      "\n",
      "         [[ 6.0745e-01]],\n",
      "\n",
      "         [[-1.9125e-02]],\n",
      "\n",
      "         [[-1.5406e-01]],\n",
      "\n",
      "         [[ 1.3816e-01]],\n",
      "\n",
      "         [[-9.9624e-02]],\n",
      "\n",
      "         [[-4.5170e-01]],\n",
      "\n",
      "         [[-2.7525e-02]],\n",
      "\n",
      "         [[-8.8473e-02]],\n",
      "\n",
      "         [[-1.4298e-01]],\n",
      "\n",
      "         [[-6.9319e-02]],\n",
      "\n",
      "         [[-3.4222e-01]],\n",
      "\n",
      "         [[ 1.3176e-01]],\n",
      "\n",
      "         [[-3.5843e-01]],\n",
      "\n",
      "         [[ 2.1024e-01]],\n",
      "\n",
      "         [[ 9.5776e-02]],\n",
      "\n",
      "         [[ 9.1032e-02]],\n",
      "\n",
      "         [[-8.8117e-02]],\n",
      "\n",
      "         [[ 2.4984e-01]],\n",
      "\n",
      "         [[-1.3267e-02]],\n",
      "\n",
      "         [[ 1.9307e-01]],\n",
      "\n",
      "         [[ 7.6222e-02]],\n",
      "\n",
      "         [[ 1.5452e-01]],\n",
      "\n",
      "         [[-4.6516e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5227e-02]],\n",
      "\n",
      "         [[ 3.0335e-01]],\n",
      "\n",
      "         [[-3.1026e-01]],\n",
      "\n",
      "         [[ 2.0074e-01]],\n",
      "\n",
      "         [[-3.0328e-01]],\n",
      "\n",
      "         [[-2.5624e-01]],\n",
      "\n",
      "         [[ 6.1515e-01]],\n",
      "\n",
      "         [[-1.2857e-02]],\n",
      "\n",
      "         [[-5.3950e-02]],\n",
      "\n",
      "         [[ 5.5451e-02]],\n",
      "\n",
      "         [[-2.6939e-02]],\n",
      "\n",
      "         [[ 4.5319e-02]],\n",
      "\n",
      "         [[-2.0740e-02]],\n",
      "\n",
      "         [[ 1.8081e-01]],\n",
      "\n",
      "         [[-6.4997e-02]],\n",
      "\n",
      "         [[-4.2968e-01]],\n",
      "\n",
      "         [[-1.1863e-01]],\n",
      "\n",
      "         [[ 2.9924e-01]],\n",
      "\n",
      "         [[-1.5266e-01]],\n",
      "\n",
      "         [[-3.8705e-01]],\n",
      "\n",
      "         [[ 2.5937e-01]],\n",
      "\n",
      "         [[-1.9165e-01]],\n",
      "\n",
      "         [[ 5.7401e-01]],\n",
      "\n",
      "         [[ 1.2048e-01]],\n",
      "\n",
      "         [[-8.6233e-02]],\n",
      "\n",
      "         [[-1.5908e-01]],\n",
      "\n",
      "         [[-5.3144e-02]],\n",
      "\n",
      "         [[-2.6994e-01]],\n",
      "\n",
      "         [[ 1.4984e-01]],\n",
      "\n",
      "         [[-1.1166e-01]],\n",
      "\n",
      "         [[ 4.8439e-01]],\n",
      "\n",
      "         [[ 9.7098e-02]],\n",
      "\n",
      "         [[ 8.7276e-02]],\n",
      "\n",
      "         [[-7.8700e-02]],\n",
      "\n",
      "         [[-1.0457e-01]],\n",
      "\n",
      "         [[-1.7577e-02]],\n",
      "\n",
      "         [[ 1.0332e-01]],\n",
      "\n",
      "         [[ 9.2614e-02]],\n",
      "\n",
      "         [[ 3.6698e-02]],\n",
      "\n",
      "         [[-4.0847e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.7810e-02]],\n",
      "\n",
      "         [[-2.3034e-01]],\n",
      "\n",
      "         [[ 4.2570e-03]],\n",
      "\n",
      "         [[-3.5930e-01]],\n",
      "\n",
      "         [[ 1.4406e-01]],\n",
      "\n",
      "         [[ 2.3464e-01]],\n",
      "\n",
      "         [[ 3.1301e-01]],\n",
      "\n",
      "         [[ 1.1669e-02]],\n",
      "\n",
      "         [[ 2.2939e-01]],\n",
      "\n",
      "         [[ 2.5385e-01]],\n",
      "\n",
      "         [[ 8.2923e-02]],\n",
      "\n",
      "         [[ 1.5279e-01]],\n",
      "\n",
      "         [[ 4.1847e-02]],\n",
      "\n",
      "         [[-2.1468e-02]],\n",
      "\n",
      "         [[-4.4800e-03]],\n",
      "\n",
      "         [[-2.4807e-01]],\n",
      "\n",
      "         [[-9.2296e-02]],\n",
      "\n",
      "         [[ 3.5938e-01]],\n",
      "\n",
      "         [[-8.5418e-02]],\n",
      "\n",
      "         [[-2.5415e-01]],\n",
      "\n",
      "         [[ 5.7378e-03]],\n",
      "\n",
      "         [[-2.5686e-01]],\n",
      "\n",
      "         [[-2.5994e-02]],\n",
      "\n",
      "         [[-1.2514e+00]],\n",
      "\n",
      "         [[ 3.0076e-02]],\n",
      "\n",
      "         [[ 5.6482e-03]],\n",
      "\n",
      "         [[-1.3878e-03]],\n",
      "\n",
      "         [[-5.9131e-02]],\n",
      "\n",
      "         [[-7.9991e-03]],\n",
      "\n",
      "         [[ 1.3757e-02]],\n",
      "\n",
      "         [[-3.8682e-02]],\n",
      "\n",
      "         [[-1.9497e-02]],\n",
      "\n",
      "         [[-4.6575e-02]],\n",
      "\n",
      "         [[ 5.0307e-03]],\n",
      "\n",
      "         [[ 9.2301e-02]],\n",
      "\n",
      "         [[-4.2178e-02]],\n",
      "\n",
      "         [[ 4.8356e-01]],\n",
      "\n",
      "         [[-8.3658e-02]],\n",
      "\n",
      "         [[ 5.5470e-02]],\n",
      "\n",
      "         [[-7.7193e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.8445e-02]],\n",
      "\n",
      "         [[-7.5163e-01]],\n",
      "\n",
      "         [[-4.1337e-01]],\n",
      "\n",
      "         [[-8.0407e-01]],\n",
      "\n",
      "         [[-1.8712e-01]],\n",
      "\n",
      "         [[-2.4005e-01]],\n",
      "\n",
      "         [[ 1.4851e-01]],\n",
      "\n",
      "         [[ 4.3249e-02]],\n",
      "\n",
      "         [[ 1.1161e-01]],\n",
      "\n",
      "         [[-2.6852e-02]],\n",
      "\n",
      "         [[ 1.2259e-01]],\n",
      "\n",
      "         [[ 7.6766e-02]],\n",
      "\n",
      "         [[-5.9765e-02]],\n",
      "\n",
      "         [[-1.3925e-01]],\n",
      "\n",
      "         [[-9.1469e-03]],\n",
      "\n",
      "         [[ 7.4462e-02]],\n",
      "\n",
      "         [[-2.2189e-01]],\n",
      "\n",
      "         [[-2.6454e-01]],\n",
      "\n",
      "         [[ 2.9087e-01]],\n",
      "\n",
      "         [[-8.5388e-03]],\n",
      "\n",
      "         [[-4.7398e-02]],\n",
      "\n",
      "         [[ 1.5519e-01]],\n",
      "\n",
      "         [[ 7.3670e-02]],\n",
      "\n",
      "         [[-5.4908e-01]],\n",
      "\n",
      "         [[-2.3491e-02]],\n",
      "\n",
      "         [[-1.2471e-03]],\n",
      "\n",
      "         [[-1.4152e-02]],\n",
      "\n",
      "         [[-2.3505e-01]],\n",
      "\n",
      "         [[-1.7093e-01]],\n",
      "\n",
      "         [[ 1.0983e-01]],\n",
      "\n",
      "         [[-6.7668e-02]],\n",
      "\n",
      "         [[-2.6191e-01]],\n",
      "\n",
      "         [[-1.0585e-01]],\n",
      "\n",
      "         [[ 3.9864e-03]],\n",
      "\n",
      "         [[-1.1946e-01]],\n",
      "\n",
      "         [[ 8.6762e-02]],\n",
      "\n",
      "         [[ 1.9802e-02]],\n",
      "\n",
      "         [[-4.8730e-02]],\n",
      "\n",
      "         [[-1.2617e-02]],\n",
      "\n",
      "         [[-5.8847e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.0402e-02]],\n",
      "\n",
      "         [[-2.4950e-01]],\n",
      "\n",
      "         [[ 2.7233e-02]],\n",
      "\n",
      "         [[-5.5173e-01]],\n",
      "\n",
      "         [[ 4.1705e-02]],\n",
      "\n",
      "         [[-5.2860e-02]],\n",
      "\n",
      "         [[ 3.5339e-01]],\n",
      "\n",
      "         [[-1.1334e-01]],\n",
      "\n",
      "         [[ 1.0368e-01]],\n",
      "\n",
      "         [[ 3.8837e-02]],\n",
      "\n",
      "         [[-3.8173e-01]],\n",
      "\n",
      "         [[ 3.5880e-02]],\n",
      "\n",
      "         [[-2.5329e-01]],\n",
      "\n",
      "         [[ 1.8980e-01]],\n",
      "\n",
      "         [[-4.4811e-02]],\n",
      "\n",
      "         [[ 5.6344e-02]],\n",
      "\n",
      "         [[-1.1538e-01]],\n",
      "\n",
      "         [[ 2.0119e-01]],\n",
      "\n",
      "         [[ 1.7931e-02]],\n",
      "\n",
      "         [[-2.0208e-03]],\n",
      "\n",
      "         [[-9.8162e-02]],\n",
      "\n",
      "         [[ 1.0061e-02]],\n",
      "\n",
      "         [[-5.0384e-01]],\n",
      "\n",
      "         [[-8.0614e-02]],\n",
      "\n",
      "         [[ 1.3117e-01]],\n",
      "\n",
      "         [[-1.2103e-01]],\n",
      "\n",
      "         [[-1.0961e-01]],\n",
      "\n",
      "         [[ 1.9565e-01]],\n",
      "\n",
      "         [[-5.1619e-02]],\n",
      "\n",
      "         [[-5.9667e-01]],\n",
      "\n",
      "         [[ 2.5083e-01]],\n",
      "\n",
      "         [[ 2.1526e-02]],\n",
      "\n",
      "         [[-2.6084e-02]],\n",
      "\n",
      "         [[-7.0408e-02]],\n",
      "\n",
      "         [[ 1.5029e-02]],\n",
      "\n",
      "         [[-3.0287e-01]],\n",
      "\n",
      "         [[ 5.5261e-01]],\n",
      "\n",
      "         [[-1.8883e-01]],\n",
      "\n",
      "         [[ 3.6232e-02]],\n",
      "\n",
      "         [[-2.7887e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9283e-02]],\n",
      "\n",
      "         [[ 4.7571e-02]],\n",
      "\n",
      "         [[-8.1683e-01]],\n",
      "\n",
      "         [[ 1.6516e-01]],\n",
      "\n",
      "         [[-5.9005e-02]],\n",
      "\n",
      "         [[-3.6379e-01]],\n",
      "\n",
      "         [[ 2.6354e-01]],\n",
      "\n",
      "         [[ 5.0407e-02]],\n",
      "\n",
      "         [[ 1.7035e-01]],\n",
      "\n",
      "         [[ 4.5998e-02]],\n",
      "\n",
      "         [[ 1.2926e-01]],\n",
      "\n",
      "         [[-1.5767e-02]],\n",
      "\n",
      "         [[ 1.3471e-01]],\n",
      "\n",
      "         [[ 1.3727e-01]],\n",
      "\n",
      "         [[ 1.1172e-01]],\n",
      "\n",
      "         [[ 5.5052e-02]],\n",
      "\n",
      "         [[ 3.4043e-01]],\n",
      "\n",
      "         [[ 3.0040e-02]],\n",
      "\n",
      "         [[-9.5586e-01]],\n",
      "\n",
      "         [[-1.5953e-01]],\n",
      "\n",
      "         [[ 3.8705e-02]],\n",
      "\n",
      "         [[-8.4865e-01]],\n",
      "\n",
      "         [[ 2.8654e-03]],\n",
      "\n",
      "         [[-1.3108e+00]],\n",
      "\n",
      "         [[ 1.4856e-01]],\n",
      "\n",
      "         [[ 1.8564e-01]],\n",
      "\n",
      "         [[ 3.8751e-02]],\n",
      "\n",
      "         [[-1.7199e-01]],\n",
      "\n",
      "         [[ 1.6706e-02]],\n",
      "\n",
      "         [[ 1.9484e-01]],\n",
      "\n",
      "         [[ 2.3275e-01]],\n",
      "\n",
      "         [[ 4.0145e-02]],\n",
      "\n",
      "         [[ 2.3977e-01]],\n",
      "\n",
      "         [[ 2.1179e-01]],\n",
      "\n",
      "         [[-1.9449e-01]],\n",
      "\n",
      "         [[-8.1296e-03]],\n",
      "\n",
      "         [[-1.9585e-01]],\n",
      "\n",
      "         [[ 4.4097e-02]],\n",
      "\n",
      "         [[ 1.0526e-01]],\n",
      "\n",
      "         [[ 7.7584e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.6077e-02]],\n",
      "\n",
      "         [[-5.5433e-02]],\n",
      "\n",
      "         [[ 3.9393e-01]],\n",
      "\n",
      "         [[-3.1337e-01]],\n",
      "\n",
      "         [[-3.1113e-01]],\n",
      "\n",
      "         [[-1.0797e-01]],\n",
      "\n",
      "         [[-2.3849e-01]],\n",
      "\n",
      "         [[-6.4281e-02]],\n",
      "\n",
      "         [[ 9.1245e-02]],\n",
      "\n",
      "         [[ 4.2892e-02]],\n",
      "\n",
      "         [[ 7.4252e-02]],\n",
      "\n",
      "         [[-1.1753e-01]],\n",
      "\n",
      "         [[-4.8432e-03]],\n",
      "\n",
      "         [[-2.5002e-01]],\n",
      "\n",
      "         [[-1.7902e-01]],\n",
      "\n",
      "         [[ 7.0212e-02]],\n",
      "\n",
      "         [[ 4.7142e-02]],\n",
      "\n",
      "         [[-3.4068e-01]],\n",
      "\n",
      "         [[-6.6841e-01]],\n",
      "\n",
      "         [[ 1.2674e-01]],\n",
      "\n",
      "         [[-2.9538e-01]],\n",
      "\n",
      "         [[-3.8167e-01]],\n",
      "\n",
      "         [[-1.7118e-02]],\n",
      "\n",
      "         [[-3.2217e-01]],\n",
      "\n",
      "         [[ 2.1847e-01]],\n",
      "\n",
      "         [[ 5.6155e-02]],\n",
      "\n",
      "         [[-1.6864e-01]],\n",
      "\n",
      "         [[-4.3026e-01]],\n",
      "\n",
      "         [[-1.6255e-01]],\n",
      "\n",
      "         [[ 4.7900e-02]],\n",
      "\n",
      "         [[-1.1733e-01]],\n",
      "\n",
      "         [[-9.1188e-02]],\n",
      "\n",
      "         [[-8.4261e-02]],\n",
      "\n",
      "         [[ 7.7343e-02]],\n",
      "\n",
      "         [[ 1.0334e-01]],\n",
      "\n",
      "         [[-2.2624e-01]],\n",
      "\n",
      "         [[-1.6793e-01]],\n",
      "\n",
      "         [[-2.2898e-01]],\n",
      "\n",
      "         [[-7.8274e-02]],\n",
      "\n",
      "         [[ 6.3789e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.3879e-02]],\n",
      "\n",
      "         [[ 3.7879e-01]],\n",
      "\n",
      "         [[-5.6423e-01]],\n",
      "\n",
      "         [[ 3.2901e-01]],\n",
      "\n",
      "         [[-6.0127e-03]],\n",
      "\n",
      "         [[-4.8556e-01]],\n",
      "\n",
      "         [[ 7.5062e-01]],\n",
      "\n",
      "         [[ 6.8774e-02]],\n",
      "\n",
      "         [[ 7.2938e-02]],\n",
      "\n",
      "         [[-9.9669e-02]],\n",
      "\n",
      "         [[-1.0490e-01]],\n",
      "\n",
      "         [[-1.1582e-01]],\n",
      "\n",
      "         [[-7.4176e-02]],\n",
      "\n",
      "         [[-1.2209e-01]],\n",
      "\n",
      "         [[ 1.8353e-01]],\n",
      "\n",
      "         [[-2.7899e-01]],\n",
      "\n",
      "         [[-4.6241e-02]],\n",
      "\n",
      "         [[ 1.4881e-02]],\n",
      "\n",
      "         [[-2.0392e-02]],\n",
      "\n",
      "         [[ 1.5097e-01]],\n",
      "\n",
      "         [[-9.7785e-02]],\n",
      "\n",
      "         [[ 2.9606e-01]],\n",
      "\n",
      "         [[ 5.3591e-01]],\n",
      "\n",
      "         [[-2.5197e-01]],\n",
      "\n",
      "         [[-8.7684e-02]],\n",
      "\n",
      "         [[ 1.4999e-01]],\n",
      "\n",
      "         [[-1.0193e-01]],\n",
      "\n",
      "         [[-9.3112e-02]],\n",
      "\n",
      "         [[-2.6590e-01]],\n",
      "\n",
      "         [[-1.5540e-01]],\n",
      "\n",
      "         [[-2.8551e-02]],\n",
      "\n",
      "         [[-1.5740e-01]],\n",
      "\n",
      "         [[-6.0379e-02]],\n",
      "\n",
      "         [[ 2.4982e-02]],\n",
      "\n",
      "         [[-3.1542e-01]],\n",
      "\n",
      "         [[-1.5393e-01]],\n",
      "\n",
      "         [[ 5.8590e-01]],\n",
      "\n",
      "         [[-3.9566e-02]],\n",
      "\n",
      "         [[-1.0322e-01]],\n",
      "\n",
      "         [[-6.4268e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.4678e-02]],\n",
      "\n",
      "         [[-1.0014e-02]],\n",
      "\n",
      "         [[-3.8298e-02]],\n",
      "\n",
      "         [[ 1.2137e-01]],\n",
      "\n",
      "         [[-1.9743e-01]],\n",
      "\n",
      "         [[-3.3882e-01]],\n",
      "\n",
      "         [[ 8.1730e-01]],\n",
      "\n",
      "         [[-7.4437e-02]],\n",
      "\n",
      "         [[-3.3835e-01]],\n",
      "\n",
      "         [[-2.2801e-02]],\n",
      "\n",
      "         [[ 1.3565e-01]],\n",
      "\n",
      "         [[ 1.2141e-01]],\n",
      "\n",
      "         [[ 6.7770e-02]],\n",
      "\n",
      "         [[ 3.4931e-02]],\n",
      "\n",
      "         [[-3.2837e-02]],\n",
      "\n",
      "         [[-6.8787e-01]],\n",
      "\n",
      "         [[ 1.0370e-01]],\n",
      "\n",
      "         [[-9.2011e-02]],\n",
      "\n",
      "         [[-5.4229e-01]],\n",
      "\n",
      "         [[-2.4013e-01]],\n",
      "\n",
      "         [[ 4.0274e-02]],\n",
      "\n",
      "         [[-3.5508e-01]],\n",
      "\n",
      "         [[ 1.3734e-01]],\n",
      "\n",
      "         [[ 1.0474e-02]],\n",
      "\n",
      "         [[-3.3751e-01]],\n",
      "\n",
      "         [[ 1.3010e-01]],\n",
      "\n",
      "         [[-1.8641e-01]],\n",
      "\n",
      "         [[-1.5726e-01]],\n",
      "\n",
      "         [[ 5.4343e-02]],\n",
      "\n",
      "         [[ 1.1816e-01]],\n",
      "\n",
      "         [[ 1.5671e-01]],\n",
      "\n",
      "         [[ 1.2359e-01]],\n",
      "\n",
      "         [[ 9.8904e-02]],\n",
      "\n",
      "         [[ 5.4096e-02]],\n",
      "\n",
      "         [[-2.1563e-01]],\n",
      "\n",
      "         [[-2.8999e-02]],\n",
      "\n",
      "         [[-2.5811e-01]],\n",
      "\n",
      "         [[ 1.1822e-01]],\n",
      "\n",
      "         [[ 3.2730e-02]],\n",
      "\n",
      "         [[-4.0258e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.6267e-02]],\n",
      "\n",
      "         [[-7.9715e-02]],\n",
      "\n",
      "         [[ 1.3031e-01]],\n",
      "\n",
      "         [[-1.6855e-01]],\n",
      "\n",
      "         [[-6.1312e-03]],\n",
      "\n",
      "         [[-2.5526e-01]],\n",
      "\n",
      "         [[ 2.0498e-01]],\n",
      "\n",
      "         [[-4.5995e-01]],\n",
      "\n",
      "         [[ 3.9881e-01]],\n",
      "\n",
      "         [[ 6.7335e-02]],\n",
      "\n",
      "         [[-1.7479e-01]],\n",
      "\n",
      "         [[ 2.9007e-02]],\n",
      "\n",
      "         [[-4.5098e-01]],\n",
      "\n",
      "         [[ 3.7501e-02]],\n",
      "\n",
      "         [[-1.8227e-01]],\n",
      "\n",
      "         [[ 4.5410e-03]],\n",
      "\n",
      "         [[ 1.0077e-02]],\n",
      "\n",
      "         [[ 1.5878e-01]],\n",
      "\n",
      "         [[ 3.1094e-01]],\n",
      "\n",
      "         [[ 3.9651e-01]],\n",
      "\n",
      "         [[ 5.7392e-02]],\n",
      "\n",
      "         [[-3.8019e-01]],\n",
      "\n",
      "         [[-1.0287e-01]],\n",
      "\n",
      "         [[-1.9218e-01]],\n",
      "\n",
      "         [[ 1.5383e-01]],\n",
      "\n",
      "         [[-6.5635e-01]],\n",
      "\n",
      "         [[-4.7530e-02]],\n",
      "\n",
      "         [[-4.1894e-02]],\n",
      "\n",
      "         [[ 1.7713e-01]],\n",
      "\n",
      "         [[ 1.2347e-01]],\n",
      "\n",
      "         [[ 2.4866e-01]],\n",
      "\n",
      "         [[-5.7190e-02]],\n",
      "\n",
      "         [[ 1.7451e-02]],\n",
      "\n",
      "         [[-5.1644e-01]],\n",
      "\n",
      "         [[-1.5729e-01]],\n",
      "\n",
      "         [[-2.1046e-02]],\n",
      "\n",
      "         [[ 5.6457e-01]],\n",
      "\n",
      "         [[ 4.8125e-02]],\n",
      "\n",
      "         [[-5.0677e-02]],\n",
      "\n",
      "         [[-8.1341e-02]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1698,  0.1921,  0.0135, -0.1314,  0.2112,  0.0509, -0.1543, -0.1418,\n",
      "         0.0835,  0.1151], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.8215]],\n",
      "\n",
      "         [[-0.6920]],\n",
      "\n",
      "         [[ 0.1956]],\n",
      "\n",
      "         [[ 0.0891]],\n",
      "\n",
      "         [[-1.1595]],\n",
      "\n",
      "         [[ 0.0679]],\n",
      "\n",
      "         [[ 0.1006]],\n",
      "\n",
      "         [[-0.1967]],\n",
      "\n",
      "         [[-0.3323]],\n",
      "\n",
      "         [[-0.9792]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2048]],\n",
      "\n",
      "         [[ 0.3515]],\n",
      "\n",
      "         [[-0.3545]],\n",
      "\n",
      "         [[-0.3378]],\n",
      "\n",
      "         [[ 0.0740]],\n",
      "\n",
      "         [[-0.5265]],\n",
      "\n",
      "         [[-0.3083]],\n",
      "\n",
      "         [[ 0.1225]],\n",
      "\n",
      "         [[-0.2881]],\n",
      "\n",
      "         [[ 0.0311]]],\n",
      "\n",
      "\n",
      "        [[[-0.0708]],\n",
      "\n",
      "         [[-1.0223]],\n",
      "\n",
      "         [[ 0.0978]],\n",
      "\n",
      "         [[-1.0288]],\n",
      "\n",
      "         [[ 0.0408]],\n",
      "\n",
      "         [[-0.9112]],\n",
      "\n",
      "         [[ 0.4466]],\n",
      "\n",
      "         [[-1.0745]],\n",
      "\n",
      "         [[-0.6044]],\n",
      "\n",
      "         [[ 0.1082]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0860]],\n",
      "\n",
      "         [[ 0.6073]],\n",
      "\n",
      "         [[-0.2799]],\n",
      "\n",
      "         [[-0.1906]],\n",
      "\n",
      "         [[-0.1177]],\n",
      "\n",
      "         [[-0.0894]],\n",
      "\n",
      "         [[-0.5323]],\n",
      "\n",
      "         [[ 0.4083]],\n",
      "\n",
      "         [[-0.0158]],\n",
      "\n",
      "         [[ 0.5150]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7138]],\n",
      "\n",
      "         [[ 0.7191]],\n",
      "\n",
      "         [[ 0.6226]],\n",
      "\n",
      "         [[-0.0376]],\n",
      "\n",
      "         [[ 0.5368]],\n",
      "\n",
      "         [[ 0.3139]],\n",
      "\n",
      "         [[ 0.0890]],\n",
      "\n",
      "         [[ 0.7239]],\n",
      "\n",
      "         [[ 0.5366]],\n",
      "\n",
      "         [[ 0.7117]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2358]],\n",
      "\n",
      "         [[-1.1522]],\n",
      "\n",
      "         [[ 0.7950]],\n",
      "\n",
      "         [[-0.1214]],\n",
      "\n",
      "         [[ 0.2836]],\n",
      "\n",
      "         [[ 0.2503]],\n",
      "\n",
      "         [[ 0.0801]],\n",
      "\n",
      "         [[-1.2361]],\n",
      "\n",
      "         [[-0.8382]],\n",
      "\n",
      "         [[ 0.2430]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2075]],\n",
      "\n",
      "         [[-0.0023]],\n",
      "\n",
      "         [[-0.5838]],\n",
      "\n",
      "         [[-0.3663]],\n",
      "\n",
      "         [[ 0.1433]],\n",
      "\n",
      "         [[-0.4012]],\n",
      "\n",
      "         [[-0.3326]],\n",
      "\n",
      "         [[-0.3683]],\n",
      "\n",
      "         [[-0.1857]],\n",
      "\n",
      "         [[ 0.1473]]],\n",
      "\n",
      "\n",
      "        [[[-0.1671]],\n",
      "\n",
      "         [[-0.6260]],\n",
      "\n",
      "         [[-0.0594]],\n",
      "\n",
      "         [[-0.0400]],\n",
      "\n",
      "         [[-0.6119]],\n",
      "\n",
      "         [[-0.1477]],\n",
      "\n",
      "         [[ 0.2188]],\n",
      "\n",
      "         [[-0.3920]],\n",
      "\n",
      "         [[-0.3729]],\n",
      "\n",
      "         [[-0.6762]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6088]],\n",
      "\n",
      "         [[ 0.6299]],\n",
      "\n",
      "         [[-0.0102]],\n",
      "\n",
      "         [[-0.0624]],\n",
      "\n",
      "         [[ 0.5889]],\n",
      "\n",
      "         [[ 0.1425]],\n",
      "\n",
      "         [[ 0.4819]],\n",
      "\n",
      "         [[ 0.4252]],\n",
      "\n",
      "         [[ 0.7298]],\n",
      "\n",
      "         [[ 0.5143]]],\n",
      "\n",
      "\n",
      "        [[[-0.4030]],\n",
      "\n",
      "         [[-0.0808]],\n",
      "\n",
      "         [[ 0.6342]],\n",
      "\n",
      "         [[ 0.2866]],\n",
      "\n",
      "         [[ 0.0345]],\n",
      "\n",
      "         [[-0.0204]],\n",
      "\n",
      "         [[-0.1449]],\n",
      "\n",
      "         [[-0.5282]],\n",
      "\n",
      "         [[-0.5464]],\n",
      "\n",
      "         [[-0.0143]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1377]],\n",
      "\n",
      "         [[-0.1549]],\n",
      "\n",
      "         [[ 0.0763]],\n",
      "\n",
      "         [[ 0.1753]],\n",
      "\n",
      "         [[-0.0156]],\n",
      "\n",
      "         [[-0.1244]],\n",
      "\n",
      "         [[ 0.4416]],\n",
      "\n",
      "         [[ 0.2611]],\n",
      "\n",
      "         [[ 0.2114]],\n",
      "\n",
      "         [[ 0.0521]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5292]],\n",
      "\n",
      "         [[ 0.5792]],\n",
      "\n",
      "         [[ 0.6054]],\n",
      "\n",
      "         [[ 0.6857]],\n",
      "\n",
      "         [[ 0.5309]],\n",
      "\n",
      "         [[ 0.0691]],\n",
      "\n",
      "         [[ 0.4718]],\n",
      "\n",
      "         [[ 0.5487]],\n",
      "\n",
      "         [[ 0.6743]],\n",
      "\n",
      "         [[ 0.3697]]],\n",
      "\n",
      "\n",
      "        [[[-0.3287]],\n",
      "\n",
      "         [[-0.3209]],\n",
      "\n",
      "         [[ 0.1331]],\n",
      "\n",
      "         [[ 0.0159]],\n",
      "\n",
      "         [[-0.5598]],\n",
      "\n",
      "         [[ 0.2911]],\n",
      "\n",
      "         [[ 0.3099]],\n",
      "\n",
      "         [[-0.3623]],\n",
      "\n",
      "         [[ 0.4238]],\n",
      "\n",
      "         [[-0.7222]]],\n",
      "\n",
      "\n",
      "        [[[-0.0715]],\n",
      "\n",
      "         [[-0.0080]],\n",
      "\n",
      "         [[-0.0342]],\n",
      "\n",
      "         [[ 0.4028]],\n",
      "\n",
      "         [[-0.2103]],\n",
      "\n",
      "         [[ 0.1267]],\n",
      "\n",
      "         [[ 0.2258]],\n",
      "\n",
      "         [[-0.1220]],\n",
      "\n",
      "         [[ 0.4156]],\n",
      "\n",
      "         [[-0.3088]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9952]],\n",
      "\n",
      "         [[ 0.1288]],\n",
      "\n",
      "         [[ 1.7115]],\n",
      "\n",
      "         [[ 0.3307]],\n",
      "\n",
      "         [[ 1.5378]],\n",
      "\n",
      "         [[-1.0786]],\n",
      "\n",
      "         [[ 0.0648]],\n",
      "\n",
      "         [[-0.6794]],\n",
      "\n",
      "         [[ 0.1953]],\n",
      "\n",
      "         [[ 0.8902]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5961]],\n",
      "\n",
      "         [[ 0.8772]],\n",
      "\n",
      "         [[ 0.3114]],\n",
      "\n",
      "         [[ 0.8275]],\n",
      "\n",
      "         [[ 0.9089]],\n",
      "\n",
      "         [[-0.5624]],\n",
      "\n",
      "         [[ 0.2596]],\n",
      "\n",
      "         [[ 0.1194]],\n",
      "\n",
      "         [[ 0.1703]],\n",
      "\n",
      "         [[ 0.8457]]],\n",
      "\n",
      "\n",
      "        [[[-2.0346]],\n",
      "\n",
      "         [[-0.1836]],\n",
      "\n",
      "         [[-0.0703]],\n",
      "\n",
      "         [[-0.5776]],\n",
      "\n",
      "         [[-1.2807]],\n",
      "\n",
      "         [[ 0.0611]],\n",
      "\n",
      "         [[-0.0759]],\n",
      "\n",
      "         [[ 0.0056]],\n",
      "\n",
      "         [[ 0.1354]],\n",
      "\n",
      "         [[-0.8784]]],\n",
      "\n",
      "\n",
      "        [[[-0.3033]],\n",
      "\n",
      "         [[ 0.0901]],\n",
      "\n",
      "         [[-0.7567]],\n",
      "\n",
      "         [[-1.2625]],\n",
      "\n",
      "         [[-0.1970]],\n",
      "\n",
      "         [[-0.7306]],\n",
      "\n",
      "         [[-0.0939]],\n",
      "\n",
      "         [[-0.6353]],\n",
      "\n",
      "         [[-0.1726]],\n",
      "\n",
      "         [[-0.1572]]],\n",
      "\n",
      "\n",
      "        [[[-0.0681]],\n",
      "\n",
      "         [[-0.6080]],\n",
      "\n",
      "         [[-0.2280]],\n",
      "\n",
      "         [[ 0.2606]],\n",
      "\n",
      "         [[-0.0053]],\n",
      "\n",
      "         [[-1.3549]],\n",
      "\n",
      "         [[-1.6307]],\n",
      "\n",
      "         [[-0.4839]],\n",
      "\n",
      "         [[-1.0245]],\n",
      "\n",
      "         [[ 0.2941]]],\n",
      "\n",
      "\n",
      "        [[[-0.1734]],\n",
      "\n",
      "         [[-0.0556]],\n",
      "\n",
      "         [[-2.2080]],\n",
      "\n",
      "         [[-1.0561]],\n",
      "\n",
      "         [[ 0.0473]],\n",
      "\n",
      "         [[-0.6703]],\n",
      "\n",
      "         [[-0.4013]],\n",
      "\n",
      "         [[-0.0242]],\n",
      "\n",
      "         [[-0.1491]],\n",
      "\n",
      "         [[-0.0971]]],\n",
      "\n",
      "\n",
      "        [[[-0.1740]],\n",
      "\n",
      "         [[-0.2659]],\n",
      "\n",
      "         [[-0.0925]],\n",
      "\n",
      "         [[ 0.2161]],\n",
      "\n",
      "         [[-0.2950]],\n",
      "\n",
      "         [[ 0.0244]],\n",
      "\n",
      "         [[ 0.1057]],\n",
      "\n",
      "         [[-0.1776]],\n",
      "\n",
      "         [[-0.1706]],\n",
      "\n",
      "         [[-0.3697]]],\n",
      "\n",
      "\n",
      "        [[[-0.4409]],\n",
      "\n",
      "         [[-1.3597]],\n",
      "\n",
      "         [[-0.4329]],\n",
      "\n",
      "         [[ 0.1247]],\n",
      "\n",
      "         [[-0.0961]],\n",
      "\n",
      "         [[-0.5288]],\n",
      "\n",
      "         [[-0.4924]],\n",
      "\n",
      "         [[-0.1850]],\n",
      "\n",
      "         [[-1.2717]],\n",
      "\n",
      "         [[-0.6298]]],\n",
      "\n",
      "\n",
      "        [[[-0.2314]],\n",
      "\n",
      "         [[ 0.1679]],\n",
      "\n",
      "         [[ 0.3210]],\n",
      "\n",
      "         [[-0.0145]],\n",
      "\n",
      "         [[ 0.0159]],\n",
      "\n",
      "         [[-0.2863]],\n",
      "\n",
      "         [[ 0.3383]],\n",
      "\n",
      "         [[ 0.3803]],\n",
      "\n",
      "         [[-0.0506]],\n",
      "\n",
      "         [[ 0.5022]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1130]],\n",
      "\n",
      "         [[-0.1215]],\n",
      "\n",
      "         [[-1.6768]],\n",
      "\n",
      "         [[-1.0715]],\n",
      "\n",
      "         [[ 0.0100]],\n",
      "\n",
      "         [[-1.3575]],\n",
      "\n",
      "         [[-0.6839]],\n",
      "\n",
      "         [[-0.6962]],\n",
      "\n",
      "         [[ 0.0619]],\n",
      "\n",
      "         [[-0.5424]]],\n",
      "\n",
      "\n",
      "        [[[-0.4714]],\n",
      "\n",
      "         [[ 0.0228]],\n",
      "\n",
      "         [[-1.0172]],\n",
      "\n",
      "         [[-0.4778]],\n",
      "\n",
      "         [[-0.0965]],\n",
      "\n",
      "         [[-0.7406]],\n",
      "\n",
      "         [[ 0.0484]],\n",
      "\n",
      "         [[-0.5395]],\n",
      "\n",
      "         [[-0.9323]],\n",
      "\n",
      "         [[ 0.3531]]],\n",
      "\n",
      "\n",
      "        [[[-0.5963]],\n",
      "\n",
      "         [[-0.7437]],\n",
      "\n",
      "         [[-0.0298]],\n",
      "\n",
      "         [[-0.0095]],\n",
      "\n",
      "         [[-0.8181]],\n",
      "\n",
      "         [[ 0.1262]],\n",
      "\n",
      "         [[-0.0796]],\n",
      "\n",
      "         [[-0.1017]],\n",
      "\n",
      "         [[-0.2896]],\n",
      "\n",
      "         [[-1.1087]]],\n",
      "\n",
      "\n",
      "        [[[-0.0144]],\n",
      "\n",
      "         [[-0.3006]],\n",
      "\n",
      "         [[-0.3048]],\n",
      "\n",
      "         [[ 0.2371]],\n",
      "\n",
      "         [[-0.0881]],\n",
      "\n",
      "         [[ 0.0874]],\n",
      "\n",
      "         [[ 0.0664]],\n",
      "\n",
      "         [[ 0.2403]],\n",
      "\n",
      "         [[-0.4149]],\n",
      "\n",
      "         [[-0.0143]]],\n",
      "\n",
      "\n",
      "        [[[-0.2903]],\n",
      "\n",
      "         [[-0.9345]],\n",
      "\n",
      "         [[ 0.1250]],\n",
      "\n",
      "         [[-0.0351]],\n",
      "\n",
      "         [[-0.4482]],\n",
      "\n",
      "         [[-0.0665]],\n",
      "\n",
      "         [[ 0.2369]],\n",
      "\n",
      "         [[ 0.1610]],\n",
      "\n",
      "         [[ 0.1010]],\n",
      "\n",
      "         [[-0.2688]]],\n",
      "\n",
      "\n",
      "        [[[-0.2337]],\n",
      "\n",
      "         [[-0.2548]],\n",
      "\n",
      "         [[-0.2522]],\n",
      "\n",
      "         [[ 0.4044]],\n",
      "\n",
      "         [[-0.4558]],\n",
      "\n",
      "         [[ 0.0472]],\n",
      "\n",
      "         [[-0.5327]],\n",
      "\n",
      "         [[ 0.0499]],\n",
      "\n",
      "         [[-0.1769]],\n",
      "\n",
      "         [[-0.2143]]],\n",
      "\n",
      "\n",
      "        [[[-0.4857]],\n",
      "\n",
      "         [[-0.3828]],\n",
      "\n",
      "         [[-0.0146]],\n",
      "\n",
      "         [[ 0.1955]],\n",
      "\n",
      "         [[-0.4309]],\n",
      "\n",
      "         [[ 0.2444]],\n",
      "\n",
      "         [[-0.1699]],\n",
      "\n",
      "         [[-0.0756]],\n",
      "\n",
      "         [[-0.2448]],\n",
      "\n",
      "         [[ 0.1673]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0496]],\n",
      "\n",
      "         [[ 0.3991]],\n",
      "\n",
      "         [[-1.6038]],\n",
      "\n",
      "         [[ 0.1767]],\n",
      "\n",
      "         [[ 0.0168]],\n",
      "\n",
      "         [[ 0.1135]],\n",
      "\n",
      "         [[-0.3429]],\n",
      "\n",
      "         [[ 1.0153]],\n",
      "\n",
      "         [[ 0.6526]],\n",
      "\n",
      "         [[ 0.1118]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0382]],\n",
      "\n",
      "         [[-0.2658]],\n",
      "\n",
      "         [[ 0.2856]],\n",
      "\n",
      "         [[-0.2598]],\n",
      "\n",
      "         [[-1.1919]],\n",
      "\n",
      "         [[-0.0928]],\n",
      "\n",
      "         [[ 0.3701]],\n",
      "\n",
      "         [[-0.5836]],\n",
      "\n",
      "         [[ 0.0975]],\n",
      "\n",
      "         [[-0.9887]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2869]],\n",
      "\n",
      "         [[ 0.4979]],\n",
      "\n",
      "         [[ 0.0225]],\n",
      "\n",
      "         [[ 0.9221]],\n",
      "\n",
      "         [[-0.0267]],\n",
      "\n",
      "         [[ 0.6808]],\n",
      "\n",
      "         [[ 0.2613]],\n",
      "\n",
      "         [[ 0.8677]],\n",
      "\n",
      "         [[ 0.3970]],\n",
      "\n",
      "         [[ 0.2261]]],\n",
      "\n",
      "\n",
      "        [[[-0.5256]],\n",
      "\n",
      "         [[-0.6739]],\n",
      "\n",
      "         [[ 0.0254]],\n",
      "\n",
      "         [[-0.0982]],\n",
      "\n",
      "         [[-0.8293]],\n",
      "\n",
      "         [[-0.0616]],\n",
      "\n",
      "         [[ 0.2254]],\n",
      "\n",
      "         [[-0.0812]],\n",
      "\n",
      "         [[-0.1727]],\n",
      "\n",
      "         [[-1.1602]]],\n",
      "\n",
      "\n",
      "        [[[-0.4185]],\n",
      "\n",
      "         [[ 0.2661]],\n",
      "\n",
      "         [[ 0.2568]],\n",
      "\n",
      "         [[ 0.4203]],\n",
      "\n",
      "         [[-0.0052]],\n",
      "\n",
      "         [[-0.1466]],\n",
      "\n",
      "         [[ 0.5895]],\n",
      "\n",
      "         [[ 0.6863]],\n",
      "\n",
      "         [[ 0.1953]],\n",
      "\n",
      "         [[ 0.1062]]],\n",
      "\n",
      "\n",
      "        [[[-0.0842]],\n",
      "\n",
      "         [[-0.5411]],\n",
      "\n",
      "         [[-0.4322]],\n",
      "\n",
      "         [[ 0.1122]],\n",
      "\n",
      "         [[-0.5567]],\n",
      "\n",
      "         [[ 0.4477]],\n",
      "\n",
      "         [[-0.1284]],\n",
      "\n",
      "         [[ 0.0920]],\n",
      "\n",
      "         [[-0.1208]],\n",
      "\n",
      "         [[-0.4972]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1477]],\n",
      "\n",
      "         [[-0.3369]],\n",
      "\n",
      "         [[-0.5322]],\n",
      "\n",
      "         [[-0.6145]],\n",
      "\n",
      "         [[-0.3855]],\n",
      "\n",
      "         [[-0.5355]],\n",
      "\n",
      "         [[-0.4526]],\n",
      "\n",
      "         [[-0.1681]],\n",
      "\n",
      "         [[-0.3442]],\n",
      "\n",
      "         [[-0.3702]]],\n",
      "\n",
      "\n",
      "        [[[-0.1724]],\n",
      "\n",
      "         [[-0.2089]],\n",
      "\n",
      "         [[-0.2779]],\n",
      "\n",
      "         [[ 0.0067]],\n",
      "\n",
      "         [[-0.6710]],\n",
      "\n",
      "         [[-0.0885]],\n",
      "\n",
      "         [[-0.2914]],\n",
      "\n",
      "         [[-0.2254]],\n",
      "\n",
      "         [[ 0.2027]],\n",
      "\n",
      "         [[-0.2131]]],\n",
      "\n",
      "\n",
      "        [[[-0.2411]],\n",
      "\n",
      "         [[-0.3782]],\n",
      "\n",
      "         [[ 0.1302]],\n",
      "\n",
      "         [[ 0.1363]],\n",
      "\n",
      "         [[-0.5941]],\n",
      "\n",
      "         [[ 0.2020]],\n",
      "\n",
      "         [[ 0.1194]],\n",
      "\n",
      "         [[-0.0266]],\n",
      "\n",
      "         [[ 0.1239]],\n",
      "\n",
      "         [[-0.4983]]],\n",
      "\n",
      "\n",
      "        [[[-0.4920]],\n",
      "\n",
      "         [[-0.3195]],\n",
      "\n",
      "         [[-0.3634]],\n",
      "\n",
      "         [[ 0.4277]],\n",
      "\n",
      "         [[-0.6209]],\n",
      "\n",
      "         [[ 0.0571]],\n",
      "\n",
      "         [[-0.2510]],\n",
      "\n",
      "         [[ 0.0709]],\n",
      "\n",
      "         [[-0.0546]],\n",
      "\n",
      "         [[-0.3372]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-2.5559e-01, -3.7194e-01, -1.9297e+00, -1.4295e-03, -8.5549e-01,\n",
      "        -9.6463e-01,  4.6436e-01, -1.2150e+00, -3.2034e-01, -5.0405e-01,\n",
      "        -1.5998e+00, -8.6510e-01, -1.0549e+00,  5.1958e-02, -2.3403e+00,\n",
      "        -1.7265e+00, -5.8843e-02,  2.3755e-01, -1.9741e+00, -8.2934e-01,\n",
      "         2.0061e-01, -1.6933e+00,  9.0859e-02, -1.8200e+00, -1.8588e-01,\n",
      "        -3.7215e-01, -1.2381e+00,  3.5696e-02,  1.2610e-01, -1.1598e+00,\n",
      "         3.3783e-01,  4.5082e-01, -3.7189e-01, -8.7979e-01, -3.1591e-01,\n",
      "        -1.0966e+00,  7.1067e-01,  6.4909e-02,  3.7095e-02, -3.2410e-01],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 2.9297e-01]],\n",
      "\n",
      "         [[ 2.6996e-01]],\n",
      "\n",
      "         [[ 1.4738e+00]],\n",
      "\n",
      "         [[ 4.2282e-01]],\n",
      "\n",
      "         [[ 3.0188e-01]],\n",
      "\n",
      "         [[ 6.1142e-01]],\n",
      "\n",
      "         [[ 5.2779e-01]],\n",
      "\n",
      "         [[-4.2603e-02]],\n",
      "\n",
      "         [[ 6.4733e-01]],\n",
      "\n",
      "         [[ 5.2003e-01]],\n",
      "\n",
      "         [[-1.2617e-01]],\n",
      "\n",
      "         [[ 7.7590e-02]],\n",
      "\n",
      "         [[-5.2303e-01]],\n",
      "\n",
      "         [[-1.4215e-01]],\n",
      "\n",
      "         [[ 8.1149e-01]],\n",
      "\n",
      "         [[-2.2283e-01]],\n",
      "\n",
      "         [[ 1.9194e-01]],\n",
      "\n",
      "         [[ 1.8294e-01]],\n",
      "\n",
      "         [[ 1.7953e-01]],\n",
      "\n",
      "         [[-1.0141e+00]],\n",
      "\n",
      "         [[ 5.1661e-02]],\n",
      "\n",
      "         [[ 2.4140e-01]],\n",
      "\n",
      "         [[ 8.4403e-01]],\n",
      "\n",
      "         [[-1.6262e+00]],\n",
      "\n",
      "         [[-8.3374e-01]],\n",
      "\n",
      "         [[ 1.9878e-02]],\n",
      "\n",
      "         [[-1.4246e-01]],\n",
      "\n",
      "         [[ 8.0209e-02]],\n",
      "\n",
      "         [[ 1.0781e-01]],\n",
      "\n",
      "         [[-2.4306e-01]],\n",
      "\n",
      "         [[-1.4674e+00]],\n",
      "\n",
      "         [[-3.5441e-01]],\n",
      "\n",
      "         [[-8.5789e-01]],\n",
      "\n",
      "         [[ 6.8729e-02]],\n",
      "\n",
      "         [[-2.4106e-02]],\n",
      "\n",
      "         [[ 1.4210e-01]],\n",
      "\n",
      "         [[-2.1019e-01]],\n",
      "\n",
      "         [[ 4.9215e-02]],\n",
      "\n",
      "         [[-5.0447e-02]],\n",
      "\n",
      "         [[-2.7448e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.1543e-02]],\n",
      "\n",
      "         [[ 2.4237e-01]],\n",
      "\n",
      "         [[-5.1787e-01]],\n",
      "\n",
      "         [[ 7.2284e-02]],\n",
      "\n",
      "         [[ 3.0946e-01]],\n",
      "\n",
      "         [[-1.3335e+00]],\n",
      "\n",
      "         [[-3.0615e-01]],\n",
      "\n",
      "         [[ 8.1061e-02]],\n",
      "\n",
      "         [[ 2.6306e-01]],\n",
      "\n",
      "         [[ 2.5333e-01]],\n",
      "\n",
      "         [[ 2.2103e-01]],\n",
      "\n",
      "         [[-1.2107e-02]],\n",
      "\n",
      "         [[ 2.4558e-01]],\n",
      "\n",
      "         [[-8.4918e-02]],\n",
      "\n",
      "         [[ 4.7135e-01]],\n",
      "\n",
      "         [[-2.1057e-01]],\n",
      "\n",
      "         [[ 5.1812e-01]],\n",
      "\n",
      "         [[ 2.5397e-03]],\n",
      "\n",
      "         [[-5.3979e-01]],\n",
      "\n",
      "         [[-8.7453e-01]],\n",
      "\n",
      "         [[-4.9559e-02]],\n",
      "\n",
      "         [[-4.5467e-01]],\n",
      "\n",
      "         [[-1.0084e-01]],\n",
      "\n",
      "         [[-1.5789e+00]],\n",
      "\n",
      "         [[ 3.6984e-01]],\n",
      "\n",
      "         [[ 9.4419e-02]],\n",
      "\n",
      "         [[ 9.1424e-02]],\n",
      "\n",
      "         [[-4.0030e-01]],\n",
      "\n",
      "         [[-2.5279e-01]],\n",
      "\n",
      "         [[ 2.2726e-01]],\n",
      "\n",
      "         [[-4.5323e-01]],\n",
      "\n",
      "         [[ 2.3330e-01]],\n",
      "\n",
      "         [[ 4.2525e-01]],\n",
      "\n",
      "         [[ 5.5213e-01]],\n",
      "\n",
      "         [[ 2.3035e-01]],\n",
      "\n",
      "         [[ 3.2491e-02]],\n",
      "\n",
      "         [[ 1.1415e-01]],\n",
      "\n",
      "         [[ 8.6935e-02]],\n",
      "\n",
      "         [[ 2.0178e-01]],\n",
      "\n",
      "         [[ 5.2126e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.1996e-01]],\n",
      "\n",
      "         [[ 9.5132e-01]],\n",
      "\n",
      "         [[-2.9339e-01]],\n",
      "\n",
      "         [[ 5.1918e-01]],\n",
      "\n",
      "         [[-1.4369e-01]],\n",
      "\n",
      "         [[ 2.9049e-01]],\n",
      "\n",
      "         [[ 5.3566e-01]],\n",
      "\n",
      "         [[ 4.8557e-01]],\n",
      "\n",
      "         [[-1.3098e-01]],\n",
      "\n",
      "         [[-1.1603e-01]],\n",
      "\n",
      "         [[-2.0061e-01]],\n",
      "\n",
      "         [[ 9.6402e-02]],\n",
      "\n",
      "         [[-8.7365e-03]],\n",
      "\n",
      "         [[-4.7240e-01]],\n",
      "\n",
      "         [[ 2.6727e-03]],\n",
      "\n",
      "         [[ 2.3699e-01]],\n",
      "\n",
      "         [[ 9.5180e-01]],\n",
      "\n",
      "         [[ 4.1523e-01]],\n",
      "\n",
      "         [[-1.2424e-01]],\n",
      "\n",
      "         [[ 1.4042e-01]],\n",
      "\n",
      "         [[ 2.3226e-01]],\n",
      "\n",
      "         [[-1.0464e-01]],\n",
      "\n",
      "         [[ 4.8871e-01]],\n",
      "\n",
      "         [[-2.3707e-01]],\n",
      "\n",
      "         [[-8.7324e-02]],\n",
      "\n",
      "         [[ 1.0366e-01]],\n",
      "\n",
      "         [[-3.1820e-01]],\n",
      "\n",
      "         [[-2.6175e-01]],\n",
      "\n",
      "         [[-5.5580e-01]],\n",
      "\n",
      "         [[ 4.5374e-01]],\n",
      "\n",
      "         [[ 6.0794e-01]],\n",
      "\n",
      "         [[ 1.0767e-01]],\n",
      "\n",
      "         [[-2.0266e-01]],\n",
      "\n",
      "         [[ 9.2836e-02]],\n",
      "\n",
      "         [[-8.9756e-02]],\n",
      "\n",
      "         [[ 5.4454e-01]],\n",
      "\n",
      "         [[-8.1500e-01]],\n",
      "\n",
      "         [[ 1.4774e-01]],\n",
      "\n",
      "         [[ 9.3027e-01]],\n",
      "\n",
      "         [[ 2.7092e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.9070e-01]],\n",
      "\n",
      "         [[-4.7459e-02]],\n",
      "\n",
      "         [[ 1.7940e-01]],\n",
      "\n",
      "         [[-8.4633e-01]],\n",
      "\n",
      "         [[-3.3953e-01]],\n",
      "\n",
      "         [[ 1.7179e-01]],\n",
      "\n",
      "         [[-8.0623e-01]],\n",
      "\n",
      "         [[-1.2015e+00]],\n",
      "\n",
      "         [[-3.7096e-01]],\n",
      "\n",
      "         [[ 1.4391e-02]],\n",
      "\n",
      "         [[ 2.2608e-01]],\n",
      "\n",
      "         [[ 6.0726e-01]],\n",
      "\n",
      "         [[-5.3838e-01]],\n",
      "\n",
      "         [[-1.6210e-01]],\n",
      "\n",
      "         [[ 3.4621e-03]],\n",
      "\n",
      "         [[ 1.1966e-01]],\n",
      "\n",
      "         [[ 5.2705e-01]],\n",
      "\n",
      "         [[-4.6663e-02]],\n",
      "\n",
      "         [[ 6.4765e-02]],\n",
      "\n",
      "         [[ 1.0851e-05]],\n",
      "\n",
      "         [[-4.9191e-01]],\n",
      "\n",
      "         [[ 7.0108e-02]],\n",
      "\n",
      "         [[-5.2802e-01]],\n",
      "\n",
      "         [[ 2.6246e-01]],\n",
      "\n",
      "         [[-3.1109e-01]],\n",
      "\n",
      "         [[ 1.3934e-02]],\n",
      "\n",
      "         [[ 2.9678e-01]],\n",
      "\n",
      "         [[-6.7635e-01]],\n",
      "\n",
      "         [[-6.9333e-01]],\n",
      "\n",
      "         [[ 1.9412e-01]],\n",
      "\n",
      "         [[-3.1379e-01]],\n",
      "\n",
      "         [[ 2.4172e-01]],\n",
      "\n",
      "         [[-1.5352e-01]],\n",
      "\n",
      "         [[ 2.9662e-01]],\n",
      "\n",
      "         [[ 6.3966e-02]],\n",
      "\n",
      "         [[ 1.9270e-01]],\n",
      "\n",
      "         [[-1.1895e-01]],\n",
      "\n",
      "         [[ 1.4027e-01]],\n",
      "\n",
      "         [[-3.4708e-01]],\n",
      "\n",
      "         [[ 5.1054e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2739e-02]],\n",
      "\n",
      "         [[ 2.7141e-01]],\n",
      "\n",
      "         [[ 1.1037e-01]],\n",
      "\n",
      "         [[-4.9631e-01]],\n",
      "\n",
      "         [[ 3.4365e-01]],\n",
      "\n",
      "         [[-1.0069e-01]],\n",
      "\n",
      "         [[-3.0249e-01]],\n",
      "\n",
      "         [[ 2.9686e-03]],\n",
      "\n",
      "         [[-3.5025e-01]],\n",
      "\n",
      "         [[-3.1571e-01]],\n",
      "\n",
      "         [[-3.8466e-01]],\n",
      "\n",
      "         [[-3.2024e-01]],\n",
      "\n",
      "         [[-2.7918e-02]],\n",
      "\n",
      "         [[-5.1131e-01]],\n",
      "\n",
      "         [[-2.4265e-01]],\n",
      "\n",
      "         [[-1.9379e-01]],\n",
      "\n",
      "         [[-2.3108e-01]],\n",
      "\n",
      "         [[-3.1263e-01]],\n",
      "\n",
      "         [[ 1.0165e-01]],\n",
      "\n",
      "         [[-7.0146e-02]],\n",
      "\n",
      "         [[ 1.6150e+00]],\n",
      "\n",
      "         [[-1.1685e-01]],\n",
      "\n",
      "         [[ 1.8711e-01]],\n",
      "\n",
      "         [[ 1.3583e-01]],\n",
      "\n",
      "         [[-2.5006e-01]],\n",
      "\n",
      "         [[ 5.4146e-01]],\n",
      "\n",
      "         [[ 1.8040e-01]],\n",
      "\n",
      "         [[-1.8524e-01]],\n",
      "\n",
      "         [[ 5.7066e-01]],\n",
      "\n",
      "         [[ 2.1624e-01]],\n",
      "\n",
      "         [[ 4.9953e-01]],\n",
      "\n",
      "         [[-4.3629e-01]],\n",
      "\n",
      "         [[-3.7135e-01]],\n",
      "\n",
      "         [[ 9.6705e-01]],\n",
      "\n",
      "         [[-5.5112e-01]],\n",
      "\n",
      "         [[-4.3309e-01]],\n",
      "\n",
      "         [[ 2.1233e-01]],\n",
      "\n",
      "         [[ 4.1087e-01]],\n",
      "\n",
      "         [[ 4.4183e-01]],\n",
      "\n",
      "         [[ 6.2474e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9175e-01]],\n",
      "\n",
      "         [[ 4.0220e-01]],\n",
      "\n",
      "         [[ 2.2422e-01]],\n",
      "\n",
      "         [[ 6.9928e-01]],\n",
      "\n",
      "         [[ 4.6897e-01]],\n",
      "\n",
      "         [[ 2.9540e-01]],\n",
      "\n",
      "         [[ 1.0106e-02]],\n",
      "\n",
      "         [[ 4.7619e-01]],\n",
      "\n",
      "         [[-6.3313e-02]],\n",
      "\n",
      "         [[-2.2854e-01]],\n",
      "\n",
      "         [[ 8.1813e-01]],\n",
      "\n",
      "         [[-2.2736e-01]],\n",
      "\n",
      "         [[ 3.7980e-01]],\n",
      "\n",
      "         [[ 2.5941e-01]],\n",
      "\n",
      "         [[ 2.4828e-01]],\n",
      "\n",
      "         [[ 6.5424e-03]],\n",
      "\n",
      "         [[ 7.6120e-01]],\n",
      "\n",
      "         [[-5.3105e-01]],\n",
      "\n",
      "         [[ 5.2086e-02]],\n",
      "\n",
      "         [[ 4.6975e-01]],\n",
      "\n",
      "         [[ 2.9555e-01]],\n",
      "\n",
      "         [[ 1.1583e-01]],\n",
      "\n",
      "         [[ 6.3449e-01]],\n",
      "\n",
      "         [[ 1.2893e-01]],\n",
      "\n",
      "         [[ 1.2425e-01]],\n",
      "\n",
      "         [[ 3.2807e-01]],\n",
      "\n",
      "         [[ 8.3520e-01]],\n",
      "\n",
      "         [[ 1.1160e+00]],\n",
      "\n",
      "         [[-6.5221e-02]],\n",
      "\n",
      "         [[ 5.8870e-01]],\n",
      "\n",
      "         [[-7.6563e-01]],\n",
      "\n",
      "         [[ 1.8294e-01]],\n",
      "\n",
      "         [[-4.7557e-01]],\n",
      "\n",
      "         [[ 3.9575e-01]],\n",
      "\n",
      "         [[-6.2353e-01]],\n",
      "\n",
      "         [[ 5.2622e-01]],\n",
      "\n",
      "         [[-6.4581e-01]],\n",
      "\n",
      "         [[ 1.9760e-01]],\n",
      "\n",
      "         [[-1.1452e-01]],\n",
      "\n",
      "         [[ 7.3734e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4535e-02]],\n",
      "\n",
      "         [[-8.2409e-01]],\n",
      "\n",
      "         [[ 1.6169e-02]],\n",
      "\n",
      "         [[-9.3555e-01]],\n",
      "\n",
      "         [[ 9.9394e-02]],\n",
      "\n",
      "         [[ 1.3620e-01]],\n",
      "\n",
      "         [[-6.9793e-01]],\n",
      "\n",
      "         [[-1.6765e-01]],\n",
      "\n",
      "         [[-1.5784e-02]],\n",
      "\n",
      "         [[-2.4014e-01]],\n",
      "\n",
      "         [[-1.7546e-01]],\n",
      "\n",
      "         [[ 3.2081e-01]],\n",
      "\n",
      "         [[-1.6692e-01]],\n",
      "\n",
      "         [[-1.3781e-01]],\n",
      "\n",
      "         [[ 2.9042e-01]],\n",
      "\n",
      "         [[-8.8823e-02]],\n",
      "\n",
      "         [[-2.3421e-01]],\n",
      "\n",
      "         [[ 4.2251e-01]],\n",
      "\n",
      "         [[ 3.2176e-02]],\n",
      "\n",
      "         [[-3.3249e-01]],\n",
      "\n",
      "         [[ 6.7959e-02]],\n",
      "\n",
      "         [[-5.8243e-02]],\n",
      "\n",
      "         [[-2.7120e-01]],\n",
      "\n",
      "         [[ 5.4604e-01]],\n",
      "\n",
      "         [[-2.2809e-01]],\n",
      "\n",
      "         [[ 2.4726e-01]],\n",
      "\n",
      "         [[-1.8737e-01]],\n",
      "\n",
      "         [[-2.0333e-01]],\n",
      "\n",
      "         [[ 3.2088e-01]],\n",
      "\n",
      "         [[-3.8075e-01]],\n",
      "\n",
      "         [[ 4.0407e-01]],\n",
      "\n",
      "         [[-1.5303e+00]],\n",
      "\n",
      "         [[-8.4989e-02]],\n",
      "\n",
      "         [[ 2.7508e-01]],\n",
      "\n",
      "         [[-8.4201e-02]],\n",
      "\n",
      "         [[-3.1563e-01]],\n",
      "\n",
      "         [[ 1.0588e+00]],\n",
      "\n",
      "         [[-2.8966e-01]],\n",
      "\n",
      "         [[-4.9549e-02]],\n",
      "\n",
      "         [[ 1.4749e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2852e-01]],\n",
      "\n",
      "         [[ 3.1006e-01]],\n",
      "\n",
      "         [[ 2.5745e-01]],\n",
      "\n",
      "         [[-5.8973e-01]],\n",
      "\n",
      "         [[-2.5409e-01]],\n",
      "\n",
      "         [[ 1.4777e-01]],\n",
      "\n",
      "         [[-2.6089e-02]],\n",
      "\n",
      "         [[ 2.6089e-01]],\n",
      "\n",
      "         [[-4.5618e-01]],\n",
      "\n",
      "         [[ 2.2751e-01]],\n",
      "\n",
      "         [[ 5.0468e-01]],\n",
      "\n",
      "         [[ 4.5657e-01]],\n",
      "\n",
      "         [[ 9.5288e-01]],\n",
      "\n",
      "         [[-7.1974e-01]],\n",
      "\n",
      "         [[-1.8048e-02]],\n",
      "\n",
      "         [[-4.5090e-01]],\n",
      "\n",
      "         [[-2.0495e-01]],\n",
      "\n",
      "         [[-3.0644e-01]],\n",
      "\n",
      "         [[ 2.0051e-01]],\n",
      "\n",
      "         [[-2.8948e-01]],\n",
      "\n",
      "         [[ 4.0696e-01]],\n",
      "\n",
      "         [[-3.5076e-01]],\n",
      "\n",
      "         [[ 2.3611e-01]],\n",
      "\n",
      "         [[-2.2133e-01]],\n",
      "\n",
      "         [[ 3.7607e-02]],\n",
      "\n",
      "         [[ 1.0531e-01]],\n",
      "\n",
      "         [[ 1.9010e-01]],\n",
      "\n",
      "         [[-2.4466e-01]],\n",
      "\n",
      "         [[-7.8558e-02]],\n",
      "\n",
      "         [[ 9.0422e-01]],\n",
      "\n",
      "         [[-5.2284e-02]],\n",
      "\n",
      "         [[-6.0488e-02]],\n",
      "\n",
      "         [[-8.0590e-01]],\n",
      "\n",
      "         [[ 4.7085e-01]],\n",
      "\n",
      "         [[ 4.3121e-01]],\n",
      "\n",
      "         [[ 8.7559e-01]],\n",
      "\n",
      "         [[-9.0959e-01]],\n",
      "\n",
      "         [[ 1.2496e+00]],\n",
      "\n",
      "         [[ 1.0063e-01]],\n",
      "\n",
      "         [[-7.4676e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.8207e-01]],\n",
      "\n",
      "         [[-1.9976e-01]],\n",
      "\n",
      "         [[-3.0604e-02]],\n",
      "\n",
      "         [[-9.3614e-02]],\n",
      "\n",
      "         [[-1.3109e-01]],\n",
      "\n",
      "         [[-2.8598e-01]],\n",
      "\n",
      "         [[-4.2946e-01]],\n",
      "\n",
      "         [[ 9.8191e-02]],\n",
      "\n",
      "         [[-3.3727e-03]],\n",
      "\n",
      "         [[-2.4519e-02]],\n",
      "\n",
      "         [[-1.4582e-02]],\n",
      "\n",
      "         [[ 1.4999e-02]],\n",
      "\n",
      "         [[ 4.7100e-01]],\n",
      "\n",
      "         [[ 7.9918e-01]],\n",
      "\n",
      "         [[ 2.5970e-02]],\n",
      "\n",
      "         [[-2.1026e-01]],\n",
      "\n",
      "         [[-1.7341e+00]],\n",
      "\n",
      "         [[ 1.9545e-01]],\n",
      "\n",
      "         [[-2.8078e-02]],\n",
      "\n",
      "         [[-2.2001e-01]],\n",
      "\n",
      "         [[-9.4727e-01]],\n",
      "\n",
      "         [[-1.6693e-01]],\n",
      "\n",
      "         [[-2.2579e-01]],\n",
      "\n",
      "         [[-3.8906e-02]],\n",
      "\n",
      "         [[ 6.3465e-02]],\n",
      "\n",
      "         [[ 6.4986e-02]],\n",
      "\n",
      "         [[-9.6440e-02]],\n",
      "\n",
      "         [[ 1.1389e+00]],\n",
      "\n",
      "         [[-6.8521e-01]],\n",
      "\n",
      "         [[-8.8477e-01]],\n",
      "\n",
      "         [[-2.8318e-01]],\n",
      "\n",
      "         [[ 6.8551e-01]],\n",
      "\n",
      "         [[-7.2304e-01]],\n",
      "\n",
      "         [[-3.8182e-01]],\n",
      "\n",
      "         [[-2.4365e-01]],\n",
      "\n",
      "         [[ 3.0754e-01]],\n",
      "\n",
      "         [[-6.8932e-01]],\n",
      "\n",
      "         [[-9.5114e-01]],\n",
      "\n",
      "         [[-5.8189e-02]],\n",
      "\n",
      "         [[ 1.3993e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6906e-01]],\n",
      "\n",
      "         [[ 4.3365e-02]],\n",
      "\n",
      "         [[-6.3260e-02]],\n",
      "\n",
      "         [[-1.6634e-01]],\n",
      "\n",
      "         [[ 5.4831e-01]],\n",
      "\n",
      "         [[ 2.5309e-01]],\n",
      "\n",
      "         [[-3.2594e-01]],\n",
      "\n",
      "         [[ 1.2463e-01]],\n",
      "\n",
      "         [[ 3.6232e-01]],\n",
      "\n",
      "         [[ 5.7394e-02]],\n",
      "\n",
      "         [[ 1.0426e-02]],\n",
      "\n",
      "         [[-3.0627e-01]],\n",
      "\n",
      "         [[ 5.4696e-01]],\n",
      "\n",
      "         [[ 1.5598e-01]],\n",
      "\n",
      "         [[-2.8173e-02]],\n",
      "\n",
      "         [[ 4.7594e-04]],\n",
      "\n",
      "         [[-1.6523e+00]],\n",
      "\n",
      "         [[ 5.0955e-01]],\n",
      "\n",
      "         [[ 7.9211e-02]],\n",
      "\n",
      "         [[ 1.1953e-01]],\n",
      "\n",
      "         [[ 5.2033e-02]],\n",
      "\n",
      "         [[ 4.0174e-02]],\n",
      "\n",
      "         [[ 1.6356e-02]],\n",
      "\n",
      "         [[-2.4745e-01]],\n",
      "\n",
      "         [[ 7.8576e-02]],\n",
      "\n",
      "         [[-1.5698e+00]],\n",
      "\n",
      "         [[-2.1117e-01]],\n",
      "\n",
      "         [[ 1.5278e+00]],\n",
      "\n",
      "         [[ 2.7110e-01]],\n",
      "\n",
      "         [[ 4.3744e-01]],\n",
      "\n",
      "         [[-2.4182e-01]],\n",
      "\n",
      "         [[-3.0450e-01]],\n",
      "\n",
      "         [[-3.6045e-01]],\n",
      "\n",
      "         [[ 1.3662e+00]],\n",
      "\n",
      "         [[-3.7705e-01]],\n",
      "\n",
      "         [[ 6.2843e-04]],\n",
      "\n",
      "         [[ 9.9044e-02]],\n",
      "\n",
      "         [[-5.3267e-03]],\n",
      "\n",
      "         [[-6.0068e-01]],\n",
      "\n",
      "         [[-7.1019e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2189e-01]],\n",
      "\n",
      "         [[ 4.4621e-01]],\n",
      "\n",
      "         [[ 7.7547e-02]],\n",
      "\n",
      "         [[-1.8961e-01]],\n",
      "\n",
      "         [[ 3.2505e-01]],\n",
      "\n",
      "         [[ 1.8231e-01]],\n",
      "\n",
      "         [[-1.8036e-01]],\n",
      "\n",
      "         [[-3.6572e-01]],\n",
      "\n",
      "         [[ 1.0890e-01]],\n",
      "\n",
      "         [[-1.9934e-01]],\n",
      "\n",
      "         [[-3.4689e-01]],\n",
      "\n",
      "         [[-6.6139e-01]],\n",
      "\n",
      "         [[ 2.8656e-01]],\n",
      "\n",
      "         [[ 4.7728e-01]],\n",
      "\n",
      "         [[ 6.4156e-04]],\n",
      "\n",
      "         [[ 1.9225e-01]],\n",
      "\n",
      "         [[-2.4611e-01]],\n",
      "\n",
      "         [[ 5.7058e-01]],\n",
      "\n",
      "         [[ 8.2179e-02]],\n",
      "\n",
      "         [[ 2.6288e-01]],\n",
      "\n",
      "         [[ 6.8309e-01]],\n",
      "\n",
      "         [[-1.3883e-01]],\n",
      "\n",
      "         [[ 4.1367e-01]],\n",
      "\n",
      "         [[-3.6365e-02]],\n",
      "\n",
      "         [[ 3.4719e-01]],\n",
      "\n",
      "         [[-4.0270e-01]],\n",
      "\n",
      "         [[-6.2247e-01]],\n",
      "\n",
      "         [[ 3.1049e-01]],\n",
      "\n",
      "         [[ 7.3966e-01]],\n",
      "\n",
      "         [[ 4.9013e-01]],\n",
      "\n",
      "         [[ 2.9374e-01]],\n",
      "\n",
      "         [[ 1.4607e-01]],\n",
      "\n",
      "         [[-2.8518e-01]],\n",
      "\n",
      "         [[-1.3949e-02]],\n",
      "\n",
      "         [[-1.8309e-01]],\n",
      "\n",
      "         [[ 9.8562e-01]],\n",
      "\n",
      "         [[-3.8040e-01]],\n",
      "\n",
      "         [[ 7.2430e-01]],\n",
      "\n",
      "         [[ 1.7009e-01]],\n",
      "\n",
      "         [[ 2.4592e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.4567e-02]],\n",
      "\n",
      "         [[-1.9745e-01]],\n",
      "\n",
      "         [[-2.5780e-01]],\n",
      "\n",
      "         [[-9.5890e-02]],\n",
      "\n",
      "         [[ 2.3417e-01]],\n",
      "\n",
      "         [[ 8.6929e-01]],\n",
      "\n",
      "         [[ 1.1637e+00]],\n",
      "\n",
      "         [[-3.2904e-01]],\n",
      "\n",
      "         [[ 7.4886e-02]],\n",
      "\n",
      "         [[-7.6409e-02]],\n",
      "\n",
      "         [[-5.2291e-01]],\n",
      "\n",
      "         [[-4.1760e-01]],\n",
      "\n",
      "         [[ 6.5261e-02]],\n",
      "\n",
      "         [[-4.7575e-01]],\n",
      "\n",
      "         [[ 1.2982e-01]],\n",
      "\n",
      "         [[-3.5355e-01]],\n",
      "\n",
      "         [[ 8.2462e-01]],\n",
      "\n",
      "         [[-3.3551e-01]],\n",
      "\n",
      "         [[-3.2541e-01]],\n",
      "\n",
      "         [[ 1.7859e-01]],\n",
      "\n",
      "         [[-5.9380e-02]],\n",
      "\n",
      "         [[ 4.4948e-01]],\n",
      "\n",
      "         [[-4.2644e-02]],\n",
      "\n",
      "         [[-2.0388e-01]],\n",
      "\n",
      "         [[-4.5759e-01]],\n",
      "\n",
      "         [[-1.0880e-01]],\n",
      "\n",
      "         [[-8.7052e-01]],\n",
      "\n",
      "         [[-2.7297e-01]],\n",
      "\n",
      "         [[-1.6426e-01]],\n",
      "\n",
      "         [[ 5.4626e-02]],\n",
      "\n",
      "         [[ 1.3991e-02]],\n",
      "\n",
      "         [[-1.0958e-01]],\n",
      "\n",
      "         [[-2.5842e-01]],\n",
      "\n",
      "         [[-1.9996e-01]],\n",
      "\n",
      "         [[-1.2092e+00]],\n",
      "\n",
      "         [[ 2.0994e-01]],\n",
      "\n",
      "         [[ 7.1182e-01]],\n",
      "\n",
      "         [[ 1.9316e-01]],\n",
      "\n",
      "         [[-2.1764e-01]],\n",
      "\n",
      "         [[-3.1991e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2281e-01]],\n",
      "\n",
      "         [[ 1.8919e-02]],\n",
      "\n",
      "         [[-1.6780e-01]],\n",
      "\n",
      "         [[-3.2147e-01]],\n",
      "\n",
      "         [[ 2.1897e-01]],\n",
      "\n",
      "         [[ 8.9452e-02]],\n",
      "\n",
      "         [[ 5.7353e-01]],\n",
      "\n",
      "         [[-1.3879e-01]],\n",
      "\n",
      "         [[-2.8339e-02]],\n",
      "\n",
      "         [[-8.7630e-01]],\n",
      "\n",
      "         [[ 1.2444e-01]],\n",
      "\n",
      "         [[ 2.1804e-01]],\n",
      "\n",
      "         [[-2.2759e-01]],\n",
      "\n",
      "         [[ 7.9438e-01]],\n",
      "\n",
      "         [[ 1.9978e-01]],\n",
      "\n",
      "         [[-3.5774e-01]],\n",
      "\n",
      "         [[ 9.6718e-01]],\n",
      "\n",
      "         [[-8.6739e-01]],\n",
      "\n",
      "         [[-1.5018e+00]],\n",
      "\n",
      "         [[ 5.0496e-01]],\n",
      "\n",
      "         [[-1.3552e-01]],\n",
      "\n",
      "         [[ 1.2520e+00]],\n",
      "\n",
      "         [[ 1.9471e-01]],\n",
      "\n",
      "         [[ 7.7803e-02]],\n",
      "\n",
      "         [[-7.4060e-01]],\n",
      "\n",
      "         [[ 1.1398e-01]],\n",
      "\n",
      "         [[ 7.2576e-02]],\n",
      "\n",
      "         [[-1.0623e+00]],\n",
      "\n",
      "         [[ 1.4218e-01]],\n",
      "\n",
      "         [[ 3.0921e-01]],\n",
      "\n",
      "         [[-2.0295e-01]],\n",
      "\n",
      "         [[-2.0098e-01]],\n",
      "\n",
      "         [[-1.2793e-01]],\n",
      "\n",
      "         [[ 1.3099e-01]],\n",
      "\n",
      "         [[ 1.7357e-01]],\n",
      "\n",
      "         [[ 4.4253e-01]],\n",
      "\n",
      "         [[ 3.8117e-01]],\n",
      "\n",
      "         [[-9.1154e-01]],\n",
      "\n",
      "         [[ 1.2714e-01]],\n",
      "\n",
      "         [[-2.0831e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2207e-01]],\n",
      "\n",
      "         [[ 4.0351e-01]],\n",
      "\n",
      "         [[ 8.2350e-02]],\n",
      "\n",
      "         [[ 8.1744e-01]],\n",
      "\n",
      "         [[-1.0696e-01]],\n",
      "\n",
      "         [[-4.4996e-02]],\n",
      "\n",
      "         [[ 1.9090e-01]],\n",
      "\n",
      "         [[ 1.1402e-01]],\n",
      "\n",
      "         [[-5.0406e-02]],\n",
      "\n",
      "         [[-1.8398e-01]],\n",
      "\n",
      "         [[-2.6615e-01]],\n",
      "\n",
      "         [[ 4.4625e-01]],\n",
      "\n",
      "         [[ 2.1013e-02]],\n",
      "\n",
      "         [[-1.8444e-01]],\n",
      "\n",
      "         [[-1.3416e-01]],\n",
      "\n",
      "         [[ 5.1336e-02]],\n",
      "\n",
      "         [[ 7.7612e-02]],\n",
      "\n",
      "         [[-5.0319e-01]],\n",
      "\n",
      "         [[-1.8332e-01]],\n",
      "\n",
      "         [[ 3.1238e-01]],\n",
      "\n",
      "         [[-1.0971e+00]],\n",
      "\n",
      "         [[ 1.8281e-01]],\n",
      "\n",
      "         [[ 2.0790e-01]],\n",
      "\n",
      "         [[-1.4826e-01]],\n",
      "\n",
      "         [[-2.6215e-01]],\n",
      "\n",
      "         [[-1.2799e-01]],\n",
      "\n",
      "         [[ 1.5356e-01]],\n",
      "\n",
      "         [[ 1.4607e-01]],\n",
      "\n",
      "         [[-1.2663e+00]],\n",
      "\n",
      "         [[-6.8177e-01]],\n",
      "\n",
      "         [[-9.1740e-01]],\n",
      "\n",
      "         [[ 1.7325e-01]],\n",
      "\n",
      "         [[-1.2047e-01]],\n",
      "\n",
      "         [[-1.0126e-01]],\n",
      "\n",
      "         [[-1.1138e-01]],\n",
      "\n",
      "         [[-1.3975e+00]],\n",
      "\n",
      "         [[-2.0653e-01]],\n",
      "\n",
      "         [[ 9.0408e-03]],\n",
      "\n",
      "         [[-5.1845e-01]],\n",
      "\n",
      "         [[-1.0828e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5009e-03]],\n",
      "\n",
      "         [[-4.0948e-01]],\n",
      "\n",
      "         [[ 1.5508e-02]],\n",
      "\n",
      "         [[-8.7268e-03]],\n",
      "\n",
      "         [[ 1.0071e-01]],\n",
      "\n",
      "         [[ 1.4918e-01]],\n",
      "\n",
      "         [[-5.1316e-01]],\n",
      "\n",
      "         [[ 2.1934e+00]],\n",
      "\n",
      "         [[ 3.3789e-01]],\n",
      "\n",
      "         [[-1.0051e-01]],\n",
      "\n",
      "         [[ 7.5287e-01]],\n",
      "\n",
      "         [[-2.8196e-01]],\n",
      "\n",
      "         [[ 5.6416e-01]],\n",
      "\n",
      "         [[ 1.5121e-01]],\n",
      "\n",
      "         [[ 4.4474e-01]],\n",
      "\n",
      "         [[-4.7392e-01]],\n",
      "\n",
      "         [[-1.4602e-01]],\n",
      "\n",
      "         [[ 3.6274e-01]],\n",
      "\n",
      "         [[ 4.4774e-03]],\n",
      "\n",
      "         [[-1.3120e-01]],\n",
      "\n",
      "         [[ 2.0671e-01]],\n",
      "\n",
      "         [[ 2.8381e-01]],\n",
      "\n",
      "         [[-4.3877e-01]],\n",
      "\n",
      "         [[-2.6438e-01]],\n",
      "\n",
      "         [[-2.3123e-01]],\n",
      "\n",
      "         [[ 9.9012e-01]],\n",
      "\n",
      "         [[ 9.9564e-01]],\n",
      "\n",
      "         [[-1.5526e-01]],\n",
      "\n",
      "         [[-1.0415e-01]],\n",
      "\n",
      "         [[-4.3900e-02]],\n",
      "\n",
      "         [[-4.9506e-02]],\n",
      "\n",
      "         [[ 3.9083e-01]],\n",
      "\n",
      "         [[-4.0313e-01]],\n",
      "\n",
      "         [[ 2.3004e-01]],\n",
      "\n",
      "         [[ 3.6188e-01]],\n",
      "\n",
      "         [[ 4.1481e-01]],\n",
      "\n",
      "         [[ 2.0091e-01]],\n",
      "\n",
      "         [[-1.3138e-01]],\n",
      "\n",
      "         [[ 1.5355e-01]],\n",
      "\n",
      "         [[ 5.3419e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5747e+00]],\n",
      "\n",
      "         [[ 9.2210e-01]],\n",
      "\n",
      "         [[-1.1703e-01]],\n",
      "\n",
      "         [[-5.6488e-01]],\n",
      "\n",
      "         [[ 4.0484e-01]],\n",
      "\n",
      "         [[ 3.4386e-02]],\n",
      "\n",
      "         [[ 1.4711e-02]],\n",
      "\n",
      "         [[-5.1863e-01]],\n",
      "\n",
      "         [[ 2.5546e-01]],\n",
      "\n",
      "         [[ 7.2757e-02]],\n",
      "\n",
      "         [[ 1.4908e-01]],\n",
      "\n",
      "         [[ 2.3546e-01]],\n",
      "\n",
      "         [[ 1.9788e-01]],\n",
      "\n",
      "         [[ 4.2770e-01]],\n",
      "\n",
      "         [[-1.5358e-01]],\n",
      "\n",
      "         [[ 9.2770e-02]],\n",
      "\n",
      "         [[-2.6238e-01]],\n",
      "\n",
      "         [[-3.1965e-01]],\n",
      "\n",
      "         [[ 1.1572e-01]],\n",
      "\n",
      "         [[ 7.0346e-02]],\n",
      "\n",
      "         [[ 3.7396e-01]],\n",
      "\n",
      "         [[ 1.1824e-01]],\n",
      "\n",
      "         [[ 3.9093e-01]],\n",
      "\n",
      "         [[-6.2886e-02]],\n",
      "\n",
      "         [[-2.5303e-01]],\n",
      "\n",
      "         [[-6.1673e-03]],\n",
      "\n",
      "         [[-1.4838e-01]],\n",
      "\n",
      "         [[-2.5302e-01]],\n",
      "\n",
      "         [[ 1.6830e-01]],\n",
      "\n",
      "         [[ 2.2604e-02]],\n",
      "\n",
      "         [[ 6.5659e-01]],\n",
      "\n",
      "         [[-8.8891e-01]],\n",
      "\n",
      "         [[-8.6388e-02]],\n",
      "\n",
      "         [[ 9.3399e-02]],\n",
      "\n",
      "         [[ 2.4248e-01]],\n",
      "\n",
      "         [[-1.2208e-02]],\n",
      "\n",
      "         [[ 4.2419e-01]],\n",
      "\n",
      "         [[ 1.2459e-03]],\n",
      "\n",
      "         [[-1.1176e+00]],\n",
      "\n",
      "         [[-1.7116e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.2886e-01]],\n",
      "\n",
      "         [[ 4.6351e-01]],\n",
      "\n",
      "         [[-8.1068e-02]],\n",
      "\n",
      "         [[-1.5759e-01]],\n",
      "\n",
      "         [[ 2.5577e-01]],\n",
      "\n",
      "         [[-4.8132e-02]],\n",
      "\n",
      "         [[ 1.3092e-01]],\n",
      "\n",
      "         [[-8.9457e-02]],\n",
      "\n",
      "         [[ 5.4968e-02]],\n",
      "\n",
      "         [[-1.1835e+00]],\n",
      "\n",
      "         [[ 6.0161e-03]],\n",
      "\n",
      "         [[ 4.0369e-01]],\n",
      "\n",
      "         [[ 1.6383e-01]],\n",
      "\n",
      "         [[-7.3901e-01]],\n",
      "\n",
      "         [[ 1.1357e-01]],\n",
      "\n",
      "         [[-6.3560e-01]],\n",
      "\n",
      "         [[-8.9332e-01]],\n",
      "\n",
      "         [[ 1.5394e-01]],\n",
      "\n",
      "         [[-1.1936e+00]],\n",
      "\n",
      "         [[ 8.3186e-01]],\n",
      "\n",
      "         [[ 2.3425e-01]],\n",
      "\n",
      "         [[ 1.0183e+00]],\n",
      "\n",
      "         [[-2.6837e-01]],\n",
      "\n",
      "         [[-2.6669e-02]],\n",
      "\n",
      "         [[-7.4123e-01]],\n",
      "\n",
      "         [[ 2.7374e-02]],\n",
      "\n",
      "         [[ 2.1828e-01]],\n",
      "\n",
      "         [[ 1.1816e+00]],\n",
      "\n",
      "         [[-1.6374e-02]],\n",
      "\n",
      "         [[-3.3809e-01]],\n",
      "\n",
      "         [[-1.3162e-01]],\n",
      "\n",
      "         [[ 2.4644e-01]],\n",
      "\n",
      "         [[ 8.4992e-02]],\n",
      "\n",
      "         [[-2.5327e-01]],\n",
      "\n",
      "         [[ 3.5189e-01]],\n",
      "\n",
      "         [[-3.5914e-01]],\n",
      "\n",
      "         [[-1.9998e-01]],\n",
      "\n",
      "         [[ 8.0854e-01]],\n",
      "\n",
      "         [[-1.1082e-01]],\n",
      "\n",
      "         [[-5.6125e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5014e-01]],\n",
      "\n",
      "         [[ 2.1877e-01]],\n",
      "\n",
      "         [[-1.7927e-01]],\n",
      "\n",
      "         [[-1.7081e-01]],\n",
      "\n",
      "         [[ 1.9170e-01]],\n",
      "\n",
      "         [[-1.3411e-01]],\n",
      "\n",
      "         [[ 9.8828e-02]],\n",
      "\n",
      "         [[-1.5336e-01]],\n",
      "\n",
      "         [[-8.1294e-01]],\n",
      "\n",
      "         [[-1.9539e-01]],\n",
      "\n",
      "         [[-6.1160e-02]],\n",
      "\n",
      "         [[ 8.1170e-02]],\n",
      "\n",
      "         [[-4.1347e-01]],\n",
      "\n",
      "         [[-4.9712e-01]],\n",
      "\n",
      "         [[-1.2128e-03]],\n",
      "\n",
      "         [[ 2.7962e-01]],\n",
      "\n",
      "         [[ 1.7457e+00]],\n",
      "\n",
      "         [[ 7.2359e-02]],\n",
      "\n",
      "         [[-1.0905e-01]],\n",
      "\n",
      "         [[ 2.7217e-02]],\n",
      "\n",
      "         [[-1.2506e-01]],\n",
      "\n",
      "         [[-8.3062e-02]],\n",
      "\n",
      "         [[ 1.2822e-01]],\n",
      "\n",
      "         [[ 8.6499e-02]],\n",
      "\n",
      "         [[ 6.3617e-02]],\n",
      "\n",
      "         [[-4.5501e-01]],\n",
      "\n",
      "         [[-1.9506e-01]],\n",
      "\n",
      "         [[-1.2466e+00]],\n",
      "\n",
      "         [[-9.9126e-01]],\n",
      "\n",
      "         [[-1.2135e+00]],\n",
      "\n",
      "         [[ 2.7300e-01]],\n",
      "\n",
      "         [[-7.4717e-01]],\n",
      "\n",
      "         [[ 5.2727e-01]],\n",
      "\n",
      "         [[ 1.1294e+00]],\n",
      "\n",
      "         [[ 1.3904e-01]],\n",
      "\n",
      "         [[-5.3465e-02]],\n",
      "\n",
      "         [[-1.0363e+00]],\n",
      "\n",
      "         [[-1.3857e-01]],\n",
      "\n",
      "         [[-5.1232e-01]],\n",
      "\n",
      "         [[ 1.3509e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0988e-01]],\n",
      "\n",
      "         [[-8.9371e-02]],\n",
      "\n",
      "         [[-7.0077e-02]],\n",
      "\n",
      "         [[-1.1842e-01]],\n",
      "\n",
      "         [[ 2.9090e-01]],\n",
      "\n",
      "         [[-9.0762e-02]],\n",
      "\n",
      "         [[ 5.5080e-02]],\n",
      "\n",
      "         [[-4.5540e-01]],\n",
      "\n",
      "         [[-3.7903e-01]],\n",
      "\n",
      "         [[ 1.2084e-01]],\n",
      "\n",
      "         [[ 2.3187e-01]],\n",
      "\n",
      "         [[ 1.1106e-01]],\n",
      "\n",
      "         [[-2.9757e-02]],\n",
      "\n",
      "         [[ 3.5006e-01]],\n",
      "\n",
      "         [[-1.2952e-01]],\n",
      "\n",
      "         [[ 1.4781e-01]],\n",
      "\n",
      "         [[ 2.9626e-01]],\n",
      "\n",
      "         [[-1.5091e-01]],\n",
      "\n",
      "         [[ 3.2650e-01]],\n",
      "\n",
      "         [[-6.6577e-02]],\n",
      "\n",
      "         [[ 1.9044e-02]],\n",
      "\n",
      "         [[ 6.9826e-02]],\n",
      "\n",
      "         [[ 3.3642e-01]],\n",
      "\n",
      "         [[ 4.8396e-02]],\n",
      "\n",
      "         [[-1.7066e-01]],\n",
      "\n",
      "         [[-3.0409e+00]],\n",
      "\n",
      "         [[-2.7727e-02]],\n",
      "\n",
      "         [[-3.6192e-02]],\n",
      "\n",
      "         [[-8.5021e-03]],\n",
      "\n",
      "         [[-1.6829e-03]],\n",
      "\n",
      "         [[-3.2247e-01]],\n",
      "\n",
      "         [[-5.2023e-01]],\n",
      "\n",
      "         [[ 3.2982e-01]],\n",
      "\n",
      "         [[ 9.9548e-01]],\n",
      "\n",
      "         [[ 7.1179e-02]],\n",
      "\n",
      "         [[ 1.5274e-02]],\n",
      "\n",
      "         [[-3.4471e-01]],\n",
      "\n",
      "         [[-1.4255e-01]],\n",
      "\n",
      "         [[-5.1558e-01]],\n",
      "\n",
      "         [[-3.6121e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8673e-01]],\n",
      "\n",
      "         [[ 2.3247e-01]],\n",
      "\n",
      "         [[ 6.7683e-02]],\n",
      "\n",
      "         [[ 5.4529e-02]],\n",
      "\n",
      "         [[ 1.6692e-01]],\n",
      "\n",
      "         [[-5.3015e-01]],\n",
      "\n",
      "         [[ 5.8608e-01]],\n",
      "\n",
      "         [[ 9.8684e-03]],\n",
      "\n",
      "         [[ 2.2095e-01]],\n",
      "\n",
      "         [[-6.1924e-01]],\n",
      "\n",
      "         [[ 1.6157e-01]],\n",
      "\n",
      "         [[ 2.7012e-02]],\n",
      "\n",
      "         [[ 1.5584e-01]],\n",
      "\n",
      "         [[-4.1318e-02]],\n",
      "\n",
      "         [[ 1.9592e-01]],\n",
      "\n",
      "         [[-5.4831e-01]],\n",
      "\n",
      "         [[ 1.6953e-02]],\n",
      "\n",
      "         [[-6.9583e-01]],\n",
      "\n",
      "         [[-9.8464e-01]],\n",
      "\n",
      "         [[ 7.2809e-01]],\n",
      "\n",
      "         [[-3.0946e-02]],\n",
      "\n",
      "         [[ 1.7126e+00]],\n",
      "\n",
      "         [[ 9.4861e-02]],\n",
      "\n",
      "         [[ 2.3957e-01]],\n",
      "\n",
      "         [[-1.3722e+00]],\n",
      "\n",
      "         [[-2.1176e-01]],\n",
      "\n",
      "         [[ 3.3549e-01]],\n",
      "\n",
      "         [[ 6.9003e-02]],\n",
      "\n",
      "         [[ 1.6542e-01]],\n",
      "\n",
      "         [[-1.9111e-01]],\n",
      "\n",
      "         [[ 5.3602e-02]],\n",
      "\n",
      "         [[-2.7227e-01]],\n",
      "\n",
      "         [[-1.5632e-01]],\n",
      "\n",
      "         [[-3.6381e-02]],\n",
      "\n",
      "         [[-2.6259e-02]],\n",
      "\n",
      "         [[ 1.7842e-02]],\n",
      "\n",
      "         [[-4.0265e-01]],\n",
      "\n",
      "         [[ 1.9432e-01]],\n",
      "\n",
      "         [[ 8.9592e-02]],\n",
      "\n",
      "         [[ 1.7231e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1679e-01]],\n",
      "\n",
      "         [[ 3.3651e-01]],\n",
      "\n",
      "         [[ 3.2043e-02]],\n",
      "\n",
      "         [[ 4.3496e-01]],\n",
      "\n",
      "         [[-1.6290e-01]],\n",
      "\n",
      "         [[-4.9077e-02]],\n",
      "\n",
      "         [[ 1.2899e+00]],\n",
      "\n",
      "         [[ 1.5551e-01]],\n",
      "\n",
      "         [[ 1.3486e-01]],\n",
      "\n",
      "         [[-2.0562e-01]],\n",
      "\n",
      "         [[-1.5940e-01]],\n",
      "\n",
      "         [[-7.4389e-02]],\n",
      "\n",
      "         [[ 3.5451e-01]],\n",
      "\n",
      "         [[ 5.0848e-02]],\n",
      "\n",
      "         [[-1.9198e-01]],\n",
      "\n",
      "         [[-3.8232e-01]],\n",
      "\n",
      "         [[ 3.8256e-01]],\n",
      "\n",
      "         [[-6.7058e-02]],\n",
      "\n",
      "         [[-2.1572e-01]],\n",
      "\n",
      "         [[ 4.1257e-02]],\n",
      "\n",
      "         [[ 8.3752e-01]],\n",
      "\n",
      "         [[ 7.5689e-02]],\n",
      "\n",
      "         [[-6.5121e-02]],\n",
      "\n",
      "         [[ 1.7376e-01]],\n",
      "\n",
      "         [[-3.1322e-02]],\n",
      "\n",
      "         [[-4.9649e-01]],\n",
      "\n",
      "         [[ 2.8104e-01]],\n",
      "\n",
      "         [[-3.9765e-01]],\n",
      "\n",
      "         [[ 3.3219e-01]],\n",
      "\n",
      "         [[-6.9579e-02]],\n",
      "\n",
      "         [[ 9.0844e-01]],\n",
      "\n",
      "         [[ 1.3725e+00]],\n",
      "\n",
      "         [[-1.7158e-01]],\n",
      "\n",
      "         [[-6.0239e-01]],\n",
      "\n",
      "         [[ 8.0377e-01]],\n",
      "\n",
      "         [[-5.9387e-02]],\n",
      "\n",
      "         [[-3.8775e-01]],\n",
      "\n",
      "         [[ 5.6175e-01]],\n",
      "\n",
      "         [[ 3.3606e-01]],\n",
      "\n",
      "         [[-4.0667e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2898e-01]],\n",
      "\n",
      "         [[-3.2152e-01]],\n",
      "\n",
      "         [[-1.0080e-01]],\n",
      "\n",
      "         [[-6.5617e-01]],\n",
      "\n",
      "         [[-1.2821e-01]],\n",
      "\n",
      "         [[ 2.8094e-01]],\n",
      "\n",
      "         [[-9.4903e-01]],\n",
      "\n",
      "         [[-4.9636e-01]],\n",
      "\n",
      "         [[ 1.0898e+00]],\n",
      "\n",
      "         [[ 4.7268e-01]],\n",
      "\n",
      "         [[-1.7809e-01]],\n",
      "\n",
      "         [[-9.4286e-02]],\n",
      "\n",
      "         [[-3.6424e-01]],\n",
      "\n",
      "         [[-3.1009e-01]],\n",
      "\n",
      "         [[ 2.1567e-01]],\n",
      "\n",
      "         [[-1.1782e-01]],\n",
      "\n",
      "         [[-1.3011e+00]],\n",
      "\n",
      "         [[ 2.0273e+00]],\n",
      "\n",
      "         [[ 5.1123e-03]],\n",
      "\n",
      "         [[ 1.2289e-01]],\n",
      "\n",
      "         [[ 1.8991e-01]],\n",
      "\n",
      "         [[ 1.5882e-01]],\n",
      "\n",
      "         [[-8.9051e-01]],\n",
      "\n",
      "         [[ 3.5353e-02]],\n",
      "\n",
      "         [[ 1.2217e-01]],\n",
      "\n",
      "         [[ 4.7828e-01]],\n",
      "\n",
      "         [[-3.2291e-01]],\n",
      "\n",
      "         [[ 3.2455e-01]],\n",
      "\n",
      "         [[ 2.6726e-01]],\n",
      "\n",
      "         [[-3.1029e-01]],\n",
      "\n",
      "         [[-2.6016e-03]],\n",
      "\n",
      "         [[-3.1150e-01]],\n",
      "\n",
      "         [[ 4.6282e-01]],\n",
      "\n",
      "         [[ 1.0361e-01]],\n",
      "\n",
      "         [[ 3.5864e-01]],\n",
      "\n",
      "         [[-1.5779e-01]],\n",
      "\n",
      "         [[ 6.0156e-01]],\n",
      "\n",
      "         [[-1.7316e-01]],\n",
      "\n",
      "         [[ 2.8539e-01]],\n",
      "\n",
      "         [[ 3.3735e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0596e-01]],\n",
      "\n",
      "         [[-7.7289e-01]],\n",
      "\n",
      "         [[ 2.2169e+00]],\n",
      "\n",
      "         [[-2.2037e-01]],\n",
      "\n",
      "         [[-4.0960e-01]],\n",
      "\n",
      "         [[ 5.3230e-01]],\n",
      "\n",
      "         [[ 2.4387e-01]],\n",
      "\n",
      "         [[-7.3901e-02]],\n",
      "\n",
      "         [[-1.2985e-01]],\n",
      "\n",
      "         [[ 1.3929e-01]],\n",
      "\n",
      "         [[ 4.4081e-02]],\n",
      "\n",
      "         [[ 6.1303e-02]],\n",
      "\n",
      "         [[ 1.3003e-01]],\n",
      "\n",
      "         [[ 2.7001e-01]],\n",
      "\n",
      "         [[ 5.5033e-01]],\n",
      "\n",
      "         [[-1.7524e-01]],\n",
      "\n",
      "         [[-1.1716e-01]],\n",
      "\n",
      "         [[-6.3428e-01]],\n",
      "\n",
      "         [[ 3.0379e-02]],\n",
      "\n",
      "         [[-1.2812e+00]],\n",
      "\n",
      "         [[-6.1271e-02]],\n",
      "\n",
      "         [[ 3.0946e-01]],\n",
      "\n",
      "         [[-4.6416e-01]],\n",
      "\n",
      "         [[-1.3504e+00]],\n",
      "\n",
      "         [[-9.8539e-01]],\n",
      "\n",
      "         [[-1.1116e-01]],\n",
      "\n",
      "         [[ 1.2048e-01]],\n",
      "\n",
      "         [[-3.8300e-01]],\n",
      "\n",
      "         [[ 1.9685e-01]],\n",
      "\n",
      "         [[ 1.3261e-02]],\n",
      "\n",
      "         [[ 1.1112e-01]],\n",
      "\n",
      "         [[ 2.4235e-01]],\n",
      "\n",
      "         [[ 4.6409e-01]],\n",
      "\n",
      "         [[ 1.9356e-01]],\n",
      "\n",
      "         [[-1.2909e-02]],\n",
      "\n",
      "         [[-3.3059e-01]],\n",
      "\n",
      "         [[ 4.4167e-01]],\n",
      "\n",
      "         [[ 8.4714e-02]],\n",
      "\n",
      "         [[ 1.9663e-01]],\n",
      "\n",
      "         [[ 2.9211e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1735e-01]],\n",
      "\n",
      "         [[-3.8578e-01]],\n",
      "\n",
      "         [[ 1.9353e-01]],\n",
      "\n",
      "         [[-4.4794e-01]],\n",
      "\n",
      "         [[ 1.1417e-01]],\n",
      "\n",
      "         [[-1.8003e-01]],\n",
      "\n",
      "         [[-3.1901e-01]],\n",
      "\n",
      "         [[-1.1337e-01]],\n",
      "\n",
      "         [[ 3.0482e-01]],\n",
      "\n",
      "         [[ 1.6172e-01]],\n",
      "\n",
      "         [[ 1.4152e-02]],\n",
      "\n",
      "         [[-5.4871e-02]],\n",
      "\n",
      "         [[-4.4286e-01]],\n",
      "\n",
      "         [[ 1.0062e+00]],\n",
      "\n",
      "         [[ 2.2925e-01]],\n",
      "\n",
      "         [[-1.8111e-01]],\n",
      "\n",
      "         [[-4.1118e-01]],\n",
      "\n",
      "         [[ 4.4952e-01]],\n",
      "\n",
      "         [[-6.6729e-02]],\n",
      "\n",
      "         [[ 3.1951e-02]],\n",
      "\n",
      "         [[-8.2405e-02]],\n",
      "\n",
      "         [[ 6.4878e-02]],\n",
      "\n",
      "         [[-3.6706e-01]],\n",
      "\n",
      "         [[ 1.9005e-01]],\n",
      "\n",
      "         [[-5.7407e-02]],\n",
      "\n",
      "         [[ 3.1646e-02]],\n",
      "\n",
      "         [[ 1.1608e-01]],\n",
      "\n",
      "         [[-2.9406e-01]],\n",
      "\n",
      "         [[-4.0920e-01]],\n",
      "\n",
      "         [[-1.0655e+00]],\n",
      "\n",
      "         [[-7.0116e-02]],\n",
      "\n",
      "         [[-2.1700e-01]],\n",
      "\n",
      "         [[-1.1019e-01]],\n",
      "\n",
      "         [[-1.5148e-01]],\n",
      "\n",
      "         [[-3.1039e-01]],\n",
      "\n",
      "         [[ 5.4945e-02]],\n",
      "\n",
      "         [[ 3.9624e-01]],\n",
      "\n",
      "         [[-1.2860e+00]],\n",
      "\n",
      "         [[-2.5412e-01]],\n",
      "\n",
      "         [[ 1.1400e+00]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([4.1048, 4.6232, 2.9138, 5.5186, 4.4993, 4.5229, 1.1532, 5.3401, 9.0092,\n",
      "        9.1761, 2.0912, 3.0143, 7.5321, 4.2379, 2.8362, 4.5315, 6.2254, 9.3629,\n",
      "        2.0466, 0.5422, 5.9982, 2.5400, 3.9061, 3.7610], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.4254, -0.2558,  0.4478,  3.6605, -0.9656, -0.7651,  3.5372,  0.4513,\n",
      "         1.1589,  1.3475,  0.2001,  0.0186, -1.0867, -0.5263,  1.3149,  2.0100,\n",
      "        -0.8904,  2.7912, -0.8153,  1.1871, -0.4152,  5.9270,  0.7626, -0.9343],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 4.1294e-01,  6.2828e-01,  3.2731e-01],\n",
      "          [ 7.8791e-01, -1.1223e+00, -3.6826e-01],\n",
      "          [ 2.8820e-01, -1.4285e-01, -1.0634e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3153e-02,  8.0631e-04, -1.0012e-01],\n",
      "          [-5.9268e-01, -7.9531e-01, -5.6355e-01],\n",
      "          [-5.2965e-02,  1.5939e-01,  3.3730e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4324e-01,  1.5454e+00,  2.3987e-01],\n",
      "          [-8.3253e-02, -8.0842e-01, -4.8256e-02],\n",
      "          [-1.0909e-01, -4.2021e-01, -1.6746e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2010e-01, -9.1140e-02,  4.9292e-01],\n",
      "          [ 2.8724e-01, -1.0805e+00,  2.2956e-01],\n",
      "          [ 2.1931e-01, -2.9046e-01,  1.9704e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.3223e-01,  1.7114e-01,  3.7540e-01],\n",
      "          [ 3.1707e-01,  4.5585e-01, -9.4052e-01],\n",
      "          [ 2.6021e-02,  2.4201e-01, -2.9122e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.8686e-01, -3.9949e-01, -1.0125e+00],\n",
      "          [-5.8097e-02,  1.1841e+00, -3.8255e-01],\n",
      "          [-5.5257e-02, -4.1948e-02, -1.5941e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.5910e-01, -4.6897e-01,  2.4633e-01],\n",
      "          [-4.3752e-01, -5.5292e-01,  1.6424e+00],\n",
      "          [ 1.5130e-02, -1.6226e-01, -3.5243e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6130e-02, -7.6583e-02, -3.7065e-02],\n",
      "          [-2.1367e-01,  2.2605e+00,  4.5785e-01],\n",
      "          [ 7.5560e-02, -1.1303e-02,  1.4558e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.9328e-02, -2.0314e-01, -2.0457e-01],\n",
      "          [-1.0419e-01, -5.2873e-01, -7.0563e-01],\n",
      "          [-6.1937e-01, -5.3636e-01,  4.1121e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5810e-01, -8.7165e-02, -1.6561e-01],\n",
      "          [ 1.0206e+00,  9.2509e-01,  1.5299e-01],\n",
      "          [ 4.8333e-01,  5.0098e-01, -2.2138e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8834e-01, -1.1890e-01, -2.2930e-01],\n",
      "          [-9.8492e-01,  2.7552e-01,  4.4726e-01],\n",
      "          [-6.1493e-02,  1.3052e-01, -7.9142e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2393e-01,  4.0731e-01,  4.1026e-01],\n",
      "          [-3.6320e-01, -5.1848e-01, -1.0703e-02],\n",
      "          [-5.2297e-02, -5.6700e-02, -1.4208e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2313e-01, -7.0383e-01, -2.8174e-01],\n",
      "          [-9.7970e-01, -6.0454e-02,  4.1258e-03],\n",
      "          [ 7.4674e-03,  2.6366e-02,  2.8665e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6027e-01,  1.5654e+00,  1.1648e-01],\n",
      "          [-2.5526e-01, -2.0848e-01, -3.6076e-01],\n",
      "          [-1.8055e-01,  5.0133e-02,  6.6942e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.2960e-02, -3.9776e-01, -8.6604e-02],\n",
      "          [ 1.3235e-01, -2.6078e+00, -4.8833e-01],\n",
      "          [ 4.9299e-02, -1.0157e-01, -2.4744e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0867e-01, -7.1815e-01, -2.6995e-01],\n",
      "          [-4.3595e-01,  9.6133e-02,  2.9936e-01],\n",
      "          [-4.1151e-01,  1.1661e-01,  1.4898e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4977e-02,  1.2485e-01,  1.5795e-02],\n",
      "          [-2.0375e+00, -2.6522e-01, -2.0777e-01],\n",
      "          [ 1.5666e-01,  1.7790e-01,  1.6562e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.1731e-01,  5.2282e-01,  1.9831e-01],\n",
      "          [ 2.9123e-01,  4.0378e-01,  5.6947e-01],\n",
      "          [-3.3074e-02,  1.0463e-02,  2.6770e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7409e-02,  4.3162e-01, -2.8511e-02],\n",
      "          [ 1.1086e+00,  1.6565e-01,  4.4634e-01],\n",
      "          [-2.7272e-01,  5.8302e-01, -5.9306e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7693e-01,  6.9763e-01,  1.0827e-01],\n",
      "          [ 6.2750e-01, -1.0276e+00, -5.0226e-01],\n",
      "          [ 5.0076e-02, -4.0885e-01, -6.0479e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6179e-04,  5.1588e-01, -1.0132e+00],\n",
      "          [ 1.3934e-01, -1.2939e-01,  8.1525e-01],\n",
      "          [ 8.1948e-02, -2.1481e-01,  8.4501e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.3652e-02, -1.9622e-01, -1.2106e-01],\n",
      "          [ 1.7192e+00, -6.4008e-01, -6.0843e-01],\n",
      "          [-1.5660e-01, -6.9774e-02, -2.2457e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5791e-01, -6.0491e-01, -3.9924e-01],\n",
      "          [-1.0417e+00,  1.3427e+00,  2.3468e-01],\n",
      "          [-1.5420e-01,  3.2247e-01,  2.5801e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.7514e-02, -3.6599e-01,  1.4454e-02],\n",
      "          [ 1.3462e-01, -1.5294e-01,  3.0791e-01],\n",
      "          [ 1.0497e-01, -1.9839e+00, -2.7871e-01]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([2.0707, 1.6287, 1.8384, 2.7220, 1.7253, 0.9325, 2.6457, 5.2081, 1.5749,\n",
      "        1.7227, 1.6077, 3.1095, 1.5901, 1.9262, 3.5344, 1.1707, 1.3556, 1.5059,\n",
      "        2.9322, 0.7276, 1.3702, 2.0530, 3.0975, 1.4915], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.9013, -3.4607,  1.9324, -2.8637,  1.1219,  1.5235,  2.5289, -1.3796,\n",
      "         2.5328,  4.8585,  2.3998, -4.2738,  4.1641,  2.2935, -0.0742,  2.1272,\n",
      "         2.7700,  3.1802,  1.8835,  5.8186,  1.6067,  2.1364,  1.7231,  1.9106],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-1.8639e-01]],\n",
      "\n",
      "         [[-3.7617e-01]],\n",
      "\n",
      "         [[-1.6415e-03]],\n",
      "\n",
      "         [[ 1.9408e-01]],\n",
      "\n",
      "         [[ 2.6601e-02]],\n",
      "\n",
      "         [[ 4.0690e-03]],\n",
      "\n",
      "         [[ 6.6909e-03]],\n",
      "\n",
      "         [[-2.2287e-01]],\n",
      "\n",
      "         [[ 1.1845e-01]],\n",
      "\n",
      "         [[ 2.9198e-01]],\n",
      "\n",
      "         [[ 1.8052e-03]],\n",
      "\n",
      "         [[-8.2293e-02]],\n",
      "\n",
      "         [[-8.2467e-01]],\n",
      "\n",
      "         [[-1.6732e-01]],\n",
      "\n",
      "         [[ 5.2884e-02]],\n",
      "\n",
      "         [[ 3.9425e-02]],\n",
      "\n",
      "         [[-6.7078e-01]],\n",
      "\n",
      "         [[-8.5768e-02]],\n",
      "\n",
      "         [[-9.3854e-03]],\n",
      "\n",
      "         [[-3.7107e-02]],\n",
      "\n",
      "         [[ 9.1975e-02]],\n",
      "\n",
      "         [[ 7.1732e-02]],\n",
      "\n",
      "         [[-3.3828e-02]],\n",
      "\n",
      "         [[ 1.5252e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2853e-02]],\n",
      "\n",
      "         [[-2.0419e-01]],\n",
      "\n",
      "         [[-1.0955e-01]],\n",
      "\n",
      "         [[ 3.8559e-01]],\n",
      "\n",
      "         [[-2.2340e-01]],\n",
      "\n",
      "         [[ 1.1131e-01]],\n",
      "\n",
      "         [[-1.7030e-01]],\n",
      "\n",
      "         [[-1.7829e+00]],\n",
      "\n",
      "         [[ 9.8051e-02]],\n",
      "\n",
      "         [[ 2.1033e-01]],\n",
      "\n",
      "         [[-1.8138e-01]],\n",
      "\n",
      "         [[ 1.6874e-01]],\n",
      "\n",
      "         [[-6.1073e-02]],\n",
      "\n",
      "         [[-3.0066e-01]],\n",
      "\n",
      "         [[ 2.1720e-01]],\n",
      "\n",
      "         [[-1.7084e-02]],\n",
      "\n",
      "         [[-9.6294e-02]],\n",
      "\n",
      "         [[-1.0927e-01]],\n",
      "\n",
      "         [[ 5.7245e-01]],\n",
      "\n",
      "         [[ 1.4566e-02]],\n",
      "\n",
      "         [[-3.7379e-02]],\n",
      "\n",
      "         [[-1.8889e-01]],\n",
      "\n",
      "         [[ 9.1581e-02]],\n",
      "\n",
      "         [[ 9.9203e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.4501e-02]],\n",
      "\n",
      "         [[-3.1345e-01]],\n",
      "\n",
      "         [[ 1.2253e-02]],\n",
      "\n",
      "         [[-8.4939e-02]],\n",
      "\n",
      "         [[ 1.6353e-01]],\n",
      "\n",
      "         [[ 1.7507e-01]],\n",
      "\n",
      "         [[ 1.1279e-03]],\n",
      "\n",
      "         [[-2.4063e-01]],\n",
      "\n",
      "         [[-6.2177e-02]],\n",
      "\n",
      "         [[ 2.6336e-01]],\n",
      "\n",
      "         [[ 6.5801e-02]],\n",
      "\n",
      "         [[-7.9298e-02]],\n",
      "\n",
      "         [[-8.3654e-01]],\n",
      "\n",
      "         [[ 2.1546e-01]],\n",
      "\n",
      "         [[ 1.2776e-01]],\n",
      "\n",
      "         [[ 1.5509e-01]],\n",
      "\n",
      "         [[-9.3889e-01]],\n",
      "\n",
      "         [[ 2.1598e-02]],\n",
      "\n",
      "         [[ 9.9587e-03]],\n",
      "\n",
      "         [[-1.0324e-01]],\n",
      "\n",
      "         [[ 1.4799e-01]],\n",
      "\n",
      "         [[-7.7693e-02]],\n",
      "\n",
      "         [[ 6.9129e-02]],\n",
      "\n",
      "         [[ 9.7608e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.7197e-02]],\n",
      "\n",
      "         [[-9.6137e-02]],\n",
      "\n",
      "         [[ 3.0836e-03]],\n",
      "\n",
      "         [[-4.9554e-01]],\n",
      "\n",
      "         [[ 9.6954e-02]],\n",
      "\n",
      "         [[ 3.3488e-01]],\n",
      "\n",
      "         [[-5.2581e-01]],\n",
      "\n",
      "         [[-1.3995e+00]],\n",
      "\n",
      "         [[-7.9909e-02]],\n",
      "\n",
      "         [[ 1.1026e-01]],\n",
      "\n",
      "         [[-1.3747e-01]],\n",
      "\n",
      "         [[ 2.5161e-01]],\n",
      "\n",
      "         [[ 2.1291e-01]],\n",
      "\n",
      "         [[-8.5242e-02]],\n",
      "\n",
      "         [[-3.0240e-01]],\n",
      "\n",
      "         [[ 2.2499e-01]],\n",
      "\n",
      "         [[ 1.0898e-02]],\n",
      "\n",
      "         [[-1.5679e-01]],\n",
      "\n",
      "         [[-7.3153e-01]],\n",
      "\n",
      "         [[ 1.1837e-01]],\n",
      "\n",
      "         [[ 4.4376e-02]],\n",
      "\n",
      "         [[-7.5923e-02]],\n",
      "\n",
      "         [[-1.4007e-01]],\n",
      "\n",
      "         [[-1.5054e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.5524e-02]],\n",
      "\n",
      "         [[-4.8164e-01]],\n",
      "\n",
      "         [[ 5.7159e-02]],\n",
      "\n",
      "         [[ 1.0844e+00]],\n",
      "\n",
      "         [[ 7.4458e-02]],\n",
      "\n",
      "         [[-3.2232e-01]],\n",
      "\n",
      "         [[-1.4700e-01]],\n",
      "\n",
      "         [[-1.2084e-01]],\n",
      "\n",
      "         [[ 4.0974e-02]],\n",
      "\n",
      "         [[-1.4176e-01]],\n",
      "\n",
      "         [[ 3.3602e-02]],\n",
      "\n",
      "         [[ 4.6281e-01]],\n",
      "\n",
      "         [[-2.1998e-01]],\n",
      "\n",
      "         [[-9.5621e-02]],\n",
      "\n",
      "         [[-3.4636e-01]],\n",
      "\n",
      "         [[-2.0254e-01]],\n",
      "\n",
      "         [[ 9.4898e-02]],\n",
      "\n",
      "         [[ 1.2499e-02]],\n",
      "\n",
      "         [[-6.3310e-02]],\n",
      "\n",
      "         [[-8.6976e-02]],\n",
      "\n",
      "         [[-1.7067e-01]],\n",
      "\n",
      "         [[ 1.8625e-03]],\n",
      "\n",
      "         [[ 1.3452e-01]],\n",
      "\n",
      "         [[-2.0025e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.0633e-01]],\n",
      "\n",
      "         [[ 2.7680e-02]],\n",
      "\n",
      "         [[-4.4234e-02]],\n",
      "\n",
      "         [[ 6.1270e-01]],\n",
      "\n",
      "         [[ 2.1196e-03]],\n",
      "\n",
      "         [[ 9.3586e-02]],\n",
      "\n",
      "         [[-1.3826e-01]],\n",
      "\n",
      "         [[-8.5111e-01]],\n",
      "\n",
      "         [[ 5.6421e-02]],\n",
      "\n",
      "         [[ 1.5758e-01]],\n",
      "\n",
      "         [[-4.7467e-02]],\n",
      "\n",
      "         [[ 3.8906e-01]],\n",
      "\n",
      "         [[-1.4246e-01]],\n",
      "\n",
      "         [[-5.3834e-02]],\n",
      "\n",
      "         [[ 2.8093e-02]],\n",
      "\n",
      "         [[ 2.9374e-02]],\n",
      "\n",
      "         [[-2.2821e-01]],\n",
      "\n",
      "         [[ 1.4232e-02]],\n",
      "\n",
      "         [[ 3.0469e-01]],\n",
      "\n",
      "         [[ 2.1271e-02]],\n",
      "\n",
      "         [[ 6.4167e-02]],\n",
      "\n",
      "         [[-2.0440e-01]],\n",
      "\n",
      "         [[-1.0651e+00]],\n",
      "\n",
      "         [[-5.1874e-02]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.0649,  0.0757,  0.0897,  0.0839, -0.0537,  0.0502], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-7.3969e-02]],\n",
      "\n",
      "         [[ 1.7142e-02]],\n",
      "\n",
      "         [[ 2.4703e-01]],\n",
      "\n",
      "         [[-1.0098e-01]],\n",
      "\n",
      "         [[-3.1353e-01]],\n",
      "\n",
      "         [[-2.8265e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.5800e-02]],\n",
      "\n",
      "         [[-8.2584e-02]],\n",
      "\n",
      "         [[-1.1248e-01]],\n",
      "\n",
      "         [[ 8.8776e-02]],\n",
      "\n",
      "         [[-4.4091e-01]],\n",
      "\n",
      "         [[-1.8787e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0146e-01]],\n",
      "\n",
      "         [[-4.2846e-01]],\n",
      "\n",
      "         [[-1.8636e-01]],\n",
      "\n",
      "         [[-1.9368e-01]],\n",
      "\n",
      "         [[-1.7767e-01]],\n",
      "\n",
      "         [[-2.4971e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.1390e-02]],\n",
      "\n",
      "         [[-1.0165e-01]],\n",
      "\n",
      "         [[ 1.4952e-01]],\n",
      "\n",
      "         [[ 4.4931e-02]],\n",
      "\n",
      "         [[-2.1329e-01]],\n",
      "\n",
      "         [[-2.4739e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1886e-01]],\n",
      "\n",
      "         [[-1.1018e+00]],\n",
      "\n",
      "         [[ 1.3980e-01]],\n",
      "\n",
      "         [[-5.5934e-01]],\n",
      "\n",
      "         [[ 1.5423e-01]],\n",
      "\n",
      "         [[-4.5896e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.6611e-01]],\n",
      "\n",
      "         [[-3.6609e-01]],\n",
      "\n",
      "         [[-4.6941e-01]],\n",
      "\n",
      "         [[-7.2286e-01]],\n",
      "\n",
      "         [[ 1.1535e-01]],\n",
      "\n",
      "         [[-5.3331e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7030e-02]],\n",
      "\n",
      "         [[-7.0029e-01]],\n",
      "\n",
      "         [[-1.3389e-01]],\n",
      "\n",
      "         [[-1.1952e+00]],\n",
      "\n",
      "         [[ 2.0454e-01]],\n",
      "\n",
      "         [[-2.8197e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5112e-01]],\n",
      "\n",
      "         [[ 3.3589e-01]],\n",
      "\n",
      "         [[ 7.1963e-01]],\n",
      "\n",
      "         [[ 1.6346e-01]],\n",
      "\n",
      "         [[-3.7374e-03]],\n",
      "\n",
      "         [[ 1.0260e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.2004e-01]],\n",
      "\n",
      "         [[-7.3870e-01]],\n",
      "\n",
      "         [[-4.3400e-01]],\n",
      "\n",
      "         [[-6.5318e-01]],\n",
      "\n",
      "         [[-7.6438e-01]],\n",
      "\n",
      "         [[-5.7434e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3664e-01]],\n",
      "\n",
      "         [[ 5.1901e-04]],\n",
      "\n",
      "         [[ 8.9710e-01]],\n",
      "\n",
      "         [[-1.7551e-01]],\n",
      "\n",
      "         [[-1.4980e+00]],\n",
      "\n",
      "         [[-1.0698e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.7530e-02]],\n",
      "\n",
      "         [[-1.1646e+00]],\n",
      "\n",
      "         [[-2.0655e-01]],\n",
      "\n",
      "         [[-1.1740e+00]],\n",
      "\n",
      "         [[-6.2170e-03]],\n",
      "\n",
      "         [[-4.2350e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7576e-01]],\n",
      "\n",
      "         [[-3.4879e-01]],\n",
      "\n",
      "         [[ 6.4603e-02]],\n",
      "\n",
      "         [[ 2.4832e-02]],\n",
      "\n",
      "         [[ 1.7114e-01]],\n",
      "\n",
      "         [[ 5.4187e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7211e-01]],\n",
      "\n",
      "         [[-4.2450e-01]],\n",
      "\n",
      "         [[-1.0084e+00]],\n",
      "\n",
      "         [[-5.3678e-01]],\n",
      "\n",
      "         [[ 8.0840e-01]],\n",
      "\n",
      "         [[-4.8266e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.2612e-01]],\n",
      "\n",
      "         [[-1.0172e+00]],\n",
      "\n",
      "         [[-1.8596e-01]],\n",
      "\n",
      "         [[-5.4699e-01]],\n",
      "\n",
      "         [[-3.3703e-01]],\n",
      "\n",
      "         [[-3.3114e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5624e-01]],\n",
      "\n",
      "         [[-5.7461e-01]],\n",
      "\n",
      "         [[ 8.6703e-02]],\n",
      "\n",
      "         [[-9.7930e-01]],\n",
      "\n",
      "         [[ 5.3928e-01]],\n",
      "\n",
      "         [[-5.6430e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4011e-01]],\n",
      "\n",
      "         [[-1.1486e+00]],\n",
      "\n",
      "         [[ 6.2169e-02]],\n",
      "\n",
      "         [[-5.4945e-01]],\n",
      "\n",
      "         [[ 2.5271e-01]],\n",
      "\n",
      "         [[-8.3406e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4779e-01]],\n",
      "\n",
      "         [[-5.1830e-02]],\n",
      "\n",
      "         [[ 3.8608e-01]],\n",
      "\n",
      "         [[ 1.4226e-01]],\n",
      "\n",
      "         [[-4.3892e-01]],\n",
      "\n",
      "         [[-2.6621e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4142e-01]],\n",
      "\n",
      "         [[-2.7235e-01]],\n",
      "\n",
      "         [[ 5.2874e-01]],\n",
      "\n",
      "         [[ 1.3574e-01]],\n",
      "\n",
      "         [[-5.8913e-01]],\n",
      "\n",
      "         [[-1.8698e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7099e-01]],\n",
      "\n",
      "         [[-2.7591e-01]],\n",
      "\n",
      "         [[-2.7584e-01]],\n",
      "\n",
      "         [[-7.3172e-01]],\n",
      "\n",
      "         [[-1.9672e-01]],\n",
      "\n",
      "         [[-3.2658e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9238e+00]],\n",
      "\n",
      "         [[-3.0052e-01]],\n",
      "\n",
      "         [[-1.9408e+00]],\n",
      "\n",
      "         [[ 2.4772e-02]],\n",
      "\n",
      "         [[-3.6717e-01]],\n",
      "\n",
      "         [[-2.2230e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2882e-01]],\n",
      "\n",
      "         [[-7.7632e-01]],\n",
      "\n",
      "         [[-2.7755e-02]],\n",
      "\n",
      "         [[-8.0260e-01]],\n",
      "\n",
      "         [[ 3.9692e-01]],\n",
      "\n",
      "         [[-2.9806e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2860e-01]],\n",
      "\n",
      "         [[-9.2522e-01]],\n",
      "\n",
      "         [[ 2.7972e-01]],\n",
      "\n",
      "         [[-2.0209e-01]],\n",
      "\n",
      "         [[ 2.9078e-01]],\n",
      "\n",
      "         [[-7.5004e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3092e-01]],\n",
      "\n",
      "         [[ 2.9418e-02]],\n",
      "\n",
      "         [[-4.4833e-02]],\n",
      "\n",
      "         [[-5.6167e-01]],\n",
      "\n",
      "         [[ 4.9027e-01]],\n",
      "\n",
      "         [[-1.4220e+00]]],\n",
      "\n",
      "\n",
      "        [[[-2.5163e-01]],\n",
      "\n",
      "         [[-5.9493e-01]],\n",
      "\n",
      "         [[-3.9727e-01]],\n",
      "\n",
      "         [[-3.3933e-01]],\n",
      "\n",
      "         [[-5.3567e-01]],\n",
      "\n",
      "         [[-2.6110e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.9585,  0.1996, -0.5468, -0.1327, -0.5000,  0.2719, -0.8258, -1.1588,\n",
      "         0.3007,  0.4797, -0.0643, -0.1570, -0.7394, -0.0515, -0.5362,  0.1002,\n",
      "        -0.1741,  0.3047, -0.0642, -0.3948,  0.0629, -1.1764, -1.6250,  0.0572],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-1.4338e+00]],\n",
      "\n",
      "         [[ 7.8316e-01]],\n",
      "\n",
      "         [[ 1.5462e-01]],\n",
      "\n",
      "         [[-1.4507e-01]],\n",
      "\n",
      "         [[-1.9901e-01]],\n",
      "\n",
      "         [[-1.6270e-01]],\n",
      "\n",
      "         [[ 1.9504e-01]],\n",
      "\n",
      "         [[-5.2298e-01]],\n",
      "\n",
      "         [[-3.6157e-01]],\n",
      "\n",
      "         [[ 3.1603e-01]],\n",
      "\n",
      "         [[ 7.1555e-02]],\n",
      "\n",
      "         [[ 1.3037e-02]],\n",
      "\n",
      "         [[ 6.2629e-01]],\n",
      "\n",
      "         [[ 5.7985e-01]],\n",
      "\n",
      "         [[ 2.3183e-02]],\n",
      "\n",
      "         [[ 6.1428e-02]],\n",
      "\n",
      "         [[ 1.0597e-01]],\n",
      "\n",
      "         [[-1.0293e-01]],\n",
      "\n",
      "         [[ 1.2043e-01]],\n",
      "\n",
      "         [[-2.9087e-01]],\n",
      "\n",
      "         [[-2.0511e-01]],\n",
      "\n",
      "         [[-4.5568e-01]],\n",
      "\n",
      "         [[ 1.2907e+00]],\n",
      "\n",
      "         [[ 1.9119e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.9011e-01]],\n",
      "\n",
      "         [[ 1.1794e+00]],\n",
      "\n",
      "         [[-2.4726e-01]],\n",
      "\n",
      "         [[ 1.8504e-01]],\n",
      "\n",
      "         [[ 1.4083e-01]],\n",
      "\n",
      "         [[ 2.1592e-01]],\n",
      "\n",
      "         [[ 2.0957e-01]],\n",
      "\n",
      "         [[ 2.7141e-01]],\n",
      "\n",
      "         [[-7.4232e-01]],\n",
      "\n",
      "         [[ 7.4632e-01]],\n",
      "\n",
      "         [[-1.7602e-01]],\n",
      "\n",
      "         [[ 9.3483e-02]],\n",
      "\n",
      "         [[ 5.6911e-01]],\n",
      "\n",
      "         [[-3.4012e-01]],\n",
      "\n",
      "         [[ 1.0957e-01]],\n",
      "\n",
      "         [[-3.6493e-02]],\n",
      "\n",
      "         [[-5.0209e-01]],\n",
      "\n",
      "         [[-3.3604e-01]],\n",
      "\n",
      "         [[ 1.9847e-01]],\n",
      "\n",
      "         [[ 4.8265e-01]],\n",
      "\n",
      "         [[ 3.3623e-02]],\n",
      "\n",
      "         [[ 1.1447e-01]],\n",
      "\n",
      "         [[ 3.2803e-01]],\n",
      "\n",
      "         [[ 7.5269e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9258e-01]],\n",
      "\n",
      "         [[-3.6141e-01]],\n",
      "\n",
      "         [[-1.7651e-01]],\n",
      "\n",
      "         [[-4.2714e-01]],\n",
      "\n",
      "         [[-4.8086e-01]],\n",
      "\n",
      "         [[-6.3766e-01]],\n",
      "\n",
      "         [[-7.5103e-02]],\n",
      "\n",
      "         [[-1.1432e-01]],\n",
      "\n",
      "         [[-4.0653e-01]],\n",
      "\n",
      "         [[ 9.9945e-01]],\n",
      "\n",
      "         [[-5.1496e-01]],\n",
      "\n",
      "         [[-1.9287e-03]],\n",
      "\n",
      "         [[ 3.3426e-01]],\n",
      "\n",
      "         [[-6.0435e-01]],\n",
      "\n",
      "         [[ 2.8448e-01]],\n",
      "\n",
      "         [[ 4.1068e-01]],\n",
      "\n",
      "         [[-1.6571e-01]],\n",
      "\n",
      "         [[-3.9720e-01]],\n",
      "\n",
      "         [[-7.7913e-02]],\n",
      "\n",
      "         [[ 5.5273e-02]],\n",
      "\n",
      "         [[ 3.8953e-01]],\n",
      "\n",
      "         [[-3.7462e-01]],\n",
      "\n",
      "         [[ 2.5207e-02]],\n",
      "\n",
      "         [[-8.9829e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1263e-01]],\n",
      "\n",
      "         [[-3.3846e-01]],\n",
      "\n",
      "         [[-8.3027e-02]],\n",
      "\n",
      "         [[ 1.0533e+00]],\n",
      "\n",
      "         [[ 2.0074e-03]],\n",
      "\n",
      "         [[-1.9826e-01]],\n",
      "\n",
      "         [[ 3.9094e-01]],\n",
      "\n",
      "         [[ 3.0148e-01]],\n",
      "\n",
      "         [[-4.1927e-01]],\n",
      "\n",
      "         [[ 3.8474e-01]],\n",
      "\n",
      "         [[-3.6320e-01]],\n",
      "\n",
      "         [[ 3.3503e-01]],\n",
      "\n",
      "         [[ 4.8675e-01]],\n",
      "\n",
      "         [[ 2.5787e-01]],\n",
      "\n",
      "         [[ 5.1471e-01]],\n",
      "\n",
      "         [[-4.7645e-01]],\n",
      "\n",
      "         [[-6.6235e-01]],\n",
      "\n",
      "         [[-8.9788e-01]],\n",
      "\n",
      "         [[ 4.7681e-02]],\n",
      "\n",
      "         [[-2.9060e-01]],\n",
      "\n",
      "         [[ 1.0739e-01]],\n",
      "\n",
      "         [[ 2.8406e-01]],\n",
      "\n",
      "         [[-9.2939e-02]],\n",
      "\n",
      "         [[-5.7124e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3893e-02]],\n",
      "\n",
      "         [[ 3.3847e-01]],\n",
      "\n",
      "         [[ 3.6221e-01]],\n",
      "\n",
      "         [[ 1.4876e-01]],\n",
      "\n",
      "         [[ 7.3735e-01]],\n",
      "\n",
      "         [[-7.2583e-01]],\n",
      "\n",
      "         [[-1.1871e-01]],\n",
      "\n",
      "         [[-7.2242e-01]],\n",
      "\n",
      "         [[-3.9805e-02]],\n",
      "\n",
      "         [[-4.7422e-02]],\n",
      "\n",
      "         [[-8.9489e-01]],\n",
      "\n",
      "         [[ 3.7839e-01]],\n",
      "\n",
      "         [[-1.5326e-01]],\n",
      "\n",
      "         [[ 4.8044e-02]],\n",
      "\n",
      "         [[-3.1482e-01]],\n",
      "\n",
      "         [[ 9.1364e-03]],\n",
      "\n",
      "         [[-6.9230e-02]],\n",
      "\n",
      "         [[ 3.5493e-02]],\n",
      "\n",
      "         [[-4.4664e-01]],\n",
      "\n",
      "         [[-2.9162e-01]],\n",
      "\n",
      "         [[ 5.5502e-01]],\n",
      "\n",
      "         [[-2.3441e-01]],\n",
      "\n",
      "         [[-2.9869e-01]],\n",
      "\n",
      "         [[-3.6195e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7407e-01]],\n",
      "\n",
      "         [[ 9.5899e-02]],\n",
      "\n",
      "         [[ 3.1196e-01]],\n",
      "\n",
      "         [[ 6.8085e-01]],\n",
      "\n",
      "         [[ 1.1636e-01]],\n",
      "\n",
      "         [[ 2.0667e+00]],\n",
      "\n",
      "         [[-5.2098e-02]],\n",
      "\n",
      "         [[ 1.8680e-01]],\n",
      "\n",
      "         [[-1.6894e-01]],\n",
      "\n",
      "         [[-3.4195e-02]],\n",
      "\n",
      "         [[ 1.0427e-02]],\n",
      "\n",
      "         [[ 5.2295e-01]],\n",
      "\n",
      "         [[-1.8796e-02]],\n",
      "\n",
      "         [[-3.7276e-01]],\n",
      "\n",
      "         [[ 9.2661e-01]],\n",
      "\n",
      "         [[-7.6730e-02]],\n",
      "\n",
      "         [[ 1.7890e-01]],\n",
      "\n",
      "         [[-1.0683e-02]],\n",
      "\n",
      "         [[-2.8413e-01]],\n",
      "\n",
      "         [[-1.8636e-01]],\n",
      "\n",
      "         [[ 4.5561e-01]],\n",
      "\n",
      "         [[ 1.3398e-01]],\n",
      "\n",
      "         [[ 4.6256e-02]],\n",
      "\n",
      "         [[ 7.9876e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.0844e-01]],\n",
      "\n",
      "         [[ 5.4645e-01]],\n",
      "\n",
      "         [[ 5.2977e-01]],\n",
      "\n",
      "         [[-8.5836e-02]],\n",
      "\n",
      "         [[ 1.1002e-01]],\n",
      "\n",
      "         [[ 2.7480e-01]],\n",
      "\n",
      "         [[-5.5138e-01]],\n",
      "\n",
      "         [[-1.0291e-02]],\n",
      "\n",
      "         [[-3.1554e-01]],\n",
      "\n",
      "         [[-4.1767e-01]],\n",
      "\n",
      "         [[-4.4726e-01]],\n",
      "\n",
      "         [[ 3.1709e-02]],\n",
      "\n",
      "         [[ 7.2003e-02]],\n",
      "\n",
      "         [[-1.5781e+00]],\n",
      "\n",
      "         [[-2.0886e-01]],\n",
      "\n",
      "         [[ 7.4340e-01]],\n",
      "\n",
      "         [[-2.2277e-01]],\n",
      "\n",
      "         [[ 3.5578e-01]],\n",
      "\n",
      "         [[-2.6817e-03]],\n",
      "\n",
      "         [[-1.8677e-01]],\n",
      "\n",
      "         [[-3.8426e-01]],\n",
      "\n",
      "         [[-1.6215e-01]],\n",
      "\n",
      "         [[ 2.3326e-01]],\n",
      "\n",
      "         [[ 2.8855e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9668e-02]],\n",
      "\n",
      "         [[-4.6964e-01]],\n",
      "\n",
      "         [[-3.8852e-01]],\n",
      "\n",
      "         [[ 2.2099e-01]],\n",
      "\n",
      "         [[-1.5208e-01]],\n",
      "\n",
      "         [[ 1.4925e-01]],\n",
      "\n",
      "         [[-3.6478e-01]],\n",
      "\n",
      "         [[-1.4003e+00]],\n",
      "\n",
      "         [[-1.0847e-02]],\n",
      "\n",
      "         [[-4.6037e-02]],\n",
      "\n",
      "         [[-2.7370e-01]],\n",
      "\n",
      "         [[ 4.2743e-01]],\n",
      "\n",
      "         [[-4.0976e-02]],\n",
      "\n",
      "         [[ 9.8494e-02]],\n",
      "\n",
      "         [[ 5.6469e-02]],\n",
      "\n",
      "         [[ 8.0791e-01]],\n",
      "\n",
      "         [[-3.5450e-01]],\n",
      "\n",
      "         [[ 4.9316e-01]],\n",
      "\n",
      "         [[-2.1741e-01]],\n",
      "\n",
      "         [[-1.6688e-01]],\n",
      "\n",
      "         [[ 9.5140e-02]],\n",
      "\n",
      "         [[-1.7713e-01]],\n",
      "\n",
      "         [[ 4.8980e-02]],\n",
      "\n",
      "         [[-8.0996e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2839e-02]],\n",
      "\n",
      "         [[ 2.1970e-01]],\n",
      "\n",
      "         [[ 8.9612e-01]],\n",
      "\n",
      "         [[ 6.5495e-02]],\n",
      "\n",
      "         [[ 2.6802e-01]],\n",
      "\n",
      "         [[-3.4099e-01]],\n",
      "\n",
      "         [[ 2.9339e-02]],\n",
      "\n",
      "         [[ 1.8960e-01]],\n",
      "\n",
      "         [[ 9.5358e-02]],\n",
      "\n",
      "         [[-7.8099e-01]],\n",
      "\n",
      "         [[-9.6935e-03]],\n",
      "\n",
      "         [[-5.3800e-01]],\n",
      "\n",
      "         [[-1.0737e+00]],\n",
      "\n",
      "         [[ 7.1183e-01]],\n",
      "\n",
      "         [[-2.5414e-01]],\n",
      "\n",
      "         [[-1.1146e-01]],\n",
      "\n",
      "         [[ 9.4455e-01]],\n",
      "\n",
      "         [[ 1.3088e+00]],\n",
      "\n",
      "         [[-5.1937e-01]],\n",
      "\n",
      "         [[ 3.2736e-02]],\n",
      "\n",
      "         [[-1.7587e-01]],\n",
      "\n",
      "         [[ 9.3011e-02]],\n",
      "\n",
      "         [[ 5.7240e-02]],\n",
      "\n",
      "         [[-6.1368e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6854e-01]],\n",
      "\n",
      "         [[ 5.0600e-02]],\n",
      "\n",
      "         [[-2.7112e-01]],\n",
      "\n",
      "         [[ 6.9600e-01]],\n",
      "\n",
      "         [[-2.9866e-01]],\n",
      "\n",
      "         [[-2.1825e-01]],\n",
      "\n",
      "         [[ 1.1097e-01]],\n",
      "\n",
      "         [[-1.3553e-01]],\n",
      "\n",
      "         [[ 1.0816e+00]],\n",
      "\n",
      "         [[-7.9457e-01]],\n",
      "\n",
      "         [[ 1.1578e-01]],\n",
      "\n",
      "         [[-5.9842e-02]],\n",
      "\n",
      "         [[-6.4578e-01]],\n",
      "\n",
      "         [[-3.5092e-01]],\n",
      "\n",
      "         [[ 2.6868e-01]],\n",
      "\n",
      "         [[-1.8589e-01]],\n",
      "\n",
      "         [[ 9.6127e-01]],\n",
      "\n",
      "         [[ 7.9915e-01]],\n",
      "\n",
      "         [[ 1.3739e+00]],\n",
      "\n",
      "         [[-1.1020e-01]],\n",
      "\n",
      "         [[ 2.5810e-01]],\n",
      "\n",
      "         [[-5.4089e-01]],\n",
      "\n",
      "         [[ 6.7570e-02]],\n",
      "\n",
      "         [[ 1.5659e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3143e-01]],\n",
      "\n",
      "         [[-1.4731e-01]],\n",
      "\n",
      "         [[ 9.5406e-02]],\n",
      "\n",
      "         [[-2.9181e-01]],\n",
      "\n",
      "         [[-5.7470e-01]],\n",
      "\n",
      "         [[-3.3323e-01]],\n",
      "\n",
      "         [[ 5.8006e-01]],\n",
      "\n",
      "         [[-3.5734e-01]],\n",
      "\n",
      "         [[-6.4349e-01]],\n",
      "\n",
      "         [[ 5.0307e-01]],\n",
      "\n",
      "         [[ 1.8039e-01]],\n",
      "\n",
      "         [[-3.0058e-01]],\n",
      "\n",
      "         [[ 3.6812e-01]],\n",
      "\n",
      "         [[-1.5139e-01]],\n",
      "\n",
      "         [[-1.1402e-01]],\n",
      "\n",
      "         [[ 6.6019e-01]],\n",
      "\n",
      "         [[ 1.7430e-01]],\n",
      "\n",
      "         [[ 7.0217e-01]],\n",
      "\n",
      "         [[-1.5729e-01]],\n",
      "\n",
      "         [[-5.7529e-01]],\n",
      "\n",
      "         [[-5.3474e-01]],\n",
      "\n",
      "         [[ 1.5690e-01]],\n",
      "\n",
      "         [[-2.6241e-01]],\n",
      "\n",
      "         [[ 1.1084e+00]]],\n",
      "\n",
      "\n",
      "        [[[-3.1908e-01]],\n",
      "\n",
      "         [[-1.6651e-01]],\n",
      "\n",
      "         [[ 1.8011e-01]],\n",
      "\n",
      "         [[ 2.7184e-01]],\n",
      "\n",
      "         [[ 1.2137e-01]],\n",
      "\n",
      "         [[ 5.1597e-01]],\n",
      "\n",
      "         [[-1.7795e-01]],\n",
      "\n",
      "         [[ 6.8639e-01]],\n",
      "\n",
      "         [[-1.9505e-01]],\n",
      "\n",
      "         [[ 2.3943e-01]],\n",
      "\n",
      "         [[ 1.1411e-01]],\n",
      "\n",
      "         [[ 1.1181e+00]],\n",
      "\n",
      "         [[ 1.0217e+00]],\n",
      "\n",
      "         [[ 4.3726e-01]],\n",
      "\n",
      "         [[-2.7854e-01]],\n",
      "\n",
      "         [[-2.0475e-01]],\n",
      "\n",
      "         [[-1.1785e-01]],\n",
      "\n",
      "         [[-7.7223e-02]],\n",
      "\n",
      "         [[-5.9407e-02]],\n",
      "\n",
      "         [[-7.7905e-01]],\n",
      "\n",
      "         [[-1.7639e-01]],\n",
      "\n",
      "         [[ 1.4034e-02]],\n",
      "\n",
      "         [[ 1.6037e-01]],\n",
      "\n",
      "         [[ 9.2072e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3360e-01]],\n",
      "\n",
      "         [[-9.5348e-02]],\n",
      "\n",
      "         [[ 3.5441e-01]],\n",
      "\n",
      "         [[ 8.6549e-02]],\n",
      "\n",
      "         [[-3.5510e-02]],\n",
      "\n",
      "         [[ 3.9006e-01]],\n",
      "\n",
      "         [[-2.4031e-01]],\n",
      "\n",
      "         [[-1.9929e-01]],\n",
      "\n",
      "         [[-5.7435e-01]],\n",
      "\n",
      "         [[ 4.0875e-01]],\n",
      "\n",
      "         [[ 1.2381e-01]],\n",
      "\n",
      "         [[-4.1682e-01]],\n",
      "\n",
      "         [[ 6.7353e-01]],\n",
      "\n",
      "         [[ 4.2788e-01]],\n",
      "\n",
      "         [[ 1.9691e-01]],\n",
      "\n",
      "         [[-2.6443e-01]],\n",
      "\n",
      "         [[-3.1943e-01]],\n",
      "\n",
      "         [[-1.0006e+00]],\n",
      "\n",
      "         [[ 2.7090e-01]],\n",
      "\n",
      "         [[-1.6755e+00]],\n",
      "\n",
      "         [[-1.1226e-01]],\n",
      "\n",
      "         [[-2.1319e-01]],\n",
      "\n",
      "         [[ 1.6533e-01]],\n",
      "\n",
      "         [[ 2.1551e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0986e-01]],\n",
      "\n",
      "         [[-3.9005e-01]],\n",
      "\n",
      "         [[ 4.4336e-01]],\n",
      "\n",
      "         [[ 1.7969e-01]],\n",
      "\n",
      "         [[-1.1299e-01]],\n",
      "\n",
      "         [[-1.4311e-01]],\n",
      "\n",
      "         [[ 3.1324e-01]],\n",
      "\n",
      "         [[ 5.4623e-01]],\n",
      "\n",
      "         [[ 4.3375e-01]],\n",
      "\n",
      "         [[ 2.6763e-01]],\n",
      "\n",
      "         [[-9.7654e-01]],\n",
      "\n",
      "         [[-2.5924e-01]],\n",
      "\n",
      "         [[ 2.0863e-01]],\n",
      "\n",
      "         [[ 1.9183e-01]],\n",
      "\n",
      "         [[-3.8578e-01]],\n",
      "\n",
      "         [[ 8.2634e-01]],\n",
      "\n",
      "         [[ 4.4812e-01]],\n",
      "\n",
      "         [[-1.6846e-01]],\n",
      "\n",
      "         [[ 3.4130e-02]],\n",
      "\n",
      "         [[ 2.8261e-01]],\n",
      "\n",
      "         [[-8.0606e-02]],\n",
      "\n",
      "         [[ 6.7157e-02]],\n",
      "\n",
      "         [[-6.5041e-01]],\n",
      "\n",
      "         [[-2.5716e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1778e-01]],\n",
      "\n",
      "         [[-3.2308e-01]],\n",
      "\n",
      "         [[ 1.2017e-01]],\n",
      "\n",
      "         [[-1.9336e-01]],\n",
      "\n",
      "         [[-5.8364e-03]],\n",
      "\n",
      "         [[ 9.7282e-01]],\n",
      "\n",
      "         [[ 4.0517e-01]],\n",
      "\n",
      "         [[ 1.6956e-01]],\n",
      "\n",
      "         [[-2.8883e-01]],\n",
      "\n",
      "         [[ 4.2317e-01]],\n",
      "\n",
      "         [[-2.3865e-01]],\n",
      "\n",
      "         [[-5.5915e-01]],\n",
      "\n",
      "         [[ 2.3911e-01]],\n",
      "\n",
      "         [[ 4.4206e-01]],\n",
      "\n",
      "         [[-5.8990e-01]],\n",
      "\n",
      "         [[-2.5235e-01]],\n",
      "\n",
      "         [[ 2.2778e-01]],\n",
      "\n",
      "         [[-5.2327e-01]],\n",
      "\n",
      "         [[ 3.9530e-01]],\n",
      "\n",
      "         [[ 2.6106e-01]],\n",
      "\n",
      "         [[-1.4148e-01]],\n",
      "\n",
      "         [[ 1.1286e-01]],\n",
      "\n",
      "         [[ 8.8038e-01]],\n",
      "\n",
      "         [[ 2.0901e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3764e-01]],\n",
      "\n",
      "         [[ 4.4382e-01]],\n",
      "\n",
      "         [[ 1.0467e-01]],\n",
      "\n",
      "         [[ 6.1352e-01]],\n",
      "\n",
      "         [[-3.5656e-01]],\n",
      "\n",
      "         [[ 4.3033e-01]],\n",
      "\n",
      "         [[ 8.2140e-01]],\n",
      "\n",
      "         [[-2.7572e-01]],\n",
      "\n",
      "         [[-3.9982e-01]],\n",
      "\n",
      "         [[-4.4584e-01]],\n",
      "\n",
      "         [[-2.0247e-01]],\n",
      "\n",
      "         [[-1.6917e-01]],\n",
      "\n",
      "         [[ 1.2375e-01]],\n",
      "\n",
      "         [[-2.1887e-01]],\n",
      "\n",
      "         [[ 7.1987e-01]],\n",
      "\n",
      "         [[ 7.2667e-01]],\n",
      "\n",
      "         [[-4.2505e-01]],\n",
      "\n",
      "         [[ 2.3785e-01]],\n",
      "\n",
      "         [[ 1.1274e-01]],\n",
      "\n",
      "         [[-1.1464e-01]],\n",
      "\n",
      "         [[-8.4021e-01]],\n",
      "\n",
      "         [[-2.7437e-02]],\n",
      "\n",
      "         [[ 2.7607e-02]],\n",
      "\n",
      "         [[ 2.0833e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0832e-01]],\n",
      "\n",
      "         [[-5.0809e-01]],\n",
      "\n",
      "         [[ 1.1945e-03]],\n",
      "\n",
      "         [[-2.8788e-01]],\n",
      "\n",
      "         [[ 5.1440e-02]],\n",
      "\n",
      "         [[-3.3603e-01]],\n",
      "\n",
      "         [[-1.7435e-01]],\n",
      "\n",
      "         [[ 9.1406e-02]],\n",
      "\n",
      "         [[ 6.4683e-01]],\n",
      "\n",
      "         [[-9.3339e-02]],\n",
      "\n",
      "         [[-2.7401e-02]],\n",
      "\n",
      "         [[-2.8469e-02]],\n",
      "\n",
      "         [[-5.1176e-01]],\n",
      "\n",
      "         [[-2.2951e-01]],\n",
      "\n",
      "         [[-2.4704e-01]],\n",
      "\n",
      "         [[ 2.4149e-01]],\n",
      "\n",
      "         [[ 5.5738e-01]],\n",
      "\n",
      "         [[ 9.4587e-01]],\n",
      "\n",
      "         [[-2.0284e-01]],\n",
      "\n",
      "         [[-1.5964e+00]],\n",
      "\n",
      "         [[ 3.9020e-01]],\n",
      "\n",
      "         [[ 1.3851e-01]],\n",
      "\n",
      "         [[ 2.7608e-01]],\n",
      "\n",
      "         [[-3.6231e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5092e-01]],\n",
      "\n",
      "         [[-2.8363e-01]],\n",
      "\n",
      "         [[ 5.0840e-01]],\n",
      "\n",
      "         [[ 3.5853e-01]],\n",
      "\n",
      "         [[ 2.2807e-02]],\n",
      "\n",
      "         [[-1.8291e-02]],\n",
      "\n",
      "         [[ 6.0618e-01]],\n",
      "\n",
      "         [[ 1.0245e-01]],\n",
      "\n",
      "         [[-1.1452e+00]],\n",
      "\n",
      "         [[ 8.2601e-01]],\n",
      "\n",
      "         [[ 3.2337e-01]],\n",
      "\n",
      "         [[-1.9417e-01]],\n",
      "\n",
      "         [[ 7.8323e-01]],\n",
      "\n",
      "         [[ 5.6351e-01]],\n",
      "\n",
      "         [[ 2.5017e-01]],\n",
      "\n",
      "         [[-1.6946e-02]],\n",
      "\n",
      "         [[-7.5095e-01]],\n",
      "\n",
      "         [[-7.2871e-01]],\n",
      "\n",
      "         [[ 9.9637e-01]],\n",
      "\n",
      "         [[ 2.6770e-01]],\n",
      "\n",
      "         [[-1.1722e-01]],\n",
      "\n",
      "         [[-4.3323e-01]],\n",
      "\n",
      "         [[ 1.5528e-01]],\n",
      "\n",
      "         [[-8.8856e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1739e-01]],\n",
      "\n",
      "         [[-3.9564e-02]],\n",
      "\n",
      "         [[-8.7658e-02]],\n",
      "\n",
      "         [[ 5.6763e-01]],\n",
      "\n",
      "         [[-5.1055e-01]],\n",
      "\n",
      "         [[ 4.9820e-01]],\n",
      "\n",
      "         [[ 1.0960e+00]],\n",
      "\n",
      "         [[ 5.1790e-02]],\n",
      "\n",
      "         [[ 1.6784e-02]],\n",
      "\n",
      "         [[-5.9927e-02]],\n",
      "\n",
      "         [[ 8.9117e-02]],\n",
      "\n",
      "         [[ 4.1239e-01]],\n",
      "\n",
      "         [[-2.1275e-01]],\n",
      "\n",
      "         [[-5.9562e-01]],\n",
      "\n",
      "         [[ 3.6189e-01]],\n",
      "\n",
      "         [[-8.8369e-01]],\n",
      "\n",
      "         [[-1.3309e-02]],\n",
      "\n",
      "         [[ 1.8042e-01]],\n",
      "\n",
      "         [[-1.4254e+00]],\n",
      "\n",
      "         [[-4.5988e-01]],\n",
      "\n",
      "         [[ 6.0829e-01]],\n",
      "\n",
      "         [[-2.0966e-01]],\n",
      "\n",
      "         [[-3.7533e-01]],\n",
      "\n",
      "         [[-2.5551e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.4475e-02]],\n",
      "\n",
      "         [[-2.4394e-01]],\n",
      "\n",
      "         [[ 9.4072e-02]],\n",
      "\n",
      "         [[-7.8024e-03]],\n",
      "\n",
      "         [[-1.2015e+00]],\n",
      "\n",
      "         [[ 4.3213e-01]],\n",
      "\n",
      "         [[ 2.8840e-01]],\n",
      "\n",
      "         [[ 3.3621e-01]],\n",
      "\n",
      "         [[-3.4926e-02]],\n",
      "\n",
      "         [[-3.1134e-01]],\n",
      "\n",
      "         [[ 1.0333e+00]],\n",
      "\n",
      "         [[-3.1500e-01]],\n",
      "\n",
      "         [[-1.0385e-01]],\n",
      "\n",
      "         [[ 6.9575e-04]],\n",
      "\n",
      "         [[ 1.2618e-01]],\n",
      "\n",
      "         [[ 1.5009e-01]],\n",
      "\n",
      "         [[ 1.8183e-01]],\n",
      "\n",
      "         [[-3.0560e-01]],\n",
      "\n",
      "         [[ 2.3474e-01]],\n",
      "\n",
      "         [[ 7.6501e-02]],\n",
      "\n",
      "         [[ 1.2216e+00]],\n",
      "\n",
      "         [[ 2.5053e-01]],\n",
      "\n",
      "         [[ 1.6824e-01]],\n",
      "\n",
      "         [[-1.4958e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.8468e-02]],\n",
      "\n",
      "         [[-2.1172e-01]],\n",
      "\n",
      "         [[ 3.8285e-01]],\n",
      "\n",
      "         [[-3.4958e-01]],\n",
      "\n",
      "         [[ 2.9214e-02]],\n",
      "\n",
      "         [[ 7.2407e-01]],\n",
      "\n",
      "         [[-2.0049e-01]],\n",
      "\n",
      "         [[-4.7052e-01]],\n",
      "\n",
      "         [[-2.2387e-01]],\n",
      "\n",
      "         [[ 1.0553e+00]],\n",
      "\n",
      "         [[-7.2447e-01]],\n",
      "\n",
      "         [[-1.4582e-01]],\n",
      "\n",
      "         [[ 6.5198e-02]],\n",
      "\n",
      "         [[-5.1637e-01]],\n",
      "\n",
      "         [[ 1.8003e-01]],\n",
      "\n",
      "         [[ 1.1571e-01]],\n",
      "\n",
      "         [[ 2.5406e-01]],\n",
      "\n",
      "         [[ 9.2640e-02]],\n",
      "\n",
      "         [[ 4.5888e-01]],\n",
      "\n",
      "         [[-4.5963e-01]],\n",
      "\n",
      "         [[-1.1992e-01]],\n",
      "\n",
      "         [[ 6.0236e-01]],\n",
      "\n",
      "         [[-2.2800e-02]],\n",
      "\n",
      "         [[-1.1380e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7219e-01]],\n",
      "\n",
      "         [[-2.0080e-01]],\n",
      "\n",
      "         [[ 9.4526e-02]],\n",
      "\n",
      "         [[ 5.2174e-01]],\n",
      "\n",
      "         [[-1.8044e-01]],\n",
      "\n",
      "         [[-2.2776e-03]],\n",
      "\n",
      "         [[-3.3635e-01]],\n",
      "\n",
      "         [[-2.6531e-01]],\n",
      "\n",
      "         [[-3.3669e-01]],\n",
      "\n",
      "         [[ 2.0802e+00]],\n",
      "\n",
      "         [[ 4.9255e-01]],\n",
      "\n",
      "         [[ 2.1130e-02]],\n",
      "\n",
      "         [[ 7.1456e-02]],\n",
      "\n",
      "         [[-2.6464e-01]],\n",
      "\n",
      "         [[ 4.7811e-01]],\n",
      "\n",
      "         [[-1.2971e-01]],\n",
      "\n",
      "         [[-1.5874e-01]],\n",
      "\n",
      "         [[-1.0412e-01]],\n",
      "\n",
      "         [[-1.9814e-01]],\n",
      "\n",
      "         [[ 4.2808e-03]],\n",
      "\n",
      "         [[ 1.1699e-01]],\n",
      "\n",
      "         [[-8.3767e-01]],\n",
      "\n",
      "         [[-3.6270e-02]],\n",
      "\n",
      "         [[-1.6846e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0211e+00]],\n",
      "\n",
      "         [[ 6.0223e-01]],\n",
      "\n",
      "         [[ 2.3275e-01]],\n",
      "\n",
      "         [[-1.9264e-02]],\n",
      "\n",
      "         [[-4.9985e-03]],\n",
      "\n",
      "         [[ 1.0792e-01]],\n",
      "\n",
      "         [[ 7.2027e-02]],\n",
      "\n",
      "         [[ 2.2179e-01]],\n",
      "\n",
      "         [[ 4.0807e-01]],\n",
      "\n",
      "         [[-7.4209e-01]],\n",
      "\n",
      "         [[-4.0386e-01]],\n",
      "\n",
      "         [[ 1.3543e-01]],\n",
      "\n",
      "         [[ 8.5630e-02]],\n",
      "\n",
      "         [[-1.9454e-01]],\n",
      "\n",
      "         [[-1.1489e-01]],\n",
      "\n",
      "         [[-1.8866e-01]],\n",
      "\n",
      "         [[ 3.5742e-01]],\n",
      "\n",
      "         [[ 1.6331e-02]],\n",
      "\n",
      "         [[-4.0835e-01]],\n",
      "\n",
      "         [[-5.2395e-02]],\n",
      "\n",
      "         [[ 5.5152e-02]],\n",
      "\n",
      "         [[ 7.3379e-01]],\n",
      "\n",
      "         [[ 8.7116e-01]],\n",
      "\n",
      "         [[-1.3352e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8398e-01]],\n",
      "\n",
      "         [[ 1.7267e-01]],\n",
      "\n",
      "         [[ 5.4799e-01]],\n",
      "\n",
      "         [[ 1.2311e-01]],\n",
      "\n",
      "         [[ 1.8708e-02]],\n",
      "\n",
      "         [[ 5.5200e-02]],\n",
      "\n",
      "         [[ 7.0148e-01]],\n",
      "\n",
      "         [[ 3.2532e-01]],\n",
      "\n",
      "         [[ 8.2427e-01]],\n",
      "\n",
      "         [[ 3.0756e-01]],\n",
      "\n",
      "         [[-8.8709e-01]],\n",
      "\n",
      "         [[-3.0567e-01]],\n",
      "\n",
      "         [[-1.2808e-01]],\n",
      "\n",
      "         [[ 3.6792e-01]],\n",
      "\n",
      "         [[ 1.6248e-01]],\n",
      "\n",
      "         [[ 3.0521e-02]],\n",
      "\n",
      "         [[ 4.8197e-01]],\n",
      "\n",
      "         [[-7.5128e-01]],\n",
      "\n",
      "         [[-2.0346e-01]],\n",
      "\n",
      "         [[-4.3860e-01]],\n",
      "\n",
      "         [[ 4.3835e-01]],\n",
      "\n",
      "         [[ 1.3250e-01]],\n",
      "\n",
      "         [[ 4.5715e-01]],\n",
      "\n",
      "         [[ 3.2860e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.8665, 2.8040, 3.9700, 4.2014, 1.0570, 1.7915, 3.4372, 2.9713, 7.0094,\n",
      "        7.7747, 3.8287, 1.3601, 4.2968, 1.6515, 1.7832, 2.1692, 3.9705, 8.0075,\n",
      "        2.9925, 3.1568, 2.6607, 2.6710, 0.9944, 3.2741], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 7.3510e-01, -4.3306e-01,  2.7502e+00,  1.5019e-01,  1.6342e+00,\n",
      "        -9.3301e-01, -2.6088e-01, -4.7833e-01,  1.6759e+00,  1.2812e+00,\n",
      "        -9.1534e-02,  4.6735e-01,  9.9067e-01,  4.4345e+00, -1.7003e+00,\n",
      "         3.1621e-02, -1.7853e+00, -1.0483e+00, -8.9572e-01,  1.2665e-01,\n",
      "         2.3833e-01,  1.6113e-01, -2.3037e-03, -2.7859e+00], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 1.4385]],\n",
      "\n",
      "         [[ 0.1795]],\n",
      "\n",
      "         [[-0.0328]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1241]],\n",
      "\n",
      "         [[ 1.1129]],\n",
      "\n",
      "         [[ 0.2562]]],\n",
      "\n",
      "\n",
      "        [[[-0.0613]],\n",
      "\n",
      "         [[-0.4817]],\n",
      "\n",
      "         [[-0.0919]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3063]],\n",
      "\n",
      "         [[-0.1397]],\n",
      "\n",
      "         [[ 0.2360]]],\n",
      "\n",
      "\n",
      "        [[[-0.6701]],\n",
      "\n",
      "         [[-0.5579]],\n",
      "\n",
      "         [[-0.1142]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1752]],\n",
      "\n",
      "         [[-0.9515]],\n",
      "\n",
      "         [[-0.2873]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2536]],\n",
      "\n",
      "         [[ 0.0416]],\n",
      "\n",
      "         [[-0.0965]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1118]],\n",
      "\n",
      "         [[-0.0105]],\n",
      "\n",
      "         [[-0.3466]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1415]],\n",
      "\n",
      "         [[-0.6233]],\n",
      "\n",
      "         [[ 0.1542]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9866]],\n",
      "\n",
      "         [[-0.3757]],\n",
      "\n",
      "         [[ 0.4044]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5480]],\n",
      "\n",
      "         [[-0.4235]],\n",
      "\n",
      "         [[-0.3423]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0685]],\n",
      "\n",
      "         [[ 0.3624]],\n",
      "\n",
      "         [[ 0.1630]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 7.3554e-01,  1.6706e+00,  2.8660e+00,  5.1161e-01,  1.4892e+00,\n",
      "         6.2277e-01, -1.3287e-02,  1.9376e+00,  1.4277e-01,  1.5406e-01,\n",
      "         1.0660e+00,  7.4954e-01,  1.6104e+00,  8.5310e-01,  5.9559e-01,\n",
      "         1.6648e+00, -1.7004e+00,  1.0078e-01,  8.9578e-01,  5.7548e-01,\n",
      "         1.9373e+00, -8.3063e-01,  1.6235e+00,  8.5849e-02,  1.1171e+00,\n",
      "         2.8407e+00,  1.0777e+00,  4.6047e-01,  2.5967e+00,  4.3008e+00,\n",
      "         2.4111e+00,  8.7631e-01,  2.8361e+00,  7.7653e-01,  1.1676e+00,\n",
      "         1.2862e+00,  7.5227e-01,  5.4800e-01,  9.9086e-01,  1.1927e+00,\n",
      "         5.3324e+00,  3.1689e+00,  2.8309e+00,  3.5001e+00,  5.4212e-01,\n",
      "         1.3102e+00,  3.4477e+00,  6.5402e-01,  5.8225e-01,  1.5334e+00,\n",
      "         9.6136e-01,  1.5121e+00,  5.7031e+00,  9.5408e-01,  2.0742e+00,\n",
      "         5.9604e-01,  8.4308e-01,  8.9212e-01,  4.5638e+00,  1.1856e+00,\n",
      "         3.7325e+00,  1.5555e+00,  5.5928e-01,  1.5658e+00,  4.3249e+00,\n",
      "         2.0418e+00,  1.9271e-03,  4.0251e-01,  6.1154e-01,  3.1983e-01,\n",
      "         2.3220e+00,  1.4007e+00,  5.4891e-01,  9.2028e-01,  7.9318e-02,\n",
      "         1.2067e+00,  1.5833e+00,  2.8001e-01,  1.4252e+00,  7.9758e-01,\n",
      "         7.9095e-01,  2.1882e+00,  7.7789e-01,  3.2476e-01,  9.4209e-01,\n",
      "         3.9186e+00,  9.2105e-01,  4.0972e-01,  3.5545e+00,  1.1291e+00,\n",
      "         1.4758e-01,  1.0585e+00,  3.8049e+00,  8.1764e-01,  6.3484e-01,\n",
      "         1.4023e+00,  6.2756e-01,  2.7607e+00,  1.7396e+00,  1.1266e+00,\n",
      "         2.3145e+00,  5.9253e-01,  5.6278e+00,  1.0601e+00,  4.9190e-02,\n",
      "         4.2828e+00,  1.3043e+00,  1.8181e+00,  7.5473e-01,  1.0998e+00,\n",
      "         4.8417e-01,  1.0112e+00,  4.4107e-01,  1.9766e+00,  5.5381e+00,\n",
      "         2.3554e+00,  4.4174e-02,  1.7274e+00,  1.6166e+00,  1.7631e+00,\n",
      "         2.4210e+00,  3.8805e+00,  1.9443e+00,  1.9289e+00,  3.5164e+00,\n",
      "         2.4844e+00,  1.7641e+00,  2.2952e-01,  4.6425e+00,  5.9809e-01,\n",
      "         6.6962e-01,  1.3481e+00,  1.5290e+00,  5.1547e+00,  9.9247e-01,\n",
      "         1.4054e+00,  3.6124e+00,  2.5622e+00,  2.5663e+00,  1.0354e+00,\n",
      "         9.0677e-01,  6.5416e-01,  1.0554e+00,  4.8816e+00], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.8126e+00,  3.6009e-01,  1.9045e+00,  1.7345e+00, -1.9080e+00,\n",
      "         2.9740e+00,  1.1126e-01,  2.7095e+00,  3.5302e+00, -5.5408e-01,\n",
      "         2.2819e+00,  2.2378e+00,  2.3806e+00,  1.1340e+00,  1.6619e-01,\n",
      "         2.1952e+00,  2.6718e+00,  2.9548e+00,  2.4842e+00,  2.5256e+00,\n",
      "         5.4061e-03,  2.2593e+00,  2.3011e+00, -5.0132e-01,  2.9115e+00,\n",
      "        -3.5184e+00,  1.1353e+00,  1.8519e+00,  2.2057e+00,  1.3377e+00,\n",
      "        -2.6655e+00,  2.4186e+00, -2.0041e+00,  2.6737e+00,  2.6819e+00,\n",
      "         2.1318e+00,  1.7302e+00,  2.0012e+00,  1.5404e+00,  3.0368e+00,\n",
      "        -1.1251e+00, -7.9752e-01,  3.0915e+00, -2.9363e+00,  1.9996e+00,\n",
      "         2.0409e+00,  2.6125e+00,  3.0790e+00,  1.0002e+00,  2.0428e+00,\n",
      "        -1.5357e+00, -1.9925e+00,  2.6361e+00, -1.2871e+00,  2.3641e+00,\n",
      "         1.5146e+00, -1.2229e+00,  2.0217e+00, -5.0650e+00,  1.7263e+00,\n",
      "         1.3233e+00,  2.3766e+00,  1.1787e+00, -2.7583e+00, -1.0906e+01,\n",
      "         1.8721e+00,  7.3895e-02,  2.7143e+00,  1.3984e+00,  3.2661e-02,\n",
      "        -2.5568e-02,  2.4578e+00,  2.0865e+00,  4.3466e-01,  1.6992e+00,\n",
      "         6.8131e-01,  1.2937e+00,  1.4428e-01,  2.0795e+00, -1.3451e+00,\n",
      "         2.9639e+00,  1.6234e+00, -1.4338e+00,  2.0420e+00,  1.2926e-01,\n",
      "        -3.4729e+00,  2.9887e+00,  1.3884e+00, -1.1734e+00, -6.8034e-01,\n",
      "        -1.7305e-01,  2.0110e+00,  1.8439e+00,  2.4357e+00,  2.3523e+00,\n",
      "         1.5348e+00, -1.6936e+00, -4.5953e+00,  1.9608e+00,  7.5268e-01,\n",
      "         3.2133e+00,  2.5077e+00,  9.4984e-01,  2.6344e+00,  1.3935e-01,\n",
      "         3.6620e+00,  2.2085e+00,  1.6216e+00,  1.4330e+00,  1.7750e+00,\n",
      "         1.7275e+00, -1.4884e+00,  1.1315e+00,  2.7134e+00,  1.4525e+00,\n",
      "        -8.7879e-01, -4.0113e-01,  2.0300e+00,  2.4475e+00, -1.1827e+00,\n",
      "        -1.8300e+00,  2.3627e+00,  1.8433e+00,  1.5544e+00, -2.6469e+00,\n",
      "        -2.8369e+00, -1.9753e+00,  5.0765e-01,  3.0010e+00,  1.9995e+00,\n",
      "         2.9915e+00, -1.5212e+00,  9.7138e-01,  1.9596e+00,  5.1242e+00,\n",
      "         4.7808e+00, -2.4348e+00,  7.7184e-02, -8.6032e+00,  2.4670e+00,\n",
      "         2.3375e+00,  1.5800e+00,  2.7624e+00, -5.5236e+00], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.5730,  0.1473, -0.1638],\n",
      "          [ 0.0449, -1.1639, -0.1502],\n",
      "          [-0.2628, -0.5047,  0.1997]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3950,  0.2686,  0.1038],\n",
      "          [ 0.6350,  0.8144,  0.3850],\n",
      "          [ 0.1043,  0.3656,  0.0643]]],\n",
      "\n",
      "\n",
      "        [[[-0.1108, -0.2533, -0.4107],\n",
      "          [-0.4187, -0.6797, -0.6042],\n",
      "          [-0.0915, -0.0103, -0.1405]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.6556, -0.2521, -0.1101],\n",
      "          [-0.8209,  0.2795,  0.5873],\n",
      "          [ 0.1950,  0.0482, -0.4705]]],\n",
      "\n",
      "\n",
      "        [[[-0.2065, -0.3304,  0.0289],\n",
      "          [-0.7084, -0.8674, -0.2638],\n",
      "          [-0.0910, -0.3151, -0.0770]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3089,  0.3962,  0.2577],\n",
      "          [ 0.2937,  0.2456,  0.2891],\n",
      "          [ 0.3160,  0.4179,  0.3328]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.9744,  2.4147,  1.2307,  4.5657,  1.5709,  5.3962,  7.0134,  1.3271,\n",
      "         4.2044,  4.4214,  4.1477,  5.6585,  4.4549,  5.3743,  4.6774,  3.4870,\n",
      "         4.7182,  4.5217,  5.3736,  5.4719,  4.0076,  4.0161,  3.1816,  4.2359,\n",
      "         4.7069,  2.6900,  4.0401,  5.6495,  4.0385,  3.8900,  2.7128,  5.4746,\n",
      "         5.0234,  3.1305,  1.9974,  2.8859,  3.0772,  4.5899,  4.3834,  2.2064,\n",
      "         3.9498,  3.4549,  6.9119, 12.1412,  5.6675,  4.4103,  3.4368,  3.7032,\n",
      "         5.8800,  2.9857,  5.7038,  4.0352,  5.1930,  2.4454,  4.6571,  3.7909,\n",
      "         1.7286,  5.3970,  4.1622,  3.0752,  3.4026,  4.0002,  5.9401,  2.2594,\n",
      "         8.8929,  4.0934,  2.9824,  5.2050,  5.1478,  2.7411,  2.0347,  3.5869,\n",
      "         5.5822,  3.3696,  2.8060,  2.7514,  5.0118,  1.0866,  4.9694,  2.3850,\n",
      "         5.5030,  4.1003,  1.3576,  3.8885,  3.2132,  4.0157,  4.5386,  5.0235,\n",
      "         3.3048,  2.4177,  3.5910,  4.4449,  4.7905,  4.6500,  5.0475,  4.3032,\n",
      "         1.7953,  3.2269,  3.9797,  0.8435,  4.7458,  1.7199,  4.3488,  4.7391,\n",
      "         4.9024,  5.2060,  2.2090,  3.9199,  5.4150,  4.5958,  3.9720,  1.6166,\n",
      "         5.0838,  4.5423,  3.7508,  3.2735,  3.8447,  4.1510,  4.2059,  4.1692,\n",
      "         3.0589,  3.2300,  3.1785,  3.5636,  3.8292,  1.7424,  2.7680,  4.8068,\n",
      "         6.5352,  5.6353,  3.0282,  1.7170,  4.1596,  5.2641,  4.6655,  3.7883,\n",
      "         6.6524,  2.6847,  6.5858,  5.0850,  4.4249,  4.6444,  2.4978,  7.4855],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.7069,  0.8317,  2.2811, -0.6541,  1.8584, -0.8788, -3.4741,  1.3745,\n",
      "        -1.1061, -0.5666, -0.9252, -0.4082, -0.0418, -0.3921, -0.6630, -0.6872,\n",
      "        -0.7320, -1.5555, -0.6809, -0.2219,  0.9399, -1.4392, -1.0701, -0.7139,\n",
      "        -0.9338,  0.8413, -0.7495, -0.9734, -0.6706, -0.7205,  0.9224, -0.8276,\n",
      "         1.6008, -1.6310,  2.9761, -1.2836, -1.6999, -0.6757, -0.8749,  1.4728,\n",
      "         3.1009,  2.6893,  1.2665, -0.5342, -0.4360, -0.3956,  1.4186, -0.8230,\n",
      "        -0.6307, -2.6356, -0.8876,  0.0294,  0.3902,  1.9871, -0.9194, -1.4497,\n",
      "         1.7289, -0.4658, -3.0752, -1.7638,  1.2465, -1.0327, -0.4093,  1.7139,\n",
      "        -5.4468, -1.3290, -1.3425, -1.2852, -0.5427,  1.4090,  2.2589, -1.1020,\n",
      "        -0.3878,  0.9217, -1.4870,  1.2517, -0.3062,  2.8689, -0.6839,  2.4382,\n",
      "        -0.8280,  2.0682,  4.2656, -1.0664,  1.5797,  0.8695, -0.6264, -0.7521,\n",
      "         3.7726,  2.1090, -0.7182, -1.0993,  0.9550, -0.8249, -1.8203,  0.2828,\n",
      "         0.7971, -2.1155,  0.2993,  3.0452, -0.7399,  2.2842,  1.3765, -0.9114,\n",
      "        -0.4861, -0.6237, -0.4561,  0.6560, -0.5496, -0.5644, -0.9758,  1.7652,\n",
      "        -0.9858, -1.9050,  1.5691,  0.8367, -1.2330, -0.6594,  0.5041,  2.1218,\n",
      "        -0.9895,  0.8190,  0.4404, -1.6645, -0.8617,  0.1323,  0.5139, -1.2888,\n",
      "        -0.8276, -0.4206, -1.1762,  2.2060,  0.1614,  0.1650, -5.4870,  1.8481,\n",
      "         1.8187,  2.6784, -0.8944, -0.9223, -0.7406, -0.7111, -1.6195,  1.6164],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-4.7490e-01]],\n",
      "\n",
      "         [[ 1.7363e-01]],\n",
      "\n",
      "         [[ 3.2666e-01]],\n",
      "\n",
      "         [[ 5.6616e-02]],\n",
      "\n",
      "         [[ 5.2227e-01]],\n",
      "\n",
      "         [[ 1.6405e-01]],\n",
      "\n",
      "         [[-3.9013e-02]],\n",
      "\n",
      "         [[ 1.9022e-02]],\n",
      "\n",
      "         [[-7.7289e-02]],\n",
      "\n",
      "         [[ 2.5119e-02]],\n",
      "\n",
      "         [[ 3.8062e-02]],\n",
      "\n",
      "         [[-1.4160e-02]],\n",
      "\n",
      "         [[ 1.2148e-01]],\n",
      "\n",
      "         [[-4.7054e-02]],\n",
      "\n",
      "         [[-9.2897e-02]],\n",
      "\n",
      "         [[ 1.0171e-01]],\n",
      "\n",
      "         [[ 4.9597e-03]],\n",
      "\n",
      "         [[-2.7288e-02]],\n",
      "\n",
      "         [[-2.3566e-01]],\n",
      "\n",
      "         [[-2.9453e-02]],\n",
      "\n",
      "         [[-1.8101e-01]],\n",
      "\n",
      "         [[ 1.5295e-03]],\n",
      "\n",
      "         [[ 1.8996e-01]],\n",
      "\n",
      "         [[-5.2650e-02]],\n",
      "\n",
      "         [[-2.5116e-02]],\n",
      "\n",
      "         [[ 4.5723e-01]],\n",
      "\n",
      "         [[ 9.2340e-02]],\n",
      "\n",
      "         [[-5.1333e-02]],\n",
      "\n",
      "         [[-9.2979e-02]],\n",
      "\n",
      "         [[ 4.0301e-01]],\n",
      "\n",
      "         [[-5.4745e-01]],\n",
      "\n",
      "         [[ 3.6796e-02]],\n",
      "\n",
      "         [[ 5.2105e-01]],\n",
      "\n",
      "         [[ 9.7893e-02]],\n",
      "\n",
      "         [[ 2.1851e-03]],\n",
      "\n",
      "         [[-3.6662e-01]],\n",
      "\n",
      "         [[-6.5124e-02]],\n",
      "\n",
      "         [[ 1.6655e-01]],\n",
      "\n",
      "         [[ 3.7682e-02]],\n",
      "\n",
      "         [[-1.1796e-01]],\n",
      "\n",
      "         [[-4.3019e-02]],\n",
      "\n",
      "         [[-7.4535e-02]],\n",
      "\n",
      "         [[ 6.4685e-01]],\n",
      "\n",
      "         [[ 3.9732e-01]],\n",
      "\n",
      "         [[ 6.0090e-02]],\n",
      "\n",
      "         [[ 5.5141e-02]],\n",
      "\n",
      "         [[ 1.6294e-01]],\n",
      "\n",
      "         [[ 7.1005e-02]],\n",
      "\n",
      "         [[ 4.0000e-02]],\n",
      "\n",
      "         [[ 4.2774e-01]],\n",
      "\n",
      "         [[ 1.7668e-01]],\n",
      "\n",
      "         [[-2.7316e-01]],\n",
      "\n",
      "         [[ 2.7385e-01]],\n",
      "\n",
      "         [[ 3.3662e-01]],\n",
      "\n",
      "         [[-4.9516e-02]],\n",
      "\n",
      "         [[-2.7162e-01]],\n",
      "\n",
      "         [[-3.8717e-02]],\n",
      "\n",
      "         [[-1.7892e-01]],\n",
      "\n",
      "         [[ 8.5416e-02]],\n",
      "\n",
      "         [[-3.7873e-01]],\n",
      "\n",
      "         [[ 1.1304e-01]],\n",
      "\n",
      "         [[-1.5285e-01]],\n",
      "\n",
      "         [[ 1.9194e-02]],\n",
      "\n",
      "         [[ 1.6602e-01]],\n",
      "\n",
      "         [[ 1.6302e-02]],\n",
      "\n",
      "         [[-7.2609e-02]],\n",
      "\n",
      "         [[-1.2848e-01]],\n",
      "\n",
      "         [[-1.6008e-01]],\n",
      "\n",
      "         [[-1.4100e-01]],\n",
      "\n",
      "         [[ 2.8854e-01]],\n",
      "\n",
      "         [[ 1.9382e-02]],\n",
      "\n",
      "         [[-3.0918e-01]],\n",
      "\n",
      "         [[-3.6657e-02]],\n",
      "\n",
      "         [[ 8.5539e-01]],\n",
      "\n",
      "         [[-7.3385e-02]],\n",
      "\n",
      "         [[-2.1616e-01]],\n",
      "\n",
      "         [[-9.8783e-02]],\n",
      "\n",
      "         [[ 4.3605e-01]],\n",
      "\n",
      "         [[-8.1398e-02]],\n",
      "\n",
      "         [[ 7.8692e-02]],\n",
      "\n",
      "         [[ 2.3510e-02]],\n",
      "\n",
      "         [[ 1.7423e-01]],\n",
      "\n",
      "         [[ 3.5764e-01]],\n",
      "\n",
      "         [[-1.7257e-02]],\n",
      "\n",
      "         [[-5.9764e-03]],\n",
      "\n",
      "         [[-2.9349e-01]],\n",
      "\n",
      "         [[ 7.9726e-02]],\n",
      "\n",
      "         [[ 1.6935e-01]],\n",
      "\n",
      "         [[ 9.0350e-03]],\n",
      "\n",
      "         [[ 1.7884e-01]],\n",
      "\n",
      "         [[ 4.5988e-01]],\n",
      "\n",
      "         [[-1.0502e-01]],\n",
      "\n",
      "         [[ 1.5014e-01]],\n",
      "\n",
      "         [[ 1.0855e-01]],\n",
      "\n",
      "         [[-2.3719e-01]],\n",
      "\n",
      "         [[ 2.3628e-01]],\n",
      "\n",
      "         [[ 1.9503e-01]],\n",
      "\n",
      "         [[-3.7458e-01]],\n",
      "\n",
      "         [[ 7.8759e-02]],\n",
      "\n",
      "         [[ 2.7427e-01]],\n",
      "\n",
      "         [[-1.3329e-01]],\n",
      "\n",
      "         [[ 3.3757e-01]],\n",
      "\n",
      "         [[ 3.4103e-01]],\n",
      "\n",
      "         [[-1.3107e-01]],\n",
      "\n",
      "         [[-1.5938e-01]],\n",
      "\n",
      "         [[-6.5077e-02]],\n",
      "\n",
      "         [[-4.6842e-01]],\n",
      "\n",
      "         [[ 1.4953e-01]],\n",
      "\n",
      "         [[-1.2910e-01]],\n",
      "\n",
      "         [[ 8.9051e-03]],\n",
      "\n",
      "         [[-7.3450e-02]],\n",
      "\n",
      "         [[ 1.2029e-01]],\n",
      "\n",
      "         [[ 1.1034e-01]],\n",
      "\n",
      "         [[-3.2092e-02]],\n",
      "\n",
      "         [[ 2.7319e-01]],\n",
      "\n",
      "         [[-4.7988e-01]],\n",
      "\n",
      "         [[-2.7643e-01]],\n",
      "\n",
      "         [[-5.7299e-02]],\n",
      "\n",
      "         [[ 1.6514e-01]],\n",
      "\n",
      "         [[ 1.0318e-01]],\n",
      "\n",
      "         [[-5.2732e-02]],\n",
      "\n",
      "         [[ 1.6304e-01]],\n",
      "\n",
      "         [[-4.5423e-01]],\n",
      "\n",
      "         [[ 1.0905e-01]],\n",
      "\n",
      "         [[-6.6008e-01]],\n",
      "\n",
      "         [[-5.1399e-02]],\n",
      "\n",
      "         [[-1.4134e-01]],\n",
      "\n",
      "         [[-3.2275e-02]],\n",
      "\n",
      "         [[ 1.2304e-01]],\n",
      "\n",
      "         [[ 2.9711e-02]],\n",
      "\n",
      "         [[ 1.8423e-01]],\n",
      "\n",
      "         [[-1.1475e-01]],\n",
      "\n",
      "         [[-2.5571e-01]],\n",
      "\n",
      "         [[ 1.8655e-01]],\n",
      "\n",
      "         [[ 8.4141e-02]],\n",
      "\n",
      "         [[-3.0394e-02]],\n",
      "\n",
      "         [[ 8.4926e-01]],\n",
      "\n",
      "         [[ 6.7449e-01]],\n",
      "\n",
      "         [[-1.1264e-01]],\n",
      "\n",
      "         [[-5.8790e-02]],\n",
      "\n",
      "         [[ 1.9386e-01]],\n",
      "\n",
      "         [[ 2.5365e-01]],\n",
      "\n",
      "         [[-8.7275e-02]],\n",
      "\n",
      "         [[ 5.0916e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4329e-01]],\n",
      "\n",
      "         [[ 4.3512e-01]],\n",
      "\n",
      "         [[ 6.3180e-02]],\n",
      "\n",
      "         [[ 9.5796e-02]],\n",
      "\n",
      "         [[ 2.5739e-01]],\n",
      "\n",
      "         [[ 4.6676e-02]],\n",
      "\n",
      "         [[ 4.2944e-02]],\n",
      "\n",
      "         [[ 2.9105e-01]],\n",
      "\n",
      "         [[-1.8872e-01]],\n",
      "\n",
      "         [[ 2.4596e-02]],\n",
      "\n",
      "         [[ 8.6976e-02]],\n",
      "\n",
      "         [[ 5.9537e-02]],\n",
      "\n",
      "         [[-5.1432e-02]],\n",
      "\n",
      "         [[ 4.2333e-03]],\n",
      "\n",
      "         [[ 5.8297e-02]],\n",
      "\n",
      "         [[ 1.1495e-01]],\n",
      "\n",
      "         [[ 1.8050e-01]],\n",
      "\n",
      "         [[-7.1978e-02]],\n",
      "\n",
      "         [[ 3.9504e-02]],\n",
      "\n",
      "         [[ 1.0490e-02]],\n",
      "\n",
      "         [[-7.7166e-02]],\n",
      "\n",
      "         [[-3.2456e-02]],\n",
      "\n",
      "         [[-7.6679e-02]],\n",
      "\n",
      "         [[-1.3750e-01]],\n",
      "\n",
      "         [[-7.6108e-03]],\n",
      "\n",
      "         [[-1.4343e-01]],\n",
      "\n",
      "         [[-8.1046e-02]],\n",
      "\n",
      "         [[-6.4637e-03]],\n",
      "\n",
      "         [[-5.8848e-02]],\n",
      "\n",
      "         [[ 2.5479e-01]],\n",
      "\n",
      "         [[-1.8701e-01]],\n",
      "\n",
      "         [[ 3.3128e-02]],\n",
      "\n",
      "         [[ 4.4366e-01]],\n",
      "\n",
      "         [[ 2.7317e-02]],\n",
      "\n",
      "         [[ 4.7690e-01]],\n",
      "\n",
      "         [[ 2.4009e-01]],\n",
      "\n",
      "         [[-3.5062e-02]],\n",
      "\n",
      "         [[ 1.0938e-01]],\n",
      "\n",
      "         [[ 2.3322e-02]],\n",
      "\n",
      "         [[-7.3351e-01]],\n",
      "\n",
      "         [[-4.1074e-02]],\n",
      "\n",
      "         [[-9.6123e-02]],\n",
      "\n",
      "         [[-3.2835e-01]],\n",
      "\n",
      "         [[ 5.8278e-01]],\n",
      "\n",
      "         [[ 4.5574e-02]],\n",
      "\n",
      "         [[-2.2286e-02]],\n",
      "\n",
      "         [[-6.6649e-02]],\n",
      "\n",
      "         [[ 1.7990e-01]],\n",
      "\n",
      "         [[ 1.0952e-01]],\n",
      "\n",
      "         [[ 7.6862e-01]],\n",
      "\n",
      "         [[ 1.0599e-01]],\n",
      "\n",
      "         [[ 1.2450e-01]],\n",
      "\n",
      "         [[ 1.2315e-01]],\n",
      "\n",
      "         [[ 7.1369e-01]],\n",
      "\n",
      "         [[ 7.4207e-02]],\n",
      "\n",
      "         [[-1.4073e-02]],\n",
      "\n",
      "         [[ 1.4238e-02]],\n",
      "\n",
      "         [[ 5.5468e-02]],\n",
      "\n",
      "         [[ 4.2032e-02]],\n",
      "\n",
      "         [[ 2.7101e-01]],\n",
      "\n",
      "         [[-6.7385e-04]],\n",
      "\n",
      "         [[-4.0988e-01]],\n",
      "\n",
      "         [[ 2.6006e-02]],\n",
      "\n",
      "         [[-4.4252e-01]],\n",
      "\n",
      "         [[ 1.8471e-01]],\n",
      "\n",
      "         [[ 3.2411e-01]],\n",
      "\n",
      "         [[-2.2424e-02]],\n",
      "\n",
      "         [[ 2.3088e-01]],\n",
      "\n",
      "         [[ 1.1802e-02]],\n",
      "\n",
      "         [[ 6.0618e-02]],\n",
      "\n",
      "         [[ 7.5391e-03]],\n",
      "\n",
      "         [[-1.8730e-03]],\n",
      "\n",
      "         [[ 8.2060e-02]],\n",
      "\n",
      "         [[ 2.1288e-02]],\n",
      "\n",
      "         [[-7.7805e-02]],\n",
      "\n",
      "         [[ 1.8388e-01]],\n",
      "\n",
      "         [[ 1.1973e-01]],\n",
      "\n",
      "         [[-2.2317e-01]],\n",
      "\n",
      "         [[ 1.3135e-01]],\n",
      "\n",
      "         [[-4.0052e-02]],\n",
      "\n",
      "         [[ 4.6428e-02]],\n",
      "\n",
      "         [[-6.2748e-03]],\n",
      "\n",
      "         [[ 1.1284e-01]],\n",
      "\n",
      "         [[ 1.6570e-01]],\n",
      "\n",
      "         [[ 3.1523e-01]],\n",
      "\n",
      "         [[ 1.1290e+00]],\n",
      "\n",
      "         [[ 1.0419e-01]],\n",
      "\n",
      "         [[ 7.1819e-02]],\n",
      "\n",
      "         [[-1.2106e-01]],\n",
      "\n",
      "         [[-6.7587e-02]],\n",
      "\n",
      "         [[-1.5205e-01]],\n",
      "\n",
      "         [[ 3.0533e-03]],\n",
      "\n",
      "         [[ 1.5530e-01]],\n",
      "\n",
      "         [[ 7.9499e-02]],\n",
      "\n",
      "         [[ 2.3223e-01]],\n",
      "\n",
      "         [[-4.9796e-02]],\n",
      "\n",
      "         [[-1.2271e-01]],\n",
      "\n",
      "         [[-9.2110e-03]],\n",
      "\n",
      "         [[-7.7286e-02]],\n",
      "\n",
      "         [[ 1.6959e-01]],\n",
      "\n",
      "         [[ 2.2939e-02]],\n",
      "\n",
      "         [[ 3.2102e-01]],\n",
      "\n",
      "         [[ 1.5970e-01]],\n",
      "\n",
      "         [[-6.1702e-02]],\n",
      "\n",
      "         [[ 1.7373e-01]],\n",
      "\n",
      "         [[ 2.7903e-02]],\n",
      "\n",
      "         [[ 7.4412e-01]],\n",
      "\n",
      "         [[-1.0065e-02]],\n",
      "\n",
      "         [[ 4.1895e-02]],\n",
      "\n",
      "         [[ 4.4963e-02]],\n",
      "\n",
      "         [[ 1.5674e-01]],\n",
      "\n",
      "         [[ 9.0210e-02]],\n",
      "\n",
      "         [[ 5.8319e-02]],\n",
      "\n",
      "         [[ 1.3706e-01]],\n",
      "\n",
      "         [[-5.8827e-02]],\n",
      "\n",
      "         [[-6.7022e-02]],\n",
      "\n",
      "         [[-1.5364e-02]],\n",
      "\n",
      "         [[ 1.5145e-02]],\n",
      "\n",
      "         [[ 1.8270e-02]],\n",
      "\n",
      "         [[ 1.3110e-02]],\n",
      "\n",
      "         [[-1.0653e-01]],\n",
      "\n",
      "         [[-6.3625e-02]],\n",
      "\n",
      "         [[ 3.0758e-01]],\n",
      "\n",
      "         [[-3.0988e-01]],\n",
      "\n",
      "         [[-2.4524e-01]],\n",
      "\n",
      "         [[ 3.4481e-02]],\n",
      "\n",
      "         [[ 2.2418e-01]],\n",
      "\n",
      "         [[ 2.3202e-02]],\n",
      "\n",
      "         [[ 2.5163e-01]],\n",
      "\n",
      "         [[ 5.6998e-02]],\n",
      "\n",
      "         [[ 8.8960e-02]],\n",
      "\n",
      "         [[-7.9017e-02]],\n",
      "\n",
      "         [[-1.8788e-01]],\n",
      "\n",
      "         [[ 1.4159e-01]],\n",
      "\n",
      "         [[-1.5213e-02]],\n",
      "\n",
      "         [[-3.0153e-01]],\n",
      "\n",
      "         [[-5.0655e-01]],\n",
      "\n",
      "         [[ 4.9335e-02]],\n",
      "\n",
      "         [[-1.2845e-01]],\n",
      "\n",
      "         [[ 5.1421e-02]],\n",
      "\n",
      "         [[ 1.2288e-01]],\n",
      "\n",
      "         [[ 3.5922e-02]],\n",
      "\n",
      "         [[-7.8835e-02]],\n",
      "\n",
      "         [[ 3.7499e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.2282e-02]],\n",
      "\n",
      "         [[-3.0626e-01]],\n",
      "\n",
      "         [[-1.6953e-01]],\n",
      "\n",
      "         [[-1.0626e-01]],\n",
      "\n",
      "         [[-1.1684e-01]],\n",
      "\n",
      "         [[ 1.4342e-01]],\n",
      "\n",
      "         [[-8.2561e-02]],\n",
      "\n",
      "         [[-2.5165e-01]],\n",
      "\n",
      "         [[-2.7607e-02]],\n",
      "\n",
      "         [[ 1.3759e-01]],\n",
      "\n",
      "         [[-3.6390e-02]],\n",
      "\n",
      "         [[-1.7007e-01]],\n",
      "\n",
      "         [[-1.6073e-01]],\n",
      "\n",
      "         [[-9.9931e-02]],\n",
      "\n",
      "         [[-5.6585e-02]],\n",
      "\n",
      "         [[-2.9685e-01]],\n",
      "\n",
      "         [[-8.5617e-02]],\n",
      "\n",
      "         [[-5.3562e-02]],\n",
      "\n",
      "         [[ 5.8373e-02]],\n",
      "\n",
      "         [[-1.0916e-01]],\n",
      "\n",
      "         [[-9.1663e-02]],\n",
      "\n",
      "         [[ 2.0515e-02]],\n",
      "\n",
      "         [[ 1.5400e-01]],\n",
      "\n",
      "         [[ 1.0432e-01]],\n",
      "\n",
      "         [[ 6.5955e-02]],\n",
      "\n",
      "         [[-5.3161e-01]],\n",
      "\n",
      "         [[ 2.0211e-02]],\n",
      "\n",
      "         [[-9.3222e-02]],\n",
      "\n",
      "         [[-7.5940e-02]],\n",
      "\n",
      "         [[-7.1405e-01]],\n",
      "\n",
      "         [[-1.0246e-01]],\n",
      "\n",
      "         [[-1.3469e-01]],\n",
      "\n",
      "         [[-9.3245e-01]],\n",
      "\n",
      "         [[-1.5859e-01]],\n",
      "\n",
      "         [[-1.3710e-01]],\n",
      "\n",
      "         [[-1.0907e-01]],\n",
      "\n",
      "         [[ 9.0778e-02]],\n",
      "\n",
      "         [[-2.0727e-02]],\n",
      "\n",
      "         [[-2.0431e-01]],\n",
      "\n",
      "         [[-3.1091e-01]],\n",
      "\n",
      "         [[-1.1573e-01]],\n",
      "\n",
      "         [[-1.7986e-01]],\n",
      "\n",
      "         [[-1.3684e-01]],\n",
      "\n",
      "         [[-1.7298e+00]],\n",
      "\n",
      "         [[-1.8404e-01]],\n",
      "\n",
      "         [[-1.0238e-01]],\n",
      "\n",
      "         [[-1.6017e-01]],\n",
      "\n",
      "         [[-2.4819e-03]],\n",
      "\n",
      "         [[-1.4946e-01]],\n",
      "\n",
      "         [[ 1.4332e-01]],\n",
      "\n",
      "         [[-1.7316e-01]],\n",
      "\n",
      "         [[-3.8431e-01]],\n",
      "\n",
      "         [[-1.8137e-01]],\n",
      "\n",
      "         [[ 3.2822e-02]],\n",
      "\n",
      "         [[-4.5618e-02]],\n",
      "\n",
      "         [[ 1.5809e-01]],\n",
      "\n",
      "         [[-2.4566e-01]],\n",
      "\n",
      "         [[-8.4121e-02]],\n",
      "\n",
      "         [[-3.7295e-01]],\n",
      "\n",
      "         [[-8.0435e-02]],\n",
      "\n",
      "         [[-6.7310e-02]],\n",
      "\n",
      "         [[ 4.1524e-01]],\n",
      "\n",
      "         [[-1.0492e-01]],\n",
      "\n",
      "         [[-5.8021e-02]],\n",
      "\n",
      "         [[-4.6267e-01]],\n",
      "\n",
      "         [[-9.1682e-01]],\n",
      "\n",
      "         [[-1.0695e-01]],\n",
      "\n",
      "         [[-6.6443e-01]],\n",
      "\n",
      "         [[-8.3092e-02]],\n",
      "\n",
      "         [[-8.4217e-02]],\n",
      "\n",
      "         [[ 1.1891e-01]],\n",
      "\n",
      "         [[-2.2042e-01]],\n",
      "\n",
      "         [[-3.5149e-02]],\n",
      "\n",
      "         [[-2.3088e-01]],\n",
      "\n",
      "         [[ 7.9603e-02]],\n",
      "\n",
      "         [[ 1.0805e-02]],\n",
      "\n",
      "         [[-1.2075e-01]],\n",
      "\n",
      "         [[-1.3988e-01]],\n",
      "\n",
      "         [[-6.9733e-02]],\n",
      "\n",
      "         [[-4.5021e-01]],\n",
      "\n",
      "         [[-1.2219e-01]],\n",
      "\n",
      "         [[-1.9478e-01]],\n",
      "\n",
      "         [[-1.8614e-02]],\n",
      "\n",
      "         [[-1.0208e-01]],\n",
      "\n",
      "         [[-3.1210e-02]],\n",
      "\n",
      "         [[ 2.0762e-01]],\n",
      "\n",
      "         [[-7.6791e-02]],\n",
      "\n",
      "         [[ 4.5117e-02]],\n",
      "\n",
      "         [[-3.6988e-01]],\n",
      "\n",
      "         [[-1.3949e-01]],\n",
      "\n",
      "         [[-7.9021e-02]],\n",
      "\n",
      "         [[ 1.3603e-01]],\n",
      "\n",
      "         [[-1.5497e-01]],\n",
      "\n",
      "         [[-1.9570e-02]],\n",
      "\n",
      "         [[-5.4458e-01]],\n",
      "\n",
      "         [[-1.9479e-01]],\n",
      "\n",
      "         [[-1.5301e-01]],\n",
      "\n",
      "         [[ 7.4463e-02]],\n",
      "\n",
      "         [[-3.3283e-02]],\n",
      "\n",
      "         [[-3.7869e-03]],\n",
      "\n",
      "         [[-6.1877e-02]],\n",
      "\n",
      "         [[-3.2246e-01]],\n",
      "\n",
      "         [[-1.5598e-01]],\n",
      "\n",
      "         [[-5.1651e-02]],\n",
      "\n",
      "         [[-5.0267e-02]],\n",
      "\n",
      "         [[-6.5386e-01]],\n",
      "\n",
      "         [[-2.4263e-01]],\n",
      "\n",
      "         [[-1.7530e-01]],\n",
      "\n",
      "         [[ 3.2736e-02]],\n",
      "\n",
      "         [[-1.2817e-01]],\n",
      "\n",
      "         [[-1.0192e-01]],\n",
      "\n",
      "         [[-1.4193e-01]],\n",
      "\n",
      "         [[ 1.7242e-02]],\n",
      "\n",
      "         [[-3.1718e-01]],\n",
      "\n",
      "         [[-1.9161e-01]],\n",
      "\n",
      "         [[-4.8985e-01]],\n",
      "\n",
      "         [[-2.7575e-01]],\n",
      "\n",
      "         [[-2.3647e-02]],\n",
      "\n",
      "         [[-2.1267e-01]],\n",
      "\n",
      "         [[-1.2472e-01]],\n",
      "\n",
      "         [[-5.6188e-02]],\n",
      "\n",
      "         [[-2.1098e-01]],\n",
      "\n",
      "         [[-2.6650e-01]],\n",
      "\n",
      "         [[ 3.3415e-01]],\n",
      "\n",
      "         [[-7.0190e-02]],\n",
      "\n",
      "         [[-6.1234e-01]],\n",
      "\n",
      "         [[ 4.1055e-02]],\n",
      "\n",
      "         [[ 5.2506e-03]],\n",
      "\n",
      "         [[-2.9709e-01]],\n",
      "\n",
      "         [[-8.1833e-02]],\n",
      "\n",
      "         [[-3.3783e-01]],\n",
      "\n",
      "         [[-2.0452e-01]],\n",
      "\n",
      "         [[ 9.0889e-02]],\n",
      "\n",
      "         [[-2.2247e-01]],\n",
      "\n",
      "         [[-1.5623e-01]],\n",
      "\n",
      "         [[-3.0079e-01]],\n",
      "\n",
      "         [[-6.8824e-02]],\n",
      "\n",
      "         [[-7.0080e-01]],\n",
      "\n",
      "         [[ 8.8141e-04]],\n",
      "\n",
      "         [[-1.2061e-01]],\n",
      "\n",
      "         [[-1.1026e-02]],\n",
      "\n",
      "         [[-7.0210e-02]],\n",
      "\n",
      "         [[ 4.1014e-02]],\n",
      "\n",
      "         [[ 2.6961e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3781e-02]],\n",
      "\n",
      "         [[ 3.0066e-01]],\n",
      "\n",
      "         [[ 1.8506e-02]],\n",
      "\n",
      "         [[-4.2292e-01]],\n",
      "\n",
      "         [[-1.5573e-01]],\n",
      "\n",
      "         [[-5.4086e-01]],\n",
      "\n",
      "         [[-2.6006e-01]],\n",
      "\n",
      "         [[-1.0934e-02]],\n",
      "\n",
      "         [[-3.7976e-01]],\n",
      "\n",
      "         [[-4.6073e-02]],\n",
      "\n",
      "         [[-5.6026e-01]],\n",
      "\n",
      "         [[-4.8407e-01]],\n",
      "\n",
      "         [[-1.8666e-01]],\n",
      "\n",
      "         [[-3.6453e-01]],\n",
      "\n",
      "         [[-3.4883e-01]],\n",
      "\n",
      "         [[ 3.6573e-01]],\n",
      "\n",
      "         [[-3.2065e-01]],\n",
      "\n",
      "         [[-4.0124e-02]],\n",
      "\n",
      "         [[-5.9954e-01]],\n",
      "\n",
      "         [[-2.8422e-01]],\n",
      "\n",
      "         [[-6.6560e-01]],\n",
      "\n",
      "         [[-7.3248e-01]],\n",
      "\n",
      "         [[-3.5552e-01]],\n",
      "\n",
      "         [[-3.3379e-01]],\n",
      "\n",
      "         [[-4.3803e-01]],\n",
      "\n",
      "         [[-9.2068e-01]],\n",
      "\n",
      "         [[-7.6402e-01]],\n",
      "\n",
      "         [[-5.2285e-01]],\n",
      "\n",
      "         [[-3.6047e-01]],\n",
      "\n",
      "         [[-3.0966e-01]],\n",
      "\n",
      "         [[ 2.0479e-01]],\n",
      "\n",
      "         [[-4.7337e-01]],\n",
      "\n",
      "         [[ 1.1375e-01]],\n",
      "\n",
      "         [[-3.0352e-01]],\n",
      "\n",
      "         [[ 2.7050e-01]],\n",
      "\n",
      "         [[-1.5416e-01]],\n",
      "\n",
      "         [[-2.1081e-01]],\n",
      "\n",
      "         [[-4.6788e-01]],\n",
      "\n",
      "         [[-6.7930e-01]],\n",
      "\n",
      "         [[ 2.0568e-01]],\n",
      "\n",
      "         [[-4.9673e-01]],\n",
      "\n",
      "         [[-3.0145e-01]],\n",
      "\n",
      "         [[-4.2753e-01]],\n",
      "\n",
      "         [[-1.0842e+00]],\n",
      "\n",
      "         [[-4.4261e-01]],\n",
      "\n",
      "         [[-4.1253e-01]],\n",
      "\n",
      "         [[-9.1945e-04]],\n",
      "\n",
      "         [[-6.4886e-01]],\n",
      "\n",
      "         [[-3.8905e-01]],\n",
      "\n",
      "         [[-4.7739e-01]],\n",
      "\n",
      "         [[ 9.9828e-02]],\n",
      "\n",
      "         [[-1.5767e-01]],\n",
      "\n",
      "         [[ 1.5397e-01]],\n",
      "\n",
      "         [[-1.7062e-01]],\n",
      "\n",
      "         [[-6.6781e-01]],\n",
      "\n",
      "         [[-5.3991e-01]],\n",
      "\n",
      "         [[-1.9365e-03]],\n",
      "\n",
      "         [[-4.1082e-01]],\n",
      "\n",
      "         [[-1.1866e-01]],\n",
      "\n",
      "         [[ 2.5878e-01]],\n",
      "\n",
      "         [[ 7.2497e-02]],\n",
      "\n",
      "         [[-3.1958e-01]],\n",
      "\n",
      "         [[-4.5369e-01]],\n",
      "\n",
      "         [[ 2.6155e-01]],\n",
      "\n",
      "         [[-4.0060e-02]],\n",
      "\n",
      "         [[ 3.9132e-01]],\n",
      "\n",
      "         [[-2.4066e-01]],\n",
      "\n",
      "         [[-3.2628e-02]],\n",
      "\n",
      "         [[-2.5472e-01]],\n",
      "\n",
      "         [[-7.2714e-01]],\n",
      "\n",
      "         [[ 7.3317e-02]],\n",
      "\n",
      "         [[ 1.0034e-01]],\n",
      "\n",
      "         [[-4.0185e-01]],\n",
      "\n",
      "         [[-7.4703e-01]],\n",
      "\n",
      "         [[-1.8714e-01]],\n",
      "\n",
      "         [[-3.1976e-01]],\n",
      "\n",
      "         [[-5.2476e-01]],\n",
      "\n",
      "         [[ 4.0980e-02]],\n",
      "\n",
      "         [[-5.2690e-01]],\n",
      "\n",
      "         [[-1.7991e-01]],\n",
      "\n",
      "         [[-3.1902e-01]],\n",
      "\n",
      "         [[-3.0668e-02]],\n",
      "\n",
      "         [[ 2.0445e-01]],\n",
      "\n",
      "         [[-3.7003e-01]],\n",
      "\n",
      "         [[-8.5223e-02]],\n",
      "\n",
      "         [[-3.2767e-01]],\n",
      "\n",
      "         [[-4.5894e-01]],\n",
      "\n",
      "         [[-5.2601e-01]],\n",
      "\n",
      "         [[-3.5833e-01]],\n",
      "\n",
      "         [[-2.4685e-01]],\n",
      "\n",
      "         [[-8.7329e-01]],\n",
      "\n",
      "         [[-7.4637e-01]],\n",
      "\n",
      "         [[ 1.0345e-01]],\n",
      "\n",
      "         [[-4.0527e-01]],\n",
      "\n",
      "         [[-2.5078e-01]],\n",
      "\n",
      "         [[-1.6746e-01]],\n",
      "\n",
      "         [[ 6.7047e-01]],\n",
      "\n",
      "         [[ 4.9557e-02]],\n",
      "\n",
      "         [[-8.6306e-02]],\n",
      "\n",
      "         [[ 5.8168e-02]],\n",
      "\n",
      "         [[-5.0227e-01]],\n",
      "\n",
      "         [[ 1.7707e-01]],\n",
      "\n",
      "         [[ 2.1696e-01]],\n",
      "\n",
      "         [[-5.1907e-01]],\n",
      "\n",
      "         [[-3.6498e-01]],\n",
      "\n",
      "         [[ 2.0424e-01]],\n",
      "\n",
      "         [[-2.1628e-01]],\n",
      "\n",
      "         [[-6.3342e-02]],\n",
      "\n",
      "         [[-3.5940e-01]],\n",
      "\n",
      "         [[-4.2072e-01]],\n",
      "\n",
      "         [[-5.3943e-01]],\n",
      "\n",
      "         [[-5.7173e-03]],\n",
      "\n",
      "         [[-5.5538e-01]],\n",
      "\n",
      "         [[-2.3141e-01]],\n",
      "\n",
      "         [[ 1.7014e-01]],\n",
      "\n",
      "         [[ 4.6595e-01]],\n",
      "\n",
      "         [[ 4.1602e-01]],\n",
      "\n",
      "         [[-4.5400e-01]],\n",
      "\n",
      "         [[-1.3995e-01]],\n",
      "\n",
      "         [[ 1.4695e-01]],\n",
      "\n",
      "         [[ 1.1437e-01]],\n",
      "\n",
      "         [[-2.3593e-02]],\n",
      "\n",
      "         [[-1.8354e-01]],\n",
      "\n",
      "         [[-1.7440e-01]],\n",
      "\n",
      "         [[ 5.7234e-01]],\n",
      "\n",
      "         [[ 2.0064e-01]],\n",
      "\n",
      "         [[-7.1384e-01]],\n",
      "\n",
      "         [[-5.6381e-01]],\n",
      "\n",
      "         [[-1.7100e-01]],\n",
      "\n",
      "         [[-3.1270e-01]],\n",
      "\n",
      "         [[-2.6421e-02]],\n",
      "\n",
      "         [[-1.2877e-02]],\n",
      "\n",
      "         [[-5.3209e-01]],\n",
      "\n",
      "         [[ 2.0827e-02]],\n",
      "\n",
      "         [[-4.3675e-01]],\n",
      "\n",
      "         [[-4.1607e-01]],\n",
      "\n",
      "         [[-1.4129e+00]],\n",
      "\n",
      "         [[-3.1805e-01]],\n",
      "\n",
      "         [[ 7.4102e-01]],\n",
      "\n",
      "         [[-3.4809e-01]],\n",
      "\n",
      "         [[-4.4626e-01]],\n",
      "\n",
      "         [[-6.3044e-01]],\n",
      "\n",
      "         [[-3.6076e-01]],\n",
      "\n",
      "         [[-1.8757e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5417e-02]],\n",
      "\n",
      "         [[-6.6971e-02]],\n",
      "\n",
      "         [[ 7.4064e-02]],\n",
      "\n",
      "         [[-5.7023e-02]],\n",
      "\n",
      "         [[ 6.4071e-02]],\n",
      "\n",
      "         [[ 1.8304e-02]],\n",
      "\n",
      "         [[-1.6003e-03]],\n",
      "\n",
      "         [[ 5.1710e-02]],\n",
      "\n",
      "         [[ 7.1778e-02]],\n",
      "\n",
      "         [[ 1.6941e-01]],\n",
      "\n",
      "         [[ 2.4310e-01]],\n",
      "\n",
      "         [[ 1.1415e-01]],\n",
      "\n",
      "         [[ 1.6276e-01]],\n",
      "\n",
      "         [[ 1.0362e-02]],\n",
      "\n",
      "         [[ 7.1878e-02]],\n",
      "\n",
      "         [[ 3.9899e-01]],\n",
      "\n",
      "         [[-1.2740e-01]],\n",
      "\n",
      "         [[ 5.2364e-03]],\n",
      "\n",
      "         [[-7.2378e-03]],\n",
      "\n",
      "         [[ 1.2063e-01]],\n",
      "\n",
      "         [[-1.6801e-02]],\n",
      "\n",
      "         [[ 1.3920e-01]],\n",
      "\n",
      "         [[ 1.9757e-02]],\n",
      "\n",
      "         [[ 7.1242e-02]],\n",
      "\n",
      "         [[-3.8830e-01]],\n",
      "\n",
      "         [[-1.7236e-01]],\n",
      "\n",
      "         [[-2.3176e-01]],\n",
      "\n",
      "         [[ 1.8095e-01]],\n",
      "\n",
      "         [[ 4.8591e-02]],\n",
      "\n",
      "         [[-6.4934e-02]],\n",
      "\n",
      "         [[ 1.2629e-01]],\n",
      "\n",
      "         [[ 7.3319e-02]],\n",
      "\n",
      "         [[ 2.2970e-02]],\n",
      "\n",
      "         [[-8.5637e-02]],\n",
      "\n",
      "         [[ 3.7208e-01]],\n",
      "\n",
      "         [[-1.0760e-01]],\n",
      "\n",
      "         [[-1.4161e-01]],\n",
      "\n",
      "         [[ 1.9711e-01]],\n",
      "\n",
      "         [[ 2.4038e-02]],\n",
      "\n",
      "         [[ 5.0591e-01]],\n",
      "\n",
      "         [[ 1.0925e-01]],\n",
      "\n",
      "         [[ 1.1051e-01]],\n",
      "\n",
      "         [[ 6.5697e-02]],\n",
      "\n",
      "         [[-4.6716e-01]],\n",
      "\n",
      "         [[ 1.2672e-01]],\n",
      "\n",
      "         [[-6.3294e-02]],\n",
      "\n",
      "         [[ 1.8789e-01]],\n",
      "\n",
      "         [[ 4.4043e-02]],\n",
      "\n",
      "         [[-1.4604e-01]],\n",
      "\n",
      "         [[-5.6491e-01]],\n",
      "\n",
      "         [[ 2.8210e-01]],\n",
      "\n",
      "         [[-2.3790e-01]],\n",
      "\n",
      "         [[ 8.3449e-02]],\n",
      "\n",
      "         [[-5.5325e-01]],\n",
      "\n",
      "         [[ 9.9977e-02]],\n",
      "\n",
      "         [[-1.5916e-01]],\n",
      "\n",
      "         [[ 4.7173e-02]],\n",
      "\n",
      "         [[ 1.2844e-02]],\n",
      "\n",
      "         [[-2.9109e-01]],\n",
      "\n",
      "         [[-1.0133e-01]],\n",
      "\n",
      "         [[ 1.4806e-01]],\n",
      "\n",
      "         [[ 9.1735e-02]],\n",
      "\n",
      "         [[ 1.1747e-02]],\n",
      "\n",
      "         [[ 3.6265e-02]],\n",
      "\n",
      "         [[-1.1250e-01]],\n",
      "\n",
      "         [[-1.4848e-01]],\n",
      "\n",
      "         [[-5.2657e-02]],\n",
      "\n",
      "         [[-4.0574e-01]],\n",
      "\n",
      "         [[ 2.4235e-02]],\n",
      "\n",
      "         [[-1.4301e-01]],\n",
      "\n",
      "         [[ 2.0925e-01]],\n",
      "\n",
      "         [[ 1.3735e-01]],\n",
      "\n",
      "         [[ 7.7313e-02]],\n",
      "\n",
      "         [[-3.6401e-02]],\n",
      "\n",
      "         [[ 1.2818e-05]],\n",
      "\n",
      "         [[ 1.0978e-01]],\n",
      "\n",
      "         [[-8.8134e-02]],\n",
      "\n",
      "         [[ 2.8787e-01]],\n",
      "\n",
      "         [[ 3.5017e-02]],\n",
      "\n",
      "         [[ 3.5495e-01]],\n",
      "\n",
      "         [[-1.7975e-03]],\n",
      "\n",
      "         [[ 1.7856e-01]],\n",
      "\n",
      "         [[ 4.7340e-01]],\n",
      "\n",
      "         [[ 7.6599e-02]],\n",
      "\n",
      "         [[ 5.9687e-02]],\n",
      "\n",
      "         [[-8.3582e-01]],\n",
      "\n",
      "         [[ 1.5906e-01]],\n",
      "\n",
      "         [[ 2.3629e-01]],\n",
      "\n",
      "         [[ 2.2000e-01]],\n",
      "\n",
      "         [[ 3.5072e-01]],\n",
      "\n",
      "         [[-2.1700e-01]],\n",
      "\n",
      "         [[-2.7666e-01]],\n",
      "\n",
      "         [[ 8.1517e-02]],\n",
      "\n",
      "         [[ 2.1448e-01]],\n",
      "\n",
      "         [[-1.4430e-01]],\n",
      "\n",
      "         [[ 7.9516e-02]],\n",
      "\n",
      "         [[-1.7205e-01]],\n",
      "\n",
      "         [[-1.2658e-01]],\n",
      "\n",
      "         [[ 1.4409e-01]],\n",
      "\n",
      "         [[ 4.5344e-01]],\n",
      "\n",
      "         [[ 1.0449e-01]],\n",
      "\n",
      "         [[-2.4332e-01]],\n",
      "\n",
      "         [[ 2.5905e-01]],\n",
      "\n",
      "         [[ 9.6648e-02]],\n",
      "\n",
      "         [[-4.4479e-02]],\n",
      "\n",
      "         [[-3.7198e-02]],\n",
      "\n",
      "         [[-5.5598e-01]],\n",
      "\n",
      "         [[ 1.4638e-01]],\n",
      "\n",
      "         [[ 8.8714e-02]],\n",
      "\n",
      "         [[ 1.0237e-01]],\n",
      "\n",
      "         [[ 1.1100e-01]],\n",
      "\n",
      "         [[ 3.6543e-02]],\n",
      "\n",
      "         [[ 7.2713e-02]],\n",
      "\n",
      "         [[-1.6871e-01]],\n",
      "\n",
      "         [[ 2.4121e-01]],\n",
      "\n",
      "         [[ 4.4230e-01]],\n",
      "\n",
      "         [[-1.3531e-01]],\n",
      "\n",
      "         [[ 1.1851e-01]],\n",
      "\n",
      "         [[ 8.5776e-02]],\n",
      "\n",
      "         [[ 1.1158e-01]],\n",
      "\n",
      "         [[ 1.9758e-01]],\n",
      "\n",
      "         [[ 4.3906e-02]],\n",
      "\n",
      "         [[ 1.7053e-01]],\n",
      "\n",
      "         [[ 8.6172e-02]],\n",
      "\n",
      "         [[ 6.9852e-01]],\n",
      "\n",
      "         [[-1.0972e-01]],\n",
      "\n",
      "         [[ 8.9529e-02]],\n",
      "\n",
      "         [[-2.2378e-02]],\n",
      "\n",
      "         [[ 1.2490e-01]],\n",
      "\n",
      "         [[ 1.1179e-01]],\n",
      "\n",
      "         [[-1.7536e-01]],\n",
      "\n",
      "         [[ 2.6937e-02]],\n",
      "\n",
      "         [[-1.2013e-01]],\n",
      "\n",
      "         [[ 1.2869e-02]],\n",
      "\n",
      "         [[-4.8265e-02]],\n",
      "\n",
      "         [[ 2.7805e-01]],\n",
      "\n",
      "         [[ 2.2412e-01]],\n",
      "\n",
      "         [[-2.3655e-01]],\n",
      "\n",
      "         [[-3.3908e-02]],\n",
      "\n",
      "         [[-1.9544e-02]],\n",
      "\n",
      "         [[ 2.9857e-02]],\n",
      "\n",
      "         [[ 1.3591e-01]],\n",
      "\n",
      "         [[ 1.7522e-01]],\n",
      "\n",
      "         [[-3.9429e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.9498e-02]],\n",
      "\n",
      "         [[ 1.3609e-01]],\n",
      "\n",
      "         [[-3.5623e-02]],\n",
      "\n",
      "         [[-1.5209e-01]],\n",
      "\n",
      "         [[ 1.5830e-01]],\n",
      "\n",
      "         [[-3.1148e-01]],\n",
      "\n",
      "         [[-2.2638e+00]],\n",
      "\n",
      "         [[ 2.1237e-01]],\n",
      "\n",
      "         [[ 4.5025e-02]],\n",
      "\n",
      "         [[ 6.0189e-02]],\n",
      "\n",
      "         [[-2.4198e-01]],\n",
      "\n",
      "         [[-2.5172e-01]],\n",
      "\n",
      "         [[-5.4201e-02]],\n",
      "\n",
      "         [[-1.5847e-01]],\n",
      "\n",
      "         [[-1.3252e-01]],\n",
      "\n",
      "         [[ 5.6185e-02]],\n",
      "\n",
      "         [[-1.8716e-01]],\n",
      "\n",
      "         [[-2.8894e-01]],\n",
      "\n",
      "         [[-3.9098e-01]],\n",
      "\n",
      "         [[-1.4901e-01]],\n",
      "\n",
      "         [[-1.8834e-01]],\n",
      "\n",
      "         [[-3.7966e-01]],\n",
      "\n",
      "         [[-2.8792e-03]],\n",
      "\n",
      "         [[-3.4946e-01]],\n",
      "\n",
      "         [[-1.5437e-01]],\n",
      "\n",
      "         [[ 3.2604e-02]],\n",
      "\n",
      "         [[-3.6784e-01]],\n",
      "\n",
      "         [[-3.2205e-01]],\n",
      "\n",
      "         [[-3.0998e-01]],\n",
      "\n",
      "         [[-1.8593e-02]],\n",
      "\n",
      "         [[-7.0448e-01]],\n",
      "\n",
      "         [[-2.9679e-01]],\n",
      "\n",
      "         [[ 2.4275e-01]],\n",
      "\n",
      "         [[-1.9630e-01]],\n",
      "\n",
      "         [[ 2.7149e-01]],\n",
      "\n",
      "         [[-3.8904e-01]],\n",
      "\n",
      "         [[-5.2832e-01]],\n",
      "\n",
      "         [[-4.9845e-01]],\n",
      "\n",
      "         [[-1.5332e-01]],\n",
      "\n",
      "         [[-2.8069e-01]],\n",
      "\n",
      "         [[ 8.3888e-02]],\n",
      "\n",
      "         [[-6.6855e-02]],\n",
      "\n",
      "         [[-8.4041e-02]],\n",
      "\n",
      "         [[-3.2752e-01]],\n",
      "\n",
      "         [[-2.2386e-01]],\n",
      "\n",
      "         [[-6.4169e-02]],\n",
      "\n",
      "         [[ 6.5452e-02]],\n",
      "\n",
      "         [[-3.6537e-01]],\n",
      "\n",
      "         [[-1.1234e-01]],\n",
      "\n",
      "         [[-1.6701e-01]],\n",
      "\n",
      "         [[-2.4058e-02]],\n",
      "\n",
      "         [[-5.4018e-01]],\n",
      "\n",
      "         [[-1.0615e-01]],\n",
      "\n",
      "         [[-2.7885e-02]],\n",
      "\n",
      "         [[-2.2488e-01]],\n",
      "\n",
      "         [[-3.0791e-01]],\n",
      "\n",
      "         [[ 3.2369e-02]],\n",
      "\n",
      "         [[-3.4074e-01]],\n",
      "\n",
      "         [[-3.0993e-01]],\n",
      "\n",
      "         [[-3.2903e-01]],\n",
      "\n",
      "         [[ 4.7186e-02]],\n",
      "\n",
      "         [[-3.5291e-01]],\n",
      "\n",
      "         [[-2.3094e-01]],\n",
      "\n",
      "         [[-2.9179e-01]],\n",
      "\n",
      "         [[-5.4333e-03]],\n",
      "\n",
      "         [[ 2.0417e-01]],\n",
      "\n",
      "         [[-2.6136e-01]],\n",
      "\n",
      "         [[-2.4558e-01]],\n",
      "\n",
      "         [[-2.2124e-01]],\n",
      "\n",
      "         [[ 6.3294e-02]],\n",
      "\n",
      "         [[ 1.2146e-01]],\n",
      "\n",
      "         [[ 3.3438e-02]],\n",
      "\n",
      "         [[-3.8665e-01]],\n",
      "\n",
      "         [[-8.9081e-04]],\n",
      "\n",
      "         [[-2.6709e-01]],\n",
      "\n",
      "         [[-4.2642e-01]],\n",
      "\n",
      "         [[-2.6218e-01]],\n",
      "\n",
      "         [[ 8.2096e-02]],\n",
      "\n",
      "         [[-2.2198e-01]],\n",
      "\n",
      "         [[ 2.0557e-02]],\n",
      "\n",
      "         [[-1.7905e-01]],\n",
      "\n",
      "         [[ 4.0382e-02]],\n",
      "\n",
      "         [[ 6.4591e-02]],\n",
      "\n",
      "         [[-3.8799e-01]],\n",
      "\n",
      "         [[-7.2167e-01]],\n",
      "\n",
      "         [[-3.2548e-01]],\n",
      "\n",
      "         [[-2.1304e-01]],\n",
      "\n",
      "         [[-4.3952e-01]],\n",
      "\n",
      "         [[ 2.1573e-02]],\n",
      "\n",
      "         [[-1.5696e-01]],\n",
      "\n",
      "         [[-1.7226e-01]],\n",
      "\n",
      "         [[-1.0691e-01]],\n",
      "\n",
      "         [[-2.9037e-02]],\n",
      "\n",
      "         [[-2.7188e-01]],\n",
      "\n",
      "         [[-3.6762e-01]],\n",
      "\n",
      "         [[ 3.8523e-04]],\n",
      "\n",
      "         [[-7.9019e-01]],\n",
      "\n",
      "         [[-1.6452e-01]],\n",
      "\n",
      "         [[-3.7345e-02]],\n",
      "\n",
      "         [[ 1.5502e-01]],\n",
      "\n",
      "         [[-2.6950e-01]],\n",
      "\n",
      "         [[-3.7228e-01]],\n",
      "\n",
      "         [[ 1.0406e-02]],\n",
      "\n",
      "         [[-2.8758e-01]],\n",
      "\n",
      "         [[-4.8864e-01]],\n",
      "\n",
      "         [[-1.5180e-01]],\n",
      "\n",
      "         [[-3.9256e-01]],\n",
      "\n",
      "         [[ 9.5834e-03]],\n",
      "\n",
      "         [[-2.9781e-01]],\n",
      "\n",
      "         [[-3.1865e-01]],\n",
      "\n",
      "         [[-3.5293e-01]],\n",
      "\n",
      "         [[-1.2704e-02]],\n",
      "\n",
      "         [[-3.4074e-01]],\n",
      "\n",
      "         [[-6.4900e-02]],\n",
      "\n",
      "         [[ 1.3353e-01]],\n",
      "\n",
      "         [[-3.3580e-02]],\n",
      "\n",
      "         [[-8.5623e-02]],\n",
      "\n",
      "         [[-3.7636e-01]],\n",
      "\n",
      "         [[ 1.6947e-02]],\n",
      "\n",
      "         [[ 4.1171e-02]],\n",
      "\n",
      "         [[-5.0476e-01]],\n",
      "\n",
      "         [[-1.3594e-01]],\n",
      "\n",
      "         [[ 9.0141e-02]],\n",
      "\n",
      "         [[-3.0496e-02]],\n",
      "\n",
      "         [[-4.9263e-02]],\n",
      "\n",
      "         [[ 8.0255e-02]],\n",
      "\n",
      "         [[-3.3634e-01]],\n",
      "\n",
      "         [[-5.8692e-02]],\n",
      "\n",
      "         [[ 1.2794e-01]],\n",
      "\n",
      "         [[-2.0918e-01]],\n",
      "\n",
      "         [[-3.0253e-03]],\n",
      "\n",
      "         [[-9.3583e-02]],\n",
      "\n",
      "         [[-1.9387e-01]],\n",
      "\n",
      "         [[-3.6621e-02]],\n",
      "\n",
      "         [[-2.9531e-01]],\n",
      "\n",
      "         [[-3.3052e-01]],\n",
      "\n",
      "         [[-5.1700e-01]],\n",
      "\n",
      "         [[-1.2906e-01]],\n",
      "\n",
      "         [[ 1.2627e-01]],\n",
      "\n",
      "         [[-5.5947e-02]],\n",
      "\n",
      "         [[-2.9827e-01]],\n",
      "\n",
      "         [[-4.1329e-01]],\n",
      "\n",
      "         [[-3.8759e-02]],\n",
      "\n",
      "         [[-4.0955e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1546,  0.0032, -0.1818,  0.0774,  0.2118,  0.0079], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-6.6859e-02]],\n",
      "\n",
      "         [[-4.7860e-02]],\n",
      "\n",
      "         [[ 9.0540e-02]],\n",
      "\n",
      "         [[ 5.7981e-01]],\n",
      "\n",
      "         [[-1.2613e-01]],\n",
      "\n",
      "         [[ 4.0208e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9723e-01]],\n",
      "\n",
      "         [[ 1.4177e-01]],\n",
      "\n",
      "         [[ 1.7858e-01]],\n",
      "\n",
      "         [[-9.8766e-01]],\n",
      "\n",
      "         [[ 7.1357e-02]],\n",
      "\n",
      "         [[-1.0450e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3434e-01]],\n",
      "\n",
      "         [[ 4.0145e-01]],\n",
      "\n",
      "         [[ 5.7555e-02]],\n",
      "\n",
      "         [[-5.3485e-02]],\n",
      "\n",
      "         [[ 1.7625e-01]],\n",
      "\n",
      "         [[ 1.1046e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2303e-01]],\n",
      "\n",
      "         [[ 3.8500e-01]],\n",
      "\n",
      "         [[ 1.7247e-01]],\n",
      "\n",
      "         [[ 2.3394e-01]],\n",
      "\n",
      "         [[ 7.3082e-01]],\n",
      "\n",
      "         [[ 2.3268e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.0109e-01]],\n",
      "\n",
      "         [[ 2.4771e-01]],\n",
      "\n",
      "         [[ 2.7279e-02]],\n",
      "\n",
      "         [[-6.5865e-01]],\n",
      "\n",
      "         [[ 5.5652e-01]],\n",
      "\n",
      "         [[ 2.2871e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9825e-01]],\n",
      "\n",
      "         [[ 4.2382e-01]],\n",
      "\n",
      "         [[-1.3944e-02]],\n",
      "\n",
      "         [[ 2.4167e-01]],\n",
      "\n",
      "         [[ 7.5328e-01]],\n",
      "\n",
      "         [[ 1.1050e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.7428e-01]],\n",
      "\n",
      "         [[-4.2838e-01]],\n",
      "\n",
      "         [[ 1.4096e-01]],\n",
      "\n",
      "         [[ 7.9977e-01]],\n",
      "\n",
      "         [[-3.0998e-01]],\n",
      "\n",
      "         [[ 3.9228e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6250e-01]],\n",
      "\n",
      "         [[ 3.3294e-01]],\n",
      "\n",
      "         [[-6.6918e-01]],\n",
      "\n",
      "         [[-6.1370e-02]],\n",
      "\n",
      "         [[ 5.0618e-01]],\n",
      "\n",
      "         [[ 2.5775e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0796e-01]],\n",
      "\n",
      "         [[-6.0410e-01]],\n",
      "\n",
      "         [[ 1.5702e-01]],\n",
      "\n",
      "         [[ 5.7217e-01]],\n",
      "\n",
      "         [[-3.4601e-01]],\n",
      "\n",
      "         [[ 1.2838e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.9092e-01]],\n",
      "\n",
      "         [[-4.7789e-01]],\n",
      "\n",
      "         [[-1.5398e-02]],\n",
      "\n",
      "         [[-2.1154e-01]],\n",
      "\n",
      "         [[-2.7069e-01]],\n",
      "\n",
      "         [[ 2.2646e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4134e-01]],\n",
      "\n",
      "         [[ 4.0506e-01]],\n",
      "\n",
      "         [[ 6.0892e-03]],\n",
      "\n",
      "         [[ 1.8925e-01]],\n",
      "\n",
      "         [[ 5.8078e-01]],\n",
      "\n",
      "         [[ 1.1740e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5737e-01]],\n",
      "\n",
      "         [[ 5.1013e-01]],\n",
      "\n",
      "         [[ 4.8004e-02]],\n",
      "\n",
      "         [[-9.6408e-04]],\n",
      "\n",
      "         [[ 7.2851e-01]],\n",
      "\n",
      "         [[-1.4544e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2116e-01]],\n",
      "\n",
      "         [[ 2.1080e-01]],\n",
      "\n",
      "         [[ 2.3522e-01]],\n",
      "\n",
      "         [[ 7.1460e-02]],\n",
      "\n",
      "         [[ 2.9379e-01]],\n",
      "\n",
      "         [[ 6.3584e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4463e-01]],\n",
      "\n",
      "         [[ 2.6732e-01]],\n",
      "\n",
      "         [[ 4.2985e-02]],\n",
      "\n",
      "         [[ 3.3901e-01]],\n",
      "\n",
      "         [[ 6.2963e-01]],\n",
      "\n",
      "         [[ 1.1391e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4743e-01]],\n",
      "\n",
      "         [[ 2.8901e-01]],\n",
      "\n",
      "         [[ 2.8466e-02]],\n",
      "\n",
      "         [[ 3.0369e-01]],\n",
      "\n",
      "         [[ 6.2175e-01]],\n",
      "\n",
      "         [[ 1.0033e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3745e-01]],\n",
      "\n",
      "         [[ 3.4039e-01]],\n",
      "\n",
      "         [[ 3.1273e-01]],\n",
      "\n",
      "         [[-5.9602e-02]],\n",
      "\n",
      "         [[ 3.5770e-01]],\n",
      "\n",
      "         [[ 1.5674e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8978e-01]],\n",
      "\n",
      "         [[ 5.3300e-01]],\n",
      "\n",
      "         [[-2.7141e-02]],\n",
      "\n",
      "         [[ 3.4206e-01]],\n",
      "\n",
      "         [[ 3.8371e-01]],\n",
      "\n",
      "         [[ 2.0995e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.4593e-01]],\n",
      "\n",
      "         [[-5.4626e-01]],\n",
      "\n",
      "         [[ 9.1450e-02]],\n",
      "\n",
      "         [[ 1.1552e-01]],\n",
      "\n",
      "         [[-4.0920e-01]],\n",
      "\n",
      "         [[-2.8301e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9236e-01]],\n",
      "\n",
      "         [[ 5.4228e-01]],\n",
      "\n",
      "         [[ 1.4579e-01]],\n",
      "\n",
      "         [[-3.6512e-01]],\n",
      "\n",
      "         [[ 6.3389e-01]],\n",
      "\n",
      "         [[ 3.5999e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6506e-01]],\n",
      "\n",
      "         [[ 5.1797e-01]],\n",
      "\n",
      "         [[ 4.4125e-02]],\n",
      "\n",
      "         [[-2.1287e-02]],\n",
      "\n",
      "         [[ 6.3077e-01]],\n",
      "\n",
      "         [[ 6.7814e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2502e-01]],\n",
      "\n",
      "         [[ 2.8384e-01]],\n",
      "\n",
      "         [[ 1.1933e-01]],\n",
      "\n",
      "         [[ 2.4679e-01]],\n",
      "\n",
      "         [[ 5.5821e-01]],\n",
      "\n",
      "         [[ 1.9945e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6854e-02]],\n",
      "\n",
      "         [[-2.1230e-01]],\n",
      "\n",
      "         [[ 1.6504e-01]],\n",
      "\n",
      "         [[ 1.6231e-01]],\n",
      "\n",
      "         [[-1.1555e-01]],\n",
      "\n",
      "         [[ 2.3019e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2076e-01]],\n",
      "\n",
      "         [[-6.4023e-02]],\n",
      "\n",
      "         [[-6.6989e-02]],\n",
      "\n",
      "         [[-4.6530e-01]],\n",
      "\n",
      "         [[ 1.3699e-01]],\n",
      "\n",
      "         [[ 7.6788e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.0781e-01]],\n",
      "\n",
      "         [[-5.1869e-01]],\n",
      "\n",
      "         [[-4.9592e-02]],\n",
      "\n",
      "         [[ 2.2997e-01]],\n",
      "\n",
      "         [[-5.0273e-01]],\n",
      "\n",
      "         [[-1.7770e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4698e-01]],\n",
      "\n",
      "         [[ 5.4817e-01]],\n",
      "\n",
      "         [[ 1.8061e-01]],\n",
      "\n",
      "         [[-6.5975e-02]],\n",
      "\n",
      "         [[ 7.2612e-01]],\n",
      "\n",
      "         [[-7.8224e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.6547e-01]],\n",
      "\n",
      "         [[-1.9766e-01]],\n",
      "\n",
      "         [[ 1.0573e-01]],\n",
      "\n",
      "         [[ 3.1319e-01]],\n",
      "\n",
      "         [[-2.5832e-02]],\n",
      "\n",
      "         [[ 2.5424e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6017e-01]],\n",
      "\n",
      "         [[ 2.2748e-01]],\n",
      "\n",
      "         [[ 2.4000e-01]],\n",
      "\n",
      "         [[-4.7142e-02]],\n",
      "\n",
      "         [[ 2.9508e-01]],\n",
      "\n",
      "         [[ 4.7006e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9647e-01]],\n",
      "\n",
      "         [[ 2.6830e-01]],\n",
      "\n",
      "         [[-9.9351e-03]],\n",
      "\n",
      "         [[-1.3691e-01]],\n",
      "\n",
      "         [[ 4.1728e-01]],\n",
      "\n",
      "         [[ 3.7855e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6186e-01]],\n",
      "\n",
      "         [[ 7.0073e-01]],\n",
      "\n",
      "         [[ 5.4216e-03]],\n",
      "\n",
      "         [[-3.7826e-01]],\n",
      "\n",
      "         [[ 1.7545e-01]],\n",
      "\n",
      "         [[ 1.0593e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.7878e-02]],\n",
      "\n",
      "         [[ 1.0540e-01]],\n",
      "\n",
      "         [[ 2.4971e-01]],\n",
      "\n",
      "         [[ 1.0030e-01]],\n",
      "\n",
      "         [[ 4.3640e-02]],\n",
      "\n",
      "         [[ 4.0011e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.7133e-01]],\n",
      "\n",
      "         [[-5.7320e-01]],\n",
      "\n",
      "         [[-3.5222e-01]],\n",
      "\n",
      "         [[ 1.0501e+00]],\n",
      "\n",
      "         [[-1.7505e-01]],\n",
      "\n",
      "         [[ 4.0382e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5814e-01]],\n",
      "\n",
      "         [[ 6.2889e-01]],\n",
      "\n",
      "         [[ 1.0755e-01]],\n",
      "\n",
      "         [[ 2.3660e-01]],\n",
      "\n",
      "         [[ 9.7302e-01]],\n",
      "\n",
      "         [[ 8.6477e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.2476e-01]],\n",
      "\n",
      "         [[ 2.1152e-02]],\n",
      "\n",
      "         [[ 1.1952e-01]],\n",
      "\n",
      "         [[ 9.2784e-01]],\n",
      "\n",
      "         [[-2.4157e-01]],\n",
      "\n",
      "         [[ 5.6724e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2572e-01]],\n",
      "\n",
      "         [[-3.1329e-02]],\n",
      "\n",
      "         [[ 1.7094e-01]],\n",
      "\n",
      "         [[ 4.4061e-02]],\n",
      "\n",
      "         [[-8.2603e-02]],\n",
      "\n",
      "         [[-1.2178e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2888e-01]],\n",
      "\n",
      "         [[-3.8128e-02]],\n",
      "\n",
      "         [[ 9.6772e-02]],\n",
      "\n",
      "         [[-4.5199e-01]],\n",
      "\n",
      "         [[-4.2421e-02]],\n",
      "\n",
      "         [[ 5.4558e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.3148e-01]],\n",
      "\n",
      "         [[-1.6924e-01]],\n",
      "\n",
      "         [[ 1.5327e-01]],\n",
      "\n",
      "         [[-2.5926e-01]],\n",
      "\n",
      "         [[-6.2873e-02]],\n",
      "\n",
      "         [[-1.2823e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.0637e-01]],\n",
      "\n",
      "         [[-2.9160e-02]],\n",
      "\n",
      "         [[ 2.1253e-01]],\n",
      "\n",
      "         [[-1.2706e-01]],\n",
      "\n",
      "         [[ 6.4313e-02]],\n",
      "\n",
      "         [[ 4.1355e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6818e-01]],\n",
      "\n",
      "         [[ 4.2394e-01]],\n",
      "\n",
      "         [[-8.5105e-03]],\n",
      "\n",
      "         [[ 3.1563e-01]],\n",
      "\n",
      "         [[ 6.0781e-01]],\n",
      "\n",
      "         [[ 1.7192e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9760e-01]],\n",
      "\n",
      "         [[ 5.4114e-01]],\n",
      "\n",
      "         [[ 1.1969e-01]],\n",
      "\n",
      "         [[ 2.6428e-01]],\n",
      "\n",
      "         [[ 5.3212e-01]],\n",
      "\n",
      "         [[ 6.0529e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9867e-01]],\n",
      "\n",
      "         [[ 6.2309e-01]],\n",
      "\n",
      "         [[-1.3595e-01]],\n",
      "\n",
      "         [[-5.6957e-02]],\n",
      "\n",
      "         [[-6.6045e-02]],\n",
      "\n",
      "         [[ 4.2586e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.2644e-01]],\n",
      "\n",
      "         [[ 3.5001e-01]],\n",
      "\n",
      "         [[ 1.3188e-01]],\n",
      "\n",
      "         [[-1.2906e-02]],\n",
      "\n",
      "         [[ 3.2438e-01]],\n",
      "\n",
      "         [[ 1.2672e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6570e-01]],\n",
      "\n",
      "         [[ 1.9273e-01]],\n",
      "\n",
      "         [[-2.1932e-02]],\n",
      "\n",
      "         [[-2.2243e-01]],\n",
      "\n",
      "         [[ 6.0470e-01]],\n",
      "\n",
      "         [[-2.2639e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.6493e-02]],\n",
      "\n",
      "         [[-2.0619e-01]],\n",
      "\n",
      "         [[ 8.0442e-01]],\n",
      "\n",
      "         [[-2.3199e-01]],\n",
      "\n",
      "         [[-3.3416e-01]],\n",
      "\n",
      "         [[ 9.6353e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.8371e-01]],\n",
      "\n",
      "         [[-1.3599e-01]],\n",
      "\n",
      "         [[-9.0504e-02]],\n",
      "\n",
      "         [[ 1.7366e-01]],\n",
      "\n",
      "         [[-1.0618e-01]],\n",
      "\n",
      "         [[ 2.2742e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5444e-01]],\n",
      "\n",
      "         [[ 5.3145e-01]],\n",
      "\n",
      "         [[-6.4618e-02]],\n",
      "\n",
      "         [[ 4.2480e-02]],\n",
      "\n",
      "         [[ 8.1394e-01]],\n",
      "\n",
      "         [[-1.7327e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7242e-01]],\n",
      "\n",
      "         [[ 3.8130e-01]],\n",
      "\n",
      "         [[ 2.8676e-03]],\n",
      "\n",
      "         [[ 8.1896e-02]],\n",
      "\n",
      "         [[ 8.0504e-01]],\n",
      "\n",
      "         [[ 2.7785e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4414e-01]],\n",
      "\n",
      "         [[ 8.3600e-02]],\n",
      "\n",
      "         [[ 6.8377e-02]],\n",
      "\n",
      "         [[ 8.8056e-02]],\n",
      "\n",
      "         [[ 2.8851e-01]],\n",
      "\n",
      "         [[ 2.1597e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9153e-02]],\n",
      "\n",
      "         [[-8.1647e-02]],\n",
      "\n",
      "         [[-5.4061e-02]],\n",
      "\n",
      "         [[ 3.0194e-02]],\n",
      "\n",
      "         [[ 1.1482e-02]],\n",
      "\n",
      "         [[ 5.6276e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.2349e-01]],\n",
      "\n",
      "         [[ 4.2343e-01]],\n",
      "\n",
      "         [[ 9.4300e-02]],\n",
      "\n",
      "         [[ 7.0429e-02]],\n",
      "\n",
      "         [[ 4.4908e-01]],\n",
      "\n",
      "         [[ 5.9566e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.5684e-02]],\n",
      "\n",
      "         [[-5.6044e-01]],\n",
      "\n",
      "         [[-4.3053e-01]],\n",
      "\n",
      "         [[ 9.3934e-03]],\n",
      "\n",
      "         [[ 3.0680e-01]],\n",
      "\n",
      "         [[ 1.6971e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5297e-01]],\n",
      "\n",
      "         [[ 3.0519e-02]],\n",
      "\n",
      "         [[ 1.1819e-01]],\n",
      "\n",
      "         [[ 3.1513e-01]],\n",
      "\n",
      "         [[ 4.4721e-01]],\n",
      "\n",
      "         [[ 2.2678e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0617e-01]],\n",
      "\n",
      "         [[-3.8956e-01]],\n",
      "\n",
      "         [[ 1.1411e-02]],\n",
      "\n",
      "         [[-3.1073e-01]],\n",
      "\n",
      "         [[-3.2632e-01]],\n",
      "\n",
      "         [[ 6.4194e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9875e-01]],\n",
      "\n",
      "         [[ 4.9030e-01]],\n",
      "\n",
      "         [[-1.2155e-02]],\n",
      "\n",
      "         [[ 9.7878e-02]],\n",
      "\n",
      "         [[ 3.6248e-01]],\n",
      "\n",
      "         [[ 2.7248e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2224e-01]],\n",
      "\n",
      "         [[ 1.2441e-01]],\n",
      "\n",
      "         [[ 1.1612e-01]],\n",
      "\n",
      "         [[-3.9898e-02]],\n",
      "\n",
      "         [[ 5.8298e-01]],\n",
      "\n",
      "         [[-1.7379e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0150e-01]],\n",
      "\n",
      "         [[ 5.0750e-01]],\n",
      "\n",
      "         [[ 9.3396e-02]],\n",
      "\n",
      "         [[ 2.4834e-01]],\n",
      "\n",
      "         [[ 7.4829e-01]],\n",
      "\n",
      "         [[ 1.5537e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5947e-01]],\n",
      "\n",
      "         [[-2.4482e-01]],\n",
      "\n",
      "         [[-2.5913e-02]],\n",
      "\n",
      "         [[-2.9527e-02]],\n",
      "\n",
      "         [[-3.6593e-02]],\n",
      "\n",
      "         [[-1.8860e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0034e-01]],\n",
      "\n",
      "         [[ 2.6077e-01]],\n",
      "\n",
      "         [[-1.3130e-01]],\n",
      "\n",
      "         [[ 2.1144e-01]],\n",
      "\n",
      "         [[ 4.3220e-01]],\n",
      "\n",
      "         [[ 3.8054e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4758e-01]],\n",
      "\n",
      "         [[ 5.5577e-01]],\n",
      "\n",
      "         [[ 3.0128e-02]],\n",
      "\n",
      "         [[-2.5752e-01]],\n",
      "\n",
      "         [[ 5.1738e-01]],\n",
      "\n",
      "         [[ 2.3096e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8143e-01]],\n",
      "\n",
      "         [[-1.3821e-02]],\n",
      "\n",
      "         [[ 8.3545e-02]],\n",
      "\n",
      "         [[-7.1191e-01]],\n",
      "\n",
      "         [[ 3.5327e-01]],\n",
      "\n",
      "         [[-3.3687e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.1886e-02]],\n",
      "\n",
      "         [[-1.5207e-01]],\n",
      "\n",
      "         [[ 2.5204e-01]],\n",
      "\n",
      "         [[ 1.3106e-01]],\n",
      "\n",
      "         [[-8.1965e-02]],\n",
      "\n",
      "         [[-2.0764e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5582e-01]],\n",
      "\n",
      "         [[ 5.6365e-01]],\n",
      "\n",
      "         [[ 9.4365e-02]],\n",
      "\n",
      "         [[-2.9762e-01]],\n",
      "\n",
      "         [[ 5.8981e-01]],\n",
      "\n",
      "         [[-1.0984e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9734e-01]],\n",
      "\n",
      "         [[-2.9281e-02]],\n",
      "\n",
      "         [[-7.8444e-03]],\n",
      "\n",
      "         [[ 7.6555e-02]],\n",
      "\n",
      "         [[ 5.5993e-01]],\n",
      "\n",
      "         [[-1.9580e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.0802e-01]],\n",
      "\n",
      "         [[ 7.3314e-01]],\n",
      "\n",
      "         [[ 7.0482e-02]],\n",
      "\n",
      "         [[ 3.0739e-01]],\n",
      "\n",
      "         [[ 7.6085e-01]],\n",
      "\n",
      "         [[ 2.4144e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.8489e-01]],\n",
      "\n",
      "         [[ 4.2213e-01]],\n",
      "\n",
      "         [[-4.6523e-02]],\n",
      "\n",
      "         [[-3.0411e-01]],\n",
      "\n",
      "         [[ 3.5928e-01]],\n",
      "\n",
      "         [[-1.4527e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4610e-01]],\n",
      "\n",
      "         [[-3.4549e-01]],\n",
      "\n",
      "         [[ 1.8393e-01]],\n",
      "\n",
      "         [[-7.9026e-02]],\n",
      "\n",
      "         [[-1.7133e-01]],\n",
      "\n",
      "         [[-2.9673e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.5957e-02]],\n",
      "\n",
      "         [[-9.2339e-02]],\n",
      "\n",
      "         [[ 2.5822e-01]],\n",
      "\n",
      "         [[-7.6375e-03]],\n",
      "\n",
      "         [[ 1.1998e-01]],\n",
      "\n",
      "         [[ 3.4919e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2906e-01]],\n",
      "\n",
      "         [[-1.1479e-01]],\n",
      "\n",
      "         [[ 1.6797e-01]],\n",
      "\n",
      "         [[-2.8449e-01]],\n",
      "\n",
      "         [[-2.2831e-01]],\n",
      "\n",
      "         [[ 3.5437e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.0200e-02]],\n",
      "\n",
      "         [[ 5.1828e-02]],\n",
      "\n",
      "         [[ 3.8364e-01]],\n",
      "\n",
      "         [[-2.0223e-02]],\n",
      "\n",
      "         [[-3.7492e-01]],\n",
      "\n",
      "         [[-1.2483e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7775e-01]],\n",
      "\n",
      "         [[ 4.7558e-01]],\n",
      "\n",
      "         [[ 1.2464e-01]],\n",
      "\n",
      "         [[-2.1715e-01]],\n",
      "\n",
      "         [[ 1.6024e-01]],\n",
      "\n",
      "         [[ 4.8433e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6025e-01]],\n",
      "\n",
      "         [[-9.6566e-02]],\n",
      "\n",
      "         [[-8.3694e-02]],\n",
      "\n",
      "         [[-3.7978e-01]],\n",
      "\n",
      "         [[ 1.5380e-01]],\n",
      "\n",
      "         [[-7.9579e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 7.9871e-01]],\n",
      "\n",
      "         [[ 5.2184e-01]],\n",
      "\n",
      "         [[ 6.1645e-02]],\n",
      "\n",
      "         [[ 8.0491e-02]],\n",
      "\n",
      "         [[ 3.6463e-01]],\n",
      "\n",
      "         [[ 1.2831e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6868e-01]],\n",
      "\n",
      "         [[ 2.5328e-01]],\n",
      "\n",
      "         [[ 2.2657e-01]],\n",
      "\n",
      "         [[ 1.2061e-01]],\n",
      "\n",
      "         [[-1.2950e-01]],\n",
      "\n",
      "         [[ 2.9789e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3983e-01]],\n",
      "\n",
      "         [[ 4.3243e-01]],\n",
      "\n",
      "         [[-8.5705e-02]],\n",
      "\n",
      "         [[ 3.6685e-02]],\n",
      "\n",
      "         [[ 8.0431e-01]],\n",
      "\n",
      "         [[ 2.2458e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9380e-01]],\n",
      "\n",
      "         [[ 5.5377e-01]],\n",
      "\n",
      "         [[ 2.7913e-01]],\n",
      "\n",
      "         [[-3.7427e-01]],\n",
      "\n",
      "         [[ 7.2774e-01]],\n",
      "\n",
      "         [[ 2.6167e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.2089e-01]],\n",
      "\n",
      "         [[-2.6229e-01]],\n",
      "\n",
      "         [[-7.2207e-02]],\n",
      "\n",
      "         [[-9.9166e-02]],\n",
      "\n",
      "         [[-2.9853e-01]],\n",
      "\n",
      "         [[ 1.3900e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1441e-02]],\n",
      "\n",
      "         [[-1.1807e-01]],\n",
      "\n",
      "         [[ 2.1290e-01]],\n",
      "\n",
      "         [[-4.7396e-01]],\n",
      "\n",
      "         [[ 1.7560e-01]],\n",
      "\n",
      "         [[-1.1224e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6102e-01]],\n",
      "\n",
      "         [[ 2.1706e-01]],\n",
      "\n",
      "         [[-6.5855e-02]],\n",
      "\n",
      "         [[-2.8115e-01]],\n",
      "\n",
      "         [[ 6.9399e-01]],\n",
      "\n",
      "         [[-1.2711e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5131e-01]],\n",
      "\n",
      "         [[ 1.0190e-01]],\n",
      "\n",
      "         [[ 2.3259e-01]],\n",
      "\n",
      "         [[-2.6772e-01]],\n",
      "\n",
      "         [[ 1.2068e-01]],\n",
      "\n",
      "         [[ 3.1331e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2643e-01]],\n",
      "\n",
      "         [[ 1.0413e-01]],\n",
      "\n",
      "         [[ 2.8610e-02]],\n",
      "\n",
      "         [[-2.2003e-01]],\n",
      "\n",
      "         [[ 9.7403e-02]],\n",
      "\n",
      "         [[ 1.5649e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1001e-01]],\n",
      "\n",
      "         [[ 4.8108e-02]],\n",
      "\n",
      "         [[-1.3136e-01]],\n",
      "\n",
      "         [[ 2.1679e-01]],\n",
      "\n",
      "         [[ 9.0540e-01]],\n",
      "\n",
      "         [[ 7.0118e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9663e-01]],\n",
      "\n",
      "         [[ 2.6055e-01]],\n",
      "\n",
      "         [[ 3.4672e-02]],\n",
      "\n",
      "         [[ 2.8784e-02]],\n",
      "\n",
      "         [[ 7.8614e-01]],\n",
      "\n",
      "         [[-3.1641e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4053e-01]],\n",
      "\n",
      "         [[ 3.9691e-01]],\n",
      "\n",
      "         [[ 6.3372e-02]],\n",
      "\n",
      "         [[-2.3722e-01]],\n",
      "\n",
      "         [[ 6.9865e-01]],\n",
      "\n",
      "         [[ 3.2333e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5254e-01]],\n",
      "\n",
      "         [[ 5.7072e-01]],\n",
      "\n",
      "         [[ 5.1644e-02]],\n",
      "\n",
      "         [[ 3.3807e-01]],\n",
      "\n",
      "         [[ 6.9403e-01]],\n",
      "\n",
      "         [[ 4.9741e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6999e-01]],\n",
      "\n",
      "         [[ 2.1022e-01]],\n",
      "\n",
      "         [[-5.6844e-02]],\n",
      "\n",
      "         [[ 1.9217e-01]],\n",
      "\n",
      "         [[ 2.8429e-01]],\n",
      "\n",
      "         [[ 2.7517e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4612e-01]],\n",
      "\n",
      "         [[ 4.1935e-01]],\n",
      "\n",
      "         [[ 5.1760e-02]],\n",
      "\n",
      "         [[-6.1055e-01]],\n",
      "\n",
      "         [[ 6.4228e-01]],\n",
      "\n",
      "         [[ 2.5507e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9681e-01]],\n",
      "\n",
      "         [[ 8.5426e-02]],\n",
      "\n",
      "         [[ 5.7113e-03]],\n",
      "\n",
      "         [[-3.4988e-03]],\n",
      "\n",
      "         [[-3.4344e-01]],\n",
      "\n",
      "         [[-2.1866e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.5593e-01]],\n",
      "\n",
      "         [[ 6.3970e-01]],\n",
      "\n",
      "         [[ 6.7495e-03]],\n",
      "\n",
      "         [[ 3.3887e-01]],\n",
      "\n",
      "         [[ 2.2726e-01]],\n",
      "\n",
      "         [[-1.0096e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9993e-01]],\n",
      "\n",
      "         [[ 5.0849e-01]],\n",
      "\n",
      "         [[-3.3983e-02]],\n",
      "\n",
      "         [[ 2.6058e-01]],\n",
      "\n",
      "         [[ 6.4612e-01]],\n",
      "\n",
      "         [[ 6.7716e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7816e-01]],\n",
      "\n",
      "         [[ 5.5469e-01]],\n",
      "\n",
      "         [[ 2.2047e-01]],\n",
      "\n",
      "         [[-4.2627e-03]],\n",
      "\n",
      "         [[ 8.4469e-01]],\n",
      "\n",
      "         [[ 1.4236e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3853e-02]],\n",
      "\n",
      "         [[ 4.3946e-01]],\n",
      "\n",
      "         [[ 8.0607e-02]],\n",
      "\n",
      "         [[-1.7382e-01]],\n",
      "\n",
      "         [[ 2.7703e-01]],\n",
      "\n",
      "         [[ 5.6873e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.9972e-02]],\n",
      "\n",
      "         [[-2.0889e-01]],\n",
      "\n",
      "         [[ 2.7902e-01]],\n",
      "\n",
      "         [[ 3.6599e-01]],\n",
      "\n",
      "         [[ 2.7383e-01]],\n",
      "\n",
      "         [[ 1.1642e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5754e-01]],\n",
      "\n",
      "         [[ 3.7238e-01]],\n",
      "\n",
      "         [[-8.1003e-02]],\n",
      "\n",
      "         [[ 3.7592e-02]],\n",
      "\n",
      "         [[ 4.9432e-01]],\n",
      "\n",
      "         [[ 1.2318e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8817e-02]],\n",
      "\n",
      "         [[ 6.2196e-01]],\n",
      "\n",
      "         [[ 8.0790e-02]],\n",
      "\n",
      "         [[-2.6210e-01]],\n",
      "\n",
      "         [[ 3.9154e-01]],\n",
      "\n",
      "         [[-1.6215e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9016e-01]],\n",
      "\n",
      "         [[ 2.2187e-01]],\n",
      "\n",
      "         [[ 1.6383e-02]],\n",
      "\n",
      "         [[ 1.9646e-01]],\n",
      "\n",
      "         [[ 8.0105e-01]],\n",
      "\n",
      "         [[ 3.8878e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.7300e-02]],\n",
      "\n",
      "         [[-2.3604e-01]],\n",
      "\n",
      "         [[ 1.0329e-02]],\n",
      "\n",
      "         [[ 2.0331e-01]],\n",
      "\n",
      "         [[-7.3543e-02]],\n",
      "\n",
      "         [[ 1.1068e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3433e-01]],\n",
      "\n",
      "         [[ 2.8994e-01]],\n",
      "\n",
      "         [[ 6.2247e-02]],\n",
      "\n",
      "         [[-2.7134e-01]],\n",
      "\n",
      "         [[ 7.3442e-01]],\n",
      "\n",
      "         [[ 1.3724e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9333e-01]],\n",
      "\n",
      "         [[ 5.7203e-01]],\n",
      "\n",
      "         [[ 2.7778e-01]],\n",
      "\n",
      "         [[-5.4765e-02]],\n",
      "\n",
      "         [[ 3.7224e-01]],\n",
      "\n",
      "         [[-1.2236e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.6277e-01]],\n",
      "\n",
      "         [[-5.8774e-01]],\n",
      "\n",
      "         [[-6.2983e-03]],\n",
      "\n",
      "         [[-2.3205e-01]],\n",
      "\n",
      "         [[-8.2754e-02]],\n",
      "\n",
      "         [[ 4.6778e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9673e-01]],\n",
      "\n",
      "         [[ 4.4204e-01]],\n",
      "\n",
      "         [[ 1.5470e-01]],\n",
      "\n",
      "         [[-7.2210e-02]],\n",
      "\n",
      "         [[ 2.6459e-01]],\n",
      "\n",
      "         [[ 1.5734e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7300e-02]],\n",
      "\n",
      "         [[-3.0748e-01]],\n",
      "\n",
      "         [[-2.5030e-02]],\n",
      "\n",
      "         [[ 5.7715e-01]],\n",
      "\n",
      "         [[ 8.8139e-02]],\n",
      "\n",
      "         [[ 7.1040e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2984e-01]],\n",
      "\n",
      "         [[ 7.4019e-01]],\n",
      "\n",
      "         [[ 1.5380e-01]],\n",
      "\n",
      "         [[-2.7013e-01]],\n",
      "\n",
      "         [[ 2.7558e-01]],\n",
      "\n",
      "         [[ 8.4647e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6569e-01]],\n",
      "\n",
      "         [[ 3.3306e-01]],\n",
      "\n",
      "         [[ 2.1939e-01]],\n",
      "\n",
      "         [[-9.6116e-02]],\n",
      "\n",
      "         [[ 2.2042e-01]],\n",
      "\n",
      "         [[ 2.9221e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5154e-01]],\n",
      "\n",
      "         [[ 3.5118e-01]],\n",
      "\n",
      "         [[ 2.4124e-02]],\n",
      "\n",
      "         [[-1.0532e-01]],\n",
      "\n",
      "         [[ 7.2084e-01]],\n",
      "\n",
      "         [[-3.0421e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7539e-01]],\n",
      "\n",
      "         [[ 5.3229e-01]],\n",
      "\n",
      "         [[ 9.0719e-02]],\n",
      "\n",
      "         [[-9.4727e-02]],\n",
      "\n",
      "         [[ 5.7570e-01]],\n",
      "\n",
      "         [[ 6.7499e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5958e-01]],\n",
      "\n",
      "         [[ 2.0714e-01]],\n",
      "\n",
      "         [[-1.6046e-02]],\n",
      "\n",
      "         [[-1.9835e-01]],\n",
      "\n",
      "         [[ 5.8802e-01]],\n",
      "\n",
      "         [[ 1.5267e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.9191e-01]],\n",
      "\n",
      "         [[-5.1254e-01]],\n",
      "\n",
      "         [[ 7.2566e-01]],\n",
      "\n",
      "         [[-2.5566e-01]],\n",
      "\n",
      "         [[-2.9226e-01]],\n",
      "\n",
      "         [[-1.5434e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4877e-02]],\n",
      "\n",
      "         [[-1.1370e-01]],\n",
      "\n",
      "         [[ 2.7475e-01]],\n",
      "\n",
      "         [[ 3.7029e-01]],\n",
      "\n",
      "         [[ 1.8340e-01]],\n",
      "\n",
      "         [[-8.3746e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.8461e-01]],\n",
      "\n",
      "         [[ 4.5695e-01]],\n",
      "\n",
      "         [[ 8.6286e-02]],\n",
      "\n",
      "         [[-4.6243e-02]],\n",
      "\n",
      "         [[ 5.2240e-01]],\n",
      "\n",
      "         [[ 2.1620e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0378e-01]],\n",
      "\n",
      "         [[ 4.9455e-01]],\n",
      "\n",
      "         [[ 5.9335e-02]],\n",
      "\n",
      "         [[ 8.1059e-02]],\n",
      "\n",
      "         [[ 6.5831e-01]],\n",
      "\n",
      "         [[ 2.3947e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0542e-01]],\n",
      "\n",
      "         [[ 3.9127e-01]],\n",
      "\n",
      "         [[-3.0274e-02]],\n",
      "\n",
      "         [[ 2.0954e-01]],\n",
      "\n",
      "         [[ 5.0359e-01]],\n",
      "\n",
      "         [[-1.3397e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6350e-01]],\n",
      "\n",
      "         [[ 3.2400e-01]],\n",
      "\n",
      "         [[-9.6508e-02]],\n",
      "\n",
      "         [[ 1.4047e-01]],\n",
      "\n",
      "         [[ 4.0867e-01]],\n",
      "\n",
      "         [[ 9.3412e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2900e-01]],\n",
      "\n",
      "         [[ 1.8017e-01]],\n",
      "\n",
      "         [[-7.8590e-02]],\n",
      "\n",
      "         [[ 5.3425e-01]],\n",
      "\n",
      "         [[ 5.1437e-01]],\n",
      "\n",
      "         [[ 7.4770e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6482e-01]],\n",
      "\n",
      "         [[ 6.7993e-01]],\n",
      "\n",
      "         [[ 9.7041e-02]],\n",
      "\n",
      "         [[ 3.8261e-01]],\n",
      "\n",
      "         [[ 8.0105e-01]],\n",
      "\n",
      "         [[-1.7510e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0412e-01]],\n",
      "\n",
      "         [[-1.6068e-01]],\n",
      "\n",
      "         [[ 2.7546e-01]],\n",
      "\n",
      "         [[ 1.3732e-01]],\n",
      "\n",
      "         [[-7.4941e-02]],\n",
      "\n",
      "         [[-1.0782e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0535e-01]],\n",
      "\n",
      "         [[ 5.1945e-01]],\n",
      "\n",
      "         [[-1.4375e-01]],\n",
      "\n",
      "         [[ 4.7917e-02]],\n",
      "\n",
      "         [[ 5.1390e-01]],\n",
      "\n",
      "         [[ 1.5948e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.1553e-01]],\n",
      "\n",
      "         [[-7.8423e-01]],\n",
      "\n",
      "         [[-4.0696e-03]],\n",
      "\n",
      "         [[ 7.7752e-01]],\n",
      "\n",
      "         [[-9.2469e-01]],\n",
      "\n",
      "         [[-9.6148e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.3796e-02]],\n",
      "\n",
      "         [[ 7.9919e-02]],\n",
      "\n",
      "         [[ 6.4156e-01]],\n",
      "\n",
      "         [[-1.1080e-01]],\n",
      "\n",
      "         [[-8.9658e-02]],\n",
      "\n",
      "         [[ 2.6256e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5703e-02]],\n",
      "\n",
      "         [[ 4.6927e-01]],\n",
      "\n",
      "         [[ 2.6039e-01]],\n",
      "\n",
      "         [[ 4.5388e-02]],\n",
      "\n",
      "         [[ 2.8454e-01]],\n",
      "\n",
      "         [[ 4.1751e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2733e-01]],\n",
      "\n",
      "         [[ 3.6203e-01]],\n",
      "\n",
      "         [[ 2.3727e-02]],\n",
      "\n",
      "         [[-1.1785e-01]],\n",
      "\n",
      "         [[ 6.5733e-01]],\n",
      "\n",
      "         [[-1.1467e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5193e-01]],\n",
      "\n",
      "         [[ 3.0032e-01]],\n",
      "\n",
      "         [[-4.5543e-02]],\n",
      "\n",
      "         [[-3.5420e-01]],\n",
      "\n",
      "         [[ 4.3813e-01]],\n",
      "\n",
      "         [[ 3.1138e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8863e-01]],\n",
      "\n",
      "         [[ 3.5988e-01]],\n",
      "\n",
      "         [[ 7.9285e-02]],\n",
      "\n",
      "         [[ 7.9847e-02]],\n",
      "\n",
      "         [[ 1.8984e-01]],\n",
      "\n",
      "         [[-1.4627e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3483e-01]],\n",
      "\n",
      "         [[ 3.3909e-01]],\n",
      "\n",
      "         [[-1.6669e-02]],\n",
      "\n",
      "         [[ 2.1088e-01]],\n",
      "\n",
      "         [[ 4.1194e-01]],\n",
      "\n",
      "         [[-1.4033e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8676e-01]],\n",
      "\n",
      "         [[ 8.7388e-02]],\n",
      "\n",
      "         [[ 5.3081e-01]],\n",
      "\n",
      "         [[-2.0737e-01]],\n",
      "\n",
      "         [[ 4.7794e-01]],\n",
      "\n",
      "         [[ 2.3359e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7021e-02]],\n",
      "\n",
      "         [[-3.9278e-02]],\n",
      "\n",
      "         [[-2.0524e-01]],\n",
      "\n",
      "         [[ 1.2195e-03]],\n",
      "\n",
      "         [[ 2.4796e-01]],\n",
      "\n",
      "         [[ 6.7456e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4540e-02]],\n",
      "\n",
      "         [[-6.3523e-02]],\n",
      "\n",
      "         [[-1.3964e-01]],\n",
      "\n",
      "         [[-7.2374e-02]],\n",
      "\n",
      "         [[-4.8432e-01]],\n",
      "\n",
      "         [[ 1.7073e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1506e-01]],\n",
      "\n",
      "         [[-3.4608e-01]],\n",
      "\n",
      "         [[ 3.7267e-02]],\n",
      "\n",
      "         [[ 1.0243e+00]],\n",
      "\n",
      "         [[-2.9749e-01]],\n",
      "\n",
      "         [[-3.7367e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0127e-01]],\n",
      "\n",
      "         [[ 3.1573e-01]],\n",
      "\n",
      "         [[-6.6692e-02]],\n",
      "\n",
      "         [[-2.2333e-01]],\n",
      "\n",
      "         [[ 5.8399e-01]],\n",
      "\n",
      "         [[ 4.0994e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0642e-01]],\n",
      "\n",
      "         [[ 4.6583e-01]],\n",
      "\n",
      "         [[ 5.5930e-02]],\n",
      "\n",
      "         [[ 1.0201e-02]],\n",
      "\n",
      "         [[ 6.0910e-01]],\n",
      "\n",
      "         [[-9.7072e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.5466e-01]],\n",
      "\n",
      "         [[-2.7997e-01]],\n",
      "\n",
      "         [[ 6.7154e-01]],\n",
      "\n",
      "         [[-8.1119e-02]],\n",
      "\n",
      "         [[-6.7314e-01]],\n",
      "\n",
      "         [[-5.0218e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5468e-01]],\n",
      "\n",
      "         [[-4.5696e-02]],\n",
      "\n",
      "         [[-3.9706e-04]],\n",
      "\n",
      "         [[-1.0302e-02]],\n",
      "\n",
      "         [[ 5.5066e-01]],\n",
      "\n",
      "         [[ 1.0700e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.7651e-02]],\n",
      "\n",
      "         [[-1.6516e-01]],\n",
      "\n",
      "         [[ 2.0989e-01]],\n",
      "\n",
      "         [[ 4.1969e-02]],\n",
      "\n",
      "         [[-7.6561e-02]],\n",
      "\n",
      "         [[ 5.3826e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6155e-01]],\n",
      "\n",
      "         [[ 5.9559e-01]],\n",
      "\n",
      "         [[ 3.6236e-03]],\n",
      "\n",
      "         [[ 4.5456e-01]],\n",
      "\n",
      "         [[ 7.0742e-01]],\n",
      "\n",
      "         [[ 7.3154e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8550e-01]],\n",
      "\n",
      "         [[ 3.2663e-01]],\n",
      "\n",
      "         [[ 2.3506e-03]],\n",
      "\n",
      "         [[ 3.4641e-03]],\n",
      "\n",
      "         [[ 6.0368e-01]],\n",
      "\n",
      "         [[ 3.0790e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3225e-01]],\n",
      "\n",
      "         [[-1.0777e-02]],\n",
      "\n",
      "         [[ 3.2390e-02]],\n",
      "\n",
      "         [[-4.1907e-02]],\n",
      "\n",
      "         [[ 3.3505e-01]],\n",
      "\n",
      "         [[ 7.4500e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.7711e-01]],\n",
      "\n",
      "         [[-2.9733e-01]],\n",
      "\n",
      "         [[-1.0349e-02]],\n",
      "\n",
      "         [[-1.1215e-01]],\n",
      "\n",
      "         [[ 2.6555e-02]],\n",
      "\n",
      "         [[ 1.1211e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4684e-01]],\n",
      "\n",
      "         [[ 1.7415e-01]],\n",
      "\n",
      "         [[ 1.3292e-01]],\n",
      "\n",
      "         [[-7.5921e-01]],\n",
      "\n",
      "         [[ 3.5238e-01]],\n",
      "\n",
      "         [[ 6.8138e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.8795e-01]],\n",
      "\n",
      "         [[-1.5292e-01]],\n",
      "\n",
      "         [[-2.5327e-01]],\n",
      "\n",
      "         [[-2.1270e-01]],\n",
      "\n",
      "         [[-1.0842e-02]],\n",
      "\n",
      "         [[-1.4345e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0606e-01]],\n",
      "\n",
      "         [[ 5.7244e-01]],\n",
      "\n",
      "         [[ 8.6374e-02]],\n",
      "\n",
      "         [[-5.1891e-01]],\n",
      "\n",
      "         [[ 4.4930e-01]],\n",
      "\n",
      "         [[ 1.7173e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.2202e-01]],\n",
      "\n",
      "         [[-1.7737e-01]],\n",
      "\n",
      "         [[-4.9041e-02]],\n",
      "\n",
      "         [[-1.4000e-01]],\n",
      "\n",
      "         [[-6.8579e-01]],\n",
      "\n",
      "         [[-8.5608e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8230e-01]],\n",
      "\n",
      "         [[ 4.9760e-01]],\n",
      "\n",
      "         [[ 4.7140e-02]],\n",
      "\n",
      "         [[ 1.7685e-03]],\n",
      "\n",
      "         [[ 8.3854e-01]],\n",
      "\n",
      "         [[-5.3035e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0509e-01]],\n",
      "\n",
      "         [[ 3.1577e-02]],\n",
      "\n",
      "         [[ 9.9976e-02]],\n",
      "\n",
      "         [[ 2.0100e-01]],\n",
      "\n",
      "         [[ 4.7176e-01]],\n",
      "\n",
      "         [[-2.0194e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8334e-01]],\n",
      "\n",
      "         [[ 1.5659e-01]],\n",
      "\n",
      "         [[-9.9829e-03]],\n",
      "\n",
      "         [[ 2.7666e-01]],\n",
      "\n",
      "         [[ 5.0683e-01]],\n",
      "\n",
      "         [[-1.7247e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0656e-01]],\n",
      "\n",
      "         [[-1.4307e-01]],\n",
      "\n",
      "         [[-1.6755e-01]],\n",
      "\n",
      "         [[-3.6369e-01]],\n",
      "\n",
      "         [[ 2.8392e-01]],\n",
      "\n",
      "         [[ 3.5937e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9806e-01]],\n",
      "\n",
      "         [[-5.5159e-01]],\n",
      "\n",
      "         [[-3.5882e-02]],\n",
      "\n",
      "         [[-4.4614e-01]],\n",
      "\n",
      "         [[-2.3917e-01]],\n",
      "\n",
      "         [[ 1.6890e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0913,  0.0069,  0.3370,  0.5101,  0.3355,  0.5341, -0.3425,  0.4551,\n",
      "        -0.4558, -0.5989,  0.4964,  0.4582,  0.1886,  0.4088,  0.4940,  0.4861,\n",
      "         0.4409, -0.8214,  0.5064,  0.5729,  0.4125, -0.2800, -0.0726, -0.6796,\n",
      "         0.6287, -0.1799,  0.2470,  0.3081,  0.1308,  0.2081, -0.3393,  0.6954,\n",
      "        -0.2362, -0.2244,  0.2396, -0.2207, -0.1745,  0.4256,  0.5721,  0.1520,\n",
      "         0.3181,  0.4034, -0.1726, -0.4764,  0.5105,  0.5066,  0.1759, -0.1431,\n",
      "         0.5367, -0.1952,  0.0725, -0.1622,  0.2566,  0.3287,  0.6428, -0.2828,\n",
      "         0.2385,  0.3379,  0.1404, -0.0314,  0.4901,  0.1038,  0.6249,  0.3125,\n",
      "        -0.2130, -0.1283, -0.3162, -0.4034,  0.1623, -0.2543,  0.3428, -0.0587,\n",
      "         0.3760,  0.6833, -0.4617,  0.1226,  0.1993,  0.1187, -0.0556,  0.2691,\n",
      "         0.3715,  0.4004,  0.4881,  0.2156,  0.6253, -0.2632,  0.3142,  0.5337,\n",
      "         0.6171,  0.2949,  0.0890,  0.2888,  0.3643,  0.2565, -0.4005,  0.5660,\n",
      "         0.3376, -0.1162,  0.2129, -0.2463,  0.2539,  0.1797,  0.5321,  0.3864,\n",
      "         0.2385, -0.2595, -0.1436,  0.5061,  0.4590,  0.4960,  0.3767,  0.3691,\n",
      "         0.4392, -0.3382,  0.3522, -0.6202, -0.1155,  0.1148,  0.4659,  0.4054,\n",
      "         0.2926,  0.4686,  0.4643,  0.0460, -0.3078, -0.1385,  0.6434,  0.5583,\n",
      "        -0.4372,  0.1195, -0.2656,  0.5955,  0.4101,  0.2883, -0.2920,  0.0809,\n",
      "        -0.0474,  0.2383, -0.4456,  0.3501,  0.1444,  0.2225,  0.0415, -0.3278],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0368]],\n",
      "\n",
      "         [[ 0.3809]],\n",
      "\n",
      "         [[-0.1918]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3639]],\n",
      "\n",
      "         [[-0.0312]],\n",
      "\n",
      "         [[ 0.0686]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5347]],\n",
      "\n",
      "         [[ 0.4420]],\n",
      "\n",
      "         [[ 0.0942]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2601]],\n",
      "\n",
      "         [[ 0.2662]],\n",
      "\n",
      "         [[ 0.5076]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5642]],\n",
      "\n",
      "         [[ 0.0305]],\n",
      "\n",
      "         [[-0.1797]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6892]],\n",
      "\n",
      "         [[-0.2138]],\n",
      "\n",
      "         [[-0.0455]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1475]],\n",
      "\n",
      "         [[-0.1183]],\n",
      "\n",
      "         [[-0.0163]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2376]],\n",
      "\n",
      "         [[-0.2633]],\n",
      "\n",
      "         [[-0.1938]]],\n",
      "\n",
      "\n",
      "        [[[-0.0898]],\n",
      "\n",
      "         [[ 0.4221]],\n",
      "\n",
      "         [[ 0.0238]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4502]],\n",
      "\n",
      "         [[ 0.5742]],\n",
      "\n",
      "         [[ 0.0541]]],\n",
      "\n",
      "\n",
      "        [[[-0.2352]],\n",
      "\n",
      "         [[-0.1577]],\n",
      "\n",
      "         [[-0.1036]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3964]],\n",
      "\n",
      "         [[ 0.2445]],\n",
      "\n",
      "         [[-0.0230]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([9.5991, 6.6859, 7.5453, 6.2708, 5.4490, 7.8782, 3.5968, 6.2940, 5.0383,\n",
      "        7.2127, 4.8604, 5.4376, 5.9620, 5.8757, 4.9983, 4.7008, 5.6414, 7.1384,\n",
      "        3.0282, 8.4528, 3.7107, 5.7552, 7.9952, 7.1504, 5.9041, 4.9829, 5.6525,\n",
      "        6.5716, 5.8262, 8.0205, 6.8623, 6.3378], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.0202, -0.0048, -0.0094,  0.0230,  0.0005, -0.0166, -0.0129,  0.0256,\n",
      "         0.0149,  0.0253, -0.0133, -0.0106,  0.0085,  0.0097, -0.0140,  0.0006,\n",
      "        -0.0359, -0.0473,  0.0261,  0.0395,  0.0206, -0.0303,  0.0255,  0.0175,\n",
      "        -0.0180,  0.0037, -0.0496,  0.0028, -0.0021, -0.0191, -0.0030,  0.0111],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1957]],\n",
      "\n",
      "         [[ 0.0818]],\n",
      "\n",
      "         [[ 0.5328]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3375]],\n",
      "\n",
      "         [[ 0.1007]],\n",
      "\n",
      "         [[-0.2979]]],\n",
      "\n",
      "\n",
      "        [[[-0.1830]],\n",
      "\n",
      "         [[-0.1532]],\n",
      "\n",
      "         [[ 0.3090]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3426]],\n",
      "\n",
      "         [[-0.2625]],\n",
      "\n",
      "         [[-0.0880]]],\n",
      "\n",
      "\n",
      "        [[[-0.0328]],\n",
      "\n",
      "         [[ 0.3775]],\n",
      "\n",
      "         [[ 0.6631]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0420]],\n",
      "\n",
      "         [[-0.2713]],\n",
      "\n",
      "         [[-0.0862]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.6657]],\n",
      "\n",
      "         [[ 0.0653]],\n",
      "\n",
      "         [[ 0.3812]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1116]],\n",
      "\n",
      "         [[-0.1911]],\n",
      "\n",
      "         [[ 0.1009]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7226]],\n",
      "\n",
      "         [[ 0.4411]],\n",
      "\n",
      "         [[ 0.0936]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0531]],\n",
      "\n",
      "         [[-0.0524]],\n",
      "\n",
      "         [[-0.3525]]],\n",
      "\n",
      "\n",
      "        [[[-0.1529]],\n",
      "\n",
      "         [[-0.0562]],\n",
      "\n",
      "         [[ 0.1860]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3637]],\n",
      "\n",
      "         [[ 0.3677]],\n",
      "\n",
      "         [[ 0.7055]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.1203e+00, -2.1997e-01,  5.6686e-01,  4.1900e+00,  8.3415e-01,\n",
      "         1.7367e+00,  1.5761e-01,  2.8902e+00,  8.8717e-01,  1.3327e+00,\n",
      "         1.1804e+00,  1.5116e+00,  2.2519e+00,  2.4067e+00,  3.3214e+00,\n",
      "         2.3714e+00,  1.4854e+00,  1.2813e+00,  2.7940e+00,  7.5537e-01,\n",
      "         1.0225e+00, -7.8098e-04,  5.2200e+00,  2.9006e+00,  1.3263e+00,\n",
      "         1.6406e+00,  1.3211e+00,  5.8497e-01,  6.3635e-01,  1.3257e+00,\n",
      "         1.0936e+00,  2.4049e+00,  2.2518e+00,  2.2925e+00,  1.6758e+00,\n",
      "         1.1965e+00,  2.1237e+00,  8.1255e-01,  6.4893e-01,  1.3233e+00,\n",
      "         1.8920e+00,  1.0582e+00,  8.3108e-01,  1.5772e+00,  9.5851e-01,\n",
      "         9.6644e-01, -1.4882e-01,  2.1343e+00,  2.2532e+00,  1.4402e+00,\n",
      "         3.0953e+00,  2.2258e+00,  1.0548e+00,  9.0060e-01,  1.2919e+00,\n",
      "         1.8787e+00,  2.9343e-01,  1.1050e+00,  1.6338e+00,  1.0660e+00,\n",
      "         1.3093e+00,  2.7042e+00,  1.5915e+00,  2.9401e+00,  3.7540e+00,\n",
      "         2.7371e+00,  5.8897e-01,  7.7112e-01,  2.2961e+00,  3.7987e-01,\n",
      "         1.8406e+00,  2.4475e+00,  1.2619e+00,  1.7553e+00,  1.2695e+00,\n",
      "         1.1002e+00,  2.6291e+00,  1.1052e+00,  2.1965e-01,  1.1943e+00,\n",
      "         1.3628e-02,  5.8571e-01,  1.8706e+00,  7.8131e-01,  1.4243e+00,\n",
      "         3.3511e-01,  1.3689e+00,  2.1467e-01,  2.1977e-01,  7.5766e-01,\n",
      "         1.6437e+00,  8.8640e-01,  6.0774e-01,  4.4819e-01,  2.0924e+00,\n",
      "         1.7883e+00,  2.1759e+00,  6.7635e-01,  7.6122e-01,  2.7921e-01,\n",
      "         1.4521e+00,  2.6896e+00,  1.3783e+00,  2.0083e+00,  5.1628e-01,\n",
      "         1.7214e+00,  1.1876e+00,  1.1016e+00,  1.0497e+00,  1.4988e+00,\n",
      "         1.2599e+00,  5.4065e-01,  2.7991e-01,  1.5334e+00,  1.0896e+00,\n",
      "         3.0602e+00,  1.4252e+00,  1.7494e+00,  1.0734e+00,  1.1750e+00,\n",
      "         1.2441e+00,  2.6678e+00,  1.7496e+00,  9.9222e-01,  1.6011e+00,\n",
      "         1.9836e+00,  7.1590e-01,  3.5272e-01,  9.1209e-01,  1.5333e+00,\n",
      "         1.2562e+00,  2.0902e+00,  1.7347e+00,  2.9513e-01,  1.0302e+00,\n",
      "         1.0296e+00,  9.0191e-01,  6.6792e-01,  1.0295e+00,  1.8525e+00,\n",
      "         1.2938e+00,  9.4447e-01,  3.1192e+00,  1.0326e+00,  5.8882e-01,\n",
      "         1.2723e+00,  1.9319e+00,  1.1939e+00,  2.5380e+00,  2.0057e+00,\n",
      "         4.5595e-01,  1.1575e+00,  9.7367e-01,  1.5465e+00,  1.4644e+00,\n",
      "         1.9992e-01,  6.8479e-01,  7.6306e-01,  6.2177e-01,  5.8450e-01,\n",
      "         1.3449e+00,  2.2471e+00,  5.6689e-01,  4.2899e+00,  2.9059e+00,\n",
      "         3.0926e-01,  1.1503e+00,  7.6861e-01,  1.4668e+00,  1.0837e+00,\n",
      "         1.8718e+00,  2.3731e+00,  6.6846e-01,  1.4719e+00,  1.8552e+00,\n",
      "         6.4676e-01,  5.1799e-01,  4.6461e-01,  8.8098e-01,  1.4223e+00,\n",
      "         1.3263e+00,  1.5050e+00,  8.3847e-01,  6.6693e-01,  1.9418e+00,\n",
      "         1.0499e+00,  2.5381e+00,  1.6065e+00,  1.7335e+00,  1.5502e+00,\n",
      "         2.3158e+00,  1.3427e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.5346, -0.2422,  0.0373, -5.7507, -0.4971, -2.4163,  0.2566, -4.4817,\n",
      "         0.2596, -0.1374, -1.9762, -0.9884, -1.3492, -0.2664, -3.1483,  0.6381,\n",
      "         0.8254, -1.4214, -2.7788,  1.0932,  2.9477, -0.0439,  3.8106, -2.7791,\n",
      "         0.6532, -0.8232,  1.0847,  0.9151, -1.0637, -1.5074, -0.0874,  2.3554,\n",
      "        -0.4852, -1.8570,  0.6599,  1.5446, -0.5233,  0.0942,  1.2999,  2.7761,\n",
      "        -0.0122,  0.2654,  1.2781,  2.4866, -0.5734, -0.6401, -0.3702,  1.9700,\n",
      "         3.3749,  3.0189, -0.4019, -0.8613, -0.5009,  2.5025,  1.3008,  0.7537,\n",
      "         0.3627,  1.2689,  3.1166,  2.3482, -1.2682,  1.0439, -0.8863, -1.9427,\n",
      "        -4.0830, -0.7176,  1.2897, -0.0623,  1.7263,  1.9252,  2.5439, -0.7772,\n",
      "         1.6859,  1.4894,  0.1637,  0.2826, -0.6508,  1.0723,  0.3204, -0.2749,\n",
      "        -0.8909, -0.5225, -4.3621,  0.7769, -0.4651,  0.0794,  2.1709,  0.1961,\n",
      "         0.4015,  1.5558, -0.3491,  1.4630,  0.6393,  1.7705,  0.3005,  2.2834,\n",
      "         2.0384,  1.1888,  1.1972,  0.5393,  1.1759, -0.2286,  2.3174,  0.4797,\n",
      "        -0.2165,  1.9127,  0.9607, -0.9563,  1.3986,  1.7693, -1.2271,  0.5156,\n",
      "        -0.2427, -2.7427,  0.8357,  0.8799, -0.8063,  1.7569, -1.2736,  2.6738,\n",
      "         0.7626, -1.4250, -0.8967,  1.2157,  0.7887, -0.9414,  0.8507, -0.2846,\n",
      "         0.8502, -0.5923, -1.1124, -1.1372,  1.6147, -0.1186, -0.6990, -0.0816,\n",
      "         0.5755,  1.9286,  1.4350,  1.4756,  1.1714,  1.4192, -1.4428, -0.5549,\n",
      "        -0.3299, -1.3921, -0.1990,  0.7810, -0.4201,  0.2618,  0.1851,  2.0611,\n",
      "         1.6902, -1.4816,  1.9294, -0.0690,  1.2008, -0.2064,  0.2435,  2.6594,\n",
      "         1.5454, -0.9657, -0.4580, -3.7842, -2.0337, -0.0188, -1.2294,  0.3696,\n",
      "         0.2015,  0.0371,  0.1651, -1.6156, -0.1845,  0.3728,  1.5029, -0.7601,\n",
      "        -0.0103,  0.9065, -0.7906,  1.9804, -0.8735,  1.4762, -1.7655, -0.1708,\n",
      "         1.4534,  1.5186, -1.6166, -0.7304, -1.3699,  0.7870, -0.7506,  2.5261],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-2.7562e-01, -5.2252e-01, -6.4021e-02],\n",
      "          [ 4.5486e-01,  4.1070e-01,  5.8621e-01],\n",
      "          [ 2.5370e-01,  1.0576e-01,  1.6614e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9072e-01,  7.5725e-01,  5.8853e-01],\n",
      "          [-3.6263e-01, -1.0606e-01,  1.1099e-01],\n",
      "          [ 1.6132e-01, -3.6931e-01, -4.0848e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.0401e-01,  9.4540e-02,  1.9725e-01],\n",
      "          [-5.4772e-01,  9.0817e-01, -1.4136e-01],\n",
      "          [-3.7272e-01,  2.9646e-01,  1.4506e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.0526e-01, -2.3236e-01, -5.1461e-01],\n",
      "          [-2.9324e-01,  1.2261e+00, -1.9370e-01],\n",
      "          [-3.3792e-01, -2.7895e-01, -1.0314e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2593e-02,  1.5894e-01,  5.3919e-01],\n",
      "          [ 4.2159e-02, -8.1447e-01,  5.1930e-02],\n",
      "          [ 5.9026e-01,  4.7116e-02,  1.7192e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0512e-01, -2.4653e-01, -1.4555e-01],\n",
      "          [ 1.1813e-03,  4.4637e-01,  4.5002e-01],\n",
      "          [-4.2712e-01, -7.6495e-01, -1.3992e-01]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.9134, 2.0834, 2.3505, 2.7411, 1.7242, 0.7957, 2.4290, 5.8327, 1.4052,\n",
      "        1.5581, 2.8127, 2.4954, 0.7416, 1.6745, 1.5221, 2.7435, 1.6185, 0.6973,\n",
      "        0.7008, 2.1986, 1.1723, 1.2584, 4.7471, 3.7681, 2.4953, 1.1918, 0.8722,\n",
      "        1.9357, 1.8398, 2.7174, 3.3097, 2.0251, 1.0900, 0.4902, 2.1319, 1.8220,\n",
      "        1.6462, 2.3384, 1.5434, 1.7335, 0.6978, 2.5172, 1.4525, 1.7945, 1.1997,\n",
      "        2.5106, 1.8470, 1.8299, 2.1442, 2.1933, 0.8145, 1.1405, 0.6337, 1.6104,\n",
      "        1.7271, 1.9240, 2.2554, 1.7342, 1.8896, 1.7889, 1.7122, 1.2470, 0.4393,\n",
      "        2.1481, 1.8069, 1.1132, 1.7177, 3.4713, 2.1162, 1.5671, 3.1298, 2.3254,\n",
      "        1.6685, 1.6954, 1.2271, 1.0072, 1.2540, 2.9896, 1.5097, 1.5098, 0.0600,\n",
      "        1.7649, 3.6205, 1.6749, 1.4435, 1.4557, 2.2940, 1.9693, 2.7699, 2.1751,\n",
      "        1.2050, 2.3761, 1.6538, 1.2061, 1.1623, 2.3095, 1.9421, 1.8064, 1.4471,\n",
      "        1.8082, 1.5291, 0.8904, 1.2946, 1.5236, 2.3027, 1.6152, 1.4057, 0.9176,\n",
      "        1.9751, 1.2631, 0.9305, 2.0873, 1.9964, 1.6962, 1.9698, 2.9265, 2.2513,\n",
      "        2.1448, 1.0940, 1.6388, 0.5720, 1.4902, 0.5295, 1.3994, 1.6901, 1.1462,\n",
      "        2.4480, 1.3051, 1.3711, 1.4814, 0.8255, 1.9538, 1.9074, 2.5831, 1.4251,\n",
      "        1.7320, 3.0249, 1.6788, 2.0216, 2.2039, 1.7089, 2.3501, 0.8187, 1.4617,\n",
      "        1.6171, 1.5553, 0.9503, 1.1305, 1.1672, 1.7567, 2.5623, 2.5519, 1.6785,\n",
      "        2.8190, 1.6662, 1.6805, 2.0717, 1.2316, 1.3129, 2.4104, 1.1106, 1.0276,\n",
      "        2.6359, 1.0836, 5.3744, 2.4034, 0.7441, 1.9574, 2.0563, 1.4654, 2.4699,\n",
      "        1.0541, 1.0737, 1.6211, 1.5855, 1.5260, 2.7487, 2.1034, 1.2568, 1.5860,\n",
      "        0.8314, 2.6577, 0.7367, 2.5797, 1.4930, 1.8899, 2.0797, 1.0878, 0.9762,\n",
      "        1.3441, 1.7398, 2.3537], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.6828, -1.4132, -0.9884, -3.0776,  0.0105,  0.2420, -0.9703, -0.1853,\n",
      "        -0.4931,  0.3869,  0.8458,  0.4339, -0.0997,  0.5236,  0.2143, -1.5113,\n",
      "        -1.5638,  0.7072, -0.3044, -2.3876,  0.9763, -1.1802, -3.6323, -1.5898,\n",
      "        -1.2325,  0.8463,  0.9934,  0.8750, -2.2011, -0.9713, -3.5954, -2.5787,\n",
      "         0.5224,  0.0494, -1.3326, -1.8381, -0.5842, -1.4381, -1.7406, -0.5638,\n",
      "         0.9391, -1.7609, -1.1976, -1.3345,  1.0135,  0.1976, -0.2997, -1.7005,\n",
      "        -1.3627, -0.2063, -0.1484,  0.6904,  0.7384, -2.2135, -0.9183, -1.2368,\n",
      "        -1.3465,  0.5754,  1.8796, -2.0014,  0.4093,  0.1701,  0.4002, -1.9101,\n",
      "        -0.1122, -0.3488, -1.0329, -2.4013, -1.6610, -1.7354, -2.1963, -1.6563,\n",
      "         0.0533, -1.7204, -0.7212,  0.7724,  1.3020, -2.0114, -1.2481,  0.5510,\n",
      "        -0.0112, -1.5475, -2.6068, -1.0044,  1.1526, -2.5591, -0.8997, -1.2621,\n",
      "        -0.9986, -1.3756, -4.4892, -1.7367, -1.3861, -1.7916,  1.5106, -1.4895,\n",
      "        -1.0687, -1.0956, -1.0564, -0.9994, -1.1369, -0.2699, -1.5334, -1.2508,\n",
      "        -0.0995,  1.5301, -1.5183,  0.6786, -1.6439,  0.2352,  1.1456, -2.2843,\n",
      "        -1.1724, -1.6392, -1.8714, -0.0439,  0.0497, -1.0785, -0.4941, -1.2583,\n",
      "         0.7553,  0.3635,  0.9012, -1.4049, -0.1200,  1.2220,  2.3675, -1.4708,\n",
      "         1.3619, -2.3519,  0.8940, -0.7606, -1.2331, -1.4770, -1.0993, -1.9801,\n",
      "        -1.0170,  0.3599, -1.3376, -1.3038, -0.2079, -1.3713,  1.6813,  1.1739,\n",
      "        -2.2644,  0.8137, -0.5503, -0.8277,  0.5596,  0.1982, -2.0356, -1.0732,\n",
      "         0.1212, -0.7274, -1.2174, -1.2405, -1.4697, -1.5055,  0.2787, -1.0471,\n",
      "         0.5878,  0.4710, -2.3159,  0.6498, -0.6592, -1.2554,  0.5053, -0.5893,\n",
      "        -2.3520, -0.9933, -1.8486,  0.3311,  0.4864, -1.4519,  0.5723, -1.8233,\n",
      "        -0.7971, -2.1094,  0.7520, -1.2193,  0.5722, -0.2995,  0.2585, -0.7847,\n",
      "        -1.2695,  0.2624, -2.2589,  0.3564, -0.3273,  1.5793,  0.6703, -2.1978],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.5421]],\n",
      "\n",
      "         [[-0.2202]],\n",
      "\n",
      "         [[ 0.1671]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0381]],\n",
      "\n",
      "         [[-0.0977]],\n",
      "\n",
      "         [[ 0.6379]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5886]],\n",
      "\n",
      "         [[-0.0222]],\n",
      "\n",
      "         [[ 0.2510]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0519]],\n",
      "\n",
      "         [[ 0.1062]],\n",
      "\n",
      "         [[-0.0904]]],\n",
      "\n",
      "\n",
      "        [[[-0.3760]],\n",
      "\n",
      "         [[-0.2078]],\n",
      "\n",
      "         [[ 0.0359]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1511]],\n",
      "\n",
      "         [[-0.0885]],\n",
      "\n",
      "         [[ 0.0273]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4366]],\n",
      "\n",
      "         [[-0.2756]],\n",
      "\n",
      "         [[-0.0635]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1840]],\n",
      "\n",
      "         [[ 0.0626]],\n",
      "\n",
      "         [[-0.3249]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8797]],\n",
      "\n",
      "         [[ 0.5683]],\n",
      "\n",
      "         [[ 0.0255]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2316]],\n",
      "\n",
      "         [[ 0.2982]],\n",
      "\n",
      "         [[ 0.0480]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2312]],\n",
      "\n",
      "         [[-0.1356]],\n",
      "\n",
      "         [[-0.0285]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3743]],\n",
      "\n",
      "         [[-0.4033]],\n",
      "\n",
      "         [[ 0.1548]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.0955,  0.0889,  0.1410, -0.3302, -0.2925,  0.1087,  0.2090, -0.2463],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.1975]],\n",
      "\n",
      "         [[ 0.3205]],\n",
      "\n",
      "         [[ 0.0526]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7259]],\n",
      "\n",
      "         [[ 0.4083]],\n",
      "\n",
      "         [[-0.0437]]],\n",
      "\n",
      "\n",
      "        [[[-0.3026]],\n",
      "\n",
      "         [[ 0.0567]],\n",
      "\n",
      "         [[ 0.2474]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0394]],\n",
      "\n",
      "         [[ 0.0163]],\n",
      "\n",
      "         [[ 0.0734]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5608]],\n",
      "\n",
      "         [[-0.1545]],\n",
      "\n",
      "         [[ 0.2228]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4426]],\n",
      "\n",
      "         [[-0.0638]],\n",
      "\n",
      "         [[ 0.5511]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1668]],\n",
      "\n",
      "         [[ 0.1005]],\n",
      "\n",
      "         [[-0.0995]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3630]],\n",
      "\n",
      "         [[ 0.0385]],\n",
      "\n",
      "         [[ 0.4378]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0405]],\n",
      "\n",
      "         [[ 0.5213]],\n",
      "\n",
      "         [[ 0.0201]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5222]],\n",
      "\n",
      "         [[-0.0351]],\n",
      "\n",
      "         [[ 0.7274]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2262]],\n",
      "\n",
      "         [[ 0.6817]],\n",
      "\n",
      "         [[ 0.3272]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5515]],\n",
      "\n",
      "         [[ 0.2478]],\n",
      "\n",
      "         [[ 0.0567]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.6885, -0.0082,  0.0624,  0.4188,  0.4662,  0.1226,  0.2455, -0.4528,\n",
      "        -0.2896,  0.1141, -0.5610,  0.1265,  0.2920, -0.0234,  0.4947,  0.1923,\n",
      "         0.0349,  0.0887, -0.2860, -0.2802,  0.3819,  0.1868, -0.2472, -0.2658,\n",
      "         0.0749,  0.2881,  0.0265,  0.3235,  0.6430, -0.4496,  0.2265,  0.1510,\n",
      "         0.1765, -0.3243,  0.3995, -0.4895, -0.2400,  0.4491, -0.5682,  0.3359,\n",
      "        -0.0147,  0.0201, -0.1164,  0.2320, -0.0290,  0.0409,  0.2460,  0.2984,\n",
      "         0.3342,  0.5546, -0.5703,  0.8226,  0.3844, -0.0835,  0.4892,  0.2668,\n",
      "         0.0465,  0.1968,  0.7613, -0.0418,  0.3797,  0.2177, -0.0439,  0.4265,\n",
      "         0.5022, -0.2411, -0.2123,  0.2525, -0.1757, -0.1145,  0.2025, -0.0874,\n",
      "         0.1689, -0.4264, -0.2858,  0.1602, -0.2464,  0.4098, -0.2775,  0.3743,\n",
      "        -0.4102,  0.2658, -0.2142, -0.4525,  0.4861, -0.4272,  0.2047,  0.3599,\n",
      "         0.3092,  0.1423, -0.1311,  0.3621,  0.0702, -0.0357,  0.4418, -0.1495,\n",
      "         0.1886, -0.2230,  0.3344,  0.0257, -0.8984, -0.2053, -0.0893, -0.0296,\n",
      "         0.5079, -0.6505, -0.0493,  0.5796, -0.1040,  0.2318,  0.7000,  0.2840,\n",
      "        -0.3210, -0.0086,  0.0788,  0.8403, -0.2122,  0.3716, -0.0451,  0.4629,\n",
      "        -0.1504,  0.2322,  0.3227,  0.1344, -0.1323,  0.3516,  0.8287,  0.1175,\n",
      "         0.1774, -0.0694,  0.3392,  0.1849, -0.2397, -0.0685, -0.0105,  0.1882,\n",
      "         0.5319,  0.2713,  0.1535, -0.1919, -0.3232,  0.5439, -0.0465, -0.0973,\n",
      "         0.1996,  0.1666, -0.3897, -0.1231,  0.5123, -0.9457,  0.3581,  0.2966,\n",
      "        -0.4991, -0.2455,  0.5380, -0.2345,  0.6098, -0.0429, -0.0303, -0.0922,\n",
      "         0.4739,  0.1403,  0.4474,  0.4378, -0.5804,  0.1217, -0.1561,  0.4366,\n",
      "         0.0855, -0.7590, -0.0368, -0.0422,  0.1841, -0.0177, -0.2630,  0.2860,\n",
      "        -0.1016, -0.0699,  0.9362,  0.3061, -0.0127,  0.3039,  0.3125,  0.2884,\n",
      "         0.3706,  0.7660, -0.2956,  0.4275,  0.0543,  0.1732,  0.0651,  0.5388],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0261]],\n",
      "\n",
      "         [[-0.0566]],\n",
      "\n",
      "         [[-0.0686]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1612]],\n",
      "\n",
      "         [[ 0.0394]],\n",
      "\n",
      "         [[ 0.5413]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2615]],\n",
      "\n",
      "         [[ 0.0611]],\n",
      "\n",
      "         [[ 0.0436]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3751]],\n",
      "\n",
      "         [[-0.3442]],\n",
      "\n",
      "         [[ 0.6007]]],\n",
      "\n",
      "\n",
      "        [[[-0.3266]],\n",
      "\n",
      "         [[ 0.1820]],\n",
      "\n",
      "         [[-0.3031]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4003]],\n",
      "\n",
      "         [[ 0.0567]],\n",
      "\n",
      "         [[ 0.0790]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4198]],\n",
      "\n",
      "         [[ 0.1810]],\n",
      "\n",
      "         [[ 0.0644]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3502]],\n",
      "\n",
      "         [[ 0.8529]],\n",
      "\n",
      "         [[ 0.2832]]],\n",
      "\n",
      "\n",
      "        [[[-0.0718]],\n",
      "\n",
      "         [[ 0.3885]],\n",
      "\n",
      "         [[-0.2266]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5617]],\n",
      "\n",
      "         [[ 0.1155]],\n",
      "\n",
      "         [[-0.5255]]],\n",
      "\n",
      "\n",
      "        [[[-0.4031]],\n",
      "\n",
      "         [[-0.6654]],\n",
      "\n",
      "         [[-0.1895]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5097]],\n",
      "\n",
      "         [[ 0.2502]],\n",
      "\n",
      "         [[-0.5205]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.9160, 3.3610, 2.0164, 0.3112, 3.3814, 1.7687, 4.2327, 2.1397, 5.2458,\n",
      "        2.2248, 4.8811, 3.0997, 0.2716, 2.7773, 3.0438, 2.1608, 3.1023, 2.7100,\n",
      "        5.8627, 1.3539, 5.5830, 2.5875, 1.7326, 1.4584, 3.6035, 2.9497, 1.4332,\n",
      "        3.3879, 2.2874, 2.2933, 1.0553, 4.0307], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.2616, -3.3184, -1.9077,  0.3700,  2.1448, -1.3087, -0.6994,  0.7210,\n",
      "        -1.3455,  1.0560,  2.9985,  0.3674, -0.1945, -0.1494,  0.3226, -2.4472,\n",
      "        -3.1407,  0.2542,  5.1300,  0.3184,  0.2146, -3.8666,  0.3657,  0.3134,\n",
      "        -0.8888, -0.1699, -2.6050, -4.4330,  0.8017, -2.0981, -1.5014, -2.1758],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.4274]],\n",
      "\n",
      "         [[-0.5157]],\n",
      "\n",
      "         [[ 0.1619]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2456]],\n",
      "\n",
      "         [[-0.2242]],\n",
      "\n",
      "         [[ 0.0254]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1508]],\n",
      "\n",
      "         [[ 0.1067]],\n",
      "\n",
      "         [[ 0.7066]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0913]],\n",
      "\n",
      "         [[-0.4647]],\n",
      "\n",
      "         [[-0.3723]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7743]],\n",
      "\n",
      "         [[-0.6536]],\n",
      "\n",
      "         [[ 0.1829]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4020]],\n",
      "\n",
      "         [[ 0.0651]],\n",
      "\n",
      "         [[-0.0260]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.5073]],\n",
      "\n",
      "         [[ 0.7902]],\n",
      "\n",
      "         [[-0.1051]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7526]],\n",
      "\n",
      "         [[ 0.5061]],\n",
      "\n",
      "         [[-0.2492]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2042]],\n",
      "\n",
      "         [[ 0.2340]],\n",
      "\n",
      "         [[-0.6706]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2928]],\n",
      "\n",
      "         [[ 0.0768]],\n",
      "\n",
      "         [[-0.3892]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7561]],\n",
      "\n",
      "         [[ 0.2743]],\n",
      "\n",
      "         [[ 0.1472]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2362]],\n",
      "\n",
      "         [[ 0.0596]],\n",
      "\n",
      "         [[-0.0886]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.7831,  0.4773,  0.9096,  1.4735,  1.7146,  1.5144,  1.6019,  0.8813,\n",
      "         0.9193,  0.8337,  1.4993,  0.8937,  0.3636,  0.8057,  0.6401,  1.8020,\n",
      "         0.0848,  2.0177,  0.7211,  0.5754,  1.1890,  1.5401,  1.6640,  1.6204,\n",
      "         1.0234,  1.1884,  1.6388,  1.7027,  3.8076,  1.4881,  0.3207,  0.6537,\n",
      "         1.0362,  1.9124,  1.6988,  1.9456,  2.0435,  1.7204,  0.1595,  1.5116,\n",
      "         1.5780,  0.7761,  0.8373,  1.1311,  0.9142,  1.5077,  1.0920,  0.8663,\n",
      "         0.6411,  0.7045,  0.9561,  0.1607,  1.7986,  2.8360,  1.5155,  1.0338,\n",
      "         0.7337,  2.0486,  0.3760,  0.6237,  0.3016,  1.2992,  2.2208,  1.0123,\n",
      "         1.4437,  1.5159,  1.1098,  1.1700,  1.6121,  1.9596,  0.3497,  1.3435,\n",
      "         0.6076,  1.9464,  0.7810,  0.6387,  2.8240,  1.3420,  0.5078,  0.7103,\n",
      "         1.2218,  0.8752,  0.2284,  1.1272,  0.9643,  1.5586,  1.2193,  0.4203,\n",
      "         1.1210,  1.4486,  1.5644,  1.3582,  0.4613,  0.1921,  2.3023,  1.7438,\n",
      "         1.3500,  1.4233,  0.3585,  2.2366,  1.0081,  2.5616,  1.1768,  0.8700,\n",
      "         1.5672,  0.7076,  2.1832,  0.8174,  0.8217,  1.3718,  0.3713,  1.0562,\n",
      "         1.7269,  0.1682,  2.8321,  1.4783,  1.7930,  0.7164, -0.3056,  0.7714,\n",
      "         1.7292,  1.7746,  2.1880,  0.7243,  0.8159,  1.3960,  0.4849,  0.9863,\n",
      "         0.1776,  0.5380,  1.6626,  1.6474,  0.8768,  0.4761,  1.8335,  0.4674,\n",
      "         2.9243,  2.5274,  1.4242,  0.6485,  0.7588,  4.2954,  0.8057,  2.2500,\n",
      "         1.4096,  1.1580,  1.0039,  1.1107,  1.0326,  0.7337,  1.5585,  1.3677,\n",
      "         0.2412,  2.3289,  1.4907,  2.4703,  1.8030,  1.0390,  1.6490,  0.7810,\n",
      "         0.9938,  1.1681,  0.5316,  1.2459,  1.8560,  0.8678,  1.6211,  0.5074,\n",
      "         1.6592,  0.7143, -0.1161,  1.4703,  0.4167,  0.7703,  2.1787,  1.7918,\n",
      "         2.6925,  1.9614,  0.1356,  1.6898,  1.5745,  1.1620,  0.6594,  1.8468,\n",
      "         0.8069,  0.6158,  1.7341,  0.7659,  0.4053,  2.3385,  1.7699,  2.6068],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.1393e-01, -9.9025e-03, -1.2453e-01, -3.9387e-02,  1.1573e+00,\n",
      "        -1.0802e-01, -4.2516e+00, -1.4309e+00, -1.7437e+00, -1.6613e+00,\n",
      "         9.7598e-01,  6.5087e-01, -2.7480e-01, -1.6671e+00,  1.3137e+00,\n",
      "        -1.7502e+00,  1.1079e+00,  1.4659e+00,  2.4810e+00,  1.4567e+00,\n",
      "        -1.6152e+00,  1.5041e+00,  6.3911e-01, -2.0650e+00, -3.5942e-02,\n",
      "        -2.1523e-01,  3.5903e+00, -1.8438e+00, -5.1306e+00,  1.4607e+00,\n",
      "         1.6183e+00,  7.2201e-01,  3.4318e-01,  1.3146e+00, -2.4689e-02,\n",
      "        -4.5921e-01, -1.1407e+00,  7.2167e-01,  3.0883e-01,  2.4180e-01,\n",
      "        -1.4352e-01, -1.3182e+00,  1.1478e+00,  1.5157e+00,  8.3620e-01,\n",
      "         1.2073e+00,  1.2603e+00, -5.0957e-01, -8.7530e-01, -8.2753e-01,\n",
      "        -1.3337e+00,  6.7369e-02,  5.4412e-01,  1.0660e-02,  1.4490e+00,\n",
      "        -1.1494e+00,  1.4309e+00,  1.2047e+00,  6.1291e-01, -3.2578e-01,\n",
      "         2.7655e-03,  1.6519e+00, -3.8215e-01,  1.1880e-01, -8.3138e-01,\n",
      "         1.5502e-01,  1.0548e+00,  1.1984e+00,  9.5368e-01, -2.6340e+00,\n",
      "        -2.8854e-01,  1.4727e+00, -5.2474e-01,  4.2308e-01,  6.0334e-01,\n",
      "         7.5348e-01,  6.9911e-01,  1.6714e+00, -8.0055e-01,  2.7947e-01,\n",
      "         1.4634e+00,  2.0066e+00,  8.7217e-02,  5.3045e-01,  2.3217e+00,\n",
      "         1.6721e+00,  1.7965e+00,  1.7267e-01,  9.8679e-02,  6.3513e-01,\n",
      "         1.2341e+00,  8.1551e-01, -6.0756e-01, -6.7917e-01, -5.4824e-01,\n",
      "         1.2858e+00,  2.3638e+00, -1.5425e+00, -4.2956e-01, -1.2903e+00,\n",
      "        -1.7888e+00, -4.2463e-01, -2.6366e-02,  1.5882e+00, -5.4539e-02,\n",
      "         1.1113e+00,  9.8491e-01, -5.6612e-01, -1.0114e+00,  5.1282e-01,\n",
      "        -2.2492e-01, -2.0541e+00,  9.7033e-01, -2.2874e-01,  2.3130e-01,\n",
      "         1.2168e+00,  2.2073e+00,  1.4095e+00, -1.2778e-01,  8.3544e-01,\n",
      "         1.4888e+00,  6.6632e-01,  2.2999e+00,  2.0509e+00, -1.2786e+00,\n",
      "         1.5015e+00,  2.8333e-01,  1.0959e+00,  2.3049e-01,  8.0280e-02,\n",
      "         2.2576e+00, -4.7635e+00,  1.4392e+00,  2.7468e-01,  1.5115e+00,\n",
      "         4.7775e-01, -1.9091e+00,  9.4880e-01,  1.9861e+00, -5.3796e-01,\n",
      "         1.5493e+00, -3.9761e-01,  6.3703e-01,  1.2575e+00,  2.0276e+00,\n",
      "         1.0844e+00,  1.8493e-02, -1.0264e-01,  1.2893e+00, -1.0374e+00,\n",
      "        -1.0803e+00,  1.5454e+00, -2.6233e-01,  2.4153e-01,  6.4407e-01,\n",
      "         2.6925e-02, -2.9845e-01,  1.6583e+00, -4.8205e-01,  2.1272e+00,\n",
      "        -8.4265e-01, -2.7845e+00, -3.6739e-01, -8.9880e-01,  4.5517e-01,\n",
      "         1.3897e+00, -1.4784e+00, -5.7901e-01, -1.9251e+00, -1.1635e+00,\n",
      "        -1.9300e-01,  3.1051e+00,  4.9052e-01, -1.6348e+00, -5.2503e-01,\n",
      "        -1.2480e+00,  1.1396e+00,  1.6197e+00,  6.6179e-01,  1.7600e+00,\n",
      "         8.6252e-01, -6.0820e-01,  1.4733e+00,  2.4555e+00,  1.1755e-01,\n",
      "        -3.7547e-01, -1.9147e+00,  1.0080e+00, -1.2343e-01,  1.6553e+00,\n",
      "         2.1262e+00, -1.8859e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.4867,  0.0784,  0.4031],\n",
      "          [ 0.1643,  0.2049, -0.0644],\n",
      "          [-0.2275, -0.4223, -0.5419]]],\n",
      "\n",
      "\n",
      "        [[[-0.5490, -0.2727, -0.3016],\n",
      "          [-0.4324, -0.3860, -0.3376],\n",
      "          [-0.2204,  0.1785, -0.1496]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4715, -0.0413, -0.4258],\n",
      "          [-0.1640, -0.5311,  0.4512],\n",
      "          [ 0.0696,  0.5680, -0.0105]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3322, -0.3340, -0.0158],\n",
      "          [-0.4872,  0.6983,  0.0460],\n",
      "          [ 0.3344, -0.4191, -0.0221]]],\n",
      "\n",
      "\n",
      "        [[[-0.2320, -0.6215, -0.0773],\n",
      "          [ 0.4306, -0.0934,  0.6490],\n",
      "          [-0.0248, -0.5927, -0.1848]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0632, -0.1745, -0.3567],\n",
      "          [ 0.5360, -0.8166,  0.1796],\n",
      "          [ 0.4594, -0.0903,  0.0498]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.3637, 0.8315, 2.3372, 1.9363, 1.0410, 1.5635, 3.8946, 1.2449, 1.6022,\n",
      "        1.2037, 2.1311, 1.8689, 1.7670, 0.9452, 1.9781, 3.7215, 0.6910, 1.9686,\n",
      "        2.0383, 1.9304, 3.9366, 1.2770, 1.9766, 1.7737, 0.8848, 1.6578, 2.6280,\n",
      "        2.2857, 2.3238, 2.1674, 0.8819, 1.8052, 1.3204, 1.9334, 2.0228, 1.1081,\n",
      "        0.7192, 1.6284, 1.4917, 0.8525, 0.9321, 0.5639, 1.7420, 1.7192, 0.5561,\n",
      "        1.9044, 1.7706, 1.6486, 1.1243, 0.9870, 3.9759, 1.9047, 1.3796, 2.4402,\n",
      "        1.7902, 2.8787, 1.3332, 1.8512, 1.6121, 1.5650, 2.2424, 1.8931, 1.3775,\n",
      "        2.1221, 0.4914, 1.4424, 1.9675, 1.8712, 1.7465, 2.2446, 1.4539, 1.6824,\n",
      "        1.4454, 0.4236, 2.1202, 1.4601, 1.5894, 2.6778, 1.8952, 2.0403, 1.2863,\n",
      "        0.6909, 1.9639, 1.2526, 1.9695, 1.5359, 1.6983, 1.8545, 1.6055, 0.8712,\n",
      "        1.9486, 1.3888, 3.0880, 1.3905, 1.0019, 1.4865, 2.2699, 1.3645, 2.1835,\n",
      "        1.2819, 0.4380, 1.0518, 2.2542, 3.0507, 1.4256, 1.1577, 1.0801, 3.6372,\n",
      "        0.5468, 0.9715, 1.7200, 1.6744, 1.8338, 1.6044, 1.9873, 1.2541, 2.5838,\n",
      "        0.9654, 1.8037, 1.8996, 2.4971, 1.8401, 2.3760, 1.9017, 1.5053, 2.2627,\n",
      "        1.5883, 2.0636, 0.7708, 2.2671, 1.7547, 2.2934, 1.8522, 1.4610, 1.8705,\n",
      "        2.2636, 1.0861, 1.5261, 1.8262, 1.8343, 2.1405, 3.4948, 1.3394, 1.3032,\n",
      "        2.2947, 1.6418, 2.0509, 1.0803, 1.9395, 0.5898, 1.2316, 1.3406, 1.3857,\n",
      "        1.7549, 2.3267, 1.7933, 2.3301, 1.6086, 1.4767, 1.4086, 0.9446, 3.4162,\n",
      "        1.8392, 1.0826, 1.0659, 1.8537, 3.6248, 1.7183, 1.4754, 1.1192, 2.3355,\n",
      "        2.6974, 1.7429, 0.9477, 1.3506, 0.8002, 2.4242, 2.2503, 1.4571, 2.1522,\n",
      "        2.0677, 2.5159, 2.0899, 2.0053, 0.8774, 1.5406, 0.9790, 1.8499, 2.0144,\n",
      "        2.2426, 1.3166, 1.9280], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 3.6056e-01,  1.7628e-01, -1.8437e+00, -2.2959e+00,  9.3758e-01,\n",
      "        -1.6511e+00, -2.6774e+00, -1.1201e-01, -2.1300e-01,  2.1042e-01,\n",
      "        -1.2370e+00, -1.7937e+00, -8.7222e-01, -3.5979e-01, -1.7024e+00,\n",
      "        -2.6446e+00, -2.5669e-01, -1.7006e+00, -1.1739e+00, -7.9674e-01,\n",
      "        -1.0898e+00, -1.6656e-01, -8.4035e-01, -1.6743e-01,  8.4644e-01,\n",
      "        -2.2135e+00, -3.2631e+00, -2.1258e+00, -3.5766e-01, -1.6844e+00,\n",
      "         8.8109e-02, -2.5761e+00, -4.0085e-02, -9.5764e-01, -1.5073e+00,\n",
      "         6.9977e-01,  1.6604e+00, -2.0590e+00, -1.2734e+00,  2.2677e-01,\n",
      "         1.4332e-01,  1.4018e-03, -1.2527e+00, -1.3810e+00,  6.5924e-01,\n",
      "        -1.4783e+00, -1.6318e+00, -1.6358e+00,  9.6148e-01,  3.7693e-01,\n",
      "        -3.0942e+00, -1.9913e+00, -9.5368e-01, -1.4056e+00, -1.6081e+00,\n",
      "         7.1582e-01, -1.4851e+00, -1.3935e+00, -1.4036e+00, -1.3334e+00,\n",
      "        -2.5004e+00, -1.4055e+00,  4.9775e-01, -1.2822e+00,  3.6425e-01,\n",
      "        -9.9282e-01, -1.9749e+00, -1.5752e+00, -1.2533e+00, -9.8713e-01,\n",
      "        -2.9899e+00, -1.5530e+00, -1.2596e+00,  9.6760e-01, -1.0284e+00,\n",
      "        -1.0300e+00, -1.0061e+00, -7.8588e-01, -7.4418e-01, -2.0238e+00,\n",
      "         5.4689e-02,  1.6516e+00, -1.7106e+00, -1.0512e+00, -1.6400e+00,\n",
      "        -1.1596e+00, -5.3057e-01, -1.2529e+00, -1.0179e+00, -3.0254e-01,\n",
      "        -1.6440e+00,  2.2913e-01, -1.5548e+00, -1.2963e+00,  8.4247e-01,\n",
      "        -6.5641e-01, -1.7794e+00, -2.5966e+00, -1.1124e+00, -1.1200e+00,\n",
      "        -3.9345e-03,  5.5779e-01, -1.4475e+00, -1.1338e+00, -2.1465e+00,\n",
      "        -2.1745e+00,  3.9448e-01, -2.8413e+00, -1.7894e-01, -4.8065e-01,\n",
      "        -1.3724e+00, -7.8388e-01, -2.8270e+00, -1.8446e+00, -6.9932e-01,\n",
      "        -1.5855e+00, -1.1158e+00,  1.5520e-01, -1.5999e+00, -1.9054e+00,\n",
      "        -2.4850e+00, -9.9898e-01, -2.3507e+00,  5.0997e-01,  5.4193e-01,\n",
      "        -9.0278e-01, -2.1255e+00, -1.3244e+00, -8.2568e-01, -1.1555e+00,\n",
      "        -1.6150e+00, -5.6892e-02, -7.2903e-01, -1.6549e+00, -1.8557e+00,\n",
      "        -1.2462e+00,  3.0968e-01, -4.3636e-01, -1.3286e+00, -1.2212e+00,\n",
      "        -1.6541e+00, -1.8489e+00, -1.2307e+00,  1.0454e+00, -7.8521e-01,\n",
      "        -1.7794e+00, -1.8778e+00,  1.2734e+00, -1.1885e+00, -9.6628e-02,\n",
      "        -5.6229e-01, -1.1155e+00, -9.9947e-01, -7.9421e-01, -8.4905e-01,\n",
      "        -4.6812e-01,  1.4922e-01, -1.8208e+00, -8.9367e-01, -1.5029e+00,\n",
      "         5.1911e-01, -3.1195e+00, -2.0323e+00, -7.5531e-01,  1.2822e-01,\n",
      "        -5.2618e-01,  1.0016e+00, -1.3414e+00, -3.3232e+00, -1.5868e+00,\n",
      "        -1.6660e+00, -2.8155e+00, -1.7362e+00,  4.4596e-01,  1.9717e-01,\n",
      "         6.4049e-01, -1.1731e+00, -1.0212e+00, -1.4843e+00, -1.9706e+00,\n",
      "        -8.0274e-01, -7.2198e-02, -1.5381e+00, -1.7667e+00, -3.0784e-01,\n",
      "        -2.3359e+00, -2.7884e-01, -2.1645e+00, -1.4622e+00, -1.5245e+00,\n",
      "         1.6405e-02, -1.2308e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1415]],\n",
      "\n",
      "         [[-0.1986]],\n",
      "\n",
      "         [[-0.4011]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6104]],\n",
      "\n",
      "         [[-0.0480]],\n",
      "\n",
      "         [[ 0.4124]]],\n",
      "\n",
      "\n",
      "        [[[-0.1984]],\n",
      "\n",
      "         [[ 0.4306]],\n",
      "\n",
      "         [[ 0.5228]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4189]],\n",
      "\n",
      "         [[-0.0686]],\n",
      "\n",
      "         [[-0.0532]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1927]],\n",
      "\n",
      "         [[-0.0605]],\n",
      "\n",
      "         [[ 0.0413]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0229]],\n",
      "\n",
      "         [[ 0.2230]],\n",
      "\n",
      "         [[ 0.1748]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0042]],\n",
      "\n",
      "         [[ 0.0548]],\n",
      "\n",
      "         [[-0.0188]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0036]],\n",
      "\n",
      "         [[ 0.0628]],\n",
      "\n",
      "         [[ 0.3786]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2626]],\n",
      "\n",
      "         [[ 0.8402]],\n",
      "\n",
      "         [[ 0.0301]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0314]],\n",
      "\n",
      "         [[-0.1769]],\n",
      "\n",
      "         [[ 0.0561]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0946]],\n",
      "\n",
      "         [[-0.0459]],\n",
      "\n",
      "         [[-0.3187]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3690]],\n",
      "\n",
      "         [[ 0.2078]],\n",
      "\n",
      "         [[-0.0884]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1196,  0.0624,  0.1677,  0.1467, -0.1214,  0.1353,  0.0893,  0.1168],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0309]],\n",
      "\n",
      "         [[-0.3627]],\n",
      "\n",
      "         [[ 0.3401]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2214]],\n",
      "\n",
      "         [[-0.9591]],\n",
      "\n",
      "         [[-0.0048]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1781]],\n",
      "\n",
      "         [[-0.7000]],\n",
      "\n",
      "         [[-0.1480]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7006]],\n",
      "\n",
      "         [[-0.9195]],\n",
      "\n",
      "         [[-0.5653]]],\n",
      "\n",
      "\n",
      "        [[[-0.4727]],\n",
      "\n",
      "         [[ 0.0448]],\n",
      "\n",
      "         [[ 0.5796]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4206]],\n",
      "\n",
      "         [[ 0.4693]],\n",
      "\n",
      "         [[-0.2005]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3968]],\n",
      "\n",
      "         [[ 0.0311]],\n",
      "\n",
      "         [[ 0.3535]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3960]],\n",
      "\n",
      "         [[ 0.2387]],\n",
      "\n",
      "         [[-0.4711]]],\n",
      "\n",
      "\n",
      "        [[[-0.5806]],\n",
      "\n",
      "         [[ 0.4569]],\n",
      "\n",
      "         [[ 0.6800]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3257]],\n",
      "\n",
      "         [[ 0.3184]],\n",
      "\n",
      "         [[ 0.8199]]],\n",
      "\n",
      "\n",
      "        [[[-0.3497]],\n",
      "\n",
      "         [[-0.6035]],\n",
      "\n",
      "         [[ 0.4003]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5472]],\n",
      "\n",
      "         [[-0.2405]],\n",
      "\n",
      "         [[ 0.1621]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.2073, -0.4387,  0.2755, -0.1131, -0.3581,  0.2228, -0.4425,  0.1542,\n",
      "         0.4206,  0.1170,  0.1193, -0.0101, -0.0586, -0.0102,  0.3627,  0.1700,\n",
      "        -0.2841, -0.4638, -0.0541,  0.1013, -0.4486,  0.5009,  0.0651, -0.4727,\n",
      "         0.3727,  0.0514,  0.1671,  0.0378, -0.3377,  0.0271, -0.2008,  0.4106,\n",
      "         0.1059,  0.0817,  0.4153, -0.5488, -0.1664,  0.2571, -0.2018,  0.0748,\n",
      "         0.2379,  0.2521, -0.3186,  0.1859,  0.3716, -0.1182, -0.1362,  0.1399,\n",
      "         0.4977,  0.6926, -0.0124,  0.4681, -0.7610, -0.2614,  0.6979, -0.5895,\n",
      "        -0.0629, -0.1275, -0.2956, -0.4911,  0.0365,  0.0189,  0.0616, -0.0036,\n",
      "         0.4976, -0.2856,  0.1118, -0.1181,  0.1542, -0.1131, -0.1196, -0.0673,\n",
      "         0.0112, -0.0449,  0.1133,  0.0899,  0.2437,  0.2001,  0.5981,  0.2180,\n",
      "        -0.0684, -0.2639, -0.1858, -0.0939,  0.0878, -0.4695,  0.5608,  0.6687,\n",
      "        -0.0792, -0.3747,  0.5884,  0.0773,  0.4135, -0.4606, -0.2205,  0.2302,\n",
      "         0.1579, -0.1728,  0.2508, -0.2055, -0.0755,  0.2514,  0.0680, -0.5197,\n",
      "         0.1800, -0.0032,  0.4740, -0.2404, -0.0218, -0.3810,  0.1273,  0.2701,\n",
      "         0.0808,  0.1839, -0.1659, -0.6156, -0.0167, -0.2796, -0.3404,  0.2576,\n",
      "         0.2000, -0.1640, -0.1079, -0.0422,  0.4798,  0.3037,  0.2936,  0.5547,\n",
      "        -0.5466, -0.1076, -0.2970, -0.3967, -0.1081,  0.2192, -0.0914,  0.1334,\n",
      "         0.2929,  0.1310,  0.1003, -0.0015, -0.6231, -0.0653,  0.0847, -0.2238,\n",
      "         0.4858, -0.2462,  0.0076,  0.6885,  0.3984, -0.6079,  0.3232, -0.4068,\n",
      "        -0.7895,  0.2006,  0.5257, -0.0038, -0.2281,  0.1379, -0.3148, -0.6606,\n",
      "         0.4319, -0.3153,  0.0837, -0.2030, -0.1268,  0.2113, -0.4958,  0.2303,\n",
      "         0.0873,  0.3696,  0.3140,  0.0481, -0.0570,  0.3735,  0.1712, -0.1720,\n",
      "        -0.3274,  0.1295,  0.4176, -0.2739,  0.2089, -0.3227,  0.3992,  0.3224,\n",
      "        -0.3474, -0.4947, -0.5678, -0.0835,  0.1705, -0.0904,  1.1732, -0.0568],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2681]],\n",
      "\n",
      "         [[ 0.1700]],\n",
      "\n",
      "         [[-0.1179]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1310]],\n",
      "\n",
      "         [[-0.0994]],\n",
      "\n",
      "         [[-0.2435]]],\n",
      "\n",
      "\n",
      "        [[[-0.1909]],\n",
      "\n",
      "         [[-0.3915]],\n",
      "\n",
      "         [[-0.4662]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.8195]],\n",
      "\n",
      "         [[-0.6008]],\n",
      "\n",
      "         [[-0.5006]]],\n",
      "\n",
      "\n",
      "        [[[-0.8087]],\n",
      "\n",
      "         [[-0.4153]],\n",
      "\n",
      "         [[ 0.3705]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5638]],\n",
      "\n",
      "         [[-0.1932]],\n",
      "\n",
      "         [[ 0.8291]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0125]],\n",
      "\n",
      "         [[ 0.0089]],\n",
      "\n",
      "         [[ 0.1698]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0872]],\n",
      "\n",
      "         [[-0.4197]],\n",
      "\n",
      "         [[-0.1818]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2174]],\n",
      "\n",
      "         [[ 0.3056]],\n",
      "\n",
      "         [[ 0.1573]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3710]],\n",
      "\n",
      "         [[-0.0049]],\n",
      "\n",
      "         [[-0.2162]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0144]],\n",
      "\n",
      "         [[ 0.2654]],\n",
      "\n",
      "         [[ 0.1315]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0215]],\n",
      "\n",
      "         [[ 0.2440]],\n",
      "\n",
      "         [[-0.5465]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.0170, 2.3528, 1.3903, 0.3377, 2.0883, 1.8385, 4.8942, 1.4194, 3.3475,\n",
      "        2.1823, 4.1352, 2.9554, 0.3253, 2.0774, 4.3139, 1.3195, 2.0281, 1.9668,\n",
      "        4.0696, 1.2933, 4.1678, 2.4139, 1.5964, 0.9933, 2.5163, 3.5950, 1.1792,\n",
      "        2.4470, 2.5981, 1.5316, 1.6124, 2.6106], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.3106, -1.5890, -0.9007,  0.1867,  1.1025, -0.6248,  1.8074,  0.8709,\n",
      "        -1.8600, -0.0794,  2.4937, -1.0355, -0.4281, -0.0070, -2.3527, -2.8005,\n",
      "        -3.3682, -0.5602,  1.8828,  0.5808, -1.1951, -3.4834,  0.0270, -0.0501,\n",
      "        -0.0467, -0.9305, -0.9491, -2.8294,  0.3588, -0.9478, -0.8780, -1.9108],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.1790]],\n",
      "\n",
      "         [[ 0.2957]],\n",
      "\n",
      "         [[ 0.4383]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0851]],\n",
      "\n",
      "         [[-0.2746]],\n",
      "\n",
      "         [[ 0.1360]]],\n",
      "\n",
      "\n",
      "        [[[-0.0836]],\n",
      "\n",
      "         [[-0.9059]],\n",
      "\n",
      "         [[ 0.0400]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4127]],\n",
      "\n",
      "         [[-0.1455]],\n",
      "\n",
      "         [[ 0.3559]]],\n",
      "\n",
      "\n",
      "        [[[-0.3104]],\n",
      "\n",
      "         [[-0.1572]],\n",
      "\n",
      "         [[-0.5656]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0097]],\n",
      "\n",
      "         [[ 0.4409]],\n",
      "\n",
      "         [[ 0.3661]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0889]],\n",
      "\n",
      "         [[ 0.3434]],\n",
      "\n",
      "         [[ 0.1470]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3457]],\n",
      "\n",
      "         [[-0.0410]],\n",
      "\n",
      "         [[-0.0972]]],\n",
      "\n",
      "\n",
      "        [[[-0.4398]],\n",
      "\n",
      "         [[-0.0343]],\n",
      "\n",
      "         [[-1.0300]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2643]],\n",
      "\n",
      "         [[-0.2827]],\n",
      "\n",
      "         [[ 0.4766]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5618]],\n",
      "\n",
      "         [[ 0.1824]],\n",
      "\n",
      "         [[-0.2423]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1016]],\n",
      "\n",
      "         [[ 0.5169]],\n",
      "\n",
      "         [[ 0.3281]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.9134,  1.3089,  3.7988,  0.9587,  1.2512,  0.4606,  1.3598,  1.9566,\n",
      "         1.1638,  1.1218,  2.0335,  1.6048,  0.4129,  1.4864,  0.2142,  1.7243,\n",
      "         1.0435,  2.4894,  0.4011,  0.1960,  0.7819,  1.0421,  1.3102,  0.5079,\n",
      "         1.7423,  2.5894,  0.3916,  1.6845,  0.9316,  0.1752,  2.6662,  1.3399,\n",
      "         0.8803,  0.9325,  1.2380,  1.0270,  0.9397,  1.2965,  1.1416,  1.4224,\n",
      "         1.1761,  1.2126,  0.2189,  2.8403,  1.5636,  1.2384,  0.9578,  1.2014,\n",
      "         0.4874,  0.7236,  1.8557,  1.7389,  0.9712,  3.1947,  0.2325,  1.1487,\n",
      "         0.5652,  1.1095,  0.9501,  1.6093,  0.9598,  1.2561,  1.8185,  1.1583,\n",
      "         2.4066,  0.9740,  0.8383,  3.5368,  0.7850,  1.1475,  1.8460,  0.2583,\n",
      "        -0.3775,  0.6382,  1.7429,  1.4627,  0.6107,  1.6497,  0.8595,  1.3970,\n",
      "         1.4201,  0.3545,  1.9661,  1.2898,  1.2290,  0.4288,  0.9842,  1.4667,\n",
      "         0.6955,  0.7002,  1.4055,  1.2548,  2.2269,  1.3927,  0.4391,  1.1765,\n",
      "         0.1729,  2.2807,  2.8401,  0.2912,  3.6654, -0.3199,  2.9799,  2.8410,\n",
      "         0.7569,  1.7474,  0.4042, -0.2241,  0.9676,  0.4152, -0.1182,  0.8937,\n",
      "         0.4439,  0.6164,  0.9541,  0.9925,  1.8240,  0.5096,  1.7941,  1.1812,\n",
      "         0.7712,  1.1289,  0.7695,  1.1016,  0.2694,  2.1843,  0.3546,  1.1598,\n",
      "         1.1090,  0.1683,  1.7719,  1.1989,  0.1783,  1.2186,  1.2347,  1.0697,\n",
      "         0.7564,  1.3052,  1.7775,  2.1497,  3.0679,  0.9716,  0.9527,  1.7026,\n",
      "         1.4321,  1.0328,  1.1691,  3.6534,  2.1061,  2.2746,  2.0169,  1.6651,\n",
      "         0.7743,  1.4109,  1.6126,  0.6989,  3.5120,  0.9163,  1.0706,  1.4082,\n",
      "         1.2181,  0.8062,  0.2912,  1.1039,  0.8358,  0.9441,  1.5576,  1.3169,\n",
      "         2.7259,  2.2135,  0.2254,  1.7171,  1.8448,  2.0774,  1.0081,  1.8034,\n",
      "         1.5149,  2.0326,  0.8387,  0.2775,  1.0378,  0.2723,  1.4563,  1.0544,\n",
      "         0.2936,  0.9195,  1.2052,  2.0448,  0.6437,  0.3325,  1.3657,  0.7064],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.2180,  1.8093, -0.1458, -0.6625,  2.0263, -0.2995, -1.1373,  0.9585,\n",
      "        -0.9475,  0.4726, -0.1165, -0.8380,  0.1497, -0.7933,  0.0085, -1.2385,\n",
      "        -1.3571,  0.9895, -0.4593, -0.1294,  1.5430, -1.4236,  0.7850,  0.0836,\n",
      "         1.0863, -0.0871,  0.0590,  0.1634,  0.1691,  0.0884, -1.2855, -1.6592,\n",
      "        -0.1677, -1.6942, -0.9596, -0.1796, -0.4147,  2.0863, -0.4960,  1.4641,\n",
      "         0.1373,  1.5933, -0.1544,  0.0328, -1.3749, -1.3709,  1.9693, -1.2829,\n",
      "         0.0319, -1.6584,  1.1744,  0.3701,  0.0435,  0.1036,  0.4243,  0.0550,\n",
      "         0.1492, -0.0525, -1.0148, -1.1201, -0.0289, -0.9005, -0.3071, -1.5838,\n",
      "         0.4952, -1.0526, -0.8584,  2.0852,  0.1434, -0.5158,  0.1640, -0.0946,\n",
      "         0.1424,  0.1783,  2.2122,  1.5077,  0.1164,  0.3043, -1.9380, -0.5424,\n",
      "        -1.3227,  0.1204, -0.3414, -0.4331, -0.8801, -0.1969, -1.9807, -0.1921,\n",
      "        -0.0219,  0.0103, -0.2205, -0.5727, -0.4073, -0.5317, -0.1285, -1.3184,\n",
      "         0.3818, -0.2724,  1.1390,  0.0273,  1.2142,  0.3881, -0.7911,  1.2363,\n",
      "        -0.0594,  1.9137,  0.0680, -0.1548,  0.7008,  0.0191, -0.2457, -0.1031,\n",
      "         0.2550,  0.0091, -0.4027, -1.2723, -1.1746,  0.8075, -0.2331, -1.2457,\n",
      "        -0.9264, -0.0827, -0.2707, -0.9284,  0.1321,  1.1939,  0.1276,  0.3344,\n",
      "         0.3340,  0.1101, -0.2049,  0.2230,  0.2989, -1.0716, -0.0513, -1.5676,\n",
      "         0.4797,  0.2113,  1.3063, -1.6876,  0.5694,  0.0566, -1.0860, -0.3390,\n",
      "         1.8033, -0.9339, -0.8609,  1.4717, -0.3613, -0.7915,  1.0305,  0.8726,\n",
      "        -0.2669,  0.2182,  0.3247,  0.3379,  0.7413, -1.2595,  0.4298, -0.9717,\n",
      "         0.9797, -1.4876,  0.1359,  0.1366, -0.5130, -1.0741, -0.4622, -1.5887,\n",
      "         1.2878,  0.9780,  0.0788, -0.6971,  1.5932,  0.0494, -1.4227, -1.5429,\n",
      "         1.2150, -1.0398, -0.2198,  0.1083, -1.7108, -0.1174, -1.2010, -1.7265,\n",
      "        -0.0546, -0.2049,  0.0407, -0.4857, -0.1310,  0.3165,  2.2460, -0.0145],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1981, -0.2858, -0.4611, -0.2425, -0.2139],\n",
      "          [-0.0661,  0.0794,  0.7063,  0.2306, -0.2976],\n",
      "          [-0.4461,  0.2758,  1.0508,  0.6908, -0.5365],\n",
      "          [-0.1284,  0.3987,  0.6824,  0.3589, -0.0308],\n",
      "          [-0.0672, -0.4256, -0.4951,  0.0156,  0.1072]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3778, -0.0930, -0.6117,  0.3570,  0.2427],\n",
      "          [-0.0087, -0.8381,  0.0535,  0.2700,  0.0541],\n",
      "          [-0.4888,  0.2111,  0.7159,  0.1015,  0.1118],\n",
      "          [-0.0404,  0.5764,  0.2846, -0.7999, -0.0996],\n",
      "          [ 0.1196,  0.2937, -0.2068, -0.3229,  0.1359]]],\n",
      "\n",
      "\n",
      "        [[[-0.2409,  0.3550,  0.3265, -0.2782,  0.0467],\n",
      "          [-0.7047, -0.5515, -0.4093,  0.0205, -0.5963],\n",
      "          [-0.1704, -0.5246, -0.3699, -0.5846, -0.4703],\n",
      "          [-0.0324, -0.5249, -0.2736, -0.4495, -0.3491],\n",
      "          [ 0.0613,  0.0042, -0.3180, -0.0216,  0.0869]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0902,  0.6530,  0.2112,  0.1576, -0.2984],\n",
      "          [ 0.0446,  0.4920,  0.4810,  0.3973, -0.2392],\n",
      "          [-0.6716, -0.6399, -0.6968,  0.1025, -0.3232],\n",
      "          [ 0.1037, -0.1817, -0.4592, -0.1718, -0.1841],\n",
      "          [ 0.4152,  0.2127,  0.1724,  0.1080, -0.1237]]],\n",
      "\n",
      "\n",
      "        [[[-0.2421, -0.0968, -0.3008, -0.3514, -0.6012],\n",
      "          [-0.3379,  0.4663,  0.4942,  0.2305, -0.2170],\n",
      "          [-0.1675,  0.8547,  1.3582,  0.5749, -0.3129],\n",
      "          [-0.0790,  0.2805,  0.6146,  0.2297,  0.0414],\n",
      "          [-0.2152, -0.1031, -0.3582, -0.0879, -0.2453]]],\n",
      "\n",
      "\n",
      "        [[[-0.0476, -0.2012, -0.4709, -0.1970, -0.1354],\n",
      "          [-0.3220,  0.2181,  0.5821,  0.1934, -0.4794],\n",
      "          [-0.5063,  0.8554,  1.7405,  0.5186, -0.3910],\n",
      "          [-0.3182,  0.0699,  0.5210, -0.0101,  0.0036],\n",
      "          [-0.1045, -0.4954, -0.4428, -0.4520, -0.1009]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.9804, 2.9602, 2.2934, 2.2187, 2.9656, 2.9164, 1.6513, 2.0472, 1.4143,\n",
      "        2.0540, 1.7322, 1.4370, 3.0109, 1.6408, 2.3463, 1.7415, 1.6067, 2.1730,\n",
      "        2.9288, 3.0403, 3.1161, 1.2416, 1.8819, 2.5465, 2.1239, 1.5043, 3.0918,\n",
      "        1.5602, 2.5080, 1.9214, 2.7685, 2.0924, 2.3276, 1.5012, 1.3365, 2.1863,\n",
      "        2.8025, 2.5101, 2.3547, 1.7590, 2.6431, 3.1172, 3.0306, 1.4104, 1.7137,\n",
      "        0.9483, 2.9263, 1.5489, 1.2531, 0.5758, 1.4463, 1.7094, 2.3437, 1.6591,\n",
      "        2.7476, 2.3550, 2.2709, 2.3152, 1.4962, 1.7487, 2.0252, 2.1570, 1.5581,\n",
      "        1.0445, 1.6984, 1.6007, 2.7764, 3.7173, 2.8952, 1.4202, 2.4260, 2.0823,\n",
      "        3.0019, 2.9512, 1.7816, 1.4314, 2.6033, 1.8476, 1.1701, 2.6740, 1.8817,\n",
      "        2.1879, 1.7945, 1.8336, 1.2333, 2.0232, 1.2902, 2.4788, 2.2810, 2.3990,\n",
      "        2.8284, 1.8843, 2.0486, 3.3890, 2.3300, 1.7117, 2.7851, 2.1512, 3.5901,\n",
      "        2.9829, 4.0774, 2.1932, 1.9174, 2.2096, 2.8401, 3.0364, 2.2542, 2.5479,\n",
      "        2.0640, 1.7902, 1.5777, 1.7950, 1.7824, 1.1591, 2.0928, 1.3627, 2.5246,\n",
      "        3.2317, 2.2124, 1.0480, 0.9819, 2.5653, 1.4646, 2.3200, 3.2856, 2.3244,\n",
      "        2.0368, 2.3049, 2.6338, 1.3204, 1.2681, 2.3049, 2.8420, 1.2474, 2.1476,\n",
      "        0.9625, 1.9674, 2.3806, 2.4167, 2.6734, 1.5943, 1.9665, 1.5706, 1.4546,\n",
      "        1.9480, 1.4993, 0.8713, 1.7332, 1.5661, 1.9525, 2.0642, 2.0327, 2.9577,\n",
      "        2.1489, 2.2054, 2.5273, 3.0933, 1.2532, 2.4308, 1.7025, 2.1565, 0.7630,\n",
      "        1.7785, 2.6973, 1.8640, 1.2584, 2.7250, 1.2199, 1.4429, 2.6132, 1.5672,\n",
      "        1.2580, 1.7356, 2.2683, 1.2157, 1.9717, 2.0934, 2.3785, 1.6177, 2.1239,\n",
      "        1.4073, 2.2560, 2.5272, 1.3579, 2.8233, 2.0876, 2.2850, 1.9971, 3.2160,\n",
      "        2.1446, 1.5012, 2.5070], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.5682e+00, -1.0917e+00,  6.0862e-01,  1.3268e+00, -2.0710e+00,\n",
      "        -7.7321e-01,  9.8320e-01,  3.3088e+00, -9.8392e-01,  2.8852e+00,\n",
      "         1.9157e+00,  2.5068e+00, -1.0999e+00,  2.4378e+00, -9.5813e-01,\n",
      "         9.8454e-01,  2.8338e+00,  2.9158e+00, -7.8594e-01, -6.6650e-01,\n",
      "        -1.2451e+00,  2.6288e+00, -1.4788e+00, -1.2465e+00, -4.8376e-01,\n",
      "         2.1590e+00, -8.6343e-01,  2.8332e+00, -1.4491e+00, -1.2088e+00,\n",
      "         1.5496e+00,  1.0788e+00, -1.0779e+00,  2.5111e+00,  6.3090e-01,\n",
      "        -1.3334e+00, -4.2250e-01, -1.6676e+00, -7.5244e-01, -1.2014e+00,\n",
      "        -1.6480e-01, -6.3254e-01, -1.0260e+00,  1.9372e+00,  1.8597e+00,\n",
      "         2.3665e+00, -1.2915e+00,  2.0502e+00,  2.6319e+00,  3.6353e+00,\n",
      "         3.2993e+00,  3.5289e+00, -3.0021e-01,  2.7277e+00, -3.7592e-01,\n",
      "        -7.3010e-01, -1.5230e+00, -1.6404e+00,  4.0678e+00,  1.3258e+00,\n",
      "        -6.3409e-01, -7.6194e-01,  2.5378e+00,  1.4865e+00,  2.7077e+00,\n",
      "         2.5487e+00, -1.1868e+00, -1.9359e+00,  2.5059e-01,  3.4400e+00,\n",
      "         1.0694e-01, -1.6093e+00, -7.4560e-01, -9.4262e-01,  3.0227e+00,\n",
      "         4.0342e+00, -1.0244e+00,  3.3658e+00,  1.5521e+00,  1.8019e-02,\n",
      "         1.1991e+00, -1.2746e+00,  1.7859e+00,  6.6740e-01,  1.8342e+00,\n",
      "        -1.3390e+00, -2.2718e+00,  1.7903e-01, -6.8857e-01, -3.5747e-01,\n",
      "         2.0656e-01,  2.0642e+00,  1.2395e+00, -1.6013e+00,  2.4793e+00,\n",
      "         2.2749e+00, -9.1103e-01,  7.2230e-02, -1.9529e+00, -1.1861e+00,\n",
      "        -1.0535e+00, -1.3468e+00,  1.2059e+00, -1.1861e+00, -8.5301e-01,\n",
      "        -8.3371e-01, -1.0246e+00, -1.4149e+00, -1.6525e+00,  2.6286e+00,\n",
      "        -7.1638e-01,  2.4838e+00,  9.7073e-01, -6.3060e-01,  2.1923e+00,\n",
      "         2.9074e+00,  6.7738e-01, -9.9500e-01, -3.8142e-01,  1.9828e+00,\n",
      "         2.8563e+00, -7.4879e-01,  2.4213e+00, -1.3660e+00, -8.6462e-01,\n",
      "        -9.5133e-01, -1.5547e+00,  5.0735e+00, -1.2588e+00,  3.8135e+00,\n",
      "         2.6727e+00, -7.5815e-01, -8.4039e-01,  1.9867e+00,  1.7412e+00,\n",
      "         3.2209e+00, -1.8118e+00, -4.1633e-01, -1.1783e+00,  7.7336e-01,\n",
      "         2.1226e+00,  4.2007e-01,  1.6890e+00,  2.2082e+00, -1.2997e+00,\n",
      "         1.6847e+00,  2.4637e+00,  2.8380e+00,  1.2818e+00,  1.8712e+00,\n",
      "        -1.7547e+00, -3.1530e-03,  2.3062e-01,  2.4328e+00, -1.3751e+00,\n",
      "        -1.1418e+00,  2.1871e-02,  2.9522e+00, -7.8542e-01,  2.9791e+00,\n",
      "        -6.0006e-01,  4.1511e+00, -1.9639e+00, -4.4254e-01,  5.4157e-01,\n",
      "         1.9347e+00,  4.7942e-02,  1.7244e+00,  2.7587e+00, -1.2434e+00,\n",
      "        -1.2110e+00,  2.2810e+00,  4.6017e+00,  3.1931e+00,  3.8697e+00,\n",
      "         5.9858e-01, -9.9646e-01,  9.8839e-01,  2.3539e+00, -1.5484e+00,\n",
      "         2.3302e+00, -1.3352e+00, -9.0539e-01,  2.4836e+00, -6.4578e-01,\n",
      "         2.5009e+00, -6.6022e-01,  1.7685e+00, -5.3729e-01, -1.3107e+00,\n",
      "         4.5317e+00,  3.0863e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0163]],\n",
      "\n",
      "         [[-0.1856]],\n",
      "\n",
      "         [[-0.0260]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1444]],\n",
      "\n",
      "         [[-0.4414]],\n",
      "\n",
      "         [[-0.1073]]],\n",
      "\n",
      "\n",
      "        [[[-0.1384]],\n",
      "\n",
      "         [[-0.1368]],\n",
      "\n",
      "         [[-0.0798]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1502]],\n",
      "\n",
      "         [[-0.4195]],\n",
      "\n",
      "         [[ 0.0275]]],\n",
      "\n",
      "\n",
      "        [[[-0.0767]],\n",
      "\n",
      "         [[ 0.0202]],\n",
      "\n",
      "         [[-0.1299]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0702]],\n",
      "\n",
      "         [[-0.0194]],\n",
      "\n",
      "         [[-0.1453]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1238]],\n",
      "\n",
      "         [[-0.1058]],\n",
      "\n",
      "         [[-0.0437]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0123]],\n",
      "\n",
      "         [[-0.0921]],\n",
      "\n",
      "         [[-0.0172]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1846]],\n",
      "\n",
      "         [[-0.1183]],\n",
      "\n",
      "         [[-0.1288]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0376]],\n",
      "\n",
      "         [[-0.2565]],\n",
      "\n",
      "         [[-0.0942]]],\n",
      "\n",
      "\n",
      "        [[[-0.0228]],\n",
      "\n",
      "         [[ 0.0140]],\n",
      "\n",
      "         [[-0.3204]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0079]],\n",
      "\n",
      "         [[ 0.0017]],\n",
      "\n",
      "         [[-0.0758]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0881, -0.1015, -0.0746, -0.0966, -0.0975, -0.1021, -0.1143, -0.1384],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 5.0659e-04]],\n",
      "\n",
      "         [[-1.0592e-01]],\n",
      "\n",
      "         [[-3.7652e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1716e-01]],\n",
      "\n",
      "         [[ 2.3329e-01]],\n",
      "\n",
      "         [[-1.1550e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7456e-04]],\n",
      "\n",
      "         [[ 1.0289e-01]],\n",
      "\n",
      "         [[ 2.0109e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7061e-02]],\n",
      "\n",
      "         [[-4.8547e-02]],\n",
      "\n",
      "         [[-6.4893e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6002e-01]],\n",
      "\n",
      "         [[-4.5766e-02]],\n",
      "\n",
      "         [[ 2.3224e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9683e-02]],\n",
      "\n",
      "         [[-1.7902e-02]],\n",
      "\n",
      "         [[-9.1171e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.1747e-02]],\n",
      "\n",
      "         [[-5.9980e-02]],\n",
      "\n",
      "         [[ 6.2449e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2623e-02]],\n",
      "\n",
      "         [[ 5.6271e-02]],\n",
      "\n",
      "         [[-1.0610e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.8661e-01]],\n",
      "\n",
      "         [[-7.3181e-01]],\n",
      "\n",
      "         [[ 8.4036e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0526e-02]],\n",
      "\n",
      "         [[-4.8544e-01]],\n",
      "\n",
      "         [[ 2.3290e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2572e-01]],\n",
      "\n",
      "         [[ 1.3774e-01]],\n",
      "\n",
      "         [[-3.2411e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2201e-01]],\n",
      "\n",
      "         [[ 4.8061e-02]],\n",
      "\n",
      "         [[-1.8430e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1628,  0.1790,  0.1864, -0.0331,  0.3646, -0.2472,  0.0441,  0.0971,\n",
      "        -0.4936,  0.5495,  0.7065,  0.3036, -0.0120, -0.1973, -0.0276,  0.1700,\n",
      "        -0.1560,  0.4550, -0.3408, -0.1514, -0.1077,  0.0200, -0.0789,  0.3547,\n",
      "         0.1489,  0.0823,  0.0866, -0.0652,  0.2801, -0.3652,  0.6540,  0.2207,\n",
      "         0.0403,  0.0626, -0.3055, -0.1948, -0.2403,  0.2400, -0.0480, -0.0522,\n",
      "         0.2411,  0.2491,  0.1813,  0.4023,  0.1135, -0.4531, -0.0815, -0.1020,\n",
      "        -0.5606,  0.0960,  0.4403,  0.4435, -0.2951,  0.4454, -0.1000,  0.2974,\n",
      "        -0.2880,  0.0485,  0.0167, -0.1267, -0.4023, -0.0238, -0.0817, -0.1409,\n",
      "        -0.2832,  0.0139, -0.3655,  0.1322, -0.0513,  0.0180,  0.3497,  0.1574,\n",
      "        -0.4502, -0.2907,  0.0107,  0.2640,  0.0525,  0.0540, -0.2560,  0.0185,\n",
      "         0.0661, -0.4002, -0.0340,  0.4120, -0.2561, -0.2923, -0.6615, -0.2392,\n",
      "         0.2955,  0.2467, -0.0516,  0.2024,  0.6309,  0.0742,  0.1497,  0.0455,\n",
      "        -0.0796,  0.0118,  0.2201,  0.0425,  0.4300,  0.1076,  0.5862, -0.2689,\n",
      "        -0.5679,  0.0884,  0.3706,  0.1125, -0.1086, -0.4345, -0.3018,  0.2637,\n",
      "        -0.3918, -0.2787,  0.0769, -0.1246,  0.1026,  0.0564, -0.2417, -0.2063,\n",
      "         0.3417,  0.1435, -0.2652, -0.3800,  0.1929,  0.2096, -0.4213,  0.9573,\n",
      "         0.7438, -0.0479, -0.1589, -0.0824, -0.0107, -0.0920, -0.0389, -0.3783,\n",
      "        -0.0300, -0.0420,  0.0165,  0.5375,  0.0709,  0.2589, -0.1243,  0.2082,\n",
      "        -0.1743, -0.2357, -0.0629,  0.7927,  0.0515,  0.9406, -0.1117, -0.1507,\n",
      "        -0.3722,  0.4625,  0.1617,  0.0551,  0.4300, -0.1279,  0.0918,  0.2438,\n",
      "        -0.0472,  0.1918, -0.1895,  0.5374, -0.2754, -0.0210, -0.2154, -0.1917,\n",
      "         0.2725,  0.1364, -0.5470, -0.0927,  0.2678,  0.3263,  0.3886,  0.1202,\n",
      "        -0.2887,  0.1301,  0.0456,  0.0828, -0.0045, -0.0026, -0.3214, -0.0214,\n",
      "        -0.3273,  0.2845,  0.2054,  0.2922, -0.2345,  0.0961, -0.6975,  0.5827],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.4248]],\n",
      "\n",
      "         [[-0.2559]],\n",
      "\n",
      "         [[ 0.2329]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0172]],\n",
      "\n",
      "         [[ 0.9838]],\n",
      "\n",
      "         [[-0.1639]]],\n",
      "\n",
      "\n",
      "        [[[-0.7814]],\n",
      "\n",
      "         [[ 0.2369]],\n",
      "\n",
      "         [[-0.1176]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1537]],\n",
      "\n",
      "         [[ 0.1642]],\n",
      "\n",
      "         [[-0.0644]]],\n",
      "\n",
      "\n",
      "        [[[-0.3201]],\n",
      "\n",
      "         [[ 0.3453]],\n",
      "\n",
      "         [[-0.4854]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1156]],\n",
      "\n",
      "         [[ 0.4835]],\n",
      "\n",
      "         [[-1.3274]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0849]],\n",
      "\n",
      "         [[ 0.3829]],\n",
      "\n",
      "         [[ 0.0685]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5921]],\n",
      "\n",
      "         [[ 0.4477]],\n",
      "\n",
      "         [[ 0.2653]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2161]],\n",
      "\n",
      "         [[-0.4999]],\n",
      "\n",
      "         [[-0.2352]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3821]],\n",
      "\n",
      "         [[-0.3664]],\n",
      "\n",
      "         [[ 0.0353]]],\n",
      "\n",
      "\n",
      "        [[[-0.4515]],\n",
      "\n",
      "         [[-0.3573]],\n",
      "\n",
      "         [[-0.2369]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2418]],\n",
      "\n",
      "         [[-0.4422]],\n",
      "\n",
      "         [[ 0.2076]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([7.0405, 7.6519, 5.2559, 8.0711, 3.1313, 5.9586, 4.3578, 5.1163, 6.7716,\n",
      "        7.3960, 5.3416, 6.0699, 5.6801, 5.8953, 9.6289, 5.6397, 3.3046, 5.0453,\n",
      "        9.8900, 6.9123, 5.7309, 3.5599, 5.9047, 5.5010, 8.0797, 5.6462, 7.6761,\n",
      "        5.9791, 8.8122, 4.9227, 5.6756, 6.6985, 5.9584, 4.7913, 5.9218, 5.2855,\n",
      "        7.0408, 6.3342, 5.1123, 6.1562, 7.6463, 7.2842, 5.3026, 7.9879, 6.9713,\n",
      "        5.9437, 6.7258, 7.0730], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.0162, -0.0259, -0.0195,  0.0061, -0.0008, -0.0025,  0.0154, -0.0060,\n",
      "        -0.0043,  0.0167, -0.0056,  0.0267,  0.0014, -0.0159,  0.0425, -0.0108,\n",
      "        -0.0034,  0.0088,  0.0235, -0.0016, -0.0050, -0.0140,  0.0003,  0.0115,\n",
      "         0.0271,  0.0314, -0.0085, -0.0359,  0.0519,  0.0014, -0.0157,  0.0123,\n",
      "         0.0059, -0.0036, -0.0368, -0.0148,  0.0203,  0.0042, -0.0024, -0.0045,\n",
      "        -0.0267,  0.0252, -0.0140,  0.0297,  0.0368, -0.0037,  0.0127,  0.0338],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-2.5040e-01]],\n",
      "\n",
      "         [[ 6.4210e-02]],\n",
      "\n",
      "         [[-3.2465e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.5840e-02]],\n",
      "\n",
      "         [[-3.1397e-01]],\n",
      "\n",
      "         [[ 7.1020e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2089e-01]],\n",
      "\n",
      "         [[-4.8202e-02]],\n",
      "\n",
      "         [[ 1.4529e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6550e-01]],\n",
      "\n",
      "         [[-3.2386e-02]],\n",
      "\n",
      "         [[ 1.7327e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7876e-01]],\n",
      "\n",
      "         [[ 3.6429e-02]],\n",
      "\n",
      "         [[-2.0780e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8293e-01]],\n",
      "\n",
      "         [[ 3.2806e-01]],\n",
      "\n",
      "         [[-2.2317e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.9552e-01]],\n",
      "\n",
      "         [[-4.0891e-02]],\n",
      "\n",
      "         [[ 2.4244e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3273e-02]],\n",
      "\n",
      "         [[ 7.9740e-02]],\n",
      "\n",
      "         [[-4.0429e-03]]],\n",
      "\n",
      "\n",
      "        [[[-8.3049e-01]],\n",
      "\n",
      "         [[-4.5439e-02]],\n",
      "\n",
      "         [[ 5.0174e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1654e-01]],\n",
      "\n",
      "         [[-3.0176e-01]],\n",
      "\n",
      "         [[ 2.3730e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.9458e-02]],\n",
      "\n",
      "         [[ 6.3871e-02]],\n",
      "\n",
      "         [[ 1.3251e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8368e-02]],\n",
      "\n",
      "         [[ 3.1050e-01]],\n",
      "\n",
      "         [[-4.8569e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.3481,  0.2067,  1.4409,  0.3396,  1.0130,  2.1128,  2.5036,  0.2139,\n",
      "         0.1982,  0.3039,  0.2600,  2.1107,  1.2594,  1.6528,  0.3742,  1.1261,\n",
      "         0.3208,  1.0570,  1.3831,  1.3630,  1.2862,  1.2535,  0.1271,  0.2806,\n",
      "         0.5543,  2.2141,  0.2532,  0.9728,  0.5875,  0.4467,  0.5817,  0.5154,\n",
      "         1.4145,  1.0534,  1.3796,  1.0549,  0.2949,  0.2691,  0.3746,  1.3348,\n",
      "         0.9603,  0.1348,  0.9341,  0.7435,  1.2247,  1.2246,  1.3873, -0.5278,\n",
      "         1.3192,  1.3842,  0.3151,  1.9451,  0.4208,  0.4116,  3.4015,  0.8600,\n",
      "         0.2668,  0.3578,  1.6976,  0.4090,  1.1369,  0.8761,  0.4083,  0.5333,\n",
      "         0.5441,  1.0368,  2.2693,  0.8781,  0.5256,  2.2617,  1.6678,  1.8818,\n",
      "         0.7421,  1.1444,  1.0668,  2.8824,  0.9410,  1.1236,  0.9016,  0.8286,\n",
      "         1.6832,  0.5668,  1.9663,  1.6230,  0.8815,  0.4583,  1.8695,  1.1082,\n",
      "         0.3036,  0.2238,  0.7891,  1.5020,  0.1387,  0.6760,  0.2477,  0.6363,\n",
      "         0.2562,  0.4774,  1.3927,  0.5054,  1.3570,  0.9984,  1.6221,  2.3774,\n",
      "         0.7766,  0.8458,  0.9062,  1.8031,  1.0707,  0.2237,  0.9237,  1.1011,\n",
      "         0.5798,  0.3166,  0.3871,  1.9565,  0.3508,  0.5448,  0.5897,  0.9403,\n",
      "         1.8294,  0.3962, -0.4236,  1.1370,  0.4960,  0.1746,  0.7348,  1.6415,\n",
      "         0.5202,  1.1754,  0.6227,  0.9006,  0.1114,  1.0563,  1.8510,  1.1905,\n",
      "         0.8660,  1.0810,  0.3304,  0.5891,  0.3719,  1.1344,  1.5554,  1.0500,\n",
      "         0.5859,  0.5582, -0.4465,  0.5554,  1.4540,  3.1979,  0.6194,  0.7402,\n",
      "         0.5647,  1.8256,  2.8986,  0.9212,  0.9527,  1.5838,  0.1598,  0.3944,\n",
      "         1.5398,  2.0319,  0.6944,  1.2545,  1.0286,  1.8312,  0.8986,  0.7991,\n",
      "         1.0282,  1.1863,  0.3020,  1.5855,  1.1296,  1.2071,  1.3142,  0.1257,\n",
      "         0.5956,  0.4038,  1.1206,  0.8160,  1.5909,  1.1436,  0.7181,  0.8681,\n",
      "         1.3907,  1.8509,  1.2470,  0.6582,  1.6695,  0.6793,  0.9049,  0.2454,\n",
      "         0.9935,  0.4888,  1.4164,  0.1358,  0.8898,  1.2042,  1.7533,  1.0227,\n",
      "         0.2016,  1.4944,  0.2671,  0.6147,  0.8440,  2.4260,  0.4811,  0.3359,\n",
      "         0.7970,  0.3304,  1.6506,  0.6548,  0.8765,  1.4220,  0.9262,  0.4364,\n",
      "         0.3706,  1.9830,  0.6665,  0.6063,  0.7192,  0.8740,  0.5339,  1.2553,\n",
      "         0.7941,  0.3250,  1.7459,  0.7631,  0.6326,  1.0553,  0.5470,  0.6968,\n",
      "         1.8444,  0.9316,  1.2437,  1.1142,  1.6610,  1.9522,  0.0821,  0.9583,\n",
      "         1.9761,  1.5867,  1.2267,  0.5521,  0.6034,  1.2912,  1.6047,  0.3674,\n",
      "         0.6990,  0.5926,  1.0502,  0.1868,  1.0444,  1.3851,  1.1345,  0.5308,\n",
      "         1.2978,  2.9467,  1.4131,  1.4465,  1.5889,  0.5105,  0.9811,  0.9838,\n",
      "         1.7063,  0.2663,  0.5930,  1.1305,  1.7815,  0.2609,  1.2157,  0.7942,\n",
      "         0.8995,  1.4477,  0.9851,  0.1625,  1.3223,  1.1669,  1.3777,  0.8871,\n",
      "         0.7447,  0.3441,  1.7592,  1.5716,  1.8583,  1.2110,  0.2667,  1.7854],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 4.6905e-01,  2.1194e-01,  1.3763e+00,  1.1264e-01, -3.9209e-01,\n",
      "        -2.1493e-01, -1.6790e+00,  4.4857e-01,  4.4804e-01,  2.4146e-01,\n",
      "        -2.6155e-01, -8.6204e-01, -2.6331e-01,  1.7580e+00,  4.3059e-01,\n",
      "        -3.2565e-03,  9.0354e-01,  8.8620e-01, -4.9958e-01,  2.8376e+00,\n",
      "         2.4525e+00, -4.1676e-01,  4.9024e-01, -3.5837e-01,  1.7475e+00,\n",
      "         4.0252e-01,  3.4496e-01, -2.9073e-01, -6.5235e-02,  1.1941e-01,\n",
      "         5.3014e-01,  5.8003e-02,  1.0097e+00, -2.6784e-01,  3.2088e-01,\n",
      "         8.1033e-01, -1.7658e-01, -3.0443e-01,  3.0934e-01, -3.5076e-01,\n",
      "        -9.1044e-01,  3.6583e-01,  1.7366e+00,  6.5324e-01, -1.8046e+00,\n",
      "         9.6725e-01, -1.2343e+00,  1.5201e-01, -9.0507e-02,  8.4998e-01,\n",
      "         5.4250e-01, -3.3698e+00, -2.8480e-01,  5.0835e-01, -3.9071e-01,\n",
      "        -1.2351e+00, -3.4229e-01, -3.0900e-01,  7.3030e-02, -1.6181e-01,\n",
      "        -1.5795e+00, -4.3887e-01,  2.3730e-01,  3.5710e-01, -4.8691e-01,\n",
      "         1.5582e+00, -2.8672e+00,  1.6186e-01,  2.7635e-01,  5.3708e-01,\n",
      "        -8.5283e-01,  2.2710e-01,  9.0432e-01,  6.5410e-01,  5.1355e-01,\n",
      "        -3.1637e+00,  1.4973e+00,  1.2398e+00, -9.9341e-02,  8.0214e-01,\n",
      "         1.5301e+00,  7.0818e-01, -1.5046e+00, -1.1222e+00,  3.9574e-01,\n",
      "         2.7619e-02,  4.6742e-01, -1.6189e-01, -9.9140e-02, -2.1752e-03,\n",
      "         1.1118e+00,  9.9359e-01,  1.4176e-01, -9.2999e-02,  1.7318e-01,\n",
      "         5.4557e-01,  6.6433e-01,  1.6800e+00, -2.7380e-01, -8.7930e-02,\n",
      "        -4.7693e-01,  1.2726e+00,  2.4703e-01, -2.4663e-01, -4.0413e-01,\n",
      "        -2.2698e-01, -1.1222e+00,  2.9776e+00, -6.4526e-01,  2.4995e-01,\n",
      "         1.2422e+00, -1.4891e+00,  3.3353e-01, -1.9837e-01,  8.0846e-02,\n",
      "         5.0362e-01,  6.9898e-02,  5.2403e-01, -8.5761e-02, -1.3244e+00,\n",
      "         1.5620e-01, -1.2605e-01,  7.1577e-02,  1.7112e+00,  5.7960e-01,\n",
      "         3.6533e-01,  2.3315e+00,  1.0689e+00, -2.8164e-01, -8.7584e-01,\n",
      "        -1.6445e-01,  1.3333e+00, -2.7998e-01, -3.0210e-01,  1.0178e+00,\n",
      "         3.1055e-01, -4.2312e-01,  7.2654e-01,  3.8776e-02,  2.4620e-01,\n",
      "         1.9544e-01, -3.5874e-01,  3.9616e-01, -5.3026e-01,  6.1929e-01,\n",
      "        -3.0541e-01,  2.3952e-01, -1.8097e-01,  3.9457e-01, -4.0387e-01,\n",
      "        -9.5726e-01,  4.8065e-01, -5.9803e-02,  1.3833e-01,  9.4574e-01,\n",
      "        -5.0854e-01, -2.9975e-01,  4.0085e-02,  1.7192e-01, -5.9235e-02,\n",
      "         9.1265e-01,  8.1818e-03, -2.9839e-01, -3.8882e-01, -1.3625e+00,\n",
      "         1.5502e+00,  3.3290e-01,  1.6211e+00,  8.4813e-01, -1.2227e+00,\n",
      "         3.1286e-01,  1.9980e+00, -1.0091e+00, -3.9368e-01,  1.0559e+00,\n",
      "         3.1807e-01, -9.8146e-01,  2.9614e-01, -6.0523e-01,  1.2583e+00,\n",
      "        -3.4740e-01, -1.8961e+00,  4.1098e-01, -9.4243e-01,  8.4586e-01,\n",
      "        -2.3436e-01, -2.1837e-01, -6.6393e-01,  8.9782e-01, -3.7923e-02,\n",
      "        -9.8439e-01,  1.4848e-01,  1.0888e+00, -3.2759e-02,  7.2749e-01,\n",
      "        -1.5802e-01, -1.4974e+00, -3.4715e-01, -1.9307e+00,  8.4760e-01,\n",
      "        -6.6690e-02,  7.6176e-01,  1.2388e-01, -3.4951e-01,  4.8203e-01,\n",
      "        -1.1516e-01,  8.5316e-02,  1.1058e-01, -2.5449e-01,  5.2711e-01,\n",
      "        -5.0337e-01,  6.9248e-01,  3.2784e-02,  2.0221e-01,  1.0486e+00,\n",
      "        -3.7178e-01,  1.0981e-01, -2.6880e+00,  6.4803e-02, -3.0968e-01,\n",
      "         8.8962e-01,  2.9560e-01,  2.2393e-01,  9.2979e-01, -7.6081e-01,\n",
      "         1.4527e-01, -3.4070e-01, -8.5719e-01, -2.4822e-01, -1.0902e+00,\n",
      "         8.1432e-01,  7.6493e-01,  2.6374e-01,  9.4292e-01,  9.1212e-01,\n",
      "         1.1650e+00,  3.3362e-01, -4.1339e-01, -3.9495e-01,  1.8918e+00,\n",
      "         3.9746e-01,  1.7680e-01, -9.7842e-01,  7.5637e-01, -7.7040e-02,\n",
      "         1.2969e+00,  2.6218e-01, -2.5353e-01,  3.6710e-01,  4.3471e-01,\n",
      "        -1.1282e+00,  1.9314e-01,  1.6481e+00,  1.8679e-01,  8.7433e-01,\n",
      "        -1.5906e+00, -6.1024e-01,  1.0224e+00, -9.5237e-01, -1.8137e-01,\n",
      "        -3.7574e+00, -9.3007e-01,  8.8872e-02, -3.6564e-01,  7.0847e-01,\n",
      "         9.6210e-01, -4.3143e-01, -1.3315e+00,  1.7113e-01,  2.0907e-01,\n",
      "         1.5874e+00,  4.9833e-01, -6.9825e-02,  1.7260e+00, -1.0629e+00,\n",
      "        -1.1020e-01,  1.6258e+00,  9.4020e-01,  1.4793e+00, -8.1747e-02,\n",
      "        -1.3463e-01, -5.8388e-02,  6.5683e-01, -1.0784e+00,  6.6552e-01,\n",
      "         1.0041e+00, -1.1717e-01,  5.1962e-01], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-3.3207e-01, -3.5768e-01, -1.9813e-01, -5.4361e-01,  5.0406e-02],\n",
      "          [-4.1755e-01, -5.8047e-01, -1.5841e-02, -1.2063e-01, -1.4297e-01],\n",
      "          [-4.1804e-01, -5.6880e-01,  5.2028e-01, -1.0879e-01, -6.0857e-01],\n",
      "          [ 9.9235e-02, -3.1244e-01, -1.3036e-01, -2.4670e-01, -2.8253e-01],\n",
      "          [ 8.3104e-02, -1.1745e-01, -5.0728e-01, -5.3389e-01, -1.7082e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.8874e-02,  6.0652e-02, -7.8434e-02, -3.3424e-01,  5.3018e-01],\n",
      "          [ 3.1579e-02,  3.3944e-01,  2.7848e-01, -3.0855e-01, -3.7375e-01],\n",
      "          [-3.5833e-01,  1.0623e+00,  2.2937e-02, -1.0782e+00, -3.5613e-01],\n",
      "          [ 1.3655e-01,  1.1146e-01,  5.9137e-02, -1.9429e-01, -3.7230e-01],\n",
      "          [ 7.8295e-02, -2.5737e-01,  3.4835e-03, -1.5136e-01, -7.8141e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.3480e-02,  5.7356e-02,  3.2681e-01,  2.9917e-01, -5.7865e-02],\n",
      "          [ 9.6210e-02, -6.6420e-01,  1.0674e-01,  6.0370e-01,  5.2073e-01],\n",
      "          [ 3.2615e-01, -4.8596e-01, -5.9753e-01, -3.6145e-01,  1.3523e-01],\n",
      "          [ 1.9632e-01, -1.0666e-01, -6.2430e-02, -5.1598e-01, -3.6053e-01],\n",
      "          [-4.4636e-01, -4.7536e-01,  2.3316e-01,  1.5849e-01,  4.6501e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.7479e-01, -3.4065e-01, -4.7389e-01, -2.1508e-01, -6.4429e-01],\n",
      "          [-1.8700e-01,  1.0322e-01, -9.1601e-03,  2.7348e-01,  6.3974e-02],\n",
      "          [-4.8251e-01, -8.9065e-03,  4.8595e-01,  1.8678e-01, -6.1708e-01],\n",
      "          [-1.2524e-01,  1.2179e-01, -3.3466e-02,  4.1354e-01, -5.5015e-01],\n",
      "          [-7.6886e-01,  1.6950e-01, -7.1132e-01, -2.5853e-01, -3.9437e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.7134e-03, -3.8881e-01, -4.5217e-01, -3.7354e-01, -3.2433e-01],\n",
      "          [-2.5544e-01, -2.8043e-01, -3.7009e-01, -4.7107e-01,  7.9242e-02],\n",
      "          [ 4.6851e-01,  5.2858e-01,  6.1539e-01,  5.5889e-04,  9.6613e-02],\n",
      "          [-3.0190e-01,  1.4871e-01, -5.2546e-01,  2.2748e-01, -1.9450e-01],\n",
      "          [ 3.4475e-01,  6.0515e-01, -1.1247e-01, -3.9233e-02, -2.8813e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.2326e-01,  6.7864e-02, -3.0062e-01, -2.9837e-01,  6.9663e-02],\n",
      "          [-6.4121e-01, -4.1373e-01, -7.5561e-01, -2.4285e-01, -3.3871e-01],\n",
      "          [-5.2152e-01, -1.8217e-01, -3.3448e-01, -4.6247e-01, -2.5813e-01],\n",
      "          [-1.2159e-01,  4.2905e-01,  5.6395e-01,  1.4511e-01,  9.4047e-02],\n",
      "          [ 1.0328e-01, -6.7380e-02,  2.6038e-01,  2.1407e-01,  3.5378e-01]]]],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.1206, 2.5138, 1.9832, 1.8989, 1.6071, 1.6826, 2.7301, 1.9378, 1.6018,\n",
      "        2.2738, 1.6984, 1.6261, 2.0063, 1.3398, 2.0922, 1.3006, 1.5316, 2.2484,\n",
      "        0.8871, 2.2234, 2.7390, 2.0905, 1.2423, 1.5949, 1.8117, 1.4241, 1.7438,\n",
      "        1.3653, 1.8145, 1.8581, 1.8960, 1.8900, 0.8377, 1.6628, 1.6538, 1.8156,\n",
      "        1.6878, 1.8020, 1.6918, 1.4577, 0.4983, 1.6343, 2.3155, 1.5225, 0.6743,\n",
      "        1.6587, 1.5749, 1.6519, 2.1652, 1.5841, 1.5726, 3.9303, 1.6347, 1.8529,\n",
      "        3.1567, 2.1911, 1.9166, 1.7219, 1.6874, 1.2922, 2.1943, 1.4749, 1.6769,\n",
      "        1.7439, 1.3472, 0.8851, 3.6271, 1.7094, 0.9008, 0.9130, 2.1288, 1.9683,\n",
      "        1.9026, 1.9231, 1.8147, 2.7674, 1.8643, 1.8838, 2.0928, 1.3260, 2.0007,\n",
      "        1.6018, 2.6797, 2.2951, 1.8148, 1.8127, 0.5886, 1.7576, 2.0101, 2.7537,\n",
      "        0.6537, 2.6586, 2.3912, 1.7385, 1.3419, 2.0168, 2.2207, 1.6239, 1.2710,\n",
      "        1.9404, 1.7537, 1.6499, 0.5731, 2.0155, 0.7444, 1.4418, 1.6684, 2.8622,\n",
      "        1.8008, 1.7657, 1.5324, 3.3592, 1.2158, 2.1633, 1.7886, 2.0062, 2.6243,\n",
      "        1.0444, 1.1786, 0.9468, 0.1057, 1.8071, 1.8345, 1.4614, 0.1546, 1.7434,\n",
      "        1.6853, 1.5401, 1.3323, 0.9803, 2.7924, 1.8907, 1.8427, 0.6338, 1.5361,\n",
      "        1.8938, 1.9987, 1.8265, 1.4858, 1.9901, 1.6107, 1.4095, 1.8990, 0.9379,\n",
      "        1.7234, 1.6495, 1.5747, 1.9595, 1.4868, 4.0232, 1.9293, 2.0492, 1.6541,\n",
      "        1.4787, 3.0216, 0.8814, 1.7692, 2.7195, 2.0881, 1.9649, 1.5758, 1.6589,\n",
      "        0.5018, 2.5258, 0.7957, 2.2580, 2.0831, 2.2394, 1.6049, 0.3435, 2.3548,\n",
      "        2.4877, 1.0663, 2.8586, 1.8577, 1.5908, 1.2893, 2.9605, 0.8615, 1.6333,\n",
      "        0.9148, 0.6033, 1.5545, 0.7700, 2.0186, 1.9007, 1.7914, 1.7740, 1.4692,\n",
      "        1.9194, 0.6217, 2.8731, 1.5548, 1.3522, 1.9034, 2.0205, 0.9885, 1.9508,\n",
      "        2.4614, 2.0674, 2.5241, 1.7498, 3.4850, 1.9874, 2.0870, 1.0223, 2.4111,\n",
      "        1.9527, 1.1514, 1.5887, 1.6083, 1.6659, 1.7032, 2.5622, 1.7152, 1.6625,\n",
      "        2.4023, 2.2349, 1.8580, 1.5685, 1.6607, 1.1805, 1.5698, 1.8964, 2.1156,\n",
      "        2.0995, 0.6272, 1.6043, 1.7368, 0.7643, 1.5268, 1.9778, 0.7757, 1.5872,\n",
      "        2.0302, 1.9221, 2.2606, 0.7204, 1.3794, 2.3169, 2.1526, 0.4471, 1.5839,\n",
      "        1.9924, 3.8204, 1.8271, 1.0506, 1.4696, 0.5219, 1.8652, 1.0984, 1.8096,\n",
      "        1.6092, 2.0286, 1.7709, 1.1619, 0.9919, 1.8972, 0.8355, 0.5039, 0.5021,\n",
      "        1.3883, 1.4931, 0.8123, 2.2984, 1.3945, 1.2989, 0.8252, 1.4695, 2.7309,\n",
      "        2.9070, 1.3899, 1.5540, 2.0016, 1.5384, 2.0708, 1.8810, 2.4154, 2.3723,\n",
      "        1.7141, 1.2384, 1.9897, 2.2183, 2.0060, 1.3783, 1.5716, 1.7051, 1.7237],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-5.7802e-01, -1.3118e+00, -1.7934e+00, -1.0519e+00, -1.4314e+00,\n",
      "        -7.2280e-01, -1.1429e+00, -1.2345e+00, -1.9006e+00, -1.0973e+00,\n",
      "        -1.6434e+00,  3.7063e-01, -1.2440e+00, -7.8496e-02, -1.5374e+00,\n",
      "        -7.6877e-01, -1.8809e+00, -1.2493e+00,  4.6564e-01, -2.2158e+00,\n",
      "        -2.5939e+00,  3.8295e-02, -6.8560e-01, -1.3475e+00, -9.4032e-01,\n",
      "        -1.8118e-01, -1.2555e+00, -7.7577e-01, -1.2686e+00, -1.3352e+00,\n",
      "        -1.0485e+00, -1.2527e+00,  9.8129e-01, -1.4947e+00, -1.7433e+00,\n",
      "        -7.4759e-01, -1.2041e+00, -1.2800e+00, -1.2034e+00, -4.7174e-01,\n",
      "         3.6266e-01, -1.3654e+00, -1.2052e+00, -1.5830e+00,  5.8948e-02,\n",
      "        -1.1450e+00, -2.2179e+00, -1.3203e+00, -1.1204e-01, -1.3521e+00,\n",
      "        -2.0965e+00, -1.5490e+00, -1.3885e+00, -1.5525e+00, -1.5163e+00,\n",
      "         1.0204e+00, -1.5452e+00, -1.7424e+00, -1.2198e+00, -1.7283e+00,\n",
      "        -2.0827e+00, -2.1223e+00, -1.4930e+00, -1.9806e+00, -6.8445e-01,\n",
      "         5.1292e-01, -4.6477e+00, -1.0405e+00,  1.7218e-01, -1.1415e-01,\n",
      "         3.7008e-01, -3.1709e+00, -8.0456e-01, -1.4521e+00, -1.8940e+00,\n",
      "        -5.1915e+00, -2.7107e+00, -1.6454e+00, -2.5113e+00, -1.1236e+00,\n",
      "        -1.5960e+00, -1.2333e+00, -1.2239e+00, -2.2913e-01,  1.2461e+00,\n",
      "        -1.2835e+00,  3.4539e-02, -1.2845e+00, -1.7463e+00, -1.2404e+00,\n",
      "        -1.7908e-01, -1.2304e+00, -1.6019e+00, -2.5080e+00, -1.3423e+00,\n",
      "        -2.0085e+00, -1.9978e+00, -1.7003e+00, -5.1329e-01, -1.0838e+00,\n",
      "        -3.3182e-01, -2.1003e+00,  4.4598e-01, -8.8843e-01,  3.4976e-01,\n",
      "         6.5936e-01, -2.9298e+00, -1.6943e+00, -2.2742e+00, -1.3277e+00,\n",
      "        -1.3586e-01, -1.1834e+00,  5.5923e-01, -1.4897e+00, -1.4446e+00,\n",
      "        -8.9652e-01, -1.1716e+00,  6.1787e-02, -7.1429e-01,  2.9431e-01,\n",
      "         5.3330e-01, -2.2662e+00, -1.4608e+00, -1.1665e+00, -4.2297e-02,\n",
      "        -4.1749e-01, -1.1445e+00, -1.5818e+00, -1.3129e+00,  3.2312e-01,\n",
      "        -1.2877e+00, -8.0966e-01, -1.7174e+00, -1.9458e-01, -1.3371e+00,\n",
      "        -1.6992e+00, -1.1512e+00, -2.5262e+00, -1.3982e+00, -1.2492e+00,\n",
      "        -1.4495e+00,  4.6297e-01, -1.2513e+00,  1.9436e-01, -8.5555e-01,\n",
      "        -1.2312e+00, -1.2412e+00, -1.5184e+00, -1.6290e+00, -2.8504e+00,\n",
      "        -2.0078e+00, -1.7194e+00, -2.0578e+00, -8.7064e-01, -2.4229e+00,\n",
      "         3.9062e-01, -2.0571e+00, -2.2492e+00, -1.8771e+00, -1.4682e+00,\n",
      "        -1.5460e+00, -1.0475e+00, -2.2307e-02, -1.2675e+00,  1.3391e-01,\n",
      "        -1.8944e+00, -9.1849e-01, -1.5576e+00, -1.4346e+00,  1.2109e-01,\n",
      "        -1.1716e+00, -2.2413e+00,  2.5428e-01, -8.7385e-01, -1.9839e+00,\n",
      "        -1.5655e+00, -8.6409e-01, -1.1724e+00,  2.3977e-01, -2.4869e+00,\n",
      "        -1.9575e-01, -2.2125e-01, -1.7429e+00, -2.6666e-01, -1.5384e+00,\n",
      "        -6.7451e-01, -9.2857e-01,  1.2392e-01, -7.7483e-01, -9.1488e-01,\n",
      "         1.1977e-01, -1.2517e+00, -1.5412e+00, -1.6001e+00, -1.0778e+00,\n",
      "         5.6688e-01, -5.1503e-03, -8.2661e-01, -9.1723e-01, -1.2869e+00,\n",
      "        -1.1025e+00, -1.3958e+00, -1.1626e+00, -1.2028e+00, -7.3193e-01,\n",
      "         4.1332e-01, -1.3950e+00, -1.4660e+00,  4.8891e-02, -1.3805e+00,\n",
      "        -2.4068e+00, -1.8624e+00, -2.6660e+00, -1.5338e+00, -8.9805e-01,\n",
      "        -4.7010e-01, -1.2659e+00, -2.8130e+00, -1.3731e+00, -1.3807e+00,\n",
      "        -1.1244e+00, -2.6691e-01, -1.2790e+00, -1.2120e+00, -2.5949e+00,\n",
      "        -1.5587e+00, -3.0283e-01, -2.6151e+00, -2.5400e+00, -3.6917e-04,\n",
      "        -4.9780e-01, -1.4670e+00, -3.0198e-01, -2.1170e+00, -1.3727e+00,\n",
      "        -2.0457e+00, -1.3764e+00, -1.9998e-01, -8.9329e-01, -1.3213e+00,\n",
      "        -2.2164e+00,  1.7019e-01, -1.3781e+00, -1.7024e+00, -1.2310e+00,\n",
      "        -2.1530e+00,  9.8087e-01, -7.5908e-01, -4.0338e-02, -1.1849e+00,\n",
      "         7.2865e-01, -1.5115e+00, -9.8044e-01, -3.1344e+00, -1.1639e+00,\n",
      "        -2.2877e+00,  2.0879e-01,  1.9202e-01,  1.9541e-01, -7.4032e-02,\n",
      "        -2.2629e-01,  3.3344e-01, -1.9639e+00,  5.1428e-01, -1.3324e+00,\n",
      "        -6.0978e-01, -4.7995e-01,  3.2605e-01, -1.5790e+00, -1.3513e+00,\n",
      "        -2.0026e+00, -1.4862e+00, -7.4165e-01, -2.1574e+00, -2.3615e+00,\n",
      "        -1.8805e+00, -5.1122e-01, -2.1843e+00, -1.1395e+00, -5.5017e-01,\n",
      "        -5.2649e-01, -1.9866e+00, -1.3450e+00, -1.4994e-01,  8.4510e-01,\n",
      "         7.0236e-01, -1.1631e+00, -1.2975e+00], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.5915]],\n",
      "\n",
      "         [[-0.0303]],\n",
      "\n",
      "         [[-0.0942]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0845]],\n",
      "\n",
      "         [[ 0.0809]],\n",
      "\n",
      "         [[ 0.0057]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2926]],\n",
      "\n",
      "         [[-0.3150]],\n",
      "\n",
      "         [[ 0.0920]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4410]],\n",
      "\n",
      "         [[ 0.2473]],\n",
      "\n",
      "         [[-0.2715]]],\n",
      "\n",
      "\n",
      "        [[[-0.0367]],\n",
      "\n",
      "         [[-0.1163]],\n",
      "\n",
      "         [[-0.4846]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1511]],\n",
      "\n",
      "         [[ 0.0199]],\n",
      "\n",
      "         [[-0.2802]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0036]],\n",
      "\n",
      "         [[-0.1374]],\n",
      "\n",
      "         [[-0.1793]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3265]],\n",
      "\n",
      "         [[ 0.2014]],\n",
      "\n",
      "         [[ 0.1359]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0914]],\n",
      "\n",
      "         [[ 0.1654]],\n",
      "\n",
      "         [[-0.0289]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1527]],\n",
      "\n",
      "         [[ 0.0024]],\n",
      "\n",
      "         [[-0.4975]]],\n",
      "\n",
      "\n",
      "        [[[-0.1169]],\n",
      "\n",
      "         [[-0.2193]],\n",
      "\n",
      "         [[ 0.3108]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1003]],\n",
      "\n",
      "         [[ 0.2912]],\n",
      "\n",
      "         [[ 0.1673]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.0087, -0.4060, -0.0720,  0.0612,  0.2282, -0.0835, -0.0398, -0.4479,\n",
      "         0.1104, -0.1537,  0.0922, -0.0542], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.5699]],\n",
      "\n",
      "         [[-0.1783]],\n",
      "\n",
      "         [[-0.4104]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2141]],\n",
      "\n",
      "         [[-0.0890]],\n",
      "\n",
      "         [[ 0.1231]]],\n",
      "\n",
      "\n",
      "        [[[-0.1528]],\n",
      "\n",
      "         [[ 0.0370]],\n",
      "\n",
      "         [[ 0.2380]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2324]],\n",
      "\n",
      "         [[-0.1045]],\n",
      "\n",
      "         [[ 0.2854]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0482]],\n",
      "\n",
      "         [[ 0.0022]],\n",
      "\n",
      "         [[-0.0272]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0527]],\n",
      "\n",
      "         [[ 0.5942]],\n",
      "\n",
      "         [[-0.0058]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.5487]],\n",
      "\n",
      "         [[-0.1784]],\n",
      "\n",
      "         [[ 0.2284]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4732]],\n",
      "\n",
      "         [[ 0.0740]],\n",
      "\n",
      "         [[-0.1086]]],\n",
      "\n",
      "\n",
      "        [[[-0.0116]],\n",
      "\n",
      "         [[ 0.1152]],\n",
      "\n",
      "         [[ 0.6652]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0799]],\n",
      "\n",
      "         [[ 0.1512]],\n",
      "\n",
      "         [[-0.1130]]],\n",
      "\n",
      "\n",
      "        [[[-0.0317]],\n",
      "\n",
      "         [[ 0.2635]],\n",
      "\n",
      "         [[-0.2600]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2778]],\n",
      "\n",
      "         [[ 0.2444]],\n",
      "\n",
      "         [[ 0.0092]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-6.3734e-01,  6.9712e-02,  4.9022e-01,  5.8434e-01, -2.1345e-01,\n",
      "         1.1334e-02,  1.2318e-01,  1.1998e-01,  1.7943e-01,  1.6731e-01,\n",
      "        -1.6987e-01,  6.8949e-01,  7.0600e-02,  3.2788e-01,  4.5659e-01,\n",
      "        -6.2223e-01, -4.9901e-01,  4.8121e-01,  5.4572e-01,  2.8820e-02,\n",
      "         6.1725e-01, -1.2259e-01, -2.7440e-01, -3.7307e-01, -4.0043e-01,\n",
      "         6.9336e-01,  4.3649e-01,  7.0680e-02,  6.7506e-01, -4.2529e-02,\n",
      "        -2.9783e-01,  2.2275e-01,  1.9948e-01, -5.6338e-01,  9.1919e-02,\n",
      "         4.2831e-01, -1.7339e-01,  3.6203e-01,  7.1347e-02,  3.1752e-01,\n",
      "         7.7462e-02, -7.4008e-01,  3.5352e-01,  1.7229e-01,  6.1350e-01,\n",
      "         2.1118e-01,  1.6148e-01,  2.9811e-01,  9.2276e-01,  9.2832e-02,\n",
      "        -3.4503e-01, -5.6037e-01,  3.5967e-01,  2.8577e-01,  6.4672e-01,\n",
      "         1.0250e+00,  1.6968e-02,  4.6338e-01,  1.8551e-02,  1.8889e-01,\n",
      "         4.5909e-01, -1.4640e-01,  2.6005e-01,  2.3916e-02,  4.6006e-01,\n",
      "         1.5611e-01,  5.1698e-01,  5.8020e-02,  1.3469e-01, -2.2458e-01,\n",
      "         5.5831e-01, -1.2771e-02,  9.0680e-01,  6.7961e-01,  1.7675e-01,\n",
      "        -1.4550e-01, -1.1648e-01,  7.8444e-02, -3.2569e-01, -9.8252e-02,\n",
      "         2.9640e-01, -5.9600e-01, -3.0152e-01, -3.7459e-01,  8.0217e-02,\n",
      "         1.8830e-01,  3.5722e-02, -1.8357e-01,  3.3394e-01,  1.8276e-01,\n",
      "        -1.6508e-01, -1.6174e-01, -1.9941e-01,  5.8724e-01, -1.9181e-01,\n",
      "        -1.3229e-01,  2.2235e-01, -9.6197e-02,  2.5648e-01,  7.7650e-01,\n",
      "         2.8559e-01,  5.2778e-01,  4.2770e-01,  2.6726e-01,  4.1357e-01,\n",
      "         3.9314e-01,  2.4366e-02,  1.4320e-01,  2.3492e-01,  2.9723e-01,\n",
      "         2.5076e-01,  1.0816e+00,  5.9007e-01, -6.7318e-02,  2.0091e-01,\n",
      "         2.4747e-01,  6.3339e-01, -6.3298e-02,  4.1531e-02,  3.0543e-01,\n",
      "         8.5685e-02,  4.7701e-01,  5.4366e-01,  1.3476e-01, -7.2127e-01,\n",
      "         1.9932e-01,  1.8877e-01, -9.8157e-02, -4.6448e-02,  2.6879e-01,\n",
      "        -1.3534e-01,  5.6380e-01,  3.4646e-01, -4.3992e-01,  2.3092e-01,\n",
      "         4.3956e-01,  4.0051e-01, -7.5657e-03, -7.7360e-02,  4.5472e-01,\n",
      "         2.6270e-01, -5.0713e-01, -1.4056e-01,  6.0026e-01, -2.6079e-02,\n",
      "        -1.4174e-01, -2.5073e-01,  1.9340e-01,  4.9611e-02,  4.1759e-01,\n",
      "         2.3141e-01,  1.7240e-01,  2.2980e-02, -3.9390e-01,  2.7516e-01,\n",
      "         2.3874e-01, -4.3791e-02,  4.1625e-02, -3.3186e-01, -1.4573e-01,\n",
      "         1.6705e-01, -5.2749e-01, -4.1473e-01, -5.1659e-01,  1.1695e-01,\n",
      "         3.5080e-01,  4.3480e-02,  8.5581e-01, -5.2247e-01,  1.9422e-02,\n",
      "         2.6346e-01,  1.4746e-01,  7.0084e-01, -6.1489e-02,  1.8572e-01,\n",
      "         5.0892e-03, -5.2820e-02, -2.7926e-02,  5.8494e-01,  1.2433e-01,\n",
      "        -5.5127e-01, -7.7796e-02, -3.0385e-01, -4.9186e-02,  4.2052e-01,\n",
      "         1.0905e-01,  1.7424e-01,  2.7913e-01,  4.9964e-01,  1.1881e-01,\n",
      "         1.7348e-01, -1.8323e-01, -2.2415e-01,  5.8381e-02, -3.7450e-02,\n",
      "         4.5603e-01,  2.0789e-01,  3.9040e-01, -3.4060e-02,  1.0195e-01,\n",
      "        -1.2044e-01,  3.1306e-01,  6.6494e-05,  4.6439e-01,  3.8086e-01,\n",
      "         1.6764e-01, -9.4177e-02,  2.8481e-01,  7.7351e-01,  1.2298e-01,\n",
      "         5.2166e-02, -4.7137e-02,  3.7626e-02,  2.7382e-01,  1.1309e-01,\n",
      "         5.7053e-01, -8.0937e-02,  4.0913e-01,  2.4504e-01,  1.4171e-01,\n",
      "         5.3220e-02,  3.5694e-01,  6.4505e-02,  2.8489e-01,  4.2744e-01,\n",
      "         8.8282e-01,  8.9703e-02,  6.7586e-01, -1.1825e-03,  3.6207e-02,\n",
      "        -4.6036e-01,  6.3561e-01,  1.6874e-01,  1.0402e-01,  5.4396e-01,\n",
      "        -1.6117e-01,  2.5423e-01, -1.2402e-01,  1.9198e-01,  2.3681e-01,\n",
      "         7.9120e-02,  6.6255e-02, -9.2641e-02,  1.8456e-01, -8.2888e-02,\n",
      "         2.8014e-01,  3.1396e-01,  2.9021e-01,  5.0760e-03,  5.8770e-01,\n",
      "         3.1269e-01, -4.7322e-01,  1.0547e-01,  1.6952e-01,  1.6493e-01,\n",
      "         4.2928e-03,  3.5914e-01, -2.4658e-02, -1.1068e-01, -1.1634e-01,\n",
      "        -1.9731e-01,  2.6337e-02,  1.3368e-02,  2.0932e-01,  6.3961e-01,\n",
      "         4.3833e-01,  7.8009e-02,  7.8275e-01,  1.2065e-01,  2.4802e-01,\n",
      "         2.6287e-01, -3.9441e-01,  2.3888e-01,  5.0228e-01,  6.9415e-01,\n",
      "         3.0588e-01,  8.5370e-02,  2.4934e-01,  1.6467e-01,  9.8561e-02,\n",
      "         2.7936e-01,  1.9465e-01,  3.5805e-01, -4.5212e-01, -4.4436e-01,\n",
      "         3.4400e-01, -9.8062e-02, -1.3013e-01], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2428]],\n",
      "\n",
      "         [[-0.2560]],\n",
      "\n",
      "         [[ 0.0043]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1363]],\n",
      "\n",
      "         [[-0.0586]],\n",
      "\n",
      "         [[ 0.1902]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2208]],\n",
      "\n",
      "         [[-0.1629]],\n",
      "\n",
      "         [[-0.1945]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0743]],\n",
      "\n",
      "         [[ 0.3739]],\n",
      "\n",
      "         [[-0.3465]]],\n",
      "\n",
      "\n",
      "        [[[-0.4566]],\n",
      "\n",
      "         [[ 1.0438]],\n",
      "\n",
      "         [[ 0.1532]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3635]],\n",
      "\n",
      "         [[-0.2435]],\n",
      "\n",
      "         [[-0.1070]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2526]],\n",
      "\n",
      "         [[ 0.4871]],\n",
      "\n",
      "         [[ 0.0641]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4037]],\n",
      "\n",
      "         [[ 0.2525]],\n",
      "\n",
      "         [[-0.1035]]],\n",
      "\n",
      "\n",
      "        [[[-0.3397]],\n",
      "\n",
      "         [[ 0.4695]],\n",
      "\n",
      "         [[-0.9974]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1014]],\n",
      "\n",
      "         [[-0.4023]],\n",
      "\n",
      "         [[ 0.1360]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1303]],\n",
      "\n",
      "         [[ 0.2510]],\n",
      "\n",
      "         [[-0.0095]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3589]],\n",
      "\n",
      "         [[-0.1658]],\n",
      "\n",
      "         [[ 0.2662]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.3723, 0.9222, 3.9807, 0.9667, 5.5648, 0.8758, 1.8755, 1.3500, 1.3224,\n",
      "        1.1812, 1.0832, 1.5960, 0.7482, 1.4312, 1.1210, 1.7342, 3.6918, 5.1385,\n",
      "        0.7761, 1.2206, 1.2304, 2.4536, 2.2617, 4.1464, 0.8737, 0.8709, 0.9079,\n",
      "        1.1698, 1.0621, 0.9403, 1.1724, 1.2776, 1.1681, 3.9004, 1.5768, 1.9472,\n",
      "        1.0965, 1.1711, 1.8991, 1.0990, 0.9834, 1.2727, 1.8338, 1.0549, 0.5975,\n",
      "        1.0442, 1.2476, 0.6230], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.0117e+00, -1.1179e+00,  1.2209e+00, -2.0222e+00, -1.9325e+00,\n",
      "         5.9785e-01,  1.0078e+00, -6.2290e-01,  9.4464e-01, -5.6226e-01,\n",
      "         8.7881e-04, -4.1775e-01,  5.2897e-02, -7.0290e-01,  3.2204e-01,\n",
      "         3.7716e+00, -1.4536e+00, -1.7948e+00,  2.4014e-01, -9.2273e-02,\n",
      "         9.9426e-01,  5.8230e-01,  1.4565e+00,  1.8866e-01, -2.2774e+00,\n",
      "        -1.5442e-01,  7.3798e-03, -1.2335e+00,  5.6623e-02, -3.3951e-01,\n",
      "         7.8267e-01, -1.1093e-01,  1.3805e+00,  8.1660e-01, -3.8301e-02,\n",
      "        -9.0056e-01,  4.9122e-01,  2.2293e+00,  1.1295e+00, -2.6732e-01,\n",
      "         1.7999e+00,  1.8934e-01, -1.5709e+00, -2.6114e-01,  3.0774e-01,\n",
      "        -8.3577e-02,  2.7371e-01,  3.7790e-01], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.3177]],\n",
      "\n",
      "         [[ 0.3982]],\n",
      "\n",
      "         [[ 0.0504]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7133]],\n",
      "\n",
      "         [[ 0.0432]],\n",
      "\n",
      "         [[-0.1555]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3174]],\n",
      "\n",
      "         [[ 0.2927]],\n",
      "\n",
      "         [[-0.3658]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9051]],\n",
      "\n",
      "         [[-0.3664]],\n",
      "\n",
      "         [[-0.4413]]],\n",
      "\n",
      "\n",
      "        [[[-0.0727]],\n",
      "\n",
      "         [[ 0.6264]],\n",
      "\n",
      "         [[-0.4119]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6753]],\n",
      "\n",
      "         [[-0.5387]],\n",
      "\n",
      "         [[-0.0133]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0565]],\n",
      "\n",
      "         [[-0.2415]],\n",
      "\n",
      "         [[ 0.5959]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5292]],\n",
      "\n",
      "         [[-0.4337]],\n",
      "\n",
      "         [[-0.2316]]],\n",
      "\n",
      "\n",
      "        [[[-0.1095]],\n",
      "\n",
      "         [[ 0.1237]],\n",
      "\n",
      "         [[ 0.4150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7186]],\n",
      "\n",
      "         [[-0.5022]],\n",
      "\n",
      "         [[-0.3903]]],\n",
      "\n",
      "\n",
      "        [[[-0.6216]],\n",
      "\n",
      "         [[-0.7454]],\n",
      "\n",
      "         [[-0.4525]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3836]],\n",
      "\n",
      "         [[-0.2036]],\n",
      "\n",
      "         [[ 0.2226]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.1968,  1.8626,  1.7915,  0.6956,  1.5771,  1.4722,  1.0849,  0.6158,\n",
      "         0.4676,  1.4700,  0.8411,  1.7420,  0.5737,  1.1584,  1.8658,  0.6087,\n",
      "         1.0075,  0.5685,  1.1139,  1.2822,  2.2015,  1.4082,  1.6535,  1.0562,\n",
      "         0.2730,  0.5820,  0.7781,  1.1505,  0.2600, -0.1702,  0.6441,  1.2034,\n",
      "        -0.2894,  1.6899,  1.6641,  0.9201,  1.2391,  1.2937,  2.3559,  0.9776,\n",
      "         1.5715,  0.1761,  0.7793,  0.3925,  1.0337,  0.2179,  1.2897,  1.6182,\n",
      "         0.3605,  0.8224,  0.5400,  0.3140,  1.1173,  1.3700,  1.2977,  0.2997,\n",
      "         2.5685,  1.4614,  2.1227,  0.2648,  1.0362,  1.1549,  1.4285,  2.0082,\n",
      "         0.9301,  1.2172,  1.2255,  1.1923,  0.3380,  0.9680,  1.7545,  1.4792,\n",
      "        -0.3552,  0.8931,  1.4064,  1.4345,  1.1496,  0.4331,  1.2563,  1.1849,\n",
      "         1.1971,  0.4460,  0.3254,  1.0046,  1.0987,  1.2064,  1.4870,  0.3647,\n",
      "         0.4238,  0.4061,  2.1214,  1.4960,  0.7544,  0.7575,  1.2855,  1.6118,\n",
      "         0.4566,  1.7229,  2.6360,  0.5594,  2.9892,  1.7848,  1.6285,  2.8791,\n",
      "         1.0386,  1.1543,  0.7302,  0.9677, -0.3817,  2.2022,  1.4485,  0.3951,\n",
      "         1.0837,  0.7705,  1.0126,  0.3161,  1.5272,  1.9054,  1.2524,  1.4480,\n",
      "         1.2745,  0.2084,  0.9092,  2.5531,  1.3134,  2.6688,  0.6381,  2.0852,\n",
      "        -0.3030,  0.1798,  1.3688,  1.4293,  1.8333,  0.1705,  1.4797,  1.5578,\n",
      "         1.8741,  0.3411,  0.1092,  0.9212,  0.8571,  0.6374,  1.9520,  0.3053,\n",
      "         0.5537,  2.0195,  0.5712,  0.8495,  0.6532,  1.3424,  1.0884,  0.5978,\n",
      "         2.3979,  1.1905,  0.0381,  1.1198,  2.2122,  0.8113,  2.4681,  0.4262,\n",
      "         1.0653,  1.5108,  0.2151,  1.4560,  0.8953,  0.9529,  0.6756,  0.6200,\n",
      "         0.7599,  0.2646,  0.9295,  1.8362,  2.9424,  0.8033,  1.8648,  1.0608,\n",
      "         1.1613,  1.4535,  1.6716,  1.3622,  1.3542,  0.7133,  0.6154,  0.8927,\n",
      "         1.9466,  0.7817,  1.2415,  1.9220,  1.7930,  1.5377,  0.9426,  0.0845,\n",
      "         1.4675,  0.3620,  1.0304,  0.5256,  1.5498,  0.7294,  0.8064,  0.6760,\n",
      "        -0.1434,  2.2315,  0.5927,  0.4821,  2.0558,  1.5048,  1.3340,  0.9592,\n",
      "         3.0651,  1.5058,  1.4482,  0.3292,  0.2479,  1.1388,  0.6946,  2.1303,\n",
      "         1.1549,  1.5978,  1.8847,  1.7749,  1.2840,  1.1997,  1.2039,  0.9375,\n",
      "         1.8316,  2.0701,  0.0394,  1.5486,  0.5469,  0.9165,  1.5984,  0.2625,\n",
      "         2.7128,  0.9312,  1.6818,  1.1361,  1.1731,  1.7479,  0.6407,  0.3852,\n",
      "         0.6201,  0.6185,  3.4085,  2.5778,  0.8988,  1.8464,  0.2169,  0.7522,\n",
      "         0.8254,  0.5052,  0.4740,  0.5356,  0.3574,  1.9259,  0.7046,  0.5372,\n",
      "         1.2342,  1.1236,  0.5333,  1.2303,  1.7762,  1.2628,  0.6037,  1.1308,\n",
      "         0.3875,  1.4779,  1.2302,  1.7832,  0.9549,  1.4333,  0.6471,  2.2493,\n",
      "         0.1842,  0.5118,  1.7739,  0.9798,  0.7385, -0.0649,  1.9010,  1.3676,\n",
      "         1.7747,  0.6932,  1.5757,  0.8361,  0.6836,  0.9122,  1.4922,  1.4352],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-4.2736,  1.4666, -0.5225,  0.3524,  1.4081,  2.4351,  1.7040, -0.5956,\n",
      "        -0.0994,  0.8739, -0.5023,  1.2232, -0.2482,  0.5660,  0.1080, -0.5074,\n",
      "         0.9805, -0.2894, -1.0195, -0.8858, -0.4134,  1.6422, -0.1748, -0.8507,\n",
      "         0.1051,  1.1520, -1.3104,  0.1376, -0.1997,  0.0723, -0.4702, -0.6733,\n",
      "        -0.0948,  0.1836, -0.2928, -1.4725, -0.9149,  0.9866,  1.2720,  0.7932,\n",
      "         1.6280,  0.1481, -0.7032, -0.6378, -0.1677, -0.3158, -0.9118, -0.4710,\n",
      "         0.7516, -0.4587,  0.0747,  0.0164,  0.7818, -3.6190, -0.9959, -0.2773,\n",
      "         0.7354,  1.1989,  0.1752, -0.2483,  0.3189, -0.9261,  0.5026,  0.3848,\n",
      "        -1.7121,  1.1596, -0.1298, -0.6514, -0.1502, -1.0396,  0.6533, -1.3214,\n",
      "         0.2960,  1.1885, -2.1722, -1.5787,  0.9690,  0.2210, -0.3927, -0.8604,\n",
      "        -0.1498, -0.3017,  0.0598,  0.9806,  0.4443, -0.1640,  1.2865,  1.2295,\n",
      "         0.5837,  0.1705,  0.0398, -0.7505,  0.3816, -0.5840, -0.5797, -1.6396,\n",
      "         0.3306, -4.6784,  0.3767,  0.5547,  0.1045, -1.6857, -0.7839, -2.4850,\n",
      "         0.6878,  0.6609, -1.5016, -0.7917,  0.1210, -1.2047, -0.5176, -0.2348,\n",
      "         1.1209, -1.0374, -0.9753,  0.1241,  1.0359, -1.9080, -0.1255,  1.4278,\n",
      "         0.4800,  0.0490, -1.0899,  0.2504,  0.4909, -2.5567,  1.0544, -0.2713,\n",
      "         0.0933,  0.3988,  0.4589,  0.5157,  0.0311,  0.3609,  0.9332,  1.1555,\n",
      "         0.4716,  0.0709,  2.9086, -1.1134, -0.3540, -0.1059, -1.0709,  0.2574,\n",
      "         0.1849,  0.4076, -0.0187,  0.6059,  0.3536,  1.2350,  0.6441,  0.5460,\n",
      "        -2.5331, -0.3844,  0.6337,  0.7040, -1.0161, -1.3658, -0.0656, -0.4580,\n",
      "         1.0226, -1.3308,  0.2187, -0.0861,  0.8715, -2.1553, -0.3342,  0.0418,\n",
      "        -1.3833,  0.0963, -0.5837,  1.5051, -1.1375,  0.9102,  0.3275, -2.0995,\n",
      "         1.4572,  1.9534, -4.2355, -0.4640,  0.7354, -0.3231, -1.7621,  1.3591,\n",
      "        -0.4879, -1.2340,  2.1445, -0.0697, -2.3413,  0.9379, -1.3331, -0.1707,\n",
      "         0.2006, -0.1500,  0.2930,  0.0836,  0.3512,  1.9172, -1.3202, -0.4889,\n",
      "        -0.2312,  2.4370, -0.2046,  0.2665,  0.9126,  0.9718,  0.4607, -0.1787,\n",
      "        -2.2870,  1.1141, -0.6863, -0.1127, -0.2621,  1.2898,  1.4410,  0.0883,\n",
      "         1.3292, -0.4759,  1.9571,  0.0411, -0.6919, -0.6015, -1.2484, -1.1005,\n",
      "         0.2339, -1.9525, -1.4250,  0.9331, -0.0213,  0.3470,  0.5501, -0.3681,\n",
      "         2.2866,  0.8982,  0.3355,  0.5762, -0.6640, -0.4803, -0.2246, -0.6414,\n",
      "        -0.4174, -1.9367, -3.2292,  0.6242,  0.8657,  0.3914,  0.2727,  0.1272,\n",
      "        -0.5933, -0.2683, -0.3819, -0.5154, -0.2766,  0.3187,  0.6005,  0.0791,\n",
      "        -1.2498,  0.2946,  0.2082, -1.1237, -0.1500, -0.9358,  0.5709,  0.7802,\n",
      "        -0.0426, -5.4531, -0.8538, -1.2486, -0.2414,  0.9168,  1.0766,  0.0644,\n",
      "        -0.0094,  1.4530,  0.5332,  0.3494,  0.9622, -0.1698, -2.2528,  1.8308,\n",
      "        -1.1854,  1.3444,  1.6056, -1.0622, -0.2479, -1.4299, -0.6299, -0.9312],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.5655, -0.5033, -0.5435, -0.2308, -0.2356],\n",
      "          [-0.4035, -0.1855, -0.1199, -0.5681,  0.2011],\n",
      "          [-0.4749, -0.2549,  0.6676, -0.0912,  0.1911],\n",
      "          [-0.3151, -0.4490,  0.2260, -0.0492, -0.1262],\n",
      "          [-0.0683, -0.0517, -0.2790,  0.0476, -0.4715]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4544, -0.0818, -0.0146,  0.4167,  0.2190],\n",
      "          [ 0.1420,  0.5721, -0.4634,  0.3039,  0.0924],\n",
      "          [-0.0188,  0.3730, -0.6717,  0.7811, -0.0423],\n",
      "          [-0.2702,  0.2179, -0.3091,  0.3177, -0.1642],\n",
      "          [-0.3335,  0.2929, -0.4931,  0.2191,  0.0486]]],\n",
      "\n",
      "\n",
      "        [[[-0.3097, -0.5826,  0.1747, -0.0315, -0.0873],\n",
      "          [ 0.4364,  0.0463,  0.2117, -0.3588, -0.6225],\n",
      "          [ 0.6094,  0.3759,  0.2279, -0.7736, -0.1783],\n",
      "          [ 0.3277, -0.4248, -0.1712, -0.3220, -0.3190],\n",
      "          [ 0.4807,  0.0948,  0.0954,  0.1553, -0.0755]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3702,  0.0227, -0.1616,  0.1161, -0.1444],\n",
      "          [ 0.0039,  0.5426,  0.5047,  0.6785,  0.0999],\n",
      "          [-0.1525, -0.2630, -0.2927,  0.5568,  0.0941],\n",
      "          [ 0.2837,  0.2411, -0.4565, -0.1704,  0.0304],\n",
      "          [-0.3984,  0.4346,  0.3974,  0.0809, -0.0482]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0353, -0.2144, -0.1040, -0.2711, -0.5138],\n",
      "          [ 0.4024, -0.2692, -1.2778, -0.2561,  0.3850],\n",
      "          [-0.0483,  0.1268,  0.2908,  0.1042, -0.1655],\n",
      "          [-0.0980,  0.3451, -0.6890, -0.3400, -0.2000],\n",
      "          [ 0.3183,  0.2249, -0.6123, -0.3141,  0.2070]]],\n",
      "\n",
      "\n",
      "        [[[-0.0482, -0.3875, -0.5173, -0.0099, -0.0570],\n",
      "          [-0.4000,  0.1079,  0.5177,  0.3342, -0.7211],\n",
      "          [-0.2899,  0.2390,  0.4713,  0.1794, -0.8100],\n",
      "          [-0.0264,  0.0743, -0.0384,  0.2500, -0.1863],\n",
      "          [ 0.2244, -0.0020, -0.3276, -0.1921, -0.4852]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.5675e+00,  2.2153e+00,  2.0484e+00,  1.2473e+00,  1.8063e+00,\n",
      "         2.0455e+00,  1.6502e+00,  1.4189e+00,  1.7206e+00,  1.9153e+00,\n",
      "         1.1800e+00,  1.5046e+00,  2.5525e+00,  2.1449e+00,  2.3401e+00,\n",
      "         1.3351e+00,  6.2145e-01,  1.5949e+00,  7.8108e-01,  7.9336e-01,\n",
      "         2.0462e+00,  1.9377e+00,  8.1669e-01,  5.7893e-01,  1.4780e+00,\n",
      "         1.1218e+00,  8.1773e-01,  1.3258e+00,  1.7474e+00,  8.9242e-01,\n",
      "         1.1140e+00,  6.7467e-01,  1.6327e+00,  1.9250e+00,  2.7581e+00,\n",
      "         9.6762e-01,  1.4241e+00,  1.7673e+00,  1.3788e+00,  5.5817e-01,\n",
      "         1.9932e+00,  1.4676e+00,  2.0365e+00,  1.4262e+00,  1.8708e+00,\n",
      "         1.4231e+00,  4.5556e-01,  3.3223e-01,  1.1036e+00,  1.3822e+00,\n",
      "         1.2227e+00,  1.6897e+00,  1.6476e+00,  2.6152e+00,  2.1256e+00,\n",
      "         6.1604e-01,  1.6900e+00,  1.4216e+00,  2.0238e+00,  1.5270e+00,\n",
      "         1.1846e+00,  6.9332e-01,  1.5465e+00,  1.3067e+00,  9.0964e-01,\n",
      "         1.8618e+00,  1.7659e+00,  1.2903e+00,  1.0394e+00,  7.7195e-01,\n",
      "         2.0429e+00,  3.2532e+00,  1.8589e+00,  1.6989e+00,  9.2789e-01,\n",
      "         2.6246e+00,  1.6660e+00,  1.6542e+00,  7.7114e-01,  1.2225e+00,\n",
      "         1.4426e+00,  1.6323e+00,  1.4144e+00,  1.8899e+00,  1.7616e+00,\n",
      "         2.6180e+00,  1.9083e+00,  5.7770e-01,  1.8537e+00,  1.4292e+00,\n",
      "         2.0749e+00,  2.2838e+00,  8.6058e-01,  7.7497e-01,  1.7361e+00,\n",
      "         4.1165e-02,  2.0876e+00,  5.4994e+00,  2.3066e+00,  1.5636e+00,\n",
      "         1.7248e+00,  3.9275e+00,  1.0299e+00,  2.1892e+00,  1.8745e+00,\n",
      "         1.2808e+00,  9.0329e-01,  2.1637e+00,  1.9211e+00,  1.5385e+00,\n",
      "         1.6786e+00,  1.7942e+00,  1.9031e+00,  3.3562e+00,  1.1302e+00,\n",
      "         1.7710e+00,  1.4660e+00,  2.2658e+00,  1.2402e+00,  1.2936e+00,\n",
      "         1.9751e+00,  1.9624e+00,  1.2813e+00,  3.0649e+00,  8.9324e-01,\n",
      "         2.3011e+00,  1.4181e+00,  1.7501e+00,  1.7991e+00,  7.0604e-01,\n",
      "         5.8940e-01,  1.4566e+00,  1.0787e-01,  1.8491e+00,  1.6049e+00,\n",
      "         1.6786e+00,  2.2582e+00,  1.8241e+00, -1.5280e-04,  1.5532e+00,\n",
      "         1.7658e+00,  1.8627e+00,  2.6575e+00,  1.8327e+00,  2.3085e+00,\n",
      "         1.1296e+00,  8.7776e-01,  6.9019e-01,  1.1460e+00,  1.9004e+00,\n",
      "         1.4860e+00,  1.6765e+00,  2.0633e+00,  2.3097e+00,  1.6362e+00,\n",
      "         2.5277e+00,  1.7007e+00,  7.7091e-01,  1.8998e+00,  1.6351e+00,\n",
      "         1.5776e+00,  1.4980e+00,  1.5261e+00,  9.3986e-01,  1.4387e+00,\n",
      "         1.4955e+00,  1.3998e+00,  2.0746e+00,  3.3982e-01,  1.5568e+00,\n",
      "         1.2309e+00,  1.0308e+00,  2.4700e+00,  9.8921e-01,  1.6564e+00,\n",
      "         5.6192e-01,  1.6882e+00,  1.8080e+00,  3.1748e+00,  1.5540e+00,\n",
      "         2.2301e+00,  1.7673e+00,  3.6625e-01,  1.4269e+00,  7.0611e-01,\n",
      "         1.5585e+00,  1.7522e+00,  1.8031e+00,  2.2943e+00,  2.4769e+00,\n",
      "         1.0472e+00,  1.5570e+00,  2.0791e+00,  1.6015e+00,  9.9469e-01,\n",
      "         8.9592e-01,  1.8322e+00,  2.1098e+00,  1.5966e+00,  1.8195e+00,\n",
      "         1.7629e+00,  2.5375e+00,  1.3945e+00,  2.3925e+00,  1.9089e+00,\n",
      "         1.8246e+00,  1.4770e+00,  1.6548e+00,  2.8067e+00,  1.8073e+00,\n",
      "         3.0427e-01,  1.5457e+00,  1.2368e+00,  1.5087e+00,  2.1017e+00,\n",
      "         1.7767e+00,  2.3439e+00,  1.6031e+00,  2.3178e+00,  1.4530e+00,\n",
      "         1.1504e+00,  9.1372e-01,  1.4829e+00,  7.9934e-01,  7.6997e-01,\n",
      "         2.1390e+00,  1.7764e+00,  1.2802e+00,  1.9238e+00,  1.5174e+00,\n",
      "         1.9090e+00,  1.9283e+00,  1.9511e+00,  1.9680e+00,  2.1775e+00,\n",
      "         2.6947e-01,  1.4310e+00,  2.9070e+00,  9.7360e-01,  1.6081e+00,\n",
      "         2.1964e+00,  6.6519e-01,  4.9377e+00,  1.8530e+00,  2.1835e+00,\n",
      "         7.4075e-01,  1.4659e+00,  1.3490e+00,  2.3525e+00,  1.5986e+00,\n",
      "         1.0023e+00,  1.6481e+00,  2.6298e+00,  9.8329e-01,  2.1101e+00,\n",
      "         2.3943e+00,  1.4977e+00,  1.5561e+00,  2.2937e+00,  1.0566e+00,\n",
      "         1.0723e+00,  5.2638e-01,  1.4785e+00,  2.3334e+00,  1.8862e+00,\n",
      "         4.5087e+00,  1.5409e+00,  3.0927e+00,  1.6016e+00,  2.1576e+00,\n",
      "         1.6890e+00,  1.1417e+00,  1.6865e+00,  1.7401e+00,  2.4696e+00,\n",
      "         2.0917e+00,  1.7050e+00,  2.0429e+00,  1.7100e+00,  2.0109e+00,\n",
      "         6.4448e-01,  1.3115e+00,  1.6065e+00, -2.9843e-03,  1.9973e+00,\n",
      "         6.2145e-01,  7.1050e-01,  2.2081e+00], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.7199e+00, -1.1473e+00, -1.2511e+00, -2.0916e-02, -1.2616e+00,\n",
      "        -2.4771e+00, -3.4838e-01, -2.0345e+00, -7.5369e-02, -1.3865e+00,\n",
      "        -1.5606e+00, -5.5714e-01, -9.0965e-01, -1.5582e+00, -1.0691e+00,\n",
      "        -2.3334e+00, -1.4474e-01, -2.3926e+00, -3.5206e-01,  1.0050e+00,\n",
      "        -1.3505e+00, -1.4639e+00,  8.6562e-01,  2.7523e-01, -1.4610e+00,\n",
      "         5.6279e-02,  3.8011e-01, -1.0324e+00, -5.4937e-01, -8.6670e-01,\n",
      "        -1.0085e+00, -2.7456e-01, -1.5958e+00, -9.7923e-01, -1.4461e+00,\n",
      "        -1.8003e-01, -6.7467e-01, -1.5573e+00, -5.4893e-01,  1.9480e-02,\n",
      "        -8.1394e-01, -7.6822e-01, -9.3021e-01, -1.7016e+00, -1.2245e+00,\n",
      "        -1.1165e+00,  1.2890e+00,  5.1262e-01, -8.6066e-01, -9.8063e-01,\n",
      "        -2.7008e-01, -1.6350e+00,  4.2692e-01, -2.9734e+00,  4.1589e-02,\n",
      "         8.5124e-01, -1.2606e+00, -8.0332e-01, -1.6827e+00, -1.2270e+00,\n",
      "         6.7077e-01,  4.3771e-01, -1.3989e+00, -1.6953e-01, -4.4936e-02,\n",
      "        -2.7565e+00, -2.9634e+00, -1.6103e+00, -2.3442e-01,  9.1872e-01,\n",
      "        -2.4469e+00,  1.5199e-01, -1.5744e+00, -4.9711e-01,  5.0039e-01,\n",
      "        -1.1371e-01, -1.2102e-01, -1.3178e+00, -4.0962e-01,  6.0741e-01,\n",
      "        -2.2221e+00, -1.3483e+00, -1.1390e+00, -1.5150e+00, -1.5077e+00,\n",
      "        -9.5347e-01, -4.3587e-01,  1.7429e-02, -1.5509e+00,  8.1591e-03,\n",
      "        -1.5809e+00, -1.3923e+00, -4.9848e-02, -1.6105e-01, -1.5345e+00,\n",
      "         1.0258e-02, -9.7712e-01, -3.3151e+00, -2.2007e+00, -9.1369e-01,\n",
      "        -1.0508e+00,  6.4417e-01,  2.0564e-01, -4.0039e+00, -9.8567e-01,\n",
      "        -6.0818e-01, -3.7277e-01, -3.7760e-01, -2.2902e+00, -8.1112e-01,\n",
      "        -2.7131e+00, -1.5421e+00, -1.3819e+00, -6.2336e-01,  4.4873e-01,\n",
      "        -1.5405e+00, -9.2699e-01, -1.0921e+00, -9.5393e-02, -1.4376e+00,\n",
      "        -1.4234e+00, -7.6867e-01, -1.0342e-01, -2.1843e+00, -2.4694e-02,\n",
      "         6.2032e-01, -9.9766e-01, -2.6164e+00, -1.1123e+00, -6.6008e-02,\n",
      "         5.7314e-02,  9.1491e-01, -2.0803e-02, -1.4773e+00, -7.5922e-01,\n",
      "        -1.2676e+00, -6.6928e-01, -1.1544e+00, -8.8572e-03,  9.6861e-02,\n",
      "        -1.2874e+00, -1.1662e+00, -2.1261e-01, -1.2325e+00, -9.2397e-01,\n",
      "         2.4950e-01,  1.6287e-01, -4.2792e-01, -3.1845e-02, -1.1437e+00,\n",
      "        -1.8146e+00, -1.3236e+00, -3.2162e-01, -1.6287e+00, -1.3949e+00,\n",
      "        -1.8298e+00, -6.0038e-01,  1.4928e-01, -1.3254e+00, -7.4523e-01,\n",
      "        -1.6689e+00, -1.1546e+00, -1.3785e+00, -3.6684e-02, -1.8102e+00,\n",
      "        -4.4433e+00, -1.8154e-01, -1.9483e+00, -1.7424e-01, -1.6742e+00,\n",
      "         2.4786e-01, -2.0201e-01, -8.3453e-01, -3.8103e-01, -1.5672e+00,\n",
      "         1.9842e-01, -1.5539e+00, -1.6931e+00, -3.8182e+00, -8.5255e-01,\n",
      "        -1.9672e+00, -1.1704e+00,  7.7122e-01, -9.2892e-01,  2.3655e-01,\n",
      "        -2.3620e+00, -1.5762e-01, -1.2258e+00, -1.4532e+00, -6.5893e-01,\n",
      "        -3.1635e+00, -1.4664e+00, -1.1766e+00, -1.5525e+00,  1.7778e-01,\n",
      "        -1.6322e-01, -1.7360e+00, -1.0940e+00, -1.2646e+00, -1.4791e+00,\n",
      "        -1.5903e+00, -1.3899e+00, -1.2972e+00, -8.8330e-01, -2.2081e+00,\n",
      "        -1.5135e+00, -1.5878e+00, -2.4611e+00, -6.1313e-01, -1.3161e+00,\n",
      "        -9.1836e-02, -1.1721e+00, -1.8926e-01, -1.1080e+00, -1.4567e+00,\n",
      "        -1.3736e+00, -1.2055e+00, -2.1060e+00, -1.3491e+00, -2.1686e+00,\n",
      "         3.5768e-01, -1.2614e+00, -1.0760e+00, -1.4420e-01, -2.7492e-02,\n",
      "        -7.6585e-02, -6.3136e-01, -1.0775e+00, -1.2157e+00, -1.8938e+00,\n",
      "        -3.0177e+00, -1.6151e+00, -9.1431e-01, -1.0109e+00, -1.1484e+00,\n",
      "        -8.8824e-03, -5.5278e-01, -6.4345e-01, -4.4157e-02, -2.0182e+00,\n",
      "        -1.2144e+00, -1.8175e-01, -7.4546e-01, -5.9013e-01, -1.3372e+00,\n",
      "        -1.9529e-01, -1.2456e+00, -9.7530e-01, -8.5072e-01, -2.6176e+00,\n",
      "        -1.3337e-01, -2.4425e+00, -2.5577e+00, -2.1228e-01, -1.4334e+00,\n",
      "        -2.2857e+00, -7.9416e-01, -6.1455e-01, -1.4921e+00,  5.4278e-02,\n",
      "         8.6783e-01,  1.9416e-01, -9.6249e-01, -5.0741e-02, -1.3857e+00,\n",
      "        -4.4743e+00, -1.7739e-01,  4.0854e-01, -2.0125e-01, -1.4812e+00,\n",
      "        -1.7036e+00, -1.4457e-03, -1.5426e+00, -1.5452e+00, -4.8889e-01,\n",
      "        -1.1170e+00, -1.7948e+00, -1.2155e+00, -3.3304e-01, -1.3450e+00,\n",
      "         2.9750e-01, -1.1006e+00, -7.4234e-01, -1.0089e-02, -9.6657e-02,\n",
      "        -3.6198e-02,  6.3930e-01, -1.8820e-01], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.9898]],\n",
      "\n",
      "         [[ 0.2148]],\n",
      "\n",
      "         [[ 0.0141]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0485]],\n",
      "\n",
      "         [[ 0.0588]],\n",
      "\n",
      "         [[ 0.1455]]],\n",
      "\n",
      "\n",
      "        [[[-0.2235]],\n",
      "\n",
      "         [[-0.3596]],\n",
      "\n",
      "         [[-0.3911]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2858]],\n",
      "\n",
      "         [[-0.1625]],\n",
      "\n",
      "         [[-0.1116]]],\n",
      "\n",
      "\n",
      "        [[[-0.1295]],\n",
      "\n",
      "         [[ 0.0495]],\n",
      "\n",
      "         [[ 0.0784]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4499]],\n",
      "\n",
      "         [[ 0.0246]],\n",
      "\n",
      "         [[-0.0314]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6279]],\n",
      "\n",
      "         [[-0.0403]],\n",
      "\n",
      "         [[-0.0301]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0698]],\n",
      "\n",
      "         [[ 0.2050]],\n",
      "\n",
      "         [[ 0.1466]]],\n",
      "\n",
      "\n",
      "        [[[-0.2912]],\n",
      "\n",
      "         [[-0.6485]],\n",
      "\n",
      "         [[ 0.2603]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1003]],\n",
      "\n",
      "         [[ 0.1818]],\n",
      "\n",
      "         [[ 0.0573]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5790]],\n",
      "\n",
      "         [[ 0.1026]],\n",
      "\n",
      "         [[ 0.3499]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0199]],\n",
      "\n",
      "         [[-0.0124]],\n",
      "\n",
      "         [[ 0.0969]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.0707, -0.0934,  0.1064,  0.2507, -0.2017,  0.0124,  0.2679,  0.1676,\n",
      "         0.1846,  0.2355,  0.2480,  0.0426], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1982]],\n",
      "\n",
      "         [[-0.0651]],\n",
      "\n",
      "         [[-0.3015]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2175]],\n",
      "\n",
      "         [[-0.3989]],\n",
      "\n",
      "         [[-0.2350]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3124]],\n",
      "\n",
      "         [[-0.6654]],\n",
      "\n",
      "         [[-0.2345]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3501]],\n",
      "\n",
      "         [[ 0.3204]],\n",
      "\n",
      "         [[-0.1051]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4389]],\n",
      "\n",
      "         [[ 0.2984]],\n",
      "\n",
      "         [[ 0.0557]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0040]],\n",
      "\n",
      "         [[ 0.2546]],\n",
      "\n",
      "         [[-0.2781]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2664]],\n",
      "\n",
      "         [[-0.1403]],\n",
      "\n",
      "         [[ 0.2406]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1936]],\n",
      "\n",
      "         [[ 0.1673]],\n",
      "\n",
      "         [[ 0.0280]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1351]],\n",
      "\n",
      "         [[ 0.1937]],\n",
      "\n",
      "         [[ 0.0864]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0007]],\n",
      "\n",
      "         [[ 0.3502]],\n",
      "\n",
      "         [[-0.1333]]],\n",
      "\n",
      "\n",
      "        [[[-0.2509]],\n",
      "\n",
      "         [[ 0.4176]],\n",
      "\n",
      "         [[ 0.2962]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1510]],\n",
      "\n",
      "         [[-0.1812]],\n",
      "\n",
      "         [[ 0.1522]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.3094,  0.3231, -0.0991, -0.1184,  0.2277,  0.2185,  0.0864,  0.3005,\n",
      "         0.7910,  0.6353, -0.2485,  0.4426,  0.7110,  0.1968,  0.3952,  0.3059,\n",
      "         0.3952,  0.4314, -0.3317, -0.0036, -0.0093,  0.2715, -0.0793,  0.0604,\n",
      "         0.0809,  0.1365,  0.1958,  0.0493, -0.0228, -0.3742,  0.0675, -0.2561,\n",
      "        -0.9572,  0.4359,  0.0641,  0.1297, -0.2259,  0.2876,  0.2809,  0.1527,\n",
      "         0.7793,  0.2376,  0.2874,  0.2450,  0.5281, -0.2757, -0.2416,  0.6489,\n",
      "        -0.3525, -0.3606, -0.1265,  0.2591,  0.6492,  0.4586, -0.6469, -0.1523,\n",
      "         0.0799,  0.1427,  0.2409, -0.0234,  0.1011, -0.2420,  0.0197, -0.1638,\n",
      "         0.2321,  0.1444,  0.3055,  0.3286, -0.4242,  0.1444, -0.1460, -0.4149,\n",
      "         0.9648, -0.1056,  0.1667, -0.7549,  0.1411,  0.0536, -0.2381,  0.0714,\n",
      "         0.2973, -0.2359,  0.0500,  0.4589,  0.4277, -0.4179,  0.4724, -0.3320,\n",
      "         0.6444, -0.0887,  0.3338, -0.0884,  0.0462,  0.0012,  0.1852, -0.2845,\n",
      "         0.4606, -0.3056, -0.2427, -0.2558, -0.1594, -0.3333,  0.2500,  0.4329,\n",
      "         0.3018,  0.4580, -0.1327, -0.3313, -0.0917, -0.4121, -0.1156,  0.3243,\n",
      "         0.1379, -0.3713,  0.3601,  0.0034,  0.0305,  0.6722,  0.4026,  0.0865,\n",
      "         0.1381,  0.6848, -0.0865,  0.6995,  0.0792, -0.1433,  0.0712,  0.2273,\n",
      "        -0.6201, -0.2153,  0.2400,  0.0536, -0.3914, -0.1368,  0.2156,  0.3675,\n",
      "         0.5561,  0.5796, -0.5639,  0.7864,  0.1891,  0.1643, -0.3488,  0.2757,\n",
      "         0.3736, -0.1087,  0.2517, -0.3468,  0.0914,  0.3421,  0.0605,  0.2438,\n",
      "        -0.3470,  0.1603, -0.2760,  0.3643,  0.1516,  0.1556, -0.4956,  0.4557,\n",
      "        -0.1808, -0.2519,  0.2775,  0.3662, -0.0935,  0.2316,  0.2292, -0.7408,\n",
      "         0.7644, -0.0121,  0.0701, -0.3306,  0.1675,  0.0228,  0.2281,  0.2579,\n",
      "         0.0297,  0.1081,  0.0118,  0.2007,  0.3064,  0.0084, -0.1886,  0.5866,\n",
      "         0.0951, -0.0021,  0.3382, -0.2736, -0.5955,  0.3031,  0.4615,  0.1619,\n",
      "         0.4695, -0.1823,  0.0156, -0.1170,  0.5635,  0.4086,  0.1246,  0.5258,\n",
      "        -0.4952,  0.5026,  0.2564,  0.5917, -0.0914,  0.2165,  0.1938, -0.0228,\n",
      "         0.0820,  0.1806, -0.5971, -0.2154, -0.1861, -0.4076,  0.0545,  0.0194,\n",
      "        -0.0409, -0.4938,  0.3281, -0.0402,  0.2103,  0.0775, -0.1084,  0.0754,\n",
      "        -0.3282, -0.2189, -0.2203,  0.0416,  0.1685,  0.2385,  0.3990,  0.2883,\n",
      "         0.4539,  0.3590,  0.0787, -0.2947,  0.0665, -0.4713, -0.1880, -0.0448,\n",
      "         0.2424, -0.2687, -0.0064,  0.1378,  0.4866, -0.2235, -0.5086, -0.3920,\n",
      "        -0.2581,  0.5069, -0.0904,  0.1903, -0.0343, -0.4439,  0.2767, -0.0773,\n",
      "        -0.0187,  0.2843,  0.5681,  0.1183, -0.1125,  0.1220,  0.1939,  0.1069,\n",
      "        -0.0564, -0.0029, -0.2995, -0.4627,  0.0395,  0.2579,  0.0486, -0.2273,\n",
      "         0.7656, -0.1823, -0.1514,  0.1064, -0.0012,  0.0904,  0.4004,  0.1707,\n",
      "         0.6459,  0.0964,  0.0388, -0.4212,  0.1030,  0.1782,  0.1907,  0.1913],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1254]],\n",
      "\n",
      "         [[-0.4088]],\n",
      "\n",
      "         [[-0.4810]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.8004]],\n",
      "\n",
      "         [[-0.0513]],\n",
      "\n",
      "         [[-0.5036]]],\n",
      "\n",
      "\n",
      "        [[[-0.3553]],\n",
      "\n",
      "         [[-0.2466]],\n",
      "\n",
      "         [[ 0.4002]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6007]],\n",
      "\n",
      "         [[ 0.2272]],\n",
      "\n",
      "         [[-0.8747]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0749]],\n",
      "\n",
      "         [[-0.0773]],\n",
      "\n",
      "         [[ 0.5292]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3269]],\n",
      "\n",
      "         [[ 0.4343]],\n",
      "\n",
      "         [[ 0.0796]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1441]],\n",
      "\n",
      "         [[-0.1275]],\n",
      "\n",
      "         [[-0.3080]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1696]],\n",
      "\n",
      "         [[ 0.1196]],\n",
      "\n",
      "         [[-0.2921]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0794]],\n",
      "\n",
      "         [[-0.5800]],\n",
      "\n",
      "         [[-0.9284]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1402]],\n",
      "\n",
      "         [[-0.3124]],\n",
      "\n",
      "         [[-0.0586]]],\n",
      "\n",
      "\n",
      "        [[[-0.4072]],\n",
      "\n",
      "         [[ 1.3424]],\n",
      "\n",
      "         [[-0.0046]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4361]],\n",
      "\n",
      "         [[-0.3344]],\n",
      "\n",
      "         [[ 0.4647]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.3316, 0.9545, 2.7200, 0.5771, 3.3459, 0.6952, 1.2491, 1.4105, 0.5190,\n",
      "        0.7325, 0.9924, 1.4484, 0.3248, 1.4668, 0.8286, 1.3419, 2.2023, 3.4093,\n",
      "        0.5253, 0.6573, 0.8584, 2.0266, 2.4940, 3.4170, 0.9170, 0.5367, 0.8207,\n",
      "        1.1096, 0.6818, 0.6888, 1.0970, 1.1212, 1.1956, 2.8560, 1.6404, 1.5320,\n",
      "        0.2998, 0.8096, 2.0542, 0.8074, 0.5045, 0.7384, 1.5599, 0.7270, 0.3974,\n",
      "        0.8789, 1.2426, 0.3297], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.9545, -1.2089, -0.0044, -1.4154, -1.5585,  0.3953, -0.0719, -0.2799,\n",
      "         0.8638, -0.1705,  0.1623,  0.1950,  0.0192, -0.3264,  0.0939,  2.5199,\n",
      "        -1.1718, -0.6582,  0.4633,  0.0319,  0.9837,  0.2382,  0.9949,  0.7758,\n",
      "        -1.4851, -0.1955, -0.4200, -0.7675,  0.0613, -0.1055,  0.0602, -0.3875,\n",
      "         0.6823,  0.1338,  0.0799, -1.2566,  0.8175,  2.0090,  0.3845, -0.2059,\n",
      "         0.8676, -0.1580, -0.3735,  0.3248, -0.0238, -0.0680,  0.3761,  0.2067],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.5028]],\n",
      "\n",
      "         [[-0.3533]],\n",
      "\n",
      "         [[-0.0963]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0520]],\n",
      "\n",
      "         [[-0.2056]],\n",
      "\n",
      "         [[-0.3505]]],\n",
      "\n",
      "\n",
      "        [[[-0.0126]],\n",
      "\n",
      "         [[ 0.4740]],\n",
      "\n",
      "         [[ 0.1259]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3681]],\n",
      "\n",
      "         [[ 0.0837]],\n",
      "\n",
      "         [[-0.4933]]],\n",
      "\n",
      "\n",
      "        [[[-0.1546]],\n",
      "\n",
      "         [[ 0.2888]],\n",
      "\n",
      "         [[ 0.5198]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.8032]],\n",
      "\n",
      "         [[ 0.3934]],\n",
      "\n",
      "         [[-0.0904]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2532]],\n",
      "\n",
      "         [[ 0.4518]],\n",
      "\n",
      "         [[ 0.3622]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5281]],\n",
      "\n",
      "         [[-0.7880]],\n",
      "\n",
      "         [[ 0.0156]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1522]],\n",
      "\n",
      "         [[-0.1448]],\n",
      "\n",
      "         [[ 0.2092]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3463]],\n",
      "\n",
      "         [[-0.3969]],\n",
      "\n",
      "         [[-0.0482]]],\n",
      "\n",
      "\n",
      "        [[[-0.3734]],\n",
      "\n",
      "         [[ 0.5890]],\n",
      "\n",
      "         [[-0.0673]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0287]],\n",
      "\n",
      "         [[ 0.4903]],\n",
      "\n",
      "         [[-0.1477]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.0578, 1.0498, 0.7058, 1.2846, 1.0119, 1.4444, 1.8608, 0.8792, 2.0645,\n",
      "        1.0819, 1.3733, 0.5027, 1.1202, 1.0116, 1.2808, 2.3569, 1.2366, 1.2374,\n",
      "        1.2516, 1.2286, 0.9153, 2.5416, 1.1644, 0.7725, 1.1071, 0.9625, 1.1518,\n",
      "        1.0581, 0.8579, 1.2099, 1.0301, 0.6544, 1.2973, 0.9877, 0.6497, 0.8267,\n",
      "        0.8310, 0.6715, 1.4718, 0.5766, 1.6778, 1.4422, 1.6823, 3.3319, 0.2540,\n",
      "        1.2779, 0.5600, 0.8490, 1.3490, 0.9638, 2.0095, 1.2965, 0.8779, 1.5318,\n",
      "        1.9914, 1.5448, 0.9629, 2.0187, 0.2663, 1.3254, 2.0927, 0.6629, 0.8680,\n",
      "        0.9910, 0.9166, 1.0713, 1.0952, 0.9192, 1.7226, 2.2378, 1.3895, 1.8308,\n",
      "        0.8336, 2.2003, 0.7999, 1.5034, 1.3583, 1.4401, 0.7243, 2.4791, 0.9682,\n",
      "        0.8926, 0.9049, 0.9610, 1.7400, 0.8276, 0.9120, 1.0102, 0.9433, 0.9094,\n",
      "        0.6169, 0.8036, 0.5199, 0.8447, 1.1595, 1.5345, 1.3552, 1.0938, 1.0584,\n",
      "        1.6205, 0.7966, 1.8859, 1.0394, 1.3311, 1.3832, 0.9363, 0.7610, 2.9105,\n",
      "        0.8211, 1.3250, 1.3028, 2.1453, 1.3857, 1.2228, 2.0079, 1.0293, 1.4096,\n",
      "        0.4805, 1.4615, 1.3023, 1.0426, 1.3939, 0.4657, 1.2672, 0.9519, 0.7598,\n",
      "        2.1048, 0.9556, 2.4550, 0.7750, 0.8389, 0.6797, 0.1972, 1.2018, 0.8744,\n",
      "        0.9410, 0.2090, 1.1179, 0.7161, 0.1098, 1.0191, 1.3896, 3.7809, 1.0683,\n",
      "        0.3894, 1.2159, 2.3194, 0.8602, 1.2154, 0.9914, 0.6088, 1.3148, 1.2703,\n",
      "        0.8240, 1.1919, 0.9519, 1.2755, 0.9857, 1.1438, 1.1480, 2.3073, 1.0731,\n",
      "        0.9545, 1.0235, 1.1811, 0.3557, 1.5450, 0.8587, 1.7363, 1.0040, 2.5017,\n",
      "        1.2137, 0.8570, 0.9549, 0.9271, 0.4461, 0.8399, 0.6749, 1.1007, 2.9701,\n",
      "        1.4621, 0.8271, 0.9159, 2.2312, 0.4131, 0.8688, 0.7132, 1.3351, 1.2479,\n",
      "        1.3090, 1.4368, 1.8148, 1.0583, 1.2311, 2.4856, 0.4094, 1.1412, 1.0374,\n",
      "        1.9132, 0.9256, 3.1005, 1.2772, 0.9149, 0.9809, 1.0640, 0.5314, 0.4880,\n",
      "        1.2810, 0.9648, 1.3864, 1.3169, 2.1455, 0.7477, 0.9545, 0.3010, 1.0995,\n",
      "        0.9695, 2.1823, 1.3199, 0.7441, 1.8755, 1.7581, 0.2183, 1.0198, 0.9110,\n",
      "        0.6003, 1.2921, 0.6262, 2.1403, 1.8224, 0.7938, 1.1402, 0.4225, 0.9009,\n",
      "        1.3894, 1.0535, 1.0335, 1.8486, 1.2263, 1.1703, 0.8160, 2.1387, 1.1276,\n",
      "        1.1125, 1.9098, 1.0296, 1.4955, 1.3888, 0.2641, 1.1536, 1.5673, 1.3871,\n",
      "        0.7678, 1.4235, 0.9804, 1.4601, 1.0809, 1.3760, 0.7304, 1.7798, 2.3912,\n",
      "        0.8235, 1.7760, 1.4647, 0.8851, 1.8396, 1.9604, 1.3936, 0.6884, 1.6729,\n",
      "        1.0491, 0.7132, 1.1422, 2.4132, 1.0285, 0.6700, 1.5136, 1.9590, 2.8838,\n",
      "        1.3138, 1.7083, 0.8002, 0.5711, 1.2481, 0.4992, 0.9987, 1.5281, 0.7404],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.1067e+00, -3.3729e-01, -1.1383e+00, -1.4967e+00, -1.4766e+00,\n",
      "        -7.5155e-01, -9.8820e-01, -1.8117e+00, -6.1344e-01, -1.5819e+00,\n",
      "        -1.6322e+00, -6.9627e-01, -1.3587e+00, -1.5317e+00, -9.9162e-01,\n",
      "        -4.5135e-01, -6.0226e-01, -1.4245e+00,  1.5100e+00, -8.6184e-01,\n",
      "        -6.1925e-01,  1.4611e-01, -1.5549e+00, -1.0312e+00, -3.1854e-01,\n",
      "        -1.7873e+00,  7.6268e-01, -1.4703e+00, -1.5806e+00,  1.0203e+00,\n",
      "        -1.2042e+00, -3.7234e-01, -8.1864e-01, -3.0197e-01,  3.2888e+00,\n",
      "        -3.3546e-01, -1.5827e+00, -5.7084e-01, -1.6959e+00,  1.1691e-01,\n",
      "         2.1437e+00, -5.8854e-01,  8.7424e-01, -3.7872e+00,  3.6716e-01,\n",
      "        -1.5796e+00,  5.5382e-02, -9.8965e-01, -1.3601e+00, -1.6951e+00,\n",
      "        -5.2513e-01,  1.6357e+00, -1.4787e+00, -6.8151e-01, -9.1495e-01,\n",
      "        -5.3559e-01,  8.9108e-02, -6.6658e-01, -5.0589e-02,  1.9267e+00,\n",
      "        -3.5458e-01, -5.2626e-01, -3.1098e-01, -1.4690e+00, -1.0136e+00,\n",
      "         2.0360e+00, -1.6969e+00, -1.7819e+00, -1.1190e-01, -4.6928e-01,\n",
      "        -8.6638e-01, -8.4468e-01, -1.6570e+00, -7.1952e-01, -8.7881e-01,\n",
      "        -9.6407e-01, -1.0960e+00, -1.5666e+00, -1.4027e+00, -8.7571e-03,\n",
      "        -1.0789e+00,  1.1288e+00, -4.1857e-01,  1.5155e+00, -1.0020e+00,\n",
      "        -4.1348e-01, -1.3706e+00, -2.5779e+00, -1.7816e+00, -1.6168e+00,\n",
      "        -1.4109e+00, -3.6258e-01, -6.8665e-01,  1.8844e-01,  2.0591e+00,\n",
      "        -6.0962e-01, -2.0651e+00, -1.8094e+00, -1.4125e+00, -6.5937e-01,\n",
      "        -1.6483e+00, -9.5763e-01, -1.2655e+00, -1.0910e+00, -1.1789e+00,\n",
      "        -1.1989e+00, -1.6726e+00, -2.1210e-01, -1.1940e+00, -8.1404e-01,\n",
      "        -6.7652e-01,  1.1519e+00,  9.6276e-01, -5.2456e-01,  3.2620e-01,\n",
      "        -1.7425e+00, -4.4044e-01, -4.6152e-01, -1.0202e+00, -1.0312e+00,\n",
      "        -1.0652e+00, -3.0641e-01,  5.3498e-01, -1.6351e+00, -1.7264e+00,\n",
      "        -1.5970e+00, -2.3143e-01, -2.6455e-01,  6.1163e-01,  1.8232e+00,\n",
      "        -1.1203e+00, -1.4714e-01,  3.9795e-01, -2.3661e+00,  2.0276e+00,\n",
      "        -1.6374e+00,  2.2108e-01,  2.4988e-03, -1.9109e+00, -1.5067e-01,\n",
      "        -1.8839e+00, -1.4473e+00, -4.2515e+00, -5.8822e-01, -3.0689e-01,\n",
      "        -2.6325e-01,  7.0565e-01, -1.6806e+00, -1.5236e+00, -1.5759e+00,\n",
      "         4.1419e-01,  5.3335e-01, -2.1333e+00, -1.5444e+00, -9.2180e-01,\n",
      "        -1.6458e+00, -7.1199e-01, -1.5035e+00, -1.4505e-01, -1.4277e-02,\n",
      "        -6.1881e-01,  1.9146e+00, -1.3377e+00, -4.9782e-02,  1.8422e-01,\n",
      "         1.8797e-02, -1.2366e+00, -1.8020e+00, -9.2013e-01,  1.4492e+00,\n",
      "        -7.8411e-01, -8.0163e-01, -1.8378e+00, -1.7588e+00, -1.3095e+00,\n",
      "        -3.6493e-01,  1.1358e-01, -3.5536e-01, -1.5383e+00,  1.2018e-01,\n",
      "        -4.8020e-01, -1.2009e+00, -7.4013e-01, -1.0601e+00,  5.2482e-01,\n",
      "        -1.8659e+00, -5.1465e-01, -5.7890e-01, -1.1955e+00, -1.8448e+00,\n",
      "        -8.3323e-01, -5.7535e-01, -8.2972e-01, -9.2054e-01,  1.3029e+00,\n",
      "         6.1565e-01, -1.5058e+00, -1.1070e+00, -1.1596e+00, -1.1645e+00,\n",
      "         1.1194e+00, -7.8184e-01, -9.3583e-01, -1.2995e+00, -5.9859e-01,\n",
      "         1.0163e+00,  1.1421e-01, -1.0924e+00, -1.6345e+00, -1.6587e+00,\n",
      "        -1.3337e+00, -5.2002e-01, -9.2634e-01, -1.5619e+00,  1.3455e-02,\n",
      "        -1.6102e+00, -8.1268e-01, -2.7823e-01, -7.6010e-01,  6.3449e-01,\n",
      "        -6.9546e-01,  2.7923e-01,  7.8843e-01,  5.8529e-01, -4.0596e-01,\n",
      "        -1.1936e+00, -1.6781e+00, -1.6560e+00,  9.9513e-01, -8.7547e-01,\n",
      "        -8.6073e-01, -1.6095e+00, -1.8760e-01, -1.4193e+00, -1.1767e+00,\n",
      "        -1.6168e+00, -1.5650e+00, -2.1288e+00, -1.3074e-01, -1.6215e+00,\n",
      "        -1.0226e+00, -2.1049e+00, -1.7071e+00, -1.6735e+00, -1.0742e+00,\n",
      "        -1.0819e+00, -7.1291e-01, -2.7572e-01,  5.8228e-02, -1.3004e+00,\n",
      "         1.8201e+00, -1.0414e+00, -1.4084e+00, -1.0352e+00, -1.4266e+00,\n",
      "        -8.6831e-01, -1.8149e+00, -1.0752e+00,  4.3172e-01,  1.0758e+00,\n",
      "         6.7582e-01, -1.8615e+00, -2.5489e-01, -8.0074e-01, -1.8269e+00,\n",
      "        -2.7982e+00,  1.4826e+00,  2.1305e+00, -1.5958e+00, -6.5792e-01,\n",
      "        -1.7059e+00,  8.1698e-01, -1.3105e+00, -1.0835e-01, -1.6604e+00,\n",
      "         7.9061e-01,  1.2003e-01, -7.2388e-01,  2.3059e-01, -5.4382e-01,\n",
      "        -9.0755e-01, -6.8153e-01, -7.5468e-01, -1.1890e+00, -3.0086e-01,\n",
      "        -1.5501e+00, -1.1052e+00, -3.0762e-01], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2649,  0.2769,  0.1771],\n",
      "          [ 0.4408,  0.9114,  0.3409],\n",
      "          [ 0.0735,  0.4389,  0.4288]]],\n",
      "\n",
      "\n",
      "        [[[-0.0046, -0.5074, -0.3096],\n",
      "          [-0.2704,  0.2941,  0.6095],\n",
      "          [ 0.1708,  0.4771, -0.1710]]],\n",
      "\n",
      "\n",
      "        [[[-0.2032, -0.1740, -0.4980],\n",
      "          [-0.1844,  0.3996,  0.5713],\n",
      "          [-0.1058,  0.1265,  0.4656]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.8400,  0.2847,  0.2398],\n",
      "          [ 0.5530,  0.3570, -0.0038],\n",
      "          [ 0.2735,  0.3082,  0.0742]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0399, -0.4642, -0.1425],\n",
      "          [ 0.0669, -0.5670, -0.1970],\n",
      "          [-0.6995, -0.4832, -0.1558]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1731,  0.5274,  0.0253],\n",
      "          [ 0.2466,  1.0470, -0.1379],\n",
      "          [ 0.1373,  0.3798, -0.1386]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.1309,  1.4802,  1.3068,  1.4337,  1.4133,  1.6710,  1.8291,  1.0828,\n",
      "         2.0999,  1.0223,  0.9169,  1.7476,  1.2088,  1.2881,  1.0715,  2.1407,\n",
      "         1.7362,  1.4402,  2.7518,  1.3816,  1.7584,  2.0603,  0.8699,  2.0115,\n",
      "         1.0002,  1.3854,  1.6104,  1.2143,  1.5303,  2.1384,  1.0820,  1.6034,\n",
      "         0.9710,  1.8814,  1.8258,  1.6316,  1.6205,  1.3427,  0.7245,  1.5275,\n",
      "         1.8534,  1.3405,  1.5038,  1.0188,  1.9517,  1.4401,  2.1449,  1.0692,\n",
      "         1.7159,  1.1185,  1.8845,  1.9038,  0.8635,  1.3535,  2.1760,  1.6551,\n",
      "         1.2534,  2.4749,  2.1250,  1.5996,  2.1097,  1.3447,  1.7094,  1.3218,\n",
      "         1.8182,  1.9999,  0.9166,  1.1439,  2.4114,  4.0250,  1.4920,  2.4038,\n",
      "         1.6205,  0.9221,  0.8972,  2.3571,  1.7790,  1.9275,  1.7212,  2.2969,\n",
      "         1.5284,  2.4868,  1.7935,  2.3938,  3.3057,  1.5311,  1.2669,  0.9790,\n",
      "         1.1356,  0.8259,  1.0893,  1.6509,  1.7774,  1.8446,  1.9418,  1.7551,\n",
      "         1.5751,  1.3285,  1.0639,  1.2628,  1.1854,  0.8891,  1.0650,  0.8550,\n",
      "         1.8054,  1.2759,  1.2873,  1.9294,  1.4050,  0.9412,  1.4856,  0.5432,\n",
      "         0.6960,  1.9467,  2.0817,  1.0728,  1.6047,  1.6478,  1.8450,  1.1307,\n",
      "         0.9650,  1.4879,  2.2944,  0.6833,  1.4308,  0.8433,  1.5226,  1.1994,\n",
      "         3.4050,  2.4875,  1.7996,  1.9224,  2.1177,  1.1613,  2.1363,  0.8169,\n",
      "         2.1476,  1.6773,  1.1265,  1.5302,  1.3820,  1.1373,  3.1362,  0.6803,\n",
      "         1.1952,  1.4771,  1.1301,  1.2097,  1.7094,  1.1561,  1.9343,  1.7840,\n",
      "         0.9614,  1.0702,  0.9041,  1.4357,  1.2360,  1.2333,  1.1918,  1.4386,\n",
      "         1.9207,  2.1639,  1.3687,  1.6823,  0.9260,  1.1296,  1.5992,  1.8417,\n",
      "         1.9787,  1.4993,  0.7869,  1.4024,  1.0884,  1.0507,  1.1923,  1.7871,\n",
      "         2.2505,  1.9121,  0.9514,  2.5056,  0.8453,  0.8883,  1.0129,  2.0400,\n",
      "         2.0448,  0.7871,  1.8034,  1.1840,  1.0651,  1.5817,  1.7206,  2.3552,\n",
      "         1.8468,  1.0744,  1.8629,  2.4437,  1.0686,  1.4097,  1.6706,  1.2649,\n",
      "         2.9891,  1.3529,  1.6750,  1.1119,  1.5232,  2.4112,  1.5666,  0.9822,\n",
      "         0.9603,  2.1611,  1.0438,  1.8618,  1.5839,  1.0382,  1.9896,  1.5173,\n",
      "         1.1867,  1.7723,  0.9617,  1.2800,  2.0995,  1.9133,  1.8912,  1.8989,\n",
      "         1.5780,  1.1620,  1.2030,  1.4202,  1.6916,  2.7774,  1.5000,  1.0081,\n",
      "         2.0179,  1.7558,  2.3345,  0.9995,  1.3634,  1.1621,  1.6766,  1.6131,\n",
      "         1.6690,  0.5928,  1.2878,  1.1049,  2.2902,  1.3602,  1.8020,  1.4098,\n",
      "         0.7162,  0.9729,  2.3140,  1.5753,  0.9406,  1.1378,  1.3191,  1.7479,\n",
      "         1.1297,  1.0774,  1.9400,  1.5405,  2.1494,  1.4116,  1.5891,  0.7884,\n",
      "         1.5925, -1.6768,  1.0270,  1.0245,  1.2319,  1.8853,  0.8625,  1.5153,\n",
      "         1.1740,  1.4042,  1.2154,  1.5492,  2.8333,  2.0373,  2.0353,  1.2106,\n",
      "         1.7575,  1.3041,  0.9883,  1.9114,  1.7153,  1.5139,  1.8098,  0.9631],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.4768e+00,  4.5305e-01,  6.2547e-01,  1.8573e+00,  1.7699e+00,\n",
      "         3.0675e+00,  1.6247e+00,  2.1429e+00,  4.6318e-01,  2.4532e-01,\n",
      "         1.5682e+00, -8.6565e-01,  2.6734e+00,  1.8787e+00,  3.1701e+00,\n",
      "        -3.6865e-01,  9.4087e-01,  1.9350e+00, -7.1347e-01,  3.4568e+00,\n",
      "         3.3363e+00,  2.2356e-01,  1.9389e+00,  2.5382e+00,  3.1118e+00,\n",
      "         1.7855e+00, -1.4245e+00,  2.0970e+00,  2.5393e+00, -1.0497e+00,\n",
      "         1.9915e+00, -1.9395e-01,  2.8240e+00, -4.6092e-01,  7.9917e-02,\n",
      "        -9.2159e-01,  2.4151e+00,  3.8625e+00,  1.1089e+00, -8.8043e-01,\n",
      "        -1.0074e+00,  3.1358e+00,  2.8132e-01, -1.7872e+00, -1.5592e+00,\n",
      "         1.9498e+00, -9.3164e-01,  2.0478e+00,  2.2890e+00,  2.6158e+00,\n",
      "         2.4463e+00, -1.1914e+00,  2.0359e+00, -6.7354e-02,  2.6123e+00,\n",
      "        -1.0519e-01,  9.8545e-01,  1.7896e+00, -1.1403e+00,  3.3942e+00,\n",
      "         3.8660e-02, -1.1027e+00, -4.9128e-01,  2.1321e+00,  2.7383e+00,\n",
      "        -4.1084e-01,  2.8570e+00,  2.1034e+00,  3.0308e-01, -1.5861e+00,\n",
      "         1.8482e+00,  4.8195e-01,  2.6294e+00,  1.3233e+00,  3.2318e+00,\n",
      "         1.5423e+00,  2.7590e+00,  2.4876e+00,  2.6794e+00,  3.2750e-01,\n",
      "        -1.1743e+00, -7.8967e-01, -9.5810e-01, -1.9467e+00, -1.3190e+00,\n",
      "         3.3063e+00,  2.8685e+00,  1.5395e+00,  1.1460e+00,  1.3921e+00,\n",
      "         5.3821e-01,  2.5216e+00, -5.6133e-01,  5.3809e-03, -8.4358e-01,\n",
      "         2.7457e+00,  2.6452e+00,  1.8776e+00,  1.8102e+00,  2.2749e+00,\n",
      "         2.9321e+00,  2.0719e+00,  2.0271e+00,  3.2169e+00,  1.6449e+00,\n",
      "         3.0626e+00,  3.5556e-01, -1.7083e-01,  2.9569e+00,  3.0080e+00,\n",
      "        -1.2146e-01,  3.8448e-01,  2.7455e+00, -8.7199e-01,  3.2802e-01,\n",
      "         1.4509e-01, -1.9172e+00, -1.9114e+00,  1.3263e+00,  1.2932e+00,\n",
      "        -2.9758e-03,  3.6999e+00, -6.9904e-01,  1.6587e+00,  2.1201e+00,\n",
      "         9.0400e-01,  2.1704e+00,  2.5412e+00, -1.3108e+00, -2.1767e+00,\n",
      "         2.5954e+00, -4.0369e-01, -1.0288e+00,  1.1036e+00, -6.4113e-01,\n",
      "         2.9631e+00, -1.1795e+00, -2.3973e+00,  1.9079e+00, -1.2613e+00,\n",
      "         1.9524e+00,  1.4348e+00, -3.7187e+00,  2.0794e+00, -1.4099e+00,\n",
      "         9.5655e-01,  1.8061e+00,  1.4594e+00,  1.9356e+00,  2.8032e+00,\n",
      "        -8.0965e-01, -1.0159e+00,  1.7618e+00,  2.1555e+00,  2.9625e+00,\n",
      "         2.9151e+00,  3.2848e+00,  2.7629e+00,  1.8337e+00,  2.8518e+00,\n",
      "         1.9065e+00, -5.7026e-01,  2.2313e+00, -8.3555e-01,  2.9808e+00,\n",
      "         2.9978e+00,  9.1128e-01,  2.3818e+00,  1.1778e+00,  9.0309e-02,\n",
      "         3.8135e-01, -5.5193e-01,  1.6767e+00,  1.5471e+00,  1.9729e+00,\n",
      "        -1.3353e+00, -8.7554e-01, -1.6445e+00,  1.7897e+00,  1.2022e+00,\n",
      "         3.7439e+00,  2.9934e+00,  2.0404e+00,  1.8697e+00, -8.1403e-01,\n",
      "         2.5236e+00, -8.1923e-01,  4.1418e+00,  2.1455e+00,  2.3497e+00,\n",
      "         3.0388e+00,  5.2607e-01,  3.4778e-01,  3.0891e+00,  2.3072e-01,\n",
      "        -2.0454e+00,  2.3080e+00,  2.0287e+00,  1.0287e+00,  2.6202e+00,\n",
      "        -1.3832e+00,  4.0014e-01,  3.1215e+00,  2.2200e+00,  3.9868e+00,\n",
      "        -3.0088e-01, -8.4935e-01,  2.8778e+00,  2.0701e+00,  2.8937e+00,\n",
      "         2.4405e+00,  7.0995e-01,  4.3753e+00,  1.9747e+00, -9.8324e-01,\n",
      "         1.0201e+00,  2.7510e+00,  9.9564e-01,  3.7030e+00, -1.3784e+00,\n",
      "         9.6018e-01, -4.5269e-01, -2.2264e+00, -5.7065e-01, -8.0026e-01,\n",
      "        -2.9399e-01,  1.7569e+00,  2.8419e+00, -8.6968e-01,  2.3185e-01,\n",
      "         3.8068e+00,  2.3110e+00, -4.0309e-01,  2.5839e+00,  9.6586e-01,\n",
      "         2.0798e+00,  2.0008e+00,  2.2002e+00, -7.2165e-01,  1.7601e+00,\n",
      "        -3.7765e-01, -1.4089e+00,  2.0882e+00,  2.2533e+00,  4.8646e-01,\n",
      "         2.8001e+00,  2.5219e+00,  2.8345e+00,  5.5804e-01,  3.2048e+00,\n",
      "        -7.4374e-01,  1.7553e+00,  1.1069e-01,  6.2193e-01,  2.1625e+00,\n",
      "         2.9525e+00,  2.0352e+00,  3.2983e+00, -2.3272e-01,  1.5117e+00,\n",
      "         1.1572e+00,  3.0182e+00,  2.3898e+00,  4.1681e+00,  1.9427e+00,\n",
      "        -2.1300e+00,  3.1581e+00,  2.4717e+00,  2.2373e+00,  2.6030e+00,\n",
      "         1.6651e+00, -3.3002e-01,  6.0402e-01,  2.7240e-01,  2.8031e+00,\n",
      "        -7.6535e-01, -5.8549e-01,  8.0158e-01,  3.1284e+00,  2.1364e-01,\n",
      "         1.3510e+00, -6.1124e-01, -7.4678e-01,  3.1402e+00, -5.2507e-01,\n",
      "         2.6082e+00,  2.3007e+00,  4.1935e+00], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2337]],\n",
      "\n",
      "         [[-0.0744]],\n",
      "\n",
      "         [[-0.0417]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0047]],\n",
      "\n",
      "         [[-0.0499]],\n",
      "\n",
      "         [[-0.0099]]],\n",
      "\n",
      "\n",
      "        [[[-0.0038]],\n",
      "\n",
      "         [[-0.1040]],\n",
      "\n",
      "         [[-0.0210]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0778]],\n",
      "\n",
      "         [[-0.0008]],\n",
      "\n",
      "         [[-0.0660]]],\n",
      "\n",
      "\n",
      "        [[[-0.1424]],\n",
      "\n",
      "         [[-0.0964]],\n",
      "\n",
      "         [[-0.0741]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0293]],\n",
      "\n",
      "         [[-0.0158]],\n",
      "\n",
      "         [[-0.0962]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1020]],\n",
      "\n",
      "         [[-0.0157]],\n",
      "\n",
      "         [[-0.0265]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1103]],\n",
      "\n",
      "         [[-0.0802]],\n",
      "\n",
      "         [[-0.0976]]],\n",
      "\n",
      "\n",
      "        [[[-0.0559]],\n",
      "\n",
      "         [[-0.0176]],\n",
      "\n",
      "         [[-0.0583]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0847]],\n",
      "\n",
      "         [[-0.0553]],\n",
      "\n",
      "         [[-0.0182]]],\n",
      "\n",
      "\n",
      "        [[[-0.0783]],\n",
      "\n",
      "         [[ 0.0383]],\n",
      "\n",
      "         [[-0.0577]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0436]],\n",
      "\n",
      "         [[-0.0461]],\n",
      "\n",
      "         [[-0.1817]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0370, -0.0478, -0.0449, -0.0469, -0.0669, -0.0582, -0.0523, -0.0489,\n",
      "        -0.0702, -0.0556, -0.0522, -0.0562], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1621]],\n",
      "\n",
      "         [[-0.1677]],\n",
      "\n",
      "         [[-0.1147]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1438]],\n",
      "\n",
      "         [[-0.0859]],\n",
      "\n",
      "         [[-0.1537]]],\n",
      "\n",
      "\n",
      "        [[[-0.0230]],\n",
      "\n",
      "         [[-0.0193]],\n",
      "\n",
      "         [[-0.1582]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0039]],\n",
      "\n",
      "         [[-0.0224]],\n",
      "\n",
      "         [[-0.0594]]],\n",
      "\n",
      "\n",
      "        [[[-0.0101]],\n",
      "\n",
      "         [[ 0.0124]],\n",
      "\n",
      "         [[-0.1579]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0856]],\n",
      "\n",
      "         [[-0.0711]],\n",
      "\n",
      "         [[-0.0237]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0077]],\n",
      "\n",
      "         [[-0.0327]],\n",
      "\n",
      "         [[ 0.0251]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0310]],\n",
      "\n",
      "         [[ 0.0385]],\n",
      "\n",
      "         [[ 0.0152]]],\n",
      "\n",
      "\n",
      "        [[[-0.0752]],\n",
      "\n",
      "         [[-0.0402]],\n",
      "\n",
      "         [[-0.0766]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0241]],\n",
      "\n",
      "         [[ 0.0556]],\n",
      "\n",
      "         [[-0.0023]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0310]],\n",
      "\n",
      "         [[-0.1779]],\n",
      "\n",
      "         [[-0.1274]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1050]],\n",
      "\n",
      "         [[-0.1639]],\n",
      "\n",
      "         [[-0.2557]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.6161,  0.0160,  0.1002,  0.1310,  0.0952,  0.2520,  0.4027,  0.0654,\n",
      "         0.1637, -0.0874, -0.1375,  0.1706, -0.0871,  0.1357, -0.2780, -0.2677,\n",
      "         0.3805,  0.2747,  0.2090, -0.1574, -0.1348, -0.0858, -0.1620,  0.3684,\n",
      "         0.0583,  0.1361, -0.0047,  0.0326, -0.1241,  0.2648, -0.2800,  0.0805,\n",
      "        -0.3842,  0.1315, -0.5000,  0.1029,  0.3608,  0.1565, -0.3128, -0.2879,\n",
      "        -0.0297, -0.1050, -0.4660, -0.7890,  0.2446, -0.0486,  0.3226, -0.1506,\n",
      "         0.6248, -0.1226,  0.8133, -0.0912, -0.5366, -0.4922,  0.9259, -0.0697,\n",
      "        -0.0058,  0.8632,  0.1432,  0.3390,  0.1208, -0.1648, -0.0150,  0.0688,\n",
      "         0.2079,  0.0052, -0.1367,  0.0083,  0.1377, -0.1042, -0.0297,  0.7029,\n",
      "         0.0905, -0.2161,  0.2315,  0.2274,  0.1210,  0.3426,  0.4879,  0.3132,\n",
      "        -0.1893,  0.2290, -0.1787, -0.2678, -0.4971, -0.1299, -0.0164,  0.0185,\n",
      "        -0.0346, -0.3449, -0.2043,  0.3318,  0.2097,  0.0039,  0.2652,  0.0217,\n",
      "         0.1001,  0.0804, -0.0027,  0.3021, -0.1435, -0.3907, -0.0834, -0.5234,\n",
      "         0.3310, -0.0167,  0.0034, -0.1005,  0.1094, -0.6027,  0.0174, -0.8006,\n",
      "        -0.3600,  0.2815,  0.3709, -0.0189, -0.0140, -0.1496,  0.7556,  0.0287,\n",
      "        -0.1808, -0.2653,  0.2558, -0.4392,  0.0928, -0.1763,  0.5423,  0.1053,\n",
      "         0.0403,  0.1774,  0.3567, -0.0574, -0.0083,  0.0928,  0.0223, -0.4003,\n",
      "         0.1419,  0.0236, -0.1008, -0.5668,  0.0913,  0.0745, -0.4896, -0.4509,\n",
      "        -0.2583,  0.1287, -0.0496,  0.1060,  0.2974, -0.1086, -0.1181,  0.1496,\n",
      "        -0.0926, -0.1223, -0.4689, -0.0935, -0.1585,  0.0869,  0.0081, -0.0885,\n",
      "         0.5724, -0.0548, -0.0916, -0.2693, -0.2310,  0.0614,  0.1682,  0.2502,\n",
      "         0.7491, -0.2783, -0.7307, -0.3799, -0.1280, -0.1721, -0.1798, -0.1571,\n",
      "         0.2359,  0.0669, -0.1010,  0.5610, -0.6570, -0.3518, -0.1852,  0.4561,\n",
      "        -0.0754, -0.3229,  0.2416, -0.6496, -0.3617,  0.1460,  0.2601,  0.6762,\n",
      "         0.1238, -0.2944,  0.3354,  0.4086, -0.0786,  0.0755, -0.0285, -0.0836,\n",
      "        -0.0929,  0.2541,  0.0170, -0.3284,  0.3030,  0.1548, -0.2573, -0.2594,\n",
      "        -0.1982,  0.6714, -0.0932,  0.1085,  0.4862, -0.1936, -0.1512,  0.1277,\n",
      "        -0.1498,  0.2562,  0.0244, -0.0636,  0.5226,  0.2486, -0.2511,  0.1932,\n",
      "        -0.1968, -0.1973, -0.1093, -0.0984, -0.1813,  0.2023, -0.1798, -0.1165,\n",
      "         0.1414,  0.2551,  0.6885, -0.2260,  0.1063, -0.6111,  0.0656,  0.2005,\n",
      "        -0.0932, -0.2657,  0.1215, -0.2666,  0.1786,  0.1925,  0.2267, -0.0910,\n",
      "        -0.4725, -0.2484,  0.2468,  0.8382, -0.1611,  0.0017, -0.0731,  0.8055,\n",
      "         0.0298, -0.3179,  0.0024,  0.2511,  0.8101,  0.0705,  0.6033,  0.1873,\n",
      "         0.0971,  0.0878,  0.0167,  0.1335, -0.0863,  0.3316, -0.3588, -0.0844,\n",
      "        -0.0282, -0.2092, -0.1144, -0.1609, -0.1474,  0.1055,  0.3753, -0.1164,\n",
      "         0.3872, -0.0378, -0.3580, -0.5116, -0.1558,  0.1499,  0.7344, -0.6276],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 1.3764]],\n",
      "\n",
      "         [[ 0.0572]],\n",
      "\n",
      "         [[ 0.1092]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4064]],\n",
      "\n",
      "         [[-0.4632]],\n",
      "\n",
      "         [[ 0.2025]]],\n",
      "\n",
      "\n",
      "        [[[-0.3698]],\n",
      "\n",
      "         [[ 0.2249]],\n",
      "\n",
      "         [[-0.0484]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3103]],\n",
      "\n",
      "         [[ 0.1216]],\n",
      "\n",
      "         [[ 0.0897]]],\n",
      "\n",
      "\n",
      "        [[[-0.7428]],\n",
      "\n",
      "         [[ 0.1605]],\n",
      "\n",
      "         [[-0.2294]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3836]],\n",
      "\n",
      "         [[-0.5784]],\n",
      "\n",
      "         [[ 0.4234]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.5988]],\n",
      "\n",
      "         [[-0.0014]],\n",
      "\n",
      "         [[-0.1323]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0843]],\n",
      "\n",
      "         [[ 0.1957]],\n",
      "\n",
      "         [[ 0.4982]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1055]],\n",
      "\n",
      "         [[ 0.4265]],\n",
      "\n",
      "         [[ 0.6562]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2416]],\n",
      "\n",
      "         [[-0.0253]],\n",
      "\n",
      "         [[ 0.0918]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1138]],\n",
      "\n",
      "         [[-0.9449]],\n",
      "\n",
      "         [[-0.1050]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1052]],\n",
      "\n",
      "         [[ 0.0437]],\n",
      "\n",
      "         [[ 0.8110]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 8.1417,  5.2376,  6.4042,  5.1890,  5.4133,  5.4965,  5.0384,  5.6792,\n",
      "         2.9310,  7.1159,  3.3638,  6.1703,  7.5488,  2.8413,  4.3723,  4.6488,\n",
      "         3.8747,  7.5562,  3.8423,  2.2011,  4.7762,  2.9900,  4.7857,  4.8587,\n",
      "         4.4371,  4.0109,  3.9668,  5.0546,  8.8995,  3.5946,  5.4479,  4.1739,\n",
      "         4.0648,  6.8841,  5.6122,  4.6122,  2.5399,  5.9189,  3.6425,  3.3548,\n",
      "         4.0843,  4.5999,  6.8486,  4.1631,  8.6365,  5.3323,  4.1668, 10.5113,\n",
      "         9.0559,  4.5977,  6.1938,  6.4206,  4.9392,  3.4693,  9.0117,  9.1644,\n",
      "         4.5511,  9.8179,  5.1650,  3.5473,  6.0705,  3.9780,  3.3168,  7.4963,\n",
      "         4.1138,  5.3591,  4.7790,  4.7905,  2.9003,  6.1510,  9.1835,  6.4506,\n",
      "         5.1220,  5.9443,  5.1670,  4.5376,  4.2166,  5.2136,  4.7625,  4.3706,\n",
      "         5.4590,  3.3886,  2.9316,  4.4138,  3.0378,  3.2069,  8.2304,  7.2859,\n",
      "         4.9646,  4.9375,  5.5377,  6.3198,  8.3827,  8.5186,  3.5372,  8.0751],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0300,  0.0068,  0.0112,  0.0186,  0.0030,  0.0159, -0.0099, -0.0041,\n",
      "         0.0077,  0.0116,  0.0037,  0.0221,  0.0217,  0.0088,  0.0188, -0.0076,\n",
      "        -0.0046,  0.0245,  0.0210, -0.0160, -0.0036, -0.0067, -0.0029, -0.0224,\n",
      "         0.0064, -0.0044,  0.0022, -0.0201,  0.0293, -0.0003,  0.0135, -0.0185,\n",
      "        -0.0339,  0.0021,  0.0094,  0.0009,  0.0026,  0.0032,  0.0038, -0.0036,\n",
      "         0.0138, -0.0030,  0.0154,  0.0038, -0.0095, -0.0005,  0.0008, -0.0067,\n",
      "        -0.0098, -0.0072, -0.0068,  0.0082,  0.0053, -0.0154,  0.0061,  0.0056,\n",
      "         0.0151,  0.0317,  0.0028,  0.0068, -0.0042, -0.0054, -0.0007, -0.0137,\n",
      "         0.0025, -0.0130,  0.0035, -0.0125, -0.0098, -0.0079, -0.0012, -0.0269,\n",
      "         0.0030, -0.0100,  0.0074,  0.0032,  0.0026,  0.0081,  0.0045,  0.0047,\n",
      "         0.0118, -0.0071, -0.0029, -0.0043,  0.0010,  0.0045, -0.0027, -0.0225,\n",
      "         0.0096, -0.0243, -0.0185,  0.0046, -0.0009, -0.0069, -0.0116,  0.0165],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0159]],\n",
      "\n",
      "         [[ 0.2601]],\n",
      "\n",
      "         [[ 0.6016]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2354]],\n",
      "\n",
      "         [[ 0.0140]],\n",
      "\n",
      "         [[-0.1810]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1317]],\n",
      "\n",
      "         [[-0.4937]],\n",
      "\n",
      "         [[ 0.1690]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1957]],\n",
      "\n",
      "         [[-0.0132]],\n",
      "\n",
      "         [[ 0.0223]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4866]],\n",
      "\n",
      "         [[ 0.0857]],\n",
      "\n",
      "         [[-0.1843]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6777]],\n",
      "\n",
      "         [[ 0.2309]],\n",
      "\n",
      "         [[-0.2077]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3823]],\n",
      "\n",
      "         [[ 0.1437]],\n",
      "\n",
      "         [[-0.9700]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2324]],\n",
      "\n",
      "         [[ 0.2054]],\n",
      "\n",
      "         [[ 0.5987]]],\n",
      "\n",
      "\n",
      "        [[[-0.1472]],\n",
      "\n",
      "         [[-0.3404]],\n",
      "\n",
      "         [[-0.0272]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3352]],\n",
      "\n",
      "         [[-0.2341]],\n",
      "\n",
      "         [[ 0.4669]]],\n",
      "\n",
      "\n",
      "        [[[-0.2113]],\n",
      "\n",
      "         [[-0.0813]],\n",
      "\n",
      "         [[-0.2581]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5582]],\n",
      "\n",
      "         [[ 0.0667]],\n",
      "\n",
      "         [[ 0.4085]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.5606,  0.4519,  0.2344,  0.7280,  1.0269,  1.2328,  0.9855,  1.5291,\n",
      "         0.3252,  0.5670,  0.3208,  1.3745,  1.0051,  1.1874,  1.7463,  2.3928,\n",
      "         1.5684,  0.4721,  1.0869,  1.3309,  0.3471,  1.6980,  1.2423,  0.9445,\n",
      "         0.5057,  0.8296, -0.0243,  1.2719,  0.4993,  0.7455,  1.4196,  0.0289,\n",
      "         1.7112,  1.4586,  0.4737,  0.3888,  0.2439,  0.8680,  1.3010,  0.6179,\n",
      "         0.0203,  1.1790,  0.9951,  0.2830,  0.9973,  1.4923,  0.2128,  1.1836,\n",
      "         0.4160,  0.4405,  0.8428,  2.3206,  2.0450,  0.6672,  1.0610,  0.6547,\n",
      "         1.9864,  1.1194,  1.0353,  2.4286,  0.3979,  0.8623,  2.2932,  0.8527,\n",
      "         0.2026,  1.2166,  1.1303,  0.3305,  1.8014,  0.7222,  0.4580,  1.8846,\n",
      "         0.3717,  1.4883,  0.3847,  0.2908,  0.7243,  1.3014,  1.8276,  0.1657,\n",
      "         1.0748,  0.4883,  1.1411,  0.8415,  0.9531,  0.4931,  0.9784,  1.7420,\n",
      "         0.2885,  0.3882,  1.3401,  1.4254,  0.6205,  0.7417,  0.2737,  1.1602,\n",
      "         0.9439, -0.3925,  2.2172,  0.6567,  0.3922,  0.8163,  0.7739,  0.5860,\n",
      "         1.0032,  1.0467,  1.3444,  1.1400,  0.5817,  0.7095,  1.0417,  1.9920,\n",
      "         0.8982,  1.0299,  0.8768,  0.8929,  0.4707,  0.7236,  0.7340,  0.2300,\n",
      "         0.8480,  0.9485,  0.8219,  1.0682,  0.9482,  1.2329,  1.8711,  1.6413,\n",
      "         1.9133,  0.7577,  1.0967,  1.9228,  2.0932,  0.7820,  1.8180,  1.8381,\n",
      "         1.7163,  0.8639,  1.3500,  1.4747,  1.5417,  0.4138,  0.7320,  0.7561,\n",
      "         0.5258,  0.5585,  1.5107,  1.4478,  1.2553,  1.3397,  0.3266,  1.7308,\n",
      "         0.5580,  1.5273,  1.1651,  1.2968,  1.4051,  0.6405,  1.3938,  1.9189,\n",
      "         2.5881,  2.3484,  1.0754,  1.4488,  0.9333,  0.5727,  1.3923,  1.0769,\n",
      "         0.6271,  2.1738,  0.4389,  1.0204,  1.2220,  0.7324,  1.0870,  0.7991,\n",
      "         0.8772,  1.0610,  0.6899,  1.5693,  0.5040,  1.5371,  0.2183,  1.3143,\n",
      "         1.8184,  0.7823,  1.7005,  0.6756,  0.8547,  1.1290,  1.4465,  1.1576,\n",
      "         1.5684,  1.7294,  0.2166,  0.9512,  1.1787,  1.4268,  1.1172,  0.4000,\n",
      "         0.9485,  2.5482,  0.9896,  0.8108,  1.6174,  0.2386,  0.9089,  0.9792,\n",
      "         0.9437,  0.4790,  1.2155,  0.0531,  1.5343,  0.9960,  0.8064,  1.1975,\n",
      "         0.5847,  1.1817,  0.9790,  1.4511,  1.2634,  1.6422,  2.0786,  0.6660,\n",
      "         0.7124,  1.6122,  0.7889,  0.4207,  0.4910,  0.7881,  0.7422,  1.2157,\n",
      "         1.6265,  1.2073,  1.1852,  1.4418,  0.5974,  0.7004,  0.4826,  1.7441,\n",
      "         1.0783,  0.6957,  2.1093,  0.9585,  1.1939,  0.3572,  1.4580,  1.2858,\n",
      "         0.4716,  1.2974,  1.1722,  0.5751,  0.3628,  0.4865,  0.6332,  1.5035,\n",
      "         0.2753,  1.6200,  0.7606,  0.3874,  0.9708,  0.9636,  0.9895,  1.3520,\n",
      "         0.3391,  1.1451,  1.0397,  1.0116,  1.0070,  0.4895,  0.7494,  1.2896,\n",
      "         1.0326,  1.5452,  1.7195,  1.8385,  0.4302,  0.5836,  0.5019,  1.5635,\n",
      "         1.8262,  1.0971,  1.2164,  0.7033,  0.5916,  0.6156,  0.3217,  0.0036,\n",
      "         0.3422,  1.3385,  1.4966,  0.7883,  0.9470,  0.7405,  2.0625,  1.0405,\n",
      "         1.3416,  1.3820,  1.4172,  1.2479,  1.5446,  1.2329,  0.8371,  1.2526,\n",
      "         1.2114,  0.5251,  1.5568,  1.1120,  1.3993, -0.1978,  0.8993,  0.3776,\n",
      "         1.5725,  0.7384,  0.5955,  0.6079,  1.0981,  1.7300,  0.9942,  1.7613,\n",
      "         0.3192,  0.3088,  1.0278,  1.6795,  1.2962,  1.4469,  2.1734,  0.9426,\n",
      "         2.0725,  1.2498,  0.3579,  1.2352,  1.1938,  0.3355,  0.7213,  1.9789,\n",
      "         0.6698,  0.7513,  1.4133,  0.8168,  1.4344,  0.9913,  0.8246,  0.5573,\n",
      "         0.1397,  0.8078,  0.6550,  1.6076,  1.4117,  1.3093,  1.6429,  0.6327,\n",
      "         1.1101,  0.9429,  1.5351,  0.5795,  1.3531,  0.8394,  1.0758,  0.5619,\n",
      "         2.3943,  0.8039,  0.7060,  1.3025,  0.5751,  0.4326,  1.8212,  0.4414,\n",
      "         1.6131,  0.3351,  0.3087,  0.6709,  0.9035,  2.0865,  1.1873,  0.7840,\n",
      "         0.0631,  1.0819,  0.9713,  0.6255,  1.8986,  1.4483,  0.4302,  1.2769,\n",
      "         1.4860,  0.7314,  1.7594,  0.4316,  0.6960,  0.7715,  0.5615,  1.4561,\n",
      "         0.4141,  0.7645,  0.7122,  1.1664,  0.0983,  1.4705,  1.1783,  1.1229,\n",
      "         1.8318,  1.2342,  1.1525,  2.8099,  0.1841,  1.3983,  2.2272,  0.8715,\n",
      "         0.1899,  1.7225,  1.5883,  0.1378,  1.0969,  1.1055,  2.6860,  1.4725,\n",
      "         0.9956,  1.1725,  0.3525,  1.3387,  0.8682,  0.3093,  0.8753,  0.7906,\n",
      "         1.3386,  0.2240,  1.1818,  1.1266,  1.1522,  0.4623,  2.3066,  0.8575,\n",
      "         1.5725,  1.8447,  1.1812,  1.1764,  1.5108,  0.7214,  0.9875,  1.0036,\n",
      "         1.0042,  0.9319,  0.9450,  1.4577,  0.7314,  1.5409,  1.2430,  0.7924,\n",
      "         2.2563,  0.8946,  1.1745,  0.6437,  0.5462,  0.5870,  0.3529,  0.9775,\n",
      "         0.8517, -0.0114,  1.6698,  1.3041,  1.0494,  0.4312,  0.5617,  1.6068,\n",
      "         1.1713,  1.0381,  0.8595,  1.2522,  1.1549,  1.4263, -0.0782,  1.1720,\n",
      "         0.5347,  1.0964,  1.3605,  0.7381,  1.3706,  1.0271,  1.0279,  2.0826,\n",
      "         0.8317,  0.6251,  0.6945,  0.7888,  1.9674,  0.5607,  0.4340,  1.1109,\n",
      "         1.0986,  0.7043,  0.4394,  0.9013,  1.2405,  0.5153,  1.1719,  1.1627,\n",
      "         0.4198,  0.1528,  0.5040,  1.6839,  0.6134,  0.7287,  1.6197,  1.5105,\n",
      "         1.0315,  0.4805,  1.3172,  1.2861,  1.0969,  0.8139,  2.1912,  1.7688,\n",
      "         1.1358,  0.9391,  0.8680,  2.2879,  1.7286,  1.1908,  0.4005,  0.6763,\n",
      "         1.2509,  2.0082,  1.3404,  0.1923,  1.5762,  0.5611,  1.1176,  1.2444,\n",
      "         1.4999,  1.1612,  2.5589,  0.3734,  0.6200,  1.0078,  2.1086,  1.4286,\n",
      "         1.5069,  0.0361,  1.8190,  1.5427,  0.4827,  1.4146,  0.6213,  1.7503,\n",
      "         1.0912,  1.6995,  1.0453,  0.6100,  0.9162,  0.0959,  0.5780,  1.3348,\n",
      "         1.0719,  1.0384,  0.8294,  1.8836,  0.9876,  1.9103,  1.5220,  0.3964,\n",
      "         0.8690,  1.1288,  0.7652, -0.0138,  0.7135,  2.0042,  0.3707,  1.5529,\n",
      "         1.4085,  0.8648,  1.1512,  0.9070,  0.3383,  0.5491,  1.7841,  0.4481],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.8385e+00,  1.6153e-01,  3.3576e-01,  1.4511e+00, -6.4505e-01,\n",
      "         1.0401e-01,  3.4211e-01, -1.6797e-01,  3.4122e-02,  8.3572e-01,\n",
      "        -5.8800e-01, -4.0878e-01, -1.2490e-01,  1.2135e+00,  2.9597e-01,\n",
      "         9.1540e-02,  7.6586e-01,  4.7650e-01,  4.5688e-01, -9.1036e-01,\n",
      "         6.0169e-01, -1.6721e+00,  6.1671e-03,  9.0998e-02, -1.6879e-01,\n",
      "        -1.3317e+00,  1.1710e+00,  1.2228e+00,  1.2741e+00,  1.6106e+00,\n",
      "         3.2880e-01, -5.2200e-01, -2.0731e-01, -8.9685e-01,  1.1936e+00,\n",
      "         4.2595e-01,  1.2511e+00,  8.2202e-01, -2.2412e-02,  1.1636e+00,\n",
      "         1.0552e+00, -2.2485e-01,  5.8873e-01,  2.9523e-01,  5.7425e-01,\n",
      "        -6.1877e-01,  1.3741e+00, -1.2974e+00,  4.1289e-01,  5.8504e-03,\n",
      "        -1.2851e+00, -3.9087e+00, -5.9213e-01, -2.1470e-01,  2.0347e+00,\n",
      "        -4.1523e-01, -9.2784e-01,  2.5650e+00, -1.1022e+00, -1.3089e-01,\n",
      "         9.4842e-01,  1.1496e+00, -2.2289e+00,  4.3677e-01,  1.5083e-01,\n",
      "         1.0896e+00, -7.0075e-01,  1.9450e-01,  3.4305e-01,  4.0447e-01,\n",
      "         9.7596e-02,  5.4773e-01,  1.3519e-01,  1.2771e+00, -7.6150e-01,\n",
      "         6.0875e-01,  2.4965e-01,  4.8783e-01,  2.4280e-01, -4.4732e-02,\n",
      "         8.1422e-01, -1.4349e+00,  1.1035e+00, -8.4664e-01,  9.0348e-02,\n",
      "        -9.9408e-01,  5.6567e-01,  4.4700e-01,  5.5759e-01,  1.2363e+00,\n",
      "         4.3123e-01, -5.9063e-01,  7.1690e-01, -3.8839e-01,  1.8919e-01,\n",
      "         9.9762e-01, -1.0813e+00,  4.5747e-01,  4.0615e-02,  1.4645e+00,\n",
      "        -4.2506e-01,  1.4054e+00,  4.0483e-01,  2.1101e-01, -8.3025e-01,\n",
      "         7.3007e-02, -7.8553e-01, -9.5587e-01,  1.6390e+00, -1.3757e+00,\n",
      "         1.1447e-01, -6.9554e-01,  2.9162e-02, -1.0603e+00, -2.1452e+00,\n",
      "        -1.1276e+00, -2.4578e-01,  1.6206e+00,  1.2553e-01,  3.1297e-01,\n",
      "        -8.3094e-01,  8.4076e-01, -1.9478e+00, -1.4579e+00, -1.1293e+00,\n",
      "        -1.7694e+00, -2.8752e+00, -3.5734e-01, -2.0714e-01,  4.6325e-01,\n",
      "         2.0247e-01,  8.9162e-01, -3.7213e-01,  7.6617e-01, -1.8531e-01,\n",
      "        -4.6502e-01,  4.0724e-01,  7.2539e-01, -2.9596e+00, -2.3310e+00,\n",
      "         1.7851e-03, -5.2525e-02,  7.5812e-01,  1.4239e+00,  5.8720e-01,\n",
      "         3.5905e-01, -2.6917e-01,  1.1967e+00, -3.1552e-01, -2.1521e+00,\n",
      "         7.3230e-01, -1.4250e-01,  3.8834e-01, -2.2422e+00,  1.2389e+00,\n",
      "         3.5005e-01, -3.0926e-01,  1.8564e+00,  6.2316e-01, -4.1155e-01,\n",
      "         7.2388e-01, -3.8353e+00, -2.1430e-01,  9.9284e-01, -9.4259e-01,\n",
      "         1.5971e-01, -6.7366e-01, -1.7484e-01, -1.2128e-01,  1.9410e-01,\n",
      "         6.0799e-01, -5.2983e-01, -1.5025e+00, -7.3065e-01, -1.0414e+00,\n",
      "         3.6558e-01,  2.2417e-01,  1.1495e+00,  1.0925e-01, -3.1193e-01,\n",
      "         1.1454e+00, -1.6052e+00,  9.2592e-01, -8.2080e-01,  2.2082e-01,\n",
      "        -1.3017e+00,  5.0119e-01,  1.6037e+00, -1.3863e+00, -1.3389e-01,\n",
      "        -5.5866e-05,  9.8991e-03,  4.6286e-01,  8.2152e-01, -3.5852e-01,\n",
      "         1.1884e+00,  1.1012e+00,  1.4136e+00, -9.3776e-01, -2.5783e-01,\n",
      "         9.0939e-01, -3.3602e-01,  1.3824e+00,  1.5325e+00, -7.7351e-01,\n",
      "         1.2241e-01, -1.5460e+00, -1.2342e+00,  5.6847e-01, -1.4211e-01,\n",
      "         1.4297e+00,  5.4023e-01, -1.6482e-01,  1.0778e+00, -7.7424e-02,\n",
      "        -1.3149e+00,  1.0544e+00, -1.0475e+00, -1.2026e+00, -9.3356e-01,\n",
      "        -5.5789e-01, -1.9297e+00,  1.3469e+00, -3.7319e-02,  3.3729e-01,\n",
      "         1.2316e+00, -5.1909e-01,  7.3875e-01,  6.6293e-01,  5.6567e-01,\n",
      "         9.8871e-01,  1.1998e-01,  9.8463e-01, -1.8103e+00,  1.5996e+00,\n",
      "         5.0714e-01,  1.1808e+00, -5.4573e-01,  4.6403e-01,  5.5156e-02,\n",
      "         8.8702e-01,  6.8346e-01,  2.8043e-02,  2.2978e-01,  2.4163e-01,\n",
      "         1.8993e-01, -1.2410e+00, -9.7949e-01,  3.8394e-01, -3.5446e-01,\n",
      "        -7.8154e-01,  4.2525e-01, -2.6501e-01, -7.8552e-03, -1.2105e-03,\n",
      "         6.6083e-01,  1.8994e-01, -1.9724e+00, -8.2512e-01,  7.9950e-01,\n",
      "        -1.3076e+00,  2.6625e-01, -1.1041e+00,  2.1725e-01,  2.1461e+00,\n",
      "         4.8131e-01,  8.4794e-01,  1.0573e+00,  1.1417e+00,  5.1039e-01,\n",
      "         3.1748e-02, -6.3517e-01, -7.1951e-01, -4.9901e-01, -4.3226e-01,\n",
      "        -1.2037e+00,  4.2074e-01, -4.1408e-01,  5.7661e-01, -1.2270e+00,\n",
      "        -1.0853e+00, -2.0201e+00, -2.4916e-01,  5.1083e-01,  1.2909e+00,\n",
      "        -6.0874e-02, -1.6207e-01,  1.4810e-02,  3.5787e-01,  3.9092e-01,\n",
      "        -1.5958e+00,  1.1862e-02, -2.0284e+00, -2.3541e+00,  1.6058e-01,\n",
      "        -8.0576e-01,  1.7237e+00,  1.1869e+00, -2.3725e-01, -7.4070e-01,\n",
      "         1.4199e+00,  1.1375e+00, -2.6052e-01,  1.0540e+00, -2.6709e+00,\n",
      "         1.0702e+00, -2.8882e+00,  9.8298e-01,  2.1335e+00,  6.6238e-01,\n",
      "        -9.3496e-01,  1.1963e+00,  3.5978e-01, -1.1061e+00,  1.4238e+00,\n",
      "        -1.2688e+00,  1.7152e+00,  1.1774e+00, -1.2679e+00,  6.0893e-01,\n",
      "         2.3874e-01,  3.7429e-02,  3.8270e-01, -3.4596e-01,  5.3117e-01,\n",
      "         3.9164e-01, -5.5511e+00, -1.4035e+00, -2.1101e+00, -1.4201e+00,\n",
      "         8.4251e-02,  2.1976e+00,  5.7465e-01,  8.6677e-01,  9.1169e-01,\n",
      "        -5.2668e-01,  7.3718e-01,  1.1668e+00,  9.4621e-01,  1.6287e+00,\n",
      "        -6.4643e-01, -1.3191e-01,  1.2142e+00,  5.5734e-01,  1.4205e+00,\n",
      "         1.6549e+00,  1.8549e-01, -1.4670e+00,  2.2369e-01, -2.5459e+00,\n",
      "         1.7238e+00,  9.4855e-01,  5.5243e-01, -8.2751e-01,  5.9612e-01,\n",
      "         3.1141e-01, -3.7906e-01,  1.4068e+00, -7.6078e-01,  1.1204e+00,\n",
      "         1.0863e+00,  6.3642e-01, -3.5384e-01,  7.9805e-01,  1.6728e-01,\n",
      "         3.4936e-01, -2.2677e+00,  8.9985e-01,  1.4934e-01,  1.1707e+00,\n",
      "         1.7489e-01, -1.9192e+00,  2.5386e-02, -2.8955e-01, -3.0704e+00,\n",
      "         4.7007e-01, -3.3864e+00,  1.3171e+00, -1.3417e+00,  1.3636e+00,\n",
      "        -2.8112e+00, -4.3006e-02,  1.6476e-01,  1.1014e+00,  1.7463e+00,\n",
      "        -1.6866e+00, -3.4090e-01,  6.2348e-01,  8.7214e-01, -1.2153e+00,\n",
      "         1.4669e+00,  1.1227e+00,  8.9011e-01,  3.0923e-01, -1.7774e+00,\n",
      "        -6.3610e-01,  1.1368e+00, -1.2457e+00,  1.1095e+00, -9.7458e-01,\n",
      "         9.1743e-01,  5.7574e-01, -1.2898e+00, -1.4022e-01,  3.3140e-01,\n",
      "         4.4940e-01,  8.6117e-01,  1.2123e+00, -9.1968e-02,  8.7356e-01,\n",
      "         1.0072e+00,  9.4888e-01, -1.7012e+00,  1.6719e+00, -1.8095e+00,\n",
      "         5.3716e-01,  7.1441e-01, -1.4389e+00,  7.0561e-02, -2.0580e+00,\n",
      "        -2.0483e+00, -9.2834e-03, -1.2554e+00,  5.5470e-01, -1.0198e+00,\n",
      "         1.4601e+00, -2.0963e+00,  9.5126e-01, -8.1070e-01,  3.9537e-01,\n",
      "         4.3394e-01, -8.0288e-01,  8.2164e-01, -1.9610e+00,  9.2203e-01,\n",
      "        -2.9937e-01, -5.7980e-01, -1.4506e-01,  2.4311e-01,  6.4719e-01,\n",
      "         1.4840e+00,  5.3681e-01, -9.0279e-01,  1.3934e+00,  9.6443e-01,\n",
      "         8.6679e-01, -2.3646e+00,  9.6313e-01, -1.4791e+00, -1.6244e+00,\n",
      "        -5.5694e-01,  1.3659e+00, -3.0254e-02,  9.9901e-01,  1.9211e-01,\n",
      "        -1.7254e+00, -2.7344e-01, -3.1608e-01,  8.2895e-01, -1.6091e+00,\n",
      "         1.2747e+00,  1.5329e+00,  6.3106e-01,  5.1230e-01, -2.9544e-01,\n",
      "         8.9633e-01,  1.5771e+00, -1.5901e+00, -4.2952e-01,  1.0485e+00,\n",
      "         4.4703e-01, -5.3352e-01, -6.1414e-01, -7.5935e-01,  3.5610e-01,\n",
      "         8.0143e-01, -9.0964e-01,  1.1674e+00,  1.2092e+00, -1.8935e+00,\n",
      "         1.5939e+00,  9.0739e-01,  3.3266e-01,  2.7867e-01,  8.6019e-01,\n",
      "        -7.2368e-02,  6.2781e-01, -6.7846e-01,  1.1972e+00, -1.5055e-01,\n",
      "         3.2865e-01, -1.4696e+00,  5.5930e-01,  5.1496e-02,  6.2058e-01,\n",
      "         9.2194e-01,  5.4952e-01,  4.9084e-01,  1.0468e+00, -1.9611e-01,\n",
      "        -1.1881e+00,  8.0242e-01, -2.2556e-01,  1.1734e+00,  1.0506e-01,\n",
      "        -7.0269e-01,  1.4477e+00, -1.4464e+00, -2.2630e+00,  4.2941e-01,\n",
      "         1.2408e+00,  1.8082e+00, -1.2467e+00, -1.5371e+00,  7.2395e-01,\n",
      "        -4.4211e-01,  1.5880e+00,  1.9669e+00,  1.1731e+00, -1.8647e-01,\n",
      "        -4.4757e-01,  7.2324e-01, -1.3773e+00,  1.1037e+00, -1.6162e+00,\n",
      "        -1.1060e-01,  1.4235e+00, -1.0142e+00,  8.5564e-02,  1.6609e-01,\n",
      "        -7.2838e-01,  6.3437e-02,  1.1617e+00, -5.1380e-01,  1.2673e+00,\n",
      "        -8.6343e-01, -2.0453e+00,  5.2646e-01,  5.5356e-01, -7.4903e-01,\n",
      "         1.1114e+00, -2.0349e+00,  1.1100e-01,  4.2699e-01, -7.0849e-01,\n",
      "        -1.3542e+00, -9.4389e-01,  2.0115e-01, -1.4473e+00,  5.8299e-01,\n",
      "         1.1233e+00, -1.0698e+00, -1.1860e+00, -7.5452e-01,  5.0140e-01,\n",
      "        -1.5170e+00, -7.0946e-02, -3.4522e-01,  3.3967e-01,  3.4059e-01,\n",
      "        -4.7227e-01, -3.8719e-01,  8.4702e-01, -3.2288e-01,  2.8566e+00,\n",
      "        -2.3793e-01, -5.8534e-01,  1.1694e+00,  9.7533e-01,  2.2010e-01,\n",
      "         5.6538e-01,  1.0873e+00, -1.5779e-02,  1.1855e+00, -4.5347e+00,\n",
      "        -2.1061e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.3632, -0.2316,  0.4087],\n",
      "          [ 0.0873,  0.2581, -0.0171],\n",
      "          [-0.1741, -0.7284, -0.2163]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5397,  0.3590,  0.5769],\n",
      "          [ 0.2009, -0.3700, -0.2434],\n",
      "          [ 0.0678, -0.3945, -0.3078]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1721,  0.3831,  0.4082],\n",
      "          [-0.8104, -0.0672,  0.2665],\n",
      "          [-0.0570, -0.1643, -0.1076]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0905, -0.3728, -0.4746],\n",
      "          [ 0.0519, -0.5816, -0.2483],\n",
      "          [-0.2112, -0.7346, -0.3318]]],\n",
      "\n",
      "\n",
      "        [[[-0.0748, -0.1912,  0.1255],\n",
      "          [ 0.2953, -0.2257,  0.0516],\n",
      "          [-0.3408, -0.2583,  0.4867]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4342,  0.4959,  0.1799],\n",
      "          [-0.0125, -0.1034, -0.0455],\n",
      "          [-0.2943, -0.3796, -0.6476]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 3.8307e-01,  1.5210e+00,  1.6429e+00,  1.5725e+00,  2.8391e-01,\n",
      "         1.4743e+00,  1.1981e+00,  2.5058e+00,  1.6119e+00,  1.5713e+00,\n",
      "         1.1653e+00,  9.1650e-01,  9.3062e-01,  1.0608e+00,  7.5043e-01,\n",
      "         3.2516e+00,  1.3473e+00,  2.0723e+00,  1.8616e+00,  2.7864e+00,\n",
      "         1.0239e+00,  3.1595e+00,  9.2479e-01,  1.3081e+00,  1.4551e+00,\n",
      "         9.7284e-01,  1.5195e+00,  1.8254e+00,  2.9470e+00,  2.0220e+00,\n",
      "         1.5373e+00,  1.3837e+00,  1.4946e+00,  1.5411e+00,  1.1586e+00,\n",
      "         1.7083e+00,  1.2865e+00,  4.8042e-01,  1.0769e+00,  1.7805e+00,\n",
      "         2.4905e-01,  1.1454e+00,  1.4371e+00,  1.8102e+00,  1.0123e+00,\n",
      "         8.2724e-01,  1.1600e+00,  8.1293e-01,  1.4659e+00,  1.4890e+00,\n",
      "         8.1942e-01,  4.5148e+00,  8.3559e-01,  1.5799e+00,  2.2805e+00,\n",
      "         2.3615e+00,  1.8494e+00,  2.8028e+00,  1.3975e+00,  2.0830e+00,\n",
      "         1.0919e+00,  1.7776e+00,  3.8661e+00,  1.2788e+00,  1.9526e+00,\n",
      "         1.5963e+00,  1.7655e+00,  1.3663e+00,  1.5481e+00,  1.9771e+00,\n",
      "         1.9248e+00,  1.8873e+00,  1.6433e+00,  4.9118e-01,  1.0364e+00,\n",
      "         1.8235e+00,  1.7885e+00,  1.9467e+00,  1.7633e+00,  1.8186e+00,\n",
      "         1.4450e+00,  1.4326e+00,  1.4884e+00,  1.1935e+00,  1.4145e+00,\n",
      "         1.1798e+00,  1.3853e+00,  1.8785e+00,  1.5892e+00,  6.6116e-01,\n",
      "         1.2309e+00,  1.4865e+00,  2.2326e+00,  1.4663e+00,  1.7324e+00,\n",
      "         1.9939e+00,  1.1666e+00,  1.2042e+00,  9.3485e-01,  2.5837e+00,\n",
      "         1.5008e+00,  2.0473e+00,  1.5682e+00,  3.7287e-01,  1.2084e+00,\n",
      "         1.6230e+00,  1.7222e+00,  1.3785e+00,  1.6678e+00,  3.5847e-01,\n",
      "         1.1865e+00,  4.3858e-01,  1.4379e+00,  1.4656e+00,  1.7957e+00,\n",
      "         3.6991e-01,  1.2396e+00,  1.9124e+00,  1.7482e+00,  1.8817e+00,\n",
      "         6.9510e-01,  1.9503e+00,  1.5374e+00,  1.0665e+00,  1.6319e-01,\n",
      "         1.7188e+00,  4.3326e+00,  9.9263e-01,  1.7700e+00,  2.0785e+00,\n",
      "         1.3938e+00,  1.3361e-01,  2.1042e+00,  1.0811e+00,  1.8538e+00,\n",
      "         3.2338e+00,  7.2239e-01,  1.3697e+00,  2.6890e+00,  1.4139e+00,\n",
      "         6.6420e-01,  1.3198e+00,  1.4428e+00,  1.9290e+00,  1.9914e+00,\n",
      "         2.1302e+00,  1.2800e+00,  1.3524e+00,  6.2098e-01,  1.6743e+00,\n",
      "         1.4838e+00,  6.0434e-01,  1.3545e+00,  2.9452e+00,  5.7552e-01,\n",
      "         9.2160e-01,  1.0186e+00,  7.8069e-01,  1.6976e+00,  1.1193e+00,\n",
      "         1.3727e+00,  5.0932e+00,  1.3221e+00,  1.6176e+00,  1.3524e+00,\n",
      "         1.5828e+00,  1.3134e+00,  1.4571e+00,  2.2407e+00,  1.1031e+00,\n",
      "         1.7890e+00,  1.8096e+00,  5.1377e-01,  9.3683e-01,  6.1304e-01,\n",
      "         1.2182e+00,  1.0311e+00,  1.4428e+00,  8.5476e-01,  1.0511e+00,\n",
      "         1.4812e+00,  2.4084e+00,  2.7417e+00,  8.9616e-01,  1.2836e+00,\n",
      "         2.3354e+00,  1.1055e+00,  1.8245e+00,  7.2387e-01,  1.0451e+00,\n",
      "         1.2854e+00,  2.2945e+00,  1.3254e+00,  1.5613e+00,  1.4271e+00,\n",
      "         1.4598e+00,  1.5138e+00,  1.7612e+00,  7.5184e-01,  1.8526e+00,\n",
      "         1.2442e+00,  2.3808e+00,  1.2479e+00,  2.4767e+00,  4.8863e-01,\n",
      "         1.6571e+00,  2.3162e-01,  5.1881e-01,  1.4828e+00,  1.5644e+00,\n",
      "         1.7491e+00,  1.2972e+00,  1.4114e+00,  9.2160e-01,  1.8904e+00,\n",
      "         8.2501e-01,  1.8640e+00,  1.8343e+00,  1.2844e+00,  1.3292e+00,\n",
      "         1.5408e+00,  2.5271e+00,  9.0990e-01,  1.6458e+00,  1.4786e+00,\n",
      "         1.7183e+00,  6.9418e-01,  1.3676e+00,  1.9728e+00,  1.6580e+00,\n",
      "         1.2597e+00,  1.7664e+00,  1.9392e+00,  4.2292e+00,  2.0672e+00,\n",
      "         1.7805e+00,  1.5815e+00,  1.4828e+00,  1.8128e+00,  1.1672e+00,\n",
      "         1.8319e+00,  2.0678e+00,  1.4773e+00,  1.0998e+00,  2.0356e+00,\n",
      "         3.0363e-01,  6.6069e-01,  1.2981e+00,  1.6403e+00,  1.0695e+00,\n",
      "         1.1633e+00,  1.3627e+00,  1.4270e+00,  1.8988e+00,  1.4973e+00,\n",
      "         1.1353e+00,  1.9498e+00,  3.3810e+00,  1.3862e+00,  1.5801e+00,\n",
      "         1.6161e+00,  1.7104e+00,  2.8740e-01,  1.1377e+00,  1.4270e+00,\n",
      "         1.5764e+00,  1.2858e+00,  1.3369e+00,  1.2756e+00,  2.2428e+00,\n",
      "         1.6006e+00,  8.9547e-01,  1.1745e+00,  9.4659e-01,  1.6104e+00,\n",
      "         2.0543e+00,  1.3093e+00,  1.8009e+00,  1.0722e+00,  1.2153e+00,\n",
      "         1.3128e+00,  5.1639e-01,  1.9601e+00,  1.3460e+00,  1.6687e+00,\n",
      "         1.4710e+00,  1.6889e+00,  7.7364e-04,  1.5532e+00,  1.2571e+00,\n",
      "         2.5674e+00,  1.9462e+00,  8.6310e-01,  4.8457e-01,  2.2322e+00,\n",
      "         1.5287e+00,  2.9477e+00,  1.7924e+00,  8.2112e-01,  1.7404e+00,\n",
      "         1.9371e+00,  1.1026e+00,  5.7663e-01,  1.8685e+00,  1.0251e+00,\n",
      "         1.6468e+00,  1.4238e+00,  2.1821e+00,  2.3907e-01,  1.5151e+00,\n",
      "         9.2211e-01,  1.6988e+00,  5.5713e-01,  1.5824e+00,  1.3471e+00,\n",
      "         1.2148e+00,  2.3116e+00,  1.5384e+00,  5.0863e-01,  1.6183e+00,\n",
      "         1.6895e+00,  1.2556e+00,  1.5084e+00,  1.4845e+00,  1.9068e+00,\n",
      "         1.0152e+00,  5.7259e+00,  7.4644e-01,  4.3451e+00,  1.6360e+00,\n",
      "         1.5252e+00,  7.9968e-01,  2.0520e+00,  1.0298e+00,  2.0533e+00,\n",
      "         1.1587e+00,  1.6842e+00,  1.1403e+00,  2.1423e+00,  1.4061e+00,\n",
      "         1.4975e+00,  1.4264e+00,  1.7303e+00,  1.7197e+00,  1.4343e+00,\n",
      "         1.7584e+00,  1.9266e+00,  1.5815e+00,  1.2831e+00,  9.3161e-01,\n",
      "         6.2223e-02,  1.6792e+00,  1.0334e+00, -5.3192e-02,  3.1072e+00,\n",
      "         1.4111e+00,  1.5632e+00,  8.1139e-01,  1.3843e+00,  1.8943e+00,\n",
      "         8.2141e-01,  1.1341e+00,  1.6345e+00,  1.6758e+00,  1.4913e+00,\n",
      "         1.9229e+00,  3.7536e+00,  2.4373e+00,  1.0244e+00,  1.0691e+00,\n",
      "         1.7028e+00,  7.4510e-01,  5.4003e-01,  1.7007e+00,  1.7135e+00,\n",
      "         2.0948e+00,  2.0577e-01,  1.3306e+00,  9.0695e-01,  1.9900e+00,\n",
      "         2.7190e+00,  1.6896e+00,  1.7810e+00,  1.4882e+00,  7.0908e-01,\n",
      "         6.9124e-01,  8.1107e-01,  1.0195e+00,  1.8822e+00,  1.5158e+00,\n",
      "         1.9535e+00,  1.6437e+00,  1.5093e+00,  1.9396e+00, -6.2659e-02,\n",
      "         1.8541e+00,  2.3696e+00,  3.5356e+00,  1.2981e+00,  1.9836e+00,\n",
      "         1.3411e+00,  1.7529e+00,  3.1922e+00,  2.2003e+00,  1.2811e+00,\n",
      "         2.4057e-01,  2.4516e+00,  1.9777e+00,  1.2433e-01,  2.6193e+00,\n",
      "         1.3940e+00,  1.8362e+00,  2.3796e+00,  1.7893e+00,  1.6618e+00,\n",
      "         7.8821e-01,  9.5115e-01,  1.0508e+00,  1.5467e+00,  2.3377e+00,\n",
      "         2.1000e+00,  1.3483e+00,  7.8293e-01,  1.7404e+00,  5.1408e-02,\n",
      "         1.7243e+00,  1.3618e+00,  1.9550e+00,  9.5843e-01,  1.2002e+00,\n",
      "         9.3858e-01,  9.9566e-01,  1.0406e+00,  1.0795e+00,  1.3990e+00,\n",
      "         1.7115e+00,  7.7060e-01,  1.4305e+00,  9.1664e-01,  1.7577e+00,\n",
      "         1.3491e+00,  1.6375e+00,  1.4415e+00,  2.4507e+00,  2.0114e+00,\n",
      "         1.9037e+00,  2.4969e+00,  1.5191e+00,  3.2976e+00,  1.2589e+00,\n",
      "         1.9810e+00,  1.9214e+00,  1.4091e+00,  1.2812e+00,  1.6400e+00,\n",
      "         1.8463e+00,  1.4453e+00,  9.3166e-01,  1.7828e+00,  1.1185e+00,\n",
      "         1.3307e+00,  1.7049e+00,  1.2142e+00,  8.0279e-01,  2.3221e+00,\n",
      "         1.7243e+00,  1.5826e+00,  2.2318e+00,  1.1707e+00,  2.1385e+00,\n",
      "         1.5269e+00,  1.4579e+00,  1.3345e+00,  1.1712e+00,  1.6826e+00,\n",
      "         1.5211e+00,  1.6766e+00,  1.6519e+00,  1.8099e+00,  2.3383e+00,\n",
      "         6.9420e-01,  1.3373e+00,  1.9003e+00,  2.3347e+00,  2.3533e-01,\n",
      "         1.3183e+00,  1.4014e+00,  3.3667e+00,  1.0200e+00,  1.2946e+00,\n",
      "         1.6493e+00,  3.7947e-01,  1.8431e+00,  1.9265e+00,  1.4491e+00,\n",
      "         1.4595e+00,  1.9088e+00,  1.6111e+00,  1.4160e+00,  8.5220e-01,\n",
      "         6.9976e-01,  1.7748e+00,  2.0461e+00,  1.6413e+00,  2.0982e+00,\n",
      "         1.3846e+00,  1.7952e+00,  4.7769e-01,  8.7091e-01,  1.5128e+00,\n",
      "         1.2557e+00,  6.5228e-01,  8.2786e-01,  5.3610e-01,  1.4131e+00,\n",
      "         9.1110e-01,  2.2437e+00,  1.6991e+00,  1.7285e+00,  1.1077e+00,\n",
      "         1.1289e+00,  9.1650e-01,  8.9322e-01,  1.4246e+00,  3.3707e+00,\n",
      "         1.8726e+00,  1.8402e+00,  2.7514e+00,  9.1370e-01,  9.0180e-01,\n",
      "         2.5656e+00,  1.7084e+00,  1.5368e+00,  1.3531e+00,  4.6447e-01,\n",
      "         1.3821e+00,  1.4362e+00,  8.7346e-01,  8.4586e-01,  7.7347e-01,\n",
      "         1.0667e+00,  3.2233e+00,  1.3531e+00,  1.1372e+00,  1.6685e+00,\n",
      "         2.0163e+00,  8.3987e-01,  1.7742e+00,  1.1222e+00,  1.4739e+00,\n",
      "         1.9227e+00,  6.1741e-01,  7.4334e-01,  5.6221e-01,  1.6214e+00,\n",
      "         3.7867e+00,  2.2524e+00,  1.6573e+00,  1.7816e+00,  1.7999e+00,\n",
      "         1.2892e+00,  3.5769e-01,  1.2888e+00,  2.5850e-02, -8.5873e-02,\n",
      "         1.9172e+00,  1.7384e+00,  8.7136e-01,  1.6523e+00,  1.1923e+00,\n",
      "         1.6392e+00,  1.7037e+00,  1.4584e+00,  7.3641e-01,  4.3946e+00,\n",
      "         1.8488e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.3938e-01, -1.3313e+00, -1.3832e+00, -1.9988e+00, -3.7938e-01,\n",
      "        -9.6035e-01, -7.7284e-01, -1.2465e+00, -1.4488e+00, -1.8388e+00,\n",
      "        -1.1578e+00, -3.8995e-01, -2.2905e+00, -5.6567e-01, -4.6948e-01,\n",
      "        -7.3138e-01, -6.2748e-01, -1.0158e+00, -2.8045e-01, -6.0766e-01,\n",
      "        -5.0770e-01, -1.5457e-01,  5.7885e-01, -6.4115e-01, -1.9233e+00,\n",
      "        -2.7815e-01, -1.5301e+00, -1.0109e+00, -2.3495e+00, -1.4813e+00,\n",
      "        -6.1422e-01, -1.6033e+00, -3.9054e-01, -9.7035e-01, -7.3615e-01,\n",
      "        -1.3820e+00, -7.9182e-01, -1.0141e-01, -1.0661e+00, -1.4664e+00,\n",
      "        -5.4048e-02, -1.5379e+00, -1.3490e+00, -1.3638e+00, -1.0820e-01,\n",
      "         3.7161e-02, -5.0801e-01,  1.1191e-01, -1.8642e+00, -1.5354e+00,\n",
      "        -2.4592e-01, -1.0716e+00, -5.1914e-02, -1.7182e+00, -1.7878e+00,\n",
      "        -1.5532e+00, -9.2965e-01, -2.2748e+00, -6.3615e-01, -1.0358e+00,\n",
      "        -7.8088e-02, -2.6110e+00, -1.1413e-01, -1.2032e+00, -1.5670e+00,\n",
      "        -2.4347e+00, -1.8521e+00, -1.5069e+00, -1.2250e+00, -1.1769e+00,\n",
      "        -1.3314e+00, -4.9295e-01, -1.0209e+00, -2.8936e-01, -9.3841e-03,\n",
      "        -5.2501e-01, -1.5719e+00, -1.6428e+00, -1.3216e+00, -1.2544e+00,\n",
      "        -1.3170e+00, -3.4415e-02, -1.0987e+00, -6.6286e-01, -8.0462e-01,\n",
      "         6.1658e-01, -1.8260e+00, -2.1954e+00, -1.1294e+00, -3.8947e-01,\n",
      "        -2.0871e+00,  3.3982e-02, -2.2224e+00, -1.9419e+00, -1.2394e+00,\n",
      "        -1.5646e+00,  3.5895e-01, -4.3903e-01, -3.8173e-01, -1.5454e+00,\n",
      "        -2.7527e+00, -2.4586e+00, -1.4756e+00, -7.8051e-02, -5.4884e-01,\n",
      "        -2.2915e+00, -1.2894e+00, -3.1158e+00, -1.3738e+00,  8.3938e-03,\n",
      "        -8.2404e-01, -7.9611e-02, -9.4816e-01, -1.7654e+00, -5.5729e-01,\n",
      "         1.7670e-01, -5.4193e+00, -1.9782e+00, -1.4663e+00, -3.3822e-01,\n",
      "         1.8898e-01, -1.5454e+00, -1.6455e+00, -3.5086e-01,  1.1636e-02,\n",
      "        -6.9781e-01,  3.1256e-02, -2.8271e-01, -8.3458e-01, -1.0857e+00,\n",
      "        -2.1114e+00,  1.1313e-02,  4.1947e-01, -6.6980e-01, -9.5303e-02,\n",
      "        -1.4139e+00, -2.7140e-01, -2.4166e+00, -9.7283e-01,  3.3584e-02,\n",
      "        -1.0879e-01, -2.0646e+00, -1.3489e+00, -9.5201e-01, -1.3590e+00,\n",
      "        -1.1543e+00, -1.5345e+00, -1.8538e+00, -1.2569e-01, -5.5607e-01,\n",
      "        -1.3361e+00,  1.7263e-01, -1.2911e+00, -1.1464e-01,  2.2648e-03,\n",
      "        -1.3236e-01,  2.5320e-01, -2.7342e-02, -1.3449e+00, -3.3589e-01,\n",
      "        -3.8394e-01, -4.9122e-01, -2.1370e+00, -1.5204e+00, -1.3807e+00,\n",
      "        -1.5252e+00, -5.4236e-01, -1.2849e+00, -7.8858e-01, -3.2039e-01,\n",
      "        -1.4829e+00, -1.3699e+00, -3.0769e-01, -9.2329e-01, -1.0285e-01,\n",
      "        -1.4934e+00, -9.5911e-01, -9.5019e-01, -2.0257e-01, -5.6594e-01,\n",
      "        -1.4542e+00, -2.4578e-01, -1.7509e+00, -3.3662e-01, -4.1981e-01,\n",
      "        -1.2933e+00, -3.1486e-01, -1.3460e+00, -3.6180e-01, -1.0516e-01,\n",
      "        -1.5114e+00, -1.7911e+00,  9.5830e-03, -1.7874e+00, -1.1665e+00,\n",
      "        -2.2036e+00,  6.1608e-01, -7.0525e-01,  2.1970e-01, -1.3340e+00,\n",
      "        -8.0039e-01, -4.8490e-01,  2.0731e-02, -1.9395e+00,  9.7979e-01,\n",
      "        -1.5154e+00,  1.0540e-02,  1.2962e-01, -8.3598e-01, -1.4909e+00,\n",
      "        -1.4786e+00, -3.1686e-01, -1.0886e+00, -3.8671e-01, -1.7224e+00,\n",
      "         7.2959e-02, -1.4883e+00, -7.6721e-01, -7.3656e-01, -2.9833e+00,\n",
      "        -1.5220e+00, -3.6916e-02, -1.7181e-01, -1.2658e+00, -9.5864e-01,\n",
      "        -1.3613e+00, -2.7696e-01, -8.8614e-01, -1.5815e+00, -1.6135e+00,\n",
      "        -9.1895e-01, -1.6742e+00,  5.4477e-01, -2.4612e+00, -2.1815e+00,\n",
      "        -2.5161e-01, -1.4672e+00, -6.6649e-01, -1.6617e+00, -5.1000e-01,\n",
      "        -1.3125e+00, -1.8404e+00, -1.0591e+00, -2.4027e+00, -1.4740e+00,\n",
      "         2.7828e-01, -6.7783e-02, -1.4055e+00, -1.6222e+00,  1.0489e-01,\n",
      "        -9.1807e-01, -1.2073e+00, -1.5056e+00, -1.4724e+00, -2.5286e+00,\n",
      "         9.2904e-01, -1.4296e+00, -6.0187e-01, -1.3603e+00, -2.4886e+00,\n",
      "        -2.1894e+00, -1.2435e+00,  7.9540e-02, -4.7100e-01, -1.5856e+00,\n",
      "        -1.1110e+00, -9.4214e-01, -1.2929e+00, -1.0133e+00, -2.2365e+00,\n",
      "        -2.2582e+00, -2.0016e-01, -8.1242e-01, -1.8357e-01, -5.3518e-01,\n",
      "        -6.3080e-01, -1.7496e+00, -1.1726e+00, -4.9269e-01, -1.4808e+00,\n",
      "        -1.6418e+00,  3.4954e-02, -3.2055e-01, -2.0333e+00, -1.4089e+00,\n",
      "        -1.8566e+00, -1.3055e+00, -5.3307e+00, -1.1111e+00, -6.2509e-01,\n",
      "        -5.6400e-01, -1.7169e+00, -1.2036e-01, -1.3091e-01, -1.3387e+00,\n",
      "        -1.3429e+00, -1.6398e+00, -1.6974e+00,  5.2225e-02,  6.1949e-01,\n",
      "        -1.4338e+00,  6.3901e-01, -7.4612e-02, -5.8278e-01, -3.9354e-01,\n",
      "        -1.0153e+00, -5.9500e-01, -1.9119e+00, -2.0253e-02, -1.3085e+00,\n",
      "        -2.0064e-01, -1.7002e+00, -1.8391e-01, -3.3439e-01,  5.0161e-02,\n",
      "         3.6956e-01, -1.1145e+00, -1.0391e+00, -6.8277e-02, -5.3528e-01,\n",
      "        -1.4479e+00, -1.6509e+00, -2.2808e+00, -6.9366e-01, -1.7965e+00,\n",
      "        -4.2250e-01, -2.2302e+00, -4.5727e-01,  2.9469e-01, -2.5447e+00,\n",
      "        -1.3260e+00, -1.2351e-01, -1.3421e+00, -4.2216e-01, -2.5515e+00,\n",
      "        -1.0219e-02, -9.1151e-01, -3.8418e-01, -8.1804e-01, -2.5112e+00,\n",
      "         2.6998e-02, -1.6448e+00, -1.1552e+00, -1.3077e+00, -1.9481e+00,\n",
      "        -1.9693e+00, -1.8301e+00, -8.3422e-01, -8.4715e-01, -1.1766e-01,\n",
      "         5.9552e-02, -1.4637e+00, -6.3879e-01, -1.4773e-02, -1.2523e+00,\n",
      "        -1.9491e+00, -2.0595e-01, -1.3545e-01, -7.3052e-01, -1.7504e+00,\n",
      "        -1.7842e-01, -3.6414e-01, -5.5284e-01, -1.2748e+00, -1.4293e+00,\n",
      "        -1.2067e+00, -2.9198e-01, -1.8135e+00, -4.4376e-01, -4.4549e-01,\n",
      "        -1.1588e+00,  3.8400e-02, -1.8971e-01, -2.2434e+00, -9.0359e-01,\n",
      "        -1.0570e+00, -1.9619e+00,  8.7798e-01,  4.0839e-01, -1.6491e+00,\n",
      "        -7.7134e-01, -1.3961e+00, -1.3331e+00, -1.1773e+00, -1.5720e-01,\n",
      "        -5.4926e-02, -6.0853e-02, -4.2697e-01, -7.8725e-01, -8.7155e-01,\n",
      "        -1.5316e+00, -1.0601e+00, -1.1215e+00, -9.2295e-01, -5.0992e-02,\n",
      "        -2.6425e+00, -1.2505e+00,  2.4045e-01, -4.2046e-01, -1.1895e+00,\n",
      "        -7.8633e-01, -1.5560e+00, -3.7765e-01, -5.3368e-01, -1.9413e+00,\n",
      "         3.0602e-01, -1.6607e+00, -1.2998e+00,  3.2909e-02, -1.4509e+00,\n",
      "        -2.2163e+00, -1.7679e+00, -9.7594e-03, -1.8417e+00, -2.1218e-01,\n",
      "         9.9176e-01, -2.0733e-01, -2.3125e+00, -2.2872e+00,  2.8018e-01,\n",
      "        -4.5949e-01,  1.2303e-01, -2.4852e-01, -1.6908e+00, -1.6275e-02,\n",
      "        -6.6777e-01, -3.1973e+00, -1.6913e+00, -4.1586e-01,  5.2429e-01,\n",
      "         1.4210e+00, -1.1577e+00, -9.2426e-02, -2.0205e-01, -1.4068e+00,\n",
      "        -2.1021e+00, -2.2232e-01, -1.6644e+00, -3.9333e-01, -1.9772e+00,\n",
      "        -1.6778e+00, -8.9125e-01, -2.5582e+00, -1.3989e+00, -1.2368e+00,\n",
      "        -1.3124e+00, -3.8522e-01, -9.2883e-01,  3.4088e-01, -8.5664e-01,\n",
      "        -5.3899e-01, -6.8245e-01, -2.2691e+00, -1.6202e+00, -1.5261e+00,\n",
      "        -1.7667e+00, -2.2991e+00, -6.7256e-01,  1.4685e-01, -1.0855e-01,\n",
      "        -1.5364e+00, -1.8104e+00, -4.6476e-01, -1.9480e-01, -1.1049e+00,\n",
      "        -9.0528e-01, -1.4069e+00, -2.4445e-01, -4.3853e-01, -1.2304e+00,\n",
      "        -1.3891e+00, -5.0314e-01, -1.8141e+00, -1.4905e+00, -9.1792e-01,\n",
      "        -2.4383e+00, -2.1158e+00, -1.2226e+00, -1.0548e+00, -1.6978e-01,\n",
      "         5.1322e-01, -1.7555e+00, -1.2864e+00, -2.2082e+00, -1.7423e-01,\n",
      "        -9.6249e-01, -2.0977e+00, -1.3099e+00, -5.4107e-02, -1.4770e+00,\n",
      "        -1.0887e+00, -9.7711e-02, -1.3657e+00, -1.1558e+00, -8.2794e-01,\n",
      "        -8.6431e-01, -1.1615e+00, -1.3153e+00, -6.2402e-01, -2.6567e-02,\n",
      "         5.0702e-02, -1.1579e+00, -1.0679e+00, -2.5531e+00, -9.4953e-01,\n",
      "        -2.7668e+00, -1.9129e+00,  5.5001e-01, -7.6154e-01, -1.4842e+00,\n",
      "         1.1817e-01, -1.0585e-01,  7.7047e-02, -1.8443e-02, -1.9517e+00,\n",
      "         5.3080e-01, -1.7195e+00, -1.8492e+00, -1.8770e+00, -1.7478e-01,\n",
      "        -9.3778e-01, -4.4621e-01, -2.9386e-01, -1.3830e+00, -4.6616e-02,\n",
      "        -1.4908e+00, -1.3854e+00,  1.3976e-01, -2.4268e-01,  1.0388e-01,\n",
      "         1.3805e-01, -1.4857e+00, -2.1253e+00, -5.2283e-01, -2.4829e-01,\n",
      "         3.3185e-02, -3.1318e-01,  8.0826e-01,  3.8139e-01, -3.2467e-01,\n",
      "        -6.1847e-01, -3.0838e-02, -1.3324e+00,  4.1577e-01, -8.6368e-01,\n",
      "        -9.0204e-01, -2.7409e-01, -1.3725e+00, -5.2865e-01, -1.6782e+00,\n",
      "        -1.4522e+00, -6.0108e-02, -2.5907e-01,  3.4515e-02, -1.4623e+00,\n",
      "        -3.2522e-01, -9.0900e-01, -1.5372e+00, -2.1129e-01, -1.4334e+00,\n",
      "        -3.4600e+00,  5.8368e-01, -1.0357e+00,  4.2215e-02,  5.7247e-02,\n",
      "        -3.2602e-01, -1.7176e+00, -9.5662e-02, -5.9881e-01, -2.5709e+00,\n",
      "        -1.2301e+00, -9.5591e-01, -8.6337e-01, -1.1709e-02, -2.8780e+00,\n",
      "        -1.3730e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0757]],\n",
      "\n",
      "         [[ 0.1649]],\n",
      "\n",
      "         [[-0.0080]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2995]],\n",
      "\n",
      "         [[ 1.0488]],\n",
      "\n",
      "         [[ 0.0833]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1351]],\n",
      "\n",
      "         [[ 0.0996]],\n",
      "\n",
      "         [[ 0.6418]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0557]],\n",
      "\n",
      "         [[-0.2792]],\n",
      "\n",
      "         [[ 0.7480]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0094]],\n",
      "\n",
      "         [[-0.0580]],\n",
      "\n",
      "         [[-0.6883]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4324]],\n",
      "\n",
      "         [[-0.0509]],\n",
      "\n",
      "         [[ 0.1104]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2806]],\n",
      "\n",
      "         [[-0.0033]],\n",
      "\n",
      "         [[ 0.6042]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0030]],\n",
      "\n",
      "         [[-0.1073]],\n",
      "\n",
      "         [[-0.3390]]],\n",
      "\n",
      "\n",
      "        [[[-0.1976]],\n",
      "\n",
      "         [[ 0.0749]],\n",
      "\n",
      "         [[-0.1576]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4111]],\n",
      "\n",
      "         [[-0.1167]],\n",
      "\n",
      "         [[-0.7175]]],\n",
      "\n",
      "\n",
      "        [[[-0.2128]],\n",
      "\n",
      "         [[-0.0012]],\n",
      "\n",
      "         [[ 0.0392]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2571]],\n",
      "\n",
      "         [[-0.2973]],\n",
      "\n",
      "         [[ 0.2092]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.2048, -0.2788,  0.0669, -0.0072,  0.0332,  0.0681,  0.0536, -0.0973,\n",
      "         0.1430,  0.1270,  0.1301,  0.0940,  0.1868,  0.0371,  0.0127,  0.1556,\n",
      "         0.0208,  0.0361,  0.0698, -0.0511, -0.2235,  0.1432,  0.1573, -0.0441],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 1.1962e-01]],\n",
      "\n",
      "         [[-1.7964e-02]],\n",
      "\n",
      "         [[-2.6253e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.5546e-02]],\n",
      "\n",
      "         [[-6.5815e-02]],\n",
      "\n",
      "         [[ 2.5026e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3668e-01]],\n",
      "\n",
      "         [[-2.9925e-02]],\n",
      "\n",
      "         [[-2.3699e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5039e-01]],\n",
      "\n",
      "         [[-2.8045e-02]],\n",
      "\n",
      "         [[-1.1119e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1367e-01]],\n",
      "\n",
      "         [[ 3.8351e-01]],\n",
      "\n",
      "         [[ 2.9521e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2096e-01]],\n",
      "\n",
      "         [[-6.6386e-02]],\n",
      "\n",
      "         [[ 3.6065e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.6069e-04]],\n",
      "\n",
      "         [[-3.8909e-01]],\n",
      "\n",
      "         [[-1.2018e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.3267e-01]],\n",
      "\n",
      "         [[-4.3240e-01]],\n",
      "\n",
      "         [[-9.4510e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0983e-01]],\n",
      "\n",
      "         [[-2.0164e-01]],\n",
      "\n",
      "         [[ 2.7690e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4228e-02]],\n",
      "\n",
      "         [[-3.5793e-01]],\n",
      "\n",
      "         [[ 1.1062e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6354e-02]],\n",
      "\n",
      "         [[ 6.2889e-01]],\n",
      "\n",
      "         [[-2.2452e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.0287e-01]],\n",
      "\n",
      "         [[ 3.1453e-02]],\n",
      "\n",
      "         [[ 2.4011e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.3486,  0.2160,  0.2380,  0.2231,  0.3512,  0.2073,  0.3695,  0.3866,\n",
      "         0.3314,  0.2962,  0.1659,  0.0443,  0.3327, -0.1226,  0.5929,  0.3682,\n",
      "         0.1411,  0.5446, -0.0636,  0.0252, -0.0711, -0.3620, -0.2227, -0.1868,\n",
      "         0.2559,  0.2460,  0.1474,  0.4223,  0.5374,  0.1177,  0.0404, -0.0221,\n",
      "         0.1282, -0.2277,  0.5178,  0.1056, -0.1717, -0.5131, -0.0562,  0.3770,\n",
      "        -0.1643, -0.0705,  0.0227,  0.0078,  0.1255,  0.5003,  0.0034,  0.1322,\n",
      "         0.2994,  0.5794, -0.1533, -0.0340, -0.1067,  0.1847,  0.5011, -0.1484,\n",
      "        -0.0375,  0.1599, -0.0183, -0.2252, -0.3666,  0.3968, -0.1048, -0.3334,\n",
      "         0.4023, -0.1007,  0.0672,  0.4383, -0.2771, -0.0439,  0.3417,  0.0994,\n",
      "         0.0038,  0.0942,  0.2819, -0.1308,  0.6200,  0.3478, -0.3461, -0.3756,\n",
      "         0.3478, -0.0533, -0.2306,  0.0597, -0.1071, -0.0107,  0.1692, -0.1981,\n",
      "        -0.3768, -0.1045,  0.3124, -0.1095, -0.3172,  0.1639,  0.2929,  0.5137,\n",
      "         0.1962, -0.4395, -0.0597,  0.0791,  0.4226, -0.0331,  0.4126,  0.3972,\n",
      "        -0.2153, -0.5480,  0.0647, -0.3282,  0.0052,  0.0414,  0.2316,  0.4251,\n",
      "         0.1622, -0.3038,  0.2956,  0.0887, -0.3868, -0.1643,  0.1112, -0.1237,\n",
      "         0.1125,  0.4393, -0.0291,  0.0486, -0.3810,  0.3690, -0.2872, -0.3034,\n",
      "         0.2431, -0.1972, -0.1032, -0.2257,  0.1398, -0.0235, -0.1949,  0.4456,\n",
      "        -0.1537, -0.0890, -0.3862,  0.5254, -0.0105,  0.2272, -0.3588,  0.2854,\n",
      "         0.1021,  0.3766,  0.1642,  0.0158,  0.4800, -0.1775,  0.2643,  0.0702,\n",
      "        -0.0065, -0.1290, -0.2134, -0.1473, -0.3993,  0.2193, -0.1369, -0.1110,\n",
      "         0.0324, -0.1161,  0.1841,  0.6430,  0.1693,  0.1025, -0.0269, -0.3699,\n",
      "        -0.3180,  0.0680,  0.1690,  0.1660,  0.5402,  0.2425, -0.0423,  0.2188,\n",
      "        -0.0417, -0.1539, -0.1838, -0.0941,  0.2281, -0.2760,  0.5717,  0.1179,\n",
      "        -0.1662,  0.0393,  0.0892, -0.0436,  0.2231, -0.4538, -0.3216, -0.1565,\n",
      "         0.1276,  0.1224, -0.1410,  0.4979,  0.3318,  0.1551,  0.0234, -0.0355,\n",
      "        -0.0076,  0.1803, -0.2421, -0.1174, -0.3758, -0.1035, -0.1662,  0.0947,\n",
      "        -0.3581, -0.0873,  0.0346, -0.0715, -0.0098, -0.5429, -0.1583,  0.0608,\n",
      "         0.1647, -0.2882,  0.4436, -0.1070,  0.4680, -0.1221, -0.1825, -0.3784,\n",
      "        -0.2879,  0.2602, -0.0691, -0.0057,  0.1619,  0.1494, -0.3019,  0.6314,\n",
      "         0.0087,  0.4597,  0.3177, -0.0145,  0.3155,  0.1658,  0.4397, -0.0774,\n",
      "         0.2566,  0.0750,  0.0481,  0.1702, -0.2402,  0.0847, -0.3687, -0.1405,\n",
      "         0.4505,  0.0705, -0.2347, -0.5786, -0.5719,  0.1729, -0.0848, -0.0075,\n",
      "         0.0947,  0.1273, -0.2645, -0.1230,  0.1142,  0.0212, -0.0243, -0.3198,\n",
      "        -0.3433, -0.1716,  0.4193,  0.4213,  0.4830,  0.2706,  0.2544, -0.0439,\n",
      "        -0.0786, -0.5869, -0.0070,  0.5820,  0.3755, -0.1016, -0.1715, -0.0959,\n",
      "        -0.3419,  0.0682, -0.2797,  0.3285, -0.4832, -0.0822, -0.1524,  0.2704,\n",
      "         0.0925, -0.0259, -0.0160,  0.0781, -0.1209,  0.0154, -0.3718,  0.0469,\n",
      "         0.5115, -0.1906, -0.2145, -0.2697,  0.4963,  0.0603, -0.3652,  0.2006,\n",
      "         0.2805,  0.0790, -0.0243,  0.0337, -0.0587, -0.1828,  0.5056,  0.0037,\n",
      "        -0.2454,  0.0927, -0.2774,  0.1666,  0.5612, -0.0380, -0.0608, -0.1242,\n",
      "        -0.0031,  0.0763,  0.0298, -0.1439,  0.3426,  0.2174, -0.4542,  0.1228,\n",
      "        -0.1666, -0.1291,  0.2148, -0.0747,  0.5219, -0.2495,  0.4293, -0.1458,\n",
      "         0.0543, -0.2456,  0.0646,  0.0355, -0.2127, -0.0405, -0.0438, -0.2818,\n",
      "        -0.2577, -0.0260, -0.0431, -0.2362,  0.4521,  0.1389, -0.2695,  0.3140,\n",
      "        -0.6392, -0.4246, -0.5178, -0.1733, -0.0477, -0.3675,  0.2170,  0.4207,\n",
      "        -0.1761, -0.2490,  0.1366,  0.3803, -0.1202, -0.1498, -0.0916,  0.2150,\n",
      "        -0.3003,  0.0569,  0.1923,  0.5469, -0.2292,  0.4243,  0.2229,  0.2035,\n",
      "         0.0513, -0.0834,  0.2253,  0.5634, -0.3346,  0.0233, -0.0891,  0.1506,\n",
      "        -0.0893, -0.0521, -0.0208,  0.1761, -0.5417, -0.0545,  0.4672,  0.3134,\n",
      "        -0.1194,  0.3506,  0.0900, -0.3742, -0.1866, -0.3319,  0.0418, -0.0802,\n",
      "         0.0764,  0.6190,  0.1586,  0.2875,  0.0410, -0.1942, -0.3571,  0.4691,\n",
      "        -0.4056, -0.0513, -0.0059, -0.3539,  0.2330,  0.4706, -0.0279, -0.0609,\n",
      "        -0.3487,  0.0366,  0.3291, -0.0269,  0.0084, -0.2185,  0.4830,  0.2679,\n",
      "        -0.2603, -0.0840, -0.2806,  0.0523,  0.0113, -0.2479,  0.0837,  0.3625,\n",
      "        -0.0285,  0.1364,  0.0804,  0.4349, -0.2256, -0.0900, -0.1601, -0.3222,\n",
      "         0.1703,  0.5428,  0.2932,  0.1967, -0.0042,  0.5015,  0.1061, -0.1504,\n",
      "        -0.1127, -0.1654, -0.2392,  0.2086,  0.2151, -0.3300,  0.0704,  0.2263,\n",
      "         0.3454, -0.0721, -0.0980,  0.2594,  0.1298, -0.4466, -0.0022,  0.0381,\n",
      "         0.2063, -0.0956, -0.4073, -0.1356, -0.0540,  0.3192, -0.3376,  0.2135,\n",
      "        -0.1399, -0.0360, -0.1964,  0.2190, -0.0433,  0.4639,  0.2917, -0.1935,\n",
      "        -0.1715,  0.0408,  0.4414,  0.1008,  0.1207,  0.3041,  0.4805, -0.0550,\n",
      "        -0.2061, -0.3034,  0.0923, -0.2546,  0.0504, -0.1897,  0.4903, -0.0467,\n",
      "        -0.3400,  0.0685, -0.0385,  0.4138,  0.4111,  0.1420, -0.4808,  0.3784,\n",
      "         0.1107,  0.0640,  0.3544,  0.1220,  0.0734, -0.1360, -0.1615,  0.0791,\n",
      "         0.4289,  0.4199,  0.2174,  0.0945, -0.5040,  0.0330,  0.2412,  0.2261,\n",
      "         0.1361, -0.1681, -0.3315, -0.0292, -0.0753,  0.2488,  0.0585, -0.1738,\n",
      "         0.0642, -0.1236, -0.2322,  0.1416, -0.1879,  0.0470, -0.3234,  0.5500,\n",
      "         0.0420, -0.1079,  0.0143, -0.1183,  0.0104, -0.4781,  0.1849,  0.1814,\n",
      "         0.3477,  0.1835,  0.2307,  0.3009,  0.1096, -0.1068,  0.2728,  0.3866,\n",
      "         0.4056,  0.0634,  0.0424,  0.0896, -0.1453,  0.3276, -0.2048, -0.1363,\n",
      "        -0.5861, -0.1094,  0.4110, -0.2275, -0.3807,  0.0760, -0.1400, -0.0464,\n",
      "         0.4082, -0.0609,  0.0293,  0.0483,  0.1364, -0.4050, -0.1357,  0.3014],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0520]],\n",
      "\n",
      "         [[-0.7150]],\n",
      "\n",
      "         [[ 0.0625]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0725]],\n",
      "\n",
      "         [[ 0.0036]],\n",
      "\n",
      "         [[-0.6057]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2027]],\n",
      "\n",
      "         [[ 0.5321]],\n",
      "\n",
      "         [[-0.1930]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1808]],\n",
      "\n",
      "         [[-0.0323]],\n",
      "\n",
      "         [[ 0.6952]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1203]],\n",
      "\n",
      "         [[ 0.0021]],\n",
      "\n",
      "         [[ 0.2516]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2430]],\n",
      "\n",
      "         [[ 0.0790]],\n",
      "\n",
      "         [[-0.0079]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0020]],\n",
      "\n",
      "         [[ 0.0713]],\n",
      "\n",
      "         [[ 0.1671]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2277]],\n",
      "\n",
      "         [[-0.1188]],\n",
      "\n",
      "         [[-0.5021]]],\n",
      "\n",
      "\n",
      "        [[[-0.1832]],\n",
      "\n",
      "         [[ 0.2153]],\n",
      "\n",
      "         [[-0.1228]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1255]],\n",
      "\n",
      "         [[ 0.0256]],\n",
      "\n",
      "         [[-0.5408]]],\n",
      "\n",
      "\n",
      "        [[[-0.1534]],\n",
      "\n",
      "         [[ 0.1148]],\n",
      "\n",
      "         [[ 0.5575]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2696]],\n",
      "\n",
      "         [[ 0.3668]],\n",
      "\n",
      "         [[-0.1786]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.4017, 0.7699, 0.8940, 1.2321, 0.2720, 0.4900, 0.5170, 0.7405, 2.8469,\n",
      "        0.7417, 1.3411, 0.3342, 0.6146, 2.2661, 0.9069, 0.2164, 1.4026, 0.5924,\n",
      "        1.1290, 2.2461, 1.0119, 1.8074, 0.4089, 0.7596, 1.1421, 0.7995, 1.0173,\n",
      "        0.1762, 0.3341, 0.8922, 0.3811, 1.4408, 1.6959, 1.0275, 0.7085, 1.1235,\n",
      "        2.5238, 0.6195, 2.4457, 2.2519, 0.8803, 0.9689, 0.8381, 1.2582, 0.4718,\n",
      "        0.7899, 0.5344, 0.1461, 0.1896, 1.0910, 0.1776, 0.8948, 0.5105, 1.3521,\n",
      "        0.8032, 0.5408, 1.0899, 0.1055, 0.8035, 1.4980, 0.8763, 1.5059, 1.8131,\n",
      "        1.0332, 1.1156, 0.8584, 0.7354, 0.7595, 2.0267, 0.6596, 1.0461, 0.2736,\n",
      "        0.5239, 1.1279, 0.5160, 1.1247, 1.1928, 0.8950, 0.7370, 1.0499, 0.5336,\n",
      "        2.0053, 2.1296, 1.0100, 1.1461, 1.2251, 0.5089, 0.3143, 0.6457, 0.5504,\n",
      "        1.0250, 0.8520, 1.1407, 0.2273, 0.8155, 0.4813], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.6946,  0.0452,  0.4529, -1.3745,  0.1784,  0.2426, -0.6779, -0.4562,\n",
      "        -0.3086, -0.7287,  0.4647,  0.8209,  0.1045,  1.6595, -0.1256, -0.0534,\n",
      "         0.7506, -0.5519,  0.1959, -1.7862,  0.3485, -0.8884, -0.0507, -0.4510,\n",
      "         1.0697, -0.0287,  0.7741,  0.1209, -0.4312,  0.3744,  0.1938,  0.2453,\n",
      "         0.0084, -0.5625, -0.0272, -0.3610,  0.3499,  0.9939, -0.0104,  0.3324,\n",
      "        -0.8399, -0.6590,  0.3404,  0.1945, -0.2243,  0.0380,  0.1385,  0.2355,\n",
      "         0.3601,  0.1532,  0.5565,  0.7123,  0.4758, -0.8345, -0.5903,  0.6124,\n",
      "         0.8965,  0.0701, -0.0068,  0.4351,  0.3502,  0.4079, -0.0797, -0.5825,\n",
      "         0.4218, -1.4110,  0.2448,  0.5459, -1.0294,  0.1109, -0.0073,  0.0579,\n",
      "        -0.1359,  0.0398,  0.5006,  0.4019, -0.0129,  0.5061,  0.0979, -0.3192,\n",
      "        -0.2281,  0.2404, -0.1150, -0.9787,  0.6080, -0.6550,  0.7746,  0.4064,\n",
      "         0.5604,  0.2002,  0.4233,  0.0315, -0.4282, -0.1843,  0.1786,  0.4474],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2436]],\n",
      "\n",
      "         [[ 0.3127]],\n",
      "\n",
      "         [[ 0.3411]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4770]],\n",
      "\n",
      "         [[-0.3863]],\n",
      "\n",
      "         [[ 0.0541]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1034]],\n",
      "\n",
      "         [[-0.9191]],\n",
      "\n",
      "         [[-0.0082]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3636]],\n",
      "\n",
      "         [[ 0.2759]],\n",
      "\n",
      "         [[ 0.2375]]],\n",
      "\n",
      "\n",
      "        [[[-0.0170]],\n",
      "\n",
      "         [[ 0.5364]],\n",
      "\n",
      "         [[-0.1521]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3075]],\n",
      "\n",
      "         [[-0.0320]],\n",
      "\n",
      "         [[ 0.5376]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3808]],\n",
      "\n",
      "         [[-0.1504]],\n",
      "\n",
      "         [[ 0.2408]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2173]],\n",
      "\n",
      "         [[ 0.1134]],\n",
      "\n",
      "         [[ 0.1881]]],\n",
      "\n",
      "\n",
      "        [[[-0.0761]],\n",
      "\n",
      "         [[ 0.0989]],\n",
      "\n",
      "         [[ 0.0138]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4510]],\n",
      "\n",
      "         [[ 0.2004]],\n",
      "\n",
      "         [[ 0.3663]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0039]],\n",
      "\n",
      "         [[ 0.3562]],\n",
      "\n",
      "         [[ 0.0354]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4801]],\n",
      "\n",
      "         [[-0.0378]],\n",
      "\n",
      "         [[-0.1372]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.6237,  0.9461,  1.0857,  1.1320,  0.6382,  0.5495,  0.4097,  0.9460,\n",
      "         0.6179,  0.3064,  1.3222,  1.0259,  0.8896,  1.3533,  1.7396,  1.0904,\n",
      "         0.3961,  0.3290,  0.7242,  1.0533,  1.2129,  0.5853,  0.9079,  0.9979,\n",
      "         1.5252,  0.7304,  0.4606,  0.8786,  1.2275,  1.2962,  0.3728,  1.1745,\n",
      "         0.7361, -0.0102,  0.5219,  1.1157,  1.0069,  0.8437,  1.0016,  1.0239,\n",
      "         0.5175,  1.9376,  0.0653,  0.5684,  1.1737,  1.1022,  1.4451,  1.9483,\n",
      "         1.0452,  1.3161,  1.4327,  0.7892,  1.6576,  0.8658,  0.9269,  0.9080,\n",
      "         1.0734,  1.3152,  1.0334,  1.0093,  0.5712,  0.0876,  0.9739,  0.8059,\n",
      "         0.9559,  1.5469,  0.9042,  1.0614,  1.1791,  0.4440,  0.7474,  0.6546,\n",
      "         0.1711,  1.4795,  1.0978,  0.4589,  1.5270,  1.7623,  0.7755,  1.0978,\n",
      "         0.6627,  1.3616,  1.4366,  0.8633,  0.3684,  0.9588,  0.0364,  1.7206,\n",
      "         0.3212,  1.0183,  0.8626,  1.1989,  0.7238,  0.8149,  1.5349,  1.6579,\n",
      "         0.7921,  1.3316,  1.9956,  1.3021,  1.9036,  1.7489,  0.7645,  0.4313,\n",
      "         1.0125,  1.0985,  0.3134,  1.3385,  1.3931,  0.6256,  1.0017,  0.9311,\n",
      "         0.6083,  0.7690,  0.5961,  0.5682,  1.8230,  0.7996,  1.1125,  1.0899,\n",
      "         0.4135,  1.5732,  0.2223,  0.7499,  1.3429,  1.2859,  0.7888,  1.1588,\n",
      "         1.2553,  1.8905,  0.6609,  0.4272,  0.9728,  0.3800,  1.8952,  1.0500,\n",
      "         0.7993,  1.1577,  1.1286,  0.9234,  0.6686,  0.4739,  0.2556,  1.5279,\n",
      "         1.5909,  0.5677,  0.4398,  0.7524,  0.8169,  1.1759,  1.0081,  0.3573,\n",
      "         0.5176,  0.7374,  1.1901,  0.5925,  1.2777,  1.1528,  0.7127,  1.7708,\n",
      "         1.5626,  0.8631,  0.8831,  1.9924,  1.6666,  0.9350,  1.2662,  0.9376,\n",
      "         0.7780,  0.5557,  0.5501,  1.8743,  0.3265,  0.1329,  0.3982,  1.7808,\n",
      "         1.8434,  0.7993,  1.9651,  1.2712,  0.6148,  1.1459,  0.1795,  1.0913,\n",
      "         0.8518,  0.3484,  1.4161,  0.9622,  1.2601,  1.2561,  1.1781,  0.6423,\n",
      "         0.5619,  1.4161,  2.0706,  0.6966,  0.8958,  0.7989,  0.9372,  1.6332,\n",
      "         2.0367,  0.9674,  0.9630,  0.3561,  0.0875,  0.5936,  1.6324,  1.1332,\n",
      "         2.1344,  1.8987,  1.1550,  0.6532,  0.8138,  0.6019,  1.6599,  0.9591,\n",
      "         1.3035,  1.0659,  0.7671,  0.7970,  1.1880,  0.5906,  0.9551, -0.1159,\n",
      "         0.6900,  0.8716,  1.0788,  0.6400,  0.9683,  0.9654,  1.3463,  0.3816,\n",
      "         0.3893,  1.0768,  0.7586,  1.3548,  0.7393,  1.3176,  0.7513,  1.7394,\n",
      "         1.2882,  0.3736,  0.6616,  0.9666,  0.6770,  1.7025,  1.1097,  1.9104,\n",
      "        -0.1011,  1.1086,  0.0910,  0.7769,  1.0373,  0.8817,  0.8939,  1.1468,\n",
      "         0.9636,  1.5526,  0.9511,  1.2995,  0.5473,  0.2997,  0.3167,  1.5191,\n",
      "         0.5466,  0.7510,  0.8228,  1.8017,  1.6523,  1.1077,  0.7092,  0.6718,\n",
      "         1.4752,  1.1371,  0.2007,  0.9751,  0.0969,  1.1432,  0.7694,  0.9547,\n",
      "         1.7603,  0.6568,  1.1078,  1.1972,  1.0538,  1.4719,  1.1752,  0.1924,\n",
      "         0.9868,  0.9567,  0.9701,  1.2201,  1.1638,  2.0600,  0.6264,  0.0618,\n",
      "         1.1396,  0.5421,  0.9887,  1.3839,  1.4063,  1.3943,  0.5554,  1.5384,\n",
      "         0.3435,  1.4024,  2.9610,  0.4415,  1.8671,  0.6960,  0.4660,  0.3421,\n",
      "         2.1535,  1.1502,  1.0614,  1.3335,  0.3732,  0.4195,  0.4318,  0.8389,\n",
      "         1.2264,  0.7924,  0.9041,  2.1932,  0.1399,  2.1019,  1.2720,  1.2310,\n",
      "         1.3323,  1.3723,  1.1279,  1.0677,  1.1452,  1.2897,  1.2033,  0.4807,\n",
      "         1.7537,  0.6122,  0.7207,  1.3453,  1.8962,  1.1279,  0.7885,  1.5024,\n",
      "         1.7383,  1.1644,  1.2134,  1.1989,  0.3190,  1.6430,  1.2129,  1.4074,\n",
      "         1.0621,  1.0127,  1.3496,  0.6725,  0.5181,  1.2748,  1.5774,  1.3888,\n",
      "         0.8387,  0.5468,  0.4974,  1.1378,  1.2897,  0.5046,  0.2129,  0.6611,\n",
      "         1.1186,  0.4995,  0.6912,  0.6853,  1.0977,  0.4906,  1.5590,  0.9753,\n",
      "         0.2922,  0.4699,  0.5131,  1.6629,  0.5782,  1.2588,  0.2330,  1.2331,\n",
      "         0.8126,  1.4959,  1.1386,  0.8176,  0.4421,  1.0037,  0.8863,  1.2706,\n",
      "         0.5680,  2.8108,  0.3109,  0.7360,  0.4870,  0.5201,  1.4678,  1.0625,\n",
      "         0.8912,  0.8741,  0.8969,  0.7264,  0.8667, -0.2821,  0.2309,  1.2902,\n",
      "         1.4338,  0.6319,  0.2424,  0.9771,  0.9727,  2.1857,  1.1307,  0.2283,\n",
      "         1.9260,  1.4240,  1.3288,  0.5075,  1.3204,  0.9991,  1.3651,  1.6957,\n",
      "         0.9519,  2.0116,  1.5462,  0.7137,  0.6992,  1.7800,  0.6894,  1.5080,\n",
      "         0.7001,  1.7142,  1.2250,  1.0641,  0.2348,  2.5039,  0.8320,  1.0524,\n",
      "         1.0590,  0.5706,  0.9609,  0.3817,  0.4799,  0.4870,  0.9550, -0.3000,\n",
      "         0.9259,  1.2538,  1.3154,  0.7006,  1.6327,  2.0149,  0.9594,  1.5636,\n",
      "         1.1499,  0.5084,  1.4606,  0.0102,  1.2111,  0.4193,  1.3139,  1.3213,\n",
      "         0.6683,  1.2232,  1.4093,  1.2230,  1.4915,  1.3376,  1.3206,  0.5443,\n",
      "         0.7085,  1.6884,  0.3075,  1.0625,  1.2871,  1.2160,  0.7750,  0.9676,\n",
      "         0.5002,  1.7435,  1.3536,  0.9979,  0.4855,  1.0576,  2.1974,  0.6374,\n",
      "         1.3052,  0.6748,  0.6063,  0.7431,  0.7329,  1.2082,  0.8020,  1.4121,\n",
      "         0.8967,  0.3065,  0.3399,  1.7512,  1.2260,  0.4450,  0.9857,  0.5061,\n",
      "         1.2235,  1.2168,  1.6600,  0.9074,  0.9829,  1.1598,  0.9307,  0.8652,\n",
      "         1.3411,  0.1967,  1.3561,  1.1434,  0.9780,  0.8287,  0.8021,  1.5371,\n",
      "         0.5451,  0.3514,  0.1936,  0.5808,  0.6043,  1.2906,  1.3778,  1.0581,\n",
      "         0.8485,  1.6208,  1.2355,  0.5579,  1.3342,  0.2879,  0.3771,  0.7550,\n",
      "         0.3484,  0.8706, -0.0394,  0.9517,  0.5833,  0.9627,  1.1947,  1.8572,\n",
      "         0.2810,  1.3311,  0.4369,  1.2701,  1.1779,  1.0723,  1.1548,  1.6787,\n",
      "         1.1329,  1.8907,  0.5385,  1.1345,  0.4464,  1.6329,  0.9110,  0.8360,\n",
      "         1.2471,  1.6389,  1.1886,  0.7767,  0.5214,  0.2866,  1.0172,  0.6672,\n",
      "         0.4765,  0.7366,  0.5591,  1.5223,  0.1180,  1.0647,  1.4691,  1.0568],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-2.0164e-02, -6.4412e-01,  3.5090e-01, -1.5224e+00,  3.1416e-02,\n",
      "        -4.5863e-01,  2.8169e-01,  9.6954e-01, -6.2846e-01,  1.9086e-01,\n",
      "         2.0853e-03,  1.1302e-01, -9.0242e-01, -1.3793e+00, -1.0260e+00,\n",
      "         7.6413e-01, -1.0191e-01, -1.8102e-01,  1.0007e-01, -7.1610e-01,\n",
      "        -2.6443e-01,  3.8836e-01, -1.0728e+00,  3.6833e-01, -9.4356e-01,\n",
      "         5.0640e-03,  9.0559e-01, -2.4097e+00, -1.2741e+00,  7.6875e-01,\n",
      "         1.6140e-01, -1.0189e+00, -2.0815e-01,  6.0900e-01,  9.0777e-02,\n",
      "        -1.7299e+00,  1.8692e-01,  4.1167e-01, -2.0378e-01, -2.5040e-01,\n",
      "         8.7130e-01, -4.5247e-01,  2.9670e-01, -4.2202e-03, -8.4357e-01,\n",
      "        -1.6775e-01, -1.0791e+00, -1.3603e-01, -8.4986e-01, -8.5643e-01,\n",
      "        -2.0047e+00, -8.8138e-01,  5.0319e-01, -1.2145e+00, -7.6202e-01,\n",
      "        -4.5770e-01,  1.0465e+00, -3.6697e-01, -1.8175e-01,  4.7758e-01,\n",
      "        -6.2668e-01,  6.4430e-01,  6.2282e-01,  6.4335e-01, -7.5268e-02,\n",
      "         6.7012e-01, -8.7419e-01,  7.7752e-01, -1.7829e+00,  4.4601e-01,\n",
      "        -1.7106e+00,  1.1020e+00,  5.6004e-01, -2.6222e-01,  2.3127e-01,\n",
      "         8.8209e-01, -1.2547e-01, -4.4580e-02, -2.8206e-01, -1.6516e+00,\n",
      "         1.2207e+00,  7.5398e-02,  6.0794e-01, -3.6844e-01,  6.9360e-01,\n",
      "         1.0102e+00,  9.1557e-01, -5.4826e-01,  4.0868e-02, -3.8434e-01,\n",
      "        -1.1781e+00, -9.5716e-01, -6.5678e-02, -5.1112e-01,  1.6234e-01,\n",
      "        -6.8311e-01, -4.3289e-01, -5.5819e-01, -8.9450e-01, -7.2525e-01,\n",
      "        -3.5804e-01, -2.0260e+00, -1.7041e+00,  9.6496e-01, -8.0166e-01,\n",
      "         7.5418e-01,  9.3462e-02, -6.5071e-01,  6.3553e-01, -6.9240e-02,\n",
      "         5.7084e-01, -1.6105e+00,  1.1893e+00,  4.1121e-01,  4.5126e-02,\n",
      "         1.1524e+00, -1.4117e-01,  9.6874e-01, -6.7595e-01, -1.1085e+00,\n",
      "        -1.4567e-01, -1.2654e+00,  3.9394e-01, -1.8615e+00, -1.6525e-01,\n",
      "         1.0548e-01,  3.4721e-01,  6.6709e-01, -1.7724e+00, -5.6536e-01,\n",
      "         8.7618e-01, -2.8388e-01, -1.6001e+00, -9.0987e-02, -4.1334e-01,\n",
      "        -7.4098e-01, -1.0049e+00,  1.2961e+00, -1.6138e+00,  3.7553e-01,\n",
      "        -1.7258e-01,  1.9363e-02,  1.9049e-01, -9.2572e-01,  6.5711e-01,\n",
      "         1.9935e-01,  7.8767e-02, -1.2149e+00,  1.2575e-02,  5.6457e-01,\n",
      "         7.5018e-01, -7.0470e-02, -1.9875e-02,  2.3650e-01, -2.3999e-01,\n",
      "        -2.3803e+00,  3.3050e-01, -2.3992e-01,  7.7165e-02, -1.4461e+00,\n",
      "         1.1973e+00, -1.6530e-01,  1.0714e+00,  3.2261e-01, -2.6261e-01,\n",
      "        -3.7580e-01, -9.3188e-01,  5.2378e-01, -8.5260e-01, -1.1053e-02,\n",
      "         7.7090e-02, -5.4284e-01,  1.1811e+00, -5.2332e-01, -6.8569e-03,\n",
      "        -1.0482e+00, -4.0738e-01, -1.5226e-01, -1.7758e-01,  2.8297e-01,\n",
      "         1.1390e-01, -1.4696e+00,  3.1350e-01, -8.7914e-01,  8.3166e-02,\n",
      "        -2.1603e-01, -1.2196e-01,  3.3875e-01, -1.1562e+00, -8.0033e-01,\n",
      "        -7.6911e-01,  1.3101e+00,  2.9724e-01,  1.7457e+00,  1.3986e-02,\n",
      "        -2.7651e-02,  7.8742e-01,  1.2390e-01,  5.3819e-01, -8.1468e-01,\n",
      "        -1.9735e+00, -1.5647e-01, -1.3953e+00,  5.1542e-01,  3.2473e-01,\n",
      "        -5.8469e-02,  8.4155e-01,  3.6696e-01, -2.5334e-01, -8.9201e-01,\n",
      "        -5.4762e-01, -1.6214e-01,  2.4814e-01,  5.6461e-01,  7.0028e-01,\n",
      "        -9.8400e-01, -8.6850e-01, -7.5747e-01,  1.5174e+00, -1.0441e-01,\n",
      "         5.9175e-01,  9.6293e-01, -1.3311e+00, -5.5824e-02, -7.6822e-02,\n",
      "         1.0580e+00, -1.8648e-01, -6.2755e-02,  5.6273e-01, -6.0930e-01,\n",
      "        -8.3569e-01, -5.4713e-01,  4.6692e-01,  3.1370e-02,  1.3441e+00,\n",
      "        -1.8368e+00, -9.5342e-01, -2.4940e-01, -3.9014e-01, -1.7825e+00,\n",
      "        -1.2422e+00,  1.0634e-01,  1.0851e+00, -1.7532e+00,  7.0933e-01,\n",
      "         4.2019e-01,  4.2479e-01, -8.4132e-01, -9.0308e-01,  2.1744e-01,\n",
      "         1.4943e-02,  4.3959e-01, -8.8514e-01,  5.1970e-01,  3.2704e-01,\n",
      "         3.6591e-01,  5.2579e-01, -5.8510e-01,  1.1499e+00, -4.9985e-01,\n",
      "         7.6242e-01, -2.2695e-01,  3.9136e-01, -1.8371e+00, -3.3336e-01,\n",
      "         1.3973e+00,  5.1716e-01, -1.7215e-01, -7.5408e-01,  1.3991e+00,\n",
      "        -1.3700e-01,  4.2302e-01, -1.1149e+00, -1.4372e+00,  2.2023e-01,\n",
      "        -8.4602e-01,  9.9736e-01,  5.8460e-01,  6.9543e-01,  8.9118e-01,\n",
      "         2.3685e-01,  4.2028e-01,  2.3362e-01,  7.6851e-01, -1.1531e+00,\n",
      "         3.9927e-01, -1.4620e+00,  1.0275e+00,  2.6692e-01, -4.3415e-01,\n",
      "        -1.1438e+00, -1.1084e+00, -5.0790e-02,  6.1593e-01,  1.0970e+00,\n",
      "         9.8415e-02, -9.8011e-01,  7.5169e-01,  1.9259e-01,  7.0850e-01,\n",
      "         2.7020e-01, -1.3480e+00,  4.3643e-01, -5.5841e-01, -1.1758e+00,\n",
      "         4.9205e-01, -2.7273e-01,  3.7501e-02,  1.2694e+00,  7.9200e-01,\n",
      "         1.3829e+00,  5.4450e-01, -6.5849e-01, -1.6045e+00,  5.7200e-01,\n",
      "        -1.1408e-01,  8.7704e-02,  5.8597e-01, -3.8941e-01,  1.1950e+00,\n",
      "        -6.7078e-01, -4.7770e-01,  5.9601e-01,  1.1500e-01,  5.9082e-01,\n",
      "         2.1991e-01, -1.1800e+00, -1.5490e+00, -5.8413e-01, -1.9982e-01,\n",
      "        -1.5243e+00,  6.1363e-01, -8.1905e-01, -5.4722e-01,  2.2554e-01,\n",
      "        -4.8878e-01,  1.6961e-01,  6.0083e-01,  1.1042e+00, -1.5347e-01,\n",
      "         2.8520e-01, -3.0966e+00,  9.1705e-01, -1.8061e-01, -1.0361e+00,\n",
      "         4.0711e-01, -1.0977e+00,  5.9520e-02,  1.2589e+00, -1.1286e+00,\n",
      "         3.2329e-01,  2.6349e-01,  2.7968e-01, -7.8965e-01, -1.2238e+00,\n",
      "         4.6406e-01, -5.4362e-01, -1.7983e-02, -2.2513e-02,  6.8054e-01,\n",
      "        -2.1576e-01,  7.2598e-01, -1.5887e+00, -1.4366e+00, -3.0708e-01,\n",
      "         1.9694e-01,  2.3581e-01,  1.0787e+00, -1.0165e+00, -4.2847e-02,\n",
      "        -1.4509e+00,  6.1710e-01,  3.3023e-01, -6.9384e-03,  1.7044e+00,\n",
      "        -2.3997e+00, -3.2408e-01, -4.1427e-01,  7.9811e-01, -4.5790e-01,\n",
      "         3.4343e-01, -6.3581e-01,  9.4941e-01, -5.2248e-01, -1.6901e+00,\n",
      "        -1.0498e-01, -1.9269e+00,  1.1343e+00,  1.6963e+00,  1.1388e-01,\n",
      "         1.1013e+00, -2.1038e-01, -1.1921e+00, -2.0860e+00, -5.9549e-01,\n",
      "        -1.9333e+00,  7.4012e-01, -4.6148e-01, -3.4905e-01, -1.6288e+00,\n",
      "        -1.1985e+00,  7.3150e-01,  2.9400e-01, -1.5052e+00,  9.0009e-01,\n",
      "        -4.3873e-01, -7.2423e-01, -7.4594e-01,  5.8596e-01,  7.0596e-01,\n",
      "         9.1645e-02, -8.8931e-02, -9.0512e-01, -6.2361e-01, -1.2530e+00,\n",
      "         2.4567e-01, -4.1156e-01, -1.8022e+00,  8.4910e-01, -2.1328e-02,\n",
      "        -1.6995e-01,  1.0863e+00, -4.1121e+00,  1.1384e+00, -1.9605e-01,\n",
      "        -8.0023e-02, -1.3012e+00,  1.2729e+00,  3.3349e-01, -2.6566e-01,\n",
      "        -1.5821e-01,  2.6166e-01,  3.1815e-01, -3.9594e-01, -8.7505e-01,\n",
      "         7.5596e-01,  1.8002e-01, -1.9997e+00,  2.1868e-01,  9.7693e-02,\n",
      "         8.1380e-01,  7.4254e-01, -1.7020e+00,  2.4350e-01, -4.3609e-01,\n",
      "         3.6828e-01, -6.6665e-01,  9.0927e-01,  6.2274e-01,  7.2335e-01,\n",
      "        -2.1381e+00, -3.0666e-01, -2.5809e+00, -1.3947e+00,  9.8939e-01,\n",
      "        -1.0058e+00, -3.9674e-01,  2.1876e-01,  2.3791e-01, -3.2077e-01,\n",
      "        -1.0968e+00,  9.1756e-04, -5.3992e-01, -1.4122e+00,  2.0864e-01,\n",
      "        -3.4843e-02,  3.4151e-01, -1.2615e+00,  1.6213e+00,  8.5098e-02,\n",
      "         4.8313e-01,  7.6248e-01,  3.0128e-01, -5.6521e-01,  2.8466e-01,\n",
      "        -1.0140e+00, -4.2539e-01, -7.4692e-01,  9.0039e-01, -2.8189e-01,\n",
      "         5.9318e-01, -1.3542e-01,  1.0596e+00, -2.0772e+00,  8.9302e-02,\n",
      "         2.7287e-01, -9.0029e-01,  6.0091e-01, -1.5906e-01,  1.1931e+00,\n",
      "         4.8208e-01, -8.8413e-01,  7.5224e-02, -5.9378e-01, -6.4816e-01,\n",
      "        -3.2258e-01, -8.4725e-01,  5.1963e-01,  1.2466e+00,  2.3107e-02,\n",
      "        -7.2892e-01,  9.2470e-01, -1.2522e+00, -3.2553e-01, -6.5739e-01,\n",
      "        -4.3170e-01,  2.5320e-01,  4.7047e-01, -8.7465e-01, -1.0761e+00,\n",
      "        -8.5618e-01,  4.2777e-01, -1.1584e+00, -4.3146e-01,  5.5063e-01,\n",
      "        -4.0077e-01, -1.0902e-01, -1.2102e+00,  2.7398e-01, -1.2198e+00,\n",
      "        -4.7772e-01,  8.3133e-01,  6.7222e-01,  4.1487e-01,  1.6787e+00,\n",
      "        -5.0727e-01, -8.9852e-01,  5.1684e-01, -4.1059e-01, -5.2257e-01,\n",
      "        -5.8858e-01,  7.6983e-01,  1.0513e+00,  4.0608e-01,  8.5108e-01,\n",
      "         7.8954e-01,  2.2907e-01,  5.3964e-01,  5.3846e-01, -1.5611e+00,\n",
      "         5.6665e-01,  1.8223e+00,  1.8676e-01, -3.7722e-01, -2.3818e-01,\n",
      "         1.2056e-01,  4.9188e-01, -1.9563e-01,  3.5633e-01,  1.1900e+00,\n",
      "         4.3428e-01, -7.6699e-01,  7.7248e-01, -2.6562e-01,  6.5104e-01,\n",
      "         4.4295e-01, -1.8177e-01, -1.8027e+00, -1.7021e+00,  1.1965e+00,\n",
      "        -4.6336e-02, -4.0628e-01, -4.0588e-01, -1.1916e+00, -1.7216e-01,\n",
      "        -2.1390e+00,  7.1304e-01, -3.4817e-01,  5.4549e-01, -1.1318e+00,\n",
      "         3.4855e-01, -1.8953e-01,  1.0740e-01, -1.7282e-01,  9.8305e-01,\n",
      "         8.1883e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0226, -0.2947, -0.0965],\n",
      "          [ 0.6894,  0.3525, -0.3286],\n",
      "          [ 0.3169,  0.3022,  0.0352]]],\n",
      "\n",
      "\n",
      "        [[[-0.0019,  0.1128,  0.1083],\n",
      "          [-0.0660,  0.6915, -0.0468],\n",
      "          [ 0.2046,  0.8195,  0.0859]]],\n",
      "\n",
      "\n",
      "        [[[-0.7850, -0.2476, -0.0560],\n",
      "          [ 0.0462,  0.3670,  0.1825],\n",
      "          [-0.6027, -0.4014, -0.1922]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.5865, -0.2016, -0.1971],\n",
      "          [ 0.0833, -0.6249,  0.0248],\n",
      "          [ 0.2090,  0.0152,  0.5037]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0289,  0.4861,  0.1105],\n",
      "          [-0.3059, -0.4792, -0.0094],\n",
      "          [-0.5032, -0.3389, -0.2058]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3859,  0.4009,  0.3547],\n",
      "          [ 0.2149,  0.5366, -0.2176],\n",
      "          [-0.0184, -0.0892, -0.3896]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.1150e+00, 1.8945e+00, 6.0295e-01, 1.0075e+00, 1.8514e+00, 1.8928e+00,\n",
      "        1.9713e+00, 1.7173e+00, 1.5424e+00, 1.6800e-01, 1.1283e+00, 1.4330e+00,\n",
      "        4.4670e-01, 1.5276e+00, 3.6525e+00, 2.2060e+00, 1.6488e+00, 1.9062e+00,\n",
      "        1.8424e+00, 1.4483e+00, 8.7934e-01, 1.3518e+00, 9.2245e-01, 1.8037e+00,\n",
      "        1.8328e+00, 1.9654e+00, 1.0732e+00, 1.0453e+00, 2.2413e+00, 1.6972e+00,\n",
      "        1.4809e+00, 2.0730e+00, 1.8265e+00, 2.0983e+00, 1.5095e+00, 1.2086e+00,\n",
      "        1.4047e+00, 1.3872e+00, 1.7144e+00, 1.6531e+00, 1.6950e+00, 1.4859e+00,\n",
      "        1.5078e+00, 1.3023e+00, 1.4806e+00, 1.6133e+00, 1.1640e+00, 1.6148e+00,\n",
      "        1.2106e+00, 1.0624e+00, 2.2287e+00, 1.6106e+00, 1.1260e+00, 1.4334e+00,\n",
      "        1.6401e+00, 1.5714e+00, 2.9419e+00, 1.5064e+00, 2.1311e+00, 1.3439e+00,\n",
      "        1.5247e+00, 1.2340e+00, 1.4876e+00, 1.5561e+00, 1.0449e+00, 2.5595e+00,\n",
      "        1.0855e+00, 1.7677e+00, 1.5202e+00, 1.8717e+00, 3.1294e-01, 1.1532e+00,\n",
      "        1.6163e+00, 2.2375e-01, 1.3864e+00, 2.1706e+00, 1.1605e+00, 1.4108e+00,\n",
      "        1.3577e+00, 7.1420e-01, 2.3754e+00, 1.3453e+00, 1.7370e+00, 1.3085e+00,\n",
      "        1.3094e+00, 2.3454e+00, 1.1456e+00, 8.7455e-01, 1.9516e+00, 5.2603e-01,\n",
      "        4.4974e-01, 2.5642e+00, 1.3693e+00, 9.8028e-01, 8.4363e-01, 1.1259e+00,\n",
      "        1.6065e+00, 2.0272e+00, 5.5615e-01, 1.0841e+00, 2.5949e+00, 1.7904e+00,\n",
      "        8.7980e-01, 1.4324e+00, 1.6696e+00, 5.4507e-01, 1.7192e+00, 1.7317e+00,\n",
      "        1.7520e+00, 2.4958e+00, 6.0214e-01, 2.7077e+00, 1.6177e+00, 2.1232e+00,\n",
      "        1.8778e+00, 1.9273e+00, 7.1904e-01, 1.5114e+00, 6.1679e-01, 1.6547e+00,\n",
      "        1.6183e+00, 2.8672e+00, 1.2265e+00, 6.1665e-01, 1.3792e+00, 8.5297e-01,\n",
      "        1.4075e+00, 1.6401e+00, 9.0840e-01, 8.4563e-02, 8.3645e-01, 1.8004e+00,\n",
      "        7.9442e-01, 1.9554e+00, 1.2104e+00, 1.0385e+00, 1.7599e+00, 1.9103e+00,\n",
      "        1.1721e+00, 1.9024e+00, 1.7480e+00, 2.0596e+00, 1.7598e+00, 1.5668e+00,\n",
      "        2.1044e+00, 2.3135e+00, 1.6100e+00, 7.2461e-01, 2.8404e+00, 1.4072e+00,\n",
      "        1.2821e+00, 1.7217e+00, 1.8016e+00, 1.8514e+00, 1.0323e+00, 1.7915e+00,\n",
      "        1.9494e+00, 1.1502e+00, 1.9348e+00, 3.2547e+00, 2.1494e+00, 1.3909e+00,\n",
      "        1.9365e+00, 2.1899e+00, 7.1308e-01, 2.5149e+00, 5.5201e-01, 1.6011e+00,\n",
      "        2.1978e+00, 1.5390e+00, 1.9374e+00, 2.2256e+00, 1.9842e+00, 1.5168e+00,\n",
      "        1.8789e+00, 2.6336e+00, 1.8586e+00, 1.9745e+00, 1.3405e+00, 1.3328e+00,\n",
      "        8.3811e-01, 2.5707e-01, 1.6056e+00, 1.7152e+00, 1.7299e+00, 1.4213e+00,\n",
      "        2.1475e+00, 1.3422e+00, 1.6245e+00, 2.2015e+00, 1.1745e+00, 1.5192e+00,\n",
      "        1.6949e+00, 2.1906e+00, 2.8831e+00, 7.8233e-01, 1.4861e+00, 1.6344e+00,\n",
      "        1.5636e+00, 1.4222e+00, 4.2206e+00, 1.7682e+00, 2.1269e+00, 1.4954e+00,\n",
      "        1.6885e+00, 1.3044e+00, 2.1286e+00, 3.0069e+00, 1.7573e+00, 1.9091e+00,\n",
      "        1.7090e+00, 1.7351e+00, 1.9018e+00, 2.4129e+00, 1.5447e+00, 1.1380e+00,\n",
      "        1.1452e+00, 1.7928e+00, 1.6919e+00, 1.1702e+00, 7.3209e-01, 1.5670e+00,\n",
      "        1.2409e+00, 3.0077e+00, 1.9218e+00, 1.4694e+00, 1.5232e+00, 1.5147e+00,\n",
      "        1.3217e+00, 1.5650e+00, 2.1453e+00, 1.3354e+00, 1.0557e+00, 1.7459e+00,\n",
      "        1.4368e+00, 1.3209e+00, 1.6699e+00, 9.8773e-01, 1.3642e+00, 2.5147e+00,\n",
      "        1.4667e+00, 1.8966e+00, 9.5974e-01, 1.1277e+00, 2.1399e+00, 1.6469e+00,\n",
      "        1.3161e+00, 2.0969e+00, 8.2037e-01, 1.6723e+00, 1.6099e+00, 2.1141e+00,\n",
      "        1.4006e+00, 2.3823e+00, 1.7565e+00, 2.1372e+00, 2.8821e+00, 1.7383e+00,\n",
      "        2.2533e+00, 1.2319e+00, 2.2983e+00, 1.8312e+00, 1.7150e+00, 1.7131e+00,\n",
      "        1.3649e+00, 1.8708e+00, 1.8039e+00, 1.2061e+00, 1.5309e+00, 1.7521e+00,\n",
      "        1.8613e+00, 1.4395e+00, 3.2610e+00, 3.7775e-01, 2.5228e+00, 6.4841e-01,\n",
      "        1.2732e+00, 6.1657e-01, 1.7320e+00, 1.7160e+00, 1.5112e+00, 1.4414e+00,\n",
      "        2.0659e+00, 1.8791e+00, 1.1718e+00, 1.5673e+00, 1.2058e+00, 4.2267e-01,\n",
      "        1.9664e+00, 2.1304e+00, 7.0311e-01, 1.2008e+00, 6.0933e-01, 2.9804e+00,\n",
      "        1.5008e+00, 1.7140e+00, 1.5683e+00, 1.5724e+00, 1.3302e+00, 1.8466e+00,\n",
      "        9.8122e-01, 1.9158e+00, 1.4411e+00, 7.6305e-01, 1.4626e+00, 1.1204e+00,\n",
      "        2.5975e+00, 1.8789e+00, 1.7888e+00, 1.2705e+00, 1.7882e+00, 1.5056e+00,\n",
      "        2.6527e+00, 6.7444e-01, 1.5443e+00, 9.7372e-01, 2.2097e+00, 1.9963e+00,\n",
      "        1.4558e+00, 1.4626e+00, 1.4021e+00, 1.9965e+00, 1.5451e+00, 1.4709e+00,\n",
      "        6.1165e-01, 3.3064e+00, 1.1236e+00, 2.9040e+00, 1.8668e+00, 1.6740e+00,\n",
      "        1.7068e+00, 2.0089e+00, 2.2738e+00, 5.9493e-01, 1.2942e+00, 1.1934e+00,\n",
      "        1.5921e+00, 2.1370e+00, 1.8502e+00, 1.1658e+00, 1.1633e+00, 1.1819e+00,\n",
      "        1.6381e+00, 2.0099e+00, 3.3261e+00, 2.2751e+00, 2.3372e+00, 8.5643e-01,\n",
      "        1.8048e+00, 4.2153e+00, 1.3587e+00, 1.6646e+00, 1.4964e+00, 1.1382e+00,\n",
      "        1.4347e+00, 1.8333e+00, 1.5336e+00, 2.0135e+00, 1.2357e+00, 1.2527e+00,\n",
      "        1.7908e+00, 1.7244e+00, 1.3011e+00, 2.2542e+00, 1.1333e+00, 1.6775e+00,\n",
      "        1.9509e+00, 1.7360e+00, 1.0638e+00, 1.3670e+00, 1.5914e+00, 1.9265e+00,\n",
      "        8.2136e-01, 1.6640e+00, 2.7882e+00, 9.7231e-01, 1.4828e+00, 1.2049e+00,\n",
      "        9.6982e-01, 5.0762e-01, 2.3456e+00, 1.8777e+00, 2.0172e+00, 9.6725e-01,\n",
      "        9.9185e-01, 1.3004e+00, 1.1478e+00, 2.7534e+00, 1.6842e+00, 1.4010e+00,\n",
      "        1.6364e+00, 2.2590e+00, 1.1078e+00, 4.3665e+00, 1.0622e+00, 9.5616e-01,\n",
      "        1.9090e+00, 1.0491e+00, 6.6882e-01, 8.1859e-01, 1.2529e+00, 1.8365e+00,\n",
      "        8.3599e-01, 9.5998e-01, 2.0218e+00, 9.5411e-01, 8.6514e-01, 4.7650e-01,\n",
      "        2.6638e-03, 1.8596e+00, 1.7685e+00, 1.5781e+00, 2.0304e+00, 2.1443e+00,\n",
      "        2.0785e+00, 1.7799e+00, 1.6431e+00, 1.2232e+00, 1.4187e+00, 1.7196e+00,\n",
      "        1.0604e+00, 1.9899e+00, 3.7412e+00, 1.5661e+00, 1.8005e+00, 2.0437e+00,\n",
      "        2.6464e+00, 2.7644e+00, 8.3909e-01, 1.3998e+00, 1.9727e+00, 1.2871e+00,\n",
      "        2.1792e+00, 2.2754e+00, 1.5346e+00, 1.0970e+00, 1.9802e+00, 5.3169e+00,\n",
      "        1.3103e+00, 8.5559e-01, 1.3934e+00, 1.7604e+00, 1.0236e+00, 1.7512e+00,\n",
      "        2.9800e-01, 1.7234e+00, 1.4207e+00, 1.4878e+00, 1.9382e+00, 1.4799e+00,\n",
      "        2.5194e+00, 1.3200e+00, 2.4774e+00, 1.0090e+00, 1.6581e+00, 3.5289e-01,\n",
      "        9.6135e-01, 1.3458e+00, 9.7430e-01, 1.5892e+00, 1.1948e+00, 1.1953e+00,\n",
      "        9.0710e-01, 1.7148e+00, 1.8570e+00, 8.8063e-01, 2.3407e+00, 1.6189e+00,\n",
      "        2.2193e+00, 7.5924e-01, 1.6699e+00, 1.4369e+00, 2.0218e+00, 1.2251e+00,\n",
      "        2.3804e+00, 2.0765e+00, 1.7685e+00, 1.4072e+00, 2.0247e+00, 1.4092e+00,\n",
      "        1.8548e+00, 1.5187e+00, 1.8627e+00, 9.4457e-01, 1.9152e+00, 1.1994e+00,\n",
      "        3.2056e+00, 1.3741e+00, 1.6448e+00, 1.5348e+00, 2.0328e+00, 1.3137e+00,\n",
      "        1.2771e+00, 7.9769e-01, 1.1139e+00, 1.4059e+00, 1.6151e+00, 1.5641e+00,\n",
      "        1.5726e+00, 1.6477e+00, 1.9620e+00, 1.5180e+00, 9.5518e-01, 1.8952e+00,\n",
      "        1.7334e+00, 1.0803e+00, 5.3854e-01, 1.6225e+00, 1.1958e+00, 1.3002e+00,\n",
      "        1.4016e+00, 2.1367e+00, 9.8396e-01, 1.2099e+00, 1.1764e+00, 1.3091e+00,\n",
      "        2.2420e+00, 7.1546e-01, 1.0949e+00, 5.6192e-01, 2.0339e+00, 1.5362e+00,\n",
      "        9.4363e-01, 1.5307e+00, 2.0451e+00, 1.1553e+00, 1.5089e+00, 8.2509e-01,\n",
      "        9.9008e-01, 1.8042e+00, 1.4730e+00, 1.4156e+00, 2.0447e+00, 1.7901e+00,\n",
      "        1.2861e+00, 3.7533e-01, 1.0521e+00, 1.8499e+00, 1.5587e+00, 8.3214e-01,\n",
      "        1.5811e+00, 2.7332e+00, 8.5940e-01, 1.1048e+00, 1.8810e+00, 1.4175e+00,\n",
      "        1.5388e+00, 9.8866e-01, 1.2088e+00, 2.2445e+00, 1.3346e+00, 5.4596e-02,\n",
      "        4.9601e-01, 1.5548e+00, 1.9376e+00, 9.3537e-01, 1.3989e+00, 3.4194e+00,\n",
      "        2.1705e+00, 2.0068e+00, 1.2298e+00, 1.3181e+00, 9.5503e-01, 1.1715e+00,\n",
      "        1.7980e+00, 2.6271e-01, 1.4301e+00, 1.4061e+00, 1.1850e+00, 9.6047e-01,\n",
      "        2.2081e+00, 1.4864e+00, 1.5910e+00, 1.4054e+00, 1.2726e+00, 1.3322e+00],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-2.3907e-01, -8.7932e-01, -2.1961e-01, -2.6050e-01, -1.5100e+00,\n",
      "        -8.1522e-01, -1.6039e+00, -1.7651e+00, -2.7779e+00, -2.6456e-02,\n",
      "        -9.0700e-01, -1.2915e+00, -2.4106e-01,  2.5026e-01,  6.9904e-01,\n",
      "        -8.5940e-01, -1.7610e+00, -8.5576e-01, -1.6513e+00, -1.0323e+00,\n",
      "        -2.8734e-01, -1.5126e+00, -1.3635e+00, -2.4291e+00, -5.8609e-01,\n",
      "        -1.5080e+00,  3.6534e-01,  3.7670e-01, -2.8316e+00, -1.0551e+00,\n",
      "        -1.2607e+00, -5.3462e-01, -2.1594e+00, -8.8074e-01, -1.3479e+00,\n",
      "        -1.4948e-01, -9.3529e-01, -8.2125e-01, -5.3224e-01, -2.8959e+00,\n",
      "        -1.6866e+00, -9.1305e-01, -1.6490e+00, -1.6347e+00, -3.3361e+00,\n",
      "        -1.0942e+00,  3.2487e-01, -7.8140e-01, -9.2338e-01,  2.3056e-02,\n",
      "        -4.7696e-02, -4.3261e-01, -1.8696e+00, -1.0130e+00, -4.4006e-01,\n",
      "        -9.4650e-01,  2.3708e-01, -2.3976e+00, -1.4981e+00, -8.8581e-01,\n",
      "        -3.0016e+00, -8.0464e-01, -1.8896e+00, -1.2730e+00, -2.7551e-01,\n",
      "        -7.8862e-01,  7.5251e-01, -1.5508e+00, -6.4855e-01, -1.4790e+00,\n",
      "        -1.3006e-01, -9.1998e-01, -1.5585e+00,  4.3490e-01, -8.0090e-01,\n",
      "        -9.2084e-01, -6.9218e-01, -1.2414e+00, -7.1191e-01,  3.0747e-01,\n",
      "        -1.9029e+00, -9.3129e-01, -4.1321e-01, -7.6058e-01, -1.0987e+00,\n",
      "        -3.9552e+00, -4.3101e-01, -7.1506e-01, -1.6182e+00, -1.9043e-01,\n",
      "        -6.4943e-02, -1.4554e+00, -2.5807e+00, -4.8281e-01, -1.1504e-01,\n",
      "         6.4891e-01, -3.1350e+00, -1.1151e+00, -9.7079e-02, -2.2340e-01,\n",
      "         3.1961e-01,  7.6377e-01,  2.1135e-02, -9.7131e-01, -1.1017e+00,\n",
      "        -8.0299e-02, -1.5568e+00,  1.0981e-01, -1.3397e+00, -9.7989e-01,\n",
      "        -1.7487e-01,  6.3331e-01, -1.1546e+00, -3.1497e-01, -1.4505e+00,\n",
      "        -1.8760e+00, -2.3837e-01, -1.5606e+00,  8.5928e-02, -1.1858e+00,\n",
      "        -1.4361e+00, -4.7949e-01, -1.5921e-01, -1.2643e-03, -2.4905e+00,\n",
      "        -5.4644e-01,  5.3967e-01, -1.3800e+00, -1.2344e-01,  8.4712e-02,\n",
      "        -3.1692e-01, -1.1378e+00, -5.4448e-01, -1.2838e+00, -3.8111e-01,\n",
      "        -8.9887e-01, -1.2881e+00, -1.6334e+00, -4.9248e-01, -1.6545e+00,\n",
      "        -1.2070e+00, -1.5886e+00, -1.4680e+00, -8.1971e-01, -1.3118e+00,\n",
      "        -2.2015e+00, -1.1024e+00, -3.2376e-01, -1.3697e+00, -1.3370e+00,\n",
      "         7.5361e-01, -1.6004e+00, -1.3207e+00, -1.0978e+00, -8.2863e-01,\n",
      "        -1.3954e+00, -8.8136e-01, -7.5819e-01, -1.5892e+00, -6.2948e-01,\n",
      "        -1.4995e+00, -1.4089e+00, -2.2707e+00, -7.2971e-01,  1.7259e-01,\n",
      "        -1.0042e+00,  8.4676e-02, -1.0229e+00, -8.6831e-01, -9.9532e-01,\n",
      "        -1.6369e+00, -1.0248e-02, -1.4878e+00, -2.6821e-01, -1.6811e+00,\n",
      "         3.8621e-01, -1.3555e+00, -9.7746e-01, -5.9628e-01, -6.2521e-01,\n",
      "        -4.2659e-01, -7.3930e-02, -1.4540e+00, -4.8412e-01, -1.3058e+00,\n",
      "        -5.3911e-01, -5.5126e-01, -1.0210e+00, -6.0465e-01, -8.9788e-01,\n",
      "        -5.9268e-01, -1.8634e+00, -1.8729e+00, -1.6249e+00, -2.7437e-01,\n",
      "         9.1006e-02, -1.4782e+00, -1.2393e+00, -1.1341e+00, -1.1817e-01,\n",
      "         7.8176e-01, -2.0773e+00, -1.6308e+00, -1.0158e+00, -1.8986e+00,\n",
      "         1.4098e+00, -1.0371e+00, -1.4078e-01, -6.9018e-01, -3.3820e-01,\n",
      "        -1.5156e+00, -1.6206e+00, -1.5770e+00, -1.3442e+00, -7.6040e-01,\n",
      "        -6.0303e-01, -6.8983e-01, -1.0388e+00, -2.2410e+00, -2.8084e+00,\n",
      "        -2.2941e-01, -1.4498e+00, -1.3719e+00, -2.1994e+00, -1.3913e+00,\n",
      "        -1.4131e+00, -1.2055e+00, -2.0773e+00, -1.1978e+00, -6.8639e-01,\n",
      "        -5.8959e-01, -1.1102e+00, -6.8948e-01, -1.7484e+00, -1.7843e+00,\n",
      "         1.2152e-02, -2.0293e+00,  1.1897e-01, -2.7116e-01, -1.3644e-01,\n",
      "        -1.4474e-01, -9.6122e-01, -7.3012e-01, -4.9182e-02, -1.2939e+00,\n",
      "        -1.1208e+00,  7.7452e-01, -4.9284e-01, -1.9023e-01, -1.0349e+00,\n",
      "        -1.2870e+00, -2.7273e-01, -8.2662e-01, -1.4966e+00, -2.0975e+00,\n",
      "        -1.5691e+00, -1.3858e+00, -6.7372e-01, -1.8514e+00,  7.4503e-02,\n",
      "        -1.3189e+00, -1.5336e+00, -1.5007e+00, -1.3112e+00, -2.7498e+00,\n",
      "        -1.7366e+00, -1.1440e+00, -5.1221e-01, -1.1313e+00, -6.9182e-01,\n",
      "        -1.4655e+00, -3.8800e-01,  8.0032e-02, -4.7114e-01, -8.9849e-01,\n",
      "        -1.8534e-01, -9.1532e-01, -3.0553e-02, -1.1444e+00, -1.4305e+00,\n",
      "         2.4621e-01, -7.3259e-01, -1.2563e+00, -1.0495e+00, -2.5945e-01,\n",
      "        -6.8586e-01,  4.2612e-01,  1.1844e-01, -9.8887e-01, -1.2954e+00,\n",
      "        -1.1921e-03, -2.9237e+00, -1.9314e-01, -1.0218e+00, -1.1130e+00,\n",
      "        -1.5152e+00, -1.6002e+00, -1.4423e+00, -2.6777e+00, -1.4596e+00,\n",
      "        -2.9755e-01, -4.4416e-01, -1.4567e+00, -2.6469e-01, -2.5265e+00,\n",
      "        -1.0772e+00, -1.8089e+00, -1.5557e+00, -1.4101e+00, -1.4896e+00,\n",
      "        -1.5428e+00, -1.3449e+00, -1.2030e+00, -1.4947e-01, -9.2907e-01,\n",
      "        -3.2222e-01, -1.3601e+00, -2.0142e+00, -1.8522e+00, -1.1499e+00,\n",
      "        -9.7130e-01, -1.3712e+00, -9.4504e-01,  1.7497e-01, -2.2309e-01,\n",
      "        -1.0433e+00, -4.3708e-03, -4.3605e-01,  3.7238e-02, -1.7035e+00,\n",
      "        -1.8682e-01, -1.2420e+00, -6.9031e-01, -1.2827e-01, -1.4856e+00,\n",
      "        -6.2949e-01, -9.5283e-01, -1.6774e+00, -1.4928e+00, -2.0312e-01,\n",
      "        -2.7782e-01, -1.7258e+00, -1.2345e+00, -9.1845e-01,  2.7133e-01,\n",
      "        -2.2210e+00, -7.4374e-01, -6.8741e-01, -2.1315e+00,  9.7721e-01,\n",
      "        -9.2850e-01, -1.1714e+00, -4.1172e-01, -4.2288e-01, -7.3517e-02,\n",
      "        -1.2139e+00, -6.9933e-01, -1.1958e+00, -1.8829e+00, -1.5765e+00,\n",
      "        -1.1868e+00, -1.6150e+00, -1.2970e+00, -5.2216e-01, -6.4326e-01,\n",
      "        -1.6696e+00, -1.4382e+00, -9.3504e-01, -3.6082e-01, -3.0763e+00,\n",
      "        -2.7735e-01, -1.2592e+00,  6.7551e-01, -3.2044e-01, -2.3953e+00,\n",
      "        -7.2148e-01, -1.4980e+00, -2.8871e+00, -7.3418e-01, -1.4176e-01,\n",
      "        -9.7575e-01, -1.7096e+00, -1.9374e+00, -4.0165e-01, -4.1808e-01,\n",
      "        -1.3823e-01, -5.1897e-02, -3.3242e-01, -1.5971e+00, -7.1624e-01,\n",
      "        -1.2908e+00, -2.1783e-01, -2.6436e+00,  1.1230e-02, -1.0707e+00,\n",
      "        -6.5860e-01, -1.1794e+00, -1.4172e+00, -1.4322e-01, -1.5639e+00,\n",
      "        -2.9711e-01, -1.7006e+00, -4.4246e-01, -6.9229e-01, -1.5031e+00,\n",
      "        -4.9345e-01, -7.8336e-01,  9.5096e-01,  8.7493e-01, -1.4945e+00,\n",
      "        -1.6558e+00, -9.2419e-01, -1.2156e+00, -1.0916e+00, -1.1715e+00,\n",
      "        -1.4159e+00, -5.8699e-01, -3.0305e+00, -2.1587e+00, -1.4120e+00,\n",
      "        -2.6455e-01, -1.2757e+00, -2.2801e+00, -1.3771e+00, -2.7871e+00,\n",
      "        -1.1383e+00, -1.9305e-01, -1.0548e+00, -4.8998e-01, -5.9887e-01,\n",
      "        -1.4318e+00, -9.2100e-01, -6.0811e-01, -1.0926e-01, -2.4884e-01,\n",
      "        -1.7242e+00, -2.0311e+00,  2.3505e-01, -1.9905e-01,  1.8782e-01,\n",
      "        -9.3625e-01, -7.3834e-01, -9.7208e-01, -1.1921e+00,  1.2127e+00,\n",
      "        -1.2017e+00, -1.9802e+00, -1.4968e+00, -1.4823e+00, -1.2750e+00,\n",
      "        -1.1864e-01, -1.2188e+00, -2.8154e-01, -2.9759e+00, -1.2793e+00,\n",
      "        -2.6673e-01, -3.9064e-01, -1.3558e+00, -1.8809e-01, -1.2599e+00,\n",
      "        -7.8715e-01, -2.1402e+00, -1.8864e-01, -3.8410e-01, -1.6349e+00,\n",
      "         4.8592e-01, -9.7118e-01, -1.2692e+00, -1.7450e+00, -1.4292e-01,\n",
      "        -1.6319e+00, -1.0979e+00, -1.3691e+00, -4.5893e-01,  1.5354e-01,\n",
      "        -1.2366e+00,  3.1851e-01, -2.9395e-01, -1.0344e+00, -1.2595e+00,\n",
      "        -1.1289e+00, -8.3359e-01, -1.4307e+00, -3.5494e-02, -1.5155e+00,\n",
      "        -1.4087e+00,  9.0310e-01, -1.6954e+00, -1.4122e+00, -1.8212e+00,\n",
      "        -1.1124e+00, -1.6919e+00, -1.2533e+00, -4.4535e-02, -2.9393e+00,\n",
      "        -2.1472e+00, -1.1945e+00,  2.7441e-02, -1.0529e+00, -1.1532e+00,\n",
      "        -8.2817e-01, -1.5185e+00, -3.3738e-01, -1.6190e+00, -9.5253e-01,\n",
      "        -1.3269e+00, -9.2666e-02, -9.1876e-01, -2.4257e+00, -1.6497e+00,\n",
      "        -2.0630e+00, -1.4684e+00,  1.4271e-01, -3.9081e-01, -1.4379e+00,\n",
      "        -3.2402e-01, -1.2162e+00, -2.2439e-01, -8.5689e-01, -2.0603e-01,\n",
      "        -1.0149e+00, -1.7660e+00, -1.8899e-01, -1.4065e+00, -3.2625e+00,\n",
      "        -4.1532e-01, -4.9132e-01,  4.3336e-01, -4.7024e-02, -7.5526e-02,\n",
      "        -3.9434e-01, -1.7332e+00, -1.8183e+00, -1.6104e+00, -1.5674e+00,\n",
      "        -1.8013e-01,  2.4727e-01, -1.2901e+00, -1.7443e+00, -1.5844e-01,\n",
      "        -9.8131e-01, -2.1072e+00, -2.5541e-02, -4.8057e-01, -1.0509e+00,\n",
      "        -4.4544e-01, -1.6301e+00, -4.5610e-01, -1.3227e+00, -1.3356e+00,\n",
      "        -1.2504e+00, -6.2967e-03, -3.2359e-01,  5.6675e-01, -3.1052e-01,\n",
      "        -4.5939e-01, -1.5599e+00, -7.7790e-02, -1.6385e+00, -1.6273e+00,\n",
      "        -7.2379e-01, -4.8098e-01, -4.0561e-01, -1.8235e+00, -9.6396e-01,\n",
      "        -1.6035e-01, -2.2881e+00, -1.9395e+00,  1.6969e-01, -2.5679e+00,\n",
      "        -1.4567e+00, -1.0248e+00, -1.5309e+00,  7.9948e-02, -1.2097e+00,\n",
      "        -1.2123e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.1433]],\n",
      "\n",
      "         [[ 0.1723]],\n",
      "\n",
      "         [[ 0.2134]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2464]],\n",
      "\n",
      "         [[ 0.3721]],\n",
      "\n",
      "         [[-0.7312]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0642]],\n",
      "\n",
      "         [[-0.1767]],\n",
      "\n",
      "         [[ 0.1489]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1447]],\n",
      "\n",
      "         [[-0.0026]],\n",
      "\n",
      "         [[ 0.1399]]],\n",
      "\n",
      "\n",
      "        [[[-0.2768]],\n",
      "\n",
      "         [[-0.4071]],\n",
      "\n",
      "         [[-0.4277]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9419]],\n",
      "\n",
      "         [[ 0.0659]],\n",
      "\n",
      "         [[ 0.0815]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0802]],\n",
      "\n",
      "         [[ 0.1469]],\n",
      "\n",
      "         [[-0.1651]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1735]],\n",
      "\n",
      "         [[-0.2270]],\n",
      "\n",
      "         [[-0.0644]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0971]],\n",
      "\n",
      "         [[ 0.3227]],\n",
      "\n",
      "         [[ 0.0015]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0922]],\n",
      "\n",
      "         [[ 0.0421]],\n",
      "\n",
      "         [[ 0.2738]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6437]],\n",
      "\n",
      "         [[ 0.2409]],\n",
      "\n",
      "         [[-0.3130]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2022]],\n",
      "\n",
      "         [[-0.0496]],\n",
      "\n",
      "         [[-0.4174]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0059, -0.3208, -0.0513,  0.0635, -0.1837, -0.0077, -0.2691,  0.0361,\n",
      "        -0.0064,  0.2353, -0.4021,  0.0351, -0.0608,  0.0712, -0.2168,  0.2013,\n",
      "        -0.1621,  0.1292,  0.0973,  0.1371, -0.0324,  0.1664,  0.0715,  0.1670],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1036]],\n",
      "\n",
      "         [[-0.1770]],\n",
      "\n",
      "         [[ 0.3342]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4930]],\n",
      "\n",
      "         [[-0.4603]],\n",
      "\n",
      "         [[-0.2465]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1512]],\n",
      "\n",
      "         [[-0.0051]],\n",
      "\n",
      "         [[-0.0645]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3542]],\n",
      "\n",
      "         [[-0.2494]],\n",
      "\n",
      "         [[-0.3048]]],\n",
      "\n",
      "\n",
      "        [[[-0.0249]],\n",
      "\n",
      "         [[-0.3112]],\n",
      "\n",
      "         [[-0.0651]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1059]],\n",
      "\n",
      "         [[ 0.1246]],\n",
      "\n",
      "         [[ 0.4307]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0698]],\n",
      "\n",
      "         [[-0.0197]],\n",
      "\n",
      "         [[-0.0515]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9193]],\n",
      "\n",
      "         [[-0.0284]],\n",
      "\n",
      "         [[ 0.2023]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4502]],\n",
      "\n",
      "         [[-0.2701]],\n",
      "\n",
      "         [[ 0.1313]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2366]],\n",
      "\n",
      "         [[-0.3912]],\n",
      "\n",
      "         [[ 0.1699]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0379]],\n",
      "\n",
      "         [[-0.1150]],\n",
      "\n",
      "         [[-0.1595]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1362]],\n",
      "\n",
      "         [[ 0.4442]],\n",
      "\n",
      "         [[-0.4168]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.5692e-01, -3.1149e-01,  4.4732e-01, -4.2747e-01,  2.2415e-01,\n",
      "         6.2962e-02,  4.3980e-01,  1.4987e-01,  1.7421e-01, -3.7921e-01,\n",
      "        -4.6731e-01, -2.7628e-01,  3.3112e-01,  1.2309e-01, -4.6889e-01,\n",
      "        -1.1393e-02,  4.0540e-01,  2.4293e-01, -8.8130e-02, -5.3533e-01,\n",
      "        -1.2663e-01, -2.3023e-01, -1.3787e-02,  2.9372e-01, -3.5477e-01,\n",
      "         5.2857e-01, -6.5777e-02,  3.4801e-01,  5.8188e-02, -7.0202e-02,\n",
      "         2.3012e-01, -1.6850e-01, -2.6466e-02, -4.3282e-01,  1.2520e-01,\n",
      "        -3.7247e-01, -4.9256e-03, -1.5857e-01,  1.9087e-01, -3.8322e-02,\n",
      "         4.4862e-01, -4.7445e-01,  2.2614e-01, -3.0104e-01,  1.6131e-01,\n",
      "        -2.1523e-01,  1.9216e-01, -1.2695e-02, -4.0300e-01,  6.1850e-01,\n",
      "         8.6949e-02, -1.5464e-01,  3.3802e-01,  1.0797e-01, -4.5552e-02,\n",
      "        -1.6384e-01, -2.0577e-02,  2.2244e-01, -2.0919e-02, -3.2544e-01,\n",
      "        -2.3534e-01, -4.6886e-01,  5.7187e-02, -2.0938e-01, -4.3536e-01,\n",
      "         1.5234e-01,  3.8821e-01,  1.9577e-01,  1.7114e-01,  2.4858e-01,\n",
      "        -3.2211e-01, -3.1165e-01,  1.5306e-01, -2.1957e-02, -4.1408e-01,\n",
      "         5.4565e-02, -1.9914e-01, -1.5040e-01, -1.7035e-01, -1.1922e-02,\n",
      "        -1.2205e-01, -3.9136e-01, -3.4999e-01, -1.6536e-01, -1.7677e-01,\n",
      "        -1.0711e-01, -2.4598e-01,  8.6701e-03, -1.6079e-01, -5.0308e-01,\n",
      "         1.6109e-01, -3.5666e-01, -2.6804e-01, -1.6890e-01, -3.7301e-01,\n",
      "         4.8020e-02,  4.5058e-01,  1.5718e-01, -1.7116e-01, -5.3170e-01,\n",
      "        -2.2505e-02, -2.1671e-01,  2.6429e-01,  4.7895e-03, -7.2303e-02,\n",
      "        -5.2926e-03, -5.1510e-02,  6.1868e-01, -3.6717e-01,  4.6202e-01,\n",
      "        -2.7149e-01, -1.1083e-01,  2.4223e-01, -1.2165e-01, -5.9312e-02,\n",
      "         3.2198e-01, -4.2606e-01,  1.3559e-01,  2.2467e-01,  2.4146e-01,\n",
      "         4.2690e-01, -5.3153e-01, -9.4544e-02,  1.4350e-01, -2.7647e-02,\n",
      "         1.4035e-02,  1.3916e-01,  1.5853e-03,  4.7759e-01, -6.3055e-02,\n",
      "         1.4616e-01,  9.0040e-02, -1.1417e-01,  1.2750e-01, -1.4621e-01,\n",
      "         1.1819e-01, -1.6290e-01,  5.5096e-02,  2.1002e-01,  4.6888e-02,\n",
      "        -6.0337e-01,  2.5061e-01, -1.2782e-01,  1.1321e-02,  3.9425e-01,\n",
      "         5.1697e-01,  3.8067e-01,  1.6559e-01,  4.2114e-01,  4.4663e-01,\n",
      "         9.3907e-02,  3.8852e-01,  2.0393e-01, -1.2911e-01, -7.4792e-02,\n",
      "         1.8419e-01,  3.6642e-01, -3.9137e-01,  2.9626e-01,  2.1491e-01,\n",
      "         6.9380e-02,  1.0231e-01,  1.7316e-01,  5.2115e-01, -7.9560e-02,\n",
      "         4.6551e-01, -6.8765e-03, -2.4387e-01, -2.0224e-01,  1.0921e-01,\n",
      "         4.8944e-01, -3.7415e-01,  2.4049e-02, -3.8212e-01,  4.4097e-01,\n",
      "        -1.5414e-01,  2.6348e-01,  2.2937e-01, -5.1532e-01,  4.7483e-01,\n",
      "        -3.0089e-01, -4.9599e-01, -4.2761e-02,  4.6419e-02, -1.7365e-01,\n",
      "         3.2371e-01, -2.7814e-01,  2.2059e-01, -2.1637e-01, -1.2019e-01,\n",
      "        -2.5694e-01,  4.1913e-01, -4.2541e-01,  3.9974e-01, -4.2543e-02,\n",
      "        -6.8051e-02, -1.0538e-01,  2.5807e-02,  4.8579e-01,  4.2741e-01,\n",
      "         3.2865e-02, -5.5569e-02,  1.1086e-01, -2.4610e-01,  2.6931e-01,\n",
      "         4.4453e-02,  1.7629e-01, -2.6234e-01,  1.8044e-01, -2.5091e-02,\n",
      "        -6.6408e-02, -2.0140e-01,  4.3257e-01,  3.2537e-01, -2.3801e-01,\n",
      "        -1.1200e-01, -2.4864e-01,  1.9241e-01, -7.3458e-02, -2.7646e-01,\n",
      "        -2.9554e-01,  3.6312e-01,  2.6311e-01, -4.6648e-01, -2.8041e-01,\n",
      "         2.5839e-01,  2.1206e-01,  4.9245e-02,  1.5516e-01,  2.6446e-01,\n",
      "        -3.6063e-01,  7.9391e-02, -3.0075e-01,  2.3552e-01, -2.1188e-02,\n",
      "         4.4119e-01,  7.6231e-03,  4.8742e-01,  1.3154e-01, -3.4366e-01,\n",
      "        -3.1820e-01,  3.5082e-01,  1.4119e-01,  4.4604e-01,  1.2256e-01,\n",
      "         2.8086e-01,  1.7814e-02,  1.4897e-01, -7.3577e-02,  4.0538e-01,\n",
      "         1.5938e-02,  1.0371e-01,  6.9536e-02,  2.1976e-02,  2.3923e-01,\n",
      "         6.4969e-01,  2.0817e-01,  4.8275e-02,  3.0967e-01,  1.7569e-01,\n",
      "         1.4325e-01,  1.8502e-01,  2.1400e-01,  1.5701e-01,  1.3527e-01,\n",
      "         6.1182e-01,  1.9027e-01,  1.0675e-01, -3.6381e-01, -4.3341e-01,\n",
      "        -2.2556e-01, -2.5589e-01,  1.2634e-01,  8.7588e-02,  1.2174e-02,\n",
      "         1.3947e-01,  4.4470e-03, -2.2400e-01, -3.0836e-01, -9.4284e-02,\n",
      "        -3.6203e-01, -4.1842e-01,  1.4202e-01,  1.9593e-01, -4.3524e-02,\n",
      "         2.4032e-01,  3.7219e-02, -8.2503e-02,  5.3443e-01,  9.1795e-02,\n",
      "        -6.4098e-02,  4.3282e-01, -2.1847e-02,  5.7766e-01, -9.1394e-02,\n",
      "        -1.1348e-02, -1.8895e-01,  5.4601e-01,  2.1522e-01,  2.6139e-01,\n",
      "        -2.8080e-01,  4.1475e-02, -1.4657e-01,  2.2335e-01, -1.8608e-01,\n",
      "         3.5885e-01,  4.7201e-01,  2.0895e-01,  1.0185e-01,  1.9680e-02,\n",
      "        -4.9386e-01,  4.3507e-01, -2.2535e-03, -2.7494e-01, -5.5044e-02,\n",
      "        -4.6295e-01,  1.4523e-01,  3.3082e-01,  1.0604e-01, -2.7800e-01,\n",
      "         2.0432e-01, -5.0336e-01, -3.3950e-01,  4.6959e-03, -1.4683e-01,\n",
      "         7.9003e-02, -1.0585e-01, -8.3324e-02,  1.5757e-01, -1.5033e-01,\n",
      "         4.6491e-01,  3.8924e-02,  1.0653e-01, -4.2488e-01,  8.0721e-02,\n",
      "        -4.6708e-02,  4.6309e-01,  1.7336e-01, -3.1117e-02, -9.8903e-02,\n",
      "        -2.7647e-01,  3.9949e-01, -1.2523e-01, -4.4311e-02,  2.3783e-02,\n",
      "        -3.8780e-01,  4.0493e-02,  7.0124e-02,  1.0665e-01, -9.2695e-02,\n",
      "        -7.5587e-02, -1.2203e-01, -9.6105e-02, -5.0410e-02, -3.4064e-01,\n",
      "         1.4508e-01, -9.0508e-02,  4.7179e-01,  1.7156e-01,  4.9306e-01,\n",
      "        -9.8456e-02,  2.6847e-01,  2.9183e-02,  1.2357e-01, -1.2726e-01,\n",
      "         5.2943e-02,  5.5748e-01,  2.7353e-01,  1.6069e-01, -1.1796e-01,\n",
      "         4.5519e-01,  1.8529e-02,  1.2226e-02,  7.4516e-04, -9.6963e-02,\n",
      "        -1.8148e-01, -4.9490e-01,  5.1327e-01, -7.0965e-02,  2.0608e-01,\n",
      "        -2.2719e-02,  1.1036e-01, -5.1963e-02, -1.8386e-01, -5.6468e-01,\n",
      "        -1.0011e-01,  2.2638e-01,  8.6988e-02, -4.1558e-01, -3.7244e-01,\n",
      "        -3.7327e-02,  1.1815e-01,  3.6804e-01, -2.0084e-01, -2.7497e-01,\n",
      "        -1.8652e-01,  3.5006e-01, -5.0655e-02, -3.9924e-02, -5.9114e-02,\n",
      "        -3.1591e-01,  1.3479e-01, -1.7275e-01,  1.2590e-01, -1.9759e-01,\n",
      "        -3.7125e-02,  5.0576e-02, -3.4666e-01,  2.7682e-01,  6.5865e-01,\n",
      "         3.1647e-01,  9.1287e-02, -1.5309e-01, -3.1154e-01,  3.4460e-01,\n",
      "         1.2056e-01, -3.8864e-02, -3.5640e-01,  3.1256e-01,  2.1509e-01,\n",
      "        -4.0572e-02,  4.6487e-01,  7.2812e-02,  2.4367e-01,  4.6339e-01,\n",
      "        -3.4568e-02,  1.1213e-01,  1.8614e-01, -3.0110e-01,  6.0135e-01,\n",
      "         7.0639e-02, -8.1543e-02,  5.6041e-01,  1.1640e-01, -2.4668e-02,\n",
      "         1.5652e-01,  2.0576e-01, -3.3571e-01,  7.3968e-02,  3.1252e-02,\n",
      "         5.5581e-02,  3.9361e-01,  3.2136e-01,  1.9912e-01,  1.3427e-01,\n",
      "         1.5906e-01, -4.8782e-01, -9.1169e-02, -1.5771e-02, -3.4038e-01,\n",
      "        -1.8437e-01,  2.5458e-01, -3.9446e-01, -2.4064e-01, -1.1807e-02,\n",
      "        -8.2604e-03, -4.3411e-01, -2.2338e-01, -8.8909e-02,  3.8569e-01,\n",
      "        -3.4480e-02,  4.8701e-01, -7.1771e-02,  3.6738e-01,  4.2576e-01,\n",
      "         6.1241e-02,  1.2304e-01, -1.7661e-01, -2.8188e-01, -1.3698e-01,\n",
      "         2.7216e-01,  2.7602e-02,  3.4466e-01, -2.5778e-01,  3.8509e-02,\n",
      "         5.0237e-01, -1.7383e-01, -5.8748e-02,  4.3654e-01, -3.2261e-02,\n",
      "         3.8445e-01, -3.4952e-01, -4.2796e-01,  2.0863e-02,  5.2211e-01,\n",
      "         4.8969e-01, -5.2628e-01,  1.3307e-01,  4.9830e-01, -4.0362e-01,\n",
      "         3.0922e-01,  3.7780e-04,  2.0088e-01,  3.1035e-02,  3.4545e-01,\n",
      "         1.9080e-01,  9.0220e-02, -2.0335e-01,  2.9050e-01,  7.7848e-02,\n",
      "        -7.1588e-02, -9.7691e-03, -1.1381e-01, -8.7991e-02, -2.3768e-01,\n",
      "        -2.8960e-01, -4.2079e-01, -1.9253e-02,  2.0357e-01, -2.5274e-01,\n",
      "         2.8028e-01, -1.5510e-01,  3.9192e-01, -4.0208e-01, -6.7670e-02,\n",
      "         4.9875e-01,  5.5273e-01,  1.7074e-01,  1.0261e-02, -1.0392e-02,\n",
      "        -1.0548e-01,  1.3391e-01, -7.2083e-02, -1.1804e-01,  2.7755e-01,\n",
      "        -3.1273e-02, -3.7237e-02, -1.8604e-01, -3.5742e-02, -3.5972e-01,\n",
      "        -4.7987e-01,  3.6559e-01,  4.6569e-01,  3.5748e-01, -1.6190e-01,\n",
      "        -1.8315e-01, -1.7094e-01,  3.0029e-01, -4.0595e-02, -7.9795e-02,\n",
      "        -1.4742e-02,  2.9938e-01, -1.2217e-01, -1.1958e-01,  6.0849e-01,\n",
      "         1.4741e-03,  1.5212e-01,  2.0464e-01,  3.0567e-01, -2.1903e-02,\n",
      "         1.2675e-01, -2.0464e-01, -5.5563e-03, -8.3614e-02,  4.5938e-02,\n",
      "        -2.0964e-01,  1.5947e-02, -3.9489e-01,  1.5351e-02,  4.4281e-01,\n",
      "        -2.9849e-01,  3.0530e-02,  2.4510e-01, -1.5203e-01, -1.1830e-01,\n",
      "        -3.3775e-01, -1.8078e-02,  6.1011e-02, -2.2911e-01,  6.0817e-02,\n",
      "         2.0005e-01, -1.9102e-01, -3.0869e-01,  9.6168e-02,  2.9889e-01,\n",
      "         1.0951e-02], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1670]],\n",
      "\n",
      "         [[-0.0305]],\n",
      "\n",
      "         [[ 0.6495]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1901]],\n",
      "\n",
      "         [[-0.2883]],\n",
      "\n",
      "         [[ 0.0655]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4772]],\n",
      "\n",
      "         [[-0.2871]],\n",
      "\n",
      "         [[ 0.3367]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1746]],\n",
      "\n",
      "         [[-0.0109]],\n",
      "\n",
      "         [[ 0.2486]]],\n",
      "\n",
      "\n",
      "        [[[-0.3215]],\n",
      "\n",
      "         [[-0.1282]],\n",
      "\n",
      "         [[ 0.0746]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0057]],\n",
      "\n",
      "         [[ 0.3733]],\n",
      "\n",
      "         [[-0.0712]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.4662]],\n",
      "\n",
      "         [[-0.0240]],\n",
      "\n",
      "         [[ 0.3947]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6020]],\n",
      "\n",
      "         [[ 0.4074]],\n",
      "\n",
      "         [[ 0.4817]]],\n",
      "\n",
      "\n",
      "        [[[-0.3885]],\n",
      "\n",
      "         [[-0.1126]],\n",
      "\n",
      "         [[-0.1651]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4751]],\n",
      "\n",
      "         [[ 0.2285]],\n",
      "\n",
      "         [[-0.4082]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0869]],\n",
      "\n",
      "         [[ 0.3791]],\n",
      "\n",
      "         [[-0.0051]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1738]],\n",
      "\n",
      "         [[ 0.3736]],\n",
      "\n",
      "         [[-0.5309]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.2858, 0.5269, 0.7384, 0.6583, 0.4040, 0.4999, 0.8023, 0.6334, 2.9581,\n",
      "        0.4677, 1.1368, 0.6830, 0.3647, 2.5226, 0.9393, 0.8303, 1.9953, 0.0886,\n",
      "        1.3871, 2.0910, 1.0915, 1.1171, 0.5006, 0.3048, 0.9250, 0.9884, 1.0267,\n",
      "        0.9908, 0.5964, 1.5430, 0.3440, 1.1878, 1.4222, 0.7769, 0.6942, 1.2166,\n",
      "        2.8200, 0.2946, 0.8789, 1.8476, 0.9388, 0.2492, 0.2337, 1.1848, 0.3675,\n",
      "        0.5960, 1.0913, 0.1374, 0.4023, 0.7851, 0.6952, 0.4692, 0.6729, 1.3207,\n",
      "        0.3286, 0.2334, 0.9040, 0.1107, 0.8145, 1.6093, 0.9449, 1.4981, 1.9291,\n",
      "        0.5450, 1.0696, 0.8741, 0.6385, 0.8494, 1.9377, 1.0371, 0.0633, 0.6690,\n",
      "        0.7184, 0.8350, 0.6367, 1.3262, 0.9380, 1.1865, 0.8342, 1.2842, 0.3566,\n",
      "        1.5736, 1.8817, 0.7360, 1.3009, 1.1024, 0.2772, 0.3461, 0.8536, 0.4590,\n",
      "        0.8177, 0.3110, 0.4974, 0.5417, 0.9662, 0.4557], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.7436,  0.1296,  0.0639, -0.5798,  0.3121,  0.2451, -0.7124, -0.6018,\n",
      "         0.2911, -0.8663,  0.2900,  0.8218,  0.2392,  1.3851,  0.1389, -0.3814,\n",
      "         0.3463, -0.3674, -0.4977, -1.4521, -0.2739, -1.0788,  0.0057, -0.2078,\n",
      "         0.1659,  0.5101,  0.4965, -0.1380, -0.8513,  0.9866, -0.1328, -0.3108,\n",
      "         0.4261,  0.0486,  0.6915,  0.2549,  0.3188,  0.9578,  0.2438,  0.1974,\n",
      "        -0.5770, -0.2243, -0.1897,  0.2825,  0.0040,  0.0349, -0.0055,  0.3382,\n",
      "         0.3982, -0.2570,  0.1814,  0.5973,  0.5438, -0.0959, -0.1975,  0.3697,\n",
      "         0.0377, -0.0417, -0.2606,  0.2122,  0.6564,  0.7899,  0.2310, -0.9643,\n",
      "         0.9411, -1.2376,  0.4860,  0.1310, -0.7738,  0.2839, -0.0506, -0.1148,\n",
      "         0.0801,  0.1214,  0.5096,  0.5150,  0.4744, -0.0665, -0.0428,  0.0215,\n",
      "        -0.3757,  0.5359, -0.1098, -0.1686,  0.5930, -0.8942,  0.5735,  0.7322,\n",
      "        -0.3342, -0.2842, -0.0479, -0.1880, -0.1429, -0.1872,  0.3051,  0.1249],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.3408]],\n",
      "\n",
      "         [[ 0.5645]],\n",
      "\n",
      "         [[-0.3301]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5033]],\n",
      "\n",
      "         [[-0.0427]],\n",
      "\n",
      "         [[-0.3925]]],\n",
      "\n",
      "\n",
      "        [[[-0.1692]],\n",
      "\n",
      "         [[-0.1143]],\n",
      "\n",
      "         [[-0.2504]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4100]],\n",
      "\n",
      "         [[-0.0698]],\n",
      "\n",
      "         [[-0.0664]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1210]],\n",
      "\n",
      "         [[ 0.0115]],\n",
      "\n",
      "         [[ 0.6530]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2749]],\n",
      "\n",
      "         [[ 0.3842]],\n",
      "\n",
      "         [[-0.0604]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0917]],\n",
      "\n",
      "         [[ 0.5506]],\n",
      "\n",
      "         [[-0.1288]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0785]],\n",
      "\n",
      "         [[-0.2795]],\n",
      "\n",
      "         [[ 0.0302]]],\n",
      "\n",
      "\n",
      "        [[[-0.0498]],\n",
      "\n",
      "         [[ 0.1256]],\n",
      "\n",
      "         [[-0.1900]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1071]],\n",
      "\n",
      "         [[-0.3416]],\n",
      "\n",
      "         [[-0.3132]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3894]],\n",
      "\n",
      "         [[ 0.1909]],\n",
      "\n",
      "         [[-0.1934]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2877]],\n",
      "\n",
      "         [[ 0.1184]],\n",
      "\n",
      "         [[-0.1958]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.5577,  0.9299,  0.7075,  1.3354,  1.4583,  1.1141,  0.6588,  0.4293,\n",
      "         0.9617,  0.4709,  0.7539,  1.0667,  0.7654,  0.7237,  0.5541,  0.4670,\n",
      "         1.1576,  0.6600,  1.4893,  1.0401,  1.4851,  0.4578,  0.5581,  1.0989,\n",
      "         0.9829,  1.9024,  0.7554,  2.8567,  0.9496,  1.1041,  1.3039,  1.2665,\n",
      "         0.1170,  0.6354,  2.8238,  1.1752,  0.8642,  0.1900,  0.4880,  1.8353,\n",
      "         0.6980,  0.8965,  0.6863,  1.4003,  0.9868,  1.6641,  2.0701,  1.0566,\n",
      "         0.1728,  1.0984,  1.2622,  1.3499,  1.0174,  1.0612,  1.0722,  1.5244,\n",
      "        -0.0648,  1.4360,  0.9556,  1.6842,  1.0401,  1.4681,  1.6974,  1.5945,\n",
      "         0.9722,  1.0010,  0.9491,  0.5870,  0.3093,  0.9248,  0.9593,  0.8318,\n",
      "         0.9643,  0.9549,  0.7810,  0.7594,  0.4158,  1.4302,  1.5947,  1.2110,\n",
      "         0.2707,  0.8020,  1.2490,  1.9955,  1.0458,  1.5085,  0.4178,  1.3367,\n",
      "         0.8571,  1.2144,  0.8994,  0.7497,  0.9586,  1.0063,  0.6602,  0.6862,\n",
      "         1.3953,  1.1545,  0.5193,  1.1437,  1.4469,  0.3047,  0.9223,  1.1979,\n",
      "         0.2476,  0.9064,  1.4708,  1.1948,  1.2720,  1.3460,  2.3024,  0.4349,\n",
      "         1.0263,  0.2789,  1.2997,  1.5224,  1.2545,  0.9181,  1.3937,  0.7155,\n",
      "         0.9923,  0.4832,  1.2809,  0.1543,  1.3264,  1.8424,  0.6120,  0.9892,\n",
      "         0.9697,  1.4623,  1.7252,  1.7702,  1.1242,  0.3904,  0.8472,  1.0794,\n",
      "         0.8064,  1.4446,  0.5498,  1.0279,  0.4172,  1.4396,  2.2537,  0.5051,\n",
      "         0.9804,  1.2310,  0.6552,  1.1583,  1.6322,  1.8452,  1.1477,  0.6183,\n",
      "         0.4070,  0.6149,  0.6464,  1.3866,  0.6022,  1.1008,  0.8682,  1.0917,\n",
      "         0.7894,  0.9187,  0.3107,  1.2393,  1.4722,  1.6049,  0.6335,  1.1862,\n",
      "         0.7725,  1.1363,  0.2814,  1.1051,  1.4769,  1.1142,  1.9578,  1.1430,\n",
      "         1.4922,  1.0100,  0.5375,  1.9408,  1.6959,  0.7892,  1.3380,  0.7378,\n",
      "         1.1413,  0.6254,  0.4382,  1.0640,  1.3249,  1.2942,  0.4506,  1.0920,\n",
      "         0.8919,  2.6450,  0.9905,  2.0211,  1.5315,  1.3429,  1.4779,  1.1414,\n",
      "         1.0744,  0.9419,  1.2268,  0.3999,  1.4118,  1.8273,  1.0830,  1.2383,\n",
      "         0.8832,  0.3865,  2.2565,  0.8560,  1.0777,  1.0962,  0.8368,  0.5952,\n",
      "         0.9456,  0.8351,  0.4531,  1.2132,  1.2273,  1.1154,  1.4407,  1.3615,\n",
      "         1.1036,  0.8068,  1.0668,  1.8656,  0.6822,  1.4950,  1.3277,  1.2461,\n",
      "         1.2792,  0.8265,  0.9127,  1.4977,  1.1776,  0.9299,  0.6492,  0.2252,\n",
      "         1.1871,  0.9498,  0.5357,  1.1784,  1.6455,  1.2765,  1.2857,  1.7118,\n",
      "         0.3057,  2.1329,  1.1823,  1.4161,  1.1456,  1.3115,  0.7458,  0.9191,\n",
      "         0.6314,  0.2234,  0.8903,  0.5381,  0.7824,  2.2295,  0.6645,  0.2168,\n",
      "         0.8408,  1.5363,  1.0135,  1.0313,  1.1405,  1.5400,  0.6484,  1.1350,\n",
      "         0.6947,  0.3232,  1.5045,  0.6152,  0.9318,  0.3012,  1.4008,  0.8931,\n",
      "         1.5577,  1.6148,  1.1441,  0.6285,  1.3170,  1.4846,  1.3431,  0.9470,\n",
      "         1.0710, -0.3450,  1.2669,  1.4200,  0.9333,  0.0247,  0.1816,  0.3986,\n",
      "         1.0002,  2.0940,  1.3513,  1.3287,  0.7204,  1.3677,  0.2642,  2.1642,\n",
      "         0.5079,  1.4336,  0.7173,  0.4203,  0.8557,  1.6124,  1.5349,  1.2400,\n",
      "         1.1420,  1.3869,  0.8998,  0.3416,  0.1899,  0.8223,  0.3566,  1.4961,\n",
      "         0.5797,  0.5478,  0.6532,  0.5039,  0.5036,  0.9624,  0.7684,  1.7681,\n",
      "         1.7231,  0.6963,  0.2210,  0.7629,  1.0147,  0.5674,  1.1189,  1.6958,\n",
      "         1.0341,  1.0628,  0.1727,  1.4273,  1.0633, -0.2416,  0.9406,  1.7971,\n",
      "         0.7644,  1.2015,  1.5823,  1.2072,  0.5774,  1.6240,  0.6301,  1.1401,\n",
      "         0.9796,  1.8599, -0.0030,  0.8959,  0.7627,  0.9448,  0.9833,  1.0200,\n",
      "         1.4240,  1.3764,  1.7251,  1.3766,  0.7483,  0.7805,  0.3536,  1.2046,\n",
      "         0.3765,  0.5710,  0.4533,  2.1136,  0.9339,  0.3724,  0.4698,  1.4879,\n",
      "         0.7850,  1.6649,  1.3622,  0.5559,  1.5893,  1.2979,  1.4113,  1.9090,\n",
      "         1.8917,  1.6491,  0.8917,  0.9366,  1.4331,  0.9700,  1.4708,  1.5596,\n",
      "         1.1465,  1.3249,  2.0704,  0.6649,  1.7004,  1.5172,  1.7807,  1.9940,\n",
      "         0.6868,  0.4135,  0.9980,  0.6211,  0.8184,  0.3440,  1.0075,  0.8807,\n",
      "         0.7705,  1.4340,  0.9970,  1.3092,  0.5750,  1.1495,  1.3066,  1.4269,\n",
      "         0.8985,  1.2809,  1.1319,  1.4124,  0.0896,  0.9376,  1.7851,  1.0951,\n",
      "         1.4303,  0.6989,  0.6105,  1.1244,  1.9019,  0.8823,  0.8664,  1.7039,\n",
      "         1.0228,  0.9717,  0.7809,  1.6720,  0.9757,  0.2553,  1.7512,  0.6855,\n",
      "         1.0644,  1.2685,  0.6566,  0.2480,  1.5717,  0.1168,  1.0395,  1.6162,\n",
      "         1.4871,  2.3773,  0.5547,  0.8759,  1.6500,  0.8689,  1.1582,  0.3688,\n",
      "        -0.0142,  0.3887,  0.6511,  0.6092,  1.2249,  0.8512,  1.1089,  1.2393,\n",
      "         1.6944,  1.8283,  0.6489,  0.7435,  1.2667,  0.4700,  0.3144,  0.6418,\n",
      "         1.2044,  0.7613, -0.4931,  2.0059,  1.6253,  0.3260,  1.4496,  0.8372,\n",
      "         0.5873,  1.3440,  1.4782,  0.9476,  1.2564,  0.5682,  1.2394,  1.3547,\n",
      "         1.1541,  0.7818,  1.0624,  1.1058,  0.4390,  0.7771,  1.0893,  0.8981,\n",
      "         1.0458,  0.7351,  0.6858,  1.5194,  1.0107,  1.6794,  0.9976,  1.1403,\n",
      "         1.3547,  1.3178,  1.7976,  0.7944,  0.2140, -0.2920,  1.5614,  1.7382,\n",
      "         2.5732, -0.0247,  1.4711,  1.5077,  0.9467, -0.3968,  1.6268,  0.9576,\n",
      "         1.9645,  1.0613,  1.7317,  1.2773,  1.6421,  1.3779,  1.7050,  1.3337,\n",
      "         1.2114,  0.8436,  0.9559,  1.7008,  1.7952,  1.6065,  0.6778,  1.6112,\n",
      "         1.3059,  1.6017,  0.9395,  1.3695,  0.5228,  0.9808,  1.1721,  1.4714,\n",
      "         1.8131,  1.3439,  2.0957,  1.2785,  0.8802,  1.3595,  1.5234,  1.2020,\n",
      "         0.3006,  1.2026,  0.4088,  1.0824,  0.6704,  1.1259,  0.2199,  0.5483,\n",
      "         0.3214,  1.3175,  0.8443,  2.2360,  0.2740,  1.4344,  0.9401,  0.1191,\n",
      "         0.7358,  0.7940,  0.4965,  0.7868,  2.3373,  1.1920,  0.7716,  1.1454],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0573,  0.8997, -0.1581, -0.2127, -0.7996, -0.8006, -1.7552, -1.7302,\n",
      "        -1.8292,  0.0148,  0.0667,  1.8509, -0.2223, -1.3628,  1.1859, -0.2454,\n",
      "         0.0433, -2.3123, -0.2865,  0.3377, -1.6133,  0.0116,  0.0356, -0.7806,\n",
      "         0.3515, -2.2048, -2.2518, -0.4407,  0.7930, -0.5270,  0.8130, -1.3066,\n",
      "        -0.0420,  0.6604, -2.8354, -1.8185,  0.6918,  2.2761,  0.6770, -2.1494,\n",
      "         0.4101,  0.0287, -0.5906, -0.3248,  1.2721, -1.0891, -0.0603, -1.9223,\n",
      "        -0.1566, -2.2598, -0.3480, -0.4256,  0.7691,  1.0159,  0.3013, -1.1848,\n",
      "        -1.4431, -0.2035, -1.0054,  0.2701,  0.0099, -1.6882, -0.2907, -0.7128,\n",
      "         0.8711, -1.8001,  0.1766,  0.9972, -0.0503, -0.8057,  0.0536, -0.8404,\n",
      "        -2.3003, -0.8071, -0.9658, -1.5792, -0.5095, -1.4749, -0.3132, -1.7293,\n",
      "         0.2906, -1.0243, -0.6816, -1.1768,  0.5458, -0.1489, -0.3795, -0.4413,\n",
      "        -2.1717, -1.4966,  1.0306,  0.1374, -1.0465, -0.8841,  0.6141,  0.6943,\n",
      "        -0.5562, -0.0152, -1.6654, -1.5575,  0.3179,  0.4183, -0.8438, -0.0412,\n",
      "        -0.0299, -0.0617, -2.1241,  0.0183,  0.4584, -0.0350, -2.8156,  0.1192,\n",
      "        -0.8899,  0.2851, -0.9543, -0.1784, -0.9197, -1.4464, -0.9871, -1.5940,\n",
      "        -1.6766,  0.2355, -0.2151,  0.1099, -1.9671, -1.4920, -0.8826,  1.3798,\n",
      "        -1.1846, -3.3710, -0.8823, -1.4871, -0.0999,  0.1490, -2.3624, -0.0882,\n",
      "        -0.4413, -0.7321,  0.4674,  0.3968, -0.0696, -0.8521,  0.4081,  0.5104,\n",
      "        -1.9038, -1.0960,  0.5950, -0.6578,  0.3853, -0.8027, -1.5409, -1.2390,\n",
      "         0.8000, -1.0405, -0.2073, -0.7356, -0.0138, -1.2987, -1.4669,  0.0689,\n",
      "        -0.0897, -0.9159,  0.6632, -1.0796,  0.8621,  1.3981, -1.1232, -0.1987,\n",
      "        -1.1198, -0.6606, -0.1288,  0.0699, -1.7732, -0.8304, -4.3938, -0.5922,\n",
      "        -0.1041, -0.7567,  1.0987, -1.6497, -0.3697,  1.6596, -2.0567, -0.9871,\n",
      "        -0.8378, -1.7768,  0.6703, -0.4032, -0.8967, -0.9847,  0.5303, -0.6104,\n",
      "        -1.3865, -0.0425, -0.3153,  0.0591, -0.8457,  0.9315,  0.1659,  1.3069,\n",
      "        -0.5318,  0.6701, -0.9072,  0.1315, -1.2167, -0.1318,  0.2549, -0.6893,\n",
      "        -1.4049,  0.6028, -4.0239,  0.5482, -1.9629, -1.9246,  0.5432,  0.3669,\n",
      "        -0.4768,  0.7004, -0.8296,  0.9732,  0.1640, -0.3907, -0.3437,  0.4080,\n",
      "         0.2876, -0.4247, -0.4971,  0.2664,  1.0592, -0.7550, -0.0443, -0.3920,\n",
      "        -0.6767,  0.7302, -0.4194, -1.1762,  0.2357, -0.2024, -0.0324,  0.2591,\n",
      "        -0.9526, -1.1617,  0.6862, -1.3404, -0.3978, -1.6814, -0.1441,  0.8321,\n",
      "         1.3461, -3.6744, -0.7756, -0.2071, -0.9261, -0.1988,  0.9102,  0.2320,\n",
      "        -1.6171,  0.3422, -1.0962,  0.3017, -1.0451, -3.5071,  0.8698,  0.1447,\n",
      "        -1.5055, -0.0716, -0.8471,  0.3285, -0.4159, -1.1735, -0.0770, -0.3688,\n",
      "        -1.1233, -0.2016, -0.1731,  1.3925, -0.6583,  0.0129, -0.8890,  0.7003,\n",
      "        -0.4675,  0.5717, -0.8181, -0.8882, -0.5921, -0.3483, -0.2300,  1.6171,\n",
      "        -0.6748,  0.3076, -2.0572,  0.4210, -0.5693, -0.1686,  0.4679,  0.1035,\n",
      "         0.1544,  0.9021,  0.7530, -2.3195, -0.3887, -0.7092,  0.6178, -0.4813,\n",
      "        -0.1293, -0.6169,  0.3263,  0.3575, -0.5437, -1.3301, -0.1674, -0.6034,\n",
      "        -1.1440,  0.2458, -0.4535,  0.2974, -0.0882, -0.9943,  0.1811,  0.1085,\n",
      "         0.3216,  0.9390, -0.4520,  0.8418,  0.1164, -0.6468, -0.1387, -0.3247,\n",
      "         1.1543, -0.1343,  1.1570,  0.4406,  1.0523, -0.0077,  0.6746, -1.4009,\n",
      "        -1.3738, -1.0446, -0.3465, -0.3480, -0.3578,  0.6001, -1.4644, -3.9175,\n",
      "        -1.1460, -1.5166, -1.7493, -0.7271,  0.4397,  0.2326,  0.6058, -1.6068,\n",
      "         0.0519,  0.9904, -0.3912, -0.9652,  0.5173,  0.7922, -1.6848, -0.0209,\n",
      "         0.3062,  0.4681, -0.5034, -1.2246, -0.2087,  1.3224,  0.1854,  0.2008,\n",
      "         0.7916,  0.3800,  0.1626, -1.8142, -2.0907,  1.5024,  1.0110, -0.3032,\n",
      "         0.3758, -2.0946, -0.9591, -0.2352,  0.5906, -1.2394, -0.9889,  0.9214,\n",
      "        -1.9564, -0.8999,  0.8231, -0.7404,  0.4833, -1.1997, -1.7409, -0.5565,\n",
      "         0.9803, -1.3904, -0.2019, -0.7150, -0.9526, -1.5608, -1.4358,  0.1683,\n",
      "        -1.1312, -0.0516, -0.1604,  1.3083,  0.2249, -0.2598, -0.9827, -1.1446,\n",
      "         0.5985,  0.1425, -0.0794, -0.5794,  0.2812, -0.3114, -0.9218,  0.4081,\n",
      "        -1.6302, -1.6475,  0.6901, -0.3458, -0.0167,  0.9988, -0.2591, -1.1494,\n",
      "        -0.3398,  0.4720,  0.4026, -1.4488,  0.0147,  0.6563, -0.1857, -0.8033,\n",
      "        -1.0305,  0.1804, -0.8945, -2.1474, -1.2896, -0.4120,  0.8424, -1.0765,\n",
      "         0.8882,  0.0420,  0.3079, -0.0874, -0.1051, -1.3404, -1.5385, -0.3256,\n",
      "        -0.0843, -1.3236,  0.5334, -1.4437, -0.7480,  0.4577, -0.9579,  1.0984,\n",
      "         1.0171,  1.2395,  0.2380,  0.7703, -1.0324,  0.9851, -2.0900, -1.2442,\n",
      "        -0.1237,  0.8209, -1.4154, -0.0737,  0.3724,  0.3284,  0.6461,  0.5216,\n",
      "         0.2114,  1.7524,  0.4145, -2.7473, -0.4043,  0.7289, -0.5981,  1.0594,\n",
      "        -0.2054, -1.5865, -0.9865, -0.2370,  0.2534,  0.6236, -0.7174, -1.4438,\n",
      "        -1.1646, -1.8140,  0.2771,  0.7666,  0.9606, -1.0498, -0.8015,  0.4998,\n",
      "        -1.6541, -0.7320,  0.0363, -1.6941, -0.7789, -2.0453, -1.6790,  0.3252,\n",
      "        -0.7305, -1.3038,  0.0761, -0.1783,  0.0856,  0.0244, -1.1385, -1.5618,\n",
      "        -4.1371, -0.0420, -0.8237,  0.8350,  0.4835, -0.2825,  1.0651, -1.5422,\n",
      "        -2.6686,  0.3001,  0.2194, -1.4264, -0.6286,  0.2785,  1.4963, -0.2053,\n",
      "        -1.2457,  1.4150,  0.2393, -0.2426,  0.0469, -1.0621, -1.3555,  0.5832,\n",
      "        -0.5604, -1.9560, -1.2020, -0.1002,  0.8092,  0.2827,  0.1376, -2.2330,\n",
      "        -0.8393, -1.6011, -1.9656, -1.2702,  0.0973, -0.6908, -1.5277, -1.1463,\n",
      "         0.3224,  0.7974,  1.7016, -1.1450,  0.8945,  0.2946,  1.2094,  0.0243,\n",
      "         0.3763, -1.0925, -0.6664, -0.6474,  0.5426,  0.2385,  0.7246,  0.2295,\n",
      "        -1.5627, -0.4273,  0.6769,  1.4493, -2.7812,  0.9456, -0.1411, -0.7316],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2594,  0.5330,  0.2063],\n",
      "          [-0.0099,  0.1023,  0.3890],\n",
      "          [ 0.5085,  0.1027, -0.1169]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3899,  0.4134,  0.4063],\n",
      "          [-0.0106, -0.3725,  0.0188],\n",
      "          [-0.0860,  0.0389, -0.0906]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0630,  0.8094, -0.0787],\n",
      "          [-0.1026,  0.0166, -0.1795],\n",
      "          [ 0.2051, -0.4013, -0.3117]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1559,  0.4358,  0.3487],\n",
      "          [ 0.3375,  0.5118,  0.2648],\n",
      "          [-0.2318, -0.1211,  0.5125]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0593,  0.3823,  0.2182],\n",
      "          [ 0.4416,  0.5241,  0.3148],\n",
      "          [ 0.2988,  0.1504,  0.0800]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2864,  0.2807,  0.4457],\n",
      "          [ 0.5768,  0.3719,  0.3551],\n",
      "          [ 0.0998, -0.1509, -0.1443]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.9190,  1.2967,  2.6517,  0.6533,  2.0296,  1.3918,  0.2286,  1.6194,\n",
      "         0.3635,  0.4300,  1.6464,  2.3968,  1.1958,  0.5551,  1.4516,  1.0429,\n",
      "         1.5560, -0.0538,  0.6725,  1.8146,  2.9224,  1.3007,  0.8110,  1.4203,\n",
      "         1.1856,  4.3851,  0.5656,  2.4160,  2.1258,  1.6325,  1.2143,  0.4044,\n",
      "         1.2297,  0.1124,  5.6455,  2.6216,  1.2758,  1.3469,  1.1443,  3.2732,\n",
      "         1.6769,  1.6051,  0.7567,  1.2809,  1.8779,  0.8865,  1.2001,  0.5782,\n",
      "         1.2493,  1.9736,  0.6223,  1.0352,  1.8275,  1.1566,  1.5718,  0.5189,\n",
      "         1.1667,  1.3651,  0.8289,  1.6136,  1.1301,  3.4237,  1.4465,  0.6336,\n",
      "         1.7191,  0.4701,  0.6876,  1.2164,  1.1855,  1.8147,  1.9610,  1.9893,\n",
      "         0.7107,  2.2746,  1.8015,  1.4462,  1.3076,  1.5032,  0.9891,  1.1648,\n",
      "         2.2601,  1.7244,  0.9676,  1.7407,  0.8048,  1.4409,  1.1515,  0.9567,\n",
      "         0.7114,  0.8524,  1.6090,  0.4777,  1.0048,  0.8378,  2.0535,  1.5814,\n",
      "         1.2440,  0.5448,  0.4560,  0.8102,  1.7454,  1.4131,  1.3866,  1.0826,\n",
      "         1.2006,  1.4291,  0.3395,  0.9978,  1.8511,  1.2623,  3.7923,  1.3605,\n",
      "         0.3744,  1.5922,  1.9780,  1.1633,  1.3472,  0.4291,  0.9800,  1.1730,\n",
      "         1.0079,  1.3770,  1.2824,  1.5957,  2.7636,  0.3493,  1.4029,  1.5611,\n",
      "         1.2773,  3.2005,  2.1428,  3.7056,  1.7430,  1.9738,  1.2836,  1.4220,\n",
      "         1.4725,  1.7507,  1.6191,  1.6904,  1.4755,  1.3709,  2.1713,  1.0168,\n",
      "         0.6180,  1.3059,  1.7855,  1.7471,  1.5759,  1.8519,  1.3207,  1.6531,\n",
      "         1.1557,  2.5652,  0.7079,  1.4417,  1.1508,  0.7431,  1.9637,  1.0480,\n",
      "         1.6154,  1.6292,  1.8014,  2.4134,  1.3517,  1.1033,  1.4498,  1.5429,\n",
      "         1.8051,  1.1502,  2.1793,  1.6653,  0.8823,  1.2885,  4.2356,  2.1218,\n",
      "         1.7383,  0.9261,  1.6318,  3.2891,  0.5949,  1.2477,  1.8129,  1.5455,\n",
      "         0.9685,  0.3988,  0.9714,  0.7950,  1.3543,  1.1228,  1.4089,  1.2673,\n",
      "         1.7220,  1.9871,  0.8558,  1.1028,  0.9368,  1.2893,  1.2688,  2.0368,\n",
      "         3.3988,  1.3281,  1.2058,  1.7184,  1.4948,  1.7450,  1.6378,  1.5696,\n",
      "         1.8093,  1.4882,  5.1338,  1.0541,  2.1777,  1.3846,  1.4968,  1.7403,\n",
      "         1.1132,  0.5788,  0.8817,  1.8015,  1.1301,  1.6529,  2.4557,  1.6829,\n",
      "         1.4100,  2.0674,  0.7750,  1.0975,  1.7939,  1.6456,  1.6247,  1.3233,\n",
      "         1.4626,  1.9913,  1.1032,  1.5880,  0.8303,  1.0156,  1.8628,  1.7832,\n",
      "         2.1531,  3.2612,  1.3999,  1.3817,  1.9109,  0.8835,  0.5034,  2.4394,\n",
      "         1.4817,  4.7484,  1.0859,  1.2306,  0.3021,  0.8602,  1.0465,  1.3399,\n",
      "         0.5654,  1.4959,  0.6681,  1.6399,  1.4617,  4.9147,  1.8271,  2.4591,\n",
      "         0.5425,  1.2051,  1.3586,  1.6756,  1.5274,  1.3072,  1.4215,  1.0134,\n",
      "         0.8150,  1.4556,  1.4313,  2.1891,  1.1685,  2.0658,  1.0110,  1.9107,\n",
      "         1.0539,  0.7488,  1.3355,  1.2530,  1.1816,  0.6434,  1.2450,  2.0620,\n",
      "         1.7229,  1.3208,  0.3403,  1.5257,  1.3110,  0.7259,  1.4228,  0.9086,\n",
      "         1.2963,  1.7728,  1.6344,  0.7278,  1.6228,  1.6493,  1.3793,  2.6626,\n",
      "         2.0798,  0.7187,  1.8325,  1.0800,  1.3989,  2.5727,  0.5889,  2.1828,\n",
      "         1.6060,  1.5861,  1.4821,  1.6485,  1.9131,  1.1906,  1.6380,  1.5995,\n",
      "         1.5424,  1.0898,  0.9730,  1.0927,  1.1147,  0.3414,  1.0136,  1.0998,\n",
      "         0.5361,  1.7952,  1.4526,  1.3673,  2.0568,  1.5790,  1.3562,  2.4834,\n",
      "         0.4621,  1.5123,  1.7514,  1.0584,  1.9388,  0.6830,  0.8290,  2.7015,\n",
      "         1.5882,  0.9122,  4.6178,  1.1967,  1.2874,  1.7101,  2.0715,  0.8163,\n",
      "         1.7728,  2.4823, -0.0061,  1.1133,  1.4848,  1.5467,  0.3136,  1.4609,\n",
      "         0.4912,  1.3784,  0.9855,  0.4300,  2.1728,  1.7938,  1.8405,  1.6706,\n",
      "         1.6979,  1.8455,  1.8258,  4.4279,  0.1435,  1.4926,  1.6212,  1.4025,\n",
      "         0.9515,  1.8214,  1.3003,  1.0716,  1.1356,  0.3420,  2.0563,  2.1622,\n",
      "         4.8221,  1.3896,  1.6254,  2.1187,  1.0531,  1.5604,  1.5759,  0.8187,\n",
      "         1.5258,  0.4535,  0.8112,  0.9612,  0.8596,  1.4199,  0.8575,  1.7492,\n",
      "         0.3693,  1.7523,  0.9146,  1.5263,  1.5926,  0.9379,  0.8879,  0.9823,\n",
      "         1.5460,  1.6624,  2.0481,  1.2261,  1.1949,  1.5371,  0.7869,  1.0393,\n",
      "         0.7660,  3.6200,  1.2494,  1.2720,  1.7906,  1.3913,  1.6599,  0.5128,\n",
      "         1.0794,  2.3608,  1.2183,  1.0858,  1.1352,  1.9562,  1.6329,  0.6250,\n",
      "         1.5075,  2.0283,  1.0423,  2.9526,  0.0914,  1.3971,  2.3893,  1.4848,\n",
      "         1.2863,  1.2588,  0.4925,  1.7186,  0.9787,  0.9477,  2.0864,  0.8165,\n",
      "         1.9215,  0.9173,  1.6126,  1.1935,  1.1171,  1.8553,  0.9464,  2.2266,\n",
      "         1.4875,  1.4691,  0.6270,  1.4642,  1.4787,  1.4142,  0.7688,  2.1827,\n",
      "         1.6093,  2.6331,  1.7195,  1.0634,  1.3301,  0.9140,  2.0436,  1.5919,\n",
      "         1.6991,  2.1199,  2.3076,  2.6638,  1.7406,  1.3973,  1.3438,  1.7887,\n",
      "         1.5676,  2.5007,  2.1837,  1.5835,  0.7945,  1.4410,  1.3669,  0.9947,\n",
      "         0.4853,  0.4055,  1.8568,  1.6450,  1.4457,  0.4471,  0.9869,  1.7683,\n",
      "         0.5127,  2.1698,  1.2582,  2.1341,  1.4972,  3.7542,  0.8370,  1.8746,\n",
      "         1.5850,  0.8197,  0.1450,  1.1235,  0.8541,  1.6396,  0.3394,  0.9770,\n",
      "         2.8488,  0.1132,  1.0753,  1.7324,  1.5846, -0.0343,  1.0917,  0.5912,\n",
      "         3.0315,  0.9623,  2.0240,  1.5461,  0.2880,  0.1160,  1.4168,  0.4316,\n",
      "         0.6352,  1.6196,  1.4318,  2.1927,  1.7229,  1.7272,  0.7959,  1.7115,\n",
      "         0.6142,  4.3430,  1.5617,  1.9166,  1.8409,  0.9373,  0.8930,  2.9242,\n",
      "         2.0671,  1.1376,  2.9062,  1.5830,  1.3882,  0.1432,  1.2588,  0.8454,\n",
      "         1.4956,  1.8500,  1.5076,  0.8099,  1.6155,  1.6393,  1.4179,  1.2480,\n",
      "         1.9426, -0.1073,  1.2295,  2.1278,  1.6369,  1.4540,  0.8982,  1.2869,\n",
      "         0.8472,  1.2539,  1.6697,  1.9062,  5.0227,  1.9160,  1.2008,  1.1149],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.0460e+00, -9.3010e-01, -3.0255e-01, -2.0226e-02, -2.7974e-01,\n",
      "        -1.7772e+00,  5.8488e-01, -8.2484e-01, -1.0328e-01, -2.1134e+00,\n",
      "        -8.2175e-01, -1.5749e+00, -2.3429e+00, -3.0113e-01, -2.4259e+00,\n",
      "        -3.0260e+00, -1.2628e+00,  6.0168e-04, -2.0166e-01, -9.7524e-01,\n",
      "         5.5975e-01, -1.0343e+00, -4.0750e-01, -9.3978e-01, -2.2186e+00,\n",
      "        -8.3751e-02, -9.6488e-02, -2.4276e-01, -1.7212e+00, -2.1269e+00,\n",
      "        -1.1533e+00, -1.0118e-01, -5.5822e-01,  9.8461e-03,  6.6349e-01,\n",
      "        -1.3177e+00, -8.2464e-01, -2.0375e+00, -1.7731e+00,  5.4429e-01,\n",
      "        -1.5722e+00, -2.6787e+00, -1.5332e+00, -1.4702e+00, -1.6569e+00,\n",
      "        -5.5767e-01, -6.8206e-01, -2.7510e-01, -1.1026e-01, -2.6073e+00,\n",
      "        -2.1510e-01, -1.0335e+00, -1.4545e+00, -9.3017e-01, -5.6542e-01,\n",
      "         2.1525e-02, -4.7724e-01, -1.2175e+00, -4.5232e-01, -1.1948e+00,\n",
      "         1.5411e-01, -7.1192e-01, -6.2648e-01, -2.2219e-01, -1.5712e+00,\n",
      "        -1.3507e-01, -3.0383e-01, -1.4071e+00, -7.6018e-01, -1.1124e+00,\n",
      "        -1.2873e+00, -1.3394e+00, -3.0449e-01, -1.4074e+00, -2.5123e+00,\n",
      "        -2.8747e+00, -9.0377e-01, -1.4713e+00, -4.3195e-01, -2.3899e-01,\n",
      "        -1.6554e+00, -1.3457e+00, -5.7183e-01, -3.3271e-01, -4.2019e-01,\n",
      "        -4.1089e-01, -4.2355e-01, -2.6755e-01,  6.5644e-02, -2.8890e-02,\n",
      "        -1.5606e+00, -6.3009e-01, -2.7587e+00, -4.5021e-01, -2.0167e+00,\n",
      "        -1.4831e+00, -2.3420e+00, -1.4601e-01,  1.8751e-01,  1.5418e-01,\n",
      "        -9.1155e-01, -1.3128e+00, -2.0728e+00,  6.0182e-01, -1.2231e+00,\n",
      "        -1.1395e+00,  4.7986e-01, -3.1173e-02, -1.9149e+00, -7.9755e-01,\n",
      "        -1.4519e-01, -8.8281e-01, -2.4797e+00, -1.3901e+00,  1.7223e-01,\n",
      "        -6.6260e-01, -4.5451e+00, -2.9154e-01,  2.7014e-02, -6.1669e-01,\n",
      "         2.3370e-01, -2.2372e+00, -1.1421e+00, -9.0222e-01, -9.2741e-01,\n",
      "         1.4706e-01, -2.5793e-01, -1.1213e+00, -3.4631e-01, -1.9230e+00,\n",
      "        -9.9548e-01,  4.1908e-01, -1.4993e+00, -1.2922e+00, -1.3349e+00,\n",
      "        -2.4339e+00, -2.2782e+00, -1.9451e+00, -2.7537e-01, -1.5555e+00,\n",
      "        -1.6121e+00, -6.0113e-01, -1.3626e+00, -1.6543e+00, -5.1842e-02,\n",
      "        -1.0871e+00, -1.5075e+00, -7.0721e-01, -1.3156e+00,  1.4491e-01,\n",
      "        -1.0734e+00, -2.0121e+00, -6.9945e-01, -1.2335e+00, -2.3685e+00,\n",
      "        -3.0241e+00, -2.1317e+00, -2.2815e-01,  1.7009e-01, -4.3132e-01,\n",
      "        -1.2103e+00, -1.0620e+00, -2.5319e+00, -1.0348e+00, -2.0576e+00,\n",
      "         3.6568e-01, -3.1068e+00, -7.8198e-01, -5.1661e-01, -7.0238e-01,\n",
      "        -1.9837e+00, -2.0334e+00, -6.7981e-02, -1.5509e+00, -6.9634e-01,\n",
      "        -1.3195e+00,  2.0265e-01, -4.8461e-01, -1.4315e+00,  3.9831e-01,\n",
      "        -3.4201e-02, -8.7585e-01, -8.9770e-01, -1.4959e+00, -4.7556e-01,\n",
      "         1.9337e-02, -5.4111e-01, -3.0757e-01, -1.7694e+00, -2.5361e+00,\n",
      "        -8.8628e-01, -9.7605e-01, -2.2119e+00, -1.1630e+00, -1.4093e-01,\n",
      "        -5.4236e-01,  1.6072e-01, -2.4639e+00, -1.4756e+00, -1.4738e+00,\n",
      "        -1.2758e+00, -8.1662e-01, -3.3976e-01, -1.6785e+00, -3.3696e-01,\n",
      "        -7.7173e-01, -1.7925e+00, -1.1210e+00, -2.0760e+00, -1.2413e+00,\n",
      "        -9.7929e-01,  1.1285e+00, -8.9209e-01, -1.9651e+00, -1.5517e+00,\n",
      "        -1.7032e+00,  1.3618e-01, -2.6498e-01, -1.2332e+00, -1.2066e+00,\n",
      "        -2.5167e-01, -2.3625e+00, -8.5309e-01, -1.0235e+00, -2.3888e+00,\n",
      "        -1.8843e+00, -2.1319e-01, -4.6939e-01, -1.8119e+00, -3.4686e-01,\n",
      "        -1.1681e+00, -3.0831e+00, -1.3403e+00, -1.2534e+00, -2.2712e-01,\n",
      "        -2.6126e+00, -3.3712e-01, -1.2496e+00, -1.7210e+00, -1.3300e+00,\n",
      "        -1.2709e+00, -2.2614e+00, -1.4807e+00, -9.7000e-01, -7.3867e-01,\n",
      "         4.3874e-02, -2.8463e-02, -1.0870e+00, -1.2934e+00, -2.0452e+00,\n",
      "        -6.3467e-01, -7.6960e-01, -1.7752e-01, -3.7709e+00, -9.0720e-01,\n",
      "        -1.0641e+00, -3.0561e-01, -1.5823e+00,  2.4480e-01, -1.5180e+00,\n",
      "        -1.5420e+00, -2.1588e-01, -1.5781e+00, -2.1033e+00, -1.4795e-01,\n",
      "        -8.1162e-01, -1.0698e+00, -1.7054e+00, -1.9569e+00, -1.3823e-01,\n",
      "        -1.3840e+00,  3.0096e-01, -3.2711e-01, -6.1720e-01, -1.2920e-01,\n",
      "        -2.4195e+00, -2.6574e+00, -1.2369e+00,  1.4026e+00, -1.1283e+00,\n",
      "        -4.0671e-01, -7.3857e-03, -1.8196e+00, -2.3304e+00, -3.0379e+00,\n",
      "        -1.5982e+00, -2.3836e+00, -1.4571e+00, -1.1833e+00, -6.2603e-01,\n",
      "        -7.6580e-02, -1.7266e+00, -4.5503e-01, -1.5266e+00, -6.1180e-01,\n",
      "        -2.5981e+00, -1.4840e+00, -1.4281e+00, -1.1073e+00,  4.0856e-02,\n",
      "        -1.7238e+00, -1.1286e+00, -4.8713e-01, -1.3562e+00, -1.5783e+00,\n",
      "        -1.2533e-01, -1.7092e+00, -6.5033e-01, -1.8729e+00, -8.6195e-01,\n",
      "         3.0130e-01,  1.2708e-02, -2.0170e+00, -1.4206e+00, -2.0753e+00,\n",
      "        -2.5289e+00,  5.7895e-01, -1.1406e+00, -1.4760e+00, -2.3286e+00,\n",
      "        -1.8523e+00, -2.1814e+00, -8.8861e-01, -1.2851e+00, -2.0549e+00,\n",
      "        -4.3064e-01, -1.8849e-01, -2.8626e-01, -9.6286e-02, -2.0119e+00,\n",
      "        -2.6488e+00, -1.2951e+00, -1.8511e+00, -1.3369e+00, -1.2745e+00,\n",
      "         3.1309e-01, -5.5069e-02, -9.0874e-01, -1.6079e+00, -7.9082e-01,\n",
      "        -6.1159e-01, -2.4333e-01, -2.3733e-01, -8.4832e-01, -2.2476e+00,\n",
      "        -8.7264e-02,  5.2648e-01, -2.4621e+00, -1.4957e+00, -1.2924e+00,\n",
      "        -1.5574e+00,  3.8569e-01, -1.1428e+00, -1.2091e+00, -3.0431e-02,\n",
      "        -5.3463e-01, -9.0697e-01, -1.6049e+00, -6.7314e-02, -9.9935e-01,\n",
      "         3.7029e-01,  4.5333e-01,  2.5058e-01, -3.2590e-01, -9.6078e-01,\n",
      "        -2.0852e+00, -1.2370e+00, -6.2527e-01, -1.3350e+00, -1.5237e+00,\n",
      "        -1.0836e+00,  8.1516e-01,  1.4369e-02, -1.3203e+00, -1.6064e+00,\n",
      "        -2.3896e+00, -3.4984e-01, -2.7570e+00, -6.7804e-01, -2.7305e+00,\n",
      "        -2.3360e+00, -5.1935e-02, -2.3011e+00, -2.3409e+00,  8.7772e-01,\n",
      "         2.6632e-01, -1.6763e+00, -1.2776e+00, -6.8602e-02, -2.1367e+00,\n",
      "        -3.8085e-01,  1.2196e+00, -1.4162e+00,  1.3565e-02, -5.9533e-02,\n",
      "        -4.8421e-01,  3.7430e-02, -1.0420e+00,  3.5649e-01, -2.6731e-01,\n",
      "        -1.6984e+00, -1.2971e+00, -3.5986e-01, -1.0670e+00, -1.2688e+00,\n",
      "        -2.4740e+00, -2.3876e+00, -3.7548e-01, -1.4962e+00,  5.1741e-01,\n",
      "        -1.4694e+00, -4.1684e-01, -1.0298e+00, -8.1766e-01, -2.9904e-01,\n",
      "        -6.7936e-01, -2.6260e-01,  4.6191e-02, -9.7714e-01, -2.8251e+00,\n",
      "        -1.6152e+00, -1.0292e+00, -4.6712e-01, -3.0045e-01, -5.4806e-01,\n",
      "        -7.7444e-01, -2.4439e+00, -6.1233e-01, -5.5823e-01, -8.8532e-01,\n",
      "        -1.3543e+00,  4.7670e-02, -6.2691e-01,  2.7887e-01, -5.5386e-01,\n",
      "         9.3856e-02, -1.6748e-02, -1.5709e+00, -1.6870e+00, -1.3860e+00,\n",
      "        -4.0747e-02, -1.9480e+00, -3.8415e-02, -1.1273e+00, -5.3016e-01,\n",
      "        -3.1000e-01, -1.7945e-01, -2.6077e-01, -5.0071e-01, -1.1897e+00,\n",
      "        -2.2029e+00, -3.3060e-01, -3.3313e-01, -1.9831e+00,  6.9478e-01,\n",
      "        -2.5188e+00, -1.7993e+00, -1.6073e+00, -3.0873e-01, -1.2211e+00,\n",
      "        -5.3013e-01, -5.2087e-01,  3.6541e-02, -6.0689e-01, -5.5445e-01,\n",
      "        -1.3551e+00, -5.8110e-01, -1.5412e+00, -4.8010e-01, -1.6939e+00,\n",
      "        -1.3864e+00, -3.4743e+00, -9.4424e-01, -7.2495e-01, -1.2541e+00,\n",
      "        -2.8893e-01, -6.7892e-01, -1.7896e+00, -5.5647e-01, -1.4187e+00,\n",
      "        -1.4365e+00, -8.4978e-02, -3.4647e-01, -2.1812e+00, -2.5293e-01,\n",
      "        -1.9512e+00, -4.1274e-01,  1.3493e-02, -2.2847e-01,  1.2589e-04,\n",
      "        -3.5062e+00, -1.2847e+00, -1.7237e+00, -3.4159e-01,  1.5583e-01,\n",
      "        -1.2102e+00,  8.9471e-02, -7.2203e-01, -2.1667e+00, -2.8342e-01,\n",
      "        -2.9464e-02, -9.3560e-02,  2.9580e-01, -1.1594e+00, -4.1275e-01,\n",
      "        -2.7378e-01, -1.7354e-02, -1.9189e+00, -2.4195e-01, -1.5903e+00,\n",
      "        -1.8278e-01, -3.3299e-01, -5.9749e-01,  2.7854e-03, -5.4840e-01,\n",
      "        -2.7221e+00, -1.4272e+00,  1.5271e+00,  6.5268e-01, -2.5526e-01,\n",
      "         4.8582e-05, -1.4227e+00, -2.2396e+00, -1.2376e+00,  2.4536e-02,\n",
      "        -3.2663e-02, -1.5505e+00, -2.5474e-01,  4.6777e-02, -1.3901e+00,\n",
      "        -1.6417e+00, -1.2236e+00, -9.7402e-01, -1.7321e+00, -3.4729e-01,\n",
      "        -9.1208e-01, -2.6230e-01,  1.4557e-01, -2.0809e+00, -1.4169e+00,\n",
      "        -1.6715e+00, -1.3171e-01, -2.8647e-01, -5.5259e-01, -9.0333e-01,\n",
      "        -1.6268e+00,  3.2970e-01, -2.8175e-01, -1.7765e+00, -6.2950e-02,\n",
      "        -2.4834e+00, -1.0629e-01, -1.2835e+00, -1.6637e+00, -1.4188e+00,\n",
      "        -4.5689e-01, -1.5767e+00, -1.5038e+00, -2.0736e+00, -7.7546e-01,\n",
      "        -1.5103e+00, -2.8487e-02, -1.8829e+00, -1.0705e+00, -1.3974e+00,\n",
      "        -1.3229e+00,  3.3184e-01, -5.9707e-01, -2.2038e+00, -2.1941e+00,\n",
      "        -1.8413e+00, -2.1070e-01,  1.0997e+00, -1.4500e+00, -1.3065e+00,\n",
      "        -3.2340e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1429]],\n",
      "\n",
      "         [[ 0.3306]],\n",
      "\n",
      "         [[-0.2316]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2625]],\n",
      "\n",
      "         [[ 0.0272]],\n",
      "\n",
      "         [[-0.0720]]],\n",
      "\n",
      "\n",
      "        [[[-0.2630]],\n",
      "\n",
      "         [[ 0.1851]],\n",
      "\n",
      "         [[-0.1300]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6821]],\n",
      "\n",
      "         [[ 0.3573]],\n",
      "\n",
      "         [[-0.0784]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0113]],\n",
      "\n",
      "         [[ 0.1758]],\n",
      "\n",
      "         [[ 0.2784]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.8210]],\n",
      "\n",
      "         [[ 0.3513]],\n",
      "\n",
      "         [[ 0.1968]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1162]],\n",
      "\n",
      "         [[ 0.1702]],\n",
      "\n",
      "         [[-0.3575]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0259]],\n",
      "\n",
      "         [[ 0.1629]],\n",
      "\n",
      "         [[ 0.0942]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0829]],\n",
      "\n",
      "         [[ 0.2912]],\n",
      "\n",
      "         [[ 0.2536]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1098]],\n",
      "\n",
      "         [[ 0.3275]],\n",
      "\n",
      "         [[ 0.1322]]],\n",
      "\n",
      "\n",
      "        [[[-0.0444]],\n",
      "\n",
      "         [[-0.3146]],\n",
      "\n",
      "         [[-0.3944]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3609]],\n",
      "\n",
      "         [[ 0.1137]],\n",
      "\n",
      "         [[-0.0807]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0474, -0.0535,  0.0317,  0.2069,  0.1788,  0.2692, -0.0198,  0.1498,\n",
      "         0.0682,  0.0817, -0.2703, -0.2398,  0.3423,  0.1819,  0.0440, -0.0329,\n",
      "        -0.0991,  0.1117,  0.2423,  0.3043,  0.2402, -0.1523,  0.0618,  0.0200],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.1986]],\n",
      "\n",
      "         [[ 0.0923]],\n",
      "\n",
      "         [[-0.4268]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0573]],\n",
      "\n",
      "         [[ 0.0759]],\n",
      "\n",
      "         [[-0.0339]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3020]],\n",
      "\n",
      "         [[-0.1159]],\n",
      "\n",
      "         [[-0.1502]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3065]],\n",
      "\n",
      "         [[-0.1445]],\n",
      "\n",
      "         [[-0.4197]]],\n",
      "\n",
      "\n",
      "        [[[-0.3407]],\n",
      "\n",
      "         [[-0.4131]],\n",
      "\n",
      "         [[-0.0290]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0020]],\n",
      "\n",
      "         [[-0.4222]],\n",
      "\n",
      "         [[ 0.0690]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0075]],\n",
      "\n",
      "         [[ 0.1208]],\n",
      "\n",
      "         [[ 0.3901]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1897]],\n",
      "\n",
      "         [[ 0.0072]],\n",
      "\n",
      "         [[ 0.1277]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2749]],\n",
      "\n",
      "         [[-0.4607]],\n",
      "\n",
      "         [[-0.0750]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1946]],\n",
      "\n",
      "         [[ 0.0881]],\n",
      "\n",
      "         [[-0.1327]]],\n",
      "\n",
      "\n",
      "        [[[-0.1607]],\n",
      "\n",
      "         [[-0.1099]],\n",
      "\n",
      "         [[ 0.1936]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3784]],\n",
      "\n",
      "         [[-0.0765]],\n",
      "\n",
      "         [[ 0.0509]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.3603, -0.2869,  0.0473,  0.0051, -0.3393, -0.2769, -0.0923, -0.4035,\n",
      "         0.1714,  0.2191,  0.0268,  0.1899,  0.3697,  0.3343,  0.3776,  0.2020,\n",
      "        -0.3729, -0.3263,  0.2771,  0.3064, -0.4913,  0.2462,  0.1957,  0.3232,\n",
      "         0.3657, -0.3671,  0.2852, -0.3835,  0.3524,  0.3011,  0.0230, -0.2903,\n",
      "        -0.4171, -0.3246, -0.1560, -0.0993,  0.0107,  0.0451, -0.1539, -0.3771,\n",
      "         0.3555,  0.5138,  0.1678,  0.3723,  0.3197, -0.3057, -0.2395,  0.0989,\n",
      "        -0.3583, -0.3031, -0.0679,  0.0128, -0.0502,  0.2481,  0.0135,  0.3054,\n",
      "        -0.1818,  0.2095, -0.1514,  0.2161, -0.4996, -0.3449, -0.2926, -0.2807,\n",
      "         0.2101, -0.0901,  0.0758,  0.3417,  0.4221,  0.1944, -0.0115,  0.2345,\n",
      "        -0.4019,  0.2197,  0.3638, -0.1231, -0.1954,  0.4264, -0.4085,  0.3312,\n",
      "        -0.3878, -0.2592,  0.1719,  0.2793, -0.4855, -0.1869, -0.1882,  0.5929,\n",
      "         0.4197,  0.2540, -0.3197,  0.2635, -0.0124,  0.0387,  0.4577, -0.1827,\n",
      "         0.4853, -0.3781,  0.0769,  0.3236, -0.3289, -0.1046,  0.3105, -0.2606,\n",
      "         0.5110, -0.1566, -0.0888,  0.2275,  0.1903, -0.3977, -0.3048,  0.2386,\n",
      "        -0.1572, -0.2587, -0.2618, -0.2944, -0.3805, -0.4567,  0.3643,  0.1211,\n",
      "         0.4103,  0.2652,  0.4274, -0.3005, -0.4105, -0.2388, -0.2818,  0.3028,\n",
      "        -0.3396,  0.2843,  0.0556, -0.3010,  0.4288,  0.4148,  0.4091,  0.3553,\n",
      "        -0.1362,  0.0804,  0.0865, -0.3217,  0.2915, -0.2062,  0.3601,  0.0679,\n",
      "        -0.1052,  0.1298,  0.0520, -0.1867,  0.4204,  0.1551,  0.1168,  0.4155,\n",
      "        -0.1930,  0.1693,  0.3767, -0.2680,  0.2007, -0.0825,  0.2050, -0.2881,\n",
      "        -0.2202,  0.2241,  0.0396,  0.0389,  0.2400,  0.3884,  0.0795,  0.1649,\n",
      "         0.0938, -0.2722,  0.3726,  0.1818,  0.0646,  0.3047, -0.2136,  0.3521,\n",
      "        -0.3274, -0.0422, -0.0833, -0.0947,  0.3547, -0.2679,  0.2717,  0.2533,\n",
      "        -0.4703, -0.2214, -0.4356, -0.3566,  0.4806, -0.2974, -0.1639, -0.3513,\n",
      "         0.0981,  0.4286, -0.2460, -0.3314,  0.1081,  0.0296, -0.2429, -0.2728,\n",
      "        -0.2937,  0.1818,  0.3752,  0.0956, -0.4374,  0.1618, -0.4687, -0.2042,\n",
      "         0.2429, -0.1703, -0.0790,  0.0319, -0.2314, -0.2529,  0.0528,  0.2352,\n",
      "         0.1364, -0.1407, -0.1729,  0.1924,  0.2979, -0.3241, -0.3919, -0.2181,\n",
      "        -0.4375,  0.1866,  0.1897, -0.0459, -0.1997, -0.0489, -0.3114, -0.1636,\n",
      "        -0.3257,  0.1864, -0.3022,  0.3924,  0.3726,  0.2834, -0.1104,  0.4478,\n",
      "        -0.3712, -0.2737,  0.2648, -0.2695,  0.2819,  0.3997, -0.2802,  0.0059,\n",
      "        -0.1858, -0.4182,  0.2207, -0.4059, -0.3619, -0.4852, -0.0264,  0.3452,\n",
      "         0.1465,  0.3295, -0.0706,  0.3849,  0.2004, -0.4192,  0.2984,  0.1361,\n",
      "        -0.3296, -0.4933, -0.0339, -0.2040,  0.0969,  0.1597, -0.5438,  0.4648,\n",
      "        -0.2126, -0.4345, -0.2767,  0.2589, -0.0320,  0.2189,  0.1622, -0.4146,\n",
      "        -0.3654, -0.3020, -0.1167,  0.3041,  0.0054,  0.1062,  0.3025,  0.4242,\n",
      "         0.3208, -0.1595, -0.2643, -0.0772,  0.0595,  0.3466, -0.3311,  0.1031,\n",
      "        -0.0216,  0.1968, -0.0360,  0.0951,  0.2771, -0.2365, -0.3343,  0.2228,\n",
      "        -0.0067, -0.2569,  0.2975, -0.4006,  0.3670, -0.0318,  0.2331,  0.2934,\n",
      "        -0.3919,  0.3886,  0.3126,  0.4061, -0.0120,  0.2341,  0.1397,  0.3736,\n",
      "        -0.1581,  0.0319, -0.1821,  0.3809,  0.2592, -0.1159,  0.4288,  0.1179,\n",
      "        -0.2601,  0.1199, -0.1258, -0.2136,  0.0222,  0.0921, -0.3595, -0.1332,\n",
      "         0.2138, -0.2699,  0.1142, -0.1511,  0.3375, -0.4045, -0.0107, -0.1497,\n",
      "         0.2063, -0.2527, -0.1076,  0.4494,  0.2644,  0.0073,  0.3660,  0.2888,\n",
      "         0.3099,  0.1311, -0.3345,  0.2148, -0.3603,  0.2390, -0.3505, -0.0127,\n",
      "        -0.4276,  0.3304, -0.4754,  0.3003,  0.1458,  0.1679, -0.1554,  0.1020,\n",
      "        -0.3437,  0.2235,  0.4402, -0.1769, -0.1345, -0.2915,  0.1924,  0.4042,\n",
      "        -0.3572, -0.0162,  0.4119,  0.1080,  0.0995, -0.1601,  0.5507,  0.0390,\n",
      "        -0.4112,  0.2845, -0.0120,  0.1240,  0.4120, -0.3462,  0.1679,  0.2318,\n",
      "         0.3098, -0.1721,  0.1260,  0.2118,  0.4000,  0.5132,  0.0208,  0.0964,\n",
      "         0.4370,  0.2384,  0.2252, -0.1464, -0.0177, -0.3139,  0.3356, -0.2582,\n",
      "         0.3674, -0.2807,  0.4006,  0.0521, -0.2141, -0.3592,  0.2136,  0.0227,\n",
      "         0.1860, -0.3848, -0.1394, -0.4140,  0.3543, -0.3848,  0.0254,  0.2596,\n",
      "         0.3485, -0.0213,  0.4112,  0.0808,  0.3496,  0.4270,  0.3313,  0.2049,\n",
      "         0.0378,  0.1172,  0.1059, -0.2916, -0.1146,  0.3196,  0.3259,  0.3181,\n",
      "        -0.1465,  0.2079, -0.3138,  0.1022, -0.2489, -0.4385,  0.2029,  0.0226,\n",
      "        -0.0644,  0.2877,  0.2103, -0.4456,  0.3954, -0.2912, -0.1798,  0.3100,\n",
      "         0.4983, -0.0033, -0.3471, -0.2940, -0.1394,  0.2554, -0.3042, -0.0783,\n",
      "        -0.2115,  0.0326,  0.2490,  0.1379, -0.0787,  0.4349, -0.1145, -0.1587,\n",
      "         0.3297, -0.0657, -0.0257, -0.1638, -0.0665,  0.3750, -0.3667,  0.0090,\n",
      "         0.1304, -0.0122,  0.3595,  0.4990, -0.3730,  0.3510, -0.4369,  0.2304,\n",
      "         0.1634, -0.0686,  0.3425,  0.1384,  0.4674,  0.0391, -0.1797,  0.3285,\n",
      "         0.3297,  0.0103,  0.3786, -0.2710,  0.2593, -0.4215, -0.2417,  0.3424,\n",
      "         0.4266,  0.0315, -0.4302,  0.0633, -0.2333,  0.2003,  0.3305, -0.2152,\n",
      "        -0.0277, -0.2219, -0.3348,  0.3796,  0.1134, -0.3377, -0.0553, -0.4044,\n",
      "        -0.3610,  0.1153, -0.0491,  0.0827,  0.3206, -0.2582,  0.0403, -0.1383,\n",
      "        -0.1143,  0.3578,  0.1999,  0.2702,  0.2600,  0.3433,  0.3034, -0.2926,\n",
      "        -0.2149, -0.0731, -0.2927, -0.2223,  0.1998, -0.0318, -0.3826, -0.0018,\n",
      "        -0.0314, -0.0595,  0.3601, -0.0327,  0.2937,  0.0496,  0.3361, -0.2409,\n",
      "        -0.3893,  0.2618, -0.0888,  0.2904, -0.1956, -0.0850, -0.1632, -0.0305,\n",
      "         0.1009, -0.2846,  0.0538,  0.3382, -0.0527,  0.0552, -0.3142, -0.2239,\n",
      "        -0.4785,  0.2615,  0.2819, -0.3331, -0.3995,  0.3991, -0.2949,  0.3840],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0351]],\n",
      "\n",
      "         [[ 0.3959]],\n",
      "\n",
      "         [[ 0.1285]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3575]],\n",
      "\n",
      "         [[-0.0947]],\n",
      "\n",
      "         [[ 0.1068]]],\n",
      "\n",
      "\n",
      "        [[[-0.1464]],\n",
      "\n",
      "         [[-0.1077]],\n",
      "\n",
      "         [[ 0.0643]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5703]],\n",
      "\n",
      "         [[ 0.2557]],\n",
      "\n",
      "         [[ 0.2977]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6844]],\n",
      "\n",
      "         [[ 0.2167]],\n",
      "\n",
      "         [[ 0.9513]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0191]],\n",
      "\n",
      "         [[-0.1283]],\n",
      "\n",
      "         [[ 0.1505]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3458]],\n",
      "\n",
      "         [[ 0.3150]],\n",
      "\n",
      "         [[-0.1242]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7547]],\n",
      "\n",
      "         [[ 0.2366]],\n",
      "\n",
      "         [[-0.4087]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0075]],\n",
      "\n",
      "         [[-0.2910]],\n",
      "\n",
      "         [[-0.3912]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1839]],\n",
      "\n",
      "         [[ 0.1379]],\n",
      "\n",
      "         [[ 0.3019]]],\n",
      "\n",
      "\n",
      "        [[[-0.2012]],\n",
      "\n",
      "         [[ 0.0954]],\n",
      "\n",
      "         [[ 0.6858]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0772]],\n",
      "\n",
      "         [[-0.0984]],\n",
      "\n",
      "         [[ 0.5005]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.5234,  0.7969,  0.7570,  0.7995,  0.1172,  0.6568,  0.6995,  0.8175,\n",
      "         2.2864,  0.9375,  1.0109,  0.5488,  0.8690,  2.3273,  0.9932,  0.8301,\n",
      "         1.3542,  0.6082,  0.5733,  2.1590,  1.0808,  1.3137,  0.8889,  0.5667,\n",
      "         1.1173,  1.1615,  0.8292,  0.6636,  0.1183,  1.2369,  0.5022,  1.0905,\n",
      "         1.6903,  0.4534,  0.4473,  1.0445,  2.4981,  0.6227,  1.6804,  2.1462,\n",
      "         0.8452,  0.7504,  0.5473,  1.6512,  0.5201,  0.8494,  1.1092,  0.3034,\n",
      "        -0.0550,  0.7450,  0.4258,  0.7251,  0.5155,  1.5939,  0.3190,  0.1407,\n",
      "         0.8161,  0.0594,  0.6509,  1.0867,  0.4952,  1.1637,  1.9909,  0.5923,\n",
      "         1.5646,  0.7138,  0.8082,  0.7104,  1.4996,  0.3715,  0.2436,  0.4652,\n",
      "         1.1958,  0.5412,  0.3879,  1.1266,  1.2425,  0.6301,  0.7097,  1.0533,\n",
      "         0.4640,  1.4746,  2.1878,  1.0759,  1.0966,  1.4093,  0.4165,  0.2968,\n",
      "         0.8970,  0.2714,  1.0672,  0.8085,  0.8851,  0.5167,  1.4374,  0.1000],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.5544, -0.1917,  0.2888, -0.9325,  0.2502,  0.0301, -0.9242, -0.3484,\n",
      "        -0.4628, -0.7742,  0.5518,  0.5765,  0.1026,  1.6219, -0.0349,  0.1833,\n",
      "         0.0957, -0.6835,  0.1730, -1.8647, -0.1717, -0.3809, -0.2004, -0.7133,\n",
      "         0.4154,  0.2635,  0.2671,  0.2182, -0.5302, -0.0096,  0.2114, -0.0574,\n",
      "        -0.2323, -0.3090,  0.1955,  0.2653,  0.1427,  1.0818,  0.0227, -0.1671,\n",
      "        -0.7353, -0.1881, -0.4407, -0.5158,  0.2402,  0.0447,  0.1707,  0.1433,\n",
      "         0.7740,  0.0465,  0.3204,  0.4392,  0.4547, -1.0919, -0.6701,  0.4038,\n",
      "         0.2537, -0.0745,  0.4138,  0.2787,  0.4831,  0.4800, -0.1704, -0.4233,\n",
      "         0.1258, -1.3596,  0.5990,  0.1867, -1.0580,  0.2719, -0.3999,  0.1068,\n",
      "        -0.1607,  0.1470,  0.5403, -0.0134,  0.4737,  0.0076, -0.0544, -0.2141,\n",
      "        -0.1903,  0.4837, -0.3528, -0.8967,  0.5712, -0.9940,  0.6971,  0.5433,\n",
      "        -0.1507, -0.3874,  0.2832, -0.6010,  0.0590,  0.4379, -0.4506,  0.5360],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1700]],\n",
      "\n",
      "         [[ 0.5049]],\n",
      "\n",
      "         [[ 0.1333]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0331]],\n",
      "\n",
      "         [[ 0.0524]],\n",
      "\n",
      "         [[ 0.0736]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0306]],\n",
      "\n",
      "         [[ 0.0636]],\n",
      "\n",
      "         [[-0.0812]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2020]],\n",
      "\n",
      "         [[ 0.2125]],\n",
      "\n",
      "         [[-0.2055]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1711]],\n",
      "\n",
      "         [[-0.1075]],\n",
      "\n",
      "         [[ 0.0032]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2826]],\n",
      "\n",
      "         [[ 0.1909]],\n",
      "\n",
      "         [[-0.8288]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2376]],\n",
      "\n",
      "         [[ 0.3137]],\n",
      "\n",
      "         [[-0.0368]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3842]],\n",
      "\n",
      "         [[-0.0566]],\n",
      "\n",
      "         [[-0.1522]]],\n",
      "\n",
      "\n",
      "        [[[-0.4291]],\n",
      "\n",
      "         [[-0.1565]],\n",
      "\n",
      "         [[-0.6427]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7185]],\n",
      "\n",
      "         [[ 0.0342]],\n",
      "\n",
      "         [[-0.7345]]],\n",
      "\n",
      "\n",
      "        [[[-0.4220]],\n",
      "\n",
      "         [[-0.3819]],\n",
      "\n",
      "         [[-0.1542]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1265]],\n",
      "\n",
      "         [[-0.2775]],\n",
      "\n",
      "         [[ 0.1425]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.4742, 1.9502, 1.2815, 1.3044, 1.4316, 0.8831, 1.8466, 1.1648, 1.1265,\n",
      "        1.6294, 0.6858, 1.4643, 0.2008, 1.3104, 0.8405, 0.6687, 0.2939, 1.1186,\n",
      "        0.0914, 1.3151, 1.4511, 1.2291, 1.0052, 1.5804, 1.1539, 0.6098, 1.6509,\n",
      "        1.6055, 1.0306, 1.3916, 0.7822, 0.2567, 1.5507, 1.6520, 0.7275, 1.5259,\n",
      "        1.0092, 0.5513, 0.7549, 1.2366, 0.7578, 1.2599, 1.5114, 0.7054, 0.9263,\n",
      "        0.2056, 0.4408, 1.0723, 0.9925, 0.6881, 1.1911, 1.0818, 1.2830, 0.7422,\n",
      "        1.0735, 1.2997, 0.5970, 0.7281, 1.2213, 1.8142, 0.7900, 0.8925, 0.4388,\n",
      "        1.8513, 0.9542, 0.6370, 0.7641, 0.4772, 1.1923, 0.9877, 1.2444, 1.0856,\n",
      "        0.7854, 0.2327, 1.2038, 1.3392, 1.1791, 0.4484, 1.1137, 1.4706, 0.9619,\n",
      "        0.7821, 0.8864, 1.0256, 1.1325, 1.2952, 1.3198, 0.7568, 1.0471, 0.8982,\n",
      "        0.5297, 1.5374, 0.8114, 1.6633, 0.3593, 1.2779, 0.9797, 1.1031, 0.6826,\n",
      "        1.6632, 0.5464, 0.9078, 0.8457, 1.1436, 0.9924, 0.7756, 0.6795, 0.9509,\n",
      "        1.0182, 0.7519, 0.6745, 1.0655, 1.0202, 0.5687, 0.8546, 0.7212, 0.8486,\n",
      "        0.8734, 1.2249, 1.2140, 0.6469, 0.3686, 2.0541, 0.9688, 1.5899, 0.3387,\n",
      "        1.8738, 1.2335, 0.6956, 1.0167, 1.5074, 1.4100, 1.2449, 0.9264, 0.7841,\n",
      "        0.6053, 0.9829, 0.3112, 1.2410, 1.0873, 1.8173, 0.7236, 1.4944, 1.0004,\n",
      "        1.3549, 1.4895, 1.0445, 1.1226, 1.4710, 0.5734, 0.9587, 1.2396, 0.6748,\n",
      "        1.3026, 0.4030, 1.3651, 1.1013, 1.0547, 1.2059, 0.7876, 0.2880, 0.8559,\n",
      "        1.9499, 0.4663, 0.1961, 0.9010, 0.6891, 1.1861, 0.8860, 0.8306, 0.9927,\n",
      "        1.2664, 0.5607, 0.8998, 0.6754, 1.2148, 1.1185, 1.1647, 0.8130, 1.3997,\n",
      "        0.1964, 1.5411, 0.0457, 0.7521, 1.2023, 1.4891, 0.7148, 1.5258, 1.0989,\n",
      "        0.4863, 1.4999, 1.3141, 1.5009, 0.6104, 1.0017, 0.6620, 1.4669, 0.4028,\n",
      "        0.7946, 1.1061, 0.9741, 1.0058, 1.0447, 1.0249, 0.8612, 1.1963, 0.2694,\n",
      "        0.7035, 0.5903, 1.2973, 1.4372, 1.1451, 1.2562, 0.8706, 0.3719, 0.8678,\n",
      "        1.5218, 1.2734, 0.9168, 1.1644, 0.8048, 0.4072, 0.3890, 1.5564, 1.1852,\n",
      "        0.8210, 0.8967, 1.2062, 1.2309, 1.0494, 1.6876, 1.4131, 1.0166, 0.8532,\n",
      "        0.6740, 1.2689, 0.9973, 0.9212, 1.0107, 0.9631, 0.3212, 1.4591, 1.1717,\n",
      "        1.3365, 1.7738, 1.4434, 1.4960, 1.1775, 1.2709, 0.7263, 1.3047, 1.8585,\n",
      "        1.6666, 0.5045, 0.6094, 0.7976, 0.7773, 0.9672, 1.0733, 0.8018, 1.3620,\n",
      "        0.7249, 1.1037, 1.1331, 0.7327, 1.3299, 1.0979, 1.8371, 0.7823, 1.0791,\n",
      "        1.0162, 0.9323, 1.2610, 1.2110, 1.7416, 1.1570, 1.2500, 0.5743, 1.0053,\n",
      "        1.2078, 1.1512, 1.0135, 1.0788, 1.0757, 1.4208, 1.3413, 0.6777, 2.0511,\n",
      "        0.7177, 0.5499, 1.1361, 1.2138, 0.8915, 0.7724, 0.9560, 1.0485, 0.8351,\n",
      "        1.2119, 0.3439, 0.7048, 1.3740, 0.9803, 1.3068, 1.6094, 0.6030, 0.9949,\n",
      "        1.2505, 1.3616, 0.9125, 1.2655, 1.1492, 1.8035, 0.7895, 1.0636, 1.1528,\n",
      "        1.8139, 1.1558, 0.0049, 2.1127, 0.7675, 1.8182, 1.4901, 1.1604, 1.4068,\n",
      "        0.8251, 0.6350, 0.9057, 1.9961, 1.7600, 1.0833, 2.0159, 1.3054, 0.6300,\n",
      "        1.0503, 1.6341, 1.0846, 0.9563, 0.5092, 1.3834, 1.3436, 0.4091, 1.0823,\n",
      "        1.5096, 1.8023, 1.2035, 1.1133, 1.2634, 0.8208, 1.0119, 0.9824, 1.0812,\n",
      "        1.3532, 0.9214, 0.5302, 0.9352, 1.3164, 1.6691, 1.6284, 0.4988, 1.0257,\n",
      "        1.3020, 0.9690, 1.8738, 1.3918, 1.2704, 1.3005, 0.9657, 1.0202, 1.1574,\n",
      "        0.9356, 1.4815, 0.7632, 0.9963, 0.4315, 1.2980, 1.6649, 0.9243, 1.0121,\n",
      "        0.8782, 0.8905, 0.5206, 0.7756, 1.0683, 0.8726, 0.3375, 1.0035, 1.0240,\n",
      "        0.9123, 1.4605, 0.9354, 1.1609, 0.6356, 0.8805, 1.5062, 0.9743, 0.6130,\n",
      "        1.0642, 1.7620, 0.5264, 0.9102, 0.4134, 0.2822, 0.4488, 1.4294, 1.4228,\n",
      "        1.3562, 1.1800, 1.1926, 2.3159, 1.7829, 1.8626, 1.0966, 0.8709, 2.0164,\n",
      "        0.9537, 1.3008, 0.6882, 0.9759, 0.7654, 1.1513, 1.0821, 1.1836, 0.1968,\n",
      "        1.4431, 0.5936, 0.6486, 1.8215, 1.2401, 1.1653, 1.5306, 1.0098, 0.9471,\n",
      "        0.2735, 0.7845, 1.2944, 1.1055, 1.8530, 1.6255, 1.1109, 0.7355, 1.1831,\n",
      "        1.1423, 1.6717, 0.6886, 0.8588, 0.9686, 1.4948, 0.9646, 1.0498, 1.0163,\n",
      "        0.8638, 1.9040, 1.0026, 1.0073, 0.5597, 0.5273, 1.5386, 1.2597, 0.2244,\n",
      "        1.1053, 1.0496, 1.1439, 1.1575, 1.3091, 1.2365, 1.2509, 1.3677, 2.2488,\n",
      "        0.4525, 1.5386, 1.0210, 0.7878, 0.8382, 1.3374, 0.9448, 1.0455, 1.7347,\n",
      "        1.2261, 1.2788, 0.8682, 1.1118, 0.9688, 1.8340, 1.1185, 0.9712, 0.8267,\n",
      "        1.7338, 1.0697, 1.0709, 0.9647, 0.5442, 1.3191, 0.1378, 1.0566, 1.1668,\n",
      "        0.7125, 1.2689, 0.9725, 0.9620, 1.7457, 1.3843, 0.9035, 0.9547, 1.3750,\n",
      "        1.3987, 0.9009, 1.0587, 1.4161, 0.8490, 0.1579, 1.0122, 1.0441, 0.7725,\n",
      "        1.1192, 0.9111, 1.6222, 1.7960, 1.1297, 0.7171, 1.1971, 0.6157, 0.6216,\n",
      "        1.0049, 0.9313, 1.0933, 0.8065, 1.2626, 0.6160, 0.4975, 0.8498, 0.7914,\n",
      "        0.5582, 0.6390, 0.8086, 0.3779, 1.4437, 0.9442, 0.9375, 0.8172, 0.8374,\n",
      "        0.6154, 1.3072, 1.1817, 1.5239, 1.2033, 0.4909, 0.5483, 0.7437, 1.1531,\n",
      "        0.8450, 0.9962, 0.4311, 0.7560, 1.0803, 1.2563, 0.8628, 1.3799, 2.3340,\n",
      "        1.2158, 0.9445, 1.0688, 0.3875, 1.2337, 0.6221, 1.0962, 1.1926, 1.0940,\n",
      "        2.3309, 1.0034, 1.1406, 0.6804, 1.5357, 1.6714, 0.5068, 1.1567, 1.6346],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 6.5622e-01, -4.0222e-01, -2.9458e-01, -1.1711e+00, -2.4906e-01,\n",
      "        -8.4272e-01,  1.2232e-01, -9.6779e-01, -1.0280e+00, -3.5808e-02,\n",
      "         3.2050e-01,  3.5538e-01,  9.9005e-01, -8.3976e-01, -1.3170e+00,\n",
      "         1.6217e+00,  1.0690e+00, -4.3134e-01, -3.7179e-01, -2.6952e-01,\n",
      "        -2.6238e-01, -6.2435e-01, -1.0273e+00,  1.3008e-01, -1.0135e+00,\n",
      "        -1.0258e+00, -5.2670e-01, -1.0623e+00, -1.3524e+00, -7.3285e-01,\n",
      "        -8.0330e-01,  3.2594e-01, -1.0028e+00, -2.7614e-02, -1.0784e-01,\n",
      "        -6.9279e-02, -8.8048e-01,  4.3245e-01,  9.2893e-01, -1.4703e+00,\n",
      "         1.4047e+00,  5.6239e-01,  3.8313e-01, -7.8502e-01, -5.7040e-01,\n",
      "         7.0853e-01,  5.1316e-01, -1.0922e+00, -1.7627e+00, -1.2774e+00,\n",
      "        -2.9616e-01, -6.9371e-01,  8.5885e-01,  7.3417e-01,  2.1297e-01,\n",
      "        -1.0520e+00,  5.4542e-01, -9.0242e-01, -7.7631e-01, -4.5639e-01,\n",
      "         7.7228e-01, -1.1673e+00,  3.8798e-01,  4.5035e-01, -1.0444e+00,\n",
      "        -1.8419e-01, -1.0680e+00,  1.1071e+00, -2.2098e+00,  2.1316e-01,\n",
      "        -1.1892e-01, -1.2657e+00, -1.4532e+00,  1.0381e-01, -7.5370e-01,\n",
      "        -1.0009e+00, -6.1511e-01,  3.3010e-01, -1.8621e+00, -4.6578e-02,\n",
      "        -1.6498e+00,  6.5079e-01, -2.5867e-01, -4.8523e-01, -1.1860e+00,\n",
      "        -9.4350e-01,  4.8562e-01, -3.9186e-01, -1.8184e+00, -7.8080e-01,\n",
      "        -9.8435e-01, -1.6273e-01, -6.8608e-02, -4.8955e-01,  1.0290e+00,\n",
      "        -1.0896e+00, -8.5641e-01, -3.4791e-01,  1.3476e-02, -8.6060e-01,\n",
      "         7.6436e-01, -1.2517e+00, -1.1725e+00, -8.2301e-01, -1.9000e+00,\n",
      "        -6.3952e-02, -1.4181e+00, -1.5120e+00, -9.5246e-01,  1.7984e-01,\n",
      "        -1.7419e+00, -4.1461e-01, -4.1448e-01, -5.9876e-01, -1.7139e+00,\n",
      "        -1.6207e+00,  7.2656e-03, -1.7275e-01,  5.8651e-01, -2.0201e-01,\n",
      "        -8.3694e-01,  3.8640e-02,  4.5789e-01, -6.8126e-01, -5.0718e-01,\n",
      "        -1.2527e-01,  1.2111e+00, -8.0338e-01, -1.2852e+00, -1.6425e+00,\n",
      "         2.9768e-01, -2.0391e+00, -5.0457e-01, -1.8512e+00, -9.1048e-01,\n",
      "        -5.8532e-01, -1.6137e+00,  4.4306e-01, -1.2320e+00, -6.7035e-01,\n",
      "         2.3383e-01, -2.3199e-02,  8.6935e-01, -1.2543e+00, -4.6557e-01,\n",
      "         7.6775e-01, -1.1873e+00, -3.8317e-01, -1.0897e+00,  1.0659e+00,\n",
      "        -1.1916e+00, -5.7875e-01,  3.6161e-01, -6.3292e-01, -5.3925e-01,\n",
      "        -1.0315e+00,  6.7978e-01, -3.1974e-01,  6.6419e-01,  5.6442e-01,\n",
      "        -1.5806e+00, -1.8855e+00, -2.0778e+00,  7.6938e-01,  3.9137e-01,\n",
      "         1.0885e+00,  9.6514e-01, -3.3447e-01, -1.5668e+00,  2.8593e-01,\n",
      "        -1.2765e-01,  1.8701e-02, -4.6633e-01, -1.1356e+00,  8.5975e-01,\n",
      "        -4.9802e-01,  9.2205e-02, -1.1519e+00, -8.8370e-01, -3.2169e-01,\n",
      "        -2.5816e-01, -5.7981e-03,  5.3495e-01, -4.3532e-01, -8.4714e-01,\n",
      "        -1.5613e+00,  9.0804e-01, -3.4695e-01,  5.2752e-01,  5.4227e-01,\n",
      "        -5.3522e-01, -1.7985e-01, -1.4780e+00, -3.3799e-01, -1.2190e+00,\n",
      "         8.0830e-01, -1.3115e+00,  7.3225e-01, -9.8169e-01,  3.1836e-01,\n",
      "        -1.0115e+00, -2.2516e+00, -1.3530e+00, -2.0887e+00, -5.6329e-01,\n",
      "        -7.9803e-02, -1.2040e-01, -3.0923e+00, -2.8141e-01, -6.4634e-02,\n",
      "        -1.3110e+00,  2.7496e-02, -5.6061e-01,  2.4698e-02,  1.0684e+00,\n",
      "        -8.0979e-02,  3.4778e-01,  1.6241e-01, -1.3272e+00, -1.5031e+00,\n",
      "        -8.0151e-01,  3.0349e-01,  4.9523e-01, -9.7272e-01,  4.8383e-01,\n",
      "        -1.1612e+00, -9.3046e-01, -7.5172e-01,  8.7283e-02, -1.0567e+00,\n",
      "         7.5315e-03, -1.7612e+00,  5.9321e-02, -2.4695e-03,  4.0442e-02,\n",
      "         1.3876e-01,  1.8922e-01, -1.4979e+00, -6.0626e-01, -9.9555e-02,\n",
      "         4.3489e-01, -7.1511e-01, -7.3425e-01, -8.6300e-01, -8.1759e-01,\n",
      "        -1.0261e-01, -3.1369e-01,  4.5964e-01, -4.4665e-01,  6.3070e-01,\n",
      "        -6.8121e-01, -1.6524e-01, -5.6368e-01,  7.9765e-01,  3.6231e-01,\n",
      "        -1.0670e+00, -6.2204e-01,  4.8625e-01, -1.7720e+00, -2.8595e-01,\n",
      "        -1.9812e-01, -7.7787e-01, -1.9640e+00, -3.8261e-02,  3.8701e-01,\n",
      "        -6.3572e-01, -3.3290e-02, -1.8178e+00, -8.3931e-01,  7.6195e-01,\n",
      "         8.5175e-01, -1.4090e+00, -1.0557e+00, -9.9997e-01, -4.0525e-01,\n",
      "        -6.1924e-01,  8.4830e-01, -1.4584e-01, -1.3974e+00, -3.3845e-02,\n",
      "        -1.1368e+00, -1.8989e+00, -1.1247e+00, -4.3428e-01, -1.2413e+00,\n",
      "        -8.4048e-01,  1.2070e+00, -2.2624e-01,  2.2889e-01,  8.2462e-01,\n",
      "        -1.3072e+00, -1.0171e+00,  3.8904e-01,  5.6129e-01, -1.2627e+00,\n",
      "        -7.8374e-01, -8.7461e-01, -1.0893e+00,  8.5211e-01, -1.0148e+00,\n",
      "        -2.4816e-01, -1.7020e+00, -1.1024e+00, -1.0648e-01,  9.5757e-01,\n",
      "        -7.5724e-01,  2.4801e-01, -1.1818e+00,  2.6606e-01, -1.1984e+00,\n",
      "        -1.5864e+00, -2.4053e+00, -1.3448e+00, -1.8470e+00, -8.6804e-02,\n",
      "        -6.0001e-01, -1.6666e+00,  6.4321e-01,  2.0422e-01, -1.5051e+00,\n",
      "         5.1960e-01, -5.0139e-01,  3.8239e-01, -2.5184e-01,  7.0552e-01,\n",
      "         1.3567e+00, -8.3650e-02, -2.0458e+00, -1.3324e+00, -9.7026e-02,\n",
      "        -3.6443e-01, -1.8777e+00, -1.0358e+00, -7.5092e-01,  2.3692e-01,\n",
      "        -8.7197e-01, -1.2159e+00,  1.1843e+00, -6.9029e-01, -1.5324e+00,\n",
      "         2.5577e-01,  6.6127e-01, -6.0659e-01,  4.1064e-01,  2.6905e-01,\n",
      "        -7.8531e-01, -3.0652e+00, -1.4726e+00,  7.7302e-01,  1.3803e-01,\n",
      "        -9.3230e-01,  2.7756e-01, -1.2315e+00,  2.4158e-01, -9.3968e-02,\n",
      "         3.0786e-02, -1.3863e+00,  1.6644e-01,  4.6393e-01, -7.0099e-01,\n",
      "         1.0266e+00, -8.8861e-01, -4.0334e-01, -9.0177e-01, -8.5743e-01,\n",
      "        -3.6113e-01,  7.9406e-01, -5.8108e-01,  2.9256e-01, -1.6801e+00,\n",
      "        -3.5962e-01, -9.1044e-01, -5.0920e-01,  2.5980e-01, -6.7291e-01,\n",
      "         8.9107e-03,  7.5638e-01, -1.9514e+00,  5.1547e-02, -1.6113e+00,\n",
      "         4.9192e-01, -1.3814e+00,  2.6526e-01,  8.4535e-01,  3.4844e-01,\n",
      "         1.2035e+00, -1.2514e+00, -1.3618e+00,  1.0072e+00, -1.7673e+00,\n",
      "        -9.3578e-01,  4.5782e-01,  5.2741e-01, -7.9134e-01,  7.2949e-01,\n",
      "         8.7771e-01,  5.0034e-01, -5.4467e-01, -3.6061e-01, -6.9975e-02,\n",
      "         7.3549e-01,  5.2892e-01,  1.4789e-01,  9.6197e-02, -1.2651e+00,\n",
      "         1.2404e-01,  8.7068e-01, -3.2859e-01, -2.3516e-02, -2.1394e+00,\n",
      "         2.1547e-01, -1.0525e+00, -3.4880e-02, -2.6525e-01,  4.4887e-01,\n",
      "         9.1277e-01,  5.2071e-01, -1.3288e+00, -1.0897e+00, -4.6045e-01,\n",
      "        -7.9358e-01, -1.2553e+00, -4.1658e-01, -1.5783e+00,  8.4402e-01,\n",
      "        -9.4410e-01, -9.8003e-01, -3.0336e-01, -7.6090e-01,  4.7315e-01,\n",
      "        -8.3945e-01, -1.7666e+00,  8.2017e-01, -1.4938e+00, -1.1967e+00,\n",
      "        -1.9801e+00, -3.5463e-01, -6.4260e-01, -1.0681e+00,  5.1730e-01,\n",
      "         3.5777e-01, -9.2716e-01, -5.0463e-01, -1.8934e+00,  1.3581e+00,\n",
      "        -1.4814e+00,  4.1546e-01, -1.1957e+00,  2.4632e-01,  1.6032e-01,\n",
      "        -9.6482e-01, -6.6925e-01, -1.7158e+00, -7.1151e-01,  5.2596e-01,\n",
      "         7.1914e-01,  5.5117e-01,  3.7009e-01,  2.6708e-01, -2.4557e+00,\n",
      "         1.3752e-01, -8.8236e-01, -1.5706e+00, -9.7621e-01, -6.3356e-01,\n",
      "        -7.6744e-01, -1.0821e-01, -1.8241e+00, -2.2076e-02, -7.9741e-01,\n",
      "         1.8197e+00,  2.0057e-01, -1.0175e+00, -7.2224e-01, -1.0802e-01,\n",
      "         1.8474e-01, -6.9362e-01,  5.8095e-01, -1.2500e+00, -1.3425e+00,\n",
      "        -1.2684e+00, -1.8294e-01,  1.4823e-01, -5.6364e-01, -3.4130e-01,\n",
      "         1.0561e+00, -1.7024e-01, -4.6044e-01, -7.5071e-01, -1.1448e+00,\n",
      "         1.1251e-01, -1.6149e+00,  1.2486e+00, -2.4726e-01,  2.2702e-01,\n",
      "        -1.5573e+00, -1.6524e+00, -7.3035e-01,  6.3813e-01, -2.6762e+00,\n",
      "        -9.0930e-01, -1.8806e+00, -8.0143e-01, -1.2886e+00, -3.3103e-01,\n",
      "        -1.2466e+00, -5.5231e-01, -3.4037e-01,  8.3215e-01,  3.3739e-01,\n",
      "        -2.7890e-01, -2.9159e-01, -1.5725e+00, -3.1691e-01, -3.8863e-01,\n",
      "        -1.0195e+00, -1.7386e+00,  6.3904e-01,  3.1995e-01, -1.4590e+00,\n",
      "        -1.2090e+00, -6.4953e-01, -7.9772e-01, -2.6891e+00, -9.1687e-01,\n",
      "         3.7983e-01, -5.2274e-01, -5.6428e-01,  1.6246e-01, -1.8280e+00,\n",
      "        -8.6606e-01,  8.9954e-01, -1.7471e+00, -1.0147e+00,  3.7168e-01,\n",
      "        -3.7436e-01,  9.7639e-01,  7.3196e-01, -1.1921e+00, -1.1044e+00,\n",
      "        -1.8047e+00, -5.8813e-01, -1.3839e+00, -2.8513e+00, -7.1711e-01,\n",
      "         7.0382e-01, -1.9349e+00,  9.7087e-01, -1.7349e+00,  1.0764e+00,\n",
      "         2.8457e-01,  8.1654e-01, -2.7641e-01, -1.0598e-01, -1.0431e+00,\n",
      "         4.1085e-01, -1.0403e-01,  2.9336e-02, -2.1844e+00, -6.2876e-01,\n",
      "        -2.2322e+00,  9.5862e-01, -1.2909e-01, -1.7345e+00, -2.2233e-01,\n",
      "        -7.7371e-01, -9.7497e-02, -2.2083e+00, -6.7224e-01,  1.2126e+00,\n",
      "        -5.5471e-01,  4.8422e-01, -3.4451e-01,  1.3044e+00, -2.1254e+00,\n",
      "         3.4135e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.6139, -0.1943, -0.2849],\n",
      "          [ 0.4630,  0.1003, -0.2348],\n",
      "          [-0.1749,  0.0620, -0.2052]]],\n",
      "\n",
      "\n",
      "        [[[-0.2869, -0.1465, -0.2140],\n",
      "          [-0.3532, -0.6079, -0.2601],\n",
      "          [-0.0751, -0.1815, -0.3597]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0914,  0.1364,  0.3796],\n",
      "          [-0.0232, -0.3844,  0.0963],\n",
      "          [ 0.7022,  0.0140, -0.0444]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6298,  0.0755,  0.5844],\n",
      "          [ 0.1352,  0.0434, -0.4722],\n",
      "          [ 0.1936, -0.2311, -0.1924]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2527,  0.0924,  0.3394],\n",
      "          [ 0.0803,  0.1632,  0.3113],\n",
      "          [-0.3668,  0.6182,  0.4614]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4108,  0.5690,  0.2159],\n",
      "          [ 0.1804, -0.2001, -0.2823],\n",
      "          [ 0.0145,  0.0947,  0.4479]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.4186e+00,  2.0417e+00,  1.3386e+00,  1.9063e+00,  1.1103e+00,\n",
      "         1.3224e+00,  9.1016e-01,  1.3311e+00,  9.2598e-01,  1.1077e+00,\n",
      "         1.4272e+00,  1.5181e+00,  1.3243e+00,  1.4692e+00,  9.3008e-01,\n",
      "         1.5336e+00,  1.5129e+00,  1.5139e+00,  1.5933e+00,  7.5858e-01,\n",
      "         9.9634e-01,  1.4172e+00,  1.4892e+00,  1.7404e+00,  6.2732e-01,\n",
      "         1.2774e+00,  1.3018e+00,  2.0016e+00,  9.1104e-01,  1.3069e+00,\n",
      "         1.9529e+00,  1.1919e+00,  1.7532e+00,  1.0582e+00,  1.9600e+00,\n",
      "         1.4177e+00,  2.9496e+00,  1.7389e+00,  2.2820e+00,  9.2628e-01,\n",
      "         1.7045e+00,  2.1485e+00,  2.6331e+00,  9.8464e-01,  8.1929e-01,\n",
      "         1.8205e+00,  1.4068e+00,  1.1684e+00,  1.2944e+00,  9.6989e-01,\n",
      "         1.0204e+00,  1.0151e+00,  2.0419e+00,  1.6878e+00,  1.8193e+00,\n",
      "         3.2628e+00,  2.0073e+00,  8.6978e-01,  1.3106e+00,  2.5538e-01,\n",
      "         1.5315e+00,  9.7417e-01,  2.0133e+00,  1.7685e+00,  1.3498e+00,\n",
      "         1.3914e+00,  1.0201e+00,  1.5982e+00,  1.7241e+00,  1.4253e+00,\n",
      "         1.2486e+00,  8.3555e-01,  1.0703e-01,  2.0843e+00,  1.3139e+00,\n",
      "         1.2774e+00,  1.7235e+00,  2.3197e+00,  9.1066e-01,  1.2200e+00,\n",
      "         1.6229e+00,  2.2334e+00,  1.7026e+00,  1.4449e+00,  1.8344e+00,\n",
      "         3.2332e-01,  1.8865e+00,  1.2735e+00,  1.0169e+00,  1.1409e+00,\n",
      "         1.2662e+00,  9.7055e-01,  1.0306e+00,  2.0636e+00,  1.4141e+00,\n",
      "         1.3396e+00,  1.5591e+00,  1.6103e+00,  1.1019e+00,  1.2455e+00,\n",
      "         1.5677e+00,  6.3613e-01,  1.5941e+00,  7.1005e-01,  1.1730e+00,\n",
      "         1.4437e+00,  7.4091e-01,  7.3724e-01,  1.1646e+00,  1.2685e+00,\n",
      "         1.0536e+00,  1.6275e+00,  1.2726e+00,  1.3665e+00,  7.1718e-01,\n",
      "         1.5437e+00,  1.1539e+00,  1.6143e+00,  1.8148e+00,  1.6634e+00,\n",
      "         1.8838e+00,  1.9824e+00,  1.5078e+00,  1.1823e+00,  1.7540e+00,\n",
      "         1.7404e+00,  2.9611e+00,  1.7270e+00,  1.0070e+00,  9.0934e-01,\n",
      "         1.2670e+00,  3.1716e+00,  1.2958e+00,  8.1928e-01,  8.2887e-01,\n",
      "         7.3084e-01,  2.2714e+00,  1.7099e+00,  3.9843e-01,  1.1779e+00,\n",
      "         2.2485e+00,  1.1738e+00,  1.7899e+00,  1.8949e+00,  1.2798e+00,\n",
      "         1.7395e+00,  1.5321e+00,  6.2445e-01,  1.6818e+00,  2.1981e+00,\n",
      "         1.1920e+00,  1.6689e+00,  1.9993e+00,  1.0918e+00,  1.2980e+00,\n",
      "         1.2748e+00,  1.0156e+00,  1.6193e+00,  1.1622e+00,  1.2725e+00,\n",
      "         1.2112e+00,  9.0090e-01,  3.0485e+00,  1.8572e+00,  1.3943e+00,\n",
      "         1.8514e+00,  1.9585e+00,  1.9299e+00,  2.1755e+00,  1.2997e+00,\n",
      "         1.4595e+00,  1.7683e+00,  1.3176e+00,  1.7186e+00,  1.5061e+00,\n",
      "         1.3520e+00,  2.1966e-03,  4.6918e-01,  1.1897e+00,  1.1776e+00,\n",
      "         1.5245e+00,  1.3862e+00,  1.8582e+00,  1.0620e+00,  2.7813e+00,\n",
      "         2.2188e-01,  1.9974e+00,  2.4332e+00,  7.5880e-01,  1.5198e+00,\n",
      "         3.0388e+00,  1.6786e+00,  1.7778e+00,  1.4277e+00,  1.2123e+00,\n",
      "         2.1173e+00,  1.5431e+00,  1.5512e+00,  8.7056e-01,  1.1002e+00,\n",
      "         1.7371e+00,  5.3727e-01,  1.5898e+00,  1.3019e+00,  1.1738e+00,\n",
      "         1.4361e+00,  1.6862e+00,  1.1332e+00,  8.1284e-01,  1.5116e+00,\n",
      "         1.9362e-01,  9.1432e-01,  6.1817e-01,  1.4600e+00,  1.7717e+00,\n",
      "         1.9762e+00,  1.6834e+00,  2.7221e+00,  8.6749e-01,  1.3819e+00,\n",
      "         1.5424e+00,  1.7816e+00,  8.9329e-01,  1.1102e+00,  1.9033e+00,\n",
      "         1.8821e-01,  1.1731e+00,  1.6292e+00,  1.3912e+00,  8.0742e-01,\n",
      "         2.0531e+00,  3.2271e+00,  1.6280e+00,  8.7585e-01,  2.3940e+00,\n",
      "         1.9063e+00,  1.9183e+00,  7.6783e-01,  1.1425e+00,  1.6705e+00,\n",
      "         1.2143e+00,  2.1534e+00,  1.2704e+00,  1.4477e+00,  7.1914e-01,\n",
      "         1.3266e+00,  1.0848e+00,  2.3979e+00,  1.7820e+00,  9.4979e-01,\n",
      "         1.7158e+00,  6.9426e-01,  1.3634e+00,  1.6996e+00,  1.1465e+00,\n",
      "         1.2943e+00,  1.2558e+00,  1.3036e+00,  2.3740e+00,  1.3284e+00,\n",
      "         1.2094e+00,  1.3271e+00,  7.1963e-01,  1.3485e+00,  9.9219e-01,\n",
      "         5.1451e-01,  1.6474e+00,  3.7015e+00,  1.4005e+00,  1.5165e+00,\n",
      "         1.4964e+00,  8.7318e-01,  2.0463e+00,  1.0658e+00,  1.2489e+00,\n",
      "         9.5441e-01,  1.6395e+00,  2.1734e+00,  2.1852e+00,  1.9962e+00,\n",
      "         1.9473e+00,  2.3737e+00,  1.6396e+00,  1.2308e+00,  2.7346e+00,\n",
      "         2.4659e+00,  1.6960e+00,  9.5514e-01,  1.3951e+00,  1.5132e+00,\n",
      "         8.9085e-01,  1.4745e+00,  1.6931e+00,  2.1235e+00,  2.0657e+00,\n",
      "         6.2579e-01,  1.6337e+00,  1.8365e+00,  1.2173e+00,  1.2532e+00,\n",
      "         2.4102e+00,  7.5114e-01,  1.3997e+00,  1.1671e+00,  2.3293e+00,\n",
      "         1.4319e+00,  1.3792e+00,  2.1222e+00,  1.2985e+00,  1.0776e+00,\n",
      "         7.9783e-01,  4.8076e+00,  1.5501e+00,  2.5117e-02,  8.7956e-01,\n",
      "         1.0100e+00,  1.7401e+00,  1.8850e+00,  1.3372e+00,  5.4209e-01,\n",
      "         2.0436e+00,  9.2563e-01,  1.0256e+00,  1.5324e+00,  2.0752e+00,\n",
      "         1.8646e+00,  1.3236e+00,  1.5766e+00,  3.1116e+00,  1.4747e+00,\n",
      "         4.0037e-01,  3.2126e+00,  1.2469e+00,  1.3363e+00,  1.9749e+00,\n",
      "         1.1888e+00,  8.8400e-01,  1.5857e+00,  2.0527e+00,  1.3640e+00,\n",
      "         1.2394e+00,  1.8317e+00,  1.2445e+00,  1.8693e+00,  9.6757e-01,\n",
      "         1.4928e+00,  2.1865e+00,  1.5585e+00,  9.4305e-01,  1.8009e+00,\n",
      "         1.4737e+00,  2.1156e+00,  1.2371e+00,  1.6455e+00,  1.1787e+00,\n",
      "         9.4114e-01,  4.3689e-01,  1.4247e+00,  1.9400e+00,  1.9141e+00,\n",
      "         2.6464e+00,  2.1325e+00,  1.5826e+00,  1.6886e+00,  1.1786e+00,\n",
      "         8.0669e-01,  1.7280e+00,  1.1080e+00,  1.2504e+00,  5.8522e-01,\n",
      "         1.2452e+00,  1.5099e+00,  8.8965e-01,  1.0479e+00,  1.1639e+00,\n",
      "         1.6936e+00,  1.8153e+00,  9.6081e-01,  1.1040e+00,  1.5188e+00,\n",
      "         1.4643e+00,  1.2817e+00,  2.1462e+00,  1.6757e+00,  1.5946e+00,\n",
      "         1.7436e+00,  1.1374e+00,  1.8001e+00,  1.8926e+00,  7.0308e-01,\n",
      "         1.3207e+00,  1.7275e+00,  1.7517e+00,  1.6656e+00,  2.0059e+00,\n",
      "         1.6169e+00,  1.7810e+00,  1.8880e+00,  1.3393e+00,  1.3398e+00,\n",
      "         1.3466e+00,  1.5406e+00,  1.1752e+00,  8.3610e-01,  1.6210e+00,\n",
      "         2.2339e+00,  1.5698e+00,  1.0726e+00, -4.4526e-02,  4.3487e+00,\n",
      "         3.1993e+00,  6.0201e-01,  1.7228e+00,  1.7618e+00,  2.2076e+00,\n",
      "         1.4229e+00,  1.7800e+00,  7.1645e-01,  1.2297e+00,  1.4222e+00,\n",
      "         1.6911e+00,  2.6683e+00,  1.3019e+00,  1.5442e+00,  1.9038e+00,\n",
      "         8.1896e-01,  2.1354e+00,  1.8870e+00,  1.2606e+00,  1.7660e+00,\n",
      "         1.3648e+00,  9.9517e-01,  1.6604e+00,  1.1075e+00,  1.8308e+00,\n",
      "         1.7578e+00,  7.4753e-01,  5.6186e-01,  6.0512e-01,  1.2268e+00,\n",
      "         1.1839e+00,  8.4914e-01,  1.5165e+00,  9.7204e-01,  1.7760e+00,\n",
      "         8.3371e-01,  1.7708e+00,  1.4964e+00,  1.1913e+00,  1.2607e+00,\n",
      "         1.0393e+00,  5.4931e-01,  1.4707e+00,  1.9126e+00,  1.8189e+00,\n",
      "         2.3076e+00,  1.8210e+00,  1.3512e+00,  1.8981e+00,  3.0224e+00,\n",
      "         1.8133e+00,  2.1388e+00,  2.1249e+00,  2.3671e+00,  1.4155e+00,\n",
      "         7.7970e-01,  1.5571e+00,  4.4511e+00,  1.0079e+00,  2.0571e+00,\n",
      "         2.9978e+00,  1.4399e+00,  1.2660e+00,  1.4468e+00,  1.2084e+00,\n",
      "         1.9088e+00,  1.9777e+00,  6.3749e-01,  1.9660e+00,  1.0028e+00,\n",
      "         1.1203e+00,  7.5809e-03,  1.6307e+00,  1.0815e+00,  1.6390e+00,\n",
      "         2.0865e+00,  1.0128e+00,  1.7641e+00,  8.7518e-01,  2.4087e+00,\n",
      "         1.6382e+00,  1.1649e+00,  1.6379e+00,  1.4131e+00,  1.5068e+00,\n",
      "         7.9164e-01,  1.0511e+00,  1.8294e+00,  1.6586e+00,  3.9155e+00,\n",
      "         1.5462e+00,  8.2986e-01,  1.5755e+00,  9.0757e-01,  1.6809e+00,\n",
      "         8.1474e-01,  1.7667e+00,  8.6066e-01,  2.0645e+00,  1.6948e+00,\n",
      "         1.5728e+00,  1.9162e+00,  9.5050e-01,  1.2626e+00,  1.2868e+00,\n",
      "         2.4673e+00,  3.2590e+00,  9.9959e-01,  1.8598e+00,  4.2718e-01,\n",
      "         8.1734e-01,  1.3699e+00,  1.8882e+00,  1.5386e+00,  1.1759e+00,\n",
      "         1.5257e+00,  1.3639e+00,  1.2601e+00,  2.1866e+00,  1.1651e+00,\n",
      "         9.2589e-01,  1.6980e+00,  3.0889e-01, -6.7567e-02,  1.1997e+00,\n",
      "         1.7855e+00,  1.7413e+00,  1.7965e+00,  1.0486e+00,  6.2916e-01,\n",
      "         1.2779e+00,  1.1517e+00,  1.7272e+00,  2.5900e+00,  2.4391e+00,\n",
      "         1.3906e+00,  6.0369e-01,  1.9912e+00,  8.2485e-01,  1.7159e+00,\n",
      "         1.5599e+00,  1.5706e+00,  1.1803e+00,  1.4280e+00,  1.1401e+00,\n",
      "         1.5271e+00,  1.1749e+00,  8.8813e-01,  1.4428e+00,  6.0978e-01,\n",
      "         1.1504e+00,  1.8783e+00,  1.7086e+00,  1.3441e+00,  1.3054e+00,\n",
      "         1.2771e+00,  1.7961e+00,  3.4878e+00,  1.1318e+00,  2.5323e+00,\n",
      "         1.9739e+00,  6.2896e-01,  1.1592e+00,  1.7064e+00,  7.8005e-01,\n",
      "         1.6731e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.1727e+00, -7.5584e-01, -2.2335e+00, -1.2407e+00, -1.0799e+00,\n",
      "        -2.1545e+00, -1.3864e-01, -5.1533e-01,  4.0653e-02, -3.4451e-01,\n",
      "        -9.3929e-01, -8.0537e-01, -1.0240e+00, -5.6621e-01, -4.9496e-01,\n",
      "        -1.8159e+00, -1.0990e+00, -1.4843e+00, -1.2301e+00, -4.1793e-01,\n",
      "        -3.9238e-01, -7.0161e-01, -8.4210e-01, -1.1881e+00, -1.6992e-01,\n",
      "        -4.9904e-01, -3.1253e-01, -1.7815e+00, -1.2787e+00, -1.4078e+00,\n",
      "        -8.2504e-01, -9.0793e-01, -7.0336e-01, -5.7550e-01, -2.1115e+00,\n",
      "        -2.2342e+00, -1.1341e+00, -1.4861e+00, -1.5541e+00, -7.2518e-01,\n",
      "        -1.1334e+00, -1.3078e+00, -1.1017e+00,  1.0467e-01, -2.4355e+00,\n",
      "        -1.4138e+00, -1.2006e+00, -1.1248e+00, -8.5841e-02, -2.7302e+00,\n",
      "        -1.0666e+00, -1.0853e+00, -1.5194e+00, -8.0395e-01, -1.1243e+00,\n",
      "         3.5431e-02, -1.7241e+00, -1.8267e+00, -9.8250e-01,  4.8190e-01,\n",
      "        -1.2899e+00, -7.2886e-01, -7.4722e-01, -8.1295e-01, -1.7942e+00,\n",
      "        -1.4581e+00, -1.8324e+00, -1.3060e+00, -4.8960e-01, -1.0334e+00,\n",
      "        -5.6349e-01, -2.2466e-01, -7.9490e-02, -1.3471e+00, -7.3908e-01,\n",
      "        -6.7357e-02, -3.3720e-01, -1.6058e+00, -2.3150e+00, -8.3635e-01,\n",
      "        -3.0284e+00, -3.9520e-01, -6.4896e-01, -5.6890e-01, -8.0737e-01,\n",
      "        -1.2343e-01, -1.1493e+00, -1.4763e+00, -1.4702e-01, -3.3235e-01,\n",
      "        -1.4806e+00, -2.5672e-01, -8.9708e-01, -5.7246e-01, -1.8334e+00,\n",
      "        -6.1445e-01, -2.6052e-01, -1.9725e+00, -1.2776e+00, -9.9886e-01,\n",
      "        -1.3339e+00, -9.4580e-02, -7.8845e-01, -4.3015e-01, -6.8267e-02,\n",
      "        -1.6474e+00, -1.9152e-02,  2.3109e-01, -6.1169e-01, -1.3103e+00,\n",
      "        -8.5271e-01, -1.7065e+00, -1.3106e+00, -2.3643e+00, -9.9588e-02,\n",
      "        -6.9590e-01, -2.3377e-01, -1.4759e+00, -1.7052e+00, -7.4269e-01,\n",
      "        -1.3404e+00, -1.3793e+00, -9.6419e-01, -8.5274e-01, -7.6995e-01,\n",
      "        -1.1715e+00, -2.2284e+00, -4.0292e-01,  3.3178e-01, -9.8697e-03,\n",
      "        -5.0346e-01,  7.0113e-01, -3.5645e-01, -2.0656e+00, -8.6698e-03,\n",
      "        -1.0511e+00, -1.2418e+00, -1.4072e+00, -2.4107e-01, -3.4555e-02,\n",
      "        -1.2762e+00, -2.1719e+00, -1.7044e+00, -1.2695e+00, -1.4328e+00,\n",
      "        -1.7095e+00, -1.2204e+00, -3.2429e-01, -7.7843e-01, -1.8093e+00,\n",
      "        -2.9216e+00, -1.5736e+00, -1.0608e+00, -6.7333e-01, -3.2518e-01,\n",
      "        -7.3093e-01, -5.0269e-01, -7.9879e-01,  3.1502e-01, -1.2528e+00,\n",
      "        -6.1624e-01, -1.1744e+00, -2.7479e-01, -1.4892e+00, -9.5817e-01,\n",
      "        -1.1220e+00, -9.8637e-01, -1.8360e+00, -2.5831e-02, -6.8020e-01,\n",
      "        -9.5869e-01, -2.1603e+00, -2.0220e+00, -2.2635e+00, -1.1405e+00,\n",
      "        -3.3081e+00, -1.4299e-01, -1.4008e-01, -2.2363e+00, -2.6993e-01,\n",
      "        -1.2572e+00, -9.5011e-01, -1.3299e+00, -1.3265e+00, -5.6289e-01,\n",
      "        -2.7422e+00, -1.0850e+00,  6.8318e-01, -2.5345e-01, -5.7469e-01,\n",
      "         1.0102e+00, -6.8489e-01,  5.2915e-01, -1.8327e+00, -1.3063e+00,\n",
      "        -1.1177e+00, -3.9271e-01, -1.3324e+00, -2.6099e-01, -4.7972e-01,\n",
      "        -1.8862e+00, -7.0710e-02, -1.0516e+00, -2.1483e-01, -1.5019e+00,\n",
      "        -6.9175e-01, -1.1769e+00, -1.1080e+00, -1.0070e+00, -3.4400e-01,\n",
      "         9.2208e-01, -7.2576e-01, -1.6034e-01, -1.9910e+00, -1.4342e+00,\n",
      "        -3.0000e+00, -5.6890e-01, -7.7911e-01, -1.2555e-01, -1.0430e+00,\n",
      "        -1.5317e+00, -1.4085e+00, -2.4794e+00, -7.6096e-01, -7.8312e-01,\n",
      "        -2.0848e-01, -1.0906e-03, -7.3667e-01, -1.3738e+00,  1.5409e-01,\n",
      "        -6.0330e-01,  3.1494e-01, -2.2968e-01, -1.9539e-01, -5.8739e-01,\n",
      "        -8.4092e-03, -1.3452e+00, -3.2814e-01, -1.5733e+00, -1.6564e+00,\n",
      "        -1.7679e+00, -3.2891e-01, -3.9764e-01, -5.4989e-01, -3.0966e-01,\n",
      "        -8.2944e-01, -2.8538e-01, -1.5581e+00, -5.0673e-01, -5.8104e-01,\n",
      "        -7.9240e-01, -5.2376e-02, -3.5091e-01, -1.7002e+00, -1.0012e+00,\n",
      "        -8.7584e-01, -1.1654e+00, -6.2059e-01, -1.0285e+00, -2.1398e+00,\n",
      "        -2.5951e+00, -1.4339e+00, -3.1064e-01, -2.9656e-01, -1.5691e+00,\n",
      "        -3.7819e-01, -1.2128e+00,  2.0839e-01, -2.4787e+00, -1.4004e+00,\n",
      "        -8.6730e-01, -5.1808e-01, -8.5641e-01, -3.0362e-01, -4.0334e-01,\n",
      "        -1.1233e+00, -8.4195e-01, -1.4111e+00, -1.9546e-01, -2.4310e+00,\n",
      "        -8.8975e-02, -2.3852e-01, -2.3464e+00, -2.3596e+00, -3.4484e-01,\n",
      "         2.5822e-01, -1.4075e+00, -5.9483e-01, -8.2782e-01, -1.6000e+00,\n",
      "        -2.2402e+00, -6.8723e-01, -1.7504e+00, -2.2131e-01, -9.6640e-01,\n",
      "        -9.3529e-02, -9.5924e-02, -1.6665e+00, -1.3724e+00, -1.4784e+00,\n",
      "        -6.2332e-01, -1.7119e-01,  1.9708e-01, -8.2063e-01, -1.7934e+00,\n",
      "        -7.5628e-01, -2.8304e+00, -1.0690e+00, -1.2110e+00,  3.8174e-01,\n",
      "        -1.8797e-01, -3.4484e-02, -2.0358e+00,  2.7311e-01, -4.1324e-01,\n",
      "        -5.5290e-01, -8.6689e-01, -1.1150e+00, -5.8949e-02, -1.1213e-01,\n",
      "        -1.1932e+00, -9.4841e-01, -8.1454e-01, -7.7676e-01, -1.3522e+00,\n",
      "        -1.3205e+00, -1.4174e+00, -1.1478e+00, -4.2185e-02, -8.0848e-01,\n",
      "        -1.6126e-01, -2.1460e-01, -8.5552e-01, -7.5802e-01, -8.3219e-01,\n",
      "        -5.8130e-01,  1.1708e-01, -1.7471e+00, -1.2241e-01,  1.0473e-01,\n",
      "        -1.2154e+00, -2.0391e+00, -2.1699e+00, -1.0071e+00, -4.6533e-01,\n",
      "        -1.9338e+00, -1.3169e+00, -5.8772e-01, -3.6068e-01, -8.0660e-01,\n",
      "        -1.4600e+00, -1.2109e+00, -2.5153e-01, -1.9971e+00, -4.7295e-01,\n",
      "        -4.6741e-01, -4.8192e-03, -6.6442e-01, -1.5258e+00, -7.3258e-01,\n",
      "        -9.9871e-02, -2.8497e+00, -2.1290e-02, -4.1183e-01, -3.9354e-01,\n",
      "        -5.3092e-01, -1.6127e+00, -1.0937e+00, -4.4050e-01, -4.5451e-02,\n",
      "        -3.2146e-01, -2.3841e+00, -2.8303e+00, -1.8943e+00, -5.9002e-01,\n",
      "        -9.6471e-01, -1.8748e+00, -9.8808e-01, -8.5558e-01, -1.2610e+00,\n",
      "        -1.6432e+00, -2.0040e+00, -2.0826e+00, -5.7013e-01, -1.0059e+00,\n",
      "        -1.4463e+00, -3.7939e-01, -1.4291e+00, -1.5990e+00, -1.3370e-01,\n",
      "        -5.9966e-01, -1.0943e+00,  9.3381e-01, -6.8143e-01, -1.3784e+00,\n",
      "        -1.2232e+00, -1.3762e+00, -1.0194e+00, -1.1084e+00, -5.8789e-01,\n",
      "        -2.5360e+00, -1.7866e+00, -9.4926e-01, -8.2968e-01, -4.0186e-01,\n",
      "        -8.6221e-01, -1.4785e+00, -3.5102e-01,  4.2384e-02,  4.1785e-01,\n",
      "        -1.8924e+00, -3.2068e-01, -1.3819e+00, -9.0340e-01, -1.3307e+00,\n",
      "        -1.1710e+00, -1.4979e+00, -1.3019e-01, -1.6264e+00, -8.2762e-01,\n",
      "        -1.9123e+00,  2.2529e-02, -5.9279e-01, -6.2588e-01, -8.9232e-01,\n",
      "        -1.3630e+00,  3.0492e-02, -7.1212e-01, -1.2563e+00, -8.5548e-01,\n",
      "        -1.4699e+00, -4.1225e-01, -1.3846e+00, -2.9405e-01, -1.6926e+00,\n",
      "        -2.6942e-01, -2.3033e-01, -2.6121e-01, -1.6850e-01, -8.3362e-01,\n",
      "        -1.5397e+00, -5.3079e-01, -6.2236e-02, -1.2861e+00, -2.6925e+00,\n",
      "        -2.1405e-01, -1.2357e+00, -3.7826e-01, -3.0280e-01, -7.2896e-01,\n",
      "        -3.9989e-01,  1.6129e-01, -3.7168e-01, -2.2563e+00, -1.2490e+00,\n",
      "        -9.0552e-01, -1.5031e+00, -1.1041e+00, -1.4113e+00, -7.3873e-01,\n",
      "        -1.2623e+00, -6.1975e-01, -2.5249e+00, -7.0543e-01, -4.7904e-01,\n",
      "        -3.8654e-01, -2.3571e-01,  1.0655e+00, -4.5783e-01, -4.0222e-01,\n",
      "        -3.2290e+00, -6.2664e-01, -1.9587e+00, -1.9799e+00, -7.2852e-01,\n",
      "        -1.9704e+00, -1.1465e-01,  4.6126e-03, -7.9595e-01,  4.6374e-01,\n",
      "        -3.5715e-01, -4.9018e-02, -7.2399e-01, -5.5594e-01, -1.5437e+00,\n",
      "        -1.3226e+00, -3.6883e-01, -1.2708e+00, -8.2288e-01, -1.0716e+00,\n",
      "        -1.3795e+00, -1.8768e-01, -1.1120e+00, -9.3224e-01, -2.2441e+00,\n",
      "        -6.1088e-02, -4.0698e-01, -5.3902e-01, -1.3694e+00, -7.4737e-02,\n",
      "        -7.9565e-01,  1.5067e+00, -6.2654e-01, -3.7777e-02, -3.1142e-01,\n",
      "        -2.0528e-01,  8.4124e-02, -6.1839e-01, -1.0708e+00, -2.1759e+00,\n",
      "        -1.6813e+00, -2.6018e+00, -2.3840e-01, -7.6213e-01, -1.6815e+00,\n",
      "        -7.9119e-01, -4.3985e-01, -5.1289e-01, -1.1904e+00,  3.0636e-02,\n",
      "        -8.9303e-02, -2.1494e+00, -1.7160e+00, -4.4033e-03, -2.3778e+00,\n",
      "        -1.8153e+00, -3.4487e-01, -1.3243e+00, -2.0035e-01, -7.9300e-01,\n",
      "        -4.9478e-01, -1.0996e+00, -1.3339e-01, -5.9543e-03, -1.1203e+00,\n",
      "         2.1393e-01, -8.5447e-01, -1.5500e+00, -3.8154e-01, -1.4399e-01,\n",
      "        -6.9708e-02, -8.2696e-02, -1.5309e+00, -1.1041e+00, -1.9316e-01,\n",
      "        -1.3289e+00, -6.8011e-02, -5.3523e-01, -2.2141e-01, -1.7348e+00,\n",
      "        -8.7359e-01, -1.3959e+00, -2.0568e+00, -1.9317e+00, -3.3906e-01,\n",
      "        -7.4651e-01, -2.8314e+00, -2.9069e-01,  5.7053e-01, -5.8388e-01,\n",
      "        -1.2802e+00, -1.5107e+00, -1.1099e+00, -4.7895e-01, -1.5054e+00,\n",
      "        -1.7208e+00, -4.4873e-01, -4.0819e-01, -3.6264e-01, -9.7847e-01,\n",
      "        -1.6539e+00, -2.9278e-01, -1.0399e+00, -1.4101e+00, -3.0001e-01,\n",
      "        -1.3503e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0674]],\n",
      "\n",
      "         [[ 0.1431]],\n",
      "\n",
      "         [[-0.2486]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0514]],\n",
      "\n",
      "         [[-0.2446]],\n",
      "\n",
      "         [[-0.2869]]],\n",
      "\n",
      "\n",
      "        [[[-0.0780]],\n",
      "\n",
      "         [[ 0.2200]],\n",
      "\n",
      "         [[ 0.1387]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2595]],\n",
      "\n",
      "         [[-0.0692]],\n",
      "\n",
      "         [[ 0.1584]]],\n",
      "\n",
      "\n",
      "        [[[-0.0922]],\n",
      "\n",
      "         [[-0.1945]],\n",
      "\n",
      "         [[ 0.0977]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0394]],\n",
      "\n",
      "         [[-0.4417]],\n",
      "\n",
      "         [[-0.3098]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0909]],\n",
      "\n",
      "         [[ 0.0989]],\n",
      "\n",
      "         [[-0.1429]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1674]],\n",
      "\n",
      "         [[ 0.0438]],\n",
      "\n",
      "         [[ 0.2156]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3837]],\n",
      "\n",
      "         [[-0.1464]],\n",
      "\n",
      "         [[ 0.2393]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3423]],\n",
      "\n",
      "         [[ 0.5932]],\n",
      "\n",
      "         [[ 0.2606]]],\n",
      "\n",
      "\n",
      "        [[[-0.0679]],\n",
      "\n",
      "         [[ 0.2352]],\n",
      "\n",
      "         [[ 0.0621]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3775]],\n",
      "\n",
      "         [[-0.0520]],\n",
      "\n",
      "         [[ 0.2213]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1651,  0.0476, -0.0182,  0.1254,  0.0542, -0.2310, -0.3744,  0.0691,\n",
      "         0.3525, -0.0994,  0.0856,  0.0044,  0.0885, -0.3135,  0.1875, -0.0211,\n",
      "         0.0705,  0.1454,  0.2129, -0.1825,  0.2142,  0.0771,  0.0457,  0.0582],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.1565]],\n",
      "\n",
      "         [[-0.2607]],\n",
      "\n",
      "         [[-0.0189]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0376]],\n",
      "\n",
      "         [[ 0.1056]],\n",
      "\n",
      "         [[ 0.1456]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4365]],\n",
      "\n",
      "         [[ 0.1358]],\n",
      "\n",
      "         [[-0.1725]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4717]],\n",
      "\n",
      "         [[ 0.0270]],\n",
      "\n",
      "         [[ 0.1755]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1322]],\n",
      "\n",
      "         [[ 0.0619]],\n",
      "\n",
      "         [[ 0.0161]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2512]],\n",
      "\n",
      "         [[-0.2644]],\n",
      "\n",
      "         [[ 0.3150]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3017]],\n",
      "\n",
      "         [[ 0.3494]],\n",
      "\n",
      "         [[-0.1244]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0164]],\n",
      "\n",
      "         [[ 0.1448]],\n",
      "\n",
      "         [[ 0.5182]]],\n",
      "\n",
      "\n",
      "        [[[-0.1643]],\n",
      "\n",
      "         [[ 0.0262]],\n",
      "\n",
      "         [[-0.3218]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1462]],\n",
      "\n",
      "         [[-0.7535]],\n",
      "\n",
      "         [[ 0.0249]]],\n",
      "\n",
      "\n",
      "        [[[-0.4196]],\n",
      "\n",
      "         [[-0.3278]],\n",
      "\n",
      "         [[-0.2630]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2828]],\n",
      "\n",
      "         [[-0.0920]],\n",
      "\n",
      "         [[-0.3406]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.6028e-01, -4.7343e-02, -1.0540e-01, -2.1770e-01, -4.1111e-01,\n",
      "         4.0114e-01,  2.6668e-01,  3.3463e-02,  5.2735e-02,  1.1114e-01,\n",
      "        -5.8056e-01, -1.2952e-01, -2.4620e-01, -8.9049e-03,  2.5966e-01,\n",
      "        -5.0755e-01,  3.3297e-01, -5.9320e-02,  2.9614e-01, -3.6240e-01,\n",
      "        -2.4947e-01, -6.9121e-02,  2.3374e-01,  3.7466e-01, -3.2372e-01,\n",
      "        -1.7290e-01, -1.3218e-01,  3.4806e-01, -9.9802e-02, -3.1805e-01,\n",
      "         1.7189e-01, -2.3328e-01,  5.7555e-01, -1.4253e-01, -1.7216e-01,\n",
      "        -1.6975e-01, -3.2231e-01, -4.7156e-01, -3.2279e-02, -2.3170e-01,\n",
      "         3.1406e-01,  4.8879e-01,  3.4699e-02,  1.0318e-01, -1.3118e-01,\n",
      "         3.8490e-01,  6.2168e-04,  7.1961e-03,  3.8757e-01, -1.9779e-01,\n",
      "        -4.7863e-01,  4.5765e-02,  3.8930e-01, -3.1086e-01,  5.5790e-01,\n",
      "        -1.6673e-01,  3.7036e-01,  3.2159e-01, -3.1082e-01,  4.5743e-01,\n",
      "        -1.0857e-01, -5.8846e-02,  1.2076e-01,  2.8939e-01,  4.0375e-02,\n",
      "        -1.6770e-01, -8.3446e-03, -2.6825e-01,  4.1543e-01, -2.2604e-01,\n",
      "        -2.5036e-01, -4.0576e-01, -3.1171e-01, -3.9924e-02, -4.2286e-01,\n",
      "         4.9868e-01,  4.7833e-01, -1.3532e-01, -1.5837e-01, -1.2041e-01,\n",
      "         4.5900e-01,  3.0029e-02, -2.0829e-01, -3.3381e-01, -1.8696e-01,\n",
      "        -5.6586e-01,  1.3620e-01,  1.1325e-01, -8.0259e-02,  3.9505e-01,\n",
      "        -1.1429e-01,  4.3056e-02, -2.5711e-01,  1.9984e-01,  3.3955e-01,\n",
      "        -6.9401e-02,  4.9079e-01,  3.2197e-01, -7.8668e-02,  1.0564e-01,\n",
      "         7.4635e-03, -2.0709e-02, -1.9426e-01,  4.5455e-01,  1.0525e-01,\n",
      "        -2.6984e-01, -4.9728e-01,  5.0607e-01,  9.3978e-02,  2.7107e-02,\n",
      "         1.5453e-01, -3.0375e-01,  6.8304e-02,  1.2039e-01,  4.7105e-01,\n",
      "         2.2128e-01,  2.8412e-01, -3.7748e-02,  2.6632e-01, -1.1989e-01,\n",
      "         1.1285e-01,  5.8036e-01, -1.5945e-01, -2.2003e-01,  3.1353e-01,\n",
      "         2.6647e-01,  3.4043e-01,  1.5037e-01, -7.2910e-02,  1.1729e-01,\n",
      "        -1.5776e-01,  2.2111e-01,  2.0577e-02,  1.4813e-01, -1.6860e-01,\n",
      "        -3.0042e-01, -4.0244e-01, -7.0042e-02, -9.9721e-02, -2.0014e-01,\n",
      "         2.6409e-01,  3.5809e-01,  4.9443e-01,  1.2348e-01,  2.8433e-02,\n",
      "         1.8574e-01,  5.4522e-02, -3.2853e-01, -2.4535e-01, -2.7180e-02,\n",
      "         3.3829e-01, -1.7872e-01,  3.2469e-01, -1.7611e-01,  6.7491e-03,\n",
      "        -1.4239e-01, -4.9565e-01,  4.2705e-02, -1.3830e-01,  1.3796e-03,\n",
      "        -1.0543e-01, -3.4086e-01,  2.1906e-01,  2.2960e-01,  6.0546e-02,\n",
      "         4.8707e-01,  1.1849e-01,  6.4465e-01,  2.6310e-02, -7.9638e-02,\n",
      "         3.6863e-01,  3.9229e-01, -1.9641e-01,  1.1350e-01,  5.9341e-02,\n",
      "         4.1820e-01, -2.5257e-01, -2.0271e-01,  5.1522e-01, -1.1097e-01,\n",
      "        -2.7827e-01, -7.6894e-02, -1.8084e-01,  7.4887e-02,  3.0786e-01,\n",
      "         4.9171e-01,  2.6385e-01,  3.1746e-01, -5.6181e-01, -7.0782e-02,\n",
      "        -1.5070e-01,  4.5883e-01,  2.7993e-01,  4.5557e-02, -1.6013e-01,\n",
      "         5.5318e-01, -1.1731e-01,  2.9771e-01, -3.2582e-01,  7.4178e-02,\n",
      "         4.1530e-01,  5.5897e-02, -4.4631e-01,  2.9376e-01,  1.8695e-01,\n",
      "        -1.0583e-01, -2.7971e-01, -2.6976e-01, -1.2704e-01,  4.4788e-01,\n",
      "        -1.4749e-01, -6.0849e-02,  1.6002e-01,  3.1269e-01, -2.6618e-01,\n",
      "         2.5710e-01,  1.7151e-01, -8.9254e-02, -1.5122e-01, -4.8451e-02,\n",
      "        -1.9598e-01,  1.9918e-01, -3.5247e-01,  2.2488e-01, -4.2698e-02,\n",
      "        -2.6341e-01,  1.2947e-01,  5.5058e-01, -1.4076e-01,  4.7795e-01,\n",
      "        -1.0862e-01, -4.9863e-01, -1.2805e-01, -4.4488e-01, -1.2303e-01,\n",
      "        -3.5657e-01,  3.8122e-01, -3.4560e-01, -2.2397e-01, -3.4455e-01,\n",
      "         1.9401e-01,  4.7885e-01, -1.4456e-02,  4.2855e-02,  3.0934e-02,\n",
      "         4.3754e-01,  1.0771e-01,  3.9814e-01, -3.8910e-01, -3.5451e-01,\n",
      "         2.4954e-02, -1.7487e-01, -1.0975e-01, -3.7294e-01, -5.4291e-01,\n",
      "        -5.6755e-01, -1.9672e-01,  2.1629e-01,  1.1586e-01,  3.4755e-01,\n",
      "         8.9877e-02,  2.1136e-01,  1.1281e-01, -9.2061e-02,  3.3007e-01,\n",
      "        -2.4960e-01,  2.4208e-01, -1.0038e-01,  1.9806e-01, -1.6721e-01,\n",
      "        -2.4716e-02,  7.0151e-02,  5.2062e-04, -6.4909e-02, -1.3059e-01,\n",
      "         4.2052e-01,  5.9816e-02,  4.9411e-01,  3.7953e-01,  9.7463e-02,\n",
      "         1.6836e-01,  1.1135e-01,  6.0809e-01,  1.8574e-01, -3.5598e-01,\n",
      "         3.9319e-01, -2.2679e-01, -2.2769e-01, -3.4022e-01, -3.4219e-01,\n",
      "         1.7962e-01,  2.4178e-02, -9.2998e-02,  1.4175e-01, -2.8434e-01,\n",
      "         5.0802e-01,  1.9680e-01, -3.1022e-01,  2.5985e-02,  1.2112e-01,\n",
      "         3.6445e-01,  1.0660e-01,  2.5005e-01, -9.8478e-02,  2.6557e-01,\n",
      "        -8.3055e-03,  5.0669e-01, -2.2683e-01,  3.8589e-01,  5.7730e-02,\n",
      "         5.8129e-02, -9.8064e-02,  1.2951e-01, -2.2242e-01,  1.3521e-01,\n",
      "        -1.4207e-01, -6.7556e-02,  4.9407e-02, -2.4070e-01, -4.4917e-01,\n",
      "         5.4696e-01,  7.5622e-02, -4.0748e-01, -3.5994e-02,  1.5045e-01,\n",
      "         5.2870e-01, -7.1825e-02, -2.5407e-01,  6.8892e-01, -3.1732e-01,\n",
      "        -6.1029e-01, -1.1006e-01, -9.8941e-02,  1.1017e-01,  1.3133e-01,\n",
      "        -3.2878e-01, -7.4569e-02,  3.4998e-01,  2.2654e-01,  5.7500e-01,\n",
      "        -2.0376e-01, -5.6969e-02,  1.3238e-01, -1.4138e-01, -4.2193e-01,\n",
      "         2.6517e-01, -2.9506e-01,  1.9531e-01, -2.1591e-01, -3.0147e-01,\n",
      "         1.7860e-01,  5.4503e-01, -1.2671e-01,  3.6077e-01, -3.9800e-02,\n",
      "        -1.6134e-01,  4.1544e-01,  1.1868e-01,  3.9008e-01, -8.4356e-02,\n",
      "         1.0637e-01, -6.2152e-02, -5.1735e-01, -3.5405e-01,  3.1326e-01,\n",
      "        -3.4465e-02, -1.5637e-01, -3.4704e-01, -1.1688e-01,  3.2193e-01,\n",
      "        -4.5723e-01,  4.5350e-02, -1.9844e-01,  4.9512e-01, -1.9375e-01,\n",
      "         4.0763e-01,  8.3576e-02, -4.6805e-03, -6.2627e-02,  1.1673e-01,\n",
      "        -1.2385e-01,  2.5019e-01,  3.0421e-02,  2.1346e-01,  5.5728e-02,\n",
      "         2.0794e-01, -1.3501e-01,  5.4306e-02,  4.0175e-01,  8.5819e-02,\n",
      "        -8.0295e-02,  3.0222e-01,  3.1236e-02, -7.0558e-02,  8.6160e-02,\n",
      "        -4.7167e-01,  1.9709e-01,  3.9509e-01, -2.2417e-01, -8.3797e-02,\n",
      "        -4.6851e-01, -1.4928e-01, -3.7694e-01, -3.9501e-01,  9.0129e-02,\n",
      "         1.0998e-01,  1.1345e-01, -5.8864e-01, -5.2786e-01,  2.1350e-02,\n",
      "         5.6316e-01, -7.9193e-02,  2.5382e-01, -2.8765e-01,  4.0147e-01,\n",
      "         3.5400e-01,  1.0214e-01,  2.2492e-01, -5.5643e-02,  4.2204e-02,\n",
      "        -4.5996e-02,  5.1098e-02, -1.2305e-01,  1.6976e-01, -1.6494e-01,\n",
      "        -4.2990e-02,  1.3166e-01,  3.5432e-01,  1.3199e-01, -2.3329e-01,\n",
      "        -2.0949e-01, -1.2317e-01,  4.6201e-01,  3.3377e-02,  5.3278e-01,\n",
      "        -3.3053e-01,  8.4424e-02, -4.0924e-01, -3.1992e-01, -7.2791e-02,\n",
      "         3.5017e-02, -3.0025e-01, -2.9623e-01,  3.4199e-01,  2.5081e-01,\n",
      "        -2.9407e-01,  1.0112e-01,  1.2614e-01,  1.0140e-01, -5.1857e-01,\n",
      "        -4.3658e-01,  1.3995e-01,  2.9585e-01,  4.1052e-01, -3.0211e-01,\n",
      "         3.8311e-01, -2.0992e-01, -2.8426e-01, -3.3119e-01, -6.2612e-01,\n",
      "         3.5532e-01, -4.6050e-01, -2.7183e-01,  1.1124e-01, -3.7156e-01,\n",
      "        -3.7540e-01, -2.5864e-01, -3.8445e-01,  2.7433e-01, -4.0070e-02,\n",
      "         4.1020e-01, -2.3321e-01,  1.7581e-01, -1.9093e-01, -2.9860e-01,\n",
      "         5.6369e-01, -3.2297e-01,  2.7542e-02, -5.6699e-01,  1.7424e-01,\n",
      "        -2.2956e-01, -4.4196e-01,  1.0640e-01, -4.6610e-01,  2.0334e-01,\n",
      "         2.7649e-01,  4.2304e-01, -8.7326e-03,  2.8255e-02, -1.5862e-01,\n",
      "         8.6380e-02,  2.8243e-01, -2.7057e-01, -2.0601e-01, -2.1482e-02,\n",
      "         5.3851e-03,  6.4020e-02,  4.7899e-01,  4.9535e-01, -1.5896e-01,\n",
      "        -1.9214e-01,  1.2101e-01,  2.9061e-01, -1.5855e-01,  8.5255e-02,\n",
      "         2.2960e-02, -2.7560e-01, -2.5336e-01,  7.4732e-02,  7.2748e-02,\n",
      "         5.8307e-02,  1.6590e-01, -3.6232e-01,  4.8909e-01, -3.2105e-01,\n",
      "        -2.6309e-01, -2.7158e-01, -3.1298e-01, -1.6260e-02, -4.0816e-02,\n",
      "        -1.8872e-01,  4.2584e-01, -7.2546e-02, -1.1993e-01,  3.6039e-01,\n",
      "        -1.2885e-01, -2.3635e-01, -2.6984e-01, -5.8870e-01,  2.5598e-01,\n",
      "         2.5436e-01, -3.3684e-01,  4.8664e-01, -3.1816e-01, -3.8861e-01,\n",
      "         9.3885e-03, -3.1632e-01, -9.3373e-02, -2.8466e-01, -2.0696e-01,\n",
      "        -3.6059e-01, -3.4398e-01,  2.5522e-01, -5.1572e-01,  3.9916e-01,\n",
      "        -1.6496e-01,  5.6806e-01, -2.6143e-01, -4.8469e-01, -5.3519e-02,\n",
      "        -1.5548e-01, -5.1532e-01, -3.3409e-01, -6.9875e-02,  1.0862e-01,\n",
      "         1.4584e-01, -7.0718e-02,  5.0837e-01,  4.5423e-01,  1.4634e-01,\n",
      "         4.0548e-01,  4.8339e-01,  3.1346e-01, -1.2232e-01,  9.8184e-02,\n",
      "        -1.7659e-01,  3.5373e-01,  2.5808e-01,  9.6168e-03,  4.3834e-01,\n",
      "         3.5427e-01, -6.0712e-01,  1.5454e-01,  5.7699e-01, -4.9660e-01,\n",
      "        -8.7447e-02], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.3214]],\n",
      "\n",
      "         [[-0.1187]],\n",
      "\n",
      "         [[-0.1368]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2332]],\n",
      "\n",
      "         [[ 0.7149]],\n",
      "\n",
      "         [[-0.3434]]],\n",
      "\n",
      "\n",
      "        [[[-0.3512]],\n",
      "\n",
      "         [[-0.1337]],\n",
      "\n",
      "         [[-0.1576]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1736]],\n",
      "\n",
      "         [[ 0.0839]],\n",
      "\n",
      "         [[-0.2794]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1834]],\n",
      "\n",
      "         [[-0.0765]],\n",
      "\n",
      "         [[-0.2504]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1475]],\n",
      "\n",
      "         [[ 0.8114]],\n",
      "\n",
      "         [[ 0.0702]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1949]],\n",
      "\n",
      "         [[ 0.1380]],\n",
      "\n",
      "         [[ 0.1611]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3682]],\n",
      "\n",
      "         [[-0.2342]],\n",
      "\n",
      "         [[-0.1463]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5161]],\n",
      "\n",
      "         [[-0.1502]],\n",
      "\n",
      "         [[ 0.3030]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0840]],\n",
      "\n",
      "         [[-0.5214]],\n",
      "\n",
      "         [[ 0.3736]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1584]],\n",
      "\n",
      "         [[ 0.3845]],\n",
      "\n",
      "         [[-0.1413]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0133]],\n",
      "\n",
      "         [[-0.2407]],\n",
      "\n",
      "         [[ 0.4479]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.0510, 0.6193, 0.5550, 0.4804, 0.9168, 0.5081, 0.4976, 0.3119, 1.1209,\n",
      "        0.5581, 1.1134, 0.4730, 0.4247, 1.5666, 0.8035, 0.3412, 1.5223, 0.1441,\n",
      "        1.4573, 2.6236, 0.9214, 1.4049, 0.8077, 0.7877, 1.3364, 1.2444, 0.8683,\n",
      "        0.1437, 0.4301, 1.2657, 0.5550, 0.9186, 1.4885, 0.0231, 0.3286, 0.8719,\n",
      "        1.5283, 0.5318, 1.4248, 1.5188, 1.0381, 0.3521, 0.2209, 0.9071, 0.3442,\n",
      "        0.2596, 0.7564, 0.1611, 0.0226, 0.4464, 0.3585, 0.4971, 0.7615, 1.6543,\n",
      "        0.7359, 0.2372, 1.1134, 0.2981, 0.6803, 1.0917, 0.1307, 1.2012, 1.9373,\n",
      "        0.2277, 1.6226, 0.6337, 0.2579, 0.8611, 1.4675, 0.3022, 0.1026, 0.5031,\n",
      "        0.2101, 0.4848, 0.5002, 1.2423, 1.0067, 1.0131, 0.4146, 0.6939, 0.2190,\n",
      "        0.8562, 1.9406, 1.1751, 0.8753, 1.3376, 0.8942, 0.6176, 0.7636, 0.2634,\n",
      "        0.5130, 0.6663, 0.7218, 0.4465, 1.3295, 0.3841], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.0413e-01, -1.2171e-01,  2.0444e-01, -6.8993e-01,  2.5978e-01,\n",
      "        -3.9945e-03, -5.1542e-01, -5.4932e-02,  3.7824e-01, -8.3362e-01,\n",
      "         3.9200e-01,  8.6914e-01, -3.6155e-02,  7.9276e-01,  3.2436e-01,\n",
      "         1.3029e-01,  2.0583e-02, -6.1147e-01,  1.4024e-01, -7.4218e-01,\n",
      "         1.9700e-02, -3.1035e-01,  6.5423e-02, -8.1632e-01, -1.8117e-01,\n",
      "        -3.1760e-02,  4.5755e-01, -8.4737e-02, -3.4391e-01,  1.5851e-01,\n",
      "         6.6211e-03, -1.6312e-02,  1.2289e-01,  1.0734e-01, -3.8684e-02,\n",
      "         3.0868e-02, -1.8290e-01,  7.9771e-01,  6.4473e-01,  3.5238e-01,\n",
      "        -5.4614e-01, -4.1539e-04,  2.2197e-02, -3.8051e-01, -5.7637e-02,\n",
      "        -2.1779e-01, -1.2240e-01, -6.8328e-03,  3.9855e-01,  3.4652e-01,\n",
      "         1.1978e-01, -7.5714e-02,  3.8769e-01, -4.2198e-01, -5.4725e-01,\n",
      "         3.5190e-02,  5.7936e-02, -3.2187e-03,  3.3254e-01,  2.4786e-01,\n",
      "        -2.3158e-02, -4.9705e-02, -1.0842e-01, -3.0654e-01,  4.6277e-01,\n",
      "        -8.8681e-01,  5.4067e-01,  4.7694e-01, -9.6502e-01,  1.0909e-01,\n",
      "        -3.5564e-01, -1.4272e-01,  1.4092e-01,  2.5135e-01,  4.3018e-01,\n",
      "         4.3405e-01, -7.5984e-02, -5.5524e-02,  4.8870e-01,  1.2052e-01,\n",
      "        -2.9218e-01,  3.6935e-01, -3.0014e-01, -4.5015e-01,  2.4886e-01,\n",
      "        -6.3788e-02,  6.3717e-01,  3.1719e-01, -3.6278e-01, -1.2299e-01,\n",
      "         3.7560e-01, -2.0966e-01, -1.0227e-01,  8.5496e-02,  2.0451e-01,\n",
      "         1.8245e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 2.7129e-01]],\n",
      "\n",
      "         [[-2.2238e-01]],\n",
      "\n",
      "         [[-4.0646e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1920e-01]],\n",
      "\n",
      "         [[-4.2483e-01]],\n",
      "\n",
      "         [[-1.5695e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4892e-01]],\n",
      "\n",
      "         [[-3.2895e-01]],\n",
      "\n",
      "         [[-4.9374e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.2176e-01]],\n",
      "\n",
      "         [[ 5.7607e-01]],\n",
      "\n",
      "         [[-3.4571e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4264e-01]],\n",
      "\n",
      "         [[-2.2177e-01]],\n",
      "\n",
      "         [[ 2.0143e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0142e-01]],\n",
      "\n",
      "         [[-4.6167e-01]],\n",
      "\n",
      "         [[ 6.1907e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-8.9227e-01]],\n",
      "\n",
      "         [[ 1.9453e-01]],\n",
      "\n",
      "         [[-1.1300e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8511e-01]],\n",
      "\n",
      "         [[-1.2011e-01]],\n",
      "\n",
      "         [[-4.8577e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.2652e-02]],\n",
      "\n",
      "         [[ 5.1301e-01]],\n",
      "\n",
      "         [[-6.7029e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1485e-01]],\n",
      "\n",
      "         [[-1.3220e-01]],\n",
      "\n",
      "         [[-3.2741e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.6860e-01]],\n",
      "\n",
      "         [[-4.7205e-04]],\n",
      "\n",
      "         [[-3.7491e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2140e-01]],\n",
      "\n",
      "         [[-2.3900e-01]],\n",
      "\n",
      "         [[-6.2329e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.0663,  1.3131,  0.3526,  0.5293,  1.3096,  0.8209,  1.1631,  2.1019,\n",
      "         1.8825,  2.4898,  1.9234,  1.6948,  0.8544,  0.1314,  1.0312,  0.3380,\n",
      "         0.9232,  1.7013,  0.5063,  0.3295,  0.9450,  1.2826,  0.2357,  1.1077,\n",
      "         0.3208,  0.7489,  1.0649,  1.0346,  0.2403,  0.8548,  1.3952,  0.3779,\n",
      "         0.8816,  4.0157,  1.5500,  0.7677,  1.9445,  1.1194,  3.8854,  0.3260,\n",
      "         2.3306,  0.3297,  2.3681,  1.6217,  0.1509,  2.2392,  0.3809,  1.9221,\n",
      "         0.7882,  0.8467,  0.9814,  0.6486,  1.0655,  1.9878,  1.4634,  1.4207,\n",
      "         1.6222,  0.9510,  0.7967,  1.0697,  2.8325,  0.6503,  1.9604,  1.3810,\n",
      "         0.9293,  0.3078,  0.7635,  1.8342,  1.2454,  0.2240,  1.0950,  2.1664,\n",
      "         0.4241,  0.4681,  1.6705,  1.9221,  1.9336,  1.3175,  0.1727,  0.9940,\n",
      "         1.1904,  0.7374,  0.8804,  0.4798,  0.1296,  0.3035,  0.3724,  1.3039,\n",
      "         1.9559,  1.2796,  2.0560,  1.3658,  0.8512,  1.1215,  1.0141,  0.7133,\n",
      "         1.5482,  1.7514,  0.8937,  1.9142,  0.3577,  0.4111,  1.3439,  1.6699,\n",
      "         1.2782,  0.9051,  1.0576,  1.6798,  1.6712,  2.8001,  1.1299,  1.6401,\n",
      "         1.5663,  1.2975,  0.9383,  1.1166,  1.2604,  3.2558,  1.3683,  1.4863,\n",
      "         1.1285,  1.2874,  1.5483,  0.4730,  1.6968,  0.6185,  0.4111,  0.3188,\n",
      "         0.6788,  0.0840,  1.2870,  1.7495,  1.6490,  1.6365,  1.4597,  1.1968,\n",
      "         1.9327,  0.2303,  1.4915,  2.2467,  1.1726,  0.2234,  1.9293,  0.1179,\n",
      "         1.8771,  1.3568,  0.5829,  2.1474,  0.4076,  0.5736,  0.2610,  2.2845,\n",
      "         1.4675,  1.1744,  0.8521,  1.2170,  1.1498,  0.3053,  1.5812,  1.4122,\n",
      "         0.5660,  1.5783,  0.6406,  1.4565,  1.6370,  1.3382,  2.1363,  0.4086,\n",
      "         1.5605,  0.8386,  1.2453,  2.0853,  0.6092,  2.6147,  0.4714,  1.1404,\n",
      "         1.3415,  2.2922,  0.7618,  2.5387,  1.2549,  1.6949,  1.1146,  1.2939,\n",
      "         0.3934,  1.6145,  0.6990,  0.9188,  0.7992,  1.8252,  0.2701,  0.7269,\n",
      "         2.7211,  1.2480,  1.1258,  1.5957,  2.1308,  1.0994,  1.7288,  1.6543,\n",
      "         0.7562,  1.9149,  0.6967,  0.3873,  0.6646,  2.1479,  2.0454,  1.0552,\n",
      "         0.9088,  1.3772,  1.5106,  0.2069,  1.6680,  0.6220,  0.4223,  1.2284,\n",
      "         1.6547,  1.1411,  0.5670,  1.5232,  1.4014,  1.2614,  0.6231,  2.0538,\n",
      "         0.7843,  1.3828,  1.3756,  2.5460,  0.3874,  0.6207,  0.8124,  2.2184,\n",
      "         0.6066,  1.4554,  1.1903,  0.3619,  0.8716,  1.2212,  1.8989,  0.4270,\n",
      "         1.1051,  1.1280,  0.2068,  0.7203,  2.0332,  0.7119,  1.0300,  1.0701,\n",
      "         1.1306,  0.6523,  0.7303,  1.1501,  1.9277,  1.1511,  1.3827,  2.3951,\n",
      "         1.1148,  1.3035,  1.6817,  1.8498,  1.0503,  1.1364,  0.8823,  1.2345,\n",
      "         2.5316,  1.1622,  2.5659,  1.3834,  0.8592,  0.7453,  0.5645,  1.6744,\n",
      "         1.1863,  0.4407,  1.3902,  0.6087,  1.7754,  1.8979,  1.0703,  0.4302,\n",
      "         0.7017,  0.5146,  1.2711,  1.0617,  0.6803,  0.9640,  2.1001,  1.2504,\n",
      "         2.0204,  0.7342,  1.9727,  0.7055,  0.4678, -0.3552,  0.5510,  1.2560,\n",
      "         1.2932,  2.2735,  3.0851,  2.9437,  0.9431,  0.3611,  1.7848,  2.0258,\n",
      "         1.6660,  1.6861,  0.4592,  0.5267,  1.1895,  2.6935,  2.1494,  2.7007,\n",
      "         1.0973,  1.2268,  1.6014,  0.5282,  2.2585,  0.3989,  0.6309,  1.5758,\n",
      "         1.9572,  1.1181,  0.8387,  0.3797,  0.4205,  1.1870,  1.3112,  1.0384,\n",
      "         0.8582,  1.3147,  0.7871,  1.9006,  2.9655,  0.8879,  2.2768,  1.1536,\n",
      "         2.6300,  1.9320,  3.1311,  2.2709,  1.7813,  0.9921,  1.0188,  1.0438,\n",
      "         0.9620,  0.3537,  2.1134,  0.4158,  3.0225,  1.7314,  2.7562,  0.4496,\n",
      "         1.8784,  2.1607,  2.1829,  1.3546,  2.7333,  0.7418,  0.5235,  0.1751,\n",
      "         1.2532,  0.9519,  2.0266,  0.9197,  0.3608,  1.9404,  1.2045,  1.3931,\n",
      "         0.5228,  2.1258,  1.5896,  2.4626,  0.6556,  2.4320,  1.5734,  1.1114,\n",
      "         1.7284,  0.7746,  1.2183,  0.9174,  0.9574,  2.0100,  0.4321,  2.3750,\n",
      "         2.3013,  1.0871,  2.4640,  1.1249,  1.7095,  1.0188,  0.5356,  1.8031,\n",
      "        -0.0936,  0.5906,  1.4079,  1.5241,  0.5369,  0.5670,  1.9602,  0.6269,\n",
      "         0.3555,  0.3003,  2.4374,  0.3900,  0.5303,  0.9092,  2.6767,  1.8020,\n",
      "         0.4039,  0.4703,  2.1860, -0.5499,  1.4691,  1.9817,  1.6549,  0.7455,\n",
      "         0.3489,  1.7732,  1.3592,  1.7810,  1.0821,  0.8162,  0.9308,  2.3292,\n",
      "         0.5535,  1.0094,  2.7632,  0.8999,  1.9454,  1.6573,  0.6013,  0.3048,\n",
      "         1.3944,  1.6502,  0.0934,  1.2054,  0.2422,  1.3632,  0.4400,  0.4864,\n",
      "         1.7920,  2.4658,  0.1943,  0.5595,  1.1627,  1.0558,  1.1632,  1.6426,\n",
      "         1.6172,  1.5820,  1.4553,  0.9766,  2.4682,  1.5635,  1.7663,  0.4000,\n",
      "         1.8152,  0.3254,  1.0126,  2.4298,  1.0740,  1.6359,  1.4196,  0.4971,\n",
      "         2.0843,  1.3932,  0.9988,  2.2667,  0.3883,  1.0867,  1.3442,  0.2708,\n",
      "         0.3345,  1.3152,  0.8947,  2.4068,  2.0764,  1.6723,  2.5429,  1.5655,\n",
      "         0.6943,  1.4913,  1.5168,  1.5275,  0.4949,  2.0275,  1.5075,  1.0105,\n",
      "         1.9496,  1.7520,  1.6299,  1.8650,  1.6499,  0.7725,  1.5431,  0.3790,\n",
      "         4.1665,  0.4149,  0.2934,  2.0256,  1.7215,  0.9190,  0.5123,  0.7320,\n",
      "         1.3832,  0.3112,  1.2560,  2.5646,  1.0868,  2.1624,  0.3026,  0.4656,\n",
      "         1.8656,  0.1826,  0.8121,  1.8730,  2.0395,  0.2241,  1.0321,  1.3527,\n",
      "         0.7949,  1.2309,  0.4776,  0.4050,  0.4684,  1.8052,  0.3291,  2.1149,\n",
      "         0.8420,  1.5802,  2.9361,  1.1514,  1.3256,  0.9274,  1.4972,  1.3505,\n",
      "         1.3230,  0.1327,  0.2993,  1.6019,  1.8202,  1.3501,  1.6517,  1.8642,\n",
      "         0.8745,  0.1834,  1.1669,  1.2626,  1.0025,  0.9309,  1.2498,  1.7049,\n",
      "         0.2053,  1.0815,  0.8394,  1.6720,  0.6248,  0.2207,  2.3641,  2.8394,\n",
      "         1.6680,  1.5280,  2.7225,  1.4107,  0.2607,  0.3832, -0.0779,  0.2307,\n",
      "         0.6739,  1.8913,  1.7441,  0.6922,  1.1527,  0.3108,  0.1679,  2.0559],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.0411e+00, -7.0102e-01, -2.5556e+00,  1.2083e+00, -2.0396e+00,\n",
      "        -9.3200e-02,  5.4865e-01,  7.9359e-02,  8.0896e-01,  1.2075e+00,\n",
      "        -3.5535e+00, -1.7523e-01,  8.1927e-01,  4.9112e-01, -9.7421e-01,\n",
      "        -1.2009e-01, -3.4692e-01, -2.9391e-01, -1.3775e-01, -1.9891e-01,\n",
      "        -8.5469e-01, -1.6197e+00,  1.1215e-01,  6.2557e-01,  1.5213e-01,\n",
      "         1.0101e+00,  2.4451e+00, -1.1620e+00,  1.3139e-02, -1.1520e+00,\n",
      "        -1.0092e+00,  7.9013e-02,  1.0579e+00,  4.0782e-01, -1.0531e+00,\n",
      "        -9.3583e-01, -2.6629e-01, -3.7015e-01, -9.9487e-01,  1.1501e-01,\n",
      "         1.1275e-01, -2.3391e-02,  3.2967e-01, -5.5264e-01, -2.0348e-01,\n",
      "        -8.5567e-01, -4.7139e-01, -5.3520e-01, -1.1200e+00, -1.6661e+00,\n",
      "         1.6206e+00,  4.0352e-01,  1.3385e-01,  7.9553e-01,  5.9042e-01,\n",
      "         6.8641e-01, -2.7210e+00, -1.4191e+00, -2.5742e-01, -2.0577e-01,\n",
      "        -2.6603e-01, -6.5939e-01, -1.4048e+00,  6.6901e-01, -6.3186e-01,\n",
      "         8.6113e-02, -1.9021e+00,  3.2279e-01,  7.0296e-01, -1.2546e-01,\n",
      "         3.9925e-02,  1.6304e+00, -5.9946e-02, -5.4766e-01, -6.0758e-02,\n",
      "         1.5302e+00, -9.1820e-01, -1.5410e+00, -2.6117e-02, -9.8731e-01,\n",
      "         5.3540e-01, -4.8577e-01,  1.2919e-01, -3.2723e-01,  2.5012e-01,\n",
      "         9.7925e-02,  2.4801e-01,  1.0230e+00,  5.7345e-01, -1.1768e+00,\n",
      "         2.3082e+00,  3.4295e-01,  2.4942e-01,  2.4185e-01, -5.3603e-01,\n",
      "        -6.7435e-01, -1.3765e+00,  1.5778e+00, -1.5787e+00,  1.6318e+00,\n",
      "         5.6407e-02,  2.8070e-01, -2.3804e-01, -1.5701e-01,  3.5531e-01,\n",
      "        -1.2571e+00, -1.0028e+00, -5.0995e-01, -7.9435e-01, -2.1879e-01,\n",
      "        -1.4136e+00,  1.6740e-01,  4.5028e-01, -1.3352e+00, -8.8684e-01,\n",
      "        -7.2651e-01, -1.8613e+00, -2.1529e+00, -7.4542e-01, -1.6469e+00,\n",
      "        -7.1989e-01,  2.5778e-01, -3.6660e+00,  2.4512e-01, -2.2839e-01,\n",
      "        -1.3904e-01,  4.1863e-01, -1.1972e-02, -6.5297e-01,  1.3449e+00,\n",
      "        -1.8494e+00,  1.0069e+00, -3.8851e-01,  2.3044e-02, -1.9342e+00,\n",
      "        -1.5213e+00, -4.9849e-01,  1.8121e-01,  1.2902e+00, -5.1500e-01,\n",
      "        -2.7589e+00,  1.7522e-01, -1.5329e+00, -7.6993e-01, -7.5005e-01,\n",
      "        -5.1939e-01, -2.0416e-01,  7.7985e-01,  1.8888e-01,  1.3257e-01,\n",
      "         4.9789e-02,  7.3051e-01,  7.0074e-01, -1.9543e+00, -9.6850e-01,\n",
      "        -1.8419e+00, -9.6421e-01,  1.3827e-01, -8.1702e-01,  5.4979e-01,\n",
      "         2.2163e-01,  3.0227e-01,  2.4880e-02,  8.9663e-01, -6.6503e-01,\n",
      "        -1.0461e+00,  1.1938e-01,  2.2555e-01, -4.8270e-01, -6.0794e-01,\n",
      "         2.2283e+00,  4.7777e-01, -4.0636e-01,  1.1309e+00,  2.8014e-01,\n",
      "         3.4110e-02, -2.1144e+00,  5.3336e-01, -3.4252e-01,  1.2348e+00,\n",
      "         1.3525e+00, -1.4184e+00, -1.7582e+00,  1.0255e+00,  1.3516e-01,\n",
      "        -5.1764e-01, -1.6808e-01,  1.7913e+00,  4.9776e-01, -1.2972e-01,\n",
      "         2.5165e-01,  1.3611e+00, -1.6445e+00, -6.3095e-01,  1.6479e-01,\n",
      "        -2.6490e+00, -9.7396e-01, -3.2826e-01,  6.4675e-01, -1.2733e+00,\n",
      "         5.0624e-02,  7.9006e-01, -5.6393e-01,  6.1315e-02,  7.6200e-02,\n",
      "        -1.3366e+00,  2.7845e-01, -1.6272e+00, -1.9282e-01,  2.5765e-01,\n",
      "         1.8125e+00, -4.6083e-02, -2.3115e-01,  4.0473e-01,  1.4681e-01,\n",
      "        -9.8247e-01,  8.4037e-01,  2.5867e-01,  2.0633e-01,  2.1442e+00,\n",
      "         5.6006e-01,  1.2245e+00,  1.9188e-01,  1.4233e+00,  1.3335e-01,\n",
      "        -2.4456e+00, -1.4562e-02,  6.3142e-01, -2.7103e-01,  2.5663e-02,\n",
      "         1.1539e+00,  1.3420e+00,  5.6631e-02, -1.1978e+00, -1.3034e+00,\n",
      "         1.0517e-01, -1.8533e+00, -8.4497e-01, -1.3720e+00,  1.6960e-01,\n",
      "         3.2258e-01,  8.2221e-01, -7.1204e-02, -4.9439e-01, -6.1092e-01,\n",
      "        -4.9357e-01, -7.2754e-01,  4.4898e-01,  1.4890e-01, -1.4000e+00,\n",
      "        -5.4476e-01, -1.8978e-01,  8.0579e-01, -1.7309e+00, -3.5652e-01,\n",
      "        -1.0086e+00, -1.7764e+00,  3.4154e-01,  8.3309e-01, -1.7590e+00,\n",
      "         1.9784e+00, -9.7127e-02,  6.4390e-01,  1.1186e+00, -1.8329e-01,\n",
      "         8.9925e-01, -1.9289e+00, -2.4514e-01, -4.3703e-01, -1.1858e+00,\n",
      "         7.6520e-02,  2.2722e-01, -1.2317e+00, -6.5965e-02,  2.7348e-01,\n",
      "        -6.4807e-01,  1.3405e+00, -2.0026e+00,  3.6671e-01,  1.3014e+00,\n",
      "         2.4429e-01,  5.8631e-02, -1.3030e+00,  1.0951e+00, -1.2209e+00,\n",
      "         1.7226e-01,  7.0415e-01, -7.2069e-02,  8.9991e-01,  5.9375e-01,\n",
      "         8.0322e-01, -4.1193e-02,  1.3265e-01, -1.0410e-01, -1.4197e-01,\n",
      "        -3.9065e+00,  3.5848e-01, -8.4990e-02, -1.2656e+00,  3.3614e-01,\n",
      "        -1.5171e+00,  1.1853e-01,  3.2935e-01,  1.0606e+00, -1.3596e-01,\n",
      "        -8.3195e-01,  3.3924e-01,  4.5026e-02, -1.1622e+00,  3.6208e-01,\n",
      "         1.4637e+00,  6.9286e-01,  4.7093e-01,  1.5343e-01,  2.9522e-01,\n",
      "         3.6440e-01, -7.1120e-01,  4.1835e-01, -4.6612e-02, -5.6838e-01,\n",
      "        -6.1516e-01, -1.6918e+00, -8.1723e-01,  8.4574e-02, -6.6178e-02,\n",
      "        -3.0868e-01, -1.9993e+00, -1.1502e+00,  6.7531e-01, -1.0991e+00,\n",
      "        -1.2622e+00, -2.2851e-01,  8.9642e-02,  2.4333e-01,  4.3498e-01,\n",
      "        -1.4927e+00, -9.0377e-02, -1.5565e+00,  5.5533e-01,  1.7462e-01,\n",
      "         1.0706e+00,  2.9476e-01, -8.5937e-01,  1.8941e+00,  1.1994e+00,\n",
      "        -3.5868e-02,  2.2364e+00,  7.4544e-02, -6.0733e-01, -2.4848e-01,\n",
      "         2.8138e-02,  1.3866e-01,  1.4460e+00,  8.6918e-01, -1.5487e+00,\n",
      "        -4.9167e-01, -1.2868e-01, -1.5590e-01, -3.0303e-02,  2.0204e-02,\n",
      "        -1.0103e+00, -1.4186e+00, -1.1004e+00,  5.2568e-01, -2.2553e-01,\n",
      "         3.2582e-01, -8.1798e-01, -1.9042e+00, -3.0136e-01, -4.7605e-02,\n",
      "        -1.0960e+00,  1.4985e-01, -1.0990e-01,  9.9042e-01, -6.2951e-01,\n",
      "        -2.4837e-01,  5.9230e-01,  4.9332e-01, -8.1599e-01, -2.0005e+00,\n",
      "         8.2531e-01, -1.4613e+00, -2.3889e-01,  5.3629e-01,  1.0722e+00,\n",
      "        -1.3610e+00,  3.8568e-01,  1.0029e+00, -9.0552e-01, -1.7489e+00,\n",
      "        -6.1278e-02, -7.7786e-03,  4.5630e-01, -4.5955e-02,  8.5318e-01,\n",
      "         1.6599e-01,  3.7913e-02, -9.1782e-02,  2.8848e-01, -4.4065e-01,\n",
      "         1.4915e-01,  2.8601e-01,  5.2055e-01,  1.0581e-01,  1.1668e-02,\n",
      "        -9.5236e-01,  6.2733e-01, -1.2675e+00, -2.2902e-01,  1.0050e-01,\n",
      "        -1.4238e+00,  1.2290e-01,  1.1020e+00, -2.1675e+00,  1.0977e+00,\n",
      "         4.7536e-02, -2.5741e-01,  6.6336e-01,  2.2768e+00,  8.7517e-01,\n",
      "        -6.5220e-01, -8.1326e-01, -5.0833e-03, -3.7413e-01,  2.6880e-01,\n",
      "         7.1655e-01, -1.7247e+00, -8.0456e-01, -8.8612e-02, -3.0096e+00,\n",
      "         2.2766e-01,  4.4481e-01,  6.3836e-01,  1.5309e+00, -1.4394e-01,\n",
      "        -9.8748e-01,  4.9285e-02, -1.5043e+00,  6.8900e-01,  4.1169e-01,\n",
      "         9.1197e-01,  7.1969e-01, -1.1285e-01, -1.8339e-01, -1.8391e+00,\n",
      "        -4.5842e-01,  3.4214e-01,  2.9299e-01,  1.6670e-02, -7.4769e-02,\n",
      "        -1.7865e+00, -6.9618e-01, -7.2159e-01,  3.4630e-01, -9.2514e-01,\n",
      "         4.4621e+00, -1.7524e+00, -1.5039e-01, -5.3494e-01,  4.7794e-02,\n",
      "         1.8093e+00, -1.9998e-01,  1.6746e+00,  7.2456e-02, -2.8741e+00,\n",
      "         1.3221e+00, -1.8871e+00, -3.1450e+00, -1.8749e-01,  1.2867e+00,\n",
      "         5.1878e-01, -8.6794e-02,  6.4023e-02, -6.1630e-01, -4.2275e-01,\n",
      "         7.0475e-01,  2.0118e-01, -1.7742e+00,  8.6799e-01,  2.7586e-01,\n",
      "         4.3439e-01, -1.1816e+00, -2.6297e+00, -7.4471e-01, -2.3367e-01,\n",
      "        -1.3979e+00,  3.1691e-01, -1.8760e+00, -1.4215e+00,  4.5754e-01,\n",
      "        -8.2834e-01, -2.2197e+00,  9.8549e-01,  6.6455e-03, -1.7893e+00,\n",
      "        -3.9790e-02, -3.3750e-01,  3.1427e-02,  2.0288e-01, -1.4506e+00,\n",
      "        -4.7643e-01, -3.1415e-01,  3.0877e-02, -1.0497e+00, -1.4440e+00,\n",
      "        -6.9767e-02, -7.2183e-01, -1.3258e-01, -4.4657e-01, -5.9215e-01,\n",
      "        -3.6265e-01, -3.3298e-01, -9.9404e-03,  4.3591e-01, -1.7634e+00,\n",
      "         8.3953e-01,  3.0872e-01, -1.3801e-01,  3.6796e-01, -1.0337e+00,\n",
      "        -5.5510e-01,  2.0684e-01, -1.4714e-01,  2.1669e-01,  1.6348e-01,\n",
      "        -1.5812e-01,  3.5611e-01,  2.9483e-02,  6.2356e-01, -6.1638e-01,\n",
      "        -1.4152e+00,  1.7321e+00, -1.0995e+00, -1.6480e+00,  4.3162e-01,\n",
      "        -9.6130e-01,  1.1183e+00,  2.2188e-01, -6.5975e-02, -1.3561e-01,\n",
      "        -4.0264e-01,  6.5017e-01,  4.9115e-01,  9.6766e-01, -4.4323e-01,\n",
      "        -4.3687e-02,  1.4691e+00, -2.2266e+00, -3.6276e-01,  1.0803e+00,\n",
      "         1.8729e-01,  8.5099e-02, -2.2370e-01,  6.2688e-01, -1.8889e-01,\n",
      "        -1.0533e+00,  5.0953e-01, -5.4104e-02, -2.9209e-01, -2.5285e-01,\n",
      "        -1.9997e-01, -1.0369e-04,  7.0291e-01,  1.2619e-02, -8.9572e-02,\n",
      "        -8.3275e-02, -1.0456e-02, -2.1640e-01, -5.5578e-02,  6.4656e-01,\n",
      "         1.0180e-01,  1.2850e-01,  7.2937e-02,  5.9980e-02, -2.8369e-01,\n",
      "        -1.7634e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2987,  0.3281,  0.1607,  0.4961,  0.3865],\n",
      "          [-0.0123,  0.1134,  0.7025,  0.1118,  0.1185],\n",
      "          [-0.0407, -0.0998,  0.2425, -0.1605, -0.2967],\n",
      "          [ 0.2015, -0.1900, -0.8041, -0.3387, -0.1973],\n",
      "          [-0.0410,  0.0202, -0.8155, -0.3336, -0.3758]]],\n",
      "\n",
      "\n",
      "        [[[-0.0107,  0.0294, -0.2406, -0.0843, -0.0438],\n",
      "          [-0.0160,  0.1224, -0.0379,  0.0889,  0.0432],\n",
      "          [ 0.0896,  0.4718,  1.5834,  0.4192,  0.1776],\n",
      "          [ 0.0225,  0.1554,  0.1153,  0.0957,  0.0285],\n",
      "          [-0.1357, -0.1911, -0.3070, -0.1586,  0.0066]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1683,  0.1435,  0.5937,  0.2836,  0.3783],\n",
      "          [-0.0442,  0.1299,  0.3736,  0.2813,  0.3711],\n",
      "          [ 0.4395,  0.5777,  0.0984,  0.5585,  0.7817],\n",
      "          [ 0.3754,  0.3113,  0.1092, -0.0197,  0.3074],\n",
      "          [ 0.3836,  0.2387,  0.0969,  0.0087,  0.3346]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3537,  0.1564, -0.0280, -0.0829, -0.1420],\n",
      "          [-0.0608, -0.1273, -0.3738, -0.1869, -0.1245],\n",
      "          [ 0.1548,  0.0141, -1.8837,  0.3779,  0.3642],\n",
      "          [-0.2877,  0.1891, -0.3793,  0.1040, -0.1321],\n",
      "          [ 0.0041, -0.1931, -0.3719, -0.1212, -0.3903]]],\n",
      "\n",
      "\n",
      "        [[[-0.4244,  0.2381,  0.2413, -0.3723,  0.0667],\n",
      "          [-0.4851,  0.1912,  0.1846, -0.2085, -0.4647],\n",
      "          [-0.6138,  0.4310,  0.6864,  0.0318, -0.2796],\n",
      "          [-0.4104,  0.2602,  0.3026, -0.1976, -0.5030],\n",
      "          [-0.1690,  0.2754,  0.2986,  0.2915, -0.3098]]],\n",
      "\n",
      "\n",
      "        [[[-0.1935,  0.1644, -0.0179, -0.2451, -0.3980],\n",
      "          [ 0.0971, -0.0422, -0.1244,  0.0932, -0.3152],\n",
      "          [ 0.2154,  0.1254,  1.4511,  0.3626,  0.1030],\n",
      "          [-0.4048, -0.2589,  0.1426,  0.3122,  0.3780],\n",
      "          [ 0.0461, -0.2611, -0.0971,  0.2447,  0.1237]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.3177,  0.9545,  1.5521,  1.0587,  1.1087,  1.4800,  0.9784,  1.1043,\n",
      "         0.9471,  1.0493,  1.3514,  1.0054,  1.9462,  1.4010,  1.2062,  1.3086,\n",
      "         0.8180,  0.9346,  1.0638,  0.9494,  1.0617,  3.0780,  1.3427,  1.2238,\n",
      "         1.8569,  2.0105,  1.9341,  0.7358,  2.0812,  2.9068,  0.9585,  2.2688,\n",
      "         2.0102,  2.3135,  0.5750,  1.3743,  0.7460,  0.9636,  1.5067,  0.7406,\n",
      "         0.9022,  0.8009,  1.6004,  1.2468,  1.9853,  1.6013,  1.4425,  0.8404,\n",
      "         0.4636,  0.8011,  1.9099,  1.3583,  1.1155,  1.0622,  1.5921,  1.3453,\n",
      "         1.7706,  0.9048,  1.4656,  1.2003,  1.0700,  1.4094,  2.2348,  1.3752,\n",
      "         0.9734,  1.6225,  2.1529,  2.0048,  1.9228,  1.2069,  0.9272,  1.4509,\n",
      "         1.3416,  1.8202,  1.0122,  1.6598,  1.2812,  4.6979,  1.4477,  1.0071,\n",
      "         1.0369,  0.9644,  2.2290,  0.6183,  1.7069,  2.4584,  1.7884,  1.6340,\n",
      "         0.9666,  0.7540,  2.0253,  1.6280,  1.3735,  1.3446,  1.1921,  0.7567,\n",
      "         1.2099,  1.7251,  1.7804,  0.8779,  1.8684,  2.2046,  0.8749,  1.1634,\n",
      "         1.0036,  0.7601,  0.9888,  0.8602,  0.9559,  1.5991,  0.5958,  1.3296,\n",
      "         1.0059,  2.2571,  1.0636,  0.8286,  0.6364,  1.2237,  0.7102,  1.3925,\n",
      "         1.1783,  1.1901,  2.2334,  1.5000,  0.7749,  1.2965,  2.6521,  0.6891,\n",
      "         1.0842,  2.3004,  1.0995,  0.8269,  0.8671,  0.8019,  0.4680,  0.7733,\n",
      "         1.3315,  1.3324,  1.7941,  1.0744,  1.1703,  0.5918,  0.5628,  0.3616,\n",
      "         0.9415,  0.7343,  0.8698,  2.2874,  1.1908,  0.3265,  0.5806,  0.8553,\n",
      "         0.4848,  0.6767,  1.1044,  0.8772,  0.9939,  1.7412,  1.0838,  0.7947,\n",
      "         0.6513,  1.8756,  0.8521,  1.2436,  0.7131,  0.7776,  1.1714,  1.4227,\n",
      "         1.1854,  1.0013,  1.3601,  0.7443,  1.6246,  1.2784,  1.9465,  0.9795,\n",
      "         0.7961,  0.7731,  1.1972,  2.7466,  1.7621,  0.6607,  2.8331,  1.6253,\n",
      "         1.7307,  1.1572,  0.5453,  0.6774,  2.0503,  0.9528,  2.0571,  1.3910,\n",
      "         1.1954,  0.8850,  0.7151,  1.0487,  0.9880,  0.6791,  1.1208,  0.7073,\n",
      "         1.0150,  0.5945,  0.9151,  0.8592,  1.0693,  1.7450,  1.5015,  0.6794,\n",
      "         1.3911,  1.1263,  1.1959,  1.1179,  0.7229,  1.2733,  0.9951,  0.9351,\n",
      "         0.6760,  1.5510,  2.1474,  1.6301,  2.2838,  1.4883,  1.0809,  1.6998,\n",
      "         1.0303,  0.9096,  0.9809,  0.9156,  1.9268,  0.6001,  1.7382,  0.9054,\n",
      "         0.7249,  0.8406,  0.4656,  1.7547,  1.7993,  0.8932,  0.8323,  1.5462,\n",
      "         1.5041,  1.4864,  0.8836,  0.9470,  1.2495,  1.1354,  0.9946,  1.3081,\n",
      "         0.6146,  0.8508,  0.9384,  0.7983,  1.3255,  0.9088,  0.7897,  1.8282,\n",
      "         0.8246,  1.0215,  1.0019,  0.6967,  2.1588,  1.2898,  1.0822,  0.7590,\n",
      "         1.3228,  1.0972, -0.3011,  1.0763,  1.0590,  0.7486,  1.0495,  0.9801,\n",
      "         0.4818,  2.0089,  2.1457,  0.9999,  0.7757,  1.2918,  0.8802,  1.0351,\n",
      "         2.1064,  0.6285,  1.0631,  0.9064,  0.9579,  1.2221,  0.9540,  1.0746,\n",
      "         1.2126,  1.4022,  1.3176,  0.8864,  0.8202,  1.9165,  1.3102,  2.6022,\n",
      "         1.3255,  0.8285,  0.0632,  0.6825,  0.3967,  0.6766,  2.1608,  0.9173,\n",
      "         0.5315,  1.1051,  1.6145,  0.8982,  0.7597,  0.9314,  0.7081,  0.6131,\n",
      "         1.1999,  0.7470,  1.0517,  1.3386,  0.9459,  0.7205,  1.0170,  1.0563,\n",
      "         1.5136,  0.4751,  1.0414,  1.1077,  1.3704,  0.6877,  0.8615,  0.6802,\n",
      "         1.1336,  1.2530,  0.5869,  1.5526,  1.4648,  1.3672,  0.9867,  1.9648,\n",
      "         1.1270,  0.8253,  1.0440,  1.4261,  0.7464,  1.0195,  0.8622,  2.0392,\n",
      "         1.0207,  1.4829,  2.1866,  1.4312,  2.5321,  1.3006,  1.7410,  1.9261,\n",
      "         1.5549,  1.0092,  0.5026,  0.7824,  0.9530,  1.2817,  1.5794,  0.8011,\n",
      "         1.0987,  0.7703,  1.8246,  2.3231,  1.2082,  1.4777,  0.8073,  1.0637,\n",
      "         0.5384,  0.7484,  0.8665,  0.9205,  0.7244,  1.3670,  0.9966,  0.8349,\n",
      "         1.1898,  0.3784,  0.2348,  0.5348,  1.3744,  0.9451,  1.5455,  1.2899,\n",
      "         1.5556,  0.5435,  1.1189,  0.0178,  0.3066,  0.6301,  0.9397,  1.6397,\n",
      "         0.8913,  0.5836,  1.6340,  0.8068,  1.8618,  1.4747,  0.8519,  0.6116,\n",
      "         1.3565,  2.0048,  0.9969,  1.7469,  1.9105,  1.0010,  1.4466,  0.8818,\n",
      "         1.4433,  1.4489,  0.9047, -0.9501,  1.6590,  0.8053,  0.7296,  0.7656,\n",
      "         1.6311,  1.0477,  1.5303,  1.0134,  1.2503,  0.8654,  2.2558,  0.7490,\n",
      "         2.2765,  1.2568,  1.0996,  0.9334,  3.4400,  1.6108,  0.7375,  0.8020,\n",
      "         0.7113,  1.1113,  1.3290,  0.8503,  0.9418,  2.5217,  1.6495,  1.5775,\n",
      "         1.8765,  2.8877,  1.7118,  1.4334,  1.6040,  1.0659,  1.2474,  0.9460,\n",
      "         0.9959,  0.7937,  0.7370,  0.2797,  1.5344,  1.5938,  0.9653,  1.5952,\n",
      "         1.4647,  1.7604,  0.5873,  1.2042,  0.6233,  1.0681,  1.1882,  1.0065,\n",
      "         1.4903,  1.9109,  0.9685,  2.1916,  1.4863,  1.2151,  1.1272,  0.8917,\n",
      "         0.7538,  0.7663,  0.9359,  0.9780,  0.9942,  1.3615,  0.9843,  1.4578,\n",
      "         1.6040,  0.7065,  2.6707,  0.4189,  0.6361,  1.4995,  1.0731,  1.0082,\n",
      "         1.3917,  0.6457,  0.8935,  0.9895,  1.1638,  0.9363,  1.8588,  1.4678,\n",
      "         2.1800,  1.7871,  1.7101,  1.7289,  1.2020,  1.0139,  1.2178,  0.5116,\n",
      "         0.7305,  1.8874,  0.7647,  1.2535,  1.5241,  0.7407,  0.9785,  1.7476,\n",
      "         1.3607,  1.2461,  0.7872,  0.9776,  1.6194,  2.0289,  1.2550,  0.5324,\n",
      "         1.1694,  1.0646,  1.1020,  1.0986,  0.9148,  1.1512,  2.1862,  1.3045,\n",
      "         1.4013,  0.9861,  1.0227,  1.8340,  1.2215,  0.2289,  1.1026,  0.3878,\n",
      "         1.8054,  1.7156,  1.1570,  0.6657,  1.3991,  1.0790,  1.3224,  1.6231,\n",
      "         1.1690,  1.1376,  1.6350,  2.0222,  1.2609,  2.6586,  1.0642,  1.1513,\n",
      "         1.3267,  1.3971,  0.4710,  1.0922,  1.6560,  1.4137,  1.1601,  1.6559,\n",
      "         0.9178,  0.8583,  1.2755,  0.0110,  1.3930,  1.7958,  1.2721,  2.6581,\n",
      "         0.7553,  0.9597,  0.9940,  1.4353,  1.1839,  1.4553,  1.3912,  1.3446],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.3996e+00, -4.8351e-01, -1.4509e+00, -5.4459e-01, -1.0657e-01,\n",
      "        -9.2150e-01, -5.5985e-01,  1.3214e-01, -3.8296e-01, -7.5569e-01,\n",
      "        -6.3955e-01, -2.6404e-01, -1.0661e+00, -1.1232e+00, -1.4585e-01,\n",
      "        -7.1190e-01,  3.0522e-01, -2.8142e-01, -4.6759e-01,  3.9247e-01,\n",
      "         3.6385e-01,  3.2820e-01, -9.2203e-01, -3.7536e-01, -1.1051e+00,\n",
      "        -1.5412e+00, -1.4635e+00, -1.2059e-02, -1.1610e+00, -1.3499e+00,\n",
      "        -2.4136e-02, -1.0829e+00, -1.4213e+00, -1.1732e+00, -3.1124e-01,\n",
      "        -9.2922e-01, -1.6262e-01,  7.0439e-02, -2.8377e-01, -1.0531e-01,\n",
      "        -1.1733e-01, -2.0163e-01, -5.9263e-01, -3.1962e-01, -1.1707e+00,\n",
      "        -3.5573e-01, -5.1903e-01, -2.5968e-01, -1.4580e-01, -1.5302e-01,\n",
      "        -1.4292e+00, -1.9502e+00,  9.5569e-02, -8.3920e-02, -2.1317e+00,\n",
      "        -4.0895e-01, -1.0787e+00, -4.0596e-01, -1.0734e+00, -1.7831e+00,\n",
      "        -1.4004e-01,  2.5215e-01, -1.7443e-01, -2.1013e+00, -1.9393e-01,\n",
      "        -1.5219e+00, -7.6348e-01, -3.5130e-01, -1.5293e+00,  3.5295e-01,\n",
      "        -1.5347e-01, -3.0585e-02,  4.3416e-01, -1.7760e+00, -4.6767e-01,\n",
      "        -1.8526e+00, -4.5439e-02, -4.1291e-01, -9.9536e-01, -7.1240e-01,\n",
      "        -2.7033e-01, -3.6302e-01, -1.1427e+00, -2.9890e-01, -1.3945e+00,\n",
      "        -1.0265e+00, -6.1678e-01,  1.8897e-01,  1.6814e-01, -1.6024e-01,\n",
      "        -1.4315e+00, -1.0008e+00, -1.0675e+00,  4.4430e-01, -5.1197e-01,\n",
      "        -3.6057e-01,  6.1000e-02, -1.7278e+00, -8.2124e-01,  9.5855e-02,\n",
      "        -1.0385e+00, -9.6912e-01,  1.7898e-01, -2.1043e-01, -2.2522e-01,\n",
      "        -3.7021e-01,  1.8191e-01, -2.5680e-01, -2.8783e-01, -8.4881e-01,\n",
      "        -1.1970e-01, -3.3963e-01, -2.6193e-01,  2.2533e-01, -8.4807e-01,\n",
      "        -6.4053e-02, -1.8091e-01, -7.0761e-02, -2.7123e-01,  5.1168e-02,\n",
      "         2.9514e-01, -4.8061e-01, -1.5428e+00, -1.4236e+00, -3.5553e-01,\n",
      "        -5.3733e-01, -1.2684e+00,  1.6977e-01, -4.7454e-01, -1.5472e+00,\n",
      "         1.4072e-01, -1.4446e-01, -1.8702e-01, -1.6514e-01,  1.5071e-02,\n",
      "        -1.4939e-01, -1.5056e+00, -9.9063e-01, -7.7016e-01,  4.9979e-01,\n",
      "        -6.0469e-01, -7.2182e-02, -1.7097e-01, -9.7107e-02, -1.1065e-01,\n",
      "        -1.8738e-01,  5.6561e-03, -6.3078e-01,  6.3906e-01, -1.1271e-01,\n",
      "        -1.3649e-01, -1.6240e-01, -7.1044e-02, -2.8780e-01, -3.2888e-01,\n",
      "         1.1857e-01, -2.2582e-01, -1.0657e+00, -2.2102e-01, -2.8395e-01,\n",
      "        -1.2383e-01, -1.0734e+00, -1.1930e-01, -5.2677e-01, -1.8425e-01,\n",
      "        -1.8584e-01, -5.2621e-01, -9.2354e-01,  3.7545e-02, -4.1813e-01,\n",
      "        -2.9436e-01,  1.1724e-01, -1.4454e+00, -1.3164e-01, -1.4064e+00,\n",
      "        -3.6851e-01,  3.4408e-02,  4.6842e-01, -4.3108e-01, -2.6616e+00,\n",
      "        -1.2257e+00, -1.4272e-01, -8.6583e-01, -1.0667e+00, -1.4561e+00,\n",
      "         2.3160e-01, -2.1557e-01, -2.1988e-01, -1.3274e+00, -1.6142e-01,\n",
      "        -1.2392e+00, -1.5035e+00,  1.3948e-02, -8.3593e-01, -2.5317e-01,\n",
      "        -3.2810e-01,  8.5742e-02, -2.2801e-01, -1.1918e-01, -6.7178e-02,\n",
      "         1.7195e-01, -2.9723e-01,  5.2411e-01,  7.6091e-01, -2.6517e-01,\n",
      "        -5.2417e-01, -3.2664e-01,  4.6446e-01, -1.1796e+00,  3.4801e-01,\n",
      "        -4.6937e-01,  7.7045e-01, -3.5073e-01, -2.0570e+00,  4.0884e-01,\n",
      "         6.5601e-02, -3.3732e-01, -7.4105e-01, -1.0190e+00, -2.0590e+00,\n",
      "        -1.2330e+00, -1.0689e+00, -1.5720e-01, -1.9031e+00,  4.8877e-02,\n",
      "         1.9694e-01, -3.8548e-01, -1.0564e-01, -1.2350e+00, -1.1188e-01,\n",
      "        -1.3468e+00, -9.6472e-02, -1.8710e-01, -2.5544e-02, -1.7735e-01,\n",
      "        -1.3888e+00, -6.1164e-01,  6.7667e-02, -3.4046e-01, -1.0317e+00,\n",
      "        -1.9354e+00, -1.0564e+00,  4.7826e-01, -3.4153e-02, -5.9564e-01,\n",
      "        -8.4774e-01, -2.7840e-01, -2.6036e+00, -2.9638e-01, -3.8989e-01,\n",
      "        -5.1999e-01, -2.1856e-01,  5.1278e-01, -4.3200e-01, -2.5124e-01,\n",
      "        -5.1242e-01, -1.6787e-02, -1.8258e-01, -5.3995e-01, -1.1211e-01,\n",
      "        -2.3889e+00,  3.3221e-01,  2.2432e-01, -3.5072e-01,  5.4833e-02,\n",
      "        -4.3349e-02,  1.0134e-01,  5.1449e-02, -2.4681e-01, -3.2864e-01,\n",
      "        -3.6540e-01, -7.4099e-02, -5.5088e-02, -1.3291e+00, -6.7799e-01,\n",
      "        -4.2548e-01, -4.2796e-02,  2.3341e-01, -2.4829e-01, -3.8434e-01,\n",
      "        -1.3387e+00, -2.0823e-01, -3.4944e-01,  1.3063e-01, -5.3097e-01,\n",
      "        -3.9077e-01, -2.5147e-01, -8.5286e-03,  4.2392e-01, -1.6078e+00,\n",
      "         8.6160e-02,  1.1840e-01, -1.6287e-01, -1.8794e+00, -2.3687e+00,\n",
      "        -2.5764e+00,  4.6498e-01, -3.3240e-01, -6.9826e-03, -1.8653e-01,\n",
      "        -1.0829e-01, -2.8275e-01, -1.3361e+00, -3.0219e-01, -1.8749e-01,\n",
      "        -1.8693e-01, -1.1477e+00, -2.6943e-01, -4.1803e-02, -1.8213e-01,\n",
      "         2.9610e-01, -2.6879e-01, -2.2112e-01, -9.5458e-02,  1.2234e-01,\n",
      "        -1.6816e+00,  1.9729e-01, -3.3392e-01, -4.0201e-01, -2.1986e-01,\n",
      "         3.7596e-02, -3.0133e-03, -1.1598e-01,  3.9764e-01, -1.2770e+00,\n",
      "         2.8136e-01, -2.5601e-01, -3.9840e-01,  4.6751e-01, -6.2816e-01,\n",
      "        -2.9864e-02, -8.9279e-01, -7.6463e-01, -1.7933e+00, -5.2504e-01,\n",
      "         1.7906e-02, -1.6946e-01, -2.6471e-01, -1.6148e-01, -1.7681e-01,\n",
      "        -2.5611e-01,  1.2346e-01, -1.3923e-01, -1.1963e+00,  2.1618e-01,\n",
      "        -1.0768e+00, -2.5016e+00, -7.4308e-01, -1.2448e+00, -4.0409e-01,\n",
      "        -5.5142e-01, -2.6680e+00, -1.8174e+00, -4.1685e-01, -1.8593e-02,\n",
      "        -1.0231e-01, -1.8272e-03, -1.3768e+00, -1.4933e+00, -1.5520e-01,\n",
      "        -5.8536e-01, -2.7611e-01, -3.3965e-02, -1.3013e+00, -2.3522e+00,\n",
      "        -8.1611e-01, -3.7791e-01, -2.1859e-01, -6.5722e-02, -3.9159e-01,\n",
      "        -2.0597e-01,  3.0543e-01, -2.4701e-01,  4.2193e-01, -3.8733e-01,\n",
      "        -3.5502e-01,  4.9576e-01, -1.8874e-01,  9.1482e-04, -2.3286e-01,\n",
      "        -8.0572e-01, -1.2298e-01, -1.2025e+00,  2.5284e-01, -1.3949e+00,\n",
      "        -2.2494e-01,  9.0860e-02, -9.6101e-03,  1.7179e-03, -1.8000e-01,\n",
      "        -4.7115e-01, -6.2046e-01, -4.4372e-01, -2.5096e-01, -2.1772e+00,\n",
      "        -1.2487e-01, -8.2244e-01, -1.5960e+00, -2.0399e-01, -3.8118e-01,\n",
      "         6.7933e-02, -1.2551e+00, -6.6321e-01, -1.3895e+00, -1.2238e+00,\n",
      "        -5.4966e-01, -3.8448e-01, -2.7398e-01, -1.1451e+00, -1.2978e+00,\n",
      "        -1.6181e-01,  2.6219e-01, -6.9039e-01,  5.1769e-02, -4.7809e-01,\n",
      "        -3.6047e-01, -1.6829e+00, -2.4965e-01, -1.3178e-02, -2.0785e-01,\n",
      "        -8.8512e-02, -2.3995e-01, -1.2603e+00, -3.9357e-01, -8.7935e-01,\n",
      "        -7.1498e-01, -4.6606e-02, -1.1569e-01, -3.2265e+00, -9.1221e-01,\n",
      "        -2.0901e-01, -4.2071e-01, -1.0247e-01,  2.3905e-01, -5.2925e-01,\n",
      "        -4.2384e-02,  3.8935e-01, -1.5728e-01, -1.4975e+00, -1.6370e+00,\n",
      "        -9.7281e-01, -1.9961e+00, -6.1037e-01, -1.9866e+00, -8.4340e-01,\n",
      "        -6.3068e-01,  3.2903e-01, -4.7673e-01, -6.8448e-02, -1.4214e-01,\n",
      "        -3.7454e-01, -1.8325e-01, -7.9794e-01,  3.0005e-02,  5.5624e-02,\n",
      "        -1.3604e+00,  3.5885e-04, -7.1799e-01, -7.1179e-02, -1.2724e-01,\n",
      "        -1.9301e-01, -3.8874e-01,  3.4676e-01, -2.0070e-01, -5.1852e-02,\n",
      "        -1.2584e+00, -2.9590e-01, -9.2018e-01, -1.4067e+00, -2.3731e-01,\n",
      "        -4.2230e-01, -2.3012e-01, -3.2656e-01, -1.6698e-01, -3.4310e-01,\n",
      "         1.3472e-02, -1.5940e-01,  1.1610e-01,  4.3576e-01,  2.4816e-01,\n",
      "        -1.4478e+00, -2.1457e-02, -2.8412e+00, -5.1917e-02, -1.5254e-01,\n",
      "        -3.9755e-01,  6.9830e-02, -2.2402e-01,  7.1978e-02, -1.6742e-01,\n",
      "        -1.2407e-02,  3.8249e-02,  6.1076e-01,  5.9012e-02,  2.7457e-02,\n",
      "        -7.3838e-01, -1.1116e+00, -1.5409e+00, -1.4766e+00, -5.3786e-01,\n",
      "        -2.6132e-01, -3.7024e-01, -1.3499e-02, -1.5131e-01, -1.4990e-01,\n",
      "        -1.1591e+00,  3.6243e-01,  1.7993e-01, -6.3538e-01, -1.4291e-01,\n",
      "        -3.6626e-01, -5.2421e-01, -5.3214e-01, -8.1760e-01,  3.1384e-01,\n",
      "         3.9797e-01, -8.7344e-01, -1.4857e+00,  1.3635e-01, -2.6238e-01,\n",
      "        -5.8112e-01, -2.3401e-01, -4.5402e-01,  6.6974e-02, -4.7625e-01,\n",
      "        -5.0613e-01, -7.3066e-01, -4.9598e-02, -1.5501e+00,  4.4272e-02,\n",
      "        -3.2090e-01, -1.3513e+00, -2.4577e-01, -1.0437e-01, -5.3862e-01,\n",
      "        -8.6092e-02, -1.2414e+00, -1.1514e+00,  1.2458e-01,  1.1319e-01,\n",
      "        -5.6087e-01, -1.7200e-01, -2.0641e+00, -2.1636e+00, -3.2447e-01,\n",
      "        -1.6643e-01, -1.3531e+00,  4.8575e-01,  7.7935e-03, -1.5250e+00,\n",
      "        -4.5775e-01,  1.8345e-02, -5.5482e-01, -1.5397e+00, -4.3795e-01,\n",
      "        -3.2829e-01, -9.7584e-01,  3.4037e-01, -8.0647e-01, -1.8454e-02,\n",
      "        -2.5270e-01, -1.2341e-01,  1.8001e-01, -8.0030e-03,  4.3622e-01,\n",
      "        -8.1586e-01, -3.7867e-01, -9.7960e-01, -1.8670e-01,  2.8214e-01,\n",
      "        -3.1721e-01, -1.0150e+00, -5.0256e-01,  2.8834e-01, -1.1686e+00,\n",
      "        -3.3827e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.4011]],\n",
      "\n",
      "         [[-0.2268]],\n",
      "\n",
      "         [[-0.2485]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1934]],\n",
      "\n",
      "         [[-0.2452]],\n",
      "\n",
      "         [[-0.1551]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2317]],\n",
      "\n",
      "         [[-0.2368]],\n",
      "\n",
      "         [[-0.3562]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1162]],\n",
      "\n",
      "         [[ 0.1061]],\n",
      "\n",
      "         [[-0.2268]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0842]],\n",
      "\n",
      "         [[-0.0329]],\n",
      "\n",
      "         [[-0.4070]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1246]],\n",
      "\n",
      "         [[-0.4087]],\n",
      "\n",
      "         [[-0.2171]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3992]],\n",
      "\n",
      "         [[-0.1853]],\n",
      "\n",
      "         [[-0.4793]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0562]],\n",
      "\n",
      "         [[ 0.0074]],\n",
      "\n",
      "         [[-0.2014]]],\n",
      "\n",
      "\n",
      "        [[[-0.0647]],\n",
      "\n",
      "         [[ 0.0111]],\n",
      "\n",
      "         [[ 0.0126]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1171]],\n",
      "\n",
      "         [[ 0.2466]],\n",
      "\n",
      "         [[ 0.5965]]],\n",
      "\n",
      "\n",
      "        [[[-2.4464]],\n",
      "\n",
      "         [[ 0.1259]],\n",
      "\n",
      "         [[-0.3787]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3036]],\n",
      "\n",
      "         [[ 0.0349]],\n",
      "\n",
      "         [[-1.8823]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.2027, -0.0745,  0.1453, -0.0204, -0.0398, -0.0457,  0.1828,  0.0761,\n",
      "         0.0883,  0.1356, -0.3684,  0.0468,  0.1166,  0.1593, -0.3332, -0.0037,\n",
      "        -0.0021,  0.1983, -0.2218, -0.3944, -0.0578,  0.2577, -0.0179, -0.0213],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.1565]],\n",
      "\n",
      "         [[-0.1508]],\n",
      "\n",
      "         [[-0.3224]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3099]],\n",
      "\n",
      "         [[-0.0353]],\n",
      "\n",
      "         [[-0.0154]]],\n",
      "\n",
      "\n",
      "        [[[-0.2896]],\n",
      "\n",
      "         [[ 0.0454]],\n",
      "\n",
      "         [[-0.6723]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4737]],\n",
      "\n",
      "         [[-0.7075]],\n",
      "\n",
      "         [[ 0.1097]]],\n",
      "\n",
      "\n",
      "        [[[-0.3158]],\n",
      "\n",
      "         [[-0.0872]],\n",
      "\n",
      "         [[-0.0064]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0995]],\n",
      "\n",
      "         [[ 0.0399]],\n",
      "\n",
      "         [[-0.2900]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0220]],\n",
      "\n",
      "         [[ 0.0535]],\n",
      "\n",
      "         [[ 0.2770]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0944]],\n",
      "\n",
      "         [[ 0.2763]],\n",
      "\n",
      "         [[-0.6768]]],\n",
      "\n",
      "\n",
      "        [[[-0.1835]],\n",
      "\n",
      "         [[ 0.1281]],\n",
      "\n",
      "         [[-0.1677]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0863]],\n",
      "\n",
      "         [[ 0.4080]],\n",
      "\n",
      "         [[-0.1245]]],\n",
      "\n",
      "\n",
      "        [[[-0.0919]],\n",
      "\n",
      "         [[-0.7382]],\n",
      "\n",
      "         [[ 0.1659]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1113]],\n",
      "\n",
      "         [[-0.7321]],\n",
      "\n",
      "         [[ 0.3724]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0741, -0.5367, -0.0717, -0.1753,  0.1786,  0.0718,  0.4553,  0.6674,\n",
      "         0.5197,  0.0118, -0.3497,  0.4312,  0.3863, -0.1302,  0.1903,  0.1223,\n",
      "         0.3527,  0.0950,  0.1533,  0.1551,  0.2764, -0.2641, -0.0585,  0.4949,\n",
      "         0.0427,  0.2520,  0.4603,  0.1205,  0.1523, -0.5879,  0.6296,  0.7616,\n",
      "        -0.1382,  0.3164,  0.0931, -0.3068,  0.1953,  0.0406, -0.2956,  0.1952,\n",
      "         0.9399, -0.0636, -0.1689,  0.2005, -0.1326,  0.2495,  0.1066,  0.1534,\n",
      "        -0.1702,  0.5577,  0.1921,  0.1888,  0.4694,  0.1227,  0.1849,  0.2771,\n",
      "        -0.0866,  0.4725, -0.0566,  0.1718,  0.2073,  0.5737,  0.5301,  0.1152,\n",
      "         0.1189,  0.3619, -0.4691,  0.8422,  0.2843,  0.5295,  0.1783,  0.2219,\n",
      "         0.7430, -0.1719,  0.1172,  0.2828,  0.3945, -0.6368,  0.0617,  0.1363,\n",
      "        -0.0644,  0.2628, -0.1225,  0.1091,  0.1690,  0.6660,  0.2628,  0.6463,\n",
      "         0.0189,  0.0222,  0.3503,  0.3049,  0.6757,  0.7309,  0.0573, -0.1230,\n",
      "         0.5937,  0.3917, -0.2163,  0.4842,  0.4002,  0.9295,  0.7161,  0.4032,\n",
      "         0.2072,  0.4678,  0.5275,  0.3858,  0.3597,  0.4171,  0.1646,  0.2633,\n",
      "        -0.0458, -0.4790, -0.1187,  0.2374,  0.1217,  0.1033, -0.0989, -0.4075,\n",
      "         0.3941,  0.1238, -0.2956,  0.1740,  0.2547,  0.1366,  0.0058,  0.2116,\n",
      "         0.0844, -0.5332,  0.0309,  0.1364,  0.4558,  0.3902,  0.5364, -0.0732,\n",
      "         0.2741,  0.9226,  0.5292,  0.6838, -0.0276,  1.2066, -0.0322, -0.1631,\n",
      "        -0.0741,  0.2403,  0.1896,  0.4684,  0.6010, -0.0997,  0.4546,  1.2780,\n",
      "         0.3218, -0.0836,  0.2722,  0.1470,  0.2544,  0.1577,  0.1269,  0.1132,\n",
      "         0.7115,  0.1528, -0.0608,  0.1034,  0.3099, -0.0542, -0.3616,  0.2761,\n",
      "         0.3606,  0.6959,  0.3615, -0.0396,  0.4538,  0.8885,  0.3890,  0.4409,\n",
      "         0.4617,  0.3935,  0.1949,  0.1996,  0.2217, -0.0501, -0.4285, -0.1087,\n",
      "         0.3662,  0.2272, -0.0632,  0.1569,  0.0082,  0.8186,  0.2757, -0.1022,\n",
      "         0.4998,  0.1522,  0.3005, -0.0411,  0.1559,  0.3143,  0.5875,  0.2556,\n",
      "         0.5203,  0.1567,  0.8531,  0.9248,  0.2695,  0.5763,  0.2345,  0.6495,\n",
      "         0.1481,  0.4258,  0.2062,  1.0035, -0.1801,  0.3538,  0.9564,  0.2486,\n",
      "         0.2828,  0.3926, -0.1316,  0.3546,  0.1806,  0.1117,  0.2576,  0.1710,\n",
      "         0.6655,  0.1862,  0.0428,  0.3881, -0.0808,  0.3414,  0.2516,  0.6183,\n",
      "         0.6951,  0.3804,  0.4713,  0.9330, -0.2752,  0.4242, -0.1332,  0.3675,\n",
      "        -0.0098, -0.0432,  0.5888,  0.1252,  0.4010, -0.1994,  0.4712,  0.2275,\n",
      "         1.1294, -0.4723, -0.0198,  0.0365,  0.8770, -0.0561,  0.2626,  0.3355,\n",
      "         0.1850,  0.3704,  0.1450, -0.1592,  0.4926,  0.2794,  0.4076,  0.2558,\n",
      "         0.3318,  0.0116, -0.6576,  0.7881,  0.6058,  0.0545,  0.5699,  0.4562,\n",
      "         0.0955,  0.8217, -0.1265,  0.1767,  0.3899,  0.0753,  0.0801,  0.0335,\n",
      "         0.5200,  1.1726,  0.1878,  0.5983,  0.0770,  0.4336,  0.1623,  0.6332,\n",
      "         0.5540,  0.1461,  0.9140,  0.4362,  0.0707, -0.0742,  0.5371, -0.4100,\n",
      "         0.3393,  0.7588, -0.3113,  0.5993, -0.2895,  0.2657,  0.6723,  0.3052,\n",
      "        -0.0964,  0.4379,  0.6797,  0.5039,  0.4777,  0.0895,  0.3435,  0.2436,\n",
      "        -0.0268, -0.1332,  0.2154,  0.1939,  0.4774,  0.0980,  0.1297, -0.1709,\n",
      "         0.7218, -0.1790,  0.5250,  0.2638,  0.2170,  0.2963, -0.0510,  0.2295,\n",
      "         0.8175, -0.0933,  0.3269,  0.0598,  0.3601,  0.4836,  0.0610, -0.2248,\n",
      "         0.5707,  0.3645,  0.6771,  0.5525,  0.1760,  0.6267,  0.0591,  0.4936,\n",
      "         0.5809, -0.0855, -0.3541,  0.0353, -0.6747,  0.4820,  0.1174,  0.0872,\n",
      "         0.4826,  0.1979, -0.0866,  0.4805, -0.0962,  0.3638,  0.8295,  0.1592,\n",
      "         0.1810,  0.1149,  0.5947,  0.0231,  0.0254,  0.0278,  0.1028, -0.3362,\n",
      "         0.2420, -0.1151,  0.8047,  0.5420,  0.3695,  0.9281,  0.8722,  0.1096,\n",
      "         0.7918,  0.0421, -0.4318, -0.0359, -0.0937,  0.5768,  0.0148, -0.0153,\n",
      "         0.0083,  0.3044,  0.7344, -0.4895, -0.1938,  0.3231, -0.1151,  0.2239,\n",
      "        -0.3171,  0.0542,  0.2768,  0.4335,  0.2929,  0.3180,  0.0431,  0.2324,\n",
      "         0.2037,  0.1354,  0.1475,  0.0909,  0.2995,  0.4330,  0.1711, -0.3382,\n",
      "        -0.2084,  0.0943, -0.3303,  0.0983,  0.5076,  0.1511,  0.3313,  0.1675,\n",
      "         0.5248,  0.4947,  0.4312,  0.3357,  0.1730,  0.0863, -0.1315,  0.2307,\n",
      "         0.0973,  0.1936,  0.2287,  0.4233,  0.0039, -0.2580,  0.3249, -0.2038,\n",
      "         0.4825,  0.7774,  0.4723,  0.0862,  0.9111, -0.4337,  0.2430,  0.4138,\n",
      "         0.2638, -0.1604,  0.2758,  0.1965, -0.3981,  0.4545,  0.6599, -0.0130,\n",
      "         0.5821,  0.4189,  0.1429, -0.2606,  0.1375,  0.6022,  0.7360,  0.4463,\n",
      "         0.4501,  0.2882,  0.5212,  0.2680,  0.0837,  0.0113, -0.2363, -0.0200,\n",
      "        -0.3589,  0.3832, -0.2995, -0.5104, -0.0210,  0.3634,  0.1121,  0.2678,\n",
      "         0.2179,  0.0212,  1.2218, -0.1078,  0.4987,  0.3246,  0.4513,  0.5936,\n",
      "         0.3665, -0.0373, -0.2678,  0.2740,  0.0225,  0.1465,  0.9106,  1.0367,\n",
      "         0.4172,  0.4848,  0.2748,  0.1066,  0.8225,  0.0883, -0.2531, -0.0213,\n",
      "         0.5612,  0.4981, -0.3244,  0.2527,  0.0303, -0.1626,  0.3648,  0.1262,\n",
      "         0.1842, -0.3237,  0.3961,  0.4164, -0.0394,  0.2481, -0.0794,  0.2601,\n",
      "         0.2099, -0.0441,  0.3148,  0.5123, -0.3521,  0.5052,  0.4033, -0.0769,\n",
      "         0.5428, -0.1033, -0.1187,  0.2007, -0.0770,  0.0428,  0.1739,  0.6122,\n",
      "         0.5377,  0.3044, -0.2585,  0.2786,  0.1791,  0.8522,  0.9378, -0.2252,\n",
      "         0.3632,  0.0239, -0.1116,  0.5103,  0.3534,  0.3827,  0.2903,  0.4674,\n",
      "         0.3291,  0.4211,  0.1896, -0.4286,  0.4232,  0.4022,  0.2285,  0.6128,\n",
      "         0.1936, -0.0593, -0.0546,  0.5102,  0.2446,  0.5473,  0.2488,  0.3980,\n",
      "         0.4513,  0.1706,  0.2902, -0.5458,  0.8680,  0.5111, -0.0471,  0.6619,\n",
      "         0.3640,  0.7005,  0.4288,  0.8896,  0.0488, -0.0705, -0.1481, -0.0748],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0121]],\n",
      "\n",
      "         [[-0.4742]],\n",
      "\n",
      "         [[-0.6174]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2870]],\n",
      "\n",
      "         [[-0.0282]],\n",
      "\n",
      "         [[-0.5583]]],\n",
      "\n",
      "\n",
      "        [[[-0.3388]],\n",
      "\n",
      "         [[ 0.5038]],\n",
      "\n",
      "         [[ 0.0298]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2563]],\n",
      "\n",
      "         [[ 0.0712]],\n",
      "\n",
      "         [[-0.0865]]],\n",
      "\n",
      "\n",
      "        [[[-0.1517]],\n",
      "\n",
      "         [[-0.3459]],\n",
      "\n",
      "         [[ 0.5226]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0168]],\n",
      "\n",
      "         [[-0.1304]],\n",
      "\n",
      "         [[ 0.0135]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6775]],\n",
      "\n",
      "         [[-0.1162]],\n",
      "\n",
      "         [[-0.0566]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4150]],\n",
      "\n",
      "         [[ 0.3754]],\n",
      "\n",
      "         [[ 0.2552]]],\n",
      "\n",
      "\n",
      "        [[[-0.4715]],\n",
      "\n",
      "         [[ 0.5046]],\n",
      "\n",
      "         [[-0.3867]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1160]],\n",
      "\n",
      "         [[ 0.3810]],\n",
      "\n",
      "         [[-0.0192]]],\n",
      "\n",
      "\n",
      "        [[[-0.4281]],\n",
      "\n",
      "         [[ 0.4987]],\n",
      "\n",
      "         [[-0.3967]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2472]],\n",
      "\n",
      "         [[ 0.4347]],\n",
      "\n",
      "         [[ 0.6196]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([4.2990, 5.5966, 5.4639, 4.7628, 5.2784, 8.1959, 4.8008, 5.1656, 3.6381,\n",
      "        4.9078, 7.0026, 5.2400, 4.5400, 6.0284, 4.5847, 4.8943, 8.5956, 4.0952,\n",
      "        4.7667, 5.2151, 4.2155, 4.2052, 4.9608, 3.9035, 4.4168, 4.7180, 6.1482,\n",
      "        7.0318, 7.0925, 7.6672, 5.0526, 6.9244, 4.6618, 5.3049, 3.5213, 6.6776,\n",
      "        5.2210, 5.2873, 4.8907, 5.6009, 3.7019, 4.3329, 6.3879, 6.6001, 5.0830,\n",
      "        3.8391, 4.8841, 4.2127, 5.0148, 4.1886, 6.8892, 4.5756, 4.3553, 6.3593,\n",
      "        4.9180, 6.1804, 4.7295, 6.5534, 4.6911, 5.2201, 4.5235, 8.0401, 5.7514,\n",
      "        3.9957, 8.7429, 5.4592, 5.9904, 4.7069, 4.4450, 6.9506, 4.2235, 4.9993,\n",
      "        4.0477, 5.3890, 3.2341, 5.5493, 3.5157, 4.1368, 4.0433, 5.9505, 6.2090,\n",
      "        6.6481, 4.4926, 6.0112, 4.5038, 6.2927, 4.4510, 5.5617, 3.6905, 6.5889,\n",
      "        4.0496, 4.5255, 4.0141, 4.9996, 6.7355, 2.8046, 6.2745, 5.6118, 4.4130,\n",
      "        5.7718, 3.5834, 8.4685, 6.9463, 5.0501, 4.4654, 4.7733, 3.3299, 3.7347,\n",
      "        5.3130, 6.1647, 2.9099, 4.4723, 5.1965, 4.1614, 5.7154, 4.3078, 4.6206,\n",
      "        4.5236, 3.7989, 4.1433, 4.8396, 4.6238, 5.0341, 4.8170, 4.5958, 3.9543,\n",
      "        4.3819, 9.6273, 4.1693, 4.5012, 3.9439, 3.7217, 8.0274, 3.6024, 5.2625,\n",
      "        4.7266], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-9.6430e-03,  4.0333e-03,  4.5499e-03, -1.5982e-02, -9.0166e-03,\n",
      "        -9.8238e-03,  4.3800e-04,  1.6884e-03, -5.0065e-03,  9.1215e-03,\n",
      "         1.2184e-02, -8.6133e-03,  1.7469e-02,  8.5974e-03,  1.5147e-02,\n",
      "        -5.9126e-03,  8.3034e-03,  8.5945e-03,  9.5902e-05, -2.0846e-02,\n",
      "         8.7804e-03, -1.4925e-02, -2.2687e-03, -5.3834e-03, -2.1945e-03,\n",
      "        -3.9263e-03,  1.2663e-02, -1.7523e-03, -2.9088e-03, -5.5997e-03,\n",
      "         1.8290e-03,  1.8386e-02, -2.0404e-02,  3.8490e-03, -1.5188e-02,\n",
      "         3.4174e-03, -1.0966e-02, -9.5104e-03,  1.4581e-02, -6.7278e-03,\n",
      "        -1.4303e-02, -1.4978e-02, -2.7019e-04,  6.4373e-03, -2.2228e-03,\n",
      "        -6.0684e-03,  4.4871e-03, -8.0583e-03, -2.6887e-03,  4.3227e-03,\n",
      "         6.7453e-04, -1.1047e-03, -4.3973e-03,  1.6252e-02,  1.0390e-02,\n",
      "         2.6516e-02, -8.8681e-04, -7.1312e-05, -1.0797e-02,  2.9679e-03,\n",
      "         1.3805e-03,  2.2377e-02,  2.2004e-02,  8.5606e-04, -1.2016e-02,\n",
      "         1.1156e-02, -9.3804e-04,  1.9669e-02, -1.4107e-03, -1.5277e-02,\n",
      "        -1.7723e-03, -3.7259e-03, -4.1257e-03, -1.2825e-02,  1.5871e-02,\n",
      "         4.9741e-03,  9.0643e-04, -5.2338e-03,  2.3526e-03, -7.3030e-03,\n",
      "        -9.7603e-03,  7.9253e-03,  3.5612e-04,  1.8416e-02,  4.8621e-03,\n",
      "         6.0630e-03,  1.5353e-02,  2.4586e-04, -8.9708e-03,  5.1801e-04,\n",
      "         4.4746e-04,  1.2525e-02, -2.4659e-03, -1.7144e-02, -1.8015e-02,\n",
      "        -6.6092e-04, -3.0097e-03, -1.7374e-02,  5.1928e-03,  1.8226e-02,\n",
      "         2.1365e-03, -2.1476e-02, -1.5243e-02,  5.7531e-03, -6.2058e-04,\n",
      "         1.2515e-03, -1.1586e-02, -7.5773e-03,  1.0405e-03,  4.5024e-03,\n",
      "         5.0155e-03,  2.4373e-03,  1.3823e-03, -4.9886e-03, -1.9272e-02,\n",
      "        -6.0688e-03, -6.8065e-03,  5.7492e-03,  3.3441e-03,  1.0511e-02,\n",
      "        -1.9375e-02, -9.6751e-03,  5.3757e-03, -1.4069e-02, -7.6047e-03,\n",
      "        -2.7639e-03,  7.6419e-03,  1.2311e-02,  2.8162e-03,  1.0406e-02,\n",
      "         5.0689e-03,  1.7361e-02, -2.5294e-02, -2.4631e-03, -1.0336e-03,\n",
      "         1.2870e-02], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0520]],\n",
      "\n",
      "         [[ 0.5053]],\n",
      "\n",
      "         [[ 0.1247]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4654]],\n",
      "\n",
      "         [[ 0.1020]],\n",
      "\n",
      "         [[-0.7930]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0867]],\n",
      "\n",
      "         [[-0.5304]],\n",
      "\n",
      "         [[ 0.3605]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1755]],\n",
      "\n",
      "         [[ 0.0672]],\n",
      "\n",
      "         [[ 0.0483]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2433]],\n",
      "\n",
      "         [[ 0.2017]],\n",
      "\n",
      "         [[ 0.4137]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1616]],\n",
      "\n",
      "         [[ 0.1054]],\n",
      "\n",
      "         [[-0.2686]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0279]],\n",
      "\n",
      "         [[ 0.2217]],\n",
      "\n",
      "         [[-0.4404]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1027]],\n",
      "\n",
      "         [[-0.2690]],\n",
      "\n",
      "         [[-0.5850]]],\n",
      "\n",
      "\n",
      "        [[[-0.3084]],\n",
      "\n",
      "         [[-0.0191]],\n",
      "\n",
      "         [[-0.2357]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3351]],\n",
      "\n",
      "         [[-0.4033]],\n",
      "\n",
      "         [[-0.2185]]],\n",
      "\n",
      "\n",
      "        [[[-0.2267]],\n",
      "\n",
      "         [[ 0.0559]],\n",
      "\n",
      "         [[ 0.0766]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4570]],\n",
      "\n",
      "         [[-0.2030]],\n",
      "\n",
      "         [[ 0.1236]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.2806,  1.3163, -0.0809,  1.5777,  1.0733,  1.2829,  0.6936,  1.3691,\n",
      "         1.3780,  1.0231,  0.8248,  1.5372,  1.2748,  1.0445,  0.9909,  1.1601,\n",
      "         0.7786,  1.7689,  0.8334,  1.2707,  1.0458,  1.1895,  1.0810,  1.0768,\n",
      "         1.2890,  1.1684,  0.7002,  1.4080,  1.0779,  0.7279,  1.9201,  1.5344,\n",
      "         1.7651,  1.3740,  0.3656,  1.2914,  0.8255,  1.1371,  1.8845,  1.3293,\n",
      "         1.4883,  1.1272,  2.0329,  1.4969,  0.7930,  0.8922,  1.7965,  1.3646,\n",
      "         0.3689,  1.6139,  0.7696,  1.6001,  1.5214,  1.0533,  0.9557,  1.5376,\n",
      "         1.3608,  1.1266,  0.3336,  1.9923,  1.1191,  1.0118,  0.9085,  1.1249,\n",
      "         1.8204,  0.2992,  1.5699,  0.8307,  1.0522,  1.2196,  0.9555,  1.2893,\n",
      "         1.4234,  1.1301,  0.5238,  0.6333,  0.5652,  1.1989,  0.8493,  1.0381,\n",
      "         1.0909,  1.4581,  1.5049,  1.1498,  1.2063,  0.8524,  0.8645,  1.1006,\n",
      "         1.1374,  1.0749,  0.4224,  0.8634,  1.2171,  1.5407,  1.2067,  1.2762,\n",
      "         0.6350,  1.7241,  0.4082,  0.9986,  1.3107,  0.7913,  1.4440,  0.8596,\n",
      "         1.0469,  0.8857,  1.6004,  0.5505,  0.5113,  1.2064,  1.9488,  2.0784,\n",
      "         1.9917,  1.1460,  1.0069,  1.4360,  0.8603,  0.6343,  1.2817,  1.3036,\n",
      "         1.3538,  1.3061,  0.5020,  1.5276,  1.3081,  1.1863,  0.9483,  1.3832,\n",
      "         0.8817,  1.4240,  1.1663,  1.1533,  0.8280,  1.0637,  0.8171,  1.0691,\n",
      "         2.4202,  2.7224,  0.7969,  1.1405,  1.0578,  0.9561,  0.5693,  1.2022,\n",
      "         1.0251,  1.6221,  1.3478,  1.5358,  0.6700,  1.2714,  1.4598,  1.2562,\n",
      "         1.7646,  0.5984,  1.5500,  1.4148,  1.2338,  0.6688,  0.6686,  0.8760,\n",
      "         1.2868,  1.1711,  0.2502,  1.5692,  0.9485,  1.0945,  0.7138,  1.0695,\n",
      "         1.0903,  1.2261,  0.3191,  0.8182,  1.2340,  1.0267,  0.3677,  1.2855,\n",
      "         1.6195,  1.3520,  0.8262,  0.9747,  0.9126,  0.6286,  1.3021,  0.9617,\n",
      "         0.9399,  0.7742,  0.9461,  1.4864,  1.9968,  1.3464,  1.3806,  0.7928,\n",
      "         0.4624,  1.5874,  1.1359,  0.8634,  1.9811,  1.2916,  1.3672,  0.9295,\n",
      "         1.5413,  1.5579,  1.5093,  0.6962,  0.7178,  1.0338,  1.4054,  1.0749,\n",
      "         1.3596,  1.3721,  1.0319,  0.9621,  0.9393,  1.0129,  0.6554,  0.7255,\n",
      "         1.1754,  1.4682,  1.3866,  1.9624,  1.3307,  1.0421,  1.2675,  0.7782,\n",
      "         0.4618,  1.3147,  1.4366,  1.0102,  1.5668,  0.4938,  1.1116,  0.7201,\n",
      "         0.9794,  1.0624,  1.1592, -0.0399,  0.9215,  0.9434,  1.5825,  1.5473,\n",
      "         1.9348,  1.2324,  0.5302,  1.0586,  0.9072,  1.2167,  0.6882,  0.6774,\n",
      "         1.4122,  1.1261,  1.6085,  0.9592,  1.1182,  1.2052,  1.7810,  0.6261,\n",
      "         1.3578,  1.0273,  0.3854,  1.7464,  1.4259,  0.4455,  1.7369,  0.5071,\n",
      "         1.5079,  0.8438,  1.2413,  0.7117,  0.7089,  0.5208,  0.7629,  1.1796,\n",
      "         1.3252,  1.2573,  0.5559,  1.6071,  1.3614,  0.6511,  1.1251,  1.0966,\n",
      "         0.9667,  1.2241,  1.7531,  1.2470,  1.4424,  1.2932,  0.8855,  1.7308,\n",
      "         0.5047,  0.6731,  1.6560,  0.5422,  1.4323,  0.9926,  1.7105,  1.0178,\n",
      "         1.0898,  1.6335,  1.0117,  0.7537,  1.8031,  1.2948,  1.1729,  1.1632,\n",
      "         0.7048,  1.2942,  0.3282,  1.0991,  0.8404,  1.5338,  0.4777,  0.7484,\n",
      "         1.2189,  1.0260,  0.9436,  1.2734,  0.3172,  1.8406,  1.3562,  1.1947,\n",
      "         1.3979,  0.4669,  1.8714,  1.1592,  1.1942,  1.0663,  1.4766,  1.7313,\n",
      "         1.7992,  1.1279,  1.1510,  0.4607,  1.0462,  1.2428,  1.3195,  1.3694,\n",
      "         1.7456,  0.8593,  0.8381,  1.7480,  0.4812,  1.5467,  1.2947,  0.8961,\n",
      "         1.1238,  1.6610,  0.4435,  0.9680,  0.9058,  1.1404,  0.5401,  1.0694,\n",
      "         1.8312,  1.4210,  1.2635,  1.1695,  1.1134,  1.4860,  1.4225,  1.7166,\n",
      "         1.6531,  1.5108,  1.1802,  1.4411,  0.5605,  1.0886,  1.4931,  1.2974,\n",
      "         0.8138,  2.1589,  1.7324,  0.6794,  0.9623,  1.0747,  1.3859,  1.3031,\n",
      "         1.2097,  0.9097,  0.9140,  0.6144,  0.6235,  1.4053,  0.5386,  0.9181,\n",
      "         1.1751,  0.9620,  0.8978,  1.3898,  1.4230,  1.2409,  1.0739,  1.0414,\n",
      "         1.1960,  0.6670,  0.9572,  1.3698,  0.2789,  1.0916,  1.4960,  1.6428,\n",
      "         0.6363,  1.2006,  1.2328,  0.9486,  0.8686,  1.0946,  1.1495,  1.6763,\n",
      "         1.2742,  1.1481,  1.0034,  1.2605,  1.3535,  1.0789,  1.2486,  1.2530,\n",
      "         1.5373,  1.3020,  1.6973,  0.3366,  1.7505,  1.0573,  1.3366,  0.7960,\n",
      "         1.6973,  0.9583,  1.4822,  1.6347,  1.0053,  0.6718,  0.4184,  0.4985,\n",
      "         1.8430,  0.4848,  1.0750,  0.8038,  0.8941,  1.1476,  1.0811,  0.9411,\n",
      "         1.0140,  0.6606,  1.1894,  1.0496,  1.0817,  1.3594,  0.9068,  1.0998,\n",
      "         1.1547,  0.9957,  1.0610,  1.5252,  0.6810,  1.2390,  1.7307,  2.0717,\n",
      "         1.3347,  0.8400,  1.3210,  0.9243,  0.8739,  0.8071,  1.1841,  0.2811,\n",
      "         0.6820,  0.4645,  0.8449,  0.5090,  0.5944,  0.3944,  1.5584,  1.6154,\n",
      "         0.9026,  0.9457,  0.4688,  0.9269,  0.4538,  1.0504,  0.3667,  1.4593,\n",
      "         1.2667,  0.2949,  1.1942,  1.0438,  1.3668,  1.2211,  1.0284,  0.9970,\n",
      "         1.6103,  0.3201,  0.8898,  0.3780,  1.4390,  1.2993,  1.0042,  1.2053,\n",
      "         0.8697,  0.5476,  0.9930,  0.4924,  1.1501,  1.0361,  1.1500,  0.8123,\n",
      "         1.1362,  1.3518,  0.7653,  0.7898,  1.3429,  1.2964,  1.2863,  0.8222,\n",
      "         1.1252,  1.1774,  1.3577,  0.3654,  0.5150,  1.2230,  1.5639,  1.1303,\n",
      "         1.7022,  2.1761,  0.4117,  0.6432,  0.6014,  1.1994,  0.5710,  0.8840,\n",
      "         1.4759,  0.7486,  2.1401,  0.1354,  1.4260,  1.0104,  0.8985,  1.1350,\n",
      "         1.6363,  0.9901,  1.4485,  1.1872,  0.5364,  1.2083,  1.3339,  1.9223,\n",
      "         1.5729,  1.6817,  0.4972,  1.6819,  1.2277,  0.3187,  1.6397,  1.5492,\n",
      "         0.5556,  1.2728,  1.1657,  2.2209,  1.4237,  1.2985,  1.0430,  0.3246,\n",
      "         1.1702,  1.1399,  1.0482,  1.0775,  0.7731,  1.5892,  0.9542,  0.2572,\n",
      "         1.3624,  0.8054,  1.4321,  0.6498,  1.2979,  1.3974,  0.8445,  1.4624,\n",
      "         1.2254,  1.4085,  0.8516,  0.8133,  0.7185,  0.9708,  1.2038,  1.1371,\n",
      "        -0.2386,  0.9888,  1.6909,  0.8687,  1.3356,  0.7403,  1.0556,  1.0647,\n",
      "         1.0354,  0.8355,  1.2592,  0.0243,  0.9030,  0.4909,  0.7630,  2.0553,\n",
      "         1.3645,  0.7811,  0.2469,  1.5814,  0.6312,  1.6959,  0.5792,  0.5189,\n",
      "         1.2102,  1.0064,  0.8538,  0.3779,  1.5887,  0.5748,  1.5084,  0.9047,\n",
      "         0.8467,  1.4051,  0.4051,  1.4068,  1.2812,  1.4594,  0.8162,  0.6312,\n",
      "         2.0533,  1.1501,  0.5743,  1.1606,  1.3856,  1.4810,  0.5959,  0.9232,\n",
      "         0.9449,  1.0839,  1.4969,  0.2564,  1.5901,  1.0088,  1.2567,  1.1808,\n",
      "         0.3420,  1.2595,  1.7834,  0.8980,  0.8796,  1.0970,  0.8797,  0.8091,\n",
      "         1.6850,  0.2047,  1.1677,  0.7343,  1.1494,  1.1973,  1.2835,  0.7301,\n",
      "         1.1149,  0.9294,  0.9548,  1.0504,  1.6460,  0.5721,  1.2790,  0.9345,\n",
      "         0.8530, -0.1271,  1.0014,  0.8888,  1.2397,  0.8565,  1.0530,  0.7242,\n",
      "         0.9750,  1.2605,  1.5836,  0.7360,  0.7414,  1.1700,  1.1459,  1.8209,\n",
      "         1.2573,  1.2271,  1.4831,  1.2357,  1.2819,  1.1349,  1.3102,  1.8285,\n",
      "         0.9913,  1.4663,  0.4245,  1.1960,  0.4518,  0.9259,  1.3675,  2.0410,\n",
      "         1.6229,  0.8360,  1.0375,  1.2743,  0.6725,  1.4351,  0.7725,  1.6331,\n",
      "         1.0111,  0.6413,  0.9383,  1.4199,  1.1330,  0.9682,  0.9851,  1.5600,\n",
      "         1.0642,  0.7842,  0.7587,  0.9960,  0.9332,  1.4732,  1.2000,  0.5605,\n",
      "         1.2231,  1.1608,  0.9341,  1.2725,  1.2919,  0.6071,  1.1996,  1.4761,\n",
      "         1.3224,  0.7546,  1.1452,  1.4426,  1.1339,  1.0352,  1.3365,  1.6142,\n",
      "         0.7202,  0.6900,  1.0881,  0.2843,  1.2916,  0.7854,  1.0403,  1.4123,\n",
      "         1.2143,  1.7268,  0.8809,  0.5390,  1.2070,  0.5012,  1.8208,  1.1981,\n",
      "         0.9716,  1.3069,  0.7002,  1.0981,  1.3677,  1.4715,  0.8168,  1.2892,\n",
      "         2.8248,  0.6997,  1.1467,  1.0099,  0.1750,  1.1937,  1.5922,  1.1915,\n",
      "         1.0809,  1.4746,  1.6815,  0.9543,  1.8472,  0.6616,  1.3247,  1.2058,\n",
      "         1.3806,  1.1366,  1.7991,  1.5570,  1.2050,  1.4079,  0.8913,  1.8987,\n",
      "         1.0986,  0.5987,  0.5523,  0.2993,  1.2270,  1.2607,  1.0219,  1.6683,\n",
      "         0.5998,  1.9032,  0.6762,  0.3130,  0.6836,  1.2518,  0.7967,  0.9112,\n",
      "         1.4019,  1.0442,  1.3396,  1.3772,  1.3001,  1.3417,  1.3750,  1.8210,\n",
      "         1.1271,  0.1804,  0.1854,  0.5551,  1.1928,  0.6461,  1.4582,  1.1234],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.7818e-02, -7.6167e-01,  1.0162e+00, -1.7105e+00, -1.4513e+00,\n",
      "        -1.3388e+00, -2.7956e-01, -6.3329e-01,  6.9777e-01, -2.0329e+00,\n",
      "        -1.9374e+00, -4.4268e-01, -7.0551e-01, -1.7397e+00,  7.0933e-01,\n",
      "         7.3085e-01,  1.8330e-01,  8.8523e-01,  1.4868e+00,  1.4760e-01,\n",
      "        -1.1599e+00,  5.9605e-01, -1.6841e+00, -3.0176e+00, -1.0734e+00,\n",
      "        -2.5661e+00, -5.2831e-01, -5.4981e-01, -1.6526e+00,  1.3338e-01,\n",
      "        -1.0391e+00, -2.2702e+00, -1.4463e+00,  1.8924e-01,  5.1087e-01,\n",
      "        -8.4570e-01,  5.7171e-01, -1.0353e+00, -2.1402e-01, -6.4939e-01,\n",
      "        -4.1990e-01, -8.5171e-01,  5.8544e-02, -4.7279e-01, -2.8072e-01,\n",
      "        -1.1172e+00, -7.3571e-01, -8.4659e-01, -6.7733e-01, -1.6233e-01,\n",
      "        -7.9289e-01, -4.0782e-02,  9.6599e-02, -1.8237e+00, -1.0405e-01,\n",
      "        -5.2831e-01, -1.3222e+00,  1.9255e-01,  7.9453e-01,  1.1611e-01,\n",
      "        -1.1999e+00, -1.6247e+00, -6.3454e-01, -1.3428e-01,  3.3915e-01,\n",
      "        -9.2277e-03, -2.1263e+00, -1.2095e+00, -8.3160e-01,  5.5232e-01,\n",
      "        -1.8037e+00, -4.0423e-01, -2.3536e-01, -1.2067e+00, -1.3188e-02,\n",
      "        -5.3951e-01, -1.1393e+00, -2.1468e+00, -1.2632e-01, -4.7528e-01,\n",
      "        -6.1830e-01, -2.7713e-01, -1.2720e+00, -1.1617e+00, -3.9445e-01,\n",
      "        -5.8998e-01, -7.2937e-01, -9.4730e-01,  6.2335e-01,  1.1488e+00,\n",
      "        -2.2035e-01, -3.8528e-02, -4.8657e-01, -7.2828e-01, -1.4563e+00,\n",
      "        -6.2808e-02, -1.0526e+00, -1.7349e+00, -4.2378e-01, -1.0931e+00,\n",
      "        -8.8947e-01,  1.1344e+00, -1.1827e+00, -2.3134e+00, -4.6717e-01,\n",
      "        -1.1212e+00, -1.7866e+00,  1.3587e-01, -3.3731e-02, -1.6355e+00,\n",
      "         2.4365e-01,  3.7601e-02,  7.9765e-01, -3.8041e-01, -1.3038e+00,\n",
      "         3.1195e-01, -8.9663e-01, -7.1662e-01,  2.7153e-01, -1.7216e+00,\n",
      "        -6.3488e-01, -1.1896e+00, -5.0003e-01, -1.8492e+00, -1.6740e+00,\n",
      "        -3.1452e-01, -9.2423e-02, -1.8690e+00, -2.0751e+00, -1.1237e-01,\n",
      "        -2.5502e+00, -1.4152e+00, -6.0510e-01, -9.3889e-01, -8.1198e-01,\n",
      "        -1.4892e+00,  4.5894e-01, -4.9276e-01,  1.8334e-02,  3.1242e-01,\n",
      "        -2.6526e+00,  3.6771e-01,  2.7456e-01, -3.1152e+00, -7.3422e-01,\n",
      "        -3.9708e-01, -5.7970e-01, -1.0823e+00, -9.6120e-01, -1.1299e+00,\n",
      "        -1.5477e+00, -2.3363e-01, -9.2310e-01,  3.2614e-01, -1.7154e+00,\n",
      "         3.1044e-01, -1.1952e+00, -9.7975e-01,  2.4346e-02, -8.2150e-01,\n",
      "        -2.4165e+00,  2.5981e-01,  2.7531e-01,  2.1885e-02, -1.4015e+00,\n",
      "        -2.1043e+00,  5.9856e-01, -1.3903e+00, -5.1476e-01,  3.1247e-01,\n",
      "        -2.2748e-01, -2.7463e-01, -6.9185e-01, -7.5989e-01,  2.2339e-01,\n",
      "        -2.0749e+00, -4.9019e-01, -5.1186e-01,  1.1638e-01,  4.9461e-01,\n",
      "         4.0168e-01,  5.5805e-01,  1.3356e-01, -5.5611e-01, -3.5419e-01,\n",
      "        -5.5508e-01, -4.3279e-01, -1.8246e-01,  4.0277e-01,  1.7386e-01,\n",
      "        -9.7867e-01, -1.4955e+00,  3.8088e-01,  1.4327e-01, -1.9063e+00,\n",
      "        -6.9462e-01, -5.6068e-01, -1.1359e+00, -4.2558e-01, -1.9202e+00,\n",
      "        -9.8024e-01,  8.0730e-02, -6.4260e-01, -1.5753e+00, -2.5219e-01,\n",
      "        -8.5690e-01, -6.2234e-01, -1.2672e+00, -1.4077e+00, -6.3444e-01,\n",
      "        -7.5548e-01, -6.6106e-01, -4.7131e-01, -1.4014e+00, -1.5871e+00,\n",
      "        -2.7394e-02, -9.1384e-01, -8.8583e-01,  2.7560e-01,  1.2891e-01,\n",
      "        -1.3096e+00, -1.4956e+00, -6.8960e-01, -2.3962e-02, -4.2050e-01,\n",
      "        -4.6210e-02, -1.2837e+00,  4.9260e-01, -4.6437e-01, -6.6115e-01,\n",
      "         3.5396e-03,  7.3936e-01, -1.4101e+00, -1.0441e+00, -7.0219e-01,\n",
      "        -3.1265e-01,  4.0657e-01, -9.5678e-01, -3.3325e-01,  7.2340e-01,\n",
      "        -3.6191e-02, -3.0032e-02,  9.2988e-01, -6.6070e-01,  1.4093e-01,\n",
      "        -1.6396e+00, -1.3616e+00, -1.6734e+00, -1.0123e+00, -4.5061e-02,\n",
      "         7.5036e-01, -1.3463e+00, -1.5050e+00, -8.7656e-01,  4.0766e-01,\n",
      "        -1.1277e+00, -6.6530e-01,  1.8980e-01,  1.9632e-01, -1.5864e+00,\n",
      "        -1.9567e+00, -4.1163e-01, -8.9872e-01,  6.4552e-02, -2.7108e+00,\n",
      "        -1.4061e-01,  7.7910e-02,  1.0032e-01, -3.8396e-01, -3.5018e-01,\n",
      "        -1.9230e+00, -1.7072e+00, -3.4337e-01, -6.3516e-01,  1.0405e+00,\n",
      "        -8.7172e-01, -2.9646e-01,  4.8459e-01, -1.7109e+00, -3.6925e-01,\n",
      "        -1.6008e+00, -8.7026e-01,  3.9038e-01,  2.3838e-01,  4.5491e-02,\n",
      "        -1.8051e+00, -2.1864e-02, -1.4114e+00, -8.6000e-01,  3.4718e-02,\n",
      "        -1.0175e+00, -7.2277e-02, -7.5258e-01,  5.3513e-01, -1.7815e+00,\n",
      "         6.8704e-01, -3.7346e-01, -1.6371e+00,  2.8221e-01, -1.5778e+00,\n",
      "        -1.0001e+00, -1.9894e+00, -1.0938e+00, -9.0675e-01, -1.3456e+00,\n",
      "        -7.1396e-01, -1.1490e-01, -4.7900e-01, -4.4081e-01, -1.9601e-01,\n",
      "        -1.1315e-01, -6.2001e-01, -1.1195e+00,  7.8944e-01, -1.4979e+00,\n",
      "        -2.5444e-02, -2.0048e-01, -1.3952e-01, -6.5546e-01,  1.5350e+00,\n",
      "        -1.8703e+00, -1.1928e+00,  1.2139e-01, -1.5203e+00, -1.3128e+00,\n",
      "        -3.9459e-01, -1.6119e+00, -4.2920e-01, -2.1723e-01, -1.1272e+00,\n",
      "        -3.2530e-01,  4.4043e-01,  6.6474e-01, -1.4249e+00, -1.2659e+00,\n",
      "        -1.5162e-01, -1.5247e+00, -9.7526e-01, -2.8631e-01, -1.2308e+00,\n",
      "        -5.6499e-04,  7.1515e-01, -6.4668e-01, -7.4314e-01, -1.5618e+00,\n",
      "        -2.4725e+00, -1.3953e-01, -8.6299e-01, -1.3946e+00, -4.9224e-01,\n",
      "        -2.3167e-01, -2.0570e+00,  6.4084e-02,  1.7712e-01, -1.9954e+00,\n",
      "        -1.9110e+00, -1.2048e+00, -2.6009e+00, -5.9753e-01,  3.4949e-01,\n",
      "         3.0961e-01, -7.1857e-01, -4.4368e-01, -7.4321e-01,  1.1294e+00,\n",
      "        -4.7526e-01, -7.2235e-01, -6.7522e-01, -1.9831e-01,  1.2740e-01,\n",
      "        -1.0901e+00, -1.9775e+00,  6.0713e-01, -6.4668e-01, -9.2774e-01,\n",
      "        -7.7708e-03,  2.8253e-01, -4.4208e-01,  1.3728e+00, -3.6439e-01,\n",
      "        -1.2717e-01, -2.7073e-02,  1.6746e-01,  1.4163e-01, -1.6202e-01,\n",
      "        -1.3490e+00, -8.1273e-01, -5.6577e-01,  1.8653e-01,  5.0564e-01,\n",
      "         6.9266e-01,  1.7007e-01,  1.3528e+00, -1.1945e+00, -7.5539e-01,\n",
      "         7.6709e-02, -1.6915e+00, -7.9090e-01, -1.6299e+00, -1.8009e-01,\n",
      "         2.1898e-02,  5.9692e-01, -3.3279e-01, -9.8689e-01, -5.8185e-01,\n",
      "        -1.5235e+00, -5.6642e-01,  1.8525e-01, -2.5193e+00, -1.2767e+00,\n",
      "        -1.1694e+00,  8.6763e-01, -4.5852e-01, -7.5601e-01, -1.8754e+00,\n",
      "        -1.7401e+00, -1.5725e+00, -2.0328e+00, -3.4961e+00,  7.8434e-01,\n",
      "        -5.9998e-01,  6.6567e-01, -1.0425e+00, -1.0095e+00, -9.8636e-01,\n",
      "         3.6765e-01, -7.0519e-01, -1.2778e-01, -2.5933e+00,  5.2595e-01,\n",
      "        -3.1636e-01, -2.7423e-01, -9.1747e-02,  4.5744e-01, -5.0905e-01,\n",
      "        -8.4434e-01,  7.7921e-01,  1.2170e-01,  1.6117e-01, -3.7747e-01,\n",
      "        -9.1597e-01, -2.0945e-01, -5.3378e-01, -6.5495e-01, -1.5525e+00,\n",
      "        -2.8460e+00,  1.5127e-01, -1.3595e+00, -8.0978e-01, -1.3788e+00,\n",
      "         1.2189e+00, -4.9850e-01,  3.6159e-01, -8.7372e-01,  8.5235e-01,\n",
      "        -3.0998e-01, -5.3291e-01, -1.3873e+00, -5.0908e-01,  2.9747e-01,\n",
      "        -2.0151e+00,  3.7020e-01, -5.9214e-02, -4.6631e-01, -2.4081e+00,\n",
      "        -5.1222e-01,  6.3709e-01, -6.7308e-01,  7.2833e-01, -1.1403e+00,\n",
      "        -1.2839e+00, -1.5289e-01, -1.5231e+00, -2.2562e+00, -4.3515e-01,\n",
      "        -1.6271e+00,  1.8096e-01, -9.1974e-01, -1.9176e-01,  3.1376e-01,\n",
      "        -1.5993e+00,  3.9962e-01, -9.9167e-01, -5.1362e-01, -2.3011e+00,\n",
      "        -8.0213e-02, -8.7250e-02, -4.3976e-01,  2.9871e-01, -2.6065e-01,\n",
      "        -1.6216e+00,  7.8788e-01, -1.9681e-01,  9.3640e-01, -1.0977e+00,\n",
      "        -8.9339e-01, -9.5425e-01, -1.3068e+00,  3.3670e-01, -4.5057e-01,\n",
      "         6.2374e-01,  1.0151e-01,  8.9255e-01,  2.4036e-01, -1.4798e+00,\n",
      "        -2.3285e+00, -1.4081e+00, -9.1468e-01,  2.2631e-01, -1.6504e+00,\n",
      "        -1.2528e+00, -1.1645e+00, -5.4189e-01, -6.6896e-01,  7.9653e-01,\n",
      "         1.6657e-01,  5.9667e-02,  1.1565e+00, -1.2076e+00, -1.7646e+00,\n",
      "        -1.2479e-01, -2.4859e-01,  5.5074e-01, -4.3320e-01, -4.9315e-01,\n",
      "        -1.9510e+00, -3.0691e-01, -5.3003e-01, -2.4630e+00, -6.4216e-01,\n",
      "        -1.7428e-01, -1.1174e-01, -1.2640e+00, -2.1066e+00, -6.6246e-01,\n",
      "        -2.1105e+00, -3.7355e-01,  5.1178e-01, -1.2332e+00, -1.0813e+00,\n",
      "        -2.8149e-01, -5.0667e-01, -9.5719e-01, -4.6238e-01, -1.5619e+00,\n",
      "        -2.6996e+00,  5.4133e-02, -6.8879e-01, -8.2172e-01,  3.5683e-01,\n",
      "        -1.4639e+00, -4.8507e-01,  2.7626e-02, -8.8547e-01, -2.0463e+00,\n",
      "         5.1379e-02, -4.4696e-01, -1.2852e+00, -5.2545e-01,  3.5339e-01,\n",
      "         5.7610e-01, -7.1201e-01, -1.2346e+00, -5.9234e-02,  5.7371e-01,\n",
      "         1.0303e+00, -8.9941e-01,  4.9938e-01, -3.5422e-01, -9.0144e-01,\n",
      "        -5.4900e-02,  1.0126e+00, -9.3082e-01, -8.9438e-01, -8.1632e-01,\n",
      "        -2.0809e+00, -1.7570e+00, -1.5294e+00,  7.0649e-01, -1.6330e+00,\n",
      "        -3.6944e-01, -1.1458e+00, -8.1036e-01,  9.4744e-01,  4.2751e-01,\n",
      "        -1.3539e+00, -1.0628e+00,  1.0399e+00,  3.3790e-01, -1.1264e+00,\n",
      "        -1.2156e+00,  2.0879e-01, -1.8628e+00, -1.8804e+00, -1.5118e+00,\n",
      "        -7.0353e-01,  6.2296e-01, -1.2701e+00, -6.7921e-01, -4.0162e-01,\n",
      "        -1.8195e+00, -3.7102e-01, -1.3542e-01, -1.3862e+00, -3.4762e-01,\n",
      "        -3.9997e-01,  1.1209e-01, -2.4566e-01, -9.0755e-01, -1.8497e+00,\n",
      "        -1.1910e+00,  4.1813e-02, -2.3969e-01,  5.1873e-01, -5.6839e-01,\n",
      "        -9.2351e-01, -7.9758e-01, -8.7099e-01, -1.5638e-01,  7.0139e-01,\n",
      "        -9.9032e-01,  5.9353e-01, -8.9508e-01, -4.4351e-01,  4.4781e-01,\n",
      "        -1.0284e+00, -1.3482e+00, -2.2539e+00,  3.8172e-01,  3.9032e-01,\n",
      "         5.4015e-01, -3.0424e-01, -9.9245e-01, -5.1423e-01, -2.6020e-02,\n",
      "         1.3307e-01, -1.4781e+00, -8.0072e-01, -5.4506e-01, -4.2218e-01,\n",
      "        -1.3661e-01, -6.1177e-01,  9.4755e-02,  5.9859e-01, -3.6543e-01,\n",
      "        -8.5306e-01, -3.5745e-01, -1.0210e+00,  4.3940e-02, -2.6350e-02,\n",
      "        -3.3271e-01, -2.2172e-01, -1.4744e+00, -2.1002e+00, -1.7258e+00,\n",
      "        -1.3779e-02, -1.8193e+00, -1.5152e+00,  6.2818e-01,  3.5750e-01,\n",
      "         7.1159e-01,  2.2357e-01, -7.4663e-01, -8.1977e-01, -8.2382e-01,\n",
      "        -1.0747e+00, -1.4292e+00,  2.0572e-01,  2.3960e-01,  7.6559e-01,\n",
      "        -1.8381e+00, -8.5599e-01,  5.5362e-01, -7.6937e-01,  3.8034e-01,\n",
      "        -2.0683e+00, -8.1168e-01, -5.3357e-01, -9.6721e-01,  8.4601e-01,\n",
      "        -1.7472e+00, -1.3803e+00,  3.0475e-01, -1.0408e+00, -1.6368e+00,\n",
      "         1.1815e+00, -1.3103e+00, -1.1061e+00, -7.2330e-01, -2.8564e-01,\n",
      "         3.5219e-01,  5.5361e-01, -4.5310e-01,  2.9593e-03, -1.9392e+00,\n",
      "         6.4153e-01, -9.7772e-01,  1.8878e-01, -1.3274e+00, -1.2054e+00,\n",
      "        -3.2908e-01, -1.0592e+00, -2.4754e+00, -5.9744e-01, -1.3085e+00,\n",
      "         5.0479e-02, -3.4482e-01, -7.4656e-01, -1.5135e+00,  5.8512e-02,\n",
      "        -1.3728e+00, -1.0346e+00, -1.3867e+00, -1.0889e+00,  6.9302e-01,\n",
      "        -1.5888e+00,  4.7584e-01, -2.0984e+00, -1.9601e+00, -8.7625e-02,\n",
      "        -1.7381e+00, -8.6791e-01,  4.7040e-01, -7.8286e-01, -9.0129e-01,\n",
      "         1.3213e-01, -7.7487e-01, -2.3312e+00,  5.1040e-02, -4.1065e-01,\n",
      "        -4.1709e-01,  9.6126e-02, -1.8260e+00, -8.7379e-01, -5.9902e-01,\n",
      "        -1.4342e+00,  7.6669e-02, -2.8062e-01, -2.9072e-01, -2.4476e-01,\n",
      "        -1.6288e+00,  1.8704e+00, -2.5828e+00, -6.7747e-01, -1.5684e+00,\n",
      "        -1.0103e+00,  5.6065e-01, -8.0789e-02, -3.3175e-01, -1.9089e-02,\n",
      "        -3.8420e-01,  8.1005e-01, -8.5030e-01, -2.7902e+00,  6.8406e-01,\n",
      "         5.1219e-01, -8.6471e-01, -1.1155e+00,  3.8257e-01,  4.0551e-01,\n",
      "        -1.6120e-01, -1.1088e+00, -1.2430e+00,  2.3601e-01, -6.1623e-02,\n",
      "        -4.8306e-01,  3.7756e-01, -8.4852e-01, -2.2422e-01, -7.6639e-01,\n",
      "        -8.6935e-01,  2.6873e-01,  1.3464e+00, -5.4244e-01, -3.0515e-01,\n",
      "        -1.0245e+00,  8.5287e-01, -1.6314e+00, -1.5077e-01, -2.1770e+00,\n",
      "        -1.5004e-01, -1.3652e+00, -4.9730e-01,  5.6383e-01, -1.1101e+00,\n",
      "         8.6483e-01, -1.3189e+00, -1.2471e-01, -3.6586e-01,  3.5179e-01,\n",
      "         1.7268e-01,  8.6633e-01,  4.0736e-01, -2.1589e+00, -9.0716e-02,\n",
      "         6.9888e-02,  3.5768e-01, -5.9469e-01, -4.4166e-01, -1.1409e+00,\n",
      "        -1.4596e+00, -9.3791e-01,  5.0777e-01,  2.5151e-01, -1.3350e+00,\n",
      "         3.6706e-01, -8.5390e-01,  5.4885e-01, -1.8536e+00, -2.4216e-01,\n",
      "         1.2684e+00,  1.4145e-01, -2.1818e+00, -8.3121e-01, -9.5451e-01,\n",
      "        -8.6579e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1309,  0.2085, -0.1758,  0.0769, -0.0212],\n",
      "          [ 0.6164,  0.1399, -0.3396, -0.3004, -0.1232],\n",
      "          [ 0.1337,  0.3125, -0.2603,  0.0619, -0.3229],\n",
      "          [-0.0269,  0.2448,  0.7243,  0.1199, -0.3620],\n",
      "          [-0.3962,  0.3476,  0.6951,  0.1539, -0.0237]]],\n",
      "\n",
      "\n",
      "        [[[-0.1236, -0.4851, -0.2284, -0.1998,  0.3943],\n",
      "          [ 0.2058,  0.2276,  0.0236, -0.4152, -0.1094],\n",
      "          [-0.5923, -0.2815, -0.1545,  0.0694,  0.5754],\n",
      "          [ 0.1453,  0.0498,  0.0958,  0.4946,  0.5647],\n",
      "          [ 0.0649, -0.2345,  0.0054,  0.1199,  0.6024]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3219,  0.4469,  0.2482,  0.0278, -0.0863],\n",
      "          [ 0.2241,  0.2539,  0.0457,  0.1536, -0.2071],\n",
      "          [ 0.0469, -0.1232, -0.3703, -0.3346, -0.2460],\n",
      "          [ 0.4121,  0.1852,  0.1058,  0.6351, -0.1569],\n",
      "          [ 0.7516,  0.6256,  0.5550,  0.2985, -0.0695]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3978,  0.5938,  0.2191, -0.1101, -0.1760],\n",
      "          [ 0.5618,  0.1314,  0.2209,  0.5074,  0.7246],\n",
      "          [-0.0368, -0.1425, -0.1616, -0.1012,  0.2668],\n",
      "          [-0.1840, -0.1444, -0.3247, -0.1323, -0.1069],\n",
      "          [-0.0629,  0.0317, -0.1718, -0.2210, -0.3833]]],\n",
      "\n",
      "\n",
      "        [[[-0.6828, -0.2340, -0.1534, -0.1510, -0.9902],\n",
      "          [-0.5644,  0.0409, -0.0268, -0.1636, -0.3016],\n",
      "          [-0.1463, -0.4996,  0.0263,  0.1153, -0.4507],\n",
      "          [ 0.0529, -0.6580,  0.0706,  0.1378, -0.0413],\n",
      "          [ 0.0975, -0.0485, -0.3996, -0.2092, -0.8660]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6703,  0.3287,  0.5044,  0.1835,  0.2746],\n",
      "          [ 0.5130,  0.2048,  0.3597, -0.0634,  0.1145],\n",
      "          [ 0.5084,  0.2702,  0.4334, -0.0555,  0.1840],\n",
      "          [ 0.3734,  0.3494,  0.4024,  0.0884,  0.1026],\n",
      "          [ 0.3858,  0.3731,  0.3806,  0.1775,  0.1282]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([2.0306, 1.5944, 1.5694, 2.8686, 2.1655, 1.5882, 0.6280, 2.2935, 1.8211,\n",
      "        2.7051, 0.5389, 1.2642, 1.1075, 0.7453, 1.4660, 1.9471, 1.7927, 2.3318,\n",
      "        2.2415, 1.0561, 1.2166, 1.0961, 1.4635, 2.5859, 1.0854, 2.2553, 0.4701,\n",
      "        1.5329, 1.1379, 1.7702, 1.4878, 2.4783, 1.9411, 1.3368, 1.5429, 0.9297,\n",
      "        1.6943, 2.0558, 1.2715, 1.1572, 0.8502, 1.7922, 0.8746, 1.5650, 1.8065,\n",
      "        1.1045, 1.3604, 1.4589, 1.5503, 1.0559, 1.5992, 1.6517, 1.5600, 0.7967,\n",
      "        1.7712, 1.4313, 1.0382, 1.7439, 1.5670, 2.5172, 0.5645, 1.4406, 1.4673,\n",
      "        1.0358, 0.9839, 1.8844, 2.8744, 1.3848, 1.5378, 2.2442, 2.0789, 1.4276,\n",
      "        0.6732, 1.9807, 1.2994, 1.4680, 1.3689, 2.0973, 2.0153, 1.4210, 1.2776,\n",
      "        1.4429, 2.0345, 2.1247, 0.0950, 1.9289, 1.4138, 2.3513, 1.7445, 2.4722,\n",
      "        1.8774, 1.1400, 1.4625, 1.9527, 1.8055, 1.2663, 1.4366, 1.8075, 1.6081,\n",
      "        1.7285, 0.8110, 0.8704, 1.4105, 1.1138, 2.1572, 1.8929, 2.6781, 1.5542,\n",
      "        1.4661, 1.0516, 1.0424, 1.2130, 2.2691, 1.7753, 1.1254, 2.3620, 1.1539,\n",
      "        1.7804, 2.4004, 2.5687, 1.5048, 0.7490, 1.3118, 1.9242, 2.5943, 1.7555,\n",
      "        1.3470, 1.1393, 1.2311, 1.5869, 1.3501, 0.8068, 1.5654, 1.8583, 1.6522,\n",
      "        1.1901, 2.0836, 2.2585, 1.9371, 2.0414, 1.2939, 1.9600, 1.2998, 1.6708,\n",
      "        1.0666, 1.7575, 0.7888, 1.5211, 0.9826, 1.3803, 1.6440, 1.5810, 1.4604,\n",
      "        1.2992, 0.8265, 1.9361, 0.5039, 1.6103, 2.1570, 1.9807, 3.4724, 0.5451,\n",
      "        1.9394, 1.3103, 2.0774, 0.8880, 1.1744, 1.0206, 1.3993, 2.0524, 1.7558,\n",
      "        1.4255, 1.4619, 0.9127, 1.7284, 1.5488, 0.9570, 1.4827, 1.7091, 1.8839,\n",
      "        1.8100, 1.7270, 1.4159, 1.1143, 1.4593, 1.4492, 1.6616, 1.3034, 1.1240,\n",
      "        2.0714, 1.3694, 1.3992, 1.5802, 1.2199, 0.8071, 1.3891, 1.9894, 1.3020,\n",
      "        1.8707, 0.4574, 0.6491, 1.1051, 2.0091, 1.0324, 1.5303, 0.8730, 1.4001,\n",
      "        1.2732, 1.3290, 1.2230, 1.6625, 0.5570, 1.1416, 1.3371, 1.3120, 1.4465,\n",
      "        1.6909, 1.3712, 1.7925, 2.0495, 2.1988, 1.2463, 1.4493, 1.3709, 1.5488,\n",
      "        1.8753, 1.0503, 1.6133, 1.7370, 1.9318, 2.0079, 1.4827, 1.8655, 1.3052,\n",
      "        1.1583, 1.6873, 1.9093, 1.0517, 1.3325, 1.8184, 1.8181, 1.2304, 1.9230,\n",
      "        1.5294, 2.1649, 0.7528, 1.0855, 1.2873, 0.2280, 0.8861, 1.9316, 2.0109,\n",
      "        0.9225, 1.8645, 2.1024, 1.3489, 1.0525, 1.7587, 2.1055, 2.9750, 4.2811,\n",
      "        1.2259, 1.2848, 2.1640, 4.8445, 1.1541, 1.8991, 1.3990, 0.7630, 1.4897,\n",
      "        1.0669, 1.2272, 1.2628, 1.1111, 1.7534, 1.1782, 1.5524, 2.3161, 1.1246,\n",
      "        1.8203, 0.4542, 0.7914, 2.1067, 1.9106, 1.1323, 1.0751, 1.4286, 1.9262,\n",
      "        1.4333, 1.4455, 2.1328, 0.9892, 2.0406, 1.8580, 2.9596, 1.1414, 1.4928,\n",
      "        2.5596, 1.3002, 1.5120, 1.2528, 1.5128, 1.3947, 1.5179, 1.7629, 1.5900,\n",
      "        1.7680, 1.4117, 1.7825, 1.8892, 1.6149, 1.2634, 0.4381, 1.5466, 2.6401,\n",
      "        1.4452, 1.7105, 1.6186, 1.2571, 1.7741, 2.3230, 1.1391, 1.5733, 1.6528,\n",
      "        1.0919, 1.9103, 0.3407, 0.5608, 1.6216, 1.3472, 1.5804, 1.7922, 1.6122,\n",
      "        0.7531, 1.5038, 1.2641, 0.7092, 1.4620, 1.0005, 3.1790, 2.1658, 2.4296,\n",
      "        1.4928, 1.5112, 2.8083, 3.1955, 2.2390, 2.4328, 0.8822, 1.6599, 1.2553,\n",
      "        0.6125, 2.3948, 1.3826, 0.8903, 1.6046, 1.5296, 1.9653, 1.4587, 1.4960,\n",
      "        2.0195, 1.5961, 0.9173, 2.0829, 1.4562, 1.7801, 1.5691, 1.2941, 1.5694,\n",
      "        1.0149, 1.0024, 0.7323, 2.0761, 1.1574, 1.5064, 1.7840, 1.9853, 2.3012,\n",
      "        2.0921, 1.8953, 1.2940, 2.2781, 1.9308, 1.6135, 1.4871, 0.5250, 1.8172,\n",
      "        1.1225, 1.8428, 1.8335, 1.8745, 1.4204, 1.7888, 1.1863, 1.3348, 1.8859,\n",
      "        1.4546, 1.5170, 2.6384, 1.4917, 2.4984, 2.0280, 1.5750, 1.7988, 1.6889,\n",
      "        0.5448, 1.0873, 2.4013, 0.7380, 1.7825, 1.3103, 1.6317, 1.6163, 1.4756,\n",
      "        2.7654, 1.3259, 2.9313, 2.8443, 3.1666, 1.7311, 1.2886, 1.6703, 1.8768,\n",
      "        1.5340, 1.0738, 1.7416, 1.4872, 1.9837, 0.8627, 1.4982, 1.7298, 1.7840,\n",
      "        2.4526, 1.7163, 1.6243, 1.5556, 2.1237, 1.8879, 2.2794, 1.4757, 2.2268,\n",
      "        1.8695, 1.2007, 1.4431, 1.2050, 3.4531, 1.8270, 1.8773, 2.7056, 1.5663,\n",
      "        1.6128, 1.7701, 1.9663, 1.8242, 1.6580, 1.6057, 1.4587, 0.8909, 1.6539,\n",
      "        1.7257, 1.8727, 1.7868, 1.6022, 1.7334, 0.3395, 1.7321, 1.4546, 1.3804,\n",
      "        1.6408, 1.2961, 2.2760, 1.1379, 1.5948, 2.6348, 1.7928, 1.3569, 1.6714,\n",
      "        1.4173, 1.4385, 0.9995, 1.6861, 1.7389, 1.0823, 1.8071, 3.1699, 1.5324,\n",
      "        1.5960, 1.5570, 1.4344, 1.1692, 1.2385, 1.1177, 2.3540, 2.0442, 2.0725,\n",
      "        2.2282, 1.1639, 1.4751, 1.7148, 1.3411, 1.8106, 1.2868, 1.7986, 2.5072,\n",
      "        1.6678, 2.7274, 1.0495, 1.5231, 1.1224, 1.1371, 1.1417, 1.7337, 1.4746,\n",
      "        1.5887, 1.8706, 1.9698, 1.7134, 2.2809, 1.4529, 1.1447, 1.2600, 1.4187,\n",
      "        1.3824, 1.8731, 1.0260, 1.3205, 1.5694, 1.0823, 2.5047, 1.0213, 2.0607,\n",
      "        1.5537, 1.7591, 0.8067, 0.9194, 1.9613, 1.4338, 1.4575, 1.4648, 2.6002,\n",
      "        2.2087, 1.5109, 2.0580, 1.5682, 2.8593, 2.9601, 2.1301, 1.0601, 2.0880,\n",
      "        2.3439, 3.3884, 1.5278, 2.0584, 1.7421, 0.7755, 2.0969, 1.3192, 2.0668,\n",
      "        2.0604, 1.8040, 1.9816, 2.1134, 1.1418, 1.3651, 1.9888, 1.9557, 1.4522,\n",
      "        1.4937, 1.2813, 1.8283, 1.0813, 1.5915, 1.7185, 2.2881, 1.0084, 2.7030,\n",
      "        0.8333, 1.9096, 2.0434, 2.4194, 1.4188, 2.0567, 1.0382, 1.9587, 1.5827,\n",
      "        1.3600, 1.6425, 2.2540, 1.5933, 1.1687, 2.0722, 1.9651, 2.5127, 0.5906,\n",
      "        1.4045, 1.2193, 1.9771, 1.5179, 2.6889, 1.0895, 2.2812, 0.9506, 2.2356,\n",
      "        1.8646, 1.6274, 1.2505, 2.4346, 1.2998, 1.2092, 1.1156, 1.3231, 1.6366,\n",
      "        2.1426, 1.6908, 1.3871, 2.0295, 2.3795, 1.5890, 2.0534, 2.2381, 1.7082,\n",
      "        0.5784, 1.1450, 1.5709, 1.7241, 2.0570, 0.8076, 1.2472, 1.9271, 1.4468,\n",
      "        1.7175, 1.0303, 1.4802, 2.0226, 1.6917, 1.6709, 1.6073, 1.5497, 1.8145,\n",
      "        1.0829, 1.3584, 1.4370, 2.0733, 2.2516, 2.2652, 1.4784, 1.6347, 1.1693,\n",
      "        1.8945, 1.8717, 1.3219, 0.9621, 0.7099, 2.2645, 2.3127, 1.6673, 0.7031,\n",
      "        0.6781, 2.0126, 1.4128, 2.0234, 1.8859, 1.5655, 0.9500, 1.4714, 0.5797,\n",
      "        0.6750, 1.3137, 1.5523, 2.0024, 1.6928, 1.1094, 2.0463, 1.9048, 0.9401,\n",
      "        0.7576, 1.5088, 1.1812, 1.2027, 2.0562, 1.8368, 0.0798, 2.2037, 1.0734,\n",
      "        1.7458, 1.7172, 0.9708, 2.9628, 1.6386, 0.9960, 2.0502, 2.5223, 1.9204,\n",
      "        2.2703, 1.3374, 2.7069, 0.8895, 2.0467, 1.5556, 2.4813, 1.2917, 1.0244,\n",
      "        0.8055, 1.2986, 1.8336, 1.6270, 2.3912, 1.6420, 1.3852, 2.1900, 0.6318,\n",
      "        1.6485, 1.3585, 1.1124, 1.7419, 0.9954, 2.4828, 1.4620, 0.7057, 2.0338,\n",
      "        0.5938, 1.5589, 1.9253, 1.6087, 1.3468, 1.6987, 1.9256, 3.6993, 1.8702,\n",
      "        1.2138, 2.3695, 0.7372, 3.4249, 1.3824, 1.3518, 2.8743, 2.0509, 1.6602,\n",
      "        1.1398, 2.0711, 2.8513, 2.3466, 0.8461, 1.5699, 1.1332, 2.4499, 2.0323,\n",
      "        1.8354, 1.6473, 1.6495, 1.8597, 1.8348, 1.2283, 2.9694, 1.6937, 1.4804,\n",
      "        1.8379, 2.5816, 2.1067, 2.2097, 1.5083, 1.6704, 1.4674, 1.1915, 2.1671,\n",
      "        1.6629, 1.2693, 1.4986, 1.6578, 1.2692, 1.4176, 1.2902, 1.7265, 1.6441,\n",
      "        1.9735, 1.4550, 2.0486, 1.7266, 1.5446, 2.5834, 1.9982, 1.6570, 1.5384,\n",
      "        2.3958, 1.4163, 1.8281, 0.9620, 1.9184, 0.0456, 1.8033, 1.1511, 1.9436,\n",
      "        1.8749, 2.4081, 1.8222, 1.7361, 1.2341, 1.2153, 2.2247, 1.8800, 2.3814,\n",
      "        1.3174, 2.3917, 1.1155, 1.3535, 1.7027, 1.3114, 1.9373, 1.2381, 1.5988,\n",
      "        1.9279, 2.3255, 2.7025, 1.4332, 1.9397, 2.0544], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.4167e+00, -1.5923e+00, -5.9299e-01, -1.1482e+00, -1.4865e+00,\n",
      "        -1.2080e+00, -2.2362e-01, -1.2649e+00, -2.0335e+00, -2.5120e+00,\n",
      "        -1.3314e-01, -7.8977e-01, -6.0868e-01, -1.2524e-01, -1.1579e+00,\n",
      "        -6.9127e-01, -1.4776e+00, -1.6023e+00, -1.5559e+00, -2.4104e-01,\n",
      "        -6.0126e-01, -3.1426e-01, -3.9921e-01, -2.3080e+00, -3.2250e-01,\n",
      "        -1.2521e+00, -4.1666e-01, -1.8727e+00, -4.6499e-01, -7.3799e-01,\n",
      "        -1.9539e-01, -9.2007e-01, -7.6197e-01, -1.2302e+00, -1.2108e+00,\n",
      "        -6.1175e-01, -1.1220e+00, -7.1863e-01, -5.0617e-01, -5.0680e-01,\n",
      "        -9.5346e-01, -1.7100e+00, -1.2026e-01, -1.4265e+00, -1.5047e+00,\n",
      "        -7.2412e-01, -1.2192e+00, -1.1240e+00, -1.1894e+00, -1.1126e+00,\n",
      "        -1.4276e+00, -1.0400e+00, -5.1977e-01, -2.3251e-01, -1.3861e+00,\n",
      "        -5.2522e-01, -1.8487e-01, -2.1475e+00, -9.9823e-01, -1.4223e+00,\n",
      "        -2.6861e-02, -6.4517e-01, -4.0696e+00, -8.6564e-01, -4.1309e-01,\n",
      "        -2.2975e+00, -8.3379e-01, -1.0071e+00, -1.1088e+00, -1.2861e+00,\n",
      "        -1.2452e+00, -7.8448e-01, -4.5493e-01, -1.4076e+00, -6.0779e-01,\n",
      "        -1.5024e+00, -1.6735e+00, -8.9330e-02, -1.4456e+00, -1.1712e+00,\n",
      "        -7.4535e-01, -2.3813e+00, -2.7596e-01, -7.8307e-01, -4.1280e-02,\n",
      "        -1.6404e+00, -1.4044e+00, -1.7885e+00, -2.9875e-01, -1.7530e+00,\n",
      "        -1.6739e+00, -7.8112e-01, -1.4361e+00, -8.1649e-02, -6.7981e-01,\n",
      "        -1.1413e+00, -1.2584e+00, -7.8524e-01, -2.0941e+00, -8.6559e-01,\n",
      "        -7.5478e-01, -5.0447e-01, -4.0250e-01, -3.1017e-01, -1.5976e+00,\n",
      "        -9.5181e-01,  6.9069e-02, -2.4671e+00, -2.5047e+00,  4.0233e-02,\n",
      "        -6.6731e-01,  4.1121e-02, -1.6846e+00, -1.9059e+00, -7.4125e-01,\n",
      "        -1.5008e+00, -4.6653e-01, -1.1480e+00, -1.4283e+00, -7.7096e-01,\n",
      "        -7.6712e-01, -1.5439e-01, -9.5462e-01, -3.0903e-01, -6.8649e-01,\n",
      "        -2.0081e+00, -4.4702e-01, -5.9053e-01, -3.4669e-01, -1.1778e+00,\n",
      "        -2.8171e-01, -1.5805e-01, -1.9519e+00, -1.4774e+00, -9.1235e-01,\n",
      "        -2.4064e+00, -1.5752e+00, -1.2497e+00, -8.8109e-01, -1.4055e+00,\n",
      "        -8.6075e-01, -2.6436e+00, -1.3889e+00, -8.3201e-01, -3.2396e-01,\n",
      "        -1.4364e+00, -2.3091e-01, -2.4555e+00, -6.8433e-01, -1.0845e+00,\n",
      "        -4.3527e-01, -2.3250e+00, -6.9017e-01, -9.6462e-01,  1.9497e-02,\n",
      "        -1.3426e+00, -1.6091e-01, -8.7280e-01, -1.3960e+00, -2.1396e+00,\n",
      "        -1.0606e+00,  5.0045e-03, -1.2363e+00, -1.4613e+00, -6.2037e-01,\n",
      "        -3.9050e-01, -7.4915e-01, -5.9724e-01, -3.2624e+00, -1.8608e+00,\n",
      "        -1.1799e+00, -8.4130e-01, -6.5033e-01, -4.6299e-01, -2.3915e+00,\n",
      "        -2.9872e+00, -5.2308e-01, -6.7855e-01, -1.1464e+00, -1.1652e+00,\n",
      "        -1.5415e+00, -1.3484e+00, -1.7555e+00, -8.2968e-01, -4.6464e-01,\n",
      "        -1.0058e+00, -1.6329e+00, -9.3245e-01, -2.4602e-01, -1.7809e+00,\n",
      "        -1.0594e-01, -9.2027e-01, -1.2894e+00, -8.2730e-01, -5.2890e-02,\n",
      "        -1.2985e+00, -1.3166e+00, -3.2601e-01, -1.8505e-03, -3.9651e-01,\n",
      "        -2.7386e-01, -1.2427e+00, -1.0493e+00, -6.2749e-01, -1.9920e+00,\n",
      "        -4.5533e-01, -9.2249e-01, -4.6971e-01, -6.1837e-01, -5.7656e-01,\n",
      "        -1.2614e+00, -3.1126e-01, -5.0507e-01, -1.0905e+00, -1.1306e+00,\n",
      "        -2.6844e+00, -4.7122e-01, -3.0839e-01, -1.5969e+00, -1.5076e+00,\n",
      "        -6.6454e-01,  8.9759e-02, -6.5935e-01, -1.1705e+00, -1.8637e+00,\n",
      "        -9.1492e-01, -6.5606e-01, -1.3627e+00, -1.2112e+00, -8.4054e-01,\n",
      "        -1.3715e+00, -1.2757e+00, -4.5639e-01, -9.2136e-01, -1.5399e+00,\n",
      "        -8.8321e-01, -9.5775e-01, -3.8574e-01, -6.0443e-01, -2.3249e+00,\n",
      "        -6.3137e-01, -8.8411e-01, -1.6891e+00, -1.0287e+00, -1.6380e+00,\n",
      "        -4.4774e-01, -1.0572e+00, -1.8629e+00, -2.9198e-01, -3.0085e-01,\n",
      "         2.6360e-01, -9.2129e-01, -1.5057e-01, -6.1550e-01, -1.4316e+00,\n",
      "        -1.0159e+00, -5.2942e-01, -1.2420e+00, -1.6039e+00, -8.9263e-01,\n",
      "        -1.9853e+00, -1.7876e+00, -5.2106e-01, -1.0046e+00, -2.0725e+00,\n",
      "        -5.9603e-01, -1.1634e+00, -1.3221e+00, -2.1610e-01, -1.7150e+00,\n",
      "        -9.9623e-01, -6.3101e-01, -6.2079e-01, -4.9194e-01, -1.5774e+00,\n",
      "        -1.2134e-01, -1.7684e+00, -1.4862e+00,  1.1992e-01, -1.2415e+00,\n",
      "        -2.3238e-01, -4.9629e-01, -1.5714e+00, -8.5695e-01, -6.0343e-01,\n",
      "        -7.4148e-02, -8.8351e-01, -6.0503e-01, -1.3516e+00, -3.2902e-01,\n",
      "        -6.5935e-01, -9.2833e-01, -1.7554e+00, -1.4819e+00, -7.2087e-01,\n",
      "        -1.2817e-01, -2.9544e+00, -1.9518e-01, -9.9347e-01, -1.4370e+00,\n",
      "        -2.1877e+00, -2.1252e+00, -2.2108e+00, -2.6348e-01, -2.9823e+00,\n",
      "        -9.0120e-01, -3.5202e-01, -6.3145e-01, -2.5473e+00, -6.2194e-01,\n",
      "        -1.6209e+00, -7.4167e-01, -2.1601e-01, -9.8888e-01, -6.7192e-01,\n",
      "        -2.4722e-01, -1.7086e+00,  5.6011e-02, -7.4058e-01, -1.3968e+00,\n",
      "         1.3808e-01, -1.4097e+00, -2.4956e-01, -7.6980e-01, -4.7093e-01,\n",
      "        -1.8367e+00, -6.5173e-02, -4.2271e-01, -1.7895e-01, -7.8250e-01,\n",
      "        -7.6903e-01, -1.7478e+00, -2.0383e+00,  3.2254e-01, -5.4753e-01,\n",
      "        -8.4724e-01, -1.2806e-01, -1.9273e+00, -6.7067e-01, -1.4714e+00,\n",
      "        -1.8675e+00, -1.4254e+00, -2.0519e+00, -2.4975e-01, -6.7785e-01,\n",
      "        -4.3636e-01, -1.3854e+00, -1.4209e+00, -3.8295e-01, -1.5944e+00,\n",
      "        -1.6526e+00, -1.4708e-01, -1.1717e+00, -8.7963e-01, -5.8132e-01,\n",
      "        -1.9556e+00, -7.9050e-01, -1.3872e+00,  2.3378e-01, -1.0901e+00,\n",
      "        -1.3984e+00, -3.5451e-01, -5.6053e-01, -9.5313e-01, -1.1256e+00,\n",
      "        -1.5154e+00, -3.4063e-01, -1.6860e+00, -9.8323e-01, -1.3702e+00,\n",
      "        -2.3524e-02, -3.8389e-01, -1.5371e+00, -4.5938e-01, -2.6189e-01,\n",
      "        -7.7392e-01, -1.8353e+00, -1.6207e+00, -1.9899e+00, -1.3642e+00,\n",
      "        -1.1774e+00, -1.3761e+00, -1.3014e+00, -1.7899e+00, -6.9819e-01,\n",
      "        -2.9314e-01, -1.7956e+00, -5.6485e-01, -1.0633e+00, -1.2643e+00,\n",
      "        -1.2076e+00, -1.3853e+00, -1.1472e+00, -1.6806e+00, -1.0275e+00,\n",
      "        -1.6723e+00, -9.8248e-01,  7.1268e-02,  1.1438e-01,  1.6417e-02,\n",
      "        -1.5741e+00, -1.7655e+00, -2.6832e+00, -1.5888e+00, -1.7937e+00,\n",
      "         1.5273e-02, -1.1957e+00, -4.0101e-01, -4.2336e-01, -6.6773e-01,\n",
      "        -3.8765e-01, -1.2394e+00, -8.0534e-01, -8.3937e-01, -2.1261e-01,\n",
      "        -4.2493e+00, -1.2043e+00, -4.4033e-01, -1.0646e+00, -1.5272e+00,\n",
      "        -1.9843e+00, -1.1575e+00, -7.9291e-01, -7.8551e-01, -4.3021e-01,\n",
      "        -1.4668e+00, -2.3935e+00, -9.3287e-01, -1.0123e-02, -1.1678e+00,\n",
      "        -1.9214e+00, -4.5114e-01, -1.6946e+00, -1.6527e+00, -2.3655e-01,\n",
      "        -2.0711e+00, -1.5142e+00, -1.2366e+00, -1.0336e+00, -8.8249e-01,\n",
      "        -1.6580e+00, -1.9257e+00, -9.6260e-01, -1.6890e+00, -3.2538e-01,\n",
      "        -2.6845e-01, -1.4171e+00, -1.1346e+00, -1.4418e+00, -1.3412e+00,\n",
      "        -1.2833e+00, -1.5306e+00, -1.0265e+00, -2.2310e+00, -5.0347e-01,\n",
      "        -1.1238e+00, -1.6115e+00, -7.2182e-01, -8.1241e-01, -1.2227e+00,\n",
      "        -2.5098e+00, -9.6241e-01, -1.0411e+00, -4.1167e-01, -1.7694e-01,\n",
      "        -2.2346e+00, -1.1664e+00, -1.2676e+00, -1.4268e+00, -1.2475e+00,\n",
      "        -8.7768e-01, -1.0736e+00, -2.1349e+00, -1.0088e+00, -2.7844e-01,\n",
      "        -6.7768e-01, -1.9831e+00, -2.2388e-02, -1.7092e+00, -8.8277e-01,\n",
      "        -1.7962e+00, -1.5301e+00, -5.4743e-01, -2.0945e+00, -1.0987e+00,\n",
      "        -2.5391e+00, -1.2444e+00, -2.1880e-01, -1.3705e+00, -4.8811e-01,\n",
      "        -4.1123e-01, -3.8112e-01, -1.0826e+00, -1.0429e+00, -1.7254e+00,\n",
      "        -8.7722e-01, -1.0422e+00, -1.3390e+00, -1.0816e+00, -2.3088e+00,\n",
      "        -2.1983e+00, -8.5795e-01, -1.7218e+00, -1.8701e+00, -1.2779e+00,\n",
      "        -2.2052e-01, -6.8274e-01, -8.8634e-01,  6.4556e-01, -3.0981e-01,\n",
      "        -1.5392e-01, -1.2418e+00, -2.5066e+00, -7.2073e-01, -1.7010e+00,\n",
      "        -1.9449e+00, -1.5288e+00, -8.7019e-01, -9.6400e-01, -3.7091e-01,\n",
      "        -7.0305e-01, -1.8832e+00, -8.2056e-01, -1.7821e+00, -9.3546e-01,\n",
      "        -2.7217e-01, -1.1637e+00, -1.1651e+00, -1.1934e+00, -6.3364e-01,\n",
      "        -1.3881e+00, -2.4469e-01, -5.2890e-01,  7.3265e-02, -4.4318e-01,\n",
      "        -3.9259e-01, -4.9549e-01, -1.3557e+00, -1.1601e+00, -7.5132e-01,\n",
      "        -1.4208e+00, -1.1287e+00, -9.1250e-01, -1.1421e-01, -3.8267e-01,\n",
      "        -1.4590e-01, -1.3597e+00, -3.9393e-01, -1.6461e-01, -1.3483e+00,\n",
      "         4.3488e-02, -8.0550e-01, -1.2797e+00,  5.5566e-02, -1.2728e-01,\n",
      "        -1.9519e+00, -1.2236e+00, -6.2982e-01, -2.9903e-01, -1.8544e+00,\n",
      "        -1.5064e+00, -3.6806e-01, -2.7437e+00, -4.6139e-01, -1.2943e+00,\n",
      "        -4.6297e-01, -1.1198e+00, -1.5679e+00, -2.5152e+00, -4.8445e-01,\n",
      "        -3.3000e-01, -1.0984e+00, -6.7836e-01, -1.1869e-01, -6.6864e-01,\n",
      "        -1.1592e+00, -2.2796e-01, -2.5876e+00, -1.5685e+00, -5.3019e-01,\n",
      "        -1.7517e+00, -9.3996e-01, -3.3256e-01, -1.7538e+00, -1.4777e+00,\n",
      "        -3.5447e-01, -8.2605e-01, -4.7950e-01, -1.8240e+00, -8.4555e-01,\n",
      "        -2.0791e+00, -1.6441e+00, -1.1142e+00, -1.6341e-01, -2.3822e+00,\n",
      "        -1.2475e+00, -1.3283e+00, -2.2306e+00, -1.9172e+00,  6.4175e-02,\n",
      "        -5.7195e-01, -6.0929e-01, -1.0810e+00, -5.9868e-01, -1.4539e+00,\n",
      "        -1.3081e+00, -1.1258e+00, -2.1183e-01, -3.4106e-01, -3.9706e-02,\n",
      "        -1.6897e-01, -1.5995e+00, -8.8435e-01, -1.5076e+00, -1.3946e+00,\n",
      "        -1.5115e+00, -8.5127e-01, -5.6098e-01, -1.4116e+00, -1.1709e+00,\n",
      "        -9.8545e-01,  7.7053e-02, -9.9457e-01, -1.3414e+00, -5.2134e-01,\n",
      "        -1.2782e+00, -3.3914e-01, -1.2132e+00, -1.0344e+00, -5.5266e-02,\n",
      "        -1.4970e+00, -6.9935e-01, -1.9377e+00, -1.3484e+00, -1.1517e+00,\n",
      "        -1.3588e+00, -8.7281e-01, -9.4780e-01, -1.2090e+00, -5.3190e-01,\n",
      "        -1.0132e+00, -1.0331e+00, -1.7888e+00, -6.5002e-01, -5.3056e-01,\n",
      "        -3.0634e+00, -7.9631e-01, -8.2917e-01, -1.1827e+00, -1.8614e+00,\n",
      "        -6.5418e-01, -2.2573e-01, -1.6386e-01, -2.7154e+00, -1.3288e+00,\n",
      "        -1.5341e+00, -1.1909e-01, -1.4805e-01, -1.3294e+00, -1.8901e+00,\n",
      "        -2.2114e+00, -1.4297e+00, -2.4503e-01, -4.7591e-01, -1.3000e+00,\n",
      "        -1.7869e-01,  2.2872e-01, -2.3297e+00, -5.3322e-01, -1.6142e+00,\n",
      "        -9.2643e-01, -1.0457e+00, -1.0968e+00, -1.7455e+00, -4.8424e-01,\n",
      "        -3.4987e-01, -1.5103e+00, -8.6587e-01, -2.7539e-01, -1.3379e+00,\n",
      "        -2.0817e-01, -7.0741e-02, -1.0516e+00, -1.7580e-01, -1.2960e+00,\n",
      "        -1.4507e+00, -3.3246e-02,  3.1371e-01, -7.6705e-01, -4.5138e-01,\n",
      "        -1.2858e+00, -1.0429e+00, -1.3435e+00, -1.4736e+00, -9.5380e-01,\n",
      "        -2.1151e+00, -2.9728e-01, -1.0078e+00, -1.1848e+00, -3.9213e-01,\n",
      "        -9.4997e-01, -3.6357e-01, -1.8471e-01, -1.0115e+00, -1.2097e+00,\n",
      "        -1.1643e+00, -1.5701e+00, -6.2332e-01, -7.6520e-01, -7.1692e-01,\n",
      "        -2.8066e-01, -5.6151e-01, -1.0047e+00, -3.6521e-02, -5.9435e-01,\n",
      "        -6.1935e-01, -1.4206e+00, -9.4044e-01, -3.0320e-01, -1.6885e+00,\n",
      "        -1.4284e-01, -1.0899e+00, -9.2653e-01, -1.4155e+00, -7.5470e-01,\n",
      "        -9.2027e-01, -1.3440e+00, -7.2340e-01, -1.4311e+00, -1.4876e+00,\n",
      "        -1.3527e+00,  2.0360e-02, -6.1495e-01, -7.1658e-01, -2.2806e+00,\n",
      "        -1.2570e+00, -1.2782e+00, -2.0774e+00, -6.3791e-01, -1.5756e+00,\n",
      "        -2.8497e-01, -3.1021e+00, -2.0782e-01, -1.8092e-01, -2.7854e-01,\n",
      "        -1.1980e+00, -1.2772e+00, -2.3127e+00, -1.0920e+00, -9.3461e-01,\n",
      "        -1.2087e+00, -1.4445e+00, -6.6363e-01, -1.8180e+00, -1.6297e+00,\n",
      "        -1.6829e+00, -3.0302e+00, -9.2821e-01, -2.0089e+00, -9.3081e-01,\n",
      "        -8.0365e-01, -1.9718e+00, -2.2437e+00, -3.3669e-01, -1.9302e+00,\n",
      "        -1.2645e+00, -5.3143e-01, -5.8435e-01, -1.6925e+00, -6.3465e-01,\n",
      "         2.2441e-02, -9.1422e-01, -7.8184e-01, -2.2747e+00, -8.6571e-01,\n",
      "        -3.2957e-01, -1.9074e+00, -1.4733e+00, -1.2959e+00, -1.1769e+00,\n",
      "        -9.8126e-01, -7.9640e-01, -9.9472e-01, -1.5018e+00, -1.1133e+00,\n",
      "        -1.9266e+00, -5.0220e-01, -1.6480e+00,  9.8743e-02, -2.0111e+00,\n",
      "        -1.0526e+00, -1.7414e+00, -1.6295e+00, -1.8898e-01, -1.2793e+00,\n",
      "        -1.4551e+00, -7.6711e-01, -1.1336e+00, -1.1507e+00, -1.5550e+00,\n",
      "        -1.2207e+00, -6.1092e-01, -1.3785e+00, -5.8646e-01, -3.1921e-01,\n",
      "        -1.0804e+00, -6.6642e-01, -6.5929e-01, -7.9144e-01, -1.9266e+00,\n",
      "        -1.4138e+00, -1.6847e+00, -1.0574e+00, -1.0581e+00, -6.6959e-01,\n",
      "        -7.8032e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.8033]],\n",
      "\n",
      "         [[-0.6309]],\n",
      "\n",
      "         [[ 0.2076]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5910]],\n",
      "\n",
      "         [[ 0.1178]],\n",
      "\n",
      "         [[ 0.5545]]],\n",
      "\n",
      "\n",
      "        [[[-0.6669]],\n",
      "\n",
      "         [[-0.5836]],\n",
      "\n",
      "         [[-0.0723]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1164]],\n",
      "\n",
      "         [[ 0.3276]],\n",
      "\n",
      "         [[-0.0780]]],\n",
      "\n",
      "\n",
      "        [[[-0.0696]],\n",
      "\n",
      "         [[ 0.2984]],\n",
      "\n",
      "         [[-0.0050]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0965]],\n",
      "\n",
      "         [[-0.2874]],\n",
      "\n",
      "         [[ 0.1779]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3760]],\n",
      "\n",
      "         [[ 0.1028]],\n",
      "\n",
      "         [[ 0.4125]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0249]],\n",
      "\n",
      "         [[-0.1110]],\n",
      "\n",
      "         [[-0.5998]]],\n",
      "\n",
      "\n",
      "        [[[-0.0856]],\n",
      "\n",
      "         [[ 0.1436]],\n",
      "\n",
      "         [[ 0.3257]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4957]],\n",
      "\n",
      "         [[-0.1067]],\n",
      "\n",
      "         [[ 0.2251]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0224]],\n",
      "\n",
      "         [[ 0.2349]],\n",
      "\n",
      "         [[-0.4082]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3037]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.5305]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1815,  0.0981, -0.2053,  0.0797,  0.2468, -0.1942,  0.2597, -0.2135,\n",
      "        -0.0057, -0.0520, -0.1288,  0.0491, -0.0029, -0.0600,  0.1813,  0.3531,\n",
      "        -0.1029, -0.0493,  0.1469, -0.0537,  0.3142,  0.0844,  0.1690,  0.2367,\n",
      "         0.1229,  0.1100,  0.1300,  0.0688, -0.1150,  0.2272, -0.0105,  0.2967,\n",
      "         0.0387, -0.0094], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2639]],\n",
      "\n",
      "         [[-0.0788]],\n",
      "\n",
      "         [[-0.0394]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1881]],\n",
      "\n",
      "         [[-0.3570]],\n",
      "\n",
      "         [[ 0.1196]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4525]],\n",
      "\n",
      "         [[ 0.1716]],\n",
      "\n",
      "         [[ 0.1755]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0243]],\n",
      "\n",
      "         [[-0.0795]],\n",
      "\n",
      "         [[ 0.6512]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2264]],\n",
      "\n",
      "         [[-0.1953]],\n",
      "\n",
      "         [[ 0.1237]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6784]],\n",
      "\n",
      "         [[-0.2228]],\n",
      "\n",
      "         [[ 0.1557]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3839]],\n",
      "\n",
      "         [[-0.0445]],\n",
      "\n",
      "         [[ 0.0342]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0650]],\n",
      "\n",
      "         [[-0.0218]],\n",
      "\n",
      "         [[-0.4054]]],\n",
      "\n",
      "\n",
      "        [[[-0.1287]],\n",
      "\n",
      "         [[-0.1618]],\n",
      "\n",
      "         [[-0.1232]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1125]],\n",
      "\n",
      "         [[-0.4896]],\n",
      "\n",
      "         [[-0.3508]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3491]],\n",
      "\n",
      "         [[ 0.3290]],\n",
      "\n",
      "         [[-0.0149]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0731]],\n",
      "\n",
      "         [[ 0.0674]],\n",
      "\n",
      "         [[-0.4870]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.3481e-01,  6.4329e-02, -2.2486e-01, -1.3658e-01,  2.8479e-02,\n",
      "        -3.2927e-01, -3.2786e-02,  2.0262e-01,  1.6706e-01, -1.8126e-01,\n",
      "         4.9929e-01,  3.3827e-01,  3.4081e-03, -5.5830e-01, -1.9392e-01,\n",
      "         2.4686e-01,  1.4309e-01,  7.5111e-02,  1.3322e-01, -5.2031e-01,\n",
      "        -3.1489e-01,  1.9186e-01, -1.3486e-01, -3.3525e-01,  1.8205e-01,\n",
      "         1.8540e-01, -5.5496e-01,  1.9800e-01,  3.8699e-01,  3.6587e-02,\n",
      "         1.9413e-02, -2.2053e-02, -1.1982e-01,  2.4159e-01, -2.3505e-01,\n",
      "        -3.0824e-01,  3.8563e-01,  7.0408e-02, -1.1234e-01, -4.5661e-01,\n",
      "         1.5213e-01,  3.8810e-01,  1.3369e-01, -1.5860e-02, -1.7687e-01,\n",
      "         1.9895e-01, -5.1178e-01,  3.3038e-01, -2.0062e-01, -3.8033e-02,\n",
      "        -1.4269e-01,  1.2076e-01,  2.3653e-02, -3.1428e-01, -2.2020e-01,\n",
      "         1.1648e-01, -4.5895e-02,  4.3161e-02,  2.4178e-01,  4.0194e-01,\n",
      "        -1.7737e-01, -2.3012e-01,  5.0382e-02, -3.7411e-01, -3.3956e-01,\n",
      "         3.0789e-01,  8.4851e-02, -1.8841e-01,  3.9138e-02,  2.1712e-01,\n",
      "        -1.8798e-01, -7.2726e-02, -3.5486e-01, -1.6158e-01, -3.0869e-02,\n",
      "        -3.2794e-01,  7.1767e-02,  2.6352e-01,  3.4659e-03,  3.0270e-02,\n",
      "        -1.2906e-01,  1.1063e-01, -3.8938e-03,  8.1930e-02, -4.0976e-01,\n",
      "         3.6890e-01,  1.8718e-01, -3.9376e-01,  3.7191e-01,  1.1354e-01,\n",
      "        -3.2429e-01,  2.3828e-01,  1.0463e-01, -2.3297e-01,  2.1978e-01,\n",
      "        -4.1857e-01,  1.6557e-01,  5.3624e-02, -2.0489e-01, -6.5068e-02,\n",
      "         9.7445e-02, -9.6824e-02, -3.0600e-01, -2.8064e-01,  1.3060e-01,\n",
      "         1.8386e-01, -1.7509e-01,  3.2719e-01,  3.2132e-01,  1.4682e-01,\n",
      "         7.4990e-02, -2.0417e-01,  1.9417e-01, -2.6313e-01, -7.8201e-02,\n",
      "         1.6485e-01, -1.2487e-01, -1.6732e-02,  9.8253e-02, -2.5268e-01,\n",
      "         4.5943e-02,  4.8444e-01, -1.5437e-01, -4.0446e-01, -1.5793e-01,\n",
      "         3.6368e-01,  1.5967e-01,  1.3615e-01, -3.6028e-01, -1.7038e-01,\n",
      "        -1.2855e-02, -1.9237e-01, -2.5711e-02,  1.9179e-01,  4.4187e-01,\n",
      "         1.7812e-01, -8.5674e-03,  3.0413e-02,  3.9339e-01,  4.9032e-01,\n",
      "        -2.3510e-01, -1.9485e-01,  1.0615e-01, -6.2863e-02,  3.2744e-01,\n",
      "         3.7006e-02, -3.8227e-01,  3.1456e-02, -1.4633e-02,  4.7425e-01,\n",
      "        -2.6156e-02, -1.5440e-02, -1.7672e-01, -6.5616e-02, -9.8780e-02,\n",
      "         2.7504e-02, -3.3137e-01,  4.2884e-01,  1.2255e-01, -6.4130e-02,\n",
      "        -4.6435e-04, -1.0213e-01,  7.3839e-03,  3.8164e-03, -3.7250e-01,\n",
      "         2.5744e-01,  2.8167e-01,  2.9979e-01,  8.2129e-02, -2.4466e-01,\n",
      "         1.4054e-01,  2.2489e-01,  3.4950e-01, -1.4072e-01, -2.4852e-01,\n",
      "        -3.0473e-01, -1.8305e-01, -2.0522e-02, -2.8152e-01,  3.9872e-01,\n",
      "         1.2067e-01, -2.5656e-01,  2.8491e-01, -4.0487e-02,  3.0617e-02,\n",
      "         6.5637e-02, -5.1082e-02,  5.2271e-02,  7.9815e-02,  1.8713e-01,\n",
      "         8.7877e-02, -1.0881e-01,  6.4196e-02,  1.2148e-01,  3.9964e-01,\n",
      "         1.3379e-01,  4.5496e-01,  2.4150e-01,  4.9534e-01, -3.8181e-01,\n",
      "        -2.1848e-01, -1.4095e-01, -9.0434e-02, -3.5289e-01,  1.0699e-02,\n",
      "        -1.5673e-01, -1.0388e-01, -2.1555e-01,  4.7510e-01,  1.6394e-01,\n",
      "        -1.3748e-01, -3.7308e-01, -2.4162e-01,  2.0289e-01,  6.4766e-02,\n",
      "        -8.0219e-02,  4.7121e-01, -1.0354e-01,  4.8162e-02, -2.6378e-02,\n",
      "         4.6129e-01, -1.0396e-01,  5.1095e-02, -4.1114e-01,  4.2393e-01,\n",
      "        -1.2821e-01, -3.1272e-01, -7.9788e-02,  1.6518e-01, -8.8305e-02,\n",
      "         4.5271e-01, -2.8772e-01,  2.0054e-01, -2.0090e-01,  2.7001e-01,\n",
      "        -2.3918e-01,  4.8952e-01, -3.9167e-01, -3.1355e-01,  3.7027e-02,\n",
      "        -2.8126e-01, -6.2257e-02,  7.1313e-02, -2.5400e-01,  4.1102e-01,\n",
      "        -3.3778e-01,  1.6975e-01,  1.8164e-01, -2.6906e-01,  3.9504e-01,\n",
      "         1.4017e-02, -4.1199e-01, -2.2876e-01, -2.0774e-01,  1.3079e-01,\n",
      "         1.4236e-01,  7.7449e-02,  1.7476e-01,  9.6894e-02, -7.9958e-02,\n",
      "        -3.1422e-01,  1.5918e-01, -2.9610e-01, -1.6121e-01,  1.2219e-01,\n",
      "        -5.3897e-03,  2.0753e-02, -1.1386e-01, -2.2085e-01, -2.4728e-01,\n",
      "        -2.0258e-01, -1.0220e-01,  2.2904e-01,  3.5081e-01,  2.8488e-01,\n",
      "        -2.1135e-01, -2.5071e-01, -1.7722e-01,  1.3779e-01,  3.1674e-01,\n",
      "        -4.3571e-01, -3.0233e-01,  4.0714e-01,  1.7947e-01,  1.0550e-01,\n",
      "        -1.7323e-01,  9.2090e-02, -2.2163e-01, -3.5530e-01, -2.5784e-01,\n",
      "         3.9297e-01, -1.4864e-01, -1.8083e-01,  1.0236e-03, -2.9603e-01,\n",
      "         1.5102e-01,  2.6898e-02, -8.5634e-02, -2.6609e-01,  2.2295e-01,\n",
      "        -2.3018e-01,  1.0491e-02, -1.4982e-01, -3.5475e-01, -3.5566e-01,\n",
      "        -2.3567e-01, -3.8338e-01, -2.6663e-01,  4.0436e-02,  2.6962e-01,\n",
      "         1.9451e-01, -1.0140e-01,  2.1802e-01, -4.7171e-01, -1.8891e-01,\n",
      "        -3.9173e-01,  1.2338e-01, -2.9478e-01, -1.9578e-01, -1.0360e-01,\n",
      "         4.9415e-02, -2.2351e-01, -2.4286e-01, -9.2440e-02, -3.0581e-01,\n",
      "         1.9408e-01, -4.4069e-01,  8.3546e-02,  3.1112e-01, -2.8286e-01,\n",
      "        -4.6614e-02,  4.0665e-01, -1.6810e-01,  3.3779e-01,  2.0522e-02,\n",
      "         1.5147e-01,  2.5468e-01,  1.8900e-01, -4.6591e-01,  6.7317e-02,\n",
      "         3.1404e-01,  1.6370e-01,  6.7395e-02,  2.6199e-02, -1.8820e-01,\n",
      "         1.0923e-03,  2.4244e-01,  2.8133e-01, -2.1660e-01, -6.8913e-02,\n",
      "        -1.5480e-01, -1.6098e-02,  7.7119e-02, -3.6322e-02, -3.8078e-02,\n",
      "        -3.3343e-01,  3.3226e-01,  3.8951e-01,  3.0515e-01,  5.0194e-01,\n",
      "        -2.3467e-01,  3.7568e-01, -6.5990e-02,  5.1738e-01, -8.7438e-02,\n",
      "        -1.9221e-01,  5.3292e-02, -2.8484e-01, -1.6419e-02, -3.1320e-01,\n",
      "         2.8044e-01,  2.2505e-02,  4.9299e-01, -1.6741e-01,  5.3882e-01,\n",
      "         1.0891e-01, -1.5051e-01,  4.3668e-01,  1.2702e-01,  2.2288e-01,\n",
      "        -5.8225e-01,  5.1121e-01,  1.1870e-01, -2.8786e-01, -8.5994e-03,\n",
      "         1.4141e-01,  7.2586e-02, -7.2177e-02, -2.2271e-01,  4.2824e-01,\n",
      "         1.1260e-01, -2.2819e-01,  4.5107e-01,  3.5608e-01, -5.4936e-02,\n",
      "        -8.6671e-02,  5.6266e-02,  3.8007e-01, -2.3165e-01,  2.1873e-01,\n",
      "         5.9753e-01, -2.4011e-01,  2.6824e-01, -1.3063e-01,  1.3942e-01,\n",
      "         1.3621e-02,  1.7080e-01,  1.7234e-01,  2.5104e-01, -1.8820e-01,\n",
      "         9.8725e-02, -5.3376e-01, -4.5185e-01, -6.2576e-02,  2.9518e-01,\n",
      "        -4.0716e-01,  1.9184e-01,  2.1506e-02, -1.4529e-01, -1.9934e-01,\n",
      "        -2.2182e-01,  7.1986e-02,  2.1464e-02,  2.3734e-01,  4.8474e-01,\n",
      "        -2.6758e-01,  2.8924e-01, -2.5850e-01,  6.7537e-02, -4.3858e-01,\n",
      "        -3.5933e-01,  4.8111e-01,  5.2097e-01,  9.7821e-02, -1.2422e-01,\n",
      "        -1.2301e-01,  8.8912e-02, -2.9618e-01,  2.2422e-01,  4.0671e-01,\n",
      "         1.8007e-02,  4.1413e-01, -1.0189e-01,  2.0523e-01,  4.2820e-01,\n",
      "        -6.8726e-02,  7.2512e-02,  7.4279e-02,  4.2623e-01,  3.5920e-02,\n",
      "        -7.1457e-04, -4.3104e-01,  2.0349e-01,  8.0066e-02,  2.4401e-01,\n",
      "        -2.7773e-01,  3.7167e-01, -3.5716e-01, -1.0617e-01,  2.5332e-01,\n",
      "         4.2101e-01,  6.6453e-01, -1.2779e-01,  3.0712e-01, -4.7260e-02,\n",
      "        -2.9536e-01,  3.3431e-01, -2.3552e-01, -9.1917e-02, -4.1135e-01,\n",
      "         3.6331e-02, -1.6093e-02, -4.3927e-02,  1.1828e-01,  1.7161e-01,\n",
      "         4.5383e-01, -5.9344e-02, -6.8130e-02, -2.7755e-01,  2.0946e-01,\n",
      "         4.1397e-01, -3.7254e-01, -4.1885e-02,  2.8957e-01,  2.7041e-01,\n",
      "        -2.4289e-01,  1.7850e-01, -8.7455e-02,  1.4284e-01,  1.4461e-01,\n",
      "        -1.7306e-01, -4.4171e-01, -7.5571e-03, -6.6786e-02, -1.7323e-02,\n",
      "         2.2551e-01,  1.4645e-01,  6.1150e-02,  5.1785e-01,  1.6953e-01,\n",
      "         2.0014e-01,  4.2822e-02,  4.0795e-01,  8.9999e-02, -1.9549e-01,\n",
      "         6.6095e-04,  1.1246e-01, -4.0693e-01, -6.9708e-03, -2.0913e-01,\n",
      "         1.2566e-01,  3.6893e-01, -1.4735e-02, -2.9816e-01, -1.9555e-01,\n",
      "        -1.8923e-01, -1.0680e-01,  3.1914e-02,  9.1992e-02,  5.3739e-02,\n",
      "         2.9542e-01, -1.1987e-01, -3.3472e-01, -1.6054e-01,  2.8289e-01,\n",
      "         1.2740e-01, -5.2074e-02, -4.2731e-01, -7.3896e-02,  1.2198e-01,\n",
      "         3.5518e-01, -2.6579e-01,  3.1518e-02,  2.2905e-01, -4.1832e-03,\n",
      "        -1.2105e-02, -1.5742e-02,  1.2476e-01,  1.3397e-02, -1.2277e-01,\n",
      "         2.2490e-01, -3.5194e-01, -2.0750e-01,  1.6108e-02, -7.3621e-03,\n",
      "        -3.8547e-01, -2.4850e-02,  7.1216e-01,  2.4339e-01,  2.2042e-01,\n",
      "        -2.8914e-01,  9.8363e-02,  1.2657e-01, -4.3998e-02, -1.5299e-01,\n",
      "         3.1426e-01,  2.7304e-01,  1.5029e-01, -2.6208e-01, -7.8834e-02,\n",
      "        -3.6840e-02, -9.8866e-03, -2.4968e-01, -1.8048e-01, -9.2992e-02,\n",
      "         2.9517e-01, -1.2236e-01,  3.0558e-01,  3.3793e-02,  1.4896e-01,\n",
      "         1.3727e-01,  9.3769e-02,  2.5978e-01, -2.6312e-01, -1.6683e-01,\n",
      "        -2.6082e-01,  3.2700e-02,  1.5676e-01,  2.7289e-01, -1.0884e-01,\n",
      "         9.5825e-02, -4.3218e-02,  1.4711e-01,  5.2332e-01, -2.4976e-01,\n",
      "         4.5425e-02,  3.2866e-01,  3.8614e-01,  1.9913e-01,  2.3580e-01,\n",
      "        -1.7497e-01,  1.0210e-01, -9.7417e-02,  4.1786e-01,  3.9087e-01,\n",
      "        -3.3160e-02,  1.4981e-01, -1.1568e-01,  4.1287e-02,  4.2730e-01,\n",
      "        -2.7130e-01, -1.3444e-01, -1.1496e-01,  1.8738e-01, -3.6252e-01,\n",
      "         3.1769e-01,  3.0529e-01,  4.3031e-01,  2.1384e-01,  3.8287e-01,\n",
      "         2.1845e-01,  6.2855e-02,  1.2504e-01, -2.9291e-01,  1.2034e-01,\n",
      "         2.2218e-01, -2.6693e-01,  3.0247e-01,  1.1075e-01,  1.4349e-01,\n",
      "         9.1083e-02,  7.5482e-02, -2.7204e-01,  6.6217e-02,  9.8946e-02,\n",
      "         2.7337e-03, -2.0439e-01,  9.4098e-02,  4.3178e-02,  1.1170e-01,\n",
      "        -2.7490e-01, -4.0968e-01,  3.9724e-02,  5.7419e-02,  9.9073e-02,\n",
      "         1.6907e-02, -5.4277e-02,  3.0271e-01, -8.7196e-02, -1.0312e-01,\n",
      "         3.5804e-01, -5.8459e-02,  7.1849e-02,  3.1928e-01, -1.9567e-01,\n",
      "        -6.3452e-02, -3.3826e-01, -7.9452e-02, -9.6595e-02, -1.3873e-01,\n",
      "         1.9973e-01, -1.0704e-01, -4.0091e-01,  1.2782e-01, -9.5843e-02,\n",
      "         1.4238e-01, -9.4107e-02, -3.5280e-02, -3.3327e-01,  2.6078e-01,\n",
      "         5.5974e-02,  1.6200e-01, -1.1382e-01,  9.5537e-02,  9.3919e-02,\n",
      "        -2.5020e-01, -7.8105e-03, -5.7970e-02,  6.5939e-02,  1.7247e-01,\n",
      "        -8.5102e-03, -8.9103e-02,  3.9241e-02, -5.7496e-02,  2.8618e-01,\n",
      "         2.9098e-01, -5.8960e-04, -5.7016e-02,  1.3678e-02, -3.5006e-01,\n",
      "         5.4487e-01,  1.5736e-01,  1.3986e-01,  5.8470e-01, -1.7582e-01,\n",
      "         2.4105e-01,  6.0871e-01,  3.4759e-02, -4.3338e-01,  3.0873e-01,\n",
      "        -2.5417e-01,  3.8709e-01, -1.5934e-02, -1.1345e-01, -2.0878e-01,\n",
      "         4.5041e-01,  1.8323e-01,  5.5033e-02, -2.5954e-01,  2.5170e-01,\n",
      "         2.0041e-01,  3.3555e-01, -3.7205e-01,  3.5388e-01,  3.9185e-01,\n",
      "        -2.4698e-01,  5.1336e-02,  3.4104e-01,  1.9252e-01,  1.2679e-01,\n",
      "         4.7346e-01,  1.4377e-01,  5.6328e-02,  2.4434e-01, -9.5282e-02,\n",
      "         1.0867e-01,  4.6672e-01, -3.7339e-01,  4.6328e-01, -1.1297e-01,\n",
      "         1.5527e-01, -5.6214e-03,  2.1088e-01, -2.3254e-01, -2.3079e-02,\n",
      "        -9.6888e-02, -1.5597e-01, -1.2235e-02, -2.6144e-01, -2.0317e-01,\n",
      "         3.1760e-01,  4.1747e-01, -3.4069e-03, -2.2416e-01,  3.7054e-01,\n",
      "        -7.6576e-02,  1.2040e-01,  1.7271e-01, -2.6595e-02,  4.6593e-01,\n",
      "        -8.0444e-02,  3.2866e-01,  3.9748e-01,  1.9486e-02,  3.4983e-01,\n",
      "         5.5278e-01,  4.5789e-01, -1.9894e-01, -1.2739e-01,  4.7905e-01,\n",
      "        -2.2436e-02,  3.5453e-01, -3.0610e-01,  1.5721e-01, -8.9869e-02,\n",
      "        -2.6675e-01,  2.7271e-01,  1.7118e-01, -2.0625e-01, -1.0290e-01,\n",
      "         1.9806e-01, -1.9150e-01, -2.3717e-01,  1.7605e-01,  2.5261e-01,\n",
      "        -2.5201e-01, -3.4081e-01,  1.6721e-01,  8.6791e-02,  1.0382e-01,\n",
      "         1.3000e-02, -3.4627e-01,  5.1842e-01, -2.4011e-01,  1.0068e-01,\n",
      "        -6.4029e-03, -6.4155e-02, -1.0152e-01, -2.4764e-02, -3.7292e-01,\n",
      "        -1.9336e-01,  2.2545e-01,  2.0222e-01,  4.8235e-01,  5.5538e-02,\n",
      "        -1.9268e-01, -3.2783e-01,  4.2336e-01, -3.2047e-01,  1.6442e-01,\n",
      "         4.7291e-02,  4.6453e-01,  3.2490e-01, -9.2219e-02,  1.3415e-01,\n",
      "        -6.0539e-02,  3.7436e-01, -3.4648e-01, -4.8582e-02,  1.6745e-01,\n",
      "        -2.8130e-01,  3.6396e-01,  3.6735e-01, -2.7502e-01, -2.9206e-02,\n",
      "         9.8287e-02,  8.9316e-02, -2.2044e-01,  2.6199e-01, -3.0877e-01,\n",
      "        -3.2920e-01,  2.5627e-01, -2.0788e-01, -5.5551e-01,  1.3854e-01,\n",
      "        -4.7359e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0501]],\n",
      "\n",
      "         [[-0.1277]],\n",
      "\n",
      "         [[-0.1608]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2263]],\n",
      "\n",
      "         [[ 0.0560]],\n",
      "\n",
      "         [[-0.2637]]],\n",
      "\n",
      "\n",
      "        [[[-0.0690]],\n",
      "\n",
      "         [[-0.0205]],\n",
      "\n",
      "         [[-0.1530]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2524]],\n",
      "\n",
      "         [[ 0.0935]],\n",
      "\n",
      "         [[ 0.1288]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4482]],\n",
      "\n",
      "         [[-0.1226]],\n",
      "\n",
      "         [[ 0.0327]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2871]],\n",
      "\n",
      "         [[ 0.0734]],\n",
      "\n",
      "         [[ 0.1700]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2446]],\n",
      "\n",
      "         [[ 0.1868]],\n",
      "\n",
      "         [[ 0.3217]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0836]],\n",
      "\n",
      "         [[-0.0396]],\n",
      "\n",
      "         [[ 0.1277]]],\n",
      "\n",
      "\n",
      "        [[[-0.5672]],\n",
      "\n",
      "         [[ 0.4157]],\n",
      "\n",
      "         [[-0.0057]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1848]],\n",
      "\n",
      "         [[ 0.0453]],\n",
      "\n",
      "         [[ 0.0093]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0629]],\n",
      "\n",
      "         [[ 0.1389]],\n",
      "\n",
      "         [[ 0.0542]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2119]],\n",
      "\n",
      "         [[ 0.1391]],\n",
      "\n",
      "         [[ 0.1580]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.5708,  0.3400,  0.9542,  1.2820,  0.6809,  0.3572,  0.8263,  3.7624,\n",
      "         0.7467,  0.5659,  0.4139,  0.6911,  0.8459,  0.4498,  0.5604,  2.5207,\n",
      "         0.4224,  1.0953,  1.0279,  0.4838,  1.6391,  0.8620,  0.8973,  1.9652,\n",
      "         1.0770,  0.9110,  0.1506,  0.0204,  0.0885,  0.3405,  0.9720,  0.4034,\n",
      "         1.5317,  0.9139,  1.6524,  0.0394,  0.4916,  1.1399,  0.3864,  0.9821,\n",
      "         1.1395,  0.8287,  0.4604,  0.6616,  0.8767,  1.6274,  1.2066,  1.8397,\n",
      "         0.8363,  1.1719,  4.4555,  0.6913,  0.7891,  0.2010,  0.8249,  0.4663,\n",
      "         0.6715,  0.5563,  1.7805,  0.3069,  0.5554,  0.3689,  0.6658,  2.0383,\n",
      "         0.0153,  0.5015,  0.8781,  0.6241,  1.5935,  0.1113,  1.5043,  1.5224,\n",
      "         1.7557,  0.8828,  1.7849,  0.9668,  1.5173,  2.8066,  0.7295,  0.5833,\n",
      "         0.6962,  0.8485,  1.2832,  0.6372,  0.4879,  0.0693,  1.0566,  0.3795,\n",
      "         0.9128,  0.1991,  1.6805,  1.4775,  1.3448,  1.3289,  0.6280,  1.3892,\n",
      "         0.2189,  0.6211,  1.1149,  0.4638,  2.0744,  0.0819, -0.0244,  0.5666,\n",
      "         1.5687,  0.6702,  1.2339,  1.2618,  1.0992,  0.8117,  1.8909,  1.1524,\n",
      "         1.2130,  1.2082,  1.0008,  1.5194,  0.7736,  1.7856,  1.0704,  1.2643,\n",
      "         1.1512,  1.2549,  0.7634,  0.7845,  1.5629,  1.2055,  1.4494,  0.2961,\n",
      "         0.6744,  0.8652,  0.9541,  0.8047,  0.0499,  1.2461,  2.4574,  1.3866],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-7.4326e-02, -5.0166e-01,  2.5731e-01,  4.6536e-02,  3.3501e-01,\n",
      "        -5.6113e-02, -7.3466e-02, -1.8711e+00, -6.7603e-01,  2.8766e-02,\n",
      "         2.9115e-01,  5.2923e-01, -8.8507e-01,  2.4261e-01,  3.0854e-02,\n",
      "         1.3556e+00,  2.9286e-01,  2.5108e-01, -2.5457e-01,  2.9286e-01,\n",
      "        -4.1731e-01, -2.4087e-01,  1.2810e-02,  5.8574e-01, -4.1117e-01,\n",
      "         1.3759e+00, -7.2106e-02, -1.5664e-01,  4.0804e-01, -3.0385e-01,\n",
      "         2.0907e-03,  4.2749e-02,  3.0713e-01,  2.2909e-02,  1.3473e-01,\n",
      "        -4.1374e-01,  8.6512e-02,  1.3319e-01, -4.3964e-01, -2.7584e-01,\n",
      "         8.8748e-02, -2.5510e-01, -3.0722e-01,  4.2264e-01, -3.8552e-01,\n",
      "         6.4409e-01,  8.1561e-02,  9.3844e-01, -3.8689e-01,  4.6012e-01,\n",
      "        -2.2058e-01, -6.6011e-03,  2.5202e-01, -1.0639e-02, -4.1631e-02,\n",
      "         5.1882e-01, -4.3054e-01,  1.6819e-02, -5.1215e-01,  7.0962e-01,\n",
      "        -2.5536e-01, -4.5921e-01, -2.2786e-01, -7.4150e-02,  2.0763e-01,\n",
      "        -4.2302e-02,  5.8352e-02, -7.2785e-02,  4.8831e-01, -5.2343e-01,\n",
      "        -6.8399e-01,  4.3367e-01,  1.0192e+00,  3.9583e-01,  1.1201e-01,\n",
      "         2.1711e-02, -2.8911e-01, -3.4926e-01, -2.9222e-01, -1.7396e-01,\n",
      "         2.1750e-01, -4.1748e-01, -3.6555e-01,  3.5107e-01, -2.4523e-01,\n",
      "        -1.6686e-01,  3.5746e-02, -1.4093e-02,  1.6880e-01,  6.5735e-01,\n",
      "        -4.1614e-01, -3.5212e-01, -3.3120e-01,  4.5268e-01, -2.5264e-01,\n",
      "        -6.5145e-02, -2.9325e-01,  1.7814e-01,  5.1645e-04,  3.2427e-01,\n",
      "         7.7565e-01,  4.7349e-02,  1.9708e-01, -3.9316e-01,  6.3453e-01,\n",
      "        -1.8176e-03, -8.2637e-01, -2.5756e-01, -7.5580e-02, -3.2231e-02,\n",
      "         8.8893e-01,  5.2025e-01, -6.5557e-02, -5.1261e-01, -6.1590e-03,\n",
      "         2.7783e-01, -1.5802e-02, -1.1333e+00, -7.1189e-02, -1.1138e-01,\n",
      "        -5.7849e-04,  5.6723e-01,  1.3790e-01, -2.2141e-01, -2.4300e-01,\n",
      "         2.4195e-01, -1.5078e-01,  1.3495e-01,  1.4536e-01,  4.4159e-01,\n",
      "        -8.3518e-02, -4.7455e-01,  1.7615e-01,  1.0292e+00,  1.0231e+00,\n",
      "         3.9745e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.5270]],\n",
      "\n",
      "         [[ 0.2899]],\n",
      "\n",
      "         [[ 0.2995]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3261]],\n",
      "\n",
      "         [[-0.5862]],\n",
      "\n",
      "         [[ 0.1378]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2228]],\n",
      "\n",
      "         [[-0.2176]],\n",
      "\n",
      "         [[-0.3815]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4213]],\n",
      "\n",
      "         [[-0.3493]],\n",
      "\n",
      "         [[ 0.0007]]],\n",
      "\n",
      "\n",
      "        [[[-0.3618]],\n",
      "\n",
      "         [[-0.1879]],\n",
      "\n",
      "         [[ 0.0093]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3802]],\n",
      "\n",
      "         [[-0.0547]],\n",
      "\n",
      "         [[-0.0156]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4677]],\n",
      "\n",
      "         [[-0.0207]],\n",
      "\n",
      "         [[ 0.4173]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6337]],\n",
      "\n",
      "         [[-0.5382]],\n",
      "\n",
      "         [[-0.1868]]],\n",
      "\n",
      "\n",
      "        [[[-0.5632]],\n",
      "\n",
      "         [[ 0.2827]],\n",
      "\n",
      "         [[-0.4123]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7141]],\n",
      "\n",
      "         [[ 0.1389]],\n",
      "\n",
      "         [[ 0.1831]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0115]],\n",
      "\n",
      "         [[ 0.2867]],\n",
      "\n",
      "         [[-0.0060]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6126]],\n",
      "\n",
      "         [[ 0.2478]],\n",
      "\n",
      "         [[ 0.5168]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.4159,  0.7828,  1.1439,  0.3594,  0.8462,  1.0320,  1.6166,  0.9012,\n",
      "         0.5313,  1.2106,  1.3163,  0.9892,  1.7511,  1.2774,  1.7615,  1.3323,\n",
      "         1.7419,  0.6397,  0.8463,  1.0822,  0.7904,  1.2930,  1.1151,  2.0502,\n",
      "         1.1009,  1.5661,  1.3132,  1.0949,  1.2321,  0.4981,  1.0183,  1.3530,\n",
      "         1.3266,  1.0320,  1.1144,  1.1744,  1.0343,  0.8589,  0.6540,  1.8075,\n",
      "         1.6489,  1.6438,  1.1503,  1.3621,  0.9311,  1.0785,  0.4677,  1.1131,\n",
      "         0.6448,  1.0952,  1.1686,  1.2502,  0.7731,  0.1451,  1.6808,  1.3027,\n",
      "         1.3993,  1.2375,  1.3631,  1.2142,  1.6308,  1.1820,  1.0224,  1.5431,\n",
      "         1.5347,  1.0544,  1.2024,  1.2848,  1.3621,  1.3030,  1.2593,  1.0562,\n",
      "         1.0066,  1.0030,  1.3073,  1.4376,  1.6273,  1.0381,  0.7502,  0.3207,\n",
      "         1.1756,  1.7319,  0.9884,  1.1435,  1.2785,  1.8127,  1.3969,  0.5799,\n",
      "         0.6940,  1.0252,  1.2815,  0.5476,  1.5384,  1.2482,  1.8433,  0.7183,\n",
      "         1.2852,  0.5884,  0.6193,  1.7050,  1.3013,  0.8790,  1.9318,  1.1881,\n",
      "         1.8459,  1.0060,  1.5379,  1.4805,  1.0291,  1.2116,  1.2746,  0.9500,\n",
      "         0.9328,  1.0642,  0.6544,  0.8218,  1.1400,  1.1728,  0.7704,  1.6127,\n",
      "         0.9148,  1.0451,  0.7600,  0.7457,  0.4062,  0.9402,  0.5188,  1.0991,\n",
      "         0.4665,  1.8274,  0.5500,  1.1904,  0.7759,  1.6568,  1.5690,  1.3175,\n",
      "         0.4352,  1.6476,  1.3287,  1.4406,  0.9797,  0.7244,  1.6376,  0.6043,\n",
      "         0.2958,  1.0253,  0.7987,  1.1699,  0.9849,  1.4090,  1.0419,  1.4106,\n",
      "         0.9528,  0.5968,  1.5504,  0.2209,  1.2972,  0.8480,  1.7652,  1.1874,\n",
      "         1.5563,  0.8704,  1.1171,  1.9257,  1.4590,  0.9672,  0.9965,  1.3398,\n",
      "         0.8073,  1.0246,  0.7858,  0.7013,  1.1310,  0.9707,  1.6067,  0.9829,\n",
      "         0.9367,  1.7435,  1.0097,  0.9517,  0.4069,  0.9541,  0.3478,  1.4556,\n",
      "         1.1561,  1.2923,  1.4361,  1.4425,  1.9097,  0.9919,  1.4152,  1.0913,\n",
      "         1.9838,  1.2041,  1.1368,  1.3376,  1.5542,  1.0788,  0.0933,  1.3008,\n",
      "         1.2640,  1.6578,  0.2512,  0.5288,  0.7946,  0.5724,  0.6104,  1.5311,\n",
      "         1.1638,  0.9742,  1.2656,  1.2379,  0.8508,  1.1267,  1.0428,  1.4590,\n",
      "         1.6773,  0.9805,  0.8993,  1.6293,  2.6107,  1.6586,  0.9642,  0.2656,\n",
      "         1.5138,  1.4563,  1.7812,  0.7859,  0.9346,  0.6542,  1.5083,  1.8053,\n",
      "         1.1148,  0.8784,  1.2928,  1.0505,  1.0226,  0.8739,  1.0713,  1.0215,\n",
      "         0.6857,  1.2979,  0.8773,  1.6320,  0.9761,  1.9689,  0.9427,  1.0571,\n",
      "         1.3446,  1.0827,  1.2724,  1.0853,  0.9482,  0.7847,  0.9882,  0.9881,\n",
      "         0.8464,  1.0963,  0.3007,  1.9640,  1.3856,  0.9003,  0.6036,  0.8518,\n",
      "         0.6738,  0.9769,  0.9812,  1.5936,  0.5232,  1.0236,  1.3450,  0.6447,\n",
      "         1.5461,  0.9023,  1.4334,  1.1252,  1.8207,  0.7742,  1.0545,  1.1746,\n",
      "         1.4360,  0.9732,  1.2307,  1.5319,  1.0796,  0.5337,  0.7790,  0.7745,\n",
      "         1.1788,  0.6921,  0.9873,  0.7218, -0.2691,  0.3053,  0.9590,  0.3315,\n",
      "         0.2750,  1.3871,  0.7931,  1.2785,  1.2780,  1.4988,  0.8968,  2.0074,\n",
      "         1.1167,  1.5156,  1.1371,  1.0901,  0.7315,  0.8699,  1.2548,  0.1466,\n",
      "         0.8582,  0.3735,  1.2330,  1.4609,  1.3438,  1.5589,  1.6153,  1.2558,\n",
      "         1.2802,  0.9144,  0.8150,  1.0990,  1.1490,  0.5923,  1.0532,  1.6554,\n",
      "         0.6183,  1.0244,  0.9038,  1.2667,  1.2961,  0.5428,  0.5898,  0.7935,\n",
      "         2.0142,  0.6387,  1.6805,  1.0246,  1.4249,  0.9916,  1.4815,  1.1945,\n",
      "         2.2877,  1.1543,  0.6767,  0.4670,  1.0158,  0.2219,  0.7739,  1.4220,\n",
      "         0.7320,  0.9350,  1.5917,  0.5429,  1.1987,  0.8726,  1.3634,  1.4240,\n",
      "         1.7715,  0.8839,  0.9535,  0.8911,  0.9924,  0.6964, -0.2131,  0.6941,\n",
      "         0.0195,  0.6914,  0.6413,  1.1344,  1.5960,  0.8306,  0.3486,  0.4312,\n",
      "         1.2817,  1.7057,  0.9627,  0.9566,  1.1278,  1.4787,  0.5974,  0.7507,\n",
      "         1.5743,  0.8927,  1.3567,  1.3433,  1.1006,  1.4756,  1.5110,  0.5840,\n",
      "         1.7398,  1.7469,  0.6968,  1.4092,  0.2950,  0.8226,  0.8490,  0.3604,\n",
      "         0.7320,  1.1264,  1.8743,  1.4267,  0.9725,  1.2607,  1.1756,  0.1938,\n",
      "         1.2900,  0.7672,  1.3710,  0.8345,  1.2027,  1.0328,  1.1909,  0.9321,\n",
      "         1.6868,  2.0995,  1.7836,  1.6286,  1.5297,  0.7315,  1.0615,  1.2806,\n",
      "         1.1275,  1.4740,  0.5805,  1.4977,  0.9945,  1.1761,  1.2027,  1.5181,\n",
      "         1.4031,  1.3471,  1.1248,  0.5800,  1.3231,  0.4176,  1.0986,  1.1811,\n",
      "         1.0378,  1.3851,  0.6782,  0.8095,  0.1983,  1.0579,  1.1133,  0.3162,\n",
      "         1.3253,  0.8138,  1.2248,  0.9203,  1.3072,  1.4058,  0.8869,  2.1819,\n",
      "         0.9167,  1.5401,  0.4276,  1.0593,  0.6792,  1.0063,  1.6393,  1.3781,\n",
      "         1.2003,  0.8833,  0.0613,  0.3158,  0.2846,  1.6289,  1.3576,  0.6486,\n",
      "         1.0576,  0.4546,  0.8339,  1.7949,  0.8851,  1.2219,  1.6327,  1.7552,\n",
      "         0.8048,  1.2403,  0.5403,  1.7267,  1.0611,  0.9802,  1.1939,  1.6564,\n",
      "         2.0341,  0.7906,  0.4726, -0.1355,  0.9944,  0.8278,  1.7168,  0.8483,\n",
      "         0.8223,  0.7928,  1.4092,  0.7681,  1.1984,  0.7780,  1.3960,  1.3283,\n",
      "         1.1951,  0.6171,  0.8345,  0.9551,  0.9682,  1.2366,  0.3818,  1.0339,\n",
      "         1.0208,  0.4723,  0.9884,  1.6325,  1.4343,  1.2125,  0.5051,  0.9849,\n",
      "         1.6025,  2.4329,  1.9444,  0.5713,  0.5793,  0.8789,  1.3507,  1.8057,\n",
      "         1.4310,  1.2202,  1.4143,  0.8009,  2.3369,  0.4048,  1.1080,  1.1476,\n",
      "         1.8671,  1.5884,  1.2852,  1.1475,  1.5800,  0.3988,  0.9716,  0.2448,\n",
      "         0.9235,  0.6001,  2.1758,  0.9296,  0.9281,  1.1632,  1.2759,  0.8955,\n",
      "         1.7138,  0.6857,  0.9622,  1.1569,  0.5582,  0.8134,  1.2516,  0.9678,\n",
      "         0.7264,  1.2744,  1.0045,  0.6811,  1.2555,  0.9230,  1.7828,  0.6313,\n",
      "         0.4648,  1.4106,  2.1108,  0.7262,  0.8134,  0.3936,  0.5861,  1.0208,\n",
      "         0.6651,  2.0111,  1.1944,  0.9978,  1.6326,  1.3206,  0.5131,  1.0967,\n",
      "         1.1338,  1.3331,  0.9609,  1.3167,  0.6791,  1.1212,  1.0419,  1.2931,\n",
      "         2.2422,  1.5019,  0.9598,  0.9485,  1.1721,  1.3120,  1.0279,  1.2556,\n",
      "         0.9288,  0.7051,  1.9303,  0.2665,  0.5136,  0.6314,  1.4009,  0.9840,\n",
      "         1.3060,  1.3406,  1.8852,  1.0793,  0.3193,  1.4989,  0.9352,  1.2392,\n",
      "         1.4665,  1.0295,  1.1960,  0.4787,  1.7555,  1.1269,  0.6884,  0.5133,\n",
      "         0.9935,  1.8567,  0.2974,  2.2405,  1.4365,  1.5171,  1.3642,  0.9835,\n",
      "         1.0145,  1.8623,  0.8442,  1.2855,  0.8498,  0.8201,  0.3066,  0.6723,\n",
      "         1.1472,  1.1681,  1.1995,  1.4690,  0.9834,  2.3324,  0.8305,  0.5311,\n",
      "         1.4174,  0.6510,  0.8231,  0.5771,  1.2779,  0.8127,  0.9674,  1.6260,\n",
      "         1.1444,  0.8703,  1.3744,  1.3188,  1.9456,  0.7524,  1.0925,  0.8901,\n",
      "         0.8718,  1.2625,  0.9578,  0.5521,  1.6329,  0.8654,  1.2976,  1.1334,\n",
      "         1.5535,  1.3140,  1.2136,  0.6029,  1.0634,  1.0059,  0.7032,  0.9824,\n",
      "         1.8545,  1.0488,  1.8478,  0.9245,  0.8950,  1.2276,  0.7894,  0.2384,\n",
      "         0.6332,  1.4088,  1.0016,  0.8270,  1.1252,  1.4055,  0.9637,  1.3120,\n",
      "         0.3335,  1.8986,  1.0059,  1.2121,  1.1838,  1.2402,  0.6297,  1.1564,\n",
      "         0.5285,  1.2614,  0.7196,  1.0031,  2.0487,  0.8170,  0.7148,  1.3439,\n",
      "         1.0713,  1.2135,  1.5974,  0.8948,  1.5021,  0.7891,  1.1836,  1.3991,\n",
      "         1.1596,  1.0505,  0.4496,  1.0552,  1.2326,  1.2989,  1.6715,  1.1042,\n",
      "         1.8220,  1.2530,  1.4274,  1.0373,  0.9324,  0.8948, -0.1612,  0.8871,\n",
      "         1.0771,  0.6757,  0.8058,  1.3833,  1.3887,  1.3980,  0.9232,  1.2686,\n",
      "         0.8518,  1.5910,  0.8532,  0.8694,  1.5198,  0.7130,  1.4832,  1.5487,\n",
      "         1.2991,  1.2235,  1.4085,  0.8751,  1.2052,  0.4712,  0.8922,  1.0644,\n",
      "         1.3376,  0.7437,  0.7024,  0.8448,  0.6274,  0.9721,  0.6320,  1.6720,\n",
      "         0.9658,  0.9941,  1.4072,  1.2610,  0.3223,  1.4284,  1.1993,  1.0764,\n",
      "         1.0364,  1.3913,  0.8659,  0.7226,  1.1940,  1.4229,  0.7824,  1.0916,\n",
      "         0.7917,  0.9491,  0.9438,  0.9540,  1.2438,  0.6419,  0.8191,  1.0819,\n",
      "         0.7828,  0.9677,  1.2082,  0.7026,  1.0183,  1.4000,  1.9146,  1.9858,\n",
      "         1.4090,  1.0008,  1.0967,  1.3796,  1.0864,  0.9788,  1.6031,  1.9273,\n",
      "         1.0676,  0.9411,  1.0477,  0.7362,  1.4718,  1.0599,  0.8780,  1.0009],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 3.8876e-01,  8.2941e-02, -7.8538e-01,  1.5315e+00,  1.4855e-01,\n",
      "        -1.6410e+00,  2.3268e-01, -1.2158e-01, -1.8279e+00, -1.6549e+00,\n",
      "        -8.7301e-01, -2.1507e+00, -1.8185e+00, -4.3905e-02, -1.5718e+00,\n",
      "         6.6573e-01, -4.2613e-01, -1.4420e-01, -1.3353e+00, -9.0947e-01,\n",
      "        -3.5956e-01, -6.2062e-01, -1.3572e+00, -1.0990e+00, -1.1928e+00,\n",
      "         6.0744e-01,  1.1433e+00, -1.4676e-01, -1.1310e+00,  6.1068e-01,\n",
      "        -1.1948e+00, -2.0478e+00, -1.7240e-02,  6.8592e-01,  3.6776e-01,\n",
      "         1.5562e-01, -7.8801e-01, -4.4330e-01,  1.4030e-01, -1.2590e-03,\n",
      "        -2.3177e-02, -2.0826e+00,  3.0509e-01,  8.3316e-02, -7.0459e-02,\n",
      "        -1.7564e+00,  6.3063e-01, -7.2941e-01, -1.3331e+00, -2.6206e+00,\n",
      "        -1.2786e+00, -1.1361e+00, -8.0409e-01, -9.6998e-02, -2.1499e+00,\n",
      "        -7.9835e-01, -1.2638e+00, -2.8659e+00, -1.1126e+00, -2.3032e-01,\n",
      "         1.2122e-01, -1.8800e+00, -1.2613e+00, -3.1780e+00, -8.8404e-01,\n",
      "         7.9353e-01, -1.8931e+00, -8.3907e-01, -1.1219e+00, -1.6055e+00,\n",
      "        -1.2229e+00, -1.3810e+00,  2.2163e-01, -3.0965e-01, -8.4928e-01,\n",
      "        -1.0925e+00,  1.3548e-01, -5.2338e-01,  8.2137e-01, -4.0116e-01,\n",
      "        -5.7066e-01, -6.9319e-01, -1.9978e-01, -1.4193e+00, -6.9977e-01,\n",
      "        -1.1424e-01,  3.1081e-01, -8.0119e-01, -8.5177e-01, -9.0799e-01,\n",
      "        -7.0590e-01,  5.9445e-01, -1.6304e+00, -1.0682e+00, -3.8299e-02,\n",
      "        -8.6853e-02, -2.0455e+00, -2.0234e+00, -3.1675e-01, -1.0925e+00,\n",
      "        -1.3127e+00, -6.0215e-01, -4.1616e-01, -1.3690e+00, -1.8733e+00,\n",
      "        -1.1901e+00, -6.8938e-01, -1.4796e+00, -1.5195e+00, -1.3421e+00,\n",
      "        -1.8019e+00, -8.6590e-02, -1.3947e+00, -4.6565e-01, -6.4397e-01,\n",
      "         7.7059e-02, -1.8848e+00, -2.5855e+00, -9.9143e-01, -1.6292e+00,\n",
      "        -1.0491e+00, -1.7007e+00,  5.6284e-01, -1.6085e+00, -1.2647e+00,\n",
      "         9.4186e-01, -7.9970e-01, -2.1412e+00, -1.7158e-01, -4.9379e-02,\n",
      "        -1.0689e+00, -1.2584e+00,  5.9359e-01, -5.5054e-02, -1.5720e+00,\n",
      "         1.5286e-02, -3.8474e-01, -7.0960e-01, -1.4413e+00, -3.9968e-01,\n",
      "        -7.5685e-01, -7.8206e-01,  2.3468e-01, -1.1641e-01,  7.0575e-01,\n",
      "        -1.7099e+00, -1.3838e+00, -2.0684e+00, -9.5884e-01, -1.1410e+00,\n",
      "        -4.7271e-01, -1.1066e+00, -5.2954e-01,  4.2186e-02, -1.5028e-01,\n",
      "         2.6810e-01, -4.5849e-01, -1.9791e+00,  2.8460e-01, -1.1307e+00,\n",
      "        -1.4062e+00, -6.4336e-01,  1.6080e-01,  4.2605e-01, -2.3064e+00,\n",
      "        -6.9756e-01, -1.6976e+00, -8.9349e-01, -1.4428e+00, -1.2017e+00,\n",
      "         1.2982e+00,  1.0355e+00, -1.1567e+00, -3.0075e-01, -5.7945e-01,\n",
      "        -7.7229e-01, -2.0637e+00,  9.9274e-03, -1.5723e+00, -5.7620e-01,\n",
      "        -2.9973e-01, -5.6214e-01, -2.8179e-01, -2.3575e+00, -5.5298e-01,\n",
      "        -1.5692e+00, -6.4039e-01, -5.5882e-01, -6.3673e-01, -1.0511e+00,\n",
      "        -1.6946e-01, -1.0549e+00, -8.6579e-01, -1.3600e+00, -1.2592e+00,\n",
      "        -6.9648e-01, -1.5639e+00, -1.9313e+00, -4.6059e-01, -8.0198e-01,\n",
      "        -1.2533e+00, -5.0306e-01, -1.1309e-01, -4.9309e-01, -5.3418e-01,\n",
      "        -2.9016e-01,  1.4960e-01, -3.3037e-01, -3.4937e-01,  2.9033e-01,\n",
      "        -1.0784e-01, -1.6768e+00, -4.3234e-01, -1.3486e+00, -1.7022e-01,\n",
      "         4.7508e-01, -2.4370e-01, -1.2953e+00,  1.6898e-01, -2.6190e+00,\n",
      "        -1.5412e-01,  2.2842e-01, -8.6748e-01,  1.9087e-01, -3.4800e-01,\n",
      "        -2.3006e+00, -5.9209e-01,  5.1325e-04, -9.0480e-01, -7.5164e-01,\n",
      "        -2.1349e+00,  2.8973e-01, -1.0122e+00,  1.6478e+00,  5.7001e-01,\n",
      "        -1.7570e+00, -1.1697e+00, -9.9451e-01, -2.7064e-01, -1.2881e+00,\n",
      "        -2.9442e-01, -1.9361e+00,  1.1563e+00, -1.1173e+00,  5.9553e-01,\n",
      "         2.3899e-01,  3.2677e-01, -1.5299e+00, -2.9855e-01, -2.3189e+00,\n",
      "        -3.4826e-01, -6.7724e-01, -2.7066e-01, -1.7683e+00, -9.1120e-01,\n",
      "        -2.5831e-01,  6.0611e-02, -1.8004e+00,  2.8222e-01, -2.2465e+00,\n",
      "        -1.5676e+00, -8.2018e-01, -2.7977e-01, -1.2898e+00, -7.7859e-01,\n",
      "        -4.2752e-01, -1.1808e+00, -1.6816e-01, -1.2637e-01, -1.6572e+00,\n",
      "         5.7846e-01,  6.3032e-01, -8.4069e-01,  2.2357e-02, -5.8431e-01,\n",
      "        -1.3568e+00, -2.2569e+00, -1.8408e+00, -6.2015e-01, -3.6870e-01,\n",
      "         4.0897e-01, -1.4494e+00, -3.6884e-01, -7.7155e-01, -2.3567e+00,\n",
      "         5.3424e-01, -5.4882e-01,  4.0755e-01, -5.1215e-01, -1.3521e+00,\n",
      "        -1.6973e+00, -6.7333e-03,  1.0491e-01,  9.1022e-01, -7.8493e-01,\n",
      "         5.5763e-01, -1.9738e+00,  1.5369e-01, -5.7542e-01, -3.1122e-01,\n",
      "         1.0922e-01, -1.2161e+00, -8.6365e-01, -6.6517e-02, -2.0942e+00,\n",
      "        -3.9424e-01, -8.5151e-01, -1.0881e+00, -9.6723e-01, -8.9355e-01,\n",
      "        -6.7133e-01,  3.1254e-01, -2.1176e-01,  4.3458e-03, -1.1600e+00,\n",
      "        -1.1240e+00, -1.2357e+00, -5.1059e-01,  4.2963e-02, -1.0494e+00,\n",
      "        -1.1310e+00, -1.2093e+00,  1.3527e+00,  2.1327e-01, -1.7738e+00,\n",
      "         2.9530e-01, -8.7600e-01, -4.7110e-01, -1.5720e+00,  2.4009e-01,\n",
      "         1.2188e-01,  1.4819e+00, -9.0260e-01,  2.1145e-01, -1.1713e+00,\n",
      "         5.8083e-02, -1.7385e+00, -6.3722e-01, -2.6223e-01, -2.3775e+00,\n",
      "        -1.3100e+00, -1.6892e+00, -8.9019e-01,  3.5511e-01, -1.1435e+00,\n",
      "         2.5363e-01,  6.4418e-01, -4.1874e-02, -7.6020e-01, -2.5167e-01,\n",
      "        -5.8619e-01, -6.0134e-01, -2.0447e-01, -9.0462e-01, -1.2728e+00,\n",
      "        -1.0457e+00, -2.1369e-01, -3.3379e-01,  2.3124e-01, -1.0185e+00,\n",
      "        -2.3438e+00, -1.2200e+00, -1.1421e+00, -1.5003e+00, -6.6090e-01,\n",
      "        -8.1070e-01,  2.4853e-02,  1.5674e-01, -5.7999e-01,  1.3062e+00,\n",
      "        -9.8779e-01, -1.7291e-02,  1.1344e-01,  1.6792e+00,  2.9384e-01,\n",
      "        -5.1250e-02, -4.6319e-01, -6.2614e-01, -1.4747e+00, -1.7577e+00,\n",
      "        -2.1328e+00,  7.2716e-02, -5.8814e-02,  6.2836e-01, -5.7400e-01,\n",
      "        -2.0095e+00, -8.6165e-01, -7.0136e-01, -1.7509e-01, -3.7175e-01,\n",
      "        -1.7968e+00, -1.1577e+00,  9.5686e-01, -2.1811e+00, -1.1051e+00,\n",
      "        -9.0695e-01, -3.1529e-01,  5.4406e-01,  6.3878e-01,  2.5019e-01,\n",
      "        -7.1131e-01, -1.7987e+00, -1.1584e+00, -3.1808e-01, -3.3382e-01,\n",
      "        -1.2485e+00, -1.2190e+00,  2.5904e-01, -1.2879e+00, -1.3788e+00,\n",
      "        -2.2055e+00, -1.3113e+00, -8.6658e-01, -1.1916e+00, -7.6905e-01,\n",
      "         7.9581e-01, -1.4948e+00, -4.6508e-01, -2.3330e+00, -1.9542e+00,\n",
      "        -1.0548e+00,  1.8321e-01, -1.1311e+00, -1.5748e+00, -2.5343e+00,\n",
      "        -1.6826e+00,  4.7232e-01,  1.3707e-01,  2.6541e-01, -1.7977e+00,\n",
      "        -2.0041e+00, -5.3598e-02, -1.6932e-01, -1.7716e-01, -1.1461e+00,\n",
      "        -1.2892e+00, -7.1026e-01,  4.5989e-01, -6.3784e-01, -1.5746e+00,\n",
      "        -2.4029e-01, -2.7540e+00,  1.6955e-01, -1.1433e+00,  4.5062e-01,\n",
      "        -2.9704e+00, -3.3893e-01,  8.0829e-01,  6.6719e-02,  5.2743e-01,\n",
      "        -1.7029e+00, -1.4591e+00, -2.4103e-01, -1.5285e+00, -8.6210e-01,\n",
      "        -2.9611e-02, -1.4674e+00, -3.8669e-01, -1.7536e+00, -5.3094e-01,\n",
      "         5.3404e-01, -1.4571e+00, -1.5146e+00, -3.4120e-01, -4.8511e-01,\n",
      "        -1.3295e+00,  8.0478e-01,  2.4076e-01, -2.3206e-01, -5.5676e-01,\n",
      "        -8.2331e-01,  8.3940e-02,  4.1443e-01,  6.6280e-01, -1.2183e+00,\n",
      "        -2.1487e+00, -1.8217e+00, -6.1548e-01, -1.1315e-01, -4.5894e-01,\n",
      "        -2.2432e+00, -1.2502e+00, -4.5953e-01,  2.9320e-01, -1.5277e+00,\n",
      "        -7.6437e-01, -1.2547e+00, -1.2033e+00,  1.4667e-01, -8.6110e-01,\n",
      "        -1.3513e+00,  3.2501e-01, -1.4493e+00, -1.0473e+00, -3.1552e-01,\n",
      "         5.8209e-01, -5.6142e-01, -1.1296e+00, -2.2752e+00,  7.4455e-01,\n",
      "        -9.9398e-01, -2.3232e-01,  2.0302e-01,  8.5135e-02, -1.2513e+00,\n",
      "        -5.6296e-01, -1.2021e+00,  1.2672e+00, -1.2250e+00, -5.0004e-01,\n",
      "        -1.5529e-01,  8.2968e-01, -1.7925e+00, -7.5145e-02, -4.8067e-01,\n",
      "        -1.9744e+00,  3.0533e-02, -9.6447e-01, -2.9898e-01, -1.3390e+00,\n",
      "        -5.8331e-01, -6.6314e-01, -2.0135e+00,  3.9163e-01,  1.7448e-01,\n",
      "         2.3153e-01, -2.1461e-01, -3.7660e-02,  1.2162e-01, -1.5657e+00,\n",
      "        -7.0022e-01,  9.5549e-01, -1.1537e+00, -4.9059e-01, -1.2499e-01,\n",
      "         4.6970e-01,  8.7491e-01, -1.1546e+00, -5.4299e-02, -1.2408e+00,\n",
      "         2.0349e-02, -8.2002e-02, -2.1545e+00, -3.9199e-01, -1.5532e+00,\n",
      "         2.7883e-02, -9.8286e-01, -2.1403e+00, -1.6482e+00, -7.8966e-01,\n",
      "        -3.7456e-01, -1.6460e+00, -7.2982e-02, -9.8851e-02,  2.5346e-01,\n",
      "         3.6501e-01,  9.1316e-01, -4.0531e-01, -5.4898e-01, -1.0291e+00,\n",
      "        -7.5037e-02, -9.9096e-01, -1.3150e-01, -6.9335e-01, -1.5128e+00,\n",
      "        -5.0156e-01, -7.8493e-01, -8.3690e-01,  6.1735e-01, -5.3257e-01,\n",
      "         3.8393e-01,  1.6216e+00, -5.1253e-01,  2.4696e-01, -6.2307e-01,\n",
      "         8.7419e-02, -2.4117e-01, -7.2787e-01, -2.5384e+00, -5.4130e-01,\n",
      "         1.4072e-01, -2.1509e-01,  4.7804e-01,  5.1030e-01, -8.7756e-01,\n",
      "        -4.8757e-01, -1.2921e+00, -5.1384e-01, -8.7716e-01,  4.3966e-01,\n",
      "         3.6465e-01, -1.5312e+00, -2.9564e-02, -3.6633e-01, -1.4039e+00,\n",
      "        -2.0446e+00, -1.6639e+00, -1.5688e+00, -4.9360e-01, -1.3937e+00,\n",
      "        -1.3884e+00, -6.2917e-01,  1.1346e-01,  3.0263e-01, -2.0819e-01,\n",
      "        -5.5773e-01, -8.7811e-01, -1.1506e+00,  2.2187e-01, -2.1096e+00,\n",
      "        -1.1611e-01, -2.7152e+00,  3.8704e-01, -1.0735e+00, -1.9291e-01,\n",
      "        -1.3442e+00, -1.2875e-01, -1.6692e+00, -9.7696e-01,  3.1429e-01,\n",
      "        -3.1173e-01, -2.1682e-01,  1.3044e-01,  9.4569e-02,  4.1086e-01,\n",
      "        -1.5534e+00, -1.6403e+00, -8.8605e-02,  1.5097e-01, -1.7277e-01,\n",
      "        -3.4173e-01, -1.5233e+00, -1.1262e+00, -8.3607e-01, -1.0107e+00,\n",
      "        -2.9022e-01, -1.1558e+00, -9.8119e-01,  1.1733e-01,  1.1066e+00,\n",
      "        -8.4808e-01,  3.1046e-01, -5.5489e-01, -1.4958e+00, -1.4284e+00,\n",
      "        -1.5920e-01, -6.3189e-01,  7.7785e-01, -1.5529e+00,  2.3359e-01,\n",
      "        -8.7732e-01, -1.0260e+00,  2.8208e-01,  6.7038e-01, -1.0160e+00,\n",
      "        -1.0168e+00,  4.7373e-01, -1.3631e+00, -7.5892e-01,  4.3544e-01,\n",
      "        -6.6271e-01, -3.0356e-01, -1.8774e+00, -1.3558e+00,  3.0514e-01,\n",
      "        -5.0250e-01, -1.4832e+00, -1.6405e+00, -3.7432e-01, -1.0275e+00,\n",
      "        -1.2690e+00, -3.3798e-01, -6.1542e-01, -2.1033e+00, -4.6525e-01,\n",
      "         4.1076e-01, -1.3305e+00, -4.6056e-01, -1.5993e+00, -1.1754e+00,\n",
      "        -2.0084e-01, -7.9029e-01,  6.8195e-01, -2.0015e+00, -2.0497e+00,\n",
      "        -7.5609e-01, -9.0112e-01, -7.8003e-01, -1.6712e-01, -1.3776e+00,\n",
      "        -8.8742e-01, -1.7364e+00, -1.1694e+00, -6.4130e-01, -1.0126e+00,\n",
      "        -1.0013e+00, -8.3709e-01, -8.9781e-01, -9.8286e-01, -5.8523e-01,\n",
      "        -1.5523e+00, -2.0604e-01,  1.0028e+00, -9.1040e-01, -1.6329e+00,\n",
      "         4.5437e-01, -1.4814e+00, -9.2259e-01, -7.0851e-01, -1.2480e+00,\n",
      "        -5.4596e-01, -1.6073e+00,  6.8680e-02, -9.7979e-01, -6.2382e-01,\n",
      "        -1.2072e-01, -1.1424e+00, -8.3864e-01,  7.2402e-01, -3.9293e-01,\n",
      "        -1.8772e+00, -8.4911e-01, -3.3384e-01, -4.0793e-01, -1.1682e+00,\n",
      "        -4.6785e-01, -8.8667e-01, -1.6309e+00, -2.0115e-01,  4.6289e-01,\n",
      "        -5.8787e-02, -1.2492e+00, -2.1275e+00,  2.0632e-01, -1.0423e-02,\n",
      "        -1.0402e+00, -9.2883e-01,  6.5669e-01,  4.4135e-01,  1.2977e-01,\n",
      "        -1.2855e+00, -6.6240e-01,  3.3297e-01,  1.8955e+00, -4.5737e-01,\n",
      "        -5.3019e-01,  4.0269e-01,  6.7132e-01, -1.3041e+00,  3.1935e-01,\n",
      "        -6.3528e-02, -1.3683e+00, -3.6952e-01, -6.8873e-01, -3.6596e-01,\n",
      "        -6.4493e-01, -1.3717e+00, -1.1287e+00, -1.2478e+00, -6.1867e-01,\n",
      "        -3.3480e-01, -2.1639e-01, -4.4013e-01, -1.3740e+00, -1.2700e-01,\n",
      "        -2.1018e+00, -5.7199e-01,  2.4976e-01, -9.7676e-01, -7.1611e-01,\n",
      "        -9.6752e-01, -1.3842e+00,  2.6712e-01, -3.4124e-01, -9.0585e-01,\n",
      "        -1.7887e+00, -1.1649e+00, -5.5162e-01, -9.9782e-01,  7.9752e-01,\n",
      "         9.1227e-01, -1.0214e+00,  3.1671e-01,  3.3103e-01, -7.9954e-01,\n",
      "        -1.3096e+00, -1.8971e+00, -4.3880e-01, -1.4047e+00, -7.9718e-01,\n",
      "         2.5022e-01,  1.1350e-01, -4.1859e-02, -1.2741e+00, -8.0061e-01,\n",
      "         2.3465e-01, -7.5625e-01, -5.8290e-01, -5.8201e-01, -7.9678e-01,\n",
      "         1.0327e+00, -7.6194e-01, -5.9534e-01, -6.6381e-01, -1.4216e+00,\n",
      "        -1.2360e+00, -4.9303e-01, -6.9940e-01, -1.3120e+00, -9.8470e-01,\n",
      "        -9.9830e-01,  4.4726e-01, -6.7781e-01, -1.5794e+00, -6.2325e-01,\n",
      "        -1.2665e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.4125, -0.3226, -0.4636, -0.1854, -0.4253],\n",
      "          [ 0.1406, -0.0537, -0.1580, -0.2839, -0.2879],\n",
      "          [ 0.1279,  0.2897, -0.0451,  0.0490, -0.0396],\n",
      "          [ 0.0274,  0.7818,  0.3556,  0.2429,  0.2986],\n",
      "          [ 0.2424,  0.7423,  0.2848, -0.0395,  0.0892]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0546,  0.1715,  0.0621, -0.3008, -0.4228],\n",
      "          [-0.4780, -0.0053, -0.3088, -0.3181, -0.0166],\n",
      "          [-0.4712, -0.0241, -0.5980, -0.0069,  0.2823],\n",
      "          [-0.1588, -0.2932, -0.0649,  0.6991,  0.1306],\n",
      "          [-0.2514, -0.5482,  0.2264,  0.2481,  0.2580]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3541, -0.0323, -0.0898,  0.2089, -0.0477],\n",
      "          [ 0.2089, -0.1074, -0.2699,  0.0601,  0.0806],\n",
      "          [-0.0565, -0.0238, -0.4224, -0.0323,  0.2739],\n",
      "          [-0.3252, -0.3652, -0.0576,  0.6184,  1.0857],\n",
      "          [-0.0567,  0.1361,  0.1423,  0.2230,  0.5633]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4993, -0.5850, -0.2498, -0.2932, -0.4006],\n",
      "          [-0.2998, -0.4838, -0.3791, -0.3743, -0.5477],\n",
      "          [-0.1554, -0.6489, -0.0336, -0.4378, -0.4596],\n",
      "          [-0.1445,  0.0161, -0.0268,  0.0127,  0.1274],\n",
      "          [-0.0829,  0.2240, -0.2216,  0.1791,  0.4793]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1454,  0.8633,  0.2170,  0.1858,  0.0579],\n",
      "          [-0.2018,  0.0766,  0.2596, -0.3304, -0.2750],\n",
      "          [ 0.2455, -0.0093, -0.2054, -0.5514, -0.2972],\n",
      "          [-0.1791,  0.3456, -0.2413, -0.5856, -0.5694],\n",
      "          [-0.2171, -0.0091,  0.0585,  0.2195, -0.1340]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4919, -0.2372, -0.3409,  0.3272,  0.8057],\n",
      "          [-0.0234, -0.1419, -0.2784,  0.0767,  0.0770],\n",
      "          [ 0.3591,  0.0062,  0.0088, -0.7580,  0.1801],\n",
      "          [-0.0696,  0.1835, -0.1202,  0.5726,  0.0452],\n",
      "          [ 0.3750,  0.1282,  0.2216,  0.1207,  0.5411]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.8791, 2.5853, 1.4348, 1.7364, 2.2816, 0.9482, 1.4961, 1.7912, 1.2036,\n",
      "        1.2717, 1.6246, 1.5046, 3.1037, 1.4794, 3.1116, 1.2441, 1.5493, 1.8704,\n",
      "        1.4607, 0.9018, 2.2812, 2.0380, 3.2889, 2.2186, 1.1099, 1.5780, 1.4716,\n",
      "        1.4148, 0.4722, 1.3097, 1.1986, 2.6770, 1.8417, 1.0922, 1.7491, 1.9423,\n",
      "        1.3435, 1.5621, 1.7332, 0.7627, 1.5911, 3.2871, 1.4087, 2.6634, 1.7270,\n",
      "        1.4549, 1.5608, 1.2831, 1.2045, 0.9213, 1.6866, 1.4417, 1.6500, 1.8685,\n",
      "        2.3188, 2.1012, 3.0011, 0.8625, 1.2301, 1.2178, 2.3756, 0.9733, 2.0098,\n",
      "        2.8340, 1.5128, 1.7296, 1.5315, 1.2096, 0.4752, 1.1256, 1.7064, 0.5519,\n",
      "        1.3911, 1.7535, 1.1971, 1.1612, 1.1373, 1.8182, 1.3848, 1.6371, 1.9645,\n",
      "        2.0449, 1.6943, 1.0621, 2.0695, 0.6383, 2.3789, 0.8921, 1.3790, 1.2633,\n",
      "        1.3459, 1.5739, 1.2092, 1.6765, 0.9634, 0.7258, 4.3138, 1.0472, 1.5200,\n",
      "        2.3623, 1.3758, 0.5199, 0.9125, 0.9392, 1.1168, 2.9197, 1.6067, 1.2693,\n",
      "        1.4300, 2.0905, 1.3368, 1.3114, 1.7185, 1.6297, 1.5682, 2.0023, 1.1834,\n",
      "        0.2472, 1.9572, 2.7568, 2.2007, 1.2041, 2.7431, 1.4649, 1.1107, 1.6195,\n",
      "        1.2596, 1.2568, 1.4299, 1.4699, 1.5976, 1.4506, 1.5875, 1.4253, 3.5763,\n",
      "        1.3442, 1.9274, 1.3110, 0.7875, 1.7997, 1.4523, 1.1420, 1.8421, 1.4970,\n",
      "        1.7642, 1.0173, 1.3077, 1.4162, 1.3778, 2.1155, 1.9187, 1.1529, 1.8537,\n",
      "        1.4406, 1.5195, 1.8862, 1.8419, 1.0955, 1.4716, 1.5652, 1.9008, 1.8067,\n",
      "        1.8333, 1.3685, 3.0124, 1.7197, 1.2459, 2.3145, 0.7940, 1.1471, 2.1660,\n",
      "        1.4974, 1.3046, 1.9119, 1.0041, 1.1364, 0.8767, 1.5289, 1.1158, 0.9995,\n",
      "        1.5553, 1.3805, 2.0914, 0.8675, 1.3416, 0.9749, 1.2292, 1.3161, 2.1209,\n",
      "        1.4538, 0.1898, 1.3599, 1.4245, 2.2103, 1.0796, 1.4464, 1.2481, 0.7530,\n",
      "        1.4148, 2.6164, 1.5370, 0.5114, 1.7004, 1.7974, 1.5037, 1.4283, 2.1650,\n",
      "        1.1109, 0.7742, 1.8615, 1.3584, 0.9235, 1.6442, 0.7523, 1.2372, 2.4084,\n",
      "        0.9031, 1.4851, 1.4645, 3.3393, 2.0572, 1.2956, 1.3794, 1.9410, 1.0988,\n",
      "        2.8430, 1.5454, 1.6687, 1.7557, 2.3809, 2.7173, 1.6606, 1.5459, 2.7728,\n",
      "        1.9868, 0.4791, 1.0122, 1.4953, 1.3480, 1.8363, 1.2312, 1.0932, 1.9363,\n",
      "        1.1257, 1.5393, 2.0345, 2.2856, 0.9292, 1.1138, 0.8615, 2.3743, 1.1122,\n",
      "        1.6138, 0.7596, 1.8266, 1.1286, 1.3993, 2.0615, 0.8054, 1.0437, 0.9594,\n",
      "        1.7216, 1.1368, 1.3134, 1.1735, 1.2148, 0.5624, 1.9299, 2.0175, 0.6732,\n",
      "        2.1958, 1.7735, 0.5894, 1.8358, 2.0381, 1.9408, 1.3788, 1.7779, 1.7293,\n",
      "        1.8721, 2.2634, 1.5767, 1.5522, 1.5287, 1.6518, 1.6449, 1.1292, 1.5451,\n",
      "        2.0585, 1.3383, 0.4140, 1.7719, 1.4462, 1.5148, 1.2252, 1.5894, 1.1054,\n",
      "        1.9779, 1.4680, 1.3444, 1.8914, 0.8513, 1.3957, 1.0064, 1.3156, 1.3637,\n",
      "        2.8882, 1.0492, 1.5188, 0.7693, 1.4203, 2.0483, 1.2131, 2.1975, 1.4284,\n",
      "        2.4281, 0.7013, 1.7993, 0.9834, 1.6462, 1.4818, 1.0020, 1.7595, 1.2206,\n",
      "        1.2990, 1.4327, 1.4194, 1.8080, 0.3128, 0.7874, 1.8752, 2.0639, 1.2550,\n",
      "        1.8797, 0.8742, 1.6530, 2.9597, 1.5307, 1.3564, 0.9361, 2.0908, 1.1473,\n",
      "        1.2143, 1.9191, 2.0218, 1.3536, 2.0315, 1.5271, 1.9627, 1.2648, 0.6966,\n",
      "        1.5339, 1.8241, 1.0047, 0.6922, 1.5271, 1.4101, 2.0563, 2.0676, 1.1206,\n",
      "        3.7354, 1.6683, 1.6075, 0.9934, 1.4742, 1.3116, 0.7029, 1.3838, 1.0546,\n",
      "        1.7915, 1.5322, 1.4159, 1.4032, 2.4981, 2.3449, 1.6220, 2.0626, 1.2198,\n",
      "        1.0746, 0.9055, 1.1742, 2.5554, 1.8604, 2.0104, 1.6635, 1.3287, 2.5336,\n",
      "        1.5780, 1.4675, 2.0483, 1.2895, 0.6528, 2.3172, 2.3138, 1.4467, 0.7039,\n",
      "        1.9944, 1.9632, 2.1043, 2.1267, 1.4832, 0.7337, 4.0420, 1.7519, 1.9848,\n",
      "        0.9453, 1.5061, 1.4714, 1.1676, 1.4131, 1.5275, 1.2268, 1.6207, 1.3898,\n",
      "        2.0045, 1.8488, 1.1169, 1.4164, 3.6264, 3.8426, 1.3252, 1.8993, 1.7150,\n",
      "        1.5731, 1.4787, 0.4673, 1.4241, 0.9895, 1.7874, 1.2383, 0.9647, 0.9130,\n",
      "        1.5354, 2.1151, 1.4476, 1.1347, 1.0299, 2.0107, 1.3108, 2.6046, 1.4961,\n",
      "        2.0819, 1.6574, 1.1420, 1.9710, 2.4571, 0.8035, 1.1856, 0.9470, 1.7976,\n",
      "        1.3057, 1.2583, 1.6311, 1.5308, 1.3986, 1.6608, 0.8025, 0.9922, 0.6519,\n",
      "        1.4709, 1.4746, 1.2905, 0.8072, 1.3395, 1.3962, 0.8189, 1.4990, 1.6597,\n",
      "        1.3069, 1.0566, 1.6445, 2.0887, 1.5585, 1.8843, 1.1678, 1.1672, 1.7349,\n",
      "        1.9407, 1.6278, 2.8090, 1.1206, 3.0017, 0.4476, 2.0833, 0.5277, 1.2963,\n",
      "        1.4857, 2.2187, 0.9151, 1.4337, 1.3028, 1.5781, 0.8477, 1.5787, 2.6450,\n",
      "        1.6597, 1.4623, 1.6126, 2.6227, 1.7579, 1.9011, 1.6956, 1.3505, 1.6988,\n",
      "        0.5892, 2.2470, 2.2273, 1.8811, 1.2583, 1.5944, 2.0616, 2.3319, 1.5685,\n",
      "        0.8883, 2.0695, 2.1317, 0.9257, 1.3642, 1.3759, 1.2487, 1.4974, 1.8244,\n",
      "        3.3429, 1.7321, 2.0536, 1.9488, 1.6132, 1.2497, 1.7211, 1.1133, 1.2230,\n",
      "        2.0035, 3.0387, 1.6370, 1.3868, 2.5237, 1.8317, 2.3978, 1.5813, 1.2902,\n",
      "        2.6453, 1.8674, 1.3013, 1.6109, 1.1461, 1.6088, 3.4290, 1.4592, 1.6443,\n",
      "        2.1972, 1.4798, 1.3382, 0.9733, 1.6821, 1.1876, 2.3952, 1.5860, 1.2912,\n",
      "        1.8312, 1.5367, 1.1459, 0.1463, 2.0091, 1.6086, 1.1202, 1.5266, 0.9528,\n",
      "        1.4607, 2.2755, 1.1282, 1.4126, 1.7589, 1.3980, 2.0893, 1.4245, 1.8639,\n",
      "        2.0628, 1.5754, 0.9282, 2.0240, 1.2898, 1.6075, 1.7789, 1.8175, 1.9761,\n",
      "        1.4037, 1.7336, 1.8769, 1.3892, 1.3387, 2.3210, 1.3863, 1.6647, 0.8610,\n",
      "        1.1380, 1.1780, 0.8252, 0.4251, 1.4110, 0.8654, 1.3811, 1.5108, 1.7812,\n",
      "        1.4195, 1.5315, 1.4826, 1.8543, 1.5855, 1.3730, 1.0015, 1.6530, 0.9628,\n",
      "        1.5603, 0.8371, 1.7876, 1.0857, 1.3332, 2.1736, 1.5416, 1.4876, 1.6329,\n",
      "        1.2302, 1.4188, 1.7648, 2.3233, 2.1938, 1.3402, 0.9636, 1.6518, 1.6834,\n",
      "        1.8136, 1.0855, 1.4036, 0.2431, 1.5365, 1.7926, 1.3685, 1.5328, 2.2946,\n",
      "        2.0882, 1.8375, 2.4403, 0.7970, 1.6810, 0.6353, 1.0735, 1.4800, 1.4788,\n",
      "        0.9251, 2.1190, 1.1143, 1.5550, 1.9111, 2.2568, 1.3832, 2.1740, 1.4567,\n",
      "        0.8489, 1.8465, 1.5798, 0.9042, 1.9066, 1.3957, 1.1746, 2.0202, 3.0244,\n",
      "        0.2501, 0.8071, 1.5793, 0.8210, 1.6047, 1.8722, 1.1655, 1.0759, 1.1577,\n",
      "        1.8527, 0.5524, 1.9358, 1.7349, 0.9592, 0.8932, 1.4261, 2.0252, 1.6349,\n",
      "        0.9198, 1.4484, 1.2596, 1.2937, 1.4280, 2.0872, 1.5599, 2.2173, 1.6779,\n",
      "        0.8972, 1.1958, 1.2641, 1.4760, 2.9411, 2.1846, 1.2980, 1.4455, 1.1138,\n",
      "        1.2728, 1.5717, 0.8731, 1.6003, 1.3315, 1.9939, 0.7977, 1.5505, 1.3791,\n",
      "        1.5076, 2.1879, 1.5648, 1.3906, 1.0530, 1.1110, 1.5372, 2.0071, 1.1065,\n",
      "        1.2022, 1.1176, 1.3997, 1.1863, 0.6365, 1.0925, 1.0756, 1.4940, 1.5681,\n",
      "        1.7585, 1.6134, 0.8243, 1.1665, 1.6926, 1.7496, 1.8124, 1.4713, 1.8587,\n",
      "        1.7577, 2.2537, 0.8595, 1.5902, 2.0934, 1.8989, 1.4189, 1.4882, 1.9376,\n",
      "        1.8636, 3.5188, 1.8558, 1.3681, 1.1598, 1.2345, 1.6263, 1.1241, 1.7372,\n",
      "        1.7601, 1.3778, 1.7831, 1.5348, 1.6812, 1.4365, 1.5559, 1.1101, 0.9475,\n",
      "        2.6567, 1.3484, 2.1003, 1.2382, 1.6836, 1.0891, 0.7450, 1.7203, 1.4034,\n",
      "        1.8504, 1.5549, 1.2877, 0.7344, 1.2779, 2.2423, 1.4294, 1.1704, 1.5730,\n",
      "        1.6445, 1.6387, 1.6771, 0.4501, 2.1279, 1.8746, 1.9761, 1.5201, 1.1914,\n",
      "        1.5173, 0.9189, 1.4295, 1.5197, 1.3340, 1.5640, 1.4607, 1.1629, 1.8363,\n",
      "        1.9231, 1.2882, 1.5832, 1.7771, 1.0764, 1.7436, 0.3072, 2.5259, 1.0215,\n",
      "        2.4474, 1.6928, 0.8626, 1.8882, 1.0311, 1.1780], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-8.6360e-01, -2.3949e+00, -6.1287e-01, -5.8459e-02, -1.1102e+00,\n",
      "        -2.6782e-01, -1.2239e+00, -1.1971e-01, -9.3415e-01, -2.0158e+00,\n",
      "        -2.7544e+00, -5.8685e-01,  5.1944e-02, -7.2307e-01,  5.8724e-01,\n",
      "        -7.1410e-01, -1.3127e+00, -1.7734e+00, -1.5208e+00, -2.7271e-01,\n",
      "        -1.1223e+00, -1.0679e+00, -2.5585e+00,  1.2371e-01, -3.6526e-01,\n",
      "        -3.6563e-01, -1.1866e+00, -1.7717e+00, -1.3999e-01, -1.9990e+00,\n",
      "        -2.5459e-01, -2.9884e+00, -1.2570e+00, -1.4227e-01, -1.7119e+00,\n",
      "        -2.8177e-01, -6.6057e-01, -2.5065e+00, -1.8578e+00, -1.5716e-01,\n",
      "        -2.8692e-01, -3.7779e-01, -1.3968e+00, -1.3641e+00, -1.6987e+00,\n",
      "        -1.0358e+00, -1.2310e+00, -7.8519e-01, -1.1618e+00, -3.0933e-01,\n",
      "        -1.0470e+00, -4.0777e+00, -1.9454e+00, -2.5595e+00, -9.5214e-01,\n",
      "        -1.3691e+00, -4.1799e-01, -2.3873e-01, -2.8000e-01, -3.8288e-01,\n",
      "        -1.9586e+00,  5.5031e-01, -9.7092e-01, -7.7904e-01, -7.0855e-01,\n",
      "        -1.2719e+00, -6.3178e-01, -4.7521e-01,  1.8355e-01, -1.7218e-01,\n",
      "        -9.1824e-01, -2.5332e-01, -6.0255e-01, -1.7442e+00, -8.1688e-01,\n",
      "         3.9612e-02, -6.6313e-01,  6.1960e-03, -2.8363e+00, -1.9609e+00,\n",
      "        -6.9242e-01, -1.1663e+00, -1.0352e+00, -1.5477e-01, -1.2642e+00,\n",
      "         6.1465e-01, -8.0785e-01, -1.8920e-01, -3.2750e-01, -5.8357e-01,\n",
      "        -9.9965e-01, -9.7138e-01, -6.7452e-01, -1.4446e+00, -4.5269e-01,\n",
      "        -3.8745e-01, -8.2238e-01, -1.4804e+00, -1.1142e+00, -8.0831e-01,\n",
      "        -1.9711e-01, -3.3246e-01, -4.3240e-01, -1.6925e-01, -1.8277e-01,\n",
      "        -1.3797e+00, -9.8198e-01, -1.2293e-01, -2.1936e+00, -2.5855e-01,\n",
      "        -5.9386e-01, -9.3408e-01, -1.3468e+00,  1.8570e-01, -1.1633e+00,\n",
      "        -1.4169e+00,  3.2470e-01, -1.3736e-01, -1.2780e+00,  5.8701e-01,\n",
      "        -1.3672e+00, -5.0378e-01, -1.2273e+00, -3.2347e+00, -6.2197e-01,\n",
      "        -9.8808e-01, -5.6209e-01, -9.4263e-01, -1.7547e-01, -9.8799e-01,\n",
      "        -2.2107e+00, -1.4412e+00, -1.8306e+00, -8.8925e-01, -1.2606e-01,\n",
      "        -3.0591e+00, -1.0815e+00, -1.2431e+00, -3.6075e-01, -4.3962e-01,\n",
      "        -1.0768e+00, -1.4385e+00, -1.8480e+00, -9.9016e-01, -1.2462e+00,\n",
      "        -7.4725e-01, -1.7798e+00,  8.2775e-02, -5.1907e-01, -1.6862e+00,\n",
      "        -1.7868e+00, -8.4707e-01, -1.6235e+00, -1.6031e+00, -7.7357e-01,\n",
      "        -1.2001e+00, -2.0626e+00, -4.2313e-01, -4.6687e-01, -2.4213e+00,\n",
      "        -1.4857e-03, -1.4884e+00, -1.2672e+00, -1.8393e-01, -4.6564e-01,\n",
      "        -1.4474e+00,  4.1619e-02, -2.3775e+00, -6.2391e-01, -6.7046e-01,\n",
      "        -1.6553e+00, -8.6409e-01, -1.0584e+00, -9.5335e-01, -3.7046e-01,\n",
      "        -4.7987e-01, -1.7251e-01, -5.4132e-01, -7.4703e-01, -4.4006e-01,\n",
      "        -1.1935e+00, -3.3287e+00, -8.4885e-01, -5.1639e-02, -1.1524e+00,\n",
      "         1.3389e-01, -4.9827e-01, -5.4945e-01, -1.9685e+00, -2.1683e+00,\n",
      "        -7.5476e-02, -1.1813e+00, -1.9874e-01, -1.1033e+00, -1.1141e-01,\n",
      "        -4.0795e-01, -2.2374e-01, -9.5216e-02, -9.4514e-01, -1.4734e+00,\n",
      "        -2.5660e-01, -8.2981e-02, -1.0287e+00, -1.3826e+00, -2.4883e+00,\n",
      "        -1.8079e+00, -1.3558e+00, -2.7546e+00, -7.7556e-01, -1.5902e+00,\n",
      "        -1.0817e+00, -6.3845e-01, -7.3293e-01, -3.1280e-01, -1.9619e-01,\n",
      "        -4.7394e-01, -1.7763e-01, -1.4463e+00, -1.7051e+00, -8.2682e-01,\n",
      "        -1.8298e+00, -1.5229e-01, -1.0715e+00, -7.9166e-01, -6.0990e-01,\n",
      "        -5.8594e-01, -9.1192e-01, -1.3397e+00, -1.2685e+00, -8.2634e-01,\n",
      "        -9.9427e-01, -1.9151e+00, -1.0171e+00, -3.0660e+00, -3.8756e-01,\n",
      "        -1.4879e-01, -3.6566e-01, -1.3747e+00, -8.6607e-01, -3.3493e-01,\n",
      "        -9.8774e-01,  1.0531e-01, -1.5610e+00, -1.5754e-01, -2.8551e-01,\n",
      "         2.2704e-01, -1.7225e+00, -5.4955e-01, -6.8597e-01,  1.5522e-01,\n",
      "        -1.3517e+00, -4.0599e-01, -6.4091e-01, -5.2196e-02, -1.7427e+00,\n",
      "        -4.6653e-01, -4.3577e-01, -1.2154e+00, -6.2674e-01, -6.3076e-03,\n",
      "         3.1975e-01, -1.0691e+00, -4.9740e-01, -2.4898e+00, -6.4414e-01,\n",
      "        -7.8477e-01, -1.1583e-01, -1.1762e+00, -1.1470e+00, -2.3757e-02,\n",
      "        -1.2924e+00, -1.5478e+00,  4.4765e-02, -1.9970e-01, -1.3107e+00,\n",
      "        -1.2258e+00, -7.3877e-01, -1.1525e+00, -2.1822e+00, -5.2884e-01,\n",
      "        -1.5894e+00, -2.3100e+00, -7.6088e-01, -2.3805e-01, -1.2921e+00,\n",
      "        -8.4022e-01, -1.0978e+00, -6.6793e-01, -1.7889e+00, -2.1196e+00,\n",
      "        -8.4356e-02, -1.5841e+00, -1.6962e+00, -1.2740e+00, -2.9597e+00,\n",
      "        -1.8260e+00, -5.8835e-01, -1.3298e+00, -5.9087e-01, -2.0107e+00,\n",
      "        -1.5601e+00, -3.0603e-01, -1.3717e+00, -2.8022e-01, -4.4354e-01,\n",
      "        -7.0314e-01, -5.3654e-01, -2.7789e-01, -2.3240e+00,  2.8745e-02,\n",
      "        -2.4005e-01, -1.1095e+00, -2.7128e-01, -1.4048e+00, -2.8116e-01,\n",
      "        -1.2199e+00, -2.6724e-01, -9.1444e-01, -2.9976e-01, -1.9217e+00,\n",
      "        -4.5030e-01, -6.3202e-01, -7.7919e-01, -4.4213e-01, -1.2019e+00,\n",
      "        -7.4575e-01, -2.1967e+00, -2.2614e+00,  9.6306e-03, -3.7902e-02,\n",
      "        -1.0134e+00, -1.4097e+00, -1.5922e-01, -1.1983e+00, -4.1724e-01,\n",
      "        -1.5323e+00, -2.3850e-02, -1.0653e+00, -4.7701e-01, -4.2784e-01,\n",
      "        -1.3949e+00, -2.9924e+00, -2.5464e+00, -9.0089e-01, -1.1477e+00,\n",
      "        -6.5263e-01, -2.1008e+00, -7.1720e-01, -1.0975e+00,  7.2964e-02,\n",
      "        -4.0835e-01, -1.2584e+00, -2.1403e+00, -1.2712e+00, -9.8692e-02,\n",
      "        -8.9794e-01, -1.2758e+00, -1.1602e+00, -1.6314e+00, -1.6456e-01,\n",
      "         4.6968e-01, -1.1209e+00, -1.7803e+00, -4.8115e-02, -1.0938e+00,\n",
      "        -1.2607e+00, -1.1872e-01, -6.3391e-01, -6.1124e-01, -1.9822e+00,\n",
      "        -8.7391e-01, -9.2877e-01, -2.3695e-01, -1.3965e+00, -1.9421e+00,\n",
      "        -1.7959e+00, -9.3157e-01, -5.9955e-01, -2.3827e-01, -2.3536e-01,\n",
      "        -1.0886e+00, -1.4649e+00, -1.3841e+00, -1.4143e+00, -5.3978e-02,\n",
      "        -1.3978e+00, -1.2612e+00, -1.5179e+00, -5.9150e-03, -1.5527e+00,\n",
      "        -1.2600e+00, -2.7249e-01, -5.2465e-01, -6.0760e-01, -1.0974e+00,\n",
      "        -1.0014e-01, -1.2905e+00, -1.0538e+00, -9.6305e-01, -6.2622e-01,\n",
      "        -1.5467e+00, -1.7671e-01, -7.3629e-01, -1.1629e+00, -1.3807e+00,\n",
      "        -9.2231e-02, -6.7233e-01, -1.8645e+00, -2.6046e-01, -9.4076e-01,\n",
      "        -2.9273e-01, -1.0688e+00, -2.7211e-01, -3.4433e+00, -8.8624e-01,\n",
      "        -1.0630e+00, -2.3106e+00, -9.9056e-02, -4.2753e-01,  5.6523e-01,\n",
      "        -5.0736e-01, -1.5112e+00, -1.7859e+00, -5.2483e-01,  1.0791e-02,\n",
      "        -3.6080e-02, -2.0187e+00, -4.1996e-02, -1.5989e+00, -2.7973e-01,\n",
      "        -1.5747e+00, -2.5790e-01, -5.2909e-01, -1.4628e+00, -3.2651e-01,\n",
      "        -4.6882e-01, -3.8703e-01, -1.9253e+00, -9.4324e-01, -1.8390e-01,\n",
      "        -4.2842e-01, -7.0343e-01, -1.3098e+00, -3.4699e+00, -1.2724e+00,\n",
      "        -1.1469e+00, -2.4228e-01, -4.8402e-01, -2.8853e-01, -1.3308e+00,\n",
      "        -2.3316e-01, -4.5138e-01, -8.0058e-01, -2.0056e+00, -2.5127e-01,\n",
      "        -2.5431e-01, -3.0885e-01, -1.1446e+00, -1.4647e-01, -4.5720e-01,\n",
      "        -6.4891e-01,  3.9845e-01, -1.9468e-01, -9.4996e-01, -1.4871e+00,\n",
      "        -4.1965e-01, -1.6881e+00, -1.7860e+00, -6.9628e-01, -4.4072e-01,\n",
      "        -1.8560e+00, -1.0315e+00, -1.5195e+00, -1.1650e+00, -2.3398e-01,\n",
      "        -7.8188e-02, -1.1602e+00, -1.7359e+00, -2.2804e+00,  8.7735e-01,\n",
      "        -3.6423e-01, -1.7739e-02,  3.6656e-01, -1.4424e+00, -3.2779e-02,\n",
      "        -1.9376e+00, -2.8393e-01, -5.6582e-01, -4.3955e-01, -2.5328e+00,\n",
      "        -8.8012e-01, -1.1648e+00, -2.3607e-01, -5.6570e-01, -1.0688e+00,\n",
      "        -1.1875e+00, -1.4286e+00, -8.0114e-01, -1.2965e+00, -1.5771e+00,\n",
      "        -9.9452e-01, -2.3598e+00, -5.1964e-01, -2.7255e+00,  2.6671e-03,\n",
      "        -1.3320e+00, -4.2417e-01, -1.0637e+00, -2.3491e+00, -1.4230e+00,\n",
      "        -1.7627e+00, -1.3486e+00, -4.8527e-01, -1.9369e-01, -1.2152e+00,\n",
      "        -6.2417e-02, -5.1164e-01, -1.1292e+00, -1.2458e+00, -8.7795e-01,\n",
      "        -7.5304e-01, -7.5944e-01,  5.6755e-01, -9.6028e-01, -1.4728e+00,\n",
      "        -5.8538e-01, -1.6788e+00, -6.9845e-01, -9.3266e-01, -6.5579e-01,\n",
      "        -1.7920e+00, -9.0895e-01,  3.0945e-01, -2.7168e-01, -5.9755e-01,\n",
      "        -2.2443e+00, -1.1141e+00, -4.6099e-01, -3.6274e-02, -7.6314e-01,\n",
      "         1.8553e-02, -1.9304e+00, -7.2870e-01, -1.9747e+00, -4.4292e-01,\n",
      "        -9.2343e-01, -3.3395e-03, -1.1429e+00, -2.1291e+00, -1.5168e+00,\n",
      "        -8.4729e-01, -6.0047e-01, -3.0444e-01, -1.5352e+00, -2.2646e-01,\n",
      "        -1.7230e+00, -1.1182e+00, -6.9881e-01, -1.5165e+00, -9.3120e-01,\n",
      "        -6.9098e-02, -4.9865e-01, -1.3480e+00, -8.0821e-01, -3.9655e-01,\n",
      "        -1.2615e+00,  8.3449e-01, -1.6512e+00, -1.4509e+00, -6.5737e-01,\n",
      "        -1.9378e+00, -1.9424e+00, -9.7785e-01, -1.1991e+00, -1.0224e+00,\n",
      "        -2.1559e+00, -1.1678e+00, -7.0798e-01, -1.9945e-01, -7.6998e-01,\n",
      "        -7.5250e-02, -1.0014e+00, -5.7472e-01, -8.8930e-01, -1.2461e+00,\n",
      "        -5.8803e-01, -3.1525e+00, -8.4729e-01, -1.1361e+00, -8.5212e-01,\n",
      "        -1.1485e+00, -6.1075e-01, -1.0488e+00, -2.1412e-01, -8.2379e-01,\n",
      "        -5.3502e-01, -1.7209e-01, -3.2914e-01, -1.0642e+00, -3.0749e-01,\n",
      "        -6.5280e-01, -9.9863e-01, -2.9166e-01, -1.2416e+00, -2.1290e+00,\n",
      "        -9.2564e-01, -2.0363e+00, -2.9682e+00, -2.7446e-01,  1.1726e-01,\n",
      "        -8.7535e-01,  2.4921e-02, -2.3846e+00, -3.3351e-01, -1.6948e+00,\n",
      "        -5.9855e-01, -5.7278e-01, -1.5784e+00, -9.8018e-01, -1.5318e+00,\n",
      "        -8.5741e-01, -5.9616e-01, -1.4447e+00, -1.4074e+00, -1.4446e+00,\n",
      "        -2.9771e-01, -8.2550e-01, -1.2309e-01, -5.5956e-01, -1.3540e+00,\n",
      "        -4.0868e-01, -1.3784e+00, -6.0108e-01,  2.1467e-01, -8.2196e-01,\n",
      "        -1.9599e+00, -8.0936e-01, -1.6898e+00, -1.0703e+00, -3.2152e+00,\n",
      "        -1.6913e+00, -1.5763e+00,  3.2304e-02, -1.6006e+00,  3.1557e-01,\n",
      "        -1.7577e-01, -1.6303e-01, -1.3270e+00, -3.2414e-01, -1.2635e+00,\n",
      "        -1.8482e+00, -9.3913e-01, -1.6533e+00, -1.6285e+00, -7.8455e-01,\n",
      "        -1.0433e+00, -1.0655e+00, -3.8779e-01, -1.1780e+00, -7.0809e-01,\n",
      "        -4.5717e-01, -1.1738e+00, -1.0653e+00, -2.1622e+00, -7.6136e-01,\n",
      "         5.0721e-01, -8.7515e-02, -3.7586e-01,  7.9405e-02, -1.8184e-01,\n",
      "        -7.0823e-01, -1.2260e+00, -1.1906e+00, -7.5801e-02, -5.7188e-01,\n",
      "        -1.4958e+00, -3.2253e-01, -1.1901e+00, -3.0864e+00, -9.1333e-02,\n",
      "        -7.2889e-01, -1.6154e+00, -1.6949e+00, -2.2200e+00, -1.7209e-01,\n",
      "        -7.2908e-01, -8.4490e-01, -1.2957e+00, -1.8604e+00, -6.8993e-01,\n",
      "        -5.0571e-01, -1.2361e+00, -1.0612e+00, -2.6325e-01, -7.4679e-01,\n",
      "        -6.8918e-01, -1.8470e+00,  6.8953e-01, -1.3369e+00, -5.2187e-01,\n",
      "        -6.6693e-01,  1.4003e-01, -8.0223e-01, -2.5777e+00, -1.6052e-01,\n",
      "        -1.0099e+00, -6.6977e-01, -1.4370e+00, -3.7787e-01, -7.0997e-01,\n",
      "        -1.1662e+00, -9.0811e-01, -1.4938e+00, -3.1039e+00, -1.8311e-01,\n",
      "         1.6556e-03, -4.1595e-01, -2.5201e+00, -1.5501e+00, -2.9357e-01,\n",
      "         2.6558e-01, -1.1724e-01, -1.1074e+00, -6.8761e-01, -6.5525e-02,\n",
      "        -6.4548e-01, -1.3926e+00, -3.4547e+00, -8.4228e-01, -1.6412e+00,\n",
      "        -9.7753e-01, -2.5235e-01, -4.8748e-01, -1.8427e+00, -1.5088e+00,\n",
      "        -2.0424e+00, -4.6704e-01, -1.8790e+00, -1.4369e+00, -9.4752e-01,\n",
      "        -1.0149e-01, -8.8593e-01, -1.8482e+00, -2.9070e-01, -2.3847e+00,\n",
      "        -6.7807e-01, -1.2215e+00, -7.2862e-01,  1.6100e-01, -1.5955e+00,\n",
      "        -1.3037e+00, -1.4869e+00, -4.7696e-02, -1.3574e+00, -2.2141e-01,\n",
      "        -2.4098e+00, -5.8904e-01, -6.7090e-01, -2.5560e+00, -7.9932e-01,\n",
      "        -1.9735e+00, -2.8866e+00, -1.4017e+00, -2.9516e+00, -4.6717e-01,\n",
      "        -1.1637e+00, -1.3750e+00, -1.0754e+00, -4.3286e-01, -2.1004e+00,\n",
      "        -9.6244e-01, -6.9484e-02, -1.3282e+00, -1.1508e+00, -7.4441e-01,\n",
      "        -1.7431e+00, -1.1951e-01, -4.8880e-01, -5.7371e-01, -1.4086e+00,\n",
      "        -5.8562e-01,  3.7414e-01, -1.5400e+00, -1.6140e+00, -1.5847e+00,\n",
      "        -2.4395e+00, -2.6219e-01, -6.1266e-01, -9.0976e-01, -1.2404e+00,\n",
      "        -9.0553e-01, -1.0130e+00, -7.1470e-01, -8.5318e-01, -5.8587e-01,\n",
      "        -1.4078e+00, -7.8208e-01, -1.0847e+00, -6.7906e-01,  4.2640e-01,\n",
      "        -1.6789e+00, -9.4664e-01, -1.0593e+00, -6.7874e-01, -1.3322e+00,\n",
      "        -5.9795e-01, -9.6107e-01,  4.6775e-01, -1.4923e+00, -1.0552e-01,\n",
      "        -1.0267e+00, -1.6899e+00, -1.7489e-01, -1.2238e+00, -4.3035e-01,\n",
      "        -1.8697e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0919]],\n",
      "\n",
      "         [[ 0.2716]],\n",
      "\n",
      "         [[-0.1332]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0289]],\n",
      "\n",
      "         [[-0.0972]],\n",
      "\n",
      "         [[ 0.0085]]],\n",
      "\n",
      "\n",
      "        [[[-0.0399]],\n",
      "\n",
      "         [[ 0.3414]],\n",
      "\n",
      "         [[ 0.0895]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0547]],\n",
      "\n",
      "         [[ 0.5079]],\n",
      "\n",
      "         [[-0.1816]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3159]],\n",
      "\n",
      "         [[-0.3622]],\n",
      "\n",
      "         [[ 0.0464]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3790]],\n",
      "\n",
      "         [[ 0.3769]],\n",
      "\n",
      "         [[-0.1994]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1633]],\n",
      "\n",
      "         [[-0.3105]],\n",
      "\n",
      "         [[-0.4168]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4500]],\n",
      "\n",
      "         [[-0.2468]],\n",
      "\n",
      "         [[-0.0993]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0375]],\n",
      "\n",
      "         [[ 0.1224]],\n",
      "\n",
      "         [[-0.2739]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0542]],\n",
      "\n",
      "         [[-0.1161]],\n",
      "\n",
      "         [[ 0.0097]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0119]],\n",
      "\n",
      "         [[-0.1364]],\n",
      "\n",
      "         [[ 0.2682]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2009]],\n",
      "\n",
      "         [[-0.0009]],\n",
      "\n",
      "         [[ 0.1108]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.3053, -0.3757,  0.1648,  0.0308, -0.0650,  0.0541,  0.1402, -0.0970,\n",
      "        -0.1116, -0.2896, -0.0480,  0.2025,  0.0804,  0.2496,  0.0895, -0.2075,\n",
      "         0.0672, -0.2308,  0.2335,  0.1514, -0.1921,  0.1439,  0.0088,  0.1470,\n",
      "         0.1322,  0.2037, -0.0329, -0.0227, -0.0399,  0.1445,  0.1691, -0.1322,\n",
      "        -0.2259,  0.0751], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-1.0383e-01]],\n",
      "\n",
      "         [[-4.5564e-01]],\n",
      "\n",
      "         [[ 2.1727e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2120e-01]],\n",
      "\n",
      "         [[ 9.2426e-02]],\n",
      "\n",
      "         [[ 4.4480e-04]]],\n",
      "\n",
      "\n",
      "        [[[-2.2665e-02]],\n",
      "\n",
      "         [[-2.2104e-01]],\n",
      "\n",
      "         [[ 5.3010e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3929e-01]],\n",
      "\n",
      "         [[ 2.2157e-02]],\n",
      "\n",
      "         [[ 3.4301e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0789e-01]],\n",
      "\n",
      "         [[ 2.4929e-01]],\n",
      "\n",
      "         [[ 1.9469e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7444e-01]],\n",
      "\n",
      "         [[-2.5780e-03]],\n",
      "\n",
      "         [[ 2.1343e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.3139e-02]],\n",
      "\n",
      "         [[-7.2176e-02]],\n",
      "\n",
      "         [[-4.5745e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.0102e-01]],\n",
      "\n",
      "         [[-6.5322e-02]],\n",
      "\n",
      "         [[-6.3872e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3230e-02]],\n",
      "\n",
      "         [[-1.5450e-01]],\n",
      "\n",
      "         [[-1.1535e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.3733e-01]],\n",
      "\n",
      "         [[-9.7046e-02]],\n",
      "\n",
      "         [[-9.8283e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.2187e-02]],\n",
      "\n",
      "         [[ 1.1595e-01]],\n",
      "\n",
      "         [[ 1.4579e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4244e-02]],\n",
      "\n",
      "         [[-2.3442e-02]],\n",
      "\n",
      "         [[ 1.7701e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.8289e-01, -5.7771e-02,  2.7193e-01,  9.6816e-02,  1.0379e-01,\n",
      "         8.2807e-03, -1.5583e-01, -3.2799e-01, -3.2221e-01, -3.3502e-01,\n",
      "         5.7655e-01,  2.5508e-01, -5.1632e-03,  2.7777e-01, -6.4354e-02,\n",
      "        -3.3891e-01, -4.9898e-01,  5.1492e-01,  3.9198e-01,  4.2431e-02,\n",
      "         1.1780e-01,  5.1502e-01, -2.6128e-01, -1.0177e-01, -1.3202e-01,\n",
      "        -1.7782e-01, -1.8694e-01,  2.3623e-01,  3.8864e-01,  2.5054e-01,\n",
      "        -9.4963e-02,  5.1484e-02, -1.9862e-01,  9.5990e-02,  7.2204e-02,\n",
      "        -3.9513e-01,  1.2119e-01,  2.1330e-01, -3.5067e-01,  4.1000e-01,\n",
      "        -5.3567e-01, -1.9596e-01,  3.9701e-01,  3.5659e-01, -1.6158e-01,\n",
      "         6.7885e-02, -5.1833e-01, -1.0875e-01,  1.3612e-02, -2.1398e-01,\n",
      "         5.0859e-03, -5.1973e-01,  4.3366e-01,  4.2263e-01, -4.9676e-02,\n",
      "         3.0729e-01, -3.7256e-01,  5.2915e-02, -1.3660e-01, -2.4893e-01,\n",
      "         2.9377e-01,  1.3919e-01, -1.8548e-01,  2.6150e-01, -4.7844e-01,\n",
      "         2.8091e-01,  2.6478e-02,  2.7773e-01, -2.8584e-01,  8.6726e-02,\n",
      "         7.9996e-02, -3.4810e-01, -3.7539e-02, -4.6259e-01, -2.0895e-01,\n",
      "         7.6542e-02, -9.3712e-02,  2.8643e-01, -5.3699e-03, -3.7509e-01,\n",
      "         1.2696e-01, -7.3223e-03, -2.2471e-01,  1.5258e-02,  4.6794e-01,\n",
      "         2.5519e-01,  3.8484e-02, -7.0965e-02,  4.5033e-01,  2.8923e-02,\n",
      "         6.7659e-02,  4.9123e-02,  3.3611e-03,  3.9905e-01, -3.4106e-01,\n",
      "         2.7071e-01, -2.5946e-01, -3.2004e-02,  3.9619e-01, -2.9893e-02,\n",
      "        -1.2833e-01,  4.9846e-02, -1.6541e-01,  1.9017e-01,  3.6054e-01,\n",
      "        -1.5402e-01,  3.1055e-02,  4.3023e-01,  2.3724e-01, -9.2285e-02,\n",
      "        -3.9039e-01, -1.7260e-01,  1.1798e-01, -1.2456e-02, -4.3475e-01,\n",
      "         1.7636e-01,  6.6749e-02,  1.2765e-01,  4.5314e-01,  2.5932e-01,\n",
      "        -5.0352e-02,  1.3572e-01, -3.7718e-02, -6.1428e-01, -4.4156e-01,\n",
      "        -1.5084e-02, -1.5360e-01, -2.0878e-01, -2.8826e-01,  7.3130e-02,\n",
      "        -1.1157e-01,  3.7083e-01, -1.2155e-01, -9.1921e-02, -9.3972e-02,\n",
      "        -3.7096e-01, -8.3350e-02, -3.1514e-01, -4.2684e-01,  3.0705e-01,\n",
      "        -1.3703e-01,  4.2565e-01,  1.4569e-01,  6.8561e-02, -3.7618e-01,\n",
      "        -6.6777e-02,  5.9373e-02,  6.5915e-02, -4.2687e-02, -2.4931e-01,\n",
      "        -7.9846e-02,  5.0664e-02,  3.0086e-01, -4.4764e-02, -8.3345e-03,\n",
      "         1.5470e-02, -7.1815e-02,  2.4393e-01, -5.1889e-01,  3.3865e-01,\n",
      "         3.8997e-01,  2.9829e-01,  2.8101e-01,  5.6612e-01, -2.0725e-01,\n",
      "        -5.2584e-01,  2.2223e-01, -3.6498e-01,  2.7028e-01, -9.1037e-02,\n",
      "         1.2826e-01,  2.7580e-01, -2.0157e-01,  1.8281e-01,  2.2991e-01,\n",
      "        -3.6287e-02, -8.8850e-03,  2.7394e-01, -2.7652e-01, -6.4957e-02,\n",
      "         2.4823e-02,  4.2804e-01,  1.1571e-01,  4.5873e-01,  4.6853e-02,\n",
      "        -2.1967e-01, -1.3367e-01,  3.0138e-02,  4.3678e-01,  5.5948e-01,\n",
      "        -2.1359e-01, -2.2517e-03,  6.3435e-01, -1.9010e-01,  4.2958e-01,\n",
      "         7.4482e-02,  1.8909e-01,  2.6345e-02, -3.9072e-01,  3.3673e-01,\n",
      "         4.6952e-01, -3.6434e-01, -1.2606e-01,  5.0788e-01,  2.3945e-01,\n",
      "         2.4074e-01,  3.8029e-01,  4.2738e-01,  2.7055e-01,  4.2019e-01,\n",
      "         1.5881e-02, -2.1557e-01,  3.3119e-01, -5.8224e-01, -3.5919e-01,\n",
      "         1.3171e-01,  3.8750e-01, -4.0746e-01,  6.4806e-02, -4.2203e-01,\n",
      "         2.6350e-01, -4.1253e-01,  4.9793e-01,  1.6145e-01, -4.0091e-01,\n",
      "        -4.2604e-01, -8.0659e-02,  1.2310e-01,  4.0107e-01,  3.6177e-01,\n",
      "        -3.2012e-01, -2.4907e-01, -2.2465e-02,  6.2491e-01,  3.0046e-01,\n",
      "        -3.1131e-01,  2.1860e-01,  5.0734e-01,  2.4941e-01,  4.1012e-01,\n",
      "         2.1129e-01,  1.1912e-01,  1.6840e-01, -1.2719e-01,  9.6522e-02,\n",
      "         4.4272e-01,  1.7206e-01,  3.6359e-01,  1.5251e-01,  1.7348e-01,\n",
      "         1.5015e-01, -2.6471e-01, -1.6420e-02, -2.9488e-01, -4.9875e-01,\n",
      "         9.8318e-02,  8.7170e-02,  2.3179e-01, -1.0583e-01, -2.5479e-01,\n",
      "         4.1058e-01, -2.2568e-02, -1.7814e-01,  3.2629e-01, -5.9556e-02,\n",
      "         1.9456e-01, -1.3903e-01,  8.6542e-02,  3.1729e-01,  2.6659e-01,\n",
      "         2.0990e-01, -4.6897e-01, -5.7744e-02,  1.0951e-01, -1.0698e-01,\n",
      "        -3.1921e-01, -2.9046e-01,  1.9988e-01,  7.7403e-02,  1.9375e-01,\n",
      "         1.2658e-01,  1.5488e-01,  3.1901e-01, -2.5838e-01,  6.5886e-03,\n",
      "        -1.0568e-01,  5.1382e-01, -3.9246e-01,  1.2137e-01,  9.7022e-03,\n",
      "         3.1145e-01, -3.3965e-01, -2.8479e-02, -6.8492e-01,  3.7173e-01,\n",
      "        -6.6011e-02, -3.4362e-01,  4.9642e-01,  1.3185e-01,  4.7206e-01,\n",
      "         4.2110e-01, -1.6140e-01,  1.0509e-01, -2.3430e-01,  1.8812e-01,\n",
      "        -1.3243e-01,  4.0671e-01, -1.3983e-01,  1.5618e-01,  2.4329e-01,\n",
      "        -6.7315e-02,  4.8227e-01, -5.6917e-02, -1.5636e-01,  1.3451e-01,\n",
      "        -3.2960e-02, -1.4838e-02, -7.5565e-02, -2.2637e-01,  2.2297e-01,\n",
      "         4.9054e-01, -8.5554e-02,  3.0836e-01,  1.5118e-02,  4.0970e-01,\n",
      "         2.7966e-01,  3.3737e-01,  1.6809e-01, -1.2841e-01, -2.2585e-01,\n",
      "        -8.7640e-02,  1.4668e-01, -2.9314e-02, -1.0467e-03, -2.0184e-01,\n",
      "        -9.8951e-02, -2.5120e-01, -3.4384e-01,  4.2696e-01, -6.4006e-02,\n",
      "         3.4083e-01, -1.6103e-01, -1.9959e-01, -2.3141e-01, -1.4527e-01,\n",
      "         1.5539e-01, -5.6940e-02, -1.7894e-01, -6.1994e-02, -1.3141e-02,\n",
      "         2.2502e-01,  3.3147e-01, -2.0977e-01,  3.0106e-02,  1.0356e-02,\n",
      "        -4.2884e-01,  7.0751e-02,  3.8956e-01,  2.3763e-01, -3.3265e-02,\n",
      "        -4.9781e-01, -3.5664e-02, -1.1766e-01,  2.5949e-01,  2.6894e-01,\n",
      "         3.6305e-02, -3.1015e-01,  8.0015e-02,  2.0677e-01, -4.1962e-01,\n",
      "        -2.5006e-01,  2.1552e-01, -4.4609e-01,  4.0500e-01, -8.3237e-02,\n",
      "         2.2177e-01,  1.3118e-02,  1.0518e-01,  4.0855e-01,  3.0032e-01,\n",
      "         4.7019e-01,  2.6249e-01, -1.7521e-01, -3.1493e-01,  1.6153e-02,\n",
      "        -2.9571e-02,  4.3388e-01,  1.2226e-01, -3.7020e-01,  2.2774e-01,\n",
      "        -3.4235e-01, -2.7331e-01,  3.4065e-01, -4.4299e-01,  2.3732e-01,\n",
      "        -3.4436e-01,  2.0753e-01,  5.4147e-01,  1.0712e-01,  3.3358e-01,\n",
      "         5.0207e-02, -2.7302e-01,  4.0978e-02,  2.7840e-01,  4.4018e-01,\n",
      "        -3.6067e-01,  4.0979e-01,  2.7366e-01, -7.1847e-02,  2.8692e-01,\n",
      "        -1.4175e-01,  2.2175e-02, -2.5553e-01, -2.6789e-01,  6.8296e-02,\n",
      "         2.7383e-01,  2.0261e-01,  2.8196e-01, -2.3843e-01, -3.8626e-01,\n",
      "        -3.3356e-01, -2.0694e-01,  1.4416e-01, -2.7250e-01,  3.5025e-01,\n",
      "         2.8170e-01,  4.4005e-01, -4.8621e-01,  1.8150e-01,  5.8978e-02,\n",
      "         6.6832e-03,  3.4332e-01,  5.7634e-01,  3.0343e-01, -3.7258e-01,\n",
      "         1.1720e-01, -1.8868e-01,  2.0368e-02,  1.6598e-01, -1.5157e-01,\n",
      "         3.2114e-01, -3.4474e-01,  3.4103e-01,  8.2075e-03,  1.3847e-01,\n",
      "        -1.5791e-01, -1.9415e-01,  2.1468e-01, -5.5529e-01, -5.0053e-01,\n",
      "        -6.1879e-02,  9.8644e-02, -1.0942e-01, -1.0137e-02,  2.0130e-01,\n",
      "         3.6554e-01,  2.0158e-01, -2.2620e-01, -4.2957e-01,  2.4562e-01,\n",
      "        -8.1207e-02,  3.7797e-01, -9.3017e-02,  2.7782e-01,  2.8951e-02,\n",
      "        -2.5687e-02, -1.1328e-01, -2.4976e-01, -1.5896e-01, -4.7075e-01,\n",
      "         1.4182e-01,  4.7826e-01, -2.6317e-01,  2.0064e-01, -3.5166e-01,\n",
      "         4.3632e-01,  2.1570e-01,  3.3283e-01,  3.4937e-02, -2.7169e-01,\n",
      "         3.2606e-02, -7.0733e-02,  1.9908e-01,  2.9350e-01,  1.4452e-01,\n",
      "         4.3449e-01,  1.3520e-01,  7.3661e-02, -1.8367e-02,  4.1886e-01,\n",
      "        -5.0140e-01, -4.3984e-01, -1.1064e-01,  3.7955e-01,  3.5853e-01,\n",
      "        -4.0649e-01, -2.2647e-01, -1.5156e-01,  2.2289e-02,  4.0012e-01,\n",
      "         1.7280e-01,  4.1295e-01, -1.2038e-01,  6.3227e-02,  5.7816e-05,\n",
      "         2.3888e-01, -1.2156e-01, -3.3092e-01,  9.0526e-02,  9.4753e-02,\n",
      "         3.8225e-01,  1.9529e-01,  2.6185e-02, -2.3207e-01,  1.6001e-01,\n",
      "         2.6649e-02,  1.7138e-01,  9.5004e-02, -8.2621e-02,  2.7613e-01,\n",
      "        -1.1102e-01, -3.3679e-01, -1.1072e-01, -8.2829e-02,  4.3255e-01,\n",
      "         2.2995e-01,  2.3775e-01, -1.8385e-01,  2.4244e-01, -4.3640e-01,\n",
      "        -1.8749e-01,  8.5933e-02, -4.0633e-01,  4.1458e-02, -1.9474e-01,\n",
      "         2.2213e-01, -2.5162e-01, -2.2837e-01,  5.4061e-01, -1.3816e-01,\n",
      "         7.6059e-01,  1.8411e-01, -3.3886e-01, -3.2154e-01,  1.8745e-01,\n",
      "        -2.2029e-01, -2.9142e-01,  3.3112e-01,  4.9693e-02,  3.6702e-01,\n",
      "        -1.7269e-01,  4.8157e-01,  2.8739e-02,  2.8721e-01, -3.5016e-01,\n",
      "        -2.7315e-01, -8.2836e-02, -1.3499e-01,  1.2323e-02,  9.6683e-02,\n",
      "         4.4717e-01, -1.5390e-01, -1.9778e-01, -3.2777e-01,  2.6941e-01,\n",
      "         4.2700e-01,  2.6706e-01, -3.4515e-01,  3.7345e-01, -4.8019e-02,\n",
      "        -1.2421e-01, -1.1131e-01,  1.6914e-01,  3.1408e-01,  1.5609e-01,\n",
      "         4.5134e-01,  4.2055e-01,  2.6888e-01, -9.5793e-02,  2.9029e-01,\n",
      "        -3.1838e-01,  2.1990e-02,  5.4629e-01,  1.3811e-01,  6.1184e-02,\n",
      "        -1.6433e-02,  5.0622e-01, -1.3334e-01, -9.1878e-02, -1.1919e-01,\n",
      "         1.9124e-01,  3.7895e-01, -1.2633e-01, -2.6235e-01, -2.5664e-01,\n",
      "         3.7069e-01, -1.1213e-01, -1.8323e-01, -3.2973e-01,  3.5341e-01,\n",
      "         2.2805e-01, -2.0738e-02,  4.9057e-01, -3.4625e-01, -4.2224e-04,\n",
      "         1.9094e-02, -3.6552e-01, -3.2178e-01,  8.6078e-02,  5.8320e-02,\n",
      "         2.5984e-01,  2.1359e-01, -4.0204e-01, -4.4820e-01,  3.3706e-01,\n",
      "         1.9027e-01, -2.2395e-01, -1.3223e-01, -9.7745e-02, -2.6110e-01,\n",
      "        -8.3143e-02,  4.1143e-01,  3.8466e-01, -5.7760e-01,  1.1689e-01,\n",
      "        -7.4986e-02, -3.6955e-01,  5.4952e-01,  1.4560e-02, -2.8468e-01,\n",
      "         3.5127e-01,  3.4384e-01,  2.1695e-02,  2.6997e-01, -3.8378e-01,\n",
      "        -4.9500e-01,  5.8518e-01, -1.8322e-01,  8.3058e-02,  5.4727e-01,\n",
      "        -3.9106e-01,  3.1606e-01,  1.4678e-02,  5.6385e-01,  2.3000e-01,\n",
      "        -3.4450e-01,  2.2522e-02, -4.3014e-01,  2.2928e-01,  2.0113e-01,\n",
      "        -1.3969e-03,  2.3527e-01, -2.1964e-01, -3.5298e-02, -3.4549e-02,\n",
      "         2.9510e-01,  1.2698e-01, -1.2919e-01,  4.9664e-01,  3.6968e-01,\n",
      "         1.2011e-01, -5.2560e-02,  1.1739e-01,  3.1325e-01,  1.1892e-01,\n",
      "        -4.6028e-01, -3.4985e-01, -2.1648e-01, -3.6191e-02, -2.3579e-01,\n",
      "        -9.0569e-02, -2.4528e-01, -3.4029e-01, -2.1911e-01,  1.9956e-02,\n",
      "         4.7808e-01, -2.0470e-01, -2.3683e-01, -2.0524e-01,  2.9245e-01,\n",
      "         3.9947e-01,  2.5496e-01, -6.6777e-02,  3.6934e-01, -3.6176e-01,\n",
      "        -1.1350e-01, -1.0215e-01, -3.8909e-01,  2.3447e-01,  6.6311e-01,\n",
      "        -6.7325e-02, -1.1076e-01,  4.6982e-02,  1.6575e-01, -4.8345e-01,\n",
      "         2.7012e-01, -2.5432e-01, -2.7557e-01, -4.2643e-01,  4.5870e-01,\n",
      "        -2.0560e-01,  3.3868e-01, -2.9559e-02,  3.9321e-01, -3.3707e-01,\n",
      "         4.0934e-01,  1.3470e-01,  4.8754e-02,  5.8645e-01,  3.1639e-01,\n",
      "         3.7071e-01, -1.5021e-01,  5.0455e-01, -2.3438e-01,  1.8641e-01,\n",
      "        -3.9153e-01,  2.6356e-01,  4.4861e-01, -1.4539e-01, -2.6488e-01,\n",
      "         7.9297e-02,  4.8064e-02,  2.7212e-02, -1.0176e-01, -8.3206e-02,\n",
      "         2.5697e-01, -2.1256e-01, -5.1861e-01, -3.2923e-01, -1.5476e-01,\n",
      "         3.9668e-01, -2.6815e-01,  2.0393e-01,  3.3587e-01,  3.3533e-02,\n",
      "         1.4513e-01, -2.5759e-01,  3.7004e-01,  3.5491e-01,  1.8905e-02,\n",
      "        -3.9232e-01,  1.8951e-02,  2.1218e-01,  5.5796e-01,  2.7465e-01,\n",
      "        -1.9817e-01,  2.5977e-01,  5.6558e-02, -3.6650e-02,  4.7937e-01,\n",
      "        -2.1998e-01,  2.0246e-01,  2.2722e-02,  9.3230e-02, -7.5349e-02,\n",
      "         4.0285e-01, -1.8543e-01, -3.3543e-01,  1.1659e-01,  1.0437e-01,\n",
      "         2.0014e-01,  1.7774e-02, -5.1723e-02,  3.7185e-03,  3.1883e-01,\n",
      "        -1.4114e-01, -1.6249e-01, -4.2142e-01,  7.2432e-02, -1.1235e-01,\n",
      "        -3.2782e-01, -5.4524e-02, -5.9204e-02,  3.5304e-01, -9.8307e-03,\n",
      "         1.7800e-01,  2.1246e-01, -2.7179e-01,  3.7481e-02, -1.1751e-02,\n",
      "        -7.1199e-02, -3.6654e-02,  8.8718e-02, -3.6854e-01,  4.7021e-01,\n",
      "        -7.2541e-02,  5.0839e-02,  5.4254e-01, -9.2136e-02,  2.1315e-01,\n",
      "        -1.0549e-02,  2.2224e-01, -2.3355e-01, -4.1474e-02, -2.2273e-01,\n",
      "         4.5175e-01,  2.6537e-01, -5.7819e-01,  3.0430e-01,  8.9186e-02,\n",
      "         1.6370e-01,  4.7333e-01,  2.9036e-01,  3.8700e-01,  3.2386e-01,\n",
      "         9.9474e-02, -4.9312e-01,  4.0588e-01, -2.6264e-01,  1.5591e-01,\n",
      "        -3.0124e-01,  4.1960e-01,  3.2548e-02, -1.7284e-01, -4.4774e-02,\n",
      "         1.3011e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.7333]],\n",
      "\n",
      "         [[-0.2719]],\n",
      "\n",
      "         [[ 0.2883]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0973]],\n",
      "\n",
      "         [[ 0.2691]],\n",
      "\n",
      "         [[ 0.0879]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0641]],\n",
      "\n",
      "         [[-0.1312]],\n",
      "\n",
      "         [[-0.4298]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2369]],\n",
      "\n",
      "         [[ 0.2811]],\n",
      "\n",
      "         [[ 0.4881]]],\n",
      "\n",
      "\n",
      "        [[[-0.7473]],\n",
      "\n",
      "         [[ 0.1291]],\n",
      "\n",
      "         [[-0.1183]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4793]],\n",
      "\n",
      "         [[-0.3217]],\n",
      "\n",
      "         [[ 0.2563]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1347]],\n",
      "\n",
      "         [[-0.4255]],\n",
      "\n",
      "         [[ 0.6219]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0153]],\n",
      "\n",
      "         [[-0.0095]],\n",
      "\n",
      "         [[-0.2998]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5821]],\n",
      "\n",
      "         [[-0.4935]],\n",
      "\n",
      "         [[ 0.7307]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4096]],\n",
      "\n",
      "         [[-0.5013]],\n",
      "\n",
      "         [[ 0.0271]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0124]],\n",
      "\n",
      "         [[-0.6349]],\n",
      "\n",
      "         [[-0.7070]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2509]],\n",
      "\n",
      "         [[ 0.4752]],\n",
      "\n",
      "         [[-0.1553]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.7766,  0.5201,  0.8792,  1.4344,  0.3113,  0.4334,  1.1278,  3.1432,\n",
      "         0.7740,  0.4368,  0.1501,  0.6894,  1.3641,  0.3327,  1.2075,  2.2694,\n",
      "         0.2539,  0.7094,  0.7370,  0.3310,  1.0184,  0.9006,  0.8511,  1.4840,\n",
      "         1.3076,  1.0801,  0.0394,  0.0134,  0.3972,  0.0284,  0.4338,  0.0826,\n",
      "         1.1421,  0.7959,  1.7706,  0.3474,  0.0624,  1.1181,  0.5493,  0.3776,\n",
      "         1.0148,  0.9958,  0.1551,  0.6349,  0.2714,  1.5088,  0.9645,  1.7643,\n",
      "         1.0590,  1.2549,  4.1451,  0.4906,  1.0411,  0.1061,  0.8646,  0.6829,\n",
      "         0.5579,  0.1069,  2.1336,  0.3246,  1.0400, -0.0166,  0.5553,  1.6089,\n",
      "         0.1142,  0.2979,  0.7339,  0.3026,  1.0315,  0.0642,  1.3080,  1.7418,\n",
      "         2.1425,  0.2181,  1.7174,  0.1962,  1.3069,  2.4683,  0.5393,  0.3428,\n",
      "         0.7355,  0.0617,  1.0703,  0.5863,  0.1234,  0.1169,  0.6631,  0.7207,\n",
      "         1.1440,  0.1579,  1.1825,  1.7911,  1.3741,  1.3165,  0.4658,  1.2791,\n",
      "         0.0690,  0.1424,  0.7511,  0.4528,  1.9176,  0.1114,  0.0087,  0.6700,\n",
      "         1.0105,  0.3715,  1.1110,  1.3054,  0.6241,  0.3697,  2.1377,  1.1877,\n",
      "         0.5420,  1.2071,  0.4873,  1.7364,  0.8927,  1.6649,  0.6304,  0.6529,\n",
      "         1.1962,  0.5439,  0.6709,  1.2657,  1.1056,  1.1759,  1.2570,  0.0373,\n",
      "         0.7744,  0.6407,  0.8376,  0.8997,  0.1715,  1.6171,  2.5406,  0.9738],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1287, -0.3199, -0.0985,  0.2231,  0.4156, -0.0765,  0.2483, -1.4478,\n",
      "        -0.2810,  0.3295,  0.3136, -0.0480, -0.2921,  0.1498,  0.2845,  1.3533,\n",
      "         0.2345, -0.0172, -0.2383,  0.2313, -0.3938,  0.0462, -0.3632,  0.2393,\n",
      "         0.0948,  1.2144,  0.1161, -0.2318,  0.4696, -0.3764,  0.1600, -0.2585,\n",
      "         0.2071, -0.0617,  0.1763, -0.3035,  0.2209, -0.0069, -0.3447, -0.0664,\n",
      "         0.2112, -0.4429, -0.1338,  0.6086, -0.5489,  0.4074,  0.4862,  0.5535,\n",
      "        -0.1618, -0.1135, -0.3984,  0.0053,  0.5186, -0.0763, -0.2019,  0.0818,\n",
      "         0.0234, -0.3618, -0.5945,  0.4928,  0.1530, -0.3086, -0.0472, -0.5614,\n",
      "         0.2289,  0.4299, -0.1392,  0.1254,  0.2175, -0.3990, -0.8002,  0.2340,\n",
      "         1.3436,  0.1973,  0.2528, -0.3828, -0.1848,  0.0948, -0.0854, -0.0396,\n",
      "        -0.1138, -0.1038, -0.2105,  0.3372, -0.3433, -0.2733,  0.1743, -0.1495,\n",
      "         0.3739,  0.6076,  0.3306, -0.0200,  0.1293,  0.3521, -0.1306, -0.3141,\n",
      "        -0.3827,  0.1444,  0.0617,  0.2225,  0.8854,  0.0580,  0.2436, -0.3292,\n",
      "         0.3803,  0.0475, -0.4749,  0.2586,  0.0469,  0.1196,  0.4206, -0.1365,\n",
      "         0.0790, -0.0238,  0.1272,  0.1200, -0.3230, -0.6272,  0.0863, -0.0719,\n",
      "         0.0070,  0.5471,  0.2933,  0.1003, -0.4571,  0.2268, -0.0683,  0.0350,\n",
      "        -0.1539,  0.2012, -0.2896, -0.5525, -0.0059,  0.9803,  0.6851,  0.3549],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2502]],\n",
      "\n",
      "         [[-1.0481]],\n",
      "\n",
      "         [[ 0.1011]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4290]],\n",
      "\n",
      "         [[-0.5159]],\n",
      "\n",
      "         [[ 0.2812]]],\n",
      "\n",
      "\n",
      "        [[[-0.0322]],\n",
      "\n",
      "         [[-0.4218]],\n",
      "\n",
      "         [[-0.2219]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5504]],\n",
      "\n",
      "         [[-0.0342]],\n",
      "\n",
      "         [[ 0.0839]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0118]],\n",
      "\n",
      "         [[-0.2326]],\n",
      "\n",
      "         [[ 0.0626]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6066]],\n",
      "\n",
      "         [[-0.2165]],\n",
      "\n",
      "         [[ 0.4248]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3342]],\n",
      "\n",
      "         [[-0.2679]],\n",
      "\n",
      "         [[-0.4804]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5064]],\n",
      "\n",
      "         [[-0.1621]],\n",
      "\n",
      "         [[ 0.6306]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3102]],\n",
      "\n",
      "         [[ 0.2429]],\n",
      "\n",
      "         [[-0.3529]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0055]],\n",
      "\n",
      "         [[-0.3441]],\n",
      "\n",
      "         [[ 0.3680]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0606]],\n",
      "\n",
      "         [[-0.6460]],\n",
      "\n",
      "         [[-0.0811]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6822]],\n",
      "\n",
      "         [[ 0.0922]],\n",
      "\n",
      "         [[ 0.1003]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.1248e+00,  1.5130e+00,  1.0960e+00,  1.4769e+00,  8.6290e-01,\n",
      "         1.3132e+00,  1.0676e+00,  1.3702e+00,  7.6246e-01,  8.3672e-01,\n",
      "         1.1078e+00,  5.5144e-01,  7.5986e-01,  8.0576e-01,  9.6984e-01,\n",
      "         1.9130e+00,  7.4800e-01,  6.5554e-01,  1.5748e+00,  1.1822e+00,\n",
      "         6.9524e-01,  1.8714e+00,  1.2491e+00,  6.1922e-01,  1.0070e+00,\n",
      "         9.0773e-01,  1.0739e+00,  1.7950e+00,  1.0870e+00,  8.0357e-01,\n",
      "         1.2055e+00,  4.7204e-01,  7.5434e-01,  1.4273e+00,  1.0731e+00,\n",
      "         9.6381e-01,  1.0655e+00,  1.2282e+00,  1.0987e+00,  1.3103e+00,\n",
      "         1.3344e+00,  1.0429e+00,  5.8026e-01,  9.1066e-01,  9.8521e-01,\n",
      "         8.9921e-01,  9.7681e-01,  1.0377e+00,  1.0520e+00,  9.7256e-01,\n",
      "         1.3337e+00,  1.0524e+00,  3.0364e-01,  1.1265e+00,  1.3981e+00,\n",
      "         1.1280e+00,  9.9089e-01,  1.0792e+00,  1.4970e+00,  1.2736e+00,\n",
      "         1.4949e+00,  5.0828e-01,  1.3516e+00,  6.1886e-01,  1.8312e+00,\n",
      "         8.0767e-01,  2.4307e-01,  1.3960e+00,  1.0084e+00,  1.2679e+00,\n",
      "         9.1046e-01,  9.5311e-01,  2.0355e+00,  5.9661e-01,  1.1617e+00,\n",
      "         7.0358e-01,  1.0321e+00,  1.0411e+00,  5.1647e-01,  1.2840e+00,\n",
      "         5.1437e-01,  1.2361e+00,  8.7588e-01,  1.2660e+00,  1.3312e+00,\n",
      "         1.5209e+00,  1.4455e+00,  1.3728e+00,  1.8569e+00,  1.4438e+00,\n",
      "         1.4295e+00,  1.0834e+00,  7.7760e-01,  7.8916e-01,  1.5977e+00,\n",
      "         1.3118e+00,  2.9742e-01,  9.8101e-01,  7.9681e-01,  9.7578e-01,\n",
      "         1.2549e+00,  1.3696e+00,  9.2406e-01,  1.2626e+00,  1.3041e+00,\n",
      "         2.3140e-01,  8.5289e-01,  1.3984e+00,  1.3565e+00,  7.5459e-01,\n",
      "         1.1366e+00,  1.1366e+00,  1.1431e+00,  1.5423e+00,  1.5753e+00,\n",
      "         1.2686e+00,  1.2316e+00,  8.3391e-01,  6.8463e-01,  1.0541e+00,\n",
      "         1.1468e+00,  8.7220e-01,  1.1086e+00,  8.9412e-01,  1.1156e+00,\n",
      "         6.8365e-01,  1.1006e+00,  1.3368e+00,  1.0265e+00,  1.1818e+00,\n",
      "         1.0313e+00,  1.5018e+00,  1.0223e+00,  1.2923e+00,  1.0205e+00,\n",
      "         1.7968e+00,  1.2709e+00,  1.2511e+00,  1.0717e+00,  1.3264e+00,\n",
      "         7.8735e-01,  7.0578e-01,  1.2136e+00,  1.3324e+00,  9.8171e-01,\n",
      "         1.1091e+00,  1.6472e+00,  1.0958e+00,  1.0221e+00,  2.2512e+00,\n",
      "         8.8173e-01,  4.4868e-01,  1.5601e+00,  1.3283e+00,  9.8039e-01,\n",
      "         6.0933e-01,  6.4282e-01,  9.1228e-01,  1.0551e+00,  6.1986e-01,\n",
      "         1.2210e+00,  1.1671e+00,  9.3833e-01,  5.5744e-01,  2.0518e+00,\n",
      "         9.8683e-01,  1.5139e+00,  7.4973e-01,  9.4527e-01,  1.3724e+00,\n",
      "         9.9175e-01,  1.0537e+00,  1.7022e+00,  1.6421e+00,  1.1482e+00,\n",
      "         1.1987e+00,  1.3355e+00,  8.0137e-01,  1.1392e+00,  1.0982e+00,\n",
      "         1.4344e+00,  1.0496e+00,  1.0050e+00,  1.3756e+00,  8.7655e-01,\n",
      "         1.0241e+00,  6.7657e-01,  9.0928e-01,  2.1066e-01,  7.4770e-01,\n",
      "         8.3728e-01,  1.5676e+00,  1.5335e+00,  8.8430e-01,  1.0620e+00,\n",
      "         1.6110e+00,  1.2494e+00,  1.4937e+00,  1.4188e+00,  1.4906e+00,\n",
      "         1.8988e+00,  1.8195e+00,  6.7279e-01,  8.0543e-01,  1.1971e+00,\n",
      "         4.7389e-01,  1.3329e+00,  1.5274e+00,  7.9413e-01,  9.5584e-01,\n",
      "         6.5653e-01,  9.5955e-01,  1.9568e+00,  1.0451e+00,  9.9542e-01,\n",
      "         1.0775e+00,  1.1397e+00,  9.6737e-01,  7.8455e-01,  2.1640e+00,\n",
      "         5.0802e-01,  1.2154e+00,  1.1877e+00,  1.0094e+00,  7.4422e-01,\n",
      "        -2.2776e-03,  1.1593e+00,  1.4672e+00,  8.3370e-01,  1.3766e+00,\n",
      "         6.3696e-01, -1.2846e-01,  9.1682e-01,  1.5296e+00,  1.4420e+00,\n",
      "         1.0536e+00,  1.1987e+00,  1.5262e+00,  9.1822e-01,  1.4308e+00,\n",
      "         1.0377e+00,  2.2368e+00,  8.9819e-01,  7.1823e-01,  9.3933e-01,\n",
      "         1.2957e+00,  1.1627e+00,  1.0677e+00,  9.1796e-01,  9.5522e-01,\n",
      "         1.2531e+00,  7.6470e-01,  9.2593e-01,  1.8203e+00,  5.8108e-01,\n",
      "         1.7816e+00,  1.6487e+00,  4.8453e-01,  1.0841e+00,  9.1106e-01,\n",
      "         1.0148e+00,  9.6959e-01,  6.0919e-01,  1.4086e+00,  1.1332e+00,\n",
      "         1.3181e+00,  6.9665e-01,  1.0602e+00,  1.2421e+00,  8.7122e-01,\n",
      "         1.2073e+00,  1.5815e+00,  6.2044e-01,  8.3646e-01,  1.0042e+00,\n",
      "         6.3181e-01,  1.1486e+00,  8.3226e-01,  1.1335e+00,  9.0009e-01,\n",
      "         1.4835e+00,  9.3695e-01,  9.9682e-01,  5.6845e-01,  6.4789e-01,\n",
      "         6.6716e-01,  7.8623e-01,  1.2828e+00,  1.2861e+00,  1.4220e+00,\n",
      "         1.1534e+00,  1.2837e+00,  1.2275e+00,  8.7749e-01,  1.0069e+00,\n",
      "         8.9918e-01,  9.7059e-01,  1.5439e+00,  5.5360e-01,  1.4545e+00,\n",
      "         4.3585e-01,  1.5307e+00,  1.4737e+00,  9.8510e-01,  1.0061e+00,\n",
      "         3.1846e-01,  1.5585e+00,  1.9209e+00,  5.7200e-01,  7.7902e-01,\n",
      "         7.0594e-01,  8.8151e-01,  1.0551e+00,  1.6791e+00,  1.2807e+00,\n",
      "         1.2347e+00,  1.8194e+00,  1.2856e+00,  1.5777e+00,  1.0029e+00,\n",
      "         1.4078e+00,  1.1772e+00,  7.6450e-01,  1.2595e+00,  6.9557e-01,\n",
      "         1.2500e+00,  1.3153e+00,  7.5778e-01,  1.0705e+00,  6.6317e-01,\n",
      "         1.2635e+00,  2.0714e-01,  1.6222e+00,  1.3537e+00,  9.6405e-01,\n",
      "         6.8847e-01,  1.7938e+00,  9.5140e-01,  9.2897e-01,  1.5059e+00,\n",
      "         8.7444e-01,  1.1704e+00,  1.7591e+00,  4.9726e-01,  1.2776e+00,\n",
      "         1.1611e+00,  6.8068e-01,  1.3517e+00,  9.0633e-01,  1.6099e+00,\n",
      "         9.6005e-01,  9.3441e-01,  1.2527e+00,  1.4722e+00,  1.3530e+00,\n",
      "         1.5595e+00,  1.3919e+00,  9.7918e-01,  1.2316e+00,  1.3753e+00,\n",
      "         1.3476e+00,  1.3718e+00,  1.3509e+00,  1.3061e+00,  5.6934e-01,\n",
      "         1.5578e+00,  1.5284e+00,  5.4889e-01,  9.7254e-01,  1.8692e+00,\n",
      "         1.1755e+00,  6.1252e-01,  1.0833e+00,  1.3389e+00,  7.4029e-01,\n",
      "         7.1088e-01,  9.2348e-01,  1.1584e+00,  8.5770e-01,  3.5846e-01,\n",
      "         1.1515e+00,  1.8494e+00,  2.4260e-01,  1.5737e+00,  1.2857e+00,\n",
      "         1.9406e+00,  8.0714e-01,  7.9566e-01,  1.1530e+00,  1.3150e+00,\n",
      "         5.1157e-01,  1.1419e+00,  6.4118e-01,  1.4811e+00,  1.3330e+00,\n",
      "         3.8635e-01,  1.3987e+00,  1.2550e+00,  1.5749e+00,  1.0044e+00,\n",
      "         4.5575e-01,  7.6043e-01,  8.0388e-01,  1.9498e-01,  9.3903e-01,\n",
      "         1.5266e+00,  2.8837e-01,  9.2949e-01,  1.1001e+00,  1.4984e+00,\n",
      "         7.9083e-01,  8.2678e-01,  2.6935e-01,  1.1744e+00,  1.4323e+00,\n",
      "         7.7927e-01,  1.0679e+00,  1.0800e+00,  1.5094e+00,  1.6541e+00,\n",
      "         1.0023e+00,  1.3681e+00,  5.9407e-01,  8.1498e-01,  1.0685e+00,\n",
      "         1.4037e+00,  1.5313e+00,  4.4260e-01,  6.5517e-01,  1.5324e+00,\n",
      "         1.1151e+00,  9.5745e-01,  1.3630e+00,  8.3777e-01,  1.4736e+00,\n",
      "         6.9110e-01,  9.8920e-01,  1.4966e+00,  1.1336e+00,  1.0334e+00,\n",
      "         1.4378e+00,  1.4725e+00,  1.2363e+00,  1.1238e+00,  7.5853e-01,\n",
      "         1.4455e+00,  1.1562e+00,  1.0824e+00,  1.3692e+00,  7.5766e-01,\n",
      "         1.4435e+00,  7.5506e-01,  1.3707e+00,  1.0699e+00,  8.8573e-01,\n",
      "         1.5547e+00,  1.1989e+00,  6.9078e-01,  8.7279e-01,  1.3517e+00,\n",
      "         8.2213e-01,  9.9438e-01,  6.9014e-01,  1.3760e+00,  5.3549e-01,\n",
      "         6.9233e-01,  1.1509e+00,  8.1872e-01,  1.1979e+00,  9.9536e-01,\n",
      "         1.9121e+00,  9.4928e-01,  2.1549e+00,  1.0892e+00,  1.2245e+00,\n",
      "         9.6619e-01,  1.3792e+00,  1.2414e+00,  6.5404e-01,  7.5690e-01,\n",
      "         1.1748e+00,  8.6739e-01,  1.9355e+00,  1.4264e+00,  1.2853e+00,\n",
      "         8.8539e-01,  1.0022e+00,  8.9275e-01,  1.4382e+00,  2.4257e+00,\n",
      "         1.0415e+00,  1.4817e+00,  9.7878e-01,  8.8083e-01,  1.5073e+00,\n",
      "         1.3234e+00,  4.0725e-01,  9.5192e-01,  1.1853e+00,  1.0937e+00,\n",
      "         9.0968e-01,  1.1753e+00,  1.3493e+00,  1.0341e+00,  1.3933e+00,\n",
      "         6.4718e-01,  9.0675e-01,  1.5416e+00,  1.7212e+00,  1.2319e+00,\n",
      "         1.1897e+00,  8.4757e-01,  6.0053e-01,  1.2714e+00,  1.3947e+00,\n",
      "         9.3137e-01,  1.0129e+00,  1.6089e+00,  1.1458e+00,  1.0206e+00,\n",
      "         8.3482e-01,  1.1985e+00,  1.0586e+00,  1.4259e+00,  4.5733e-01,\n",
      "         8.6899e-01,  1.1520e+00,  1.0109e+00,  1.2877e+00,  7.5865e-01,\n",
      "         1.7718e+00,  1.0609e+00,  9.4964e-01,  1.4138e+00,  1.3528e+00,\n",
      "         1.2248e+00,  1.0930e+00,  1.3287e+00,  8.7349e-01,  1.3836e+00,\n",
      "         1.5427e+00,  1.0897e+00,  6.2727e-01,  1.4933e+00,  1.2603e+00,\n",
      "         1.0245e+00,  8.4582e-01,  1.8586e+00,  1.4783e-01,  1.0559e+00,\n",
      "         9.4168e-01,  7.6771e-01,  3.9068e-01,  1.2727e+00,  9.9288e-01,\n",
      "         6.5530e-01,  1.1852e+00,  1.2017e+00,  1.0946e+00,  1.4107e+00,\n",
      "         7.5057e-01,  1.8262e+00,  8.4398e-01,  1.2550e+00,  2.0324e+00,\n",
      "         9.4843e-01,  1.4561e+00,  1.1221e+00,  9.0909e-01,  1.0586e+00,\n",
      "         1.8749e+00,  1.6171e+00,  1.0041e+00,  1.5284e+00,  1.7581e+00,\n",
      "         8.8005e-01,  9.0063e-01,  1.5500e+00,  1.0050e+00,  1.5321e+00,\n",
      "         2.2506e+00,  1.2729e+00,  9.0846e-01,  1.0143e+00,  1.5713e+00,\n",
      "         1.0328e+00,  1.3766e+00,  1.5502e+00,  9.2901e-01,  1.1824e+00,\n",
      "         1.1601e+00,  1.1845e+00,  1.6938e-01,  1.4966e+00,  7.9519e-01,\n",
      "         1.1935e+00,  8.1261e-01,  7.2993e-01,  8.0207e-01,  1.3338e+00,\n",
      "         1.1273e+00,  1.2820e+00,  1.4164e+00,  9.4013e-01,  1.7351e+00,\n",
      "         6.9361e-01,  1.2862e+00,  1.6026e+00,  1.2470e+00,  6.0189e-01,\n",
      "         7.6007e-01,  1.0968e+00,  8.5312e-01,  3.1663e-01,  1.1875e+00,\n",
      "         1.0549e+00,  1.7902e+00,  7.8346e-01,  1.4835e+00,  1.5486e+00,\n",
      "         7.6721e-01,  7.1062e-01,  1.0983e+00,  1.5094e+00,  1.3067e+00,\n",
      "         1.1590e+00,  1.8260e+00,  8.6244e-01,  1.0248e+00,  1.1636e+00,\n",
      "         6.7388e-01,  1.2630e+00,  1.3324e+00,  1.7164e+00,  8.7597e-01,\n",
      "         1.2019e+00,  8.0795e-01,  1.3095e+00,  1.6963e+00,  1.3875e+00,\n",
      "         1.4676e+00,  1.0504e+00,  1.2353e+00,  6.9513e-01,  9.2906e-01,\n",
      "         1.1393e+00,  1.5014e+00,  2.7163e-01,  1.0275e+00,  3.8632e-01,\n",
      "         4.3964e-01,  1.2707e+00, -3.1725e-01,  1.6783e+00,  2.0553e+00,\n",
      "         1.3594e+00,  1.5604e+00,  1.1143e+00,  1.2541e+00,  1.3760e+00,\n",
      "         1.3926e+00,  1.1403e+00,  1.4656e+00,  8.4562e-01,  1.3620e+00,\n",
      "         9.5909e-01,  1.0935e-01,  1.2410e+00,  2.2354e-01,  7.8374e-01,\n",
      "         1.8406e+00,  9.3271e-01,  6.4428e-01,  5.5007e-01,  1.2691e+00,\n",
      "         4.6870e-01,  1.1435e+00,  1.4020e+00,  1.1532e+00,  1.3403e+00,\n",
      "         1.4548e+00,  1.6881e+00,  6.9064e-01,  1.1367e+00,  2.2069e+00,\n",
      "         9.3579e-01,  1.6019e+00,  1.5024e+00,  1.2459e+00,  4.5752e-01,\n",
      "         1.1992e+00,  7.5019e-01,  1.3261e+00,  1.2595e+00,  1.1283e+00,\n",
      "         1.2952e+00,  6.5069e-01,  1.4168e+00,  1.1293e+00,  7.5023e-01,\n",
      "         8.8157e-01,  1.0608e+00,  7.3540e-01,  1.7054e+00,  1.7310e+00,\n",
      "         1.0207e+00,  9.4090e-01,  9.2127e-01,  6.6711e-01,  9.5137e-01,\n",
      "         6.8737e-01,  1.5804e+00,  1.8489e+00,  1.2738e+00,  1.7018e+00,\n",
      "         1.2575e+00,  1.5133e+00,  1.2606e+00,  8.8492e-01,  8.3344e-01,\n",
      "         1.3031e+00,  1.1579e+00,  1.4311e+00,  7.0676e-01,  1.0846e+00,\n",
      "         1.4375e+00,  1.3943e+00,  1.5487e+00,  1.6383e+00,  1.0951e+00,\n",
      "         1.0927e+00,  1.3297e+00,  9.9620e-01,  1.1661e+00,  1.8420e+00,\n",
      "         1.3951e+00,  1.3688e+00,  1.0623e+00,  1.4457e+00,  1.0937e+00,\n",
      "         1.2112e+00,  6.8881e-01,  1.5024e+00,  1.4376e+00,  1.4935e+00,\n",
      "         8.1586e-01,  1.0897e+00,  1.4664e+00,  3.4178e-01,  1.0209e+00,\n",
      "         1.1461e+00,  1.7956e+00,  1.3837e+00,  1.5222e+00,  1.1778e+00,\n",
      "         6.2640e-01,  1.3857e+00,  1.3576e+00,  1.0291e+00,  1.5542e+00,\n",
      "         1.4642e+00,  1.1313e+00,  8.1415e-01,  1.3108e+00,  1.3936e+00,\n",
      "         8.3501e-01,  1.4726e+00,  1.8514e+00,  1.5865e+00,  2.2664e+00,\n",
      "         6.2006e-01,  7.8420e-01,  1.3312e+00,  8.7029e-01,  1.7277e+00,\n",
      "         9.5470e-01,  1.1674e+00,  6.7799e-01,  1.4424e+00,  1.2787e+00,\n",
      "         1.2896e+00,  1.6020e+00,  1.0995e+00,  1.6292e+00,  6.2339e-01,\n",
      "         8.9903e-01,  1.3508e+00,  2.0716e+00,  1.0942e+00,  1.1322e+00,\n",
      "         5.4663e-01,  8.8286e-01,  1.3684e+00,  7.8476e-01,  7.8025e-01,\n",
      "         1.4944e+00,  1.1816e+00,  9.9273e-01,  1.0057e+00,  8.6811e-01,\n",
      "         1.1445e+00,  1.1338e+00,  1.4583e+00,  8.7907e-01,  9.8273e-01,\n",
      "         1.0872e+00,  1.3745e+00,  1.2267e+00,  1.3966e+00,  1.0071e+00,\n",
      "         1.4261e+00,  1.4308e+00,  9.2290e-01,  6.5853e-01,  1.1753e+00,\n",
      "         1.3621e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-5.2867e-02, -3.0837e+00, -4.4803e-01, -1.9359e+00, -8.8241e-01,\n",
      "        -1.3163e+00, -7.7377e-02, -9.2267e-01, -4.8425e-01, -1.0995e+00,\n",
      "        -1.0220e+00,  6.7344e-01, -1.1738e+00, -1.0323e+00, -7.8574e-01,\n",
      "         1.6470e-01, -1.6561e+00, -5.9991e-01, -5.5847e-01, -5.0471e-02,\n",
      "        -6.1711e-01, -1.2901e-02, -2.2337e+00,  1.4131e+00, -1.8958e+00,\n",
      "        -1.8059e+00, -5.6584e-01, -3.5955e-01, -1.3121e+00, -1.3885e+00,\n",
      "        -1.3748e+00,  2.0728e-01,  5.2571e-01, -1.1383e+00, -8.5495e-01,\n",
      "        -1.7009e+00,  6.5817e-02, -5.3153e-01, -1.3339e+00, -5.2380e-01,\n",
      "         5.8409e-01, -4.1960e-01, -6.7932e-01, -8.6010e-01, -2.0737e+00,\n",
      "        -3.4982e-01, -1.1817e+00,  1.6875e-01, -1.4247e+00, -5.9883e-01,\n",
      "        -7.6297e-01, -6.6726e-01, -1.7727e-01, -1.0674e+00, -1.7873e+00,\n",
      "        -8.3627e-01, -6.0094e-01, -1.0319e+00, -1.0147e+00, -9.4229e-01,\n",
      "         6.7527e-01,  4.5474e-01, -5.3635e-01,  2.6905e-01, -1.2555e+00,\n",
      "        -6.9154e-01,  5.1305e-01,  1.2284e-01,  1.9884e-01, -1.1040e+00,\n",
      "        -1.3472e+00, -4.3447e-01,  8.2109e-01,  3.6125e-01,  9.3116e-02,\n",
      "        -3.5979e-01, -1.0299e+00, -1.6543e+00, -4.9261e-01, -6.2002e-01,\n",
      "        -1.1369e+00, -2.2365e-01, -1.3821e+00, -5.3365e-01, -2.6363e-01,\n",
      "        -1.4470e+00, -1.4947e+00, -9.2128e-01, -1.1259e+00,  1.1695e+00,\n",
      "        -1.5181e+00, -3.3935e-01, -5.9974e-01, -1.2406e+00, -7.7094e-01,\n",
      "        -1.4342e+00,  3.7056e-01, -3.2654e-01,  9.7164e-02, -1.2371e+00,\n",
      "        -1.9667e+00,  2.0010e-01, -9.9120e-01, -4.0343e-01, -1.6199e+00,\n",
      "         1.3760e-01, -1.6773e+00, -1.8663e+00, -9.4210e-01,  1.7174e-01,\n",
      "        -1.9053e+00, -6.4137e-01, -7.1189e-01, -5.7634e-01, -1.8113e-01,\n",
      "        -1.6599e-01,  5.8478e-02,  3.0707e-01,  5.0197e-01, -1.1433e+00,\n",
      "        -5.3326e-01, -9.8017e-01, -5.0103e-01, -5.6066e-01, -1.7403e+00,\n",
      "        -7.5861e-01, -2.0333e+00, -1.1005e+00, -6.7780e-01, -3.4019e-01,\n",
      "        -1.1301e+00, -1.2137e+00, -2.3229e+00, -6.9666e-01, -7.8774e-01,\n",
      "         5.2063e-01, -4.4271e-01, -8.1696e-01, -6.0395e-01, -5.3046e-01,\n",
      "        -1.0351e+00, -1.0582e+00, -1.4591e+00, -2.1047e+00, -1.9928e-02,\n",
      "        -4.4939e-01, -8.6494e-01, -7.8651e-01, -2.1843e+00,  2.6383e-01,\n",
      "        -3.9909e-02,  1.3580e+00, -1.6338e+00, -1.2537e+00, -1.1945e+00,\n",
      "        -5.8011e-01,  4.4883e-01, -1.1847e+00, -1.1072e+00,  6.1720e-01,\n",
      "         6.0192e-01, -6.1363e-01,  6.8570e-01,  1.8772e-01, -8.6110e-01,\n",
      "        -8.2883e-01,  4.6958e-01, -3.2306e-01, -1.5780e+00, -8.4705e-01,\n",
      "        -1.4758e+00, -2.0032e-01, -1.3732e+00, -2.8830e-01, -1.9182e+00,\n",
      "        -2.7424e-01,  4.4444e-01, -9.8847e-01, -1.1324e+00, -2.1600e+00,\n",
      "        -2.8782e-01,  2.0246e-01, -1.3819e+00, -1.8906e-01, -8.1438e-01,\n",
      "        -1.2662e+00,  2.7160e-01, -3.0311e-01, -1.4722e-01, -7.9482e-02,\n",
      "        -4.6583e-01, -9.1682e-01, -1.3948e-03,  2.4218e-01, -1.0991e+00,\n",
      "        -1.7542e+00, -5.9575e-01, -1.9792e+00, -1.4539e+00,  2.2034e-01,\n",
      "        -2.0613e+00, -9.0095e-02, -8.7737e-01, -3.7723e-01, -1.6520e+00,\n",
      "        -4.4953e-01, -5.9557e-01, -1.2191e+00, -1.7064e+00, -7.1174e-01,\n",
      "         1.0588e+00, -1.5016e+00,  6.5127e-01, -9.9202e-01, -1.6885e+00,\n",
      "        -2.0780e+00, -1.0295e+00, -6.9113e-01,  5.8244e-01, -6.5720e-01,\n",
      "        -2.5267e-01, -6.0063e-01, -2.1138e+00, -1.3094e+00, -7.6835e-01,\n",
      "        -1.2785e+00,  1.5030e-01, -2.2238e+00, -2.0769e+00,  6.3432e-01,\n",
      "        -3.8024e-01,  4.4973e-01,  1.3664e+00, -2.0202e+00, -2.9057e-01,\n",
      "        -6.8847e-01, -1.1310e+00, -3.8674e-01, -2.7383e-01, -1.1270e+00,\n",
      "        -1.3710e+00,  7.2517e-01, -1.5600e+00,  1.0327e-01, -1.0181e+00,\n",
      "        -6.4407e-01, -1.5230e+00, -1.5976e+00, -1.1602e+00, -1.0081e+00,\n",
      "        -1.3408e+00,  2.0742e-01,  7.5590e-02, -2.8340e-01,  1.3430e-02,\n",
      "        -4.1650e-01, -9.1370e-01, -9.7641e-01, -1.3704e+00, -8.5320e-01,\n",
      "        -2.2672e+00, -1.4378e+00, -8.0384e-01, -1.7450e+00, -1.0662e+00,\n",
      "        -9.0043e-01, -5.8980e-01, -2.1859e+00, -1.6211e+00, -1.5224e+00,\n",
      "        -1.2509e+00, -2.1564e+00, -1.1254e+00, -9.7603e-01, -1.3840e+00,\n",
      "        -5.4695e-01, -1.9148e+00,  2.7355e-01, -5.3373e-01, -1.4001e+00,\n",
      "        -1.4794e+00, -2.7217e-01, -1.5038e+00, -6.7634e-01,  5.2144e-01,\n",
      "         9.9757e-02, -1.5229e-01,  2.2949e-01, -2.2522e-01,  1.6750e-01,\n",
      "        -1.3888e+00,  3.8987e-01,  4.8876e-01, -2.1976e+00, -1.3304e+00,\n",
      "        -1.0473e+00,  1.0247e+00, -7.0776e-01, -4.4561e-01, -2.4498e+00,\n",
      "        -2.5456e-01, -2.2085e+00, -1.2509e+00, -2.3145e+00, -3.8784e-01,\n",
      "        -2.0354e+00, -5.1841e-01, -6.7254e-01,  1.2308e+00, -4.7507e-01,\n",
      "        -1.5784e+00,  9.5391e-01, -1.7556e+00, -1.2430e+00, -1.3679e+00,\n",
      "        -8.1266e-01,  4.0822e-01, -3.9828e-01, -1.2956e+00, -8.6092e-01,\n",
      "        -1.2584e+00, -1.9211e+00, -8.8951e-01, -1.4586e+00,  8.1291e-01,\n",
      "        -1.5690e+00, -1.7412e+00,  7.5265e-01, -1.6690e+00,  1.0211e+00,\n",
      "        -1.1139e+00,  6.1070e-01, -7.5991e-01, -6.8229e-01, -3.9605e-01,\n",
      "         9.6257e-02, -1.1359e+00, -1.4109e+00, -4.9823e-01, -1.4327e+00,\n",
      "        -3.2790e-01, -9.8736e-02, -1.6427e+00, -4.5126e-01, -9.6917e-01,\n",
      "        -1.7078e+00, -8.9251e-01, -3.2189e-01,  1.0744e-01, -1.3170e+00,\n",
      "        -6.9147e-02,  9.1116e-01, -2.4210e+00, -2.0317e-01, -8.7030e-01,\n",
      "        -1.3289e+00, -2.6744e+00, -9.7930e-01, -6.6172e-02, -6.9773e-01,\n",
      "        -2.5769e+00, -2.0866e+00, -1.9370e+00, -1.5098e+00,  1.4002e-01,\n",
      "        -1.1281e+00, -5.3431e-01,  1.3547e+00, -6.6437e-01,  2.0909e-01,\n",
      "        -1.9536e+00, -1.6414e-02, -1.9841e+00, -1.5040e+00, -1.8754e+00,\n",
      "        -1.6823e+00, -8.2163e-01, -1.6074e+00, -9.5954e-01, -2.9957e-02,\n",
      "        -2.2107e+00, -8.9827e-01,  1.6770e-02, -2.7526e+00, -1.9616e+00,\n",
      "        -4.1142e-01, -3.3549e-01, -1.1546e+00, -8.0847e-01, -2.6140e-01,\n",
      "         4.8838e-01, -1.1449e+00, -1.4738e+00, -1.7994e+00,  4.2381e-01,\n",
      "        -1.9331e+00, -4.7643e-01,  1.0237e-01, -2.6100e+00, -7.5480e-01,\n",
      "        -3.7671e-01, -1.1258e+00, -1.5208e+00, -1.2877e-01, -4.4860e-02,\n",
      "        -1.3791e+00,  3.6244e-01,  7.5849e-01, -1.5567e+00, -4.3604e-01,\n",
      "        -9.2920e-01, -4.5078e-01,  1.7534e-01, -6.9196e-01, -7.2472e-01,\n",
      "        -1.3416e-01, -2.1657e+00, -1.1005e+00, -2.8038e+00, -1.7078e-01,\n",
      "        -8.9991e-02, -1.7895e+00, -2.1031e-01, -7.7174e-01, -2.4412e+00,\n",
      "        -1.7046e+00, -5.1211e-01,  1.2140e+00, -2.3747e+00, -1.5876e+00,\n",
      "        -1.3077e+00,  8.6006e-01, -1.7764e+00, -1.8577e-01, -1.6125e+00,\n",
      "         3.2806e-01, -1.6543e+00, -2.3848e-01, -1.5525e+00, -1.1853e+00,\n",
      "        -7.3743e-01, -8.0575e-02, -1.2593e+00, -1.1386e+00, -1.2000e+00,\n",
      "        -5.6491e-01, -9.4784e-01, -9.3454e-01, -1.7868e+00, -1.5369e-01,\n",
      "        -1.8210e+00, -1.8039e+00,  2.0394e-01, -1.5782e+00, -1.3249e+00,\n",
      "        -5.3323e-01, -5.2216e-01, -9.5011e-01, -1.9942e-01, -1.6887e+00,\n",
      "        -5.4155e-01, -6.9533e-01,  2.6820e-01, -7.1528e-01, -1.0384e+00,\n",
      "        -7.4204e-01, -1.4581e+00, -7.2024e-02, -2.4169e-01, -1.1763e+00,\n",
      "        -1.1224e+00,  4.7292e-01, -7.5317e-01, -8.8525e-01, -1.2348e+00,\n",
      "         3.0119e-01,  7.2122e-01, -1.4676e+00, -2.0350e-01, -1.6787e-01,\n",
      "         1.5902e-01, -1.3583e+00, -4.9005e-01,  5.2174e-02, -1.9954e+00,\n",
      "         1.8587e+00, -2.3560e+00, -6.3945e-01,  4.0326e-01, -3.0687e-01,\n",
      "        -1.4487e+00, -4.6157e-01, -1.1798e+00, -9.0919e-02,  3.7715e-01,\n",
      "         9.3678e-01,  2.7432e-01, -1.5173e+00, -1.5804e+00, -8.0959e-01,\n",
      "        -6.7847e-01, -1.1196e+00, -7.8677e-01, -5.7479e-01, -4.1412e-01,\n",
      "        -1.1347e+00, -1.4990e+00, -9.8148e-03,  4.1546e-01, -1.9518e+00,\n",
      "        -4.9330e-01, -4.7682e-01,  4.7034e-01, -6.8093e-01, -2.1221e+00,\n",
      "        -3.0899e-01, -1.1854e+00, -7.4380e-01, -1.5495e+00, -1.4848e+00,\n",
      "         7.6217e-01, -1.9828e+00, -1.6750e+00, -1.9604e-01,  7.8285e-01,\n",
      "        -1.1416e+00, -1.4256e+00, -9.0594e-01, -1.6769e+00, -7.0126e-02,\n",
      "        -1.6683e+00, -1.3237e+00, -2.5935e-01, -1.2736e+00, -5.1805e-01,\n",
      "        -6.0312e-01, -3.6035e-01, -1.0191e+00, -5.9783e-01, -4.6124e-01,\n",
      "        -1.6150e+00, -1.7667e+00, -2.0301e+00, -5.3775e-01, -9.6016e-01,\n",
      "        -4.6845e-01, -1.6374e-01, -9.1967e-01, -5.4558e-01, -1.5666e+00,\n",
      "        -1.4238e+00,  4.3945e-01,  4.7548e-01, -9.4455e-01, -2.4140e+00,\n",
      "        -7.0808e-02, -1.1473e+00, -1.8663e+00, -9.1444e-01, -2.7012e-01,\n",
      "        -8.6907e-01,  4.1121e-01, -2.8894e-01, -1.1583e+00,  1.7216e-03,\n",
      "        -7.6096e-01, -4.9533e-01, -3.0292e+00, -1.1879e+00, -1.4842e+00,\n",
      "         8.6722e-01, -1.9497e-01,  9.8340e-01, -1.2121e+00, -2.3698e-01,\n",
      "        -3.1822e-01, -9.5468e-01, -7.6165e-01, -2.1826e+00, -1.2925e+00,\n",
      "        -1.8229e+00, -3.9996e-01, -2.0310e+00, -1.0121e+00,  1.6224e-01,\n",
      "        -1.3032e+00, -8.8262e-01, -1.0802e+00, -1.2949e+00, -6.3661e-01,\n",
      "        -9.3943e-01, -6.7075e-01, -4.3564e-01, -1.9782e+00, -4.6205e-02,\n",
      "         8.7000e-02, -1.4114e+00, -1.4851e-01, -1.9020e+00,  1.6164e+00,\n",
      "        -1.2673e+00, -4.6355e-01, -1.1189e+00, -7.7485e-01, -9.0500e-01,\n",
      "        -2.8305e-04, -6.1013e-01, -1.2311e+00, -1.6438e+00,  4.2952e-01,\n",
      "        -1.5844e-01, -1.3961e+00,  5.8989e-01, -2.4379e+00, -1.5122e+00,\n",
      "         3.7426e-01, -1.5436e-01, -5.4901e-01, -1.5421e+00, -5.6298e-01,\n",
      "        -1.0866e+00, -9.8804e-01, -1.5876e+00,  1.4704e-01, -1.4221e+00,\n",
      "        -1.0040e+00, -1.2104e+00, -5.5277e-01, -6.8699e-02, -6.1963e-01,\n",
      "         7.9497e-01, -1.9552e-01, -1.0275e+00,  3.5612e-01, -1.8623e+00,\n",
      "        -7.4634e-01, -4.7938e-01, -8.1295e-01, -1.5193e+00, -7.2237e-01,\n",
      "        -2.1857e-01,  2.3171e-01, -8.0188e-01, -1.8549e+00, -7.8675e-01,\n",
      "        -1.9791e+00, -4.2105e-01,  4.5078e-02, -1.1698e-02,  2.3958e-01,\n",
      "         2.8438e-01, -7.9232e-01, -7.8337e-03, -1.6921e+00, -1.9230e-01,\n",
      "        -2.1718e+00, -1.8688e+00, -1.7899e+00, -8.0271e-01, -6.2182e-01,\n",
      "        -1.4958e+00, -6.7859e-01, -3.4332e-01, -4.8627e-01, -5.6503e-01,\n",
      "        -1.0281e+00, -4.2595e-01, -7.0753e-01,  1.6109e-01, -9.8100e-01,\n",
      "         7.3620e-02, -6.7667e-01, -1.4087e+00,  1.6960e-01, -8.0081e-01,\n",
      "        -2.6258e-01, -3.9709e-01, -7.2151e-02, -1.4142e+00,  2.7777e-01,\n",
      "        -1.3670e-02, -3.9116e-01, -5.9924e-01, -3.3235e-01, -2.4408e-01,\n",
      "        -8.7219e-01, -1.6274e+00,  6.1393e-01, -8.3714e-01, -7.2947e-01,\n",
      "        -1.5945e+00, -3.2916e-01, -7.2390e-01, -1.8798e+00, -4.5945e-01,\n",
      "        -1.8828e+00, -9.5131e-01, -9.5188e-01,  2.5732e-01,  2.0303e-01,\n",
      "         2.7263e-01, -5.6596e-01,  2.5595e-01, -2.6099e-01,  1.5596e-01,\n",
      "         4.9788e-01, -4.7289e-01, -1.3392e+00,  2.6616e-01, -9.2543e-01,\n",
      "        -6.3809e-01,  2.5918e-01, -1.4621e+00, -7.3882e-01, -2.0417e-01,\n",
      "        -1.1826e-02, -2.2159e+00, -1.2012e+00, -6.6523e-01, -7.1792e-01,\n",
      "        -6.8525e-02, -7.1457e-01, -2.2845e-01, -1.3739e+00, -8.6655e-01,\n",
      "         7.0868e-01, -3.5039e-01, -8.8167e-01, -3.9579e-01, -1.2825e+00,\n",
      "        -1.0485e+00, -7.3215e-01,  5.8989e-01, -1.3682e+00, -5.0702e-01,\n",
      "        -9.7488e-01, -9.3009e-01, -6.8105e-01, -9.3645e-01, -2.5863e+00,\n",
      "        -1.1220e-01, -9.0382e-01, -1.1375e+00, -1.8889e+00, -7.8779e-01,\n",
      "        -9.8775e-01,  1.7596e-01, -1.0498e+00,  1.0155e+00, -9.7169e-01,\n",
      "        -1.8530e+00, -2.7252e-01, -1.0857e+00,  4.3895e-02, -1.2346e+00,\n",
      "         2.8061e-01, -1.3077e+00, -1.7046e+00, -2.8161e-01, -9.7974e-01,\n",
      "        -8.6172e-01, -1.4694e-01, -1.0075e+00, -9.6774e-01, -1.0923e+00,\n",
      "        -1.2913e+00, -2.2261e+00, -5.4039e-01, -1.8585e+00, -2.2560e+00,\n",
      "        -3.0412e-01, -7.9701e-01, -8.8067e-01, -2.2351e+00,  5.2284e-01,\n",
      "        -2.0115e+00, -1.4583e+00,  3.2339e-01, -6.6245e-01, -8.1808e-01,\n",
      "        -9.9695e-01, -2.2887e+00, -1.0384e+00, -1.4988e+00, -9.0754e-02,\n",
      "        -4.9064e-01, -8.0408e-01,  4.8451e-02, -8.9097e-01, -1.1978e+00,\n",
      "        -7.4927e-01, -7.3780e-01, -4.8561e-01, -3.5531e-01, -8.7043e-01,\n",
      "        -3.9198e-01, -1.0646e+00, -1.3990e+00, -3.7849e-01,  8.3260e-01,\n",
      "        -1.3395e+00, -1.6195e+00, -1.9238e+00, -1.6581e+00,  4.7123e-03,\n",
      "        -2.4412e+00, -4.8649e-01, -1.3216e+00, -6.4863e-01, -2.1360e+00,\n",
      "        -1.9426e+00, -1.4348e+00, -1.4630e+00, -3.4678e-01, -1.3991e+00,\n",
      "        -9.2760e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.3845, -0.6952, -0.2951, -0.2186, -0.5085],\n",
      "          [-0.5882, -0.5854, -0.0951, -0.0063, -0.0134],\n",
      "          [ 0.0085,  0.3031, -0.1991, -0.4971, -0.3537],\n",
      "          [ 0.3171,  0.2249, -0.2469, -0.5724, -0.3178],\n",
      "          [ 0.1268, -0.1150, -0.4055, -0.3492, -0.3151]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0974,  0.3215, -0.0999, -0.0095, -0.1746],\n",
      "          [ 0.3598,  0.1288, -0.1244, -0.4396, -0.1557],\n",
      "          [ 0.7880,  0.0744,  0.1913, -0.1887,  0.2474],\n",
      "          [-0.1122,  0.1123,  0.1122, -0.2803, -0.4206],\n",
      "          [ 0.2142,  0.0900, -0.3506, -0.4246, -0.6199]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2306,  0.2859,  0.5503,  0.8276,  0.9162],\n",
      "          [ 0.1922,  0.3020,  0.3153,  0.3421,  0.4056],\n",
      "          [ 0.1987,  0.1753,  0.0272,  0.1759,  0.1180],\n",
      "          [ 0.1161,  0.1326,  0.2118,  0.2038,  0.0740],\n",
      "          [ 0.2435,  0.2853,  0.3450,  0.3575,  0.4454]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0103,  0.1546, -0.0531, -0.2800, -0.3258],\n",
      "          [-0.2160,  0.1057,  0.1366, -0.0992, -0.3141],\n",
      "          [-0.2173,  0.0537,  0.4165,  0.1287, -0.2235],\n",
      "          [-0.3558, -0.0261,  0.6857,  0.4812, -0.1701],\n",
      "          [-0.4015, -0.0722,  0.6878,  0.6074, -0.0256]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4811,  0.5753,  0.5721,  0.5751,  0.5838],\n",
      "          [-0.0278, -0.0268, -0.1625,  0.1922,  0.1835],\n",
      "          [-0.0922,  0.2608,  0.2730,  0.1744,  0.2093],\n",
      "          [-0.2746, -0.2820, -0.1657, -0.2368, -0.0294],\n",
      "          [ 0.2148,  0.4970,  0.3606,  0.2338,  0.4320]]],\n",
      "\n",
      "\n",
      "        [[[-0.1751,  0.0430,  0.2988,  0.3741,  0.1132],\n",
      "          [ 0.2368, -0.1209,  0.1324, -0.0182, -0.2684],\n",
      "          [ 0.4576,  0.3832,  0.0352,  0.3141,  0.1996],\n",
      "          [ 0.4563,  0.0913,  0.1072,  0.1968, -0.1850],\n",
      "          [ 0.7603,  0.6969,  0.7758,  0.3016, -0.4240]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.4259,  2.8319,  0.9470,  3.0859,  1.1681,  1.5820,  1.9351,  1.1195,\n",
      "         1.5168,  1.4935,  1.1324,  1.9889,  1.4815,  1.6214,  1.1640,  1.3972,\n",
      "         1.1357,  1.2816,  2.1691,  1.5116,  1.0236,  1.8579,  0.5230,  1.8393,\n",
      "         0.8442,  0.9621,  1.2035,  1.4861,  1.4619,  0.8035,  1.3987,  1.4747,\n",
      "         1.3609,  0.9025,  0.4618,  1.2021,  1.7414,  2.8255,  1.1118,  0.9974,\n",
      "         1.7010,  1.1374,  1.6934,  1.8391,  0.0731,  1.4786,  0.8861,  0.9088,\n",
      "         0.7629,  1.8978,  1.1200,  0.8155,  1.5305,  1.9449,  1.5961,  1.1319,\n",
      "         1.2178,  0.6897,  1.1489,  1.3065,  0.8148,  1.5819,  1.3638,  1.4983,\n",
      "         1.7508,  1.2750,  1.2595,  2.0971,  1.9979,  0.8300,  1.5716,  0.9158,\n",
      "         0.9821,  1.3121,  1.1434,  1.0387,  0.9728,  1.7269,  1.3911,  1.3768,\n",
      "         0.8779,  1.6630,  0.7850,  1.0606,  1.5067,  2.7091,  0.9706,  2.3544,\n",
      "         0.1470,  0.8565,  0.6611,  1.6368,  0.9866,  0.7008,  0.8320,  1.5309,\n",
      "         1.9221,  1.1938,  1.5354,  1.6210,  1.2634,  1.1322,  0.7659,  1.5966,\n",
      "         0.9418,  1.4056,  1.2322,  1.0674,  0.8887,  0.8064,  0.9925,  1.5478,\n",
      "         0.6811,  1.5248,  2.1076,  1.3109,  0.8631,  2.0093,  1.1335,  0.8912,\n",
      "         0.9128,  1.5314,  1.3929,  1.3631,  0.9436,  1.1126,  0.6713,  0.0712,\n",
      "         0.9583,  1.6008,  0.9776,  0.6890,  1.2003,  1.2455,  0.9052,  1.1612,\n",
      "         1.0945,  1.0223,  1.8711,  0.8566,  1.8974,  1.4639,  1.4477,  0.5070,\n",
      "         1.2921,  1.7787,  1.2026,  1.1431,  0.9988,  1.7183,  2.0453,  2.0602,\n",
      "         0.8048, -0.1077,  0.8319,  0.8389,  1.3958,  1.4443,  1.0025,  1.1158,\n",
      "         1.8349,  1.3539,  1.7266,  1.9502,  1.9062,  1.1993,  1.2862,  1.3823,\n",
      "         1.9542,  2.2093,  0.9801,  1.2564,  1.6884,  1.0943,  1.1403,  1.1143,\n",
      "         1.2933,  1.2537,  1.1038,  0.6374,  0.4669,  1.7467,  0.9383,  1.1435,\n",
      "         1.5590,  1.1781,  2.2383,  1.3032,  1.6924,  0.6036,  1.2264,  2.7149,\n",
      "         1.6346,  2.1508,  1.5899,  0.9430,  0.9977,  1.1855,  1.4940,  1.9288,\n",
      "         2.8634,  1.3915,  1.7634,  1.8819,  0.8738,  1.5294,  1.4439,  1.0304,\n",
      "         0.2682,  0.8452,  2.2658,  1.5172,  0.7441,  1.5794,  1.5583,  1.9445,\n",
      "         0.6916,  1.5296,  1.9332,  0.9775,  1.6716,  1.5233,  0.8736,  1.4535,\n",
      "         1.1868,  1.5363,  1.3830,  1.3187,  1.3715,  2.2291,  1.7742,  1.5201,\n",
      "         1.3125,  2.8544,  1.4075,  2.3360,  1.3651,  1.1297,  1.5643,  0.9349,\n",
      "         1.6317,  2.2745,  1.4156,  1.2951,  1.5563,  0.7888,  0.8865,  1.1727,\n",
      "         1.0448,  1.1881,  2.8725,  0.8322,  1.1159,  2.0224,  1.9912,  1.0810,\n",
      "         1.3670,  0.4460,  1.3412,  1.4022,  1.4572,  1.8686,  1.2558,  1.5469,\n",
      "         1.2486,  0.5556,  1.7111,  1.3538,  3.1647,  0.6482,  1.2519,  2.2660,\n",
      "         1.7187,  1.7360,  2.1175,  1.5459,  1.5314,  1.7109,  1.7605,  1.2642,\n",
      "         0.8968,  0.7570,  1.9265,  1.1679,  1.6747,  1.4457,  0.8774,  2.2396,\n",
      "         1.3430,  2.0995,  0.6228,  1.6806,  1.1555,  1.0552,  1.6615,  1.0869,\n",
      "         2.3747,  1.8449,  1.2829,  1.9628,  2.1266,  3.2848,  1.6404,  0.4418,\n",
      "         0.9914,  0.8802,  1.1979,  1.8899,  1.4575,  1.2857,  0.6100,  2.1578,\n",
      "         2.5368,  1.1339,  1.4911,  0.9352,  1.2866,  1.5090,  0.4511,  0.8304,\n",
      "         0.9354,  2.2827,  0.8630,  1.2773,  1.5515,  2.8836,  0.9661,  1.4479,\n",
      "         0.5689,  1.5693,  1.2359,  1.4877,  1.5536,  0.5062,  1.5912,  2.2718,\n",
      "         0.5161,  1.4124,  1.9185,  0.8174,  1.5242,  1.6734,  2.7247,  0.5803,\n",
      "         0.9596,  1.3438,  1.4192,  1.6212,  1.2755,  0.8633,  0.9287,  2.1874,\n",
      "         1.1294,  1.8084,  1.6964,  0.5905,  1.2575,  1.4009,  2.0204,  1.5690,\n",
      "         1.9386,  2.1573,  1.3402,  2.4256,  1.9865,  1.2692,  1.1118,  1.4049,\n",
      "         1.0101,  1.3847,  0.5260,  1.3382,  0.8371,  1.1788,  1.3811,  0.8481,\n",
      "         1.4538,  1.2352,  1.2652,  1.8086,  0.7595,  0.9923,  1.3892,  3.8297,\n",
      "         1.1584,  2.1577,  1.6231,  0.8679,  1.6194,  1.2377,  1.3783,  2.1087,\n",
      "         2.0527,  3.2597,  1.6203,  0.7313,  0.5550,  1.7292,  1.4917,  1.0670,\n",
      "         1.5120,  1.6530,  0.7087,  1.9567,  1.5644,  1.2528,  1.4150,  1.8734,\n",
      "         1.1823,  1.8317,  1.4561,  1.0813,  1.7637,  2.0139,  0.8914,  2.0962,\n",
      "         1.2405,  1.2060,  0.7723,  1.3136,  1.5916,  0.3814,  1.1240,  1.5370,\n",
      "         1.3999,  1.3263,  1.2490,  1.2635,  1.0567,  0.8690,  0.6496,  2.2376,\n",
      "         1.4889,  0.8120,  2.6726,  2.0562,  2.2579,  1.4941,  1.8327,  1.2566,\n",
      "         1.9284,  2.1567,  2.8654,  0.9353,  1.5789,  2.0941,  2.9393,  1.6709,\n",
      "         3.8594,  1.5862,  2.7235,  1.2319,  1.6969,  1.0102,  1.2528,  0.8516,\n",
      "         1.4704,  1.4594,  1.8796,  0.3725,  1.4902,  1.2878,  1.8250,  1.2859,\n",
      "         1.0838,  1.4473,  1.3796,  1.2708,  1.4114,  0.9963,  2.7923,  1.6854,\n",
      "         1.7708,  1.7513,  0.7838,  1.4024,  2.3276,  1.3140,  1.7136,  1.5042,\n",
      "         1.0713,  0.7382,  0.8485,  1.2838,  0.7766,  2.3058,  0.9324,  1.8106,\n",
      "         0.1081,  1.7654,  1.1055,  0.6643,  0.9001,  1.4566,  1.5825,  0.9176,\n",
      "         1.5771,  1.6988,  2.2002,  1.4048,  1.3339,  1.6213,  1.0120,  1.5680,\n",
      "         0.6827,  1.1563,  1.0522,  2.0826,  1.2650,  0.5047,  1.1951,  1.1337,\n",
      "         1.7043,  1.5418,  1.5264,  1.5594,  0.8921,  0.9244,  0.5725,  1.2545,\n",
      "         1.3399,  2.9970,  1.1690,  1.8206,  1.5137,  1.7757,  1.0417,  1.3828,\n",
      "         1.4701,  1.7356,  1.3136,  1.4124,  1.5426,  3.4762,  1.5848,  1.1797,\n",
      "         1.5554,  0.6362,  1.2647,  1.2018,  2.2718,  0.9964,  0.4525,  0.8894,\n",
      "         1.0188,  1.6184,  2.1374,  3.3492,  1.7602,  1.0787,  1.3005,  1.5224,\n",
      "         1.6905,  1.4792,  0.1553,  1.5010,  1.4502,  0.0835,  0.5556,  1.8103,\n",
      "         1.4022,  1.7846,  1.6789,  1.1041,  1.1122,  1.3808,  0.8523,  0.6410,\n",
      "         1.1498,  0.9106,  2.3861,  1.8099,  1.8730,  1.3999,  1.5157,  0.8470,\n",
      "         1.0496,  1.0181,  0.6639,  1.2345,  3.3082,  1.5640,  0.5627,  1.0715,\n",
      "         1.9069,  0.7820,  1.6686,  0.9167,  0.5408,  1.3987,  1.3257,  1.3251,\n",
      "         1.4049,  1.8376,  1.8921,  1.9783,  1.1138,  1.2617,  2.0144,  2.1843,\n",
      "         1.3970,  1.3224,  1.2727,  1.5847,  2.0168,  1.3210,  1.2468,  3.1452,\n",
      "         0.6108,  1.4765,  1.4927,  1.2034,  1.7500,  0.7646,  1.9853,  1.1210,\n",
      "         0.9426,  1.8416,  1.1852,  1.5383,  1.2114,  1.2497,  0.9814,  1.4982,\n",
      "         0.6653,  1.1235,  0.3109,  1.8562,  1.4208,  1.0821,  1.7667,  1.6211,\n",
      "         1.4197,  1.9096,  1.0396,  1.1963,  1.1636,  0.9786,  0.3542,  1.2996,\n",
      "         1.3131,  1.6197,  1.0274,  0.5622,  1.1304,  0.8524,  1.0621,  2.2556,\n",
      "         2.3979,  1.8488,  1.7726,  0.2141,  2.6372,  1.1880,  1.1473,  1.0340,\n",
      "         3.3213,  2.2147,  0.8648,  1.4102,  2.1031,  0.6211,  1.4950,  1.8538,\n",
      "         0.7891,  1.4341,  1.6778,  1.1481,  2.2279,  0.5516,  1.0244,  1.0881,\n",
      "         1.6572,  1.4234,  2.3244,  1.7129,  1.8465,  1.4762,  0.9295,  1.4234,\n",
      "         1.3115,  1.1241,  1.2609,  1.3274,  1.5515,  0.9653,  2.0712,  1.9256,\n",
      "         0.8862,  1.5585,  1.0303,  1.4203,  1.1381,  0.8852,  1.0453,  0.5229,\n",
      "         0.6689,  1.1118,  1.6840,  1.8385,  1.6953,  1.5256,  0.7122,  1.7845,\n",
      "         2.4221,  2.3049,  1.7378,  1.4505,  1.7682,  0.8332,  1.2615,  1.5777,\n",
      "         3.2179,  1.0157,  2.0462,  1.8108,  2.9022,  0.7422,  1.0893,  1.3740,\n",
      "         1.3882,  1.6507,  1.4802,  1.2089,  1.0386,  2.3095,  1.5278,  1.9555,\n",
      "         1.6202,  1.3732,  1.8438,  1.5499,  2.3353,  1.0355,  1.0994,  0.8787,\n",
      "         0.9300,  1.1330,  1.2640,  0.9556,  1.7290,  0.9745,  0.8556,  2.1413,\n",
      "         2.0081,  1.0871,  0.7951,  1.5780,  1.6377,  1.8428,  1.0406,  1.4504,\n",
      "         0.6841,  1.3302,  1.7700,  1.4364,  1.6797,  0.6804,  1.4692,  1.2131,\n",
      "         1.4685,  1.5068,  1.3672,  1.1256,  0.8817,  1.0737,  2.3085,  0.8942,\n",
      "         1.4852,  2.4339,  1.5256,  1.4570,  1.6207,  0.3025,  0.9759,  0.7580,\n",
      "         0.6371,  2.2971,  0.5465,  1.5490,  1.7952,  2.8673,  0.9062,  2.4735,\n",
      "         1.4101,  1.5194,  1.1429,  0.8798,  1.4189,  0.6288,  1.1074,  1.2968,\n",
      "         2.0879,  1.2123,  2.4826,  0.9217,  1.5107,  1.5636,  1.5221,  1.7686,\n",
      "         0.7020,  1.2156,  2.4716,  1.5261,  1.3102,  0.8222,  1.0911,  0.6798,\n",
      "         1.5167,  0.7447,  2.1081,  1.4339,  1.1169,  1.2839,  1.7455,  2.1430],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.4513e+00, -1.6410e+00, -5.7595e-01, -5.0975e-01, -7.2280e-01,\n",
      "        -1.0173e+00, -1.4786e+00,  8.3264e-04, -4.2932e-01, -5.9205e-01,\n",
      "        -5.2257e-01, -9.2364e-01, -1.2621e+00, -2.2597e+00, -9.4360e-01,\n",
      "        -8.4927e-01, -3.8313e+00, -1.0091e+00, -2.1398e+00, -2.3707e+00,\n",
      "        -1.7191e+00, -1.4510e+00, -1.0620e-01, -8.4304e-01, -3.6057e-01,\n",
      "        -3.3070e-01, -9.4314e-01, -1.0755e+00, -9.4749e-01, -5.2754e-01,\n",
      "        -3.3160e-01, -1.4872e+00, -1.3683e+00, -3.1800e-01, -1.3293e-01,\n",
      "        -1.7031e+00, -1.8807e+00, -1.1454e+00, -1.3345e+00, -1.2964e-01,\n",
      "        -1.5181e+00, -2.6048e+00, -1.1014e+00, -1.5146e+00,  6.5581e-02,\n",
      "        -8.3862e-01, -7.7510e-01, -5.0443e-01, -3.5106e-01, -1.9123e+00,\n",
      "        -6.7609e-01, -3.6807e-01, -1.7375e+00, -1.5131e+00, -4.1883e-01,\n",
      "        -8.7157e-01, -1.3585e-01, -1.6313e-02, -1.1359e+00, -1.8282e+00,\n",
      "        -3.8954e-01, -1.0592e+00, -1.7744e+00, -1.5203e+00, -5.2370e-01,\n",
      "        -7.9363e-01, -1.3007e+00, -9.5518e-01, -1.6290e+00, -7.4924e-01,\n",
      "        -2.6736e+00, -8.0415e-01, -5.3976e-02, -1.0967e+00, -1.0041e+00,\n",
      "        -1.2694e+00, -1.3302e+00, -2.4254e+00, -7.8006e-01, -2.2688e+00,\n",
      "        -2.0864e+00, -6.1166e-01, -2.0633e-01, -1.0305e+00, -1.0005e+00,\n",
      "        -3.2591e-02, -4.3941e-01, -1.1059e+00, -2.6911e-01,  4.6375e-01,\n",
      "         3.3059e-02, -2.3960e+00, -1.6631e-01, -1.8923e-01,  2.9842e-01,\n",
      "        -4.3633e-01, -2.3129e+00, -1.2788e+00, -1.9632e+00, -2.7641e+00,\n",
      "        -9.2787e-01, -2.0568e-01, -7.9166e-01, -4.3945e-01, -5.7735e-03,\n",
      "        -1.3196e+00, -5.3920e-02, -1.9149e-01, -8.5884e-01, -2.0139e-02,\n",
      "        -2.4241e-01, -8.9731e-01, -7.0157e-01, -3.8730e-01, -6.6158e-01,\n",
      "        -3.2530e-01, -4.0072e-01, -1.2217e+00, -8.7357e-01, -6.1054e-01,\n",
      "        -1.9915e-01, -1.4642e+00, -1.4541e+00, -8.5673e-01, -3.7995e-01,\n",
      "        -2.1474e+00, -1.8616e-01, -3.3716e-01, -4.9587e-02, -1.0340e+00,\n",
      "        -5.3930e-01, -3.4346e-02, -1.9262e-01, -6.2505e-01, -1.4154e-01,\n",
      "         4.1854e-02, -8.5541e-01, -1.7768e-01, -6.0590e-01, -2.6555e-01,\n",
      "        -1.8803e+00, -1.4536e+00, -3.2061e-01,  1.5161e-01, -7.6620e-01,\n",
      "        -5.1907e-01, -3.4683e-01, -3.9439e-01, -2.4910e-01, -1.6352e+00,\n",
      "        -1.0150e+00, -1.8913e+00, -1.0281e-01,  7.1064e-02, -5.9973e-01,\n",
      "        -6.5606e-01, -1.5822e+00, -2.0620e+00, -2.6529e-01, -7.4738e-01,\n",
      "        -1.3173e+00, -1.9759e+00, -1.3126e+00, -1.4730e+00, -1.5376e+00,\n",
      "        -2.3300e-01, -9.4093e-01, -1.3062e+00, -3.0564e+00, -4.0683e-01,\n",
      "        -6.7182e-01, -7.9896e-01, -5.4952e-01, -1.0867e+00, -8.8183e-01,\n",
      "        -1.3002e+00, -8.4944e-02, -6.2329e-01, -2.4106e-01, -1.6774e-01,\n",
      "         7.3700e-01, -1.5404e+00, -1.6717e+00, -4.7713e-01, -2.2109e+00,\n",
      "        -8.7012e-01, -7.1990e-01, -1.2748e+00, -1.8871e+00, -1.8246e-01,\n",
      "        -2.7368e+00, -6.0214e-01, -1.0935e+00, -1.0706e+00, -1.9590e+00,\n",
      "        -1.3809e-01, -7.2652e-01, -6.3541e-01, -1.2185e+00, -5.0157e-01,\n",
      "        -9.1761e-01, -1.7198e-02, -1.5520e+00, -6.1770e-01, -1.8709e-01,\n",
      "        -1.5927e+00, -5.6383e-01,  1.1727e-01,  3.3649e-02, -1.9467e+00,\n",
      "        -1.5550e+00, -9.0279e-01,  1.6423e-01, -1.3927e+00, -7.8719e-01,\n",
      "        -6.2715e-01, -3.7453e-01, -1.4761e+00, -1.7692e+00, -1.2260e+00,\n",
      "        -1.7457e+00, -1.2728e+00, -6.0119e-01, -1.9086e+00, -7.1883e-01,\n",
      "        -3.0538e+00, -1.0458e+00, -5.6236e-01, -9.1212e-01, -4.8184e-01,\n",
      "        -2.0891e+00, -1.4393e+00, -1.2222e+00,  2.8953e-02, -9.8353e-01,\n",
      "        -9.6857e-01, -8.1298e-01, -1.0081e+00, -2.7563e+00,  2.8148e-02,\n",
      "        -9.1372e-01, -4.5448e-01, -1.0441e+00, -1.2392e+00, -2.0602e+00,\n",
      "        -1.5419e-01, -1.4005e-01, -3.7963e-01, -3.4844e+00, -1.1807e+00,\n",
      "        -1.5180e+00, -4.0187e-01, -6.8138e-01,  3.8996e-01, -1.2515e+00,\n",
      "        -2.3889e+00, -9.5927e-01, -1.9741e-01, -4.9241e-01, -8.2199e-01,\n",
      "        -1.8463e+00, -8.1030e-01, -1.6937e+00, -1.8036e+00, -2.2689e+00,\n",
      "        -2.6280e-01, -1.9482e+00, -1.0236e+00, -3.2194e-01, -2.7877e-01,\n",
      "        -2.2977e-01, -2.3408e-01, -9.8895e-01, -1.1343e+00, -1.5781e+00,\n",
      "        -2.6668e-01, -1.8062e-01, -1.3051e+00, -5.5231e-01, -1.6067e+00,\n",
      "         1.9626e-01, -9.9842e-02, -1.7087e+00, -1.6266e+00, -1.5246e+00,\n",
      "        -8.9347e-01,  3.9195e-02, -1.2434e+00, -9.2021e-01, -1.4080e+00,\n",
      "        -1.1565e-01, -1.2672e+00, -2.8152e-01, -1.6903e-01, -7.5815e-01,\n",
      "        -1.4690e+00, -2.2648e+00, -6.1304e-02, -1.9680e+00, -6.3397e-01,\n",
      "        -1.6088e+00,  7.3809e-01, -1.2724e+00, -1.9293e-01, -1.1402e+00,\n",
      "        -5.0924e-01, -2.2669e+00,  4.1155e-01, -1.4535e+00, -1.0639e+00,\n",
      "        -3.5275e-01, -1.9749e+00, -2.0218e+00, -4.6387e-01, -2.3845e-01,\n",
      "        -4.2095e-01, -6.2276e-01, -1.1389e+00,  4.2098e-01, -5.3643e-01,\n",
      "        -4.8972e-01, -4.6412e-01, -6.5960e-01, -1.3902e+00, -1.6140e+00,\n",
      "        -6.1494e-01,  6.6702e-01, -1.4593e+00, -6.8092e-01, -1.1733e+00,\n",
      "         3.6330e-01, -1.8803e+00, -6.0596e-01,  3.3962e-02, -1.2262e+00,\n",
      "        -1.3985e+00,  1.8178e-01, -8.1753e-01, -1.3325e+00,  4.9693e-01,\n",
      "        -2.0767e+00, -1.3081e+00, -4.9818e-01, -3.4452e-01, -4.2002e-01,\n",
      "        -2.1504e-01, -2.0921e+00, -9.6201e-01, -5.2277e-01,  1.7334e-01,\n",
      "        -4.0913e-01, -1.6700e+00, -1.6529e-01, -2.5349e-01, -1.1652e+00,\n",
      "         1.1191e-01, -7.8677e-01, -4.9737e-01, -1.8604e+00, -7.6865e-01,\n",
      "        -4.2213e-01, -5.6170e-01,  2.8948e-01, -1.2350e+00, -1.8515e+00,\n",
      "        -1.7901e+00, -8.7861e-01, -1.0197e+00, -1.0942e-01, -6.7098e-01,\n",
      "         6.8177e-02, -1.2908e+00,  4.4121e-02, -4.2297e-01, -5.2631e-01,\n",
      "        -1.4063e-01, -1.7090e+00, -1.6271e+00, -2.1721e-01, -1.1006e+00,\n",
      "         5.8453e-01,  1.6105e-01, -1.8759e+00, -4.0462e-01,  5.0226e-01,\n",
      "        -1.0507e+00, -1.3730e+00, -3.5910e-01, -3.2949e-01, -1.0037e+00,\n",
      "        -1.2218e+00, -1.1394e+00, -1.5956e+00, -2.0555e-01, -4.5628e-01,\n",
      "        -3.4751e-01, -1.6937e-01, -2.8778e-01, -1.9306e+00, -3.5105e-01,\n",
      "        -1.5145e+00, -6.4027e-01, -1.3942e-01, -1.1047e+00, -2.3723e+00,\n",
      "        -3.0881e-01, -1.3776e+00, -9.2990e-01, -6.4334e-01, -1.1225e+00,\n",
      "        -5.0621e-01, -2.3280e+00, -1.7049e+00, -1.2170e+00, -5.9809e-01,\n",
      "        -1.6469e+00, -1.2578e+00, -7.1546e-01, -3.8107e-02, -4.0769e-01,\n",
      "        -1.0214e+00, -1.9531e-01, -4.8933e-01, -5.6889e-01, -8.1141e-03,\n",
      "         5.5739e-01, -2.2965e+00, -1.6899e+00, -6.7177e-01, -9.8737e-02,\n",
      "        -3.3114e-01, -1.8600e+00, -6.8624e-01, -3.8382e-01,  2.8857e-01,\n",
      "        -1.0253e+00, -1.5737e+00, -1.6229e+00, -3.7700e-01, -2.0935e+00,\n",
      "        -2.6970e+00, -1.5614e+00, -6.9896e-01, -5.3708e-01, -2.6307e+00,\n",
      "        -1.2286e+00, -2.4692e+00, -2.1364e+00,  9.2272e-01, -1.2356e+00,\n",
      "        -1.1905e+00, -1.3283e+00, -7.4355e-01, -1.2786e-01, -5.1297e-01,\n",
      "        -2.5441e-01, -1.8273e+00, -2.6500e+00, -8.3813e-01,  1.1885e-01,\n",
      "        -4.7457e-01, -1.5911e+00, -1.7390e+00, -2.0760e+00, -4.0769e-01,\n",
      "        -1.8133e+00, -2.4656e-01, -9.8553e-01, -4.7306e-01, -5.3581e-01,\n",
      "        -3.3680e-01, -1.5455e+00, -1.1615e+00,  5.3831e-01, -2.0542e-01,\n",
      "         2.2276e-01, -1.2281e+00,  1.9882e-01, -1.9678e+00, -1.4385e+00,\n",
      "        -4.5161e-01,  3.0732e-03, -3.5935e-01, -1.0477e+00,  1.2774e-02,\n",
      "        -1.1998e+00, -1.2711e-01, -1.9423e+00, -7.8693e-02, -4.2373e-01,\n",
      "        -7.6135e-01, -6.0647e-01, -8.4896e-01, -7.5715e-01, -2.5004e+00,\n",
      "        -9.8711e-01, -1.4619e+00, -1.9796e+00,  4.4370e-02, -1.1480e+00,\n",
      "        -2.3015e+00, -1.8167e+00, -1.4815e-01, -3.1383e+00, -3.5179e-01,\n",
      "        -6.8055e-01, -6.8898e-01,  1.0689e-01, -6.5165e-01,  9.7357e-02,\n",
      "        -1.9695e+00, -2.2074e+00, -1.7304e+00, -1.0343e+00, -8.4677e-01,\n",
      "        -1.3098e+00, -3.7579e-01, -5.9477e-01, -3.4740e-01, -2.6542e+00,\n",
      "        -9.8239e-01, -3.8080e-01, -7.7925e-01, -8.2933e-01, -1.4951e+00,\n",
      "        -1.3659e+00, -5.8289e-01, -3.7400e-01, -1.9957e-01, -1.2584e+00,\n",
      "        -2.1371e-01, -6.4680e-01, -7.3889e-01, -4.1136e-01, -8.6487e-01,\n",
      "        -3.1621e-01, -1.4668e+00, -5.5090e-02, -1.5482e+00, -6.3566e-01,\n",
      "        -7.3822e-01, -6.3954e-01,  4.6789e-03, -3.7208e-01, -4.8882e-01,\n",
      "        -2.6926e+00, -1.3473e+00,  3.2359e-01, -1.1295e+00, -3.6385e-01,\n",
      "        -1.2261e+00, -1.3948e+00, -1.6274e+00, -2.2031e-01, -2.7408e-01,\n",
      "        -1.2401e+00, -5.2629e-01,  1.1009e-01, -5.3174e-01, -7.9705e-01,\n",
      "        -2.3525e+00, -1.4193e+00,  2.5293e-01, -8.6167e-01, -2.1128e-01,\n",
      "        -1.0776e+00, -5.0682e-01, -1.0794e-01, -3.8840e-01, -8.6297e-01,\n",
      "        -4.4919e-01, -7.4070e-01, -1.7617e+00, -6.4224e-01, -1.1641e+00,\n",
      "         9.9399e-02, -5.5988e-01, -8.2717e-01, -3.7187e-01, -2.3381e-01,\n",
      "        -1.2864e-01, -4.6791e-01, -2.6423e-01, -1.1903e-01, -1.0508e+00,\n",
      "        -4.9171e-01, -5.7753e-01, -2.7380e-01, -1.5601e+00, -1.1402e+00,\n",
      "        -3.9834e-01, -1.3515e+00, -1.0549e+00, -6.6455e-01, -1.4773e+00,\n",
      "        -3.2870e-01, -4.1006e-01, -6.9107e-01, -1.1155e+00, -1.7903e+00,\n",
      "        -8.9466e-01, -1.7614e+00, -2.0385e+00, -6.6957e-01, -3.6525e-01,\n",
      "        -1.3447e+00, -8.2209e-01,  4.0870e-01, -3.6687e-01, -1.5224e+00,\n",
      "        -1.5779e+00, -5.0377e-01, -2.0824e+00, -4.7160e-01, -1.1411e+00,\n",
      "        -8.2819e-01, -6.5386e-01, -2.6688e+00, -5.3072e-01, -8.8178e-01,\n",
      "        -5.0273e-01, -8.3441e-01, -4.3060e-01, -1.0386e+00,  5.4691e-02,\n",
      "        -3.4553e-01,  4.1198e-01, -5.1934e-01, -1.6288e+00, -6.6493e-01,\n",
      "        -1.1756e+00, -9.4481e-01, -2.0789e+00, -1.4466e+00, -8.4063e-01,\n",
      "        -1.8760e-01, -1.1319e+00, -4.9978e-01, -5.0410e-02, -6.3851e-01,\n",
      "        -4.1016e-01, -1.9031e+00, -4.9990e-01, -3.2912e-01, -9.8262e-01,\n",
      "         6.9284e-01, -4.5217e-01, -1.7323e+00,  2.7538e-01, -1.7757e+00,\n",
      "        -1.7028e+00,  3.4801e-02, -3.0362e+00, -2.8484e-01, -2.9556e-01,\n",
      "         1.1756e-01, -2.4357e-01, -3.1011e-01, -5.0186e-01, -1.1674e+00,\n",
      "        -5.6559e-01, -3.7194e-01, -1.7930e+00, -8.3376e-01, -8.0925e-01,\n",
      "        -4.5017e-01, -2.0004e+00, -4.3181e-01, -1.5216e+00, -9.1901e-02,\n",
      "        -6.1349e-01, -9.1854e-01, -2.9872e+00, -9.5240e-01, -6.8507e-01,\n",
      "        -2.0825e+00, -9.5656e-01, -1.4631e+00, -6.1837e-01, -7.6100e-01,\n",
      "        -1.5355e+00, -8.0577e-01, -2.9463e+00, -1.9975e+00,  3.6599e-03,\n",
      "        -4.3472e-01, -2.9993e-01, -1.3486e+00, -2.6127e-01, -1.4698e+00,\n",
      "        -3.0938e-01, -6.7162e-01, -8.1399e-01,  4.2686e-01, -7.6774e-01,\n",
      "        -2.9789e-01, -1.8962e+00,  2.9791e-01, -1.3839e+00, -1.4356e+00,\n",
      "        -1.3049e+00, -1.0064e+00, -9.1044e-01, -9.9951e-01, -7.9858e-01,\n",
      "        -1.3160e+00, -1.4491e+00, -1.0740e+00, -1.3043e+00, -5.7232e-01,\n",
      "        -1.4732e+00,  1.7111e-01,  5.9542e-01, -7.2378e-01,  4.6111e-01,\n",
      "        -9.9607e-01, -3.4980e-01, -2.3067e-02, -2.6709e+00, -1.3097e+00,\n",
      "        -5.5174e-01, -1.2464e+00, -2.0461e+00, -1.1333e+00,  5.8308e-01,\n",
      "        -1.0876e+00, -8.6728e-01, -2.6347e-01, -2.9672e-01, -1.3904e+00,\n",
      "        -1.9323e+00, -7.9710e-01, -9.0613e-01, -4.8711e-01,  4.2452e-03,\n",
      "         2.9333e-01,  4.1274e-01, -1.1192e+00, -4.6507e-01, -1.8242e-01,\n",
      "        -2.9850e-01, -6.4556e-01, -2.8388e-01, -8.2916e-02, -3.4681e-01,\n",
      "        -6.9671e-01,  3.7124e-02, -1.9935e+00, -5.4371e-01, -2.4176e+00,\n",
      "        -5.1178e-01, -1.4948e-01, -9.9653e-02, -6.5841e-01, -1.3399e+00,\n",
      "        -1.5905e+00, -6.8421e-01, -3.4218e-02, -4.3765e-01,  3.2261e-01,\n",
      "        -7.0525e-01, -1.7846e+00, -2.2417e+00, -5.1853e-01,  7.2151e-02,\n",
      "        -8.5713e-01, -8.1862e-01, -5.9258e-01, -1.5013e+00, -1.0951e+00,\n",
      "        -1.7845e+00, -1.4054e+00, -6.4636e-01, -3.3804e-01, -4.1082e-01,\n",
      "        -2.7696e-01, -5.9188e-02, -6.8689e-01, -5.7107e-01, -9.1657e-01,\n",
      "        -9.9771e-01,  3.0501e-01, -8.8181e-02, -2.1319e-01, -1.2449e+00,\n",
      "        -2.4286e+00, -5.9049e-01,  1.0662e-01, -9.8871e-01, -2.2478e-01,\n",
      "        -8.8011e-01, -1.2705e+00, -1.8612e+00, -1.7491e+00, -1.6043e+00,\n",
      "        -1.8726e-01, -1.8088e+00, -1.4334e+00, -1.9084e+00, -1.4095e+00,\n",
      "        -1.2909e-01, -1.8091e+00,  8.7738e-02, -2.8195e+00, -1.8411e+00,\n",
      "        -3.3161e-01, -6.8406e-01, -3.6038e-01, -6.5126e-01, -4.2170e-01,\n",
      "        -1.0026e+00,  1.4177e-01, -4.4251e-01, -2.6380e+00, -1.6515e+00,\n",
      "        -1.3522e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2493]],\n",
      "\n",
      "         [[-0.3268]],\n",
      "\n",
      "         [[-0.1821]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0542]],\n",
      "\n",
      "         [[-0.1376]],\n",
      "\n",
      "         [[-0.1202]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1579]],\n",
      "\n",
      "         [[-0.0261]],\n",
      "\n",
      "         [[ 0.0277]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1360]],\n",
      "\n",
      "         [[ 0.1545]],\n",
      "\n",
      "         [[-0.6527]]],\n",
      "\n",
      "\n",
      "        [[[-0.5735]],\n",
      "\n",
      "         [[-0.1192]],\n",
      "\n",
      "         [[-0.2233]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4763]],\n",
      "\n",
      "         [[-0.6064]],\n",
      "\n",
      "         [[-0.2577]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3362]],\n",
      "\n",
      "         [[ 0.4420]],\n",
      "\n",
      "         [[ 0.2639]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0466]],\n",
      "\n",
      "         [[-0.0183]],\n",
      "\n",
      "         [[ 0.8360]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0799]],\n",
      "\n",
      "         [[-0.0082]],\n",
      "\n",
      "         [[ 0.0014]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0928]],\n",
      "\n",
      "         [[ 0.4391]],\n",
      "\n",
      "         [[-0.5958]]],\n",
      "\n",
      "\n",
      "        [[[-0.3721]],\n",
      "\n",
      "         [[-0.4964]],\n",
      "\n",
      "         [[-0.1030]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2485]],\n",
      "\n",
      "         [[-0.1573]],\n",
      "\n",
      "         [[-0.1775]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.2198, -0.2327,  0.3812, -0.0574, -0.1435, -0.0733, -0.2564, -0.2335,\n",
      "         0.1720,  0.0587,  0.0151,  0.0773,  0.1731,  0.0005, -0.3335,  0.1135,\n",
      "         0.3463, -0.3852, -0.0973,  0.3788, -0.1185,  0.1213, -0.2174,  0.3087,\n",
      "        -0.2256,  0.0490, -0.2010, -0.1292, -0.1750, -0.2757, -0.3336, -0.1811,\n",
      "         0.1919,  0.2154], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2097]],\n",
      "\n",
      "         [[ 0.0507]],\n",
      "\n",
      "         [[ 0.1409]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1691]],\n",
      "\n",
      "         [[-0.2104]],\n",
      "\n",
      "         [[ 0.6414]]],\n",
      "\n",
      "\n",
      "        [[[-0.0578]],\n",
      "\n",
      "         [[-0.3256]],\n",
      "\n",
      "         [[-0.1626]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1135]],\n",
      "\n",
      "         [[-0.0211]],\n",
      "\n",
      "         [[-0.3113]]],\n",
      "\n",
      "\n",
      "        [[[-0.1518]],\n",
      "\n",
      "         [[-0.0814]],\n",
      "\n",
      "         [[-0.1334]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1417]],\n",
      "\n",
      "         [[-0.1348]],\n",
      "\n",
      "         [[-0.4030]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1453]],\n",
      "\n",
      "         [[-0.0823]],\n",
      "\n",
      "         [[-0.1963]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2110]],\n",
      "\n",
      "         [[-0.2076]],\n",
      "\n",
      "         [[-0.2464]]],\n",
      "\n",
      "\n",
      "        [[[-0.0593]],\n",
      "\n",
      "         [[-0.1287]],\n",
      "\n",
      "         [[-0.4501]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1501]],\n",
      "\n",
      "         [[-0.2566]],\n",
      "\n",
      "         [[-0.1169]]],\n",
      "\n",
      "\n",
      "        [[[-0.0043]],\n",
      "\n",
      "         [[ 0.1547]],\n",
      "\n",
      "         [[ 0.5391]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1181]],\n",
      "\n",
      "         [[ 0.0875]],\n",
      "\n",
      "         [[ 0.0401]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 3.0203e-01, -1.9860e-01, -3.5909e-01, -4.6243e-01, -3.1110e-01,\n",
      "         1.5248e-01,  2.3460e-01,  3.1582e-02,  1.5157e-01,  2.7359e-01,\n",
      "        -1.6952e-01,  3.7887e-01, -6.1055e-03, -2.9897e-01, -3.2466e-01,\n",
      "        -1.0610e-01, -3.3818e-01, -2.7073e-01, -1.3507e-01,  2.0911e-01,\n",
      "         3.7957e-01,  2.9604e-01, -3.3545e-01, -1.9167e-01,  1.0825e-01,\n",
      "         1.3044e-03, -5.9837e-02,  3.1494e-01,  8.6121e-02, -1.9686e-01,\n",
      "         3.4363e-02,  3.2460e-01, -3.3926e-01, -2.1187e-01,  5.5448e-02,\n",
      "        -1.0217e-01,  1.9915e-01,  3.9772e-01, -9.3534e-02,  3.3770e-01,\n",
      "         4.0097e-01,  3.1783e-01,  3.8987e-01, -8.2954e-02, -1.8546e-01,\n",
      "         3.2078e-01, -3.1317e-01,  9.6769e-02,  2.1183e-01,  3.2844e-01,\n",
      "         2.2786e-01, -1.5992e-01, -2.6960e-01,  2.0408e-01, -3.4181e-01,\n",
      "        -3.2741e-01, -1.8701e-01, -1.7995e-01,  2.0069e-01, -1.9485e-01,\n",
      "         1.0881e-01, -3.5409e-01,  1.0725e-01, -2.8938e-01,  2.8452e-01,\n",
      "        -2.9843e-01, -2.1065e-01,  1.5835e-01, -1.1672e-01, -2.9624e-01,\n",
      "         3.4573e-02,  3.7868e-01, -3.0885e-01, -4.0212e-01,  2.3792e-02,\n",
      "        -9.8424e-02, -2.4710e-01,  3.4633e-01, -3.3611e-01, -3.9003e-01,\n",
      "        -5.2197e-02,  2.5674e-01,  3.5976e-02, -2.6979e-01, -2.7672e-01,\n",
      "        -1.5554e-01, -3.3570e-01,  3.4356e-01,  2.4944e-01, -3.4007e-01,\n",
      "         4.0915e-01, -9.8124e-02,  2.9710e-01, -2.2680e-01,  3.1228e-01,\n",
      "        -2.5371e-01,  3.9122e-01,  3.7614e-01, -2.4623e-01,  3.7848e-01,\n",
      "         2.6233e-01, -5.9525e-03, -2.4495e-01, -1.7752e-01,  1.8681e-01,\n",
      "         2.2844e-01,  1.2286e-01,  2.8428e-01,  3.0950e-01, -7.4497e-02,\n",
      "         2.1810e-01, -3.7586e-01,  1.8606e-01,  5.2691e-01,  3.2437e-01,\n",
      "        -6.5796e-02, -9.2344e-02,  3.0700e-01, -5.3676e-02, -2.5539e-02,\n",
      "        -2.6735e-01, -2.9160e-01,  4.4717e-01, -2.9964e-01,  4.0086e-01,\n",
      "         5.0816e-01,  2.9095e-01,  4.1333e-01,  3.5673e-01, -2.7938e-01,\n",
      "         3.1787e-01,  3.5621e-01, -1.3059e-01, -1.3697e-02,  9.2599e-02,\n",
      "        -5.7321e-03, -3.4948e-01,  3.4394e-01,  1.5512e-01,  4.0928e-01,\n",
      "         2.6674e-01, -3.0993e-01, -2.7882e-01, -1.8064e-01, -1.7819e-01,\n",
      "         3.2508e-02,  3.8749e-01, -3.9352e-02,  3.5123e-01, -2.7546e-01,\n",
      "         3.6946e-01,  1.3135e-02,  1.7890e-01, -3.4180e-01, -1.0580e-01,\n",
      "         4.6772e-01,  4.0678e-01,  1.8060e-01, -6.2915e-02, -1.3039e-01,\n",
      "        -6.8638e-02, -1.8476e-01, -6.5098e-02,  1.9380e-01, -6.8526e-02,\n",
      "        -1.5613e-02, -3.2783e-01,  3.1324e-02,  1.7844e-01, -2.5779e-01,\n",
      "         2.8879e-01, -9.4653e-02, -2.9867e-01,  6.8708e-02, -2.2395e-01,\n",
      "         1.4725e-01, -1.4574e-01,  2.7005e-01,  4.3145e-02, -1.6087e-01,\n",
      "        -7.7898e-02, -2.7896e-01,  1.2281e-01, -2.4322e-02,  1.6658e-01,\n",
      "         2.9819e-01,  2.0790e-01,  1.6344e-01,  3.2726e-01, -2.3725e-01,\n",
      "        -1.0119e-01, -2.6386e-01,  2.6723e-01,  2.6410e-01,  4.1869e-01,\n",
      "        -1.0985e-01, -2.2953e-01,  1.6357e-01, -2.5579e-01, -1.4848e-01,\n",
      "        -2.9005e-01,  2.7502e-01, -3.4906e-02, -2.8950e-01,  2.3154e-01,\n",
      "        -2.9715e-01,  2.4027e-01,  4.0599e-01, -2.0048e-01, -2.5269e-01,\n",
      "         1.2744e-01, -2.2659e-01, -1.8503e-01,  1.1061e-01, -3.3908e-01,\n",
      "        -1.2523e-01, -3.5300e-01, -3.2058e-02,  3.2905e-01,  1.0482e-01,\n",
      "         2.2139e-01,  6.8782e-02, -2.4059e-01, -6.8129e-02,  2.6613e-02,\n",
      "        -4.0069e-01, -2.7599e-01,  2.8055e-01, -3.1595e-01,  2.2953e-01,\n",
      "         1.5770e-01, -2.5063e-01, -2.8975e-01, -3.2395e-01, -8.8193e-02,\n",
      "         2.6062e-01, -2.5575e-01, -2.8876e-01,  1.4058e-01,  2.7032e-01,\n",
      "        -2.3799e-01,  3.3358e-01,  3.3023e-01,  2.5160e-01,  1.8576e-01,\n",
      "        -4.3425e-01,  2.8846e-01, -1.9920e-01,  1.7530e-02, -6.4019e-02,\n",
      "         2.3512e-02, -3.3821e-01, -1.8616e-01, -1.9541e-01,  1.9402e-01,\n",
      "        -2.7949e-01, -6.3009e-02,  5.3017e-02,  1.2046e-01,  9.6989e-02,\n",
      "         3.8956e-01, -1.4792e-01, -2.5084e-01, -1.8896e-01,  1.9193e-01,\n",
      "        -3.0597e-01, -2.1194e-01, -2.7872e-01,  3.8441e-01,  3.0559e-01,\n",
      "         2.8204e-01, -3.5247e-01, -3.0239e-01,  2.2642e-01, -2.8773e-03,\n",
      "        -2.1349e-01, -2.6136e-01,  3.0076e-01, -3.4143e-01, -1.1205e-02,\n",
      "         3.0173e-01, -2.7581e-01, -3.1579e-01,  2.8436e-01, -5.9981e-02,\n",
      "         3.6942e-01, -3.5124e-01,  2.5842e-01,  1.1914e-01, -1.3935e-01,\n",
      "         2.6802e-01, -2.7523e-01, -7.7376e-02, -3.0760e-01,  2.2020e-01,\n",
      "        -1.0728e-01,  3.2251e-01,  1.6721e-01, -2.5526e-01,  7.3761e-03,\n",
      "         2.8069e-01, -2.5166e-01, -1.7106e-02, -3.5069e-01,  3.3007e-01,\n",
      "        -2.6920e-01, -2.2139e-01,  4.1307e-01, -2.1103e-01,  6.5423e-02,\n",
      "         6.3152e-03,  3.0615e-01,  1.9632e-01,  7.4173e-02, -3.1533e-01,\n",
      "         1.0323e-01, -2.9869e-01, -1.3205e-01, -3.7256e-01, -1.7181e-01,\n",
      "        -2.9367e-01, -2.0712e-01, -1.7070e-01,  2.3223e-01,  2.6750e-01,\n",
      "        -1.0718e-04,  4.1009e-01,  1.8488e-01,  6.0709e-02,  1.5892e-01,\n",
      "         1.5451e-01, -2.9495e-01,  2.9041e-01, -3.0846e-01, -2.2834e-01,\n",
      "         2.6146e-01,  3.5067e-01, -2.9313e-01,  3.7603e-02, -2.0950e-02,\n",
      "         3.4925e-01,  3.8062e-01, -4.4965e-01, -2.6617e-01, -1.3786e-01,\n",
      "         3.2401e-01,  7.8027e-02,  2.7511e-01,  1.1464e-02,  1.2549e-01,\n",
      "        -3.0835e-01,  4.2854e-01,  2.8929e-01, -3.2899e-01, -2.6457e-01,\n",
      "         2.3886e-01,  8.4284e-02,  2.7387e-01, -1.6264e-01, -3.8234e-01,\n",
      "        -3.2743e-01,  1.1669e-01,  3.7925e-01,  3.9720e-01, -1.4267e-01,\n",
      "        -4.6047e-01,  2.6117e-01,  2.7966e-01,  2.9913e-01, -7.7857e-02,\n",
      "        -2.3136e-01,  2.1870e-01,  3.3188e-01,  1.6119e-01,  2.3021e-01,\n",
      "        -3.0711e-01, -3.2377e-01,  3.5121e-01,  2.8190e-01,  2.7431e-01,\n",
      "         1.9170e-01, -1.3400e-01,  2.2500e-01, -2.1526e-01,  4.6887e-01,\n",
      "         3.9204e-01,  7.6549e-04,  4.8108e-02,  2.2098e-01,  3.5459e-01,\n",
      "        -3.1746e-01, -1.8573e-01, -2.7819e-01, -3.0126e-01,  3.2460e-01,\n",
      "        -8.3918e-02, -2.5289e-01,  3.3405e-01,  2.9174e-01, -7.5016e-02,\n",
      "        -2.2441e-01,  3.6323e-01,  1.6960e-01, -3.4460e-01,  4.2674e-01,\n",
      "         3.4263e-01,  2.3561e-01, -7.5215e-02, -3.3920e-01,  3.6325e-01,\n",
      "         9.5236e-02,  9.1447e-02,  1.8985e-01, -1.3188e-01,  7.7369e-02,\n",
      "         3.1534e-01, -2.2688e-01,  2.4643e-01, -3.3377e-01,  2.7588e-01,\n",
      "         3.0962e-01,  2.9759e-01, -3.4218e-01, -2.5178e-01,  4.6955e-01,\n",
      "         5.1161e-01,  2.8544e-01, -3.5144e-01,  4.1844e-02,  3.8867e-01,\n",
      "        -8.1505e-02,  3.7843e-01, -3.2640e-01, -1.7889e-01, -3.0657e-01,\n",
      "         3.6751e-01,  2.9237e-01, -2.9659e-01, -2.4499e-01,  3.4888e-01,\n",
      "         4.0743e-01,  3.2347e-01, -2.6567e-01, -1.5629e-01,  7.1367e-02,\n",
      "        -1.0111e-01, -1.6771e-01,  3.2821e-01, -1.2495e-01,  2.5063e-01,\n",
      "        -1.1528e-01,  1.9524e-01,  3.5568e-01, -7.0415e-02, -2.9389e-01,\n",
      "         7.6212e-03,  2.3840e-01, -2.0335e-01,  3.0802e-02, -2.2596e-01,\n",
      "         3.4628e-01,  9.5955e-02,  5.1004e-02, -3.2501e-01,  2.0314e-01,\n",
      "        -4.7164e-02,  3.4884e-01, -2.8214e-01,  3.7558e-01,  3.2067e-02,\n",
      "        -1.7809e-01,  3.9565e-01,  2.9744e-01,  3.0103e-01, -2.3873e-01,\n",
      "        -1.9728e-01,  3.8778e-01,  3.0885e-01, -1.3490e-01, -3.9408e-01,\n",
      "         1.1781e-01,  2.3798e-01, -4.3282e-02, -3.6424e-01,  8.4219e-02,\n",
      "         1.0825e-01, -7.2755e-02,  3.0860e-01, -5.1028e-01,  3.6315e-01,\n",
      "         2.5562e-01,  3.1259e-01, -2.3987e-01, -2.6692e-01, -4.1542e-02,\n",
      "        -3.0999e-01, -2.6097e-01,  3.5734e-01, -2.9048e-01,  1.4174e-02,\n",
      "         4.2028e-01, -2.5003e-01,  3.5556e-01, -3.6709e-01, -2.7166e-01,\n",
      "        -2.7384e-01,  1.3832e-01,  3.3794e-03,  1.9096e-01, -1.2352e-02,\n",
      "         3.4578e-01, -2.5028e-01,  2.2798e-01, -3.5178e-01, -3.6199e-01,\n",
      "        -1.2604e-01, -2.7162e-01,  4.2933e-02, -2.9562e-01,  3.2124e-01,\n",
      "         1.9035e-01, -1.3774e-01,  2.5837e-01,  5.0491e-02, -1.1425e-01,\n",
      "         3.6532e-02, -1.4051e-01,  1.1159e-02, -3.5698e-01,  1.0406e-01,\n",
      "        -4.2191e-01,  3.2692e-01,  6.1944e-03, -2.2945e-01, -4.1157e-02,\n",
      "         3.4011e-01,  2.7871e-01, -1.0010e-02,  4.7135e-02, -3.7425e-01,\n",
      "        -3.3371e-01, -1.9119e-01, -3.2564e-01, -2.9515e-01, -3.5449e-01,\n",
      "         2.4410e-01,  4.3185e-01, -2.1977e-01, -3.0665e-01,  3.4610e-01,\n",
      "        -3.4043e-01,  2.1011e-01, -7.4728e-02, -4.1781e-01,  5.0174e-01,\n",
      "        -1.6210e-01, -2.2369e-01,  2.7626e-01,  3.7758e-01,  2.4780e-01,\n",
      "         2.1158e-01,  2.5377e-01,  3.1736e-01, -2.5886e-01,  1.2474e-01,\n",
      "         7.1731e-02, -3.2505e-01,  2.2417e-01,  4.0082e-01, -1.5306e-01,\n",
      "         1.7933e-01,  3.3661e-01,  2.9613e-01, -3.3561e-01, -4.0995e-01,\n",
      "        -3.5901e-01, -1.0467e-01, -2.9042e-01,  2.6530e-01,  2.8236e-01,\n",
      "        -1.6064e-01,  2.6399e-01,  3.4171e-01,  2.6526e-01, -4.9010e-02,\n",
      "         4.0661e-01, -3.6391e-01,  1.1593e-01,  1.8883e-01,  1.7652e-01,\n",
      "         2.1411e-01, -9.8949e-02, -3.5807e-01, -3.3762e-01,  3.5328e-01,\n",
      "        -2.2155e-01,  1.2189e-02, -5.9110e-02, -2.1184e-01,  3.8382e-01,\n",
      "        -2.7243e-01, -8.4045e-03, -3.9315e-01,  4.2205e-01,  3.8963e-01,\n",
      "         2.9256e-01,  1.8150e-01, -3.6007e-01,  3.3829e-01,  3.1569e-01,\n",
      "         2.2904e-01,  2.8880e-01, -2.1280e-01, -2.9759e-01, -1.1204e-01,\n",
      "         2.9965e-02,  6.1985e-02,  4.0260e-01, -2.9713e-01,  2.9792e-01,\n",
      "        -4.3471e-01, -2.7765e-01,  4.6144e-03,  7.5573e-02, -2.8511e-01,\n",
      "        -2.9523e-01, -2.0198e-01,  3.7358e-01,  3.0228e-01, -1.9025e-01,\n",
      "        -1.7581e-01, -1.8660e-01, -1.5817e-01,  3.4547e-01, -3.1133e-01,\n",
      "         4.5658e-01, -3.9159e-01, -2.1680e-01, -8.9243e-02, -6.7395e-02,\n",
      "         2.7230e-01,  2.3007e-01, -3.0497e-01, -2.9468e-01, -3.1315e-01,\n",
      "        -1.0702e-01,  1.0239e-01, -4.9808e-02, -3.8907e-01,  3.8412e-01,\n",
      "         1.6446e-01, -2.2208e-01,  3.1776e-01,  3.7169e-01, -2.2723e-01,\n",
      "         3.3772e-01, -2.2670e-01, -3.4479e-01,  2.1550e-01,  2.2530e-01,\n",
      "        -2.7244e-01, -3.6218e-01,  3.1053e-01,  2.9579e-01, -3.9472e-01,\n",
      "         3.6844e-02,  2.5926e-01,  2.8657e-01, -1.0377e-01, -5.1153e-01,\n",
      "        -1.3184e-01, -1.5937e-01, -3.3219e-01, -5.2602e-02, -4.9395e-01,\n",
      "         3.6350e-01,  2.2785e-01,  1.0720e-01, -2.7334e-01, -2.4807e-01,\n",
      "         3.0739e-01, -2.7528e-01,  2.5005e-01,  1.6041e-01, -1.7162e-01,\n",
      "        -4.4465e-02, -1.6835e-01,  2.0168e-01,  2.1313e-01, -7.7295e-02,\n",
      "         3.8817e-01,  1.3106e-01,  5.0184e-01,  2.2134e-01, -2.3547e-01,\n",
      "        -3.5244e-01,  2.8896e-01,  2.4493e-01, -2.0712e-01,  3.3524e-01,\n",
      "         1.6933e-01,  4.5352e-01, -4.2718e-01,  2.9126e-01,  1.6388e-01,\n",
      "         3.4251e-01,  1.2750e-01, -4.1849e-01,  2.6019e-01, -3.2161e-01,\n",
      "        -4.2964e-01,  5.8761e-02, -3.9053e-01,  1.2508e-02, -4.8154e-02,\n",
      "         3.0280e-01, -2.2083e-01, -2.1820e-01,  3.7431e-01,  3.7019e-01,\n",
      "        -3.5172e-01, -8.3909e-02, -3.0310e-01, -1.3447e-01,  7.9119e-02,\n",
      "         3.7562e-01, -2.4736e-01, -3.5798e-01,  3.5832e-01,  1.9939e-01,\n",
      "         3.4730e-01, -2.1850e-01,  3.1328e-01,  2.6280e-01,  2.4529e-01,\n",
      "         2.7038e-01,  6.6361e-02,  2.8398e-02, -3.2527e-01,  1.2088e-01,\n",
      "         1.2561e-01, -8.1653e-02,  1.7967e-01, -3.5483e-01,  2.5947e-01,\n",
      "        -9.3581e-02,  2.1095e-01,  3.4894e-01, -1.3871e-01,  2.6533e-01,\n",
      "        -2.3589e-01, -3.7672e-01,  2.5179e-01,  2.1760e-02,  2.2348e-01,\n",
      "         1.3641e-01,  1.3058e-01,  3.1963e-01, -2.7153e-01,  3.1103e-01,\n",
      "         2.2986e-02, -2.0357e-01,  1.2073e-01,  2.2323e-01,  2.8916e-01,\n",
      "         1.5928e-01, -8.0369e-02, -3.5425e-01, -2.6798e-01,  7.8652e-02,\n",
      "        -1.1944e-02, -1.9427e-01, -2.2150e-01, -2.2238e-02, -4.1611e-01,\n",
      "        -4.5376e-02, -1.2242e-01,  3.1516e-01, -2.8567e-01, -3.2737e-02,\n",
      "        -2.3097e-01, -4.4456e-01,  3.4098e-01, -3.8451e-01, -1.7822e-01,\n",
      "         3.1643e-01, -3.8803e-01, -2.2215e-01, -3.5177e-01,  3.0464e-01,\n",
      "        -2.5749e-01, -2.6862e-01, -3.5991e-01,  2.4232e-01, -2.8475e-01,\n",
      "         4.2268e-02, -3.5518e-01, -3.4303e-01, -1.7588e-01, -1.8376e-01,\n",
      "        -3.0656e-01, -2.4450e-01, -4.5069e-01, -4.2541e-01,  2.6931e-01,\n",
      "        -6.3861e-02, -1.6081e-01, -3.8902e-01,  3.4733e-01,  2.5704e-01,\n",
      "         1.5421e-01,  5.4515e-02, -3.0679e-01, -3.7580e-01, -1.3127e-01,\n",
      "         2.6866e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-4.9785e-01]],\n",
      "\n",
      "         [[-4.9002e-01]],\n",
      "\n",
      "         [[-3.5209e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2670e-02]],\n",
      "\n",
      "         [[ 2.6920e-01]],\n",
      "\n",
      "         [[ 9.9345e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7654e-01]],\n",
      "\n",
      "         [[-2.5440e-02]],\n",
      "\n",
      "         [[-1.5990e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3705e-01]],\n",
      "\n",
      "         [[ 1.4904e-01]],\n",
      "\n",
      "         [[ 2.8552e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6359e-02]],\n",
      "\n",
      "         [[-1.0583e-01]],\n",
      "\n",
      "         [[ 8.4385e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.0134e-02]],\n",
      "\n",
      "         [[-1.7006e-01]],\n",
      "\n",
      "         [[-7.6943e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-7.4454e-02]],\n",
      "\n",
      "         [[ 1.7094e-01]],\n",
      "\n",
      "         [[-1.1921e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1082e-02]],\n",
      "\n",
      "         [[-4.0917e-01]],\n",
      "\n",
      "         [[-1.5385e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0215e-02]],\n",
      "\n",
      "         [[ 8.2057e-02]],\n",
      "\n",
      "         [[ 2.0676e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.5721e-04]],\n",
      "\n",
      "         [[ 1.4279e-01]],\n",
      "\n",
      "         [[ 9.3395e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2419e-01]],\n",
      "\n",
      "         [[ 1.3822e-01]],\n",
      "\n",
      "         [[ 2.0526e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9380e-01]],\n",
      "\n",
      "         [[-2.5649e-01]],\n",
      "\n",
      "         [[ 4.5370e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.3785,  0.3569,  0.7953,  1.0405,  0.2083,  0.3814,  1.0009,  3.0476,\n",
      "         0.4016,  0.4605,  0.1994,  0.6221,  1.2151,  0.3188,  0.8970,  2.1065,\n",
      "         0.0604,  0.8353,  0.2483,  0.2198,  0.9858,  0.7450,  0.8338,  1.5236,\n",
      "         1.3203,  1.0843,  0.5837, -0.0111,  0.7034,  0.2403,  1.0259,  0.1938,\n",
      "         1.2597,  0.6073,  1.5297,  0.2947,  0.2434,  0.5058,  0.3886,  0.7559,\n",
      "         1.3120,  0.8531,  0.0725,  0.6603,  0.7256,  1.4870,  1.3112,  1.6107,\n",
      "         0.7606,  1.1568,  4.3530,  0.9637,  1.1134,  0.6001,  0.8652,  0.4822,\n",
      "         0.5070,  0.0725,  2.3222,  0.0744,  0.8832,  0.2409,  0.3066,  1.5873,\n",
      "         0.2751,  0.3675,  0.7194,  0.8561,  1.4709,  0.2158,  1.0636,  1.4003,\n",
      "         2.3864,  1.2148,  1.8689,  0.1590,  1.3558,  2.3933,  0.3988,  0.2527,\n",
      "         0.7801,  0.2325,  1.1327,  1.1534,  0.3134,  0.0498,  0.2512,  0.3662,\n",
      "         0.7972,  0.3470,  1.1917,  1.5967,  1.2967,  1.1292,  0.5497,  1.6845,\n",
      "        -0.0304,  0.3188,  0.7337,  0.5230,  1.9768,  0.0714,  0.0505,  0.3398,\n",
      "         0.9498,  0.4981,  1.3243,  1.1499,  0.2236,  0.7479,  1.8395,  0.8749,\n",
      "         1.6292,  0.9030,  0.5007,  1.4947,  0.6707,  1.9839,  1.0466,  1.1472,\n",
      "         0.8315,  0.8296,  0.8409,  0.8772,  1.1521,  0.8779,  1.2362,  0.0447,\n",
      "         0.5858,  0.7455,  0.6690,  1.0512,  0.0085,  1.5981,  2.1517,  0.6800],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.3604, -0.2760, -0.1381, -0.1910,  0.3156, -0.0439, -0.2725, -0.9307,\n",
      "        -0.1747,  0.2114,  0.3472,  0.6302, -0.4432,  0.1161,  0.1353,  0.9215,\n",
      "         0.2949,  0.1888, -0.4874,  0.2305, -0.1831,  0.2264, -0.0542,  0.3206,\n",
      "        -0.1518,  1.3185,  0.1262, -0.1198,  0.6975, -0.0577,  0.0813, -0.2210,\n",
      "        -0.1054, -0.0114, -0.0264, -0.1479,  0.4815, -0.2363, -0.4797, -0.1535,\n",
      "        -0.0477, -0.3399, -0.0173,  0.4245, -0.2732,  0.7160,  0.3554,  0.7506,\n",
      "         0.1134, -0.1409, -0.1135, -0.1545,  0.2854, -0.1820, -0.4269,  0.4232,\n",
      "        -0.0744, -0.3202,  0.0378,  0.4588, -0.1628, -0.4108, -0.2251, -0.3791,\n",
      "         0.0762,  0.4344,  0.2410,  0.2557,  0.2698, -0.4968, -0.3016, -0.0650,\n",
      "         0.8945,  0.0978, -0.0416, -0.0121, -0.0715,  0.3983,  0.1370, -0.2828,\n",
      "        -0.4150, -0.2004, -0.6424,  0.0707, -0.3349, -0.2057,  0.1221, -0.3072,\n",
      "         0.4892,  0.6680,  0.1784,  0.1854, -0.1270,  0.2938, -0.3232, -0.6459,\n",
      "        -0.3399,  0.0081, -0.2772,  0.1585,  0.5883,  0.1000,  0.2018, -0.0049,\n",
      "         0.1064,  0.0412, -0.4753,  0.1060, -0.3407,  0.0789,  0.6238,  0.0478,\n",
      "         0.0490, -0.0239,  0.2487,  0.0624, -0.3703, -0.6805,  0.1494, -0.1351,\n",
      "         0.1295,  0.1093,  0.3843, -0.2255,  0.0056, -0.0245,  0.0962,  0.0939,\n",
      "         0.6153,  0.5917, -0.2109, -0.4218,  0.0923,  0.6508,  0.5697,  0.1519],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 6.6247e-01]],\n",
      "\n",
      "         [[-2.7967e-01]],\n",
      "\n",
      "         [[-4.1549e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3497e-01]],\n",
      "\n",
      "         [[ 6.4444e-02]],\n",
      "\n",
      "         [[-3.8957e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4083e-01]],\n",
      "\n",
      "         [[-3.6900e-02]],\n",
      "\n",
      "         [[ 5.8170e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.5037e-01]],\n",
      "\n",
      "         [[-4.9249e-01]],\n",
      "\n",
      "         [[-1.7863e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4267e-01]],\n",
      "\n",
      "         [[ 3.1758e-01]],\n",
      "\n",
      "         [[-3.6941e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.4069e-04]],\n",
      "\n",
      "         [[-3.0441e-01]],\n",
      "\n",
      "         [[ 3.5926e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.5612e-01]],\n",
      "\n",
      "         [[-9.4106e-03]],\n",
      "\n",
      "         [[ 1.2820e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.6866e-01]],\n",
      "\n",
      "         [[-3.2899e-02]],\n",
      "\n",
      "         [[ 3.5115e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4978e-02]],\n",
      "\n",
      "         [[-1.5034e-01]],\n",
      "\n",
      "         [[-4.3339e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.0690e-02]],\n",
      "\n",
      "         [[-2.4464e-01]],\n",
      "\n",
      "         [[ 6.0110e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.6985e-01]],\n",
      "\n",
      "         [[-5.7427e-01]],\n",
      "\n",
      "         [[ 3.2110e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1853e-01]],\n",
      "\n",
      "         [[ 4.2232e-01]],\n",
      "\n",
      "         [[-3.1257e-02]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.6205, 1.2316, 1.2263, 1.3280, 1.0997, 1.1275, 1.1910, 1.3310, 1.1469,\n",
      "        1.4607, 1.4654, 1.3570, 1.5350, 0.7852, 0.2639, 1.2641, 0.8602, 1.3700,\n",
      "        0.7222, 1.3214, 1.1055, 1.6249, 1.0516, 1.0277, 0.7641, 0.7831, 1.7770,\n",
      "        1.3703, 1.4635, 1.3581, 1.3073, 0.7283, 1.3201, 1.5766, 1.3122, 1.3346,\n",
      "        0.6322, 1.2209, 1.7400, 1.2876, 0.7359, 1.3186, 0.8580, 1.3899, 1.3885,\n",
      "        1.5217, 0.5873, 1.7407, 1.1581, 1.7388, 0.2214, 1.1566, 1.6717, 1.1528,\n",
      "        1.1253, 0.7842, 1.3707, 1.3964, 1.2600, 0.3120, 1.5998, 1.2203, 1.3842,\n",
      "        1.4980, 1.3974, 0.6357, 1.6092, 1.2708, 1.0334, 1.2507, 0.4730, 1.3548,\n",
      "        0.8114, 1.1856, 1.0584, 2.0808, 1.4085, 1.4505, 1.0815, 1.0550, 1.6545,\n",
      "        0.9917, 1.2942, 0.5998, 1.7909, 0.9761, 0.7913, 1.0955, 0.9387, 0.7467,\n",
      "        1.4523, 1.1901, 1.3954, 0.9462, 0.4849, 1.1915, 0.7561, 1.3362, 1.7502,\n",
      "        1.0740, 1.1954, 1.3215, 0.6128, 1.2109, 1.1075, 0.5353, 1.0931, 1.5929,\n",
      "        1.3304, 0.7461, 1.3080, 1.5016, 1.1341, 0.6612, 1.2817, 1.0086, 0.5440,\n",
      "        0.9615, 0.9385, 0.9831, 1.5852, 1.1014, 0.9091, 1.5626, 0.4595, 1.3688,\n",
      "        0.9451, 1.6473, 1.2208, 0.5965, 1.3124, 1.6714, 0.5344, 1.2710, 1.0719,\n",
      "        1.2413, 0.9956, 1.5316, 1.8286, 0.7939, 0.8673, 1.4603, 1.6835, 1.2943,\n",
      "        0.5748, 1.1581, 1.5726, 1.4977, 1.5210, 0.6682, 0.7787, 0.9722, 1.1269,\n",
      "        1.4398, 1.4747, 1.2144, 1.0499, 1.0202, 1.1106, 0.6233, 0.4548, 1.3400,\n",
      "        0.7087, 1.0725, 1.1439, 1.1515, 1.3965, 1.4475, 1.2254, 0.6835, 1.2734,\n",
      "        1.0094, 1.3461, 1.3154, 1.4140, 1.2436, 1.4039, 1.0339, 1.5743, 0.9912,\n",
      "        1.0600, 1.2349, 1.2477, 1.5015, 1.0866, 1.0381, 0.9714, 1.1678, 1.7816,\n",
      "        1.2690, 1.3458, 1.1299, 1.3014, 1.3345, 1.8583, 0.9884, 2.4544, 1.4756,\n",
      "        1.3234, 1.2476, 2.2196, 1.6466, 1.0834, 0.2564, 1.6599, 1.2086, 0.9300,\n",
      "        1.4550, 0.8523, 2.3050, 1.4184, 0.8067, 1.5640, 0.8953, 1.6793, 1.9109,\n",
      "        1.6975, 1.2585, 0.7201, 1.2681, 1.8567, 1.0312, 1.1062, 1.4746, 1.2335,\n",
      "        1.1069, 0.8875, 1.2094, 1.0141, 1.1439, 1.3575, 1.0440, 0.9540, 1.2799,\n",
      "        0.7303, 0.7829, 1.8042, 1.2014, 0.9716, 1.1316, 1.2115, 1.3597, 1.2760,\n",
      "        0.8385, 1.6536, 1.0270, 0.5628, 1.0933, 1.2513, 1.2084, 0.7938, 1.0511,\n",
      "        0.6193, 0.8590, 1.6165, 1.3513, 0.8882, 1.3148, 1.4764, 1.3972, 1.3124,\n",
      "        1.2842, 1.4134, 1.0550, 0.6719, 1.0929, 1.0773, 1.0936, 1.2699, 0.6502,\n",
      "        1.5243, 1.1589, 1.4064, 0.5776, 1.3708, 1.6100, 1.2900, 1.7514, 0.8239,\n",
      "        1.4030, 1.3588, 1.2512, 0.8764, 0.9464, 1.7374, 1.2227, 1.2698, 0.7817,\n",
      "        1.1488, 1.5464, 1.6326, 1.2058, 1.5054, 1.7236, 1.4756, 0.6699, 0.2302,\n",
      "        0.9052, 1.4675, 0.9469, 1.1567, 1.7977, 1.2379, 0.9075, 1.0004, 0.5501,\n",
      "        1.2838, 1.5670, 0.7907, 1.1919, 0.8870, 1.0795, 0.9608, 1.3060, 1.4249,\n",
      "        1.3955, 1.0381, 0.8423, 1.1262, 1.2217, 1.0793, 1.1135, 1.0159, 0.9213,\n",
      "        1.2874, 0.7159, 1.0691, 1.4708, 0.3952, 0.7908, 0.5341, 1.2625, 1.2892,\n",
      "        1.0624, 1.1194, 0.9789, 1.0031, 1.5234, 0.9374, 1.3195, 1.0077, 1.3667,\n",
      "        1.2978, 0.6965, 1.0330, 0.7940, 1.2418, 1.3161, 0.5864, 1.0527, 1.1186,\n",
      "        0.8952, 1.2225, 0.9304, 1.2163, 1.4129, 0.6481, 1.4348, 0.9173, 1.0596,\n",
      "        1.7007, 1.0105, 0.5641, 1.7603, 1.1372, 1.1870, 1.7018, 0.7430, 0.9015,\n",
      "        1.2714, 0.4709, 1.2019, 1.2400, 1.0366, 1.9465, 0.9874, 1.3127, 1.1385,\n",
      "        1.4094, 1.0885, 1.0159, 1.0797, 1.0312, 1.0584, 1.4555, 1.0908, 1.3957,\n",
      "        1.6909, 0.9801, 1.4535, 0.9306, 1.2094, 1.1697, 0.3278, 1.1983, 1.4969,\n",
      "        1.1253, 1.4576, 1.5193, 0.8081, 1.1437, 1.2118, 1.0351, 1.0214, 1.1325,\n",
      "        1.5046, 0.9203, 1.0479, 1.0153, 1.6129, 0.9216, 0.2254, 1.2905, 1.6794,\n",
      "        1.0954, 0.4692, 1.2694, 0.4584, 1.2257, 0.5180, 1.0422, 1.5060, 0.8885,\n",
      "        1.2837, 1.0100, 1.4956, 1.3786, 0.9676, 1.5417, 1.1628, 0.5179, 0.9495,\n",
      "        1.2798, 1.3034, 1.0128, 0.8687, 2.2528, 1.6316, 0.9306, 0.9898, 0.5730,\n",
      "        1.3138, 0.6449, 1.2396, 1.3520, 0.4481, 1.5466, 1.0331, 0.6648, 0.9202,\n",
      "        1.3886, 1.4616, 0.8362, 1.4950, 1.5060, 0.9053, 1.2118, 1.3916, 0.8660,\n",
      "        0.5188, 1.2289, 0.6581, 1.2232, 1.1388, 0.6597, 1.0903, 1.3314, 1.7164,\n",
      "        1.1645, 1.4953, 0.4382, 1.6420, 1.8154, 0.3616, 1.5350, 1.3854, 0.8434,\n",
      "        1.5830, 1.0726, 1.3620, 1.3711, 1.0073, 0.8207, 0.0130, 1.0307, 1.2612,\n",
      "        1.3844, 0.9326, 1.3982, 0.6882, 1.2186, 1.8312, 0.5458, 1.4281, 1.2011,\n",
      "        0.7424, 0.9584, 1.3966, 0.9214, 0.6322, 1.0810, 0.8596, 1.4304, 1.8143,\n",
      "        1.3272, 1.0196, 0.8563, 1.8246, 1.5370, 1.3670, 1.3455, 1.3663, 0.8536,\n",
      "        0.9483, 1.3530, 1.1691, 1.2289, 1.1094, 0.9098, 1.4941, 1.0824, 0.8485,\n",
      "        2.5524, 0.9881, 1.7294, 1.2628, 1.4662, 1.8007, 1.4412, 1.0204, 1.5072,\n",
      "        1.7318, 0.8313, 1.4237, 1.7124, 0.9482, 1.4493, 1.4291, 1.2184, 1.0515,\n",
      "        1.4671, 0.6942, 1.2850, 1.3395, 1.3047, 1.4939, 1.6841, 1.6064, 0.5862,\n",
      "        1.1654, 0.7428, 1.2974, 1.1074, 1.1255, 0.6449, 1.3027, 1.5472, 1.4172,\n",
      "        0.8907, 0.9331, 1.2015, 0.9010, 0.9672, 1.2794, 1.3158, 0.8413, 1.3831,\n",
      "        1.2156, 1.8985, 1.5984, 1.1158, 1.3427, 1.4257, 0.9392, 0.7652, 0.8797,\n",
      "        0.4526, 1.3737, 0.9054, 0.8632, 1.7937, 0.9576, 1.0811, 1.6183, 1.6008,\n",
      "        0.7227, 1.1675, 1.8603, 1.3381, 1.2407, 1.2983, 0.6086, 1.1567, 1.3602,\n",
      "        0.6910, 0.7618, 1.4545, 1.2844, 0.8988, 0.1179, 1.0533, 1.4748, 1.0854,\n",
      "        1.1421, 0.8087, 0.7726, 0.7559, 0.8944, 1.2902, 1.4895, 1.0164, 1.4331,\n",
      "        0.7853, 1.3507, 1.2120, 0.9296, 0.8871, 0.3941, 0.8079, 1.2889, 0.9188,\n",
      "        1.1455, 1.3227, 1.2046, 1.5437, 1.3119, 1.6634, 1.0990, 1.0322, 1.2666,\n",
      "        1.4851, 0.9446, 0.9359, 0.7779, 1.1840, 1.3557, 1.1241, 0.6659, 1.5290,\n",
      "        1.1989, 1.2264, 0.9464, 0.9502, 1.7542, 0.9076, 2.2143, 0.9018, 2.2901,\n",
      "        1.6307, 2.0155, 0.6947, 1.4683, 0.6509, 1.8118, 1.4216, 0.9772, 1.1129,\n",
      "        0.5603, 1.3916, 1.0116, 1.8382, 1.1065, 0.9837, 1.0291, 2.1084, 2.0421,\n",
      "        1.1705, 1.6757, 1.2047, 1.1516, 1.4174, 1.3851, 1.5814, 1.0150, 0.8963,\n",
      "        1.0279, 0.4768, 1.0478, 0.6899, 1.0157, 1.4932, 1.3589, 1.0300, 1.1217,\n",
      "        1.2796, 1.0750, 1.6650, 0.9774, 0.7785, 1.4647, 1.5943, 1.0055, 0.7731,\n",
      "        0.9681, 1.2063, 0.6094, 1.5069, 1.2288, 0.9318, 1.2817, 1.1138, 1.2176,\n",
      "        1.4939, 1.3404, 1.0550, 0.6234, 0.7705, 1.1144, 0.5057, 1.1747, 2.4484,\n",
      "        0.8229, 1.0520, 1.5664, 1.3361, 1.6975, 1.3225, 1.6269, 1.3273, 0.8821,\n",
      "        1.2993, 1.2188, 1.3777, 1.0349, 1.3841, 1.6919, 1.1632, 0.9397, 1.1887,\n",
      "        0.9655, 1.1372, 1.0566, 1.5438, 0.8611, 1.1147, 0.9064, 1.6240, 0.6909,\n",
      "        1.0528, 1.7112, 0.8620, 0.7058, 1.2115, 1.2513, 1.5527, 1.2095, 1.3004,\n",
      "        1.0655, 1.1907, 0.7602, 0.4882, 0.3877, 1.0055, 1.2009, 0.9680, 0.4148,\n",
      "        0.6357, 0.9693, 1.1893, 1.7257, 1.1145, 1.3248, 1.0282, 1.1430, 0.6445,\n",
      "        1.0878, 1.8980, 1.2978, 0.9230, 1.2396, 0.4144, 0.1400, 1.1032, 0.9287,\n",
      "        1.3033, 1.7309, 0.5400, 1.4772, 1.4607, 1.1167, 0.6922, 0.9922, 0.9241,\n",
      "        0.9188, 1.3422, 1.6228, 0.5680, 1.3016, 0.4846, 0.9725, 1.0384, 0.9625,\n",
      "        1.3949, 1.4332, 0.9824, 0.8925, 1.2185, 1.2365, 1.2368, 0.6800, 1.0259,\n",
      "        1.5422, 1.1356, 1.7564, 1.3404, 0.9504, 1.0022, 1.3917, 0.9148, 0.6336,\n",
      "        1.1133, 1.1056, 0.6810, 0.3494, 1.2853, 0.6996], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.2827e+00,  2.3662e-01, -1.4478e+00, -1.0401e+00, -2.0088e+00,\n",
      "        -8.0646e-01, -1.4140e+00, -5.2907e-01, -1.3147e+00, -1.3289e+00,\n",
      "        -8.3047e-01, -1.1656e+00, -9.7691e-01, -1.5954e+00, -4.0893e-01,\n",
      "        -2.1964e+00, -8.4525e-01, -1.8316e+00, -2.1051e-01, -4.5665e-01,\n",
      "        -1.8412e+00, -6.8444e-01, -1.3448e+00, -4.9387e-02, -1.0953e+00,\n",
      "        -6.4404e-01, -5.1312e-01, -1.0043e+00,  5.9869e-02, -3.5395e-01,\n",
      "        -1.2882e+00, -5.7908e-01, -1.5469e+00, -2.0572e-01, -8.4844e-01,\n",
      "        -1.7463e+00, -2.2372e+00, -6.8282e-01, -2.9806e-01, -1.6159e+00,\n",
      "        -4.7056e-01, -6.1113e-01, -3.8024e-01, -8.6562e-01, -1.5210e+00,\n",
      "        -7.0061e-01, -1.4835e+00, -8.6596e-01,  5.2197e-01, -1.1870e-01,\n",
      "        -2.7859e-01, -1.2067e+00, -3.5597e+00, -1.3680e+00, -1.1823e+00,\n",
      "        -1.7277e-01, -4.0215e-01, -1.7860e+00, -1.3006e-01, -1.6296e+00,\n",
      "        -1.4056e+00, -2.5052e-01, -4.7146e-01, -7.2416e-01, -3.0947e-01,\n",
      "        -6.7071e-01, -1.5311e+00, -1.6375e+00, -2.4362e+00,  2.3197e-01,\n",
      "         2.0355e-01, -1.2866e+00, -5.5421e-01, -1.0769e+00, -2.2154e+00,\n",
      "        -6.4272e-01, -8.8413e-01, -2.0016e+00, -1.4851e+00, -5.2756e-01,\n",
      "        -8.8556e-01, -8.2321e-01, -1.5839e+00,  1.3715e+00, -1.0152e+00,\n",
      "        -2.0360e-01, -3.4002e-01, -1.1795e-01, -1.9737e+00,  2.6761e-01,\n",
      "         5.8942e-02, -9.9151e-01, -2.2556e+00, -1.4882e+00,  2.5341e-01,\n",
      "        -1.0945e+00, -7.7469e-01, -2.2380e+00, -1.4759e+00, -4.2684e-01,\n",
      "        -4.9040e-01, -1.2019e-01, -1.5636e+00, -1.2704e+00, -2.4727e+00,\n",
      "        -1.5774e+00, -1.3018e+00, -6.2374e-01, -1.2989e+00, -1.3651e-01,\n",
      "        -9.7793e-01, -1.5759e+00, -9.8692e-01, -1.0674e+00, -1.9964e+00,\n",
      "        -7.1867e-01, -9.0335e-02, -2.5298e-02, -4.9486e-01, -1.6891e+00,\n",
      "        -9.5548e-01, -1.6841e+00, -5.7084e-01, -1.6685e-01,  1.8335e-01,\n",
      "        -1.9770e+00, -1.4696e+00, -3.1845e-01, -9.9841e-01, -1.3177e+00,\n",
      "        -1.5721e+00, -1.4206e+00, -1.4199e+00, -8.4114e-01, -6.7176e-01,\n",
      "        -1.7793e+00, -1.5449e+00,  6.3694e-01, -3.7752e-01, -1.3446e+00,\n",
      "        -1.8262e+00, -1.8925e+00, -9.8962e-01, -1.4805e+00, -9.7049e-01,\n",
      "        -1.0758e+00, -2.0023e+00, -6.6806e-01, -1.1663e+00, -1.2301e+00,\n",
      "        -6.7000e-01, -1.9903e-01, -1.0238e+00, -3.7164e-01, -1.5268e+00,\n",
      "        -1.2388e+00, -9.0091e-01, -5.3021e-01, -1.5908e+00, -3.8615e-02,\n",
      "         3.6378e-01,  6.4471e-01, -1.5858e+00, -1.1171e+00, -7.9558e-01,\n",
      "        -1.1410e+00, -1.0112e+00, -1.1163e+00, -1.0030e+00, -1.7290e+00,\n",
      "        -8.7349e-01, -1.5665e+00, -1.7981e+00, -6.2391e-01, -8.8184e-01,\n",
      "        -1.5379e+00, -2.1260e+00, -9.8030e-01, -9.7092e-01, -9.3567e-01,\n",
      "        -4.0465e-02, -1.7114e+00, -1.5967e+00, -1.7840e+00, -1.6066e+00,\n",
      "        -1.3899e+00, -6.8254e-01, -1.2736e+00,  1.1784e-01, -1.3453e+00,\n",
      "        -1.8060e+00, -9.2262e-01, -4.5169e-01, -8.9386e-01, -1.6643e+00,\n",
      "        -1.0505e+00,  1.6380e-01, -7.5988e-01, -2.4633e+00, -9.3755e-01,\n",
      "        -6.6747e-01, -3.6326e-01, -8.0817e-01, -4.1011e-02, -1.7208e+00,\n",
      "         4.4518e-01, -1.7309e+00, -1.9553e-01, -1.4242e+00, -8.0340e-01,\n",
      "        -1.1514e-01, -7.9221e-01, -6.4255e-01, -1.0555e+00, -3.8888e-01,\n",
      "        -5.0517e-01, -4.4338e-01, -2.3059e+00,  1.7147e+00, -5.6721e-01,\n",
      "        -5.1016e-01, -5.1523e-01, -1.2842e+00, -3.5069e-01, -1.3477e+00,\n",
      "        -9.9260e-01, -1.1390e+00, -1.4268e+00, -1.7921e+00, -1.0042e+00,\n",
      "        -1.2692e+00, -9.5754e-01, -9.5456e-01, -1.2229e+00, -8.5132e-01,\n",
      "        -1.1367e+00, -5.3966e-01, -1.3537e+00, -8.4346e-01,  3.7692e-02,\n",
      "        -2.9443e+00, -1.1830e+00, -2.2061e+00,  1.3955e-01, -4.5295e-01,\n",
      "        -7.1053e-01, -3.6365e-02, -1.6390e+00, -7.5615e-01, -2.4125e+00,\n",
      "        -4.5176e-01, -1.3051e+00,  1.6104e-01, -9.5134e-01, -1.2224e+00,\n",
      "        -1.3889e+00, -8.4650e-01, -4.8251e-01, -6.8419e-01, -1.1265e+00,\n",
      "        -8.4786e-01, -3.1095e-01, -1.3536e+00, -1.4748e+00, -9.5387e-01,\n",
      "         3.7204e-01, -2.5369e-02, -6.2474e-01, -1.8145e+00, -8.3420e-01,\n",
      "        -1.3580e+00, -9.6319e-01, -3.7090e-01,  2.5860e-01, -2.1894e+00,\n",
      "        -1.5889e+00, -1.1218e+00, -1.2908e+00, -1.7381e+00, -1.1176e+00,\n",
      "         3.6062e-01, -1.9015e-01, -4.0384e-01, -2.0730e-01, -4.3867e-01,\n",
      "        -1.0295e-01, -1.6437e+00, -2.2949e+00, -2.7339e+00, -5.5959e-01,\n",
      "         1.4233e-01, -1.0568e+00, -3.2536e-01, -4.3767e-02, -1.5107e+00,\n",
      "         1.3230e+00, -1.3444e-01, -5.0945e-01, -8.1122e-01, -6.5951e-01,\n",
      "        -2.2501e+00, -6.7779e-01, -1.3195e+00, -1.0309e+00, -1.4987e+00,\n",
      "         2.7330e-01, -2.3535e+00,  4.5773e-01, -9.3810e-01, -8.3257e-01,\n",
      "        -1.1375e+00, -9.0792e-01, -1.5546e+00, -1.7844e+00, -1.4621e+00,\n",
      "        -8.5794e-01, -1.0176e+00, -1.4205e+00, -1.7865e+00, -2.1399e+00,\n",
      "        -1.6886e+00, -1.4787e+00, -1.3621e+00,  2.9083e-02, -1.3176e+00,\n",
      "        -1.5483e+00, -7.4092e-01, -7.4762e-01, -2.2924e+00, -6.2110e-01,\n",
      "         2.5664e-01, -1.0778e+00, -1.4712e+00, -8.5279e-01, -1.3346e+00,\n",
      "        -2.2566e+00, -3.7010e-01, -1.0587e+00, -1.3344e+00, -1.1217e+00,\n",
      "        -5.3420e-01, -1.5090e+00, -1.2796e+00, -1.5198e+00, -3.1510e-01,\n",
      "        -1.1553e+00, -1.3346e+00, -8.9117e-01, -4.1895e-01, -8.9132e-01,\n",
      "         4.8192e-01, -1.3711e+00, -1.2236e+00, -7.4356e-01, -1.0677e+00,\n",
      "        -1.7589e+00,  6.6250e-01, -1.6904e+00, -1.8862e+00, -1.6221e+00,\n",
      "        -1.1117e+00, -6.8282e-01, -1.5368e+00, -3.2493e-01, -8.5652e-01,\n",
      "        -9.9701e-01, -5.5699e-01, -1.4103e+00, -1.9970e+00, -7.5142e-01,\n",
      "         2.3514e-01, -1.3393e+00, -9.6182e-01, -5.3596e-01, -5.2132e-01,\n",
      "        -6.5915e-01, -1.3137e+00, -1.4691e+00, -2.3240e+00, -2.0479e-01,\n",
      "        -1.6086e+00, -3.7145e-01, -9.6927e-01, -1.9864e+00, -1.9750e+00,\n",
      "        -2.2439e-01, -4.5736e-01, -1.2959e+00, -1.4256e+00, -1.0957e+00,\n",
      "        -6.5574e-01, -1.3731e+00, -9.9731e-01, -5.0446e-01, -1.2739e+00,\n",
      "        -1.5846e+00, -2.3800e+00, -1.2640e+00, -1.2230e+00, -4.7011e-01,\n",
      "        -1.3484e+00, -1.3148e+00, -2.1271e-01, -1.2651e+00, -7.7388e-01,\n",
      "        -1.2596e+00, -1.9125e+00, -7.2155e-03,  2.2822e-01, -4.5733e-02,\n",
      "        -5.4461e-01, -2.8105e-02, -9.4248e-01, -5.1225e-01, -1.2668e+00,\n",
      "         6.2837e-01, -9.6366e-01, -8.9005e-01, -6.7546e-02,  1.6423e-01,\n",
      "        -9.4610e-01, -4.3805e-01, -5.9823e-01, -1.9190e+00,  1.4504e-02,\n",
      "        -4.7646e-01, -1.7810e+00, -1.6992e+00, -7.3773e-01, -1.3852e+00,\n",
      "         6.8881e-01, -1.1086e+00, -1.2801e+00, -8.7021e-01, -1.1905e-04,\n",
      "         2.6500e-01,  2.1118e-01, -1.3223e+00, -1.1659e+00, -1.0245e+00,\n",
      "        -1.0157e+00, -6.5917e-01,  7.6618e-02, -4.0681e-01, -1.1931e+00,\n",
      "        -1.9464e-01, -4.6442e-01, -9.6557e-01, -3.7150e-01, -1.8183e+00,\n",
      "        -1.8801e+00, -1.8819e+00, -5.5902e-01, -9.5037e-01, -2.3145e+00,\n",
      "        -1.7821e+00, -9.8427e-01, -8.2529e-01, -1.9142e-01,  7.7208e-01,\n",
      "        -2.4099e+00,  1.9592e-01, -5.2044e-01, -7.9483e-01,  1.1228e-02,\n",
      "        -1.4010e-01, -6.7192e-01, -8.8261e-01, -8.7482e-01, -1.9704e+00,\n",
      "        -7.9608e-01, -1.7227e+00, -4.0142e-04,  2.2595e-01, -6.3422e-01,\n",
      "        -1.5342e+00, -1.3452e+00, -8.4596e-01, -4.4813e-03, -2.0459e+00,\n",
      "        -2.5865e+00, -2.2897e+00, -5.6855e-01, -1.2408e+00, -5.4847e-01,\n",
      "        -1.2439e+00, -2.5647e+00, -9.3867e-01, -8.9317e-01, -2.4726e-01,\n",
      "        -1.9924e+00,  2.5822e-01,  4.4139e-01, -1.9204e+00, -1.3500e+00,\n",
      "         3.9292e-01, -2.3713e-01,  8.9215e-02, -7.5139e-01, -4.1242e-01,\n",
      "        -2.0370e+00, -1.5463e+00, -1.3488e+00, -1.2627e+00, -2.2215e-01,\n",
      "        -8.7840e-01,  1.8372e-02, -1.4250e+00, -1.3688e+00, -1.4514e+00,\n",
      "        -6.1284e-01, -8.5567e-01, -1.6936e-01, -8.5827e-01, -2.1089e+00,\n",
      "        -7.3493e-01, -5.8312e-01, -7.5862e-01, -8.9688e-01, -7.2276e-01,\n",
      "        -1.2605e+00, -6.7590e-01,  6.8566e-01, -1.4546e+00, -2.0597e+00,\n",
      "         5.0357e-01, -1.4341e+00,  4.3099e-01, -1.0282e+00, -9.4157e-01,\n",
      "        -1.6984e+00, -1.6945e-01, -7.9476e-01, -1.0077e+00,  2.4523e-02,\n",
      "        -1.4567e+00, -7.7086e-01, -1.0580e+00, -9.5435e-01, -9.7612e-01,\n",
      "        -8.3615e-01, -1.1149e+00,  6.0723e-01, -1.3447e+00, -1.6699e+00,\n",
      "        -1.4842e+00,  4.3235e-02, -1.6993e-01,  6.1574e-01, -7.9626e-01,\n",
      "        -4.9700e-01, -8.1838e-01, -8.3058e-01, -7.8229e-01, -1.0309e+00,\n",
      "        -3.9699e-01, -2.1942e+00, -7.6477e-02, -1.2741e+00, -7.8337e-01,\n",
      "        -1.0779e+00, -1.5333e+00, -2.0380e+00, -1.0586e+00, -1.2385e+00,\n",
      "        -6.3040e-01, -1.6820e+00, -2.0412e+00, -1.0066e+00, -7.3989e-01,\n",
      "        -1.4489e+00, -1.6547e+00, -1.5891e+00, -7.3716e-01, -2.1337e+00,\n",
      "        -1.8695e+00,  1.3547e-01, -8.2350e-01, -1.1096e+00, -1.6463e+00,\n",
      "        -1.1186e+00, -3.7288e-01, -1.9197e+00, -1.6058e+00, -3.3485e-01,\n",
      "        -5.1885e-01, -1.1591e+00,  1.3530e-01, -1.2596e+00, -6.9402e-01,\n",
      "        -1.0750e+00, -1.8470e-01, -1.5276e-01, -6.3623e-01,  2.7346e-01,\n",
      "        -8.9024e-01,  1.7055e-01, -1.8405e+00, -1.1283e+00,  1.8770e-01,\n",
      "        -9.7077e-02, -5.2263e-01, -1.1958e+00,  2.9114e-01, -1.1014e+00,\n",
      "         8.7203e-01, -1.3050e+00, -1.5826e+00, -2.0481e+00, -2.7344e-01,\n",
      "        -8.6415e-01, -1.2183e+00, -6.5435e-01, -1.0037e+00, -4.2761e-01,\n",
      "        -1.1183e+00, -1.4696e+00, -1.0711e-01, -9.6270e-01, -1.1364e+00,\n",
      "        -3.3809e-01, -4.7648e-01, -1.1842e+00, -1.3355e+00, -2.2580e-02,\n",
      "        -1.1502e+00, -8.9851e-01, -1.0930e+00, -1.1200e+00, -7.4768e-02,\n",
      "        -7.6347e-01, -1.4911e+00,  1.6650e-01, -1.0051e+00, -9.3801e-01,\n",
      "        -7.1684e-01, -8.8970e-02, -2.3714e+00, -1.2047e+00, -6.5230e-01,\n",
      "        -2.1266e+00, -1.7837e+00,  7.0191e-02, -5.0408e-01, -1.5604e+00,\n",
      "        -3.2023e-01, -2.5053e+00,  1.5760e-01,  2.7856e-01, -1.0575e+00,\n",
      "        -1.0534e+00, -3.8377e-01,  1.0313e-01, -5.7550e-01, -4.6973e-01,\n",
      "        -1.3436e+00, -1.3512e+00, -7.0092e-01, -1.9452e+00, -8.2545e-01,\n",
      "        -1.9391e-01, -4.9392e-01, -9.2503e-01, -1.7429e+00, -2.9837e-01,\n",
      "        -5.8274e-01, -2.3494e+00, -1.6807e-01,  8.9789e-01, -1.3315e+00,\n",
      "        -2.4182e+00, -2.7120e+00, -7.7573e-01, -1.7693e+00, -1.0865e+00,\n",
      "        -1.1470e+00, -6.2155e-02, -7.4358e-01, -6.1065e-01, -1.9624e+00,\n",
      "        -1.4391e+00, -1.0583e+00, -7.2975e-01, -1.3345e+00, -1.0642e+00,\n",
      "        -2.1263e+00, -2.0794e-01, -7.0581e-01, -8.9295e-02, -1.1350e+00,\n",
      "         3.5996e-01, -1.2198e-02, -1.0600e+00, -1.0946e+00, -1.4780e+00,\n",
      "        -8.8765e-01, -1.6104e+00, -1.6942e+00, -1.3054e+00, -1.6970e+00,\n",
      "        -9.6077e-01, -1.3509e+00, -1.0465e+00, -1.4860e-02, -1.2364e-01,\n",
      "        -5.2310e-01, -1.0454e+00, -1.7134e+00, -2.1613e-02, -4.4933e-01,\n",
      "        -2.5723e-01, -1.7043e+00, -1.1338e+00, -1.5551e+00, -1.2148e+00,\n",
      "        -1.9718e+00, -1.2631e+00, -1.5814e+00, -3.7789e-01, -1.1412e+00,\n",
      "        -2.6769e-01, -1.3744e+00, -1.1146e+00, -2.1710e+00, -1.5632e+00,\n",
      "        -5.6640e-01, -6.8585e-01,  5.6393e-01, -6.2371e-01, -6.5602e-01,\n",
      "        -1.2699e+00,  5.0225e-01, -3.3020e-01, -1.6289e+00, -1.0242e+00,\n",
      "        -1.5156e+00, -8.8011e-01, -1.1986e+00, -2.0687e+00, -1.0693e+00,\n",
      "        -1.0965e+00, -1.0186e-01, -1.1509e+00, -1.5952e+00, -8.5654e-01,\n",
      "        -9.5219e-01, -3.8981e-02, -4.2725e-01, -9.0022e-01,  1.4779e-01,\n",
      "        -9.2732e-01, -1.8936e+00, -1.3245e+00,  2.5271e-01, -2.5866e+00,\n",
      "        -5.6581e-01,  1.6356e-02, -2.2436e+00, -9.8050e-01,  7.8970e-01,\n",
      "         4.4337e-01, -2.4299e+00, -6.0718e-01, -1.2175e+00, -1.3093e+00,\n",
      "        -1.3767e+00, -4.7790e-01, -1.0391e+00, -8.5164e-01, -2.2709e+00,\n",
      "        -4.3763e-01, -2.0321e-01, -1.5920e+00, -7.3355e-01, -2.1176e+00,\n",
      "        -4.4598e-01, -2.0233e+00, -1.1775e+00, -1.4179e+00, -8.4814e-01,\n",
      "        -1.8295e-02,  1.9933e-01, -1.3273e+00, -9.6808e-01, -1.7173e+00,\n",
      "        -1.5134e+00, -4.8384e-01, -9.5864e-01,  1.3987e-01, -1.4207e-01,\n",
      "        -1.2745e+00, -1.3044e+00, -1.3653e+00, -1.8938e+00, -1.4902e+00,\n",
      "        -1.4170e+00, -2.4807e-01, -1.1345e+00, -1.2555e+00, -8.6550e-01,\n",
      "        -3.4582e-01, -4.8117e-01, -4.7404e-01, -6.5243e-01, -2.5924e-01,\n",
      "        -1.5222e+00, -1.2122e+00, -1.0816e+00,  9.4225e-01, -1.6867e+00,\n",
      "        -1.8282e+00, -7.3760e-01, -4.0016e-01, -1.5039e+00, -1.5657e+00,\n",
      "         3.9235e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.1755,  0.2569, -0.0991,  0.1036, -0.2849],\n",
      "          [ 0.2742,  0.9538,  0.1955, -0.0987, -0.2759],\n",
      "          [ 0.4104,  0.4770,  0.1075,  0.0227, -0.3647],\n",
      "          [ 0.2091,  0.1512,  0.2761,  0.5787,  0.1391],\n",
      "          [-0.0341, -0.2127, -0.1202,  0.1166,  0.1625]]],\n",
      "\n",
      "\n",
      "        [[[-0.3582, -0.2942, -0.1968, -0.1814, -0.4005],\n",
      "          [ 0.1830,  0.2532,  0.2617,  0.6034,  0.0811],\n",
      "          [ 0.2369,  0.2728,  0.6458,  0.3444,  0.2330],\n",
      "          [ 0.4057,  0.4939,  0.3767,  0.4980, -0.0983],\n",
      "          [ 0.1785,  0.3985,  0.3973,  0.2072, -0.1497]]],\n",
      "\n",
      "\n",
      "        [[[-0.1676, -0.3668, -0.0708,  0.0351,  0.1491],\n",
      "          [ 0.3933,  0.0936,  0.0612,  0.7270,  0.6104],\n",
      "          [ 0.2610, -0.0587,  0.3246,  0.1436,  0.1860],\n",
      "          [ 0.4636,  0.1351,  0.1891, -0.1565,  0.0285],\n",
      "          [ 0.6065, -0.3510,  0.0997,  0.2038,  0.4106]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.7653,  0.3425,  0.5186,  0.2920,  0.0619],\n",
      "          [ 0.5813,  0.2607,  0.3012,  0.2241,  0.1902],\n",
      "          [ 0.1686,  0.0120, -0.1600, -0.2710, -0.2915],\n",
      "          [ 0.0518, -0.1036, -0.3239, -0.4506, -0.2578],\n",
      "          [-0.0978, -0.1643,  0.1191, -0.0158, -0.0420]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2010, -0.3756, -0.1204,  0.2069,  0.4998],\n",
      "          [-0.0054, -0.2069, -0.2421,  0.4391, -0.0863],\n",
      "          [ 0.0897,  0.1110, -0.0254,  0.2607, -0.0610],\n",
      "          [-0.2977, -0.0554,  0.3332,  0.0390, -0.2463],\n",
      "          [-0.2771, -0.2614,  1.1543,  0.2599, -0.2021]]],\n",
      "\n",
      "\n",
      "        [[[-0.0814,  0.1671, -0.1768,  0.4680,  0.0617],\n",
      "          [ 0.2933, -0.0125, -0.2706,  0.3757, -0.2030],\n",
      "          [-0.2682,  0.0994, -0.2651,  0.4418, -0.2944],\n",
      "          [ 0.0404,  0.2880, -0.3709,  0.2681,  0.1469],\n",
      "          [-0.5099, -0.2306, -0.3763,  0.3394,  0.9003]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.2122,  2.6295,  1.1602,  1.9812,  1.1924,  1.5062,  1.3360,  1.4534,\n",
      "         1.6675,  0.5658,  1.3807,  2.2049,  1.3657,  1.0284,  0.9221,  1.2301,\n",
      "         1.8691,  1.2506,  1.5060,  1.6413,  1.6832,  1.6054,  1.4261,  1.6289,\n",
      "         1.3869,  1.1544,  0.9743,  0.4445,  1.5807,  1.4964,  1.1815,  1.2907,\n",
      "         0.5984,  1.8239,  0.9711,  0.9672,  0.2581,  1.0297,  2.0164,  2.2180,\n",
      "         1.4026,  3.3624,  1.6844,  1.6810,  1.1141,  1.3643,  1.9372,  1.7129,\n",
      "         2.3589,  1.4995,  1.8292,  1.7802,  2.7211,  1.1800,  1.3343,  1.3171,\n",
      "         1.0220,  1.4555,  1.7630,  1.3007,  1.3604,  1.1098,  1.3428,  1.3880,\n",
      "         1.1012,  1.7630,  2.2100,  0.9837,  0.9875,  1.7875,  1.0102,  1.4251,\n",
      "         1.1270,  1.6042,  1.4404,  1.4741,  1.7978,  0.8335,  1.5145,  1.9091,\n",
      "         0.9687,  1.3306,  1.1337,  1.6042,  1.3207,  1.5628,  1.1335,  1.4009,\n",
      "         1.5007,  1.4242,  2.0306,  1.8494,  0.7967,  0.3809,  1.9283,  1.7685,\n",
      "         1.1551,  1.4219,  2.9226,  1.5557,  1.0096,  1.4029,  0.8053,  1.3954,\n",
      "         1.1561,  0.2861,  1.9222,  1.1335,  1.6201,  1.4458,  1.2966,  0.9638,\n",
      "         0.9749,  1.1394,  1.2703,  1.4581,  1.7068,  1.7211,  1.2303,  1.2536,\n",
      "         1.0006,  1.1120,  1.6755,  1.4633,  1.3657,  2.1000,  0.9292,  1.2143,\n",
      "         1.3827,  0.7285,  1.1026,  2.7931,  1.2426,  1.3522,  1.2855,  0.4275,\n",
      "         0.6828,  1.8410,  1.8851,  1.0076,  0.8652,  1.2253,  1.0778,  0.7792,\n",
      "         1.5523,  1.6445,  0.7748,  1.4796,  1.4459,  1.2036,  1.3817,  1.6040,\n",
      "         1.3625,  1.3255,  1.6420,  1.6792,  0.9046,  1.4658,  1.7053,  1.7474,\n",
      "         1.7746,  2.4522,  0.9433,  1.7721,  1.4783,  1.2468,  1.3748,  1.5708,\n",
      "         1.0539,  0.9478,  1.2705,  1.3078,  0.5694,  1.3612,  1.4252,  1.5547,\n",
      "         1.3206,  1.5960,  1.5421,  0.8438,  1.3763,  1.1233,  0.9631,  1.5677,\n",
      "         0.8460,  1.5833,  1.6255,  1.3912,  1.2114,  1.8046,  0.8673,  0.9979,\n",
      "         1.6215,  1.1791,  1.5076,  1.2963,  1.4414,  0.5192,  1.0104,  0.8024,\n",
      "         0.9574,  1.3191,  0.8716,  2.8005,  1.6298,  1.2151,  1.0985,  1.6543,\n",
      "         1.1263,  1.7708,  1.2463,  1.7562,  1.3311,  1.0388,  1.8115,  0.1739,\n",
      "         1.2801,  0.2273,  2.1709,  1.4217,  1.2937,  0.8102,  1.6411,  1.0154,\n",
      "         1.4369,  1.3132,  2.2163,  2.4475,  2.1626,  1.1769,  1.0406,  1.3353,\n",
      "         1.1687,  0.6679,  1.9865,  1.6413,  0.7716,  0.5491,  1.5068,  1.4469,\n",
      "         1.9374,  1.4453,  0.4552,  1.7382,  1.3321,  1.4156,  1.1916,  1.0823,\n",
      "         1.7409,  2.1446,  1.1673,  1.2223,  2.0222,  0.8155,  1.4105,  1.4010,\n",
      "         1.3707,  1.3694,  1.2402,  1.3961,  1.2615,  1.9770,  1.7555,  1.6049,\n",
      "         1.6711,  1.1542,  1.6168,  1.5744,  1.0577,  0.4023,  2.2432,  1.4266,\n",
      "         1.2302,  1.7120,  0.9518,  2.9172,  1.0470,  1.0417,  1.2091,  0.9289,\n",
      "         1.4601,  1.2090,  1.5310,  1.2771,  1.2380,  1.1169,  0.9457,  0.8094,\n",
      "         1.1573,  1.3952,  1.9368,  0.9892,  1.9282,  1.3253,  0.7055,  1.9644,\n",
      "         1.6473,  1.2858,  1.6315,  1.3322,  1.3986,  1.1790,  3.3302,  1.4952,\n",
      "         0.9858,  1.4244,  1.8921,  2.3183,  0.7428,  1.0911,  1.3173,  1.4809,\n",
      "         1.4001,  1.7164,  1.2181,  1.5681,  0.9586,  1.0198,  1.3948,  0.9457,\n",
      "         1.3225,  0.9920,  0.8456,  1.9879,  1.3381,  1.2962,  1.8238,  1.3104,\n",
      "         0.6316,  1.4521,  2.0738,  1.3506,  1.1530,  1.4493,  1.6224,  1.6820,\n",
      "         1.6741,  1.3088,  1.3510,  1.2608,  1.4117,  1.4110,  0.6577,  1.1326,\n",
      "         0.7973,  1.0924,  1.3771,  1.3697,  1.4622,  1.5712,  1.8073,  0.7087,\n",
      "         1.6456,  1.3465,  1.4210,  1.5664,  1.4851,  1.0494,  1.6488,  0.7611,\n",
      "         1.2398,  1.7306,  1.1789,  2.2684,  1.7438,  0.9818,  1.2257,  1.9852,\n",
      "         0.2410,  0.5204,  1.5002,  1.4030,  1.4361,  2.0245,  1.5384,  1.0703,\n",
      "         1.6058,  1.7316,  0.6587,  1.5044,  0.8215,  0.9673,  1.4045,  2.2894,\n",
      "         1.4781,  1.3496,  0.8674,  2.0286,  1.2980,  1.2460,  1.3041,  1.8745,\n",
      "         1.5471,  1.8766,  0.8893,  1.3920,  1.0456,  1.0313,  0.6387,  1.3853,\n",
      "         1.6026,  1.4715,  1.0737,  1.5579,  1.3737,  0.7695,  1.2925,  2.1076,\n",
      "         1.7582,  1.4017,  1.2942,  1.8579,  1.1755,  1.3674,  1.2944,  2.0191,\n",
      "         1.4149,  0.9914,  2.2462,  1.9407,  2.3220,  0.8133,  1.8853,  1.1015,\n",
      "         1.2787,  0.1616,  1.5994,  1.5519,  1.1414,  1.0240,  2.2179,  1.1654,\n",
      "         0.8719,  1.6433,  2.1800,  1.5293,  1.1842,  0.4376,  1.4709,  0.9982,\n",
      "         1.3678,  1.6891,  1.0085,  1.5876,  1.0994,  1.1417,  2.5393,  1.0136,\n",
      "         1.4357,  0.4903,  1.4250,  1.0263,  0.8727,  1.5826,  1.0760,  0.4700,\n",
      "         1.0339,  1.4366,  1.6251,  1.7295,  0.9629,  1.9258,  1.2253, -0.0211,\n",
      "         1.1600,  0.4594,  1.3808,  1.1530,  1.6608,  1.2318,  1.3798,  1.7431,\n",
      "         1.5059,  2.0252,  1.9651,  0.9069,  1.2017,  1.8088,  1.9076,  1.1229,\n",
      "         0.9540,  1.0829,  1.4979,  1.2770,  0.7623,  1.5853,  1.3246,  1.2037,\n",
      "         1.6458,  1.3937,  1.5226,  2.4506,  2.2361,  1.2038,  1.0526,  1.2921,\n",
      "         1.7475,  2.2645,  1.9019,  1.5118,  0.8585,  1.6101,  0.8159,  0.7082,\n",
      "         1.0752,  1.2815,  1.6893,  1.9263,  1.9477,  1.1795,  0.7545,  1.0380,\n",
      "         1.5440,  1.9918,  1.7050,  1.2279,  1.4439,  0.7257,  0.9881,  1.3513,\n",
      "         1.3151,  1.6795,  1.7900,  1.1793,  1.5695,  1.2715,  1.1599,  1.1978,\n",
      "         0.8180,  0.9729,  1.2191,  1.3207,  0.7032,  0.8787,  2.2377,  0.9117,\n",
      "         1.3691,  1.0376,  1.1632,  1.6058,  1.0960,  1.4168,  2.4552,  1.3678,\n",
      "         1.2678,  4.2160,  2.2324,  1.8386,  1.4072,  0.9585,  1.7721,  1.7099,\n",
      "         1.4122,  1.5285,  0.9649,  1.6687,  0.9193,  1.7678,  1.3074,  1.6267,\n",
      "         1.0268,  1.4642,  1.1070,  1.2044,  1.3136,  1.2674,  0.4127,  0.9728,\n",
      "         2.3537,  0.9451,  1.4674,  0.8788,  0.7609,  1.6710,  1.3396,  1.0513,\n",
      "         1.9435,  1.8292,  1.1032,  1.5243,  1.2984,  1.7294,  0.5170,  1.6575,\n",
      "         1.6198,  1.3175,  0.6888,  2.4755,  1.1905,  1.3313,  1.2396,  1.2944,\n",
      "         1.2431,  0.9121,  1.3191,  1.3957,  1.5617,  0.5645,  1.1406,  1.9256,\n",
      "         1.2461,  1.4270,  1.3628,  1.5809,  1.1120,  2.2379,  0.0179,  1.2847,\n",
      "         1.3619,  0.9679,  2.0208,  1.3592,  1.3790,  1.3979,  1.4684,  0.4515,\n",
      "         1.6809,  1.8086,  1.0045,  1.2925,  1.8789,  1.0208,  1.6294,  1.5056,\n",
      "         1.6768,  1.3342,  1.5268,  1.7901,  1.6013,  1.5374,  0.9958,  0.9278,\n",
      "         1.8264,  1.5350,  1.3317,  0.4479,  1.0242,  0.6520,  1.6978,  1.2398,\n",
      "         1.3479,  1.9482,  1.8803,  1.0516,  1.5394,  2.0707,  0.8618,  3.6589,\n",
      "         2.1515,  1.1066,  1.2338,  1.3916,  1.7723,  1.9136,  1.3922,  1.6501,\n",
      "         1.4757,  1.9643,  2.5848,  1.4142,  1.9319,  1.4278,  1.4893,  1.0815,\n",
      "         1.9438,  1.6551,  1.1734,  1.5471,  2.1700,  0.9058,  1.4639,  0.9849,\n",
      "         1.2628,  1.2613,  1.6124,  1.0695,  1.6850,  1.4503,  1.8033,  1.8680,\n",
      "         1.7064,  1.4669,  1.1196,  1.4474,  1.2946, -0.0508,  1.3707,  1.5732,\n",
      "         1.1745,  1.7171,  1.6110,  2.0005,  1.3789,  1.5130,  1.5650,  1.6168,\n",
      "         1.0275,  1.1081,  1.0175,  1.3562,  0.5168,  1.4281,  0.7644,  0.4914,\n",
      "         1.1135,  1.3013,  1.6022,  0.2438,  1.1752,  1.5239,  2.0560,  0.9017,\n",
      "         1.0119,  1.0515,  0.7130,  1.6893,  1.5692,  1.6647,  1.6711,  1.4831,\n",
      "         1.3347,  1.4079,  1.3297,  1.0076,  2.5105,  1.0865,  0.7335,  1.6913,\n",
      "         1.3785,  1.5762,  0.7311,  2.1202,  0.8614,  1.2809,  1.4884,  2.3882,\n",
      "         1.0424,  1.3371,  1.4527,  0.9923,  1.1994,  1.0097,  1.2424,  0.5687,\n",
      "         1.7554,  1.3816,  1.3225,  1.6373,  1.6354,  2.0872,  1.5705,  1.5961,\n",
      "         0.7699,  1.3862,  0.6891,  0.9744,  1.3455,  0.6791,  0.5643,  2.0742,\n",
      "         1.5294,  2.2214,  1.3773,  1.3883,  1.2603,  1.3537,  1.4334,  0.7265,\n",
      "         1.6488,  1.0112,  1.4464,  1.4276,  0.9439,  1.6183,  1.6412,  0.7757,\n",
      "         0.6952,  2.5602,  1.6295,  1.3417,  1.7135,  1.7640,  1.2303,  1.2253,\n",
      "         1.5235,  2.6999,  1.6686,  0.9932,  1.3832,  1.6036,  1.3261,  0.7870,\n",
      "         3.3500,  1.0873,  0.6467,  1.0281,  0.9421,  1.5598,  1.9898,  1.0592,\n",
      "         1.3334,  1.0988,  1.5364,  1.3807,  1.1372,  1.5109,  1.3222,  1.5223,\n",
      "         2.7672,  1.5481,  0.1238,  1.8836,  1.2447,  0.9726,  1.6264,  2.0113],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-2.0194e+00, -2.5951e+00, -1.0688e+00, -1.2640e+00, -4.1672e-01,\n",
      "        -7.6900e-01, -7.3517e-01,  4.7586e-01, -4.0950e-01, -2.3464e-01,\n",
      "        -7.1081e-01, -2.6732e-01, -1.8849e-01, -1.3553e+00, -3.6174e-01,\n",
      "         8.5319e-02, -1.8040e+00, -1.1446e+00, -1.5883e+00, -1.4038e+00,\n",
      "        -7.6848e-01, -1.3887e+00, -1.8110e-01, -1.5163e+00, -1.7278e+00,\n",
      "        -3.8840e-01, -1.5556e-02, -4.9513e+00, -2.1001e+00, -4.6972e-01,\n",
      "        -2.8653e-01, -3.2769e-01, -2.0000e-01, -3.9430e-01, -1.8879e-01,\n",
      "        -2.2408e-01, -1.6529e-01, -4.2923e-01, -4.2003e-01, -1.1746e+00,\n",
      "        -1.7358e+00, -2.4407e-02, -1.9998e+00, -1.6214e+00, -2.0371e-01,\n",
      "        -5.6261e-01, -3.0201e+00,  3.9500e-01, -1.9106e+00, -6.9418e-01,\n",
      "        -1.8233e+00, -9.5145e-01, -1.2795e+00, -8.8017e-01, -6.7701e-01,\n",
      "        -2.5795e-01, -5.7950e-01, -1.1000e+00, -5.4141e-01, -3.1787e+00,\n",
      "        -5.3692e-01, -5.2464e-01, -5.7785e-01, -9.6357e-01, -3.3956e-01,\n",
      "        -2.1625e+00, -5.8568e-01, -4.3090e-01, -2.7171e-01, -1.1806e+00,\n",
      "        -1.9502e-01, -6.1018e-01, -6.1949e-01, -8.7274e-01, -1.9722e-01,\n",
      "        -1.0491e+00, -7.9875e-01, -2.3914e-01, -1.7516e+00, -1.2247e+00,\n",
      "        -7.1794e-01, -1.0098e+00, -5.9401e-01, -1.8366e+00, -4.7450e-01,\n",
      "        -2.0145e+00, -3.7341e-01, -8.7938e-01, -3.1363e-01, -5.9070e-01,\n",
      "        -8.2754e-01, -8.9095e-01,  1.0924e-01, -1.2599e-01, -1.8729e+00,\n",
      "        -1.3995e+00, -2.3026e+00, -5.4618e-01, -7.0341e-02, -1.1340e+00,\n",
      "        -7.3559e-01, -7.2984e-01, -6.5005e-01, -1.0069e-01,  2.5735e-01,\n",
      "        -7.0634e-02, -1.3255e+00, -5.8167e-01, -1.9030e+00, -1.7599e+00,\n",
      "        -4.0710e-01, -3.7490e-01, -2.8129e-01, -8.2520e-01, -1.7369e-01,\n",
      "        -1.1410e+00, -1.2400e+00, -1.4762e+00, -5.6541e-01, -3.7656e-01,\n",
      "        -3.0978e-01, -2.3690e-01, -9.2815e-01, -3.5298e-01, -9.6015e-01,\n",
      "        -7.7700e-01, -2.4150e-01, -5.5292e-01, -5.0635e-01, -3.4082e-01,\n",
      "        -5.9437e-01, -1.9778e-01, -5.7511e-01, -6.2930e-01, -6.2637e-01,\n",
      "        -9.4205e-02, -5.1748e-01, -1.1737e+00, -8.3347e-01, -6.7601e-01,\n",
      "        -2.8147e-01, -6.4836e-01, -4.4320e-01, -2.3618e-01, -9.2059e-01,\n",
      "        -2.0854e-01, -6.1503e-02, -1.1984e+00, -2.6309e-01, -1.0845e+00,\n",
      "        -9.3346e-01, -1.1617e+00, -2.2074e+00, -7.4544e-01, -4.2804e-01,\n",
      "        -1.1788e+00, -6.7269e-01, -1.5184e+00, -9.5804e-01, -1.2078e+00,\n",
      "        -1.4939e+00, -1.5144e+00, -5.7273e-01, -9.6385e-02, -2.1765e+00,\n",
      "        -4.3345e-01, -1.2202e+00, -7.4039e-01, -1.3726e-01, -7.0170e-01,\n",
      "        -2.4917e+00, -3.7495e+00, -3.9383e-01, -4.9089e-01, -8.7456e-01,\n",
      "        -1.0643e+00, -9.3702e-02, -1.5959e+00, -6.1825e-01, -4.1126e-01,\n",
      "        -1.2102e+00, -8.1364e-02, -2.9418e-01, -5.8029e-01, -2.9759e-01,\n",
      "        -6.8175e-01, -1.2537e+00, -8.3336e-01, -7.5549e-01, -2.3549e-01,\n",
      "        -1.2290e-01, -7.5801e-01, -1.5743e+00, -3.5489e-01, -7.9970e-02,\n",
      "        -7.1447e-01, -1.2983e+00, -3.4233e-01, -1.3643e-03, -1.4522e-01,\n",
      "        -4.1273e-01, -2.4426e+00, -3.2948e-01,  5.9361e-01,  4.3600e-02,\n",
      "        -6.2141e-01, -3.7733e-01, -1.1831e+00, -4.7464e-01, -7.5850e-01,\n",
      "        -7.9420e-01, -1.7782e+00, -1.5132e-01, -6.1529e-01, -8.7361e-01,\n",
      "        -2.4380e-02, -8.1555e-01, -1.0575e-01, -1.3696e+00, -2.8027e+00,\n",
      "        -3.7655e-02, -2.4357e-01, -5.1911e-01, -2.0588e+00, -9.2212e-01,\n",
      "        -2.0540e+00, -9.9398e-01, -1.2209e+00, -1.1123e+00, -5.4882e-01,\n",
      "        -6.7264e-02, -9.7548e-01, -5.8839e-01, -1.1202e-01, -2.0655e+00,\n",
      "        -2.9064e-01, -1.4961e-01, -1.5763e-01, -1.4328e+00, -1.6467e+00,\n",
      "        -9.6913e-01, -1.6945e+00, -7.9089e-02, -5.8555e-01, -6.4008e-01,\n",
      "        -6.8307e-01, -5.8392e-01, -3.6189e-01, -1.6884e+00, -1.4043e+00,\n",
      "        -5.4533e-01, -1.0312e+00, -1.7651e+00, -2.7598e-01, -3.1223e-01,\n",
      "        -2.8271e-01, -6.6014e-01, -5.4610e-01, -5.6011e-01, -8.1950e-01,\n",
      "        -6.3822e-01, -5.3020e-01,  8.9259e-02, -1.0854e+00, -1.3994e-01,\n",
      "        -5.4675e-01, -8.2917e-01, -1.8220e+00, -2.5491e-04, -3.5812e-01,\n",
      "        -1.1504e+00, -9.0007e-01, -6.4288e-01, -1.7672e+00, -1.6731e-01,\n",
      "        -8.6320e-01, -3.8349e-01, -1.7588e-01, -7.4002e-01, -3.2892e-01,\n",
      "        -1.4625e+00, -3.8503e-01, -1.2387e+00, -8.7817e-01, -2.3196e+00,\n",
      "        -1.2950e+00,  1.3191e-01, -2.6746e-01, -1.6267e-01, -1.1288e+00,\n",
      "        -3.7429e-01, -1.5848e-01, -7.5677e-01, -7.8997e-01, -2.2195e-01,\n",
      "        -1.3797e+00, -1.2554e+00, -1.4052e+00, -2.3230e-01, -8.9632e-01,\n",
      "        -1.6257e+00,  1.1309e-02,  6.3630e-01, -2.8373e-01, -4.4228e-02,\n",
      "        -1.8328e+00,  2.4923e-01, -1.8270e-01, -4.2479e-01, -5.2842e-01,\n",
      "        -5.4899e-01, -4.9264e-01, -8.9856e-01,  8.9219e-02, -7.5470e-01,\n",
      "        -4.9641e-01, -4.2682e-01, -4.6349e-01, -6.6063e-01, -4.0351e-01,\n",
      "        -2.4324e-01, -4.1350e-01, -6.2226e-02, -7.7515e-02, -8.1227e-01,\n",
      "        -3.3608e-01, -2.3080e+00, -5.5482e-01, -2.6846e-01, -6.5621e-01,\n",
      "        -1.5756e+00, -2.0028e-01, -2.9218e-01, -7.4203e-01, -1.6282e+00,\n",
      "        -4.8985e-01, -8.2747e-01, -5.0698e-01, -9.2472e-01, -3.4681e-01,\n",
      "        -2.7917e-01, -6.2787e-01, -4.3265e-02, -9.3411e-01, -4.6484e-01,\n",
      "        -8.6466e-01, -3.7493e+00, -7.0132e-01,  6.3712e-01, -1.3136e+00,\n",
      "        -4.6519e-01, -2.7382e-01, -1.0734e+00, -4.6335e-01, -9.2686e-01,\n",
      "        -8.0332e-01, -1.0745e+00, -7.4751e-01, -1.4665e+00, -4.5053e-01,\n",
      "        -1.1139e+00, -8.3191e-01, -3.0743e+00, -1.1868e+00, -1.5503e+00,\n",
      "        -7.1296e-01, -2.1483e+00, -2.2899e+00, -2.5253e-02, -3.9880e-02,\n",
      "        -7.3492e-01, -5.4818e-01, -3.4971e+00, -2.2365e+00, -2.0170e+00,\n",
      "        -7.0994e-01, -7.7634e-01, -2.3166e+00, -4.3971e-01, -2.4461e+00,\n",
      "        -2.9390e-01, -5.7851e-01, -5.8516e-01, -6.7364e-01, -2.4758e-03,\n",
      "        -7.6954e-01, -3.6688e-01, -1.0476e+00, -5.2236e-01, -2.9923e-01,\n",
      "        -2.6846e+00, -1.3190e+00, -1.3471e+00, -1.4390e+00, -3.4765e-01,\n",
      "        -2.0882e-01, -2.6507e-01, -4.0439e-01, -2.6382e-01, -7.8681e-01,\n",
      "        -4.8420e-01, -1.5694e+00, -4.6035e-01, -9.6364e-01, -8.9577e-01,\n",
      "        -1.3306e-01, -8.3301e-01, -4.2907e-01, -1.8247e+00, -4.2917e-01,\n",
      "        -5.8264e-01, -1.3145e+00, -5.4640e-01, -3.4979e-01, -5.2805e-01,\n",
      "        -1.6807e+00, -1.0743e+00, -5.7438e-01,  3.9175e-01, -2.0214e+00,\n",
      "        -1.3349e+00, -5.9583e-01, -1.3736e+00, -4.1787e-01, -9.3674e-01,\n",
      "        -5.9240e-02, -1.1801e+00, -5.3127e-01, -7.9654e-01, -7.2495e-01,\n",
      "        -1.4375e+00, -2.5547e-01, -3.1759e-02, -9.9821e-02, -1.1719e+00,\n",
      "        -1.4014e+00, -6.0247e-01,  1.4669e+00, -1.2851e+00, -5.7473e-01,\n",
      "        -1.4314e+00, -1.8511e+00, -6.8544e-01, -1.0058e+00, -5.7099e-01,\n",
      "        -1.0805e+00, -2.5188e-01, -5.7553e-01, -1.1490e+00, -1.0081e-01,\n",
      "        -4.2215e-01, -1.1162e+00, -2.6849e-01, -4.6703e-01, -7.9420e-02,\n",
      "         4.0648e-03, -6.3975e-01, -3.6210e-01, -7.4292e-01, -1.1167e+00,\n",
      "         2.6451e-01, -1.3396e+00, -3.1970e-01, -3.1896e-02, -6.6502e-01,\n",
      "        -5.2900e-02, -9.0523e-01, -3.3326e-01, -3.8698e-01, -2.0037e-01,\n",
      "        -9.6022e-01, -8.6531e-01, -1.1116e+00, -1.6737e+00, -5.5352e-01,\n",
      "         3.0991e-01, -4.1114e-01, -9.9471e-01, -1.5270e+00, -9.4996e-02,\n",
      "        -4.0502e-01, -4.9139e-01, -7.4247e-01, -1.4078e+00, -2.8013e-01,\n",
      "        -8.3889e-01, -4.4044e-01, -1.8548e-01, -7.1396e-01, -1.3306e+00,\n",
      "        -5.2691e-01, -1.3870e+00, -1.8754e+00, -1.3410e-02, -3.4977e-01,\n",
      "        -6.3177e-01, -1.4871e+00, -1.2773e+00, -1.1417e+00, -1.0196e+00,\n",
      "        -2.4971e-01, -3.2568e+00, -2.8671e-01,  2.3430e-01, -2.9515e-01,\n",
      "        -3.1397e-01, -1.3789e+00, -3.2374e-01, -6.8180e-01,  7.6926e-01,\n",
      "        -4.1096e-01, -3.4091e-01, -1.1363e+00,  2.0402e-02, -1.1239e-01,\n",
      "         5.4435e-03, -3.5107e-01,  1.6071e-01, -3.3620e-01, -4.3795e-01,\n",
      "        -7.0424e-01, -1.9680e+00, -7.8570e-01, -2.7656e+00, -5.4739e-01,\n",
      "        -5.0729e-01, -5.6101e-01, -6.0550e-01, -6.4453e-01, -2.6980e-01,\n",
      "        -6.5965e-02, -8.1707e-01, -1.8251e-01, -6.0929e-01, -4.6827e-01,\n",
      "        -8.6307e-02, -4.6238e-01, -2.2944e-01, -5.6376e-01, -1.1705e+00,\n",
      "        -8.4566e-01, -7.9958e-01, -1.0343e+00, -3.8308e-02, -5.3432e-02,\n",
      "         5.0036e-01,  2.8257e-01, -1.2641e+00, -1.9017e+00, -3.2106e-01,\n",
      "        -1.8011e+00, -8.2644e-01, -1.1689e+00, -1.3797e+00, -3.7859e-01,\n",
      "        -3.4597e-01,  2.7753e-01, -1.7010e+00, -1.6945e+00, -1.1686e+00,\n",
      "        -3.1213e-01, -5.8556e-01, -7.3540e-01, -5.8352e-01, -6.6881e-01,\n",
      "        -8.7006e-01, -4.2380e-02, -1.2713e-01, -1.5906e+00, -3.8083e-01,\n",
      "        -1.1265e+00, -5.0736e-01, -1.5452e-01, -2.4135e+00, -8.6949e-01,\n",
      "        -8.8625e-01, -1.6341e+00, -2.6033e+00, -7.6544e-01, -9.1338e-01,\n",
      "        -5.8304e-01, -8.6745e-01, -1.1709e-01, -5.1666e-01, -8.7008e-01,\n",
      "        -1.0350e+00, -5.1310e-01, -1.5105e+00, -7.4484e-01, -8.9038e-01,\n",
      "        -4.1323e-01, -1.6364e+00, -2.1001e+00, -8.9081e-01, -6.1836e-01,\n",
      "        -1.2565e-01, -5.0740e-01, -1.5933e-01, -6.1742e-01, -8.3074e-01,\n",
      "        -1.0422e+00, -2.5255e-01, -1.7652e+00, -1.8617e+00, -3.2979e-01,\n",
      "        -1.9146e+00,  6.3695e-02, -5.3069e-01, -2.9832e-01, -3.4084e-01,\n",
      "        -1.7378e+00, -7.2140e-01, -2.2926e+00, -5.0736e-01, -3.8266e-01,\n",
      "        -6.4967e-02, -3.0746e+00, -1.0371e+00, -3.8763e-01, -2.6179e-01,\n",
      "        -1.0278e+00,  1.8554e-01, -6.2540e-01, -7.2393e-01, -1.1511e+00,\n",
      "        -2.9592e-01, -5.5513e-01, -1.7775e+00, -1.4372e+00, -1.0642e+00,\n",
      "        -4.8313e-01, -6.1455e-01, -1.5045e+00, -6.6791e-01, -3.7539e-01,\n",
      "         1.6114e-02, -4.0295e-01, -5.2582e-02, -3.7326e-01, -6.6517e-01,\n",
      "        -4.0726e-01, -1.3761e+00, -1.5101e+00, -4.9574e-01, -1.1172e+00,\n",
      "        -1.6108e+00, -4.8633e-01, -1.5681e+00, -3.2739e-01,  7.2006e-01,\n",
      "        -1.0911e+00, -2.2624e-01, -1.8500e+00, -1.3890e+00, -8.4280e-01,\n",
      "        -7.8880e-01, -1.2300e+00, -7.8181e-01, -8.4491e-01, -1.0617e+00,\n",
      "        -1.0390e+00, -2.9337e-01, -7.7468e-01, -1.0651e+00, -9.7298e-01,\n",
      "        -8.5628e-02, -4.0243e-01, -1.2008e+00, -9.0462e-01, -1.2314e-01,\n",
      "        -1.6782e-01, -9.0328e-02, -1.0047e+00, -2.2486e-01, -7.6928e-01,\n",
      "        -5.5077e-01, -2.0534e+00, -1.4973e+00, -1.3705e+00,  2.0798e-01,\n",
      "        -2.1783e+00, -1.2183e+00, -6.2117e-01, -6.6332e-01, -2.6409e-02,\n",
      "        -3.9603e-02, -4.0156e-01, -1.7778e+00, -5.3876e-01, -7.2297e-01,\n",
      "        -1.5104e+00, -1.5859e+00, -9.6701e-01, -1.0281e+00, -9.4329e-01,\n",
      "        -2.4412e+00, -3.4990e-01, -1.8856e-01, -4.8482e-01, -1.3335e+00,\n",
      "        -8.4423e-02, -5.5661e-01, -1.6462e-01, -1.5887e-01, -9.3002e-01,\n",
      "        -7.7306e-01, -1.6801e+00, -2.8793e-02, -1.2500e+00, -1.2050e+00,\n",
      "        -3.1497e-01, -1.0010e+00, -3.8150e-01,  2.1268e-01, -9.0019e-02,\n",
      "        -1.2424e-01, -2.6214e+00, -9.6458e-01, -5.3519e-01, -1.0782e+00,\n",
      "        -7.7758e-01, -2.0761e+00, -2.1652e-01, -1.3927e+00, -3.8544e-01,\n",
      "        -5.2229e-01, -3.4592e-01, -1.3794e+00, -9.0789e-01, -9.7509e-01,\n",
      "        -2.1032e-03, -1.4847e+00, -2.0842e-01, -9.4192e-01, -6.6999e-01,\n",
      "        -1.3605e+00, -3.2506e-01, -1.2551e+00, -5.1328e-01, -6.7541e-01,\n",
      "        -6.9485e-01, -6.9496e-01, -1.5727e+00,  9.6628e-02, -1.5353e+00,\n",
      "        -5.1849e-01, -1.2478e+00, -7.4055e-01, -3.5531e-01, -1.5123e+00,\n",
      "        -2.2738e+00, -1.8623e+00,  6.1029e-01, -6.4073e-01, -2.4108e-01,\n",
      "        -7.6017e-01, -5.7402e-01, -6.7815e-02, -3.5591e-01, -1.7343e+00,\n",
      "         2.2309e-01, -8.2675e-03, -1.1305e+00, -1.0617e+00, -1.7662e+00,\n",
      "        -6.1141e-01, -9.4379e-01, -2.3013e-01, -2.1865e+00,  2.4974e-02,\n",
      "        -1.2554e+00, -1.0686e+00,  2.1595e-01, -9.9831e-01, -1.6268e+00,\n",
      "        -1.0889e-02, -2.1576e-01, -1.4097e+00, -2.1638e+00, -6.4513e-01,\n",
      "        -1.7457e+00, -1.2398e+00, -5.9302e-01, -6.6798e-01, -6.3019e-01,\n",
      "         3.7802e-01, -1.2448e+00,  1.0735e-01, -8.7955e-01, -2.4028e+00,\n",
      "        -2.0535e+00, -4.0430e-01, -2.5275e-01, -2.0364e-01,  2.4147e-01,\n",
      "        -4.3713e-01, -3.8640e-01, -1.0866e+00, -1.9595e+00, -9.6467e-01,\n",
      "        -1.0737e+00, -6.4016e-01, -1.3963e+00, -1.0086e+00, -3.8756e-01,\n",
      "        -1.4792e+00, -5.2131e-01, -1.6613e+00, -1.3942e+00, -1.5415e+00,\n",
      "         7.6443e-02, -2.2175e+00, -1.9905e-01, -6.5340e-01, -7.6727e-02,\n",
      "        -1.1157e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.1440]],\n",
      "\n",
      "         [[ 0.1656]],\n",
      "\n",
      "         [[ 0.1049]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1004]],\n",
      "\n",
      "         [[-0.0286]],\n",
      "\n",
      "         [[-0.7558]]],\n",
      "\n",
      "\n",
      "        [[[-0.1369]],\n",
      "\n",
      "         [[ 0.0864]],\n",
      "\n",
      "         [[ 0.4874]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2493]],\n",
      "\n",
      "         [[ 0.3543]],\n",
      "\n",
      "         [[ 0.2583]]],\n",
      "\n",
      "\n",
      "        [[[-0.1886]],\n",
      "\n",
      "         [[-0.6698]],\n",
      "\n",
      "         [[-0.7236]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1189]],\n",
      "\n",
      "         [[ 0.2238]],\n",
      "\n",
      "         [[-0.1014]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0513]],\n",
      "\n",
      "         [[-0.0798]],\n",
      "\n",
      "         [[-0.0136]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1154]],\n",
      "\n",
      "         [[-0.1599]],\n",
      "\n",
      "         [[-0.1012]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0096]],\n",
      "\n",
      "         [[ 0.3459]],\n",
      "\n",
      "         [[ 0.0409]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0337]],\n",
      "\n",
      "         [[ 0.0162]],\n",
      "\n",
      "         [[-0.3775]]],\n",
      "\n",
      "\n",
      "        [[[-0.0528]],\n",
      "\n",
      "         [[-0.2861]],\n",
      "\n",
      "         [[-0.2386]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2611]],\n",
      "\n",
      "         [[ 0.1183]],\n",
      "\n",
      "         [[-0.3310]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1524,  0.0570,  0.1671, -0.0083,  0.2738, -0.1378,  0.0162,  0.1522,\n",
      "        -0.2013,  0.1194, -0.0409,  0.0582,  0.0103, -0.3160, -0.3768,  0.0277,\n",
      "        -0.3466,  0.2078, -0.2777, -0.2542, -0.0553,  0.1067, -0.2062,  0.0675,\n",
      "        -0.2618,  0.0961, -0.2960, -0.0248,  0.2094, -0.2740, -0.0750, -0.3103,\n",
      "         0.2116,  0.2371], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0778]],\n",
      "\n",
      "         [[ 0.0648]],\n",
      "\n",
      "         [[-0.5101]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0783]],\n",
      "\n",
      "         [[ 0.0873]],\n",
      "\n",
      "         [[-0.2650]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4176]],\n",
      "\n",
      "         [[ 0.1532]],\n",
      "\n",
      "         [[ 0.3974]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0224]],\n",
      "\n",
      "         [[ 0.3582]],\n",
      "\n",
      "         [[ 0.1681]]],\n",
      "\n",
      "\n",
      "        [[[-0.4171]],\n",
      "\n",
      "         [[ 0.2066]],\n",
      "\n",
      "         [[-0.4628]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1326]],\n",
      "\n",
      "         [[-0.3074]],\n",
      "\n",
      "         [[-0.1244]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0530]],\n",
      "\n",
      "         [[-0.2986]],\n",
      "\n",
      "         [[-0.0554]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0179]],\n",
      "\n",
      "         [[-0.2947]],\n",
      "\n",
      "         [[-0.1624]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3782]],\n",
      "\n",
      "         [[ 0.2512]],\n",
      "\n",
      "         [[-0.0239]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0911]],\n",
      "\n",
      "         [[ 0.3144]],\n",
      "\n",
      "         [[-0.1487]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1252]],\n",
      "\n",
      "         [[ 0.0609]],\n",
      "\n",
      "         [[ 0.4009]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0990]],\n",
      "\n",
      "         [[ 0.3919]],\n",
      "\n",
      "         [[ 0.2478]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.4793e-01,  1.7150e-01, -5.9452e-02,  2.9614e-01,  5.2613e-02,\n",
      "        -2.1388e-01, -1.1888e-02,  6.3780e-01,  4.4818e-01, -7.6143e-03,\n",
      "        -5.4811e-02, -1.0981e-01, -3.1084e-01,  5.6857e-02,  3.8286e-01,\n",
      "         4.7686e-01,  6.7531e-02, -4.9474e-03,  1.3020e-01,  4.2308e-01,\n",
      "        -1.2543e-01, -2.7197e-01,  3.9040e-01,  5.7872e-01,  3.8887e-01,\n",
      "        -3.8506e-01, -2.0942e-01, -3.5475e-01,  4.6055e-01, -6.2926e-02,\n",
      "         3.5491e-01,  5.8769e-02,  1.6290e-01,  1.4716e-01, -3.5983e-01,\n",
      "         3.3605e-01, -3.0548e-01, -3.5318e-01,  6.8975e-02,  1.3430e-01,\n",
      "        -5.0923e-01, -1.0557e-01,  9.7766e-02,  8.8288e-03, -5.4371e-02,\n",
      "        -4.8485e-01, -4.4877e-01, -2.4384e-02,  1.6484e-01,  2.6200e-01,\n",
      "         3.3698e-01,  5.7279e-02, -6.0764e-02,  2.3601e-01, -4.5340e-01,\n",
      "         5.7830e-02, -1.4837e-01,  4.6856e-02,  3.3785e-01, -3.3270e-01,\n",
      "        -4.1339e-01, -1.9998e-01,  2.9543e-01, -3.6034e-01,  4.4257e-02,\n",
      "        -4.8036e-02,  3.9949e-01, -4.6760e-01,  4.7235e-01,  4.3422e-01,\n",
      "         3.8473e-01,  6.6675e-03,  3.0887e-01,  1.4341e-02,  4.9776e-01,\n",
      "         1.2538e-01, -4.6895e-01, -1.1259e-01, -4.1016e-03,  2.1678e-01,\n",
      "         3.7403e-01, -1.5002e-01, -2.6790e-01, -2.0223e-02,  2.1526e-01,\n",
      "        -3.5750e-01, -1.2739e-01, -3.2805e-01, -5.0004e-02,  3.4091e-01,\n",
      "        -2.2684e-01, -3.1975e-02, -1.0214e-02,  2.7299e-01,  1.7129e-01,\n",
      "        -2.5243e-02, -2.4585e-01,  1.3924e-01, -2.2032e-01, -2.7139e-02,\n",
      "        -2.9956e-01,  8.0307e-02,  3.5092e-01,  1.3470e-01,  3.0377e-01,\n",
      "        -4.0926e-01, -4.5217e-02, -6.6688e-02,  4.4160e-01, -4.0886e-01,\n",
      "        -1.4884e-01, -7.7409e-02, -4.4149e-01,  3.3205e-01,  2.8410e-01,\n",
      "        -6.1098e-01,  4.4393e-01,  2.3359e-03, -2.8335e-01,  3.7502e-01,\n",
      "         1.6020e-01, -2.3563e-01,  5.0314e-01,  4.4133e-01, -1.3480e-01,\n",
      "         4.7674e-02,  2.0614e-01, -1.3905e-01,  2.1605e-01, -4.6472e-01,\n",
      "         1.5118e-01, -4.2328e-01, -2.8470e-01, -3.6250e-01, -1.1566e-01,\n",
      "         2.7526e-01,  3.3964e-01,  5.0424e-02, -1.8353e-01, -2.0043e-01,\n",
      "        -2.4443e-01, -1.1492e-01, -4.7819e-01,  4.1459e-01,  2.1070e-01,\n",
      "        -1.6596e-01,  3.4685e-01, -9.3203e-02, -1.3600e-02, -1.5301e-01,\n",
      "        -4.6587e-01, -4.0916e-01, -1.2446e-01,  5.9367e-02, -3.7158e-01,\n",
      "        -6.6146e-02,  1.7104e-01, -3.1296e-01,  2.6777e-01,  5.9509e-01,\n",
      "        -4.2755e-01,  4.3387e-01, -1.4361e-02,  3.6085e-01,  3.9986e-01,\n",
      "         3.2339e-01,  7.7505e-02,  5.7826e-02,  2.2253e-01, -2.2281e-01,\n",
      "         4.0014e-01,  6.2890e-01,  7.0947e-02,  7.8476e-02, -3.1669e-01,\n",
      "        -4.4938e-01, -1.1552e-01, -5.3681e-01, -4.3010e-01, -4.4926e-01,\n",
      "        -2.4862e-02, -9.7873e-02, -1.9036e-01, -1.0954e-01, -2.3309e-01,\n",
      "         1.7674e-01,  4.9633e-01,  2.9273e-01,  3.3075e-02, -5.4220e-02,\n",
      "         2.4217e-01, -6.2460e-02, -3.5928e-01,  2.2044e-01,  1.9121e-01,\n",
      "        -2.7950e-01, -2.5490e-01, -4.5458e-03,  8.4154e-02,  3.8369e-02,\n",
      "        -3.2484e-01,  9.6393e-03, -3.6825e-01,  2.5707e-02,  1.6551e-01,\n",
      "        -4.7668e-01, -3.9132e-02,  1.7206e-01,  1.4075e-01, -4.0697e-01,\n",
      "        -3.4328e-01,  2.7592e-01,  2.6625e-01,  2.4760e-01,  2.9794e-01,\n",
      "         3.9394e-02, -1.2454e-01, -2.5643e-01,  1.5397e-01,  3.0623e-01,\n",
      "         2.8463e-01, -1.6830e-01,  9.1932e-02, -1.7311e-01, -2.1440e-01,\n",
      "         5.2433e-01,  5.8657e-01, -2.4786e-01,  4.8217e-01,  2.4716e-02,\n",
      "        -5.8667e-02,  1.9817e-01, -3.0897e-01,  3.7744e-01,  1.7539e-02,\n",
      "         3.2743e-01, -4.3125e-01,  1.4466e-01,  3.7201e-01, -4.4283e-01,\n",
      "         5.6913e-01, -5.0030e-02,  2.2227e-01, -1.8381e-01,  2.1917e-01,\n",
      "         3.8043e-02,  1.5450e-02,  4.3457e-01, -4.7599e-01,  4.7283e-01,\n",
      "        -5.0081e-01, -2.2624e-01,  2.8752e-01, -2.7406e-01,  6.0443e-02,\n",
      "         5.1783e-02,  6.4304e-01,  2.2799e-01, -1.8680e-01, -3.4486e-01,\n",
      "        -7.5771e-01, -1.5161e-01,  2.2705e-01,  1.9366e-01, -1.5139e-01,\n",
      "        -5.6838e-01,  2.4444e-02, -4.2914e-01,  2.0184e-01, -2.4564e-01,\n",
      "         2.7833e-01, -8.3640e-02, -5.4589e-02,  4.9542e-01,  1.7583e-01,\n",
      "        -1.2833e-01, -3.7867e-01,  1.3753e-01, -1.6469e-01,  8.2451e-02,\n",
      "        -4.1618e-01, -1.7720e-01,  2.9225e-01,  3.0884e-01,  2.3902e-01,\n",
      "        -1.8656e-01,  3.1244e-01, -1.0112e-01,  4.0442e-01, -2.8092e-01,\n",
      "         3.2724e-01,  2.5278e-01,  2.7254e-01, -3.3814e-01, -4.7048e-02,\n",
      "         3.3283e-01,  2.0807e-01, -5.6528e-01,  7.7799e-03, -3.7378e-01,\n",
      "         4.3250e-01,  1.4112e-01,  4.3132e-02, -2.9192e-02,  3.3371e-01,\n",
      "        -4.1213e-01,  2.9066e-01,  5.6454e-01, -5.7755e-01, -5.2608e-01,\n",
      "        -4.0221e-01, -8.0052e-02, -5.1514e-03,  4.4391e-01,  4.0068e-02,\n",
      "         4.1329e-01, -1.2550e-01, -2.3944e-01,  5.2505e-01,  1.2605e-01,\n",
      "         1.3773e-01, -8.1694e-02, -1.4656e-01, -7.7641e-02,  2.1659e-01,\n",
      "        -1.4701e-01,  4.4496e-01,  1.1654e-01, -1.8119e-01, -1.4381e-02,\n",
      "         3.6469e-01, -5.3184e-02, -7.2261e-02, -4.0901e-01, -2.9619e-01,\n",
      "         9.3561e-02, -6.9521e-02,  2.4894e-01,  1.1514e-01, -3.3245e-01,\n",
      "         2.4821e-01,  4.5278e-02,  1.9541e-01,  4.7987e-01,  1.4614e-01,\n",
      "         2.7159e-01, -1.2750e-01, -4.5963e-02,  2.0756e-01,  1.6023e-02,\n",
      "        -4.7953e-02, -1.2213e-01, -3.8807e-01,  2.8377e-01, -3.5044e-01,\n",
      "        -1.3423e-02,  2.7832e-01,  3.8959e-01,  2.3612e-01,  1.6392e-01,\n",
      "         4.5336e-02,  1.8446e-01,  2.1453e-01, -1.3001e-01, -6.2165e-01,\n",
      "         4.7398e-01, -2.9247e-02,  3.2234e-01,  4.5043e-01, -2.2360e-01,\n",
      "        -6.7215e-02,  2.2383e-01, -2.3612e-01,  2.1815e-01, -1.4713e-01,\n",
      "         4.9308e-01,  2.9849e-01,  6.8925e-02,  4.8754e-01,  1.2415e-01,\n",
      "         2.6378e-01, -6.1931e-02,  2.1757e-01,  2.0800e-01,  4.6346e-02,\n",
      "        -2.5762e-01, -4.9463e-01,  2.5678e-01,  5.4933e-01, -5.2578e-01,\n",
      "        -2.8113e-02, -1.3951e-01, -9.4950e-02, -5.5755e-02, -4.2993e-01,\n",
      "         3.2095e-02,  8.8681e-02, -1.5598e-01,  2.5553e-01, -3.2086e-01,\n",
      "         2.2315e-02, -8.0428e-02, -2.3203e-01, -3.5341e-01, -5.0000e-02,\n",
      "        -5.1352e-01,  1.7267e-01,  4.2156e-01,  3.5200e-01, -4.8096e-01,\n",
      "         1.2150e-01, -4.6203e-01,  7.0760e-02,  3.4114e-02, -3.4322e-02,\n",
      "         4.0213e-01, -5.1144e-01,  3.2908e-01,  2.7235e-01,  6.3518e-02,\n",
      "        -2.7139e-01, -1.6591e-02,  9.7836e-02, -4.7150e-01, -5.3333e-01,\n",
      "        -4.4964e-01, -3.1925e-01, -5.0434e-01, -4.7351e-01, -3.3585e-01,\n",
      "         5.2787e-02, -4.3116e-01,  6.1972e-02,  4.6807e-01,  3.0092e-01,\n",
      "         1.3385e-01, -3.1206e-01, -1.8130e-01, -3.9622e-01, -3.8506e-01,\n",
      "        -3.7693e-01, -2.1187e-01, -4.1762e-01,  7.3519e-02,  3.8264e-01,\n",
      "        -2.8077e-02,  4.7014e-01, -1.6678e-01, -1.5282e-01,  2.8343e-01,\n",
      "         4.9870e-01,  1.2663e-01, -1.5940e-02,  6.4407e-01,  3.7472e-01,\n",
      "         2.5690e-01, -3.7086e-01,  4.0442e-02,  2.3383e-01, -3.3933e-02,\n",
      "         5.8846e-01, -2.1950e-03, -3.0876e-01, -4.4257e-01, -1.4849e-01,\n",
      "        -4.2886e-01, -5.0756e-03, -5.4225e-01, -5.1854e-01, -2.3940e-01,\n",
      "         2.3923e-02,  3.7774e-01,  1.8946e-01, -1.5357e-01,  4.8055e-01,\n",
      "         2.1096e-01,  3.5033e-01,  4.4628e-01,  2.4539e-01,  2.6252e-01,\n",
      "         5.0156e-02,  4.4017e-02, -2.1264e-01, -4.9048e-01, -5.3376e-02,\n",
      "        -5.1009e-01,  3.3194e-01,  4.6880e-01, -1.4544e-01, -4.4291e-01,\n",
      "         2.6951e-02,  4.8159e-01, -2.2610e-01,  2.3380e-01,  3.2852e-01,\n",
      "        -5.2034e-01,  8.8355e-02,  4.0294e-01,  5.0194e-01,  1.3468e-01,\n",
      "        -5.2535e-01, -1.0023e-01, -2.2418e-01,  2.0873e-01, -1.4755e-01,\n",
      "         2.4851e-01, -4.0988e-01,  1.3697e-01, -9.1837e-02,  3.6085e-01,\n",
      "         1.7789e-01, -5.4599e-01, -1.5103e-01,  4.5483e-01,  5.3222e-02,\n",
      "         4.3719e-01, -2.4165e-01, -1.1023e-01, -2.5727e-01, -2.0343e-01,\n",
      "         2.2771e-01,  6.1716e-02, -1.7871e-01, -1.1999e-02,  2.8679e-01,\n",
      "        -3.2355e-01, -4.6067e-01, -3.7946e-02,  4.7616e-02, -1.1942e-01,\n",
      "         7.3544e-02,  1.4521e-01, -4.5653e-01, -8.0372e-02, -8.4568e-02,\n",
      "        -3.2705e-02,  1.7056e-01, -1.4065e-01, -2.1514e-01,  5.1758e-01,\n",
      "        -2.5718e-01, -1.8680e-01,  1.9967e-01, -1.6461e-02,  2.9905e-01,\n",
      "        -6.9053e-02, -9.2071e-02, -1.8860e-01,  4.5481e-01, -1.6677e-01,\n",
      "         2.2692e-02,  1.1187e-01,  2.0785e-01,  3.4236e-01,  1.0022e-01,\n",
      "         1.8416e-01,  3.7431e-01,  1.4036e-01,  8.3627e-02,  9.5848e-03,\n",
      "        -2.4980e-02, -6.1456e-02,  3.7734e-01,  2.4662e-01,  1.4015e-01,\n",
      "         2.0982e-01,  2.9990e-01, -1.4761e-02,  5.0412e-02, -4.2353e-01,\n",
      "        -3.3420e-01,  1.5523e-01,  1.1974e-01,  4.6002e-02, -7.6552e-02,\n",
      "         3.6403e-01,  3.0315e-01, -3.8549e-01,  1.7282e-02,  5.2307e-01,\n",
      "        -1.5580e-02,  7.7364e-02,  1.4144e-01, -9.1302e-02, -1.0145e-01,\n",
      "         6.7926e-02, -1.6385e-01,  4.3464e-01,  2.4806e-01, -2.3358e-01,\n",
      "        -4.7413e-02,  7.1329e-02,  8.2492e-02, -2.8976e-01, -2.9824e-01,\n",
      "         5.0648e-01,  3.9152e-01,  3.8140e-01, -2.3500e-01, -7.7697e-02,\n",
      "        -3.3267e-02, -2.4458e-01,  2.3887e-02, -2.0596e-01, -3.6330e-01,\n",
      "        -3.3299e-01, -5.7149e-02, -1.5195e-01,  3.0976e-01, -4.0535e-01,\n",
      "         2.8812e-01, -1.3586e-01,  1.5320e-01, -4.5115e-02,  9.9624e-02,\n",
      "        -5.5171e-01, -2.4693e-02,  4.4383e-01,  4.2275e-01, -3.7110e-01,\n",
      "        -1.2238e-01, -2.6926e-01, -3.3675e-01,  2.2574e-01, -2.5264e-01,\n",
      "        -8.1722e-02, -2.7883e-01,  9.7480e-02, -1.0217e-01,  3.8466e-02,\n",
      "        -3.5557e-01,  1.4304e-02, -1.4239e-01,  1.5052e-03,  1.4105e-01,\n",
      "        -2.3343e-01, -2.7853e-01, -4.1491e-01, -6.3197e-02,  1.8014e-01,\n",
      "         5.6419e-01, -2.1463e-02, -8.9738e-02, -3.4638e-01, -4.7823e-01,\n",
      "         3.4845e-01,  1.1500e-01, -4.2475e-01,  5.0984e-01,  1.2524e-02,\n",
      "         1.0365e-01,  1.7389e-01, -4.3852e-01,  2.2472e-02, -5.2986e-01,\n",
      "         4.7590e-01,  1.4690e-01,  1.1063e-01, -3.9303e-01, -3.8922e-01,\n",
      "         1.5135e-01, -1.0934e-01,  3.9735e-01,  2.2947e-01, -2.6478e-01,\n",
      "         2.2595e-01,  1.2095e-01, -4.4608e-01,  1.4385e-01, -3.7427e-02,\n",
      "         1.3411e-01,  5.3298e-01, -3.4963e-01,  2.4349e-01, -2.7021e-03,\n",
      "        -5.3489e-01,  5.9071e-04, -2.5678e-01, -3.4056e-01,  6.1810e-01,\n",
      "         1.1724e-01,  1.3440e-01, -2.6066e-01,  1.4770e-01,  2.6517e-01,\n",
      "        -4.8259e-01, -1.2388e-02, -2.1861e-02, -2.3783e-01, -1.7833e-01,\n",
      "        -4.3273e-01, -4.7997e-03, -1.6875e-01,  4.6371e-01,  6.2797e-02,\n",
      "         2.0842e-01,  1.5475e-01, -1.3885e-01, -3.5497e-01, -6.5250e-01,\n",
      "        -4.2895e-01,  2.0215e-01, -3.8708e-01, -3.3121e-01, -3.9324e-01,\n",
      "        -3.4341e-01, -5.6045e-01,  1.5968e-01, -1.5281e-01, -3.9977e-01,\n",
      "        -8.9908e-03,  1.6299e-01, -4.0449e-01, -2.1534e-01, -2.4435e-01,\n",
      "         1.3113e-01, -1.7675e-01, -3.7787e-02,  2.5969e-01,  4.7522e-02,\n",
      "        -4.1902e-01, -1.2991e-01,  6.0320e-02, -5.8920e-02, -3.7987e-02,\n",
      "        -3.7252e-01, -4.8342e-02,  1.3617e-02,  2.9839e-02,  3.7026e-01,\n",
      "         3.1731e-01,  1.9603e-01, -3.4472e-02, -1.7535e-01, -2.4768e-01,\n",
      "         5.1111e-01,  5.7145e-01, -4.1486e-01, -1.7469e-03, -2.8102e-01,\n",
      "        -1.2770e-01, -3.8028e-01, -2.4506e-01,  3.6514e-01, -2.9615e-01,\n",
      "         3.2837e-02,  1.1296e-01,  3.5687e-01,  4.9767e-01,  1.0684e-01,\n",
      "        -3.9326e-02, -4.1177e-01,  3.6545e-01, -2.9412e-01, -8.2051e-02,\n",
      "        -3.2901e-01, -2.8219e-01, -4.3695e-01,  9.7290e-02, -4.4029e-01,\n",
      "        -9.6832e-02,  4.7049e-01, -4.3732e-01, -3.1915e-01, -3.9142e-01,\n",
      "         4.4887e-01,  5.9601e-02,  8.5822e-02,  8.6479e-02, -1.9270e-01,\n",
      "         2.4424e-01, -1.2231e-01,  2.0661e-01, -3.9946e-01, -9.4739e-02,\n",
      "        -2.6622e-01, -2.9740e-01, -3.0759e-01,  2.7863e-01, -3.0057e-01,\n",
      "         5.4798e-02,  4.1046e-01, -5.4509e-01,  3.8377e-02,  4.6520e-02,\n",
      "        -1.3587e-02,  4.5464e-01, -8.0477e-02, -8.1680e-02, -2.3047e-01,\n",
      "         1.7870e-01,  1.4955e-01,  1.0720e-02,  2.7824e-01, -1.4206e-01,\n",
      "        -2.8581e-01, -7.4679e-02,  1.1404e-01, -2.0583e-02, -3.7798e-02,\n",
      "         3.9921e-02, -5.1721e-01, -5.0831e-01,  2.4331e-02,  2.8305e-02,\n",
      "         4.3415e-01,  3.7824e-01,  1.6417e-01,  4.8682e-01, -4.2254e-02,\n",
      "        -4.4978e-01,  3.0002e-02,  3.0501e-01, -4.7373e-01, -1.2985e-01,\n",
      "         2.3082e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1004]],\n",
      "\n",
      "         [[ 0.1175]],\n",
      "\n",
      "         [[ 0.2836]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1341]],\n",
      "\n",
      "         [[-0.4307]],\n",
      "\n",
      "         [[-0.9289]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3547]],\n",
      "\n",
      "         [[-0.4201]],\n",
      "\n",
      "         [[-0.2304]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1634]],\n",
      "\n",
      "         [[-0.1796]],\n",
      "\n",
      "         [[-0.0450]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3600]],\n",
      "\n",
      "         [[ 0.0239]],\n",
      "\n",
      "         [[ 0.0970]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4544]],\n",
      "\n",
      "         [[-0.3136]],\n",
      "\n",
      "         [[-0.3251]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1333]],\n",
      "\n",
      "         [[ 0.3931]],\n",
      "\n",
      "         [[-0.1351]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2464]],\n",
      "\n",
      "         [[-0.3427]],\n",
      "\n",
      "         [[-0.4843]]],\n",
      "\n",
      "\n",
      "        [[[-0.3559]],\n",
      "\n",
      "         [[ 0.8401]],\n",
      "\n",
      "         [[-0.0432]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4168]],\n",
      "\n",
      "         [[-0.5883]],\n",
      "\n",
      "         [[-0.0059]]],\n",
      "\n",
      "\n",
      "        [[[-0.0851]],\n",
      "\n",
      "         [[ 0.2673]],\n",
      "\n",
      "         [[ 0.0670]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4348]],\n",
      "\n",
      "         [[-0.0149]],\n",
      "\n",
      "         [[-0.9739]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 5.7752e-01,  1.0614e-01,  3.5740e-01,  9.7997e-01,  1.5111e-01,\n",
      "         3.7889e-02,  1.2635e+00,  2.2854e+00,  7.5306e-01,  3.9757e-01,\n",
      "         1.0871e-01,  4.3539e-01,  1.1214e+00,  6.9633e-02,  5.9412e-01,\n",
      "         1.7639e+00, -1.7425e-02,  6.0605e-01,  7.3637e-01,  9.3603e-02,\n",
      "         1.3805e+00,  8.7979e-01,  4.7265e-01,  1.1020e+00,  1.3725e+00,\n",
      "         8.2803e-01,  6.6040e-02,  6.6245e-02,  2.4061e-02,  1.3515e-01,\n",
      "         2.6277e-01, -1.4337e-04,  1.0026e+00,  1.1383e-01,  1.3389e+00,\n",
      "         1.7951e-01,  2.2805e-02,  2.4576e-01,  6.0484e-01,  8.8751e-01,\n",
      "         1.1655e+00,  4.3275e-01,  1.9654e-01,  6.7215e-02,  6.4596e-01,\n",
      "         1.4286e+00,  8.1542e-01,  1.1305e+00,  5.4342e-01,  6.8921e-01,\n",
      "         2.5158e+00,  6.0138e-01,  6.3719e-01,  1.1964e-01,  4.7883e-01,\n",
      "         2.4509e-01,  5.2073e-01, -2.0699e-02,  1.7456e+00,  1.0857e-01,\n",
      "         9.7408e-01,  2.3510e-01,  2.6573e-01,  1.6386e+00,  1.1040e-01,\n",
      "         6.3806e-01,  5.0279e-01,  3.2748e-01,  1.3138e+00,  1.0739e-01,\n",
      "         8.4099e-01,  1.7860e+00,  1.8624e+00,  6.9036e-01,  1.5549e+00,\n",
      "         3.6579e-01,  1.2140e+00,  1.7811e+00,  4.2557e-01,  1.2584e-01,\n",
      "         4.4063e-01,  4.0312e-01,  1.0994e+00,  3.5736e-01,  1.2031e-01,\n",
      "         3.3719e-02,  6.5085e-01,  3.2546e-01,  5.7420e-01,  2.0744e-01,\n",
      "         9.0253e-01,  1.5431e+00,  1.1217e+00,  7.6803e-01,  3.5746e-01,\n",
      "         1.1323e+00,  1.4296e-01,  1.0767e-01,  5.4109e-01,  1.0628e-01,\n",
      "         1.3906e+00, -8.1900e-02,  1.7246e-01,  6.3218e-01,  9.1833e-01,\n",
      "         4.8883e-01,  1.4732e+00,  1.0095e+00,  5.7736e-01,  5.2174e-01,\n",
      "         1.4680e+00,  7.2890e-01,  1.0284e+00,  7.2312e-01,  5.1567e-01,\n",
      "         1.1682e+00,  7.1809e-01,  1.4529e+00,  1.2279e+00,  2.3805e-01,\n",
      "         6.4645e-01,  8.6554e-01,  7.8655e-01,  9.2051e-01,  7.9968e-01,\n",
      "         1.0224e+00,  1.3057e+00,  3.9145e-02,  4.6199e-01,  2.5385e-01,\n",
      "         1.0465e+00,  8.2702e-01,  2.9905e-01,  1.6282e+00,  1.5933e+00,\n",
      "         3.3112e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.0597,  0.0357,  0.1018,  0.1156,  0.1087,  0.1530, -0.2455, -0.7668,\n",
      "        -0.3129,  0.1613,  0.4803,  0.4587, -0.1444,  0.0274,  0.2193,  0.4418,\n",
      "         0.2588, -0.0804, -0.1344,  0.1727, -0.1258,  0.1019, -0.2475,  0.1757,\n",
      "         0.0969,  0.5833,  0.0100, -0.0207,  0.2093, -0.4251, -0.1299, -0.1393,\n",
      "        -0.0163,  0.0940, -0.1458, -0.2590,  0.1326, -0.2497,  0.0255, -0.3133,\n",
      "         0.2295,  0.1127, -0.1885,  0.3444, -0.2479,  0.3173,  0.0871,  0.3218,\n",
      "        -0.3780,  0.1022, -0.2980,  0.1888,  0.3922,  0.0632,  0.0532, -0.0427,\n",
      "         0.1010, -0.2112, -0.4107, -0.0407, -0.1862, -0.1362, -0.0175, -0.0274,\n",
      "        -0.0485,  0.0728, -0.0510, -0.2726,  0.6336, -0.1359, -0.0923, -0.3313,\n",
      "         0.2194,  0.1233,  0.3224,  0.1585, -0.3102, -0.0897, -0.3644, -0.3424,\n",
      "        -0.0772, -0.0683,  0.1902,  0.2163, -0.1131,  0.0403,  0.2182, -0.3153,\n",
      "         0.2687,  0.4780,  0.1097,  0.0730, -0.2582,  0.2435, -0.1024, -0.4268,\n",
      "        -0.2855,  0.1719,  0.1859, -0.0186,  0.2428,  0.0935, -0.1210, -0.0921,\n",
      "         0.1463, -0.1051, -0.2004,  0.2670, -0.1790,  0.1739,  0.2048,  0.0842,\n",
      "        -0.2933, -0.3425, -0.0081, -0.0221, -0.0935, -0.3545, -0.0143,  0.0450,\n",
      "        -0.0328,  0.2026, -0.2000, -0.0804, -0.1173,  0.3419, -0.1564,  0.1982,\n",
      "        -0.0402,  0.1372, -0.2564, -0.0856, -0.0808,  0.3453,  0.2386,  0.0299],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0732]],\n",
      "\n",
      "         [[ 0.7270]],\n",
      "\n",
      "         [[-0.2480]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3571]],\n",
      "\n",
      "         [[ 0.1296]],\n",
      "\n",
      "         [[-0.4887]]],\n",
      "\n",
      "\n",
      "        [[[-0.1250]],\n",
      "\n",
      "         [[ 0.2258]],\n",
      "\n",
      "         [[ 0.2489]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0107]],\n",
      "\n",
      "         [[-0.5942]],\n",
      "\n",
      "         [[-0.3162]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2668]],\n",
      "\n",
      "         [[-0.3077]],\n",
      "\n",
      "         [[-0.1630]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0335]],\n",
      "\n",
      "         [[-0.0727]],\n",
      "\n",
      "         [[-0.3751]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1097]],\n",
      "\n",
      "         [[-0.3107]],\n",
      "\n",
      "         [[ 0.0538]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3566]],\n",
      "\n",
      "         [[ 0.1166]],\n",
      "\n",
      "         [[-0.2004]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2393]],\n",
      "\n",
      "         [[-0.1158]],\n",
      "\n",
      "         [[-0.3431]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1795]],\n",
      "\n",
      "         [[-0.0252]],\n",
      "\n",
      "         [[ 0.5156]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0807]],\n",
      "\n",
      "         [[ 0.0169]],\n",
      "\n",
      "         [[-0.1339]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1288]],\n",
      "\n",
      "         [[-0.0280]],\n",
      "\n",
      "         [[-0.2925]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.4525e+00,  2.2622e-01,  1.1843e+00,  5.7588e-01,  1.1479e+00,\n",
      "         1.1495e+00, -9.5981e-01,  1.0350e+00,  9.1412e-01,  1.1421e+00,\n",
      "         1.0557e+00,  1.2009e+00,  1.1846e+00,  1.3351e+00,  1.5590e+00,\n",
      "         1.0508e+00,  9.2044e-01,  1.2331e+00,  6.7342e-01,  8.5523e-01,\n",
      "         1.0575e+00,  1.0818e+00,  1.2079e+00,  3.5437e-01,  1.1852e+00,\n",
      "         3.2246e+00,  6.2836e-01,  1.2244e+00,  1.0905e+00,  1.0976e+00,\n",
      "         8.3561e-01,  1.1221e+00,  1.1895e+00,  1.2126e+00,  1.0283e+00,\n",
      "         7.9632e-01,  4.2433e-01,  3.9470e-01,  1.1928e+00,  1.1902e+00,\n",
      "         1.0648e+00, -8.4577e-02,  1.1818e+00,  1.1252e+00,  1.3228e+00,\n",
      "         9.1792e-01,  1.1153e+00,  8.8129e-01,  8.8438e-01,  1.6449e+00,\n",
      "         5.2450e-01,  1.1346e+00,  9.0224e-01,  1.4264e+00,  1.1084e+00,\n",
      "         1.2463e+00,  1.0770e+00,  1.1798e+00,  9.2688e-01,  1.3351e+00,\n",
      "         9.8286e-01,  1.1070e+00,  1.2193e+00,  1.1921e+00,  1.0724e+00,\n",
      "         1.2575e+00, -8.5623e-02,  1.2370e+00,  4.5914e-01,  1.2921e+00,\n",
      "         1.2220e+00,  1.0399e+00,  1.1690e+00,  6.3343e-03,  1.2083e+00,\n",
      "         6.8397e-01,  1.0356e+00,  1.3090e+00,  8.7158e-01,  2.1977e+00,\n",
      "         1.1467e+00,  1.3158e+00,  1.0237e+00,  1.2231e+00,  1.2106e+00,\n",
      "         1.1421e+00,  1.0785e+00,  1.2020e+00,  5.4223e-01,  1.8569e+00,\n",
      "         8.2512e-01,  4.5114e-01,  9.7930e-01,  1.0718e+00,  1.0881e+00,\n",
      "         1.0750e+00,  1.6025e+00,  1.1186e+00,  1.0041e+00,  9.2232e-01,\n",
      "         9.9851e-01,  1.1746e+00,  1.0631e+00,  1.1773e+00,  1.1292e+00,\n",
      "         1.7809e+00,  1.2708e+00,  9.1730e-01,  1.3982e+00,  1.2155e+00,\n",
      "         1.8352e+00, -1.0468e-01,  9.9058e-01,  1.9830e+00,  1.0471e+00,\n",
      "         1.1079e+00,  1.0978e+00,  1.1267e+00,  1.2417e+00,  1.0624e+00,\n",
      "         2.0610e+00,  1.2329e+00,  1.1231e+00,  1.2492e+00,  1.1470e+00,\n",
      "         9.7794e-01,  1.0863e+00,  9.9976e-01,  1.2365e+00,  3.3527e-01,\n",
      "         9.9255e-01,  2.6410e-01,  1.6823e+00,  3.1413e-01,  6.1022e-01,\n",
      "         1.5781e+00,  1.4158e+00,  1.9036e+00,  1.7069e+00,  1.9348e+00,\n",
      "         2.3018e+00,  8.8187e-01,  1.1547e+00,  1.1654e+00,  1.2632e+00,\n",
      "         1.3096e+00,  8.3757e-01,  8.8099e-01,  2.2504e+00,  2.0526e+00,\n",
      "         5.8467e-01,  1.0323e+00,  1.3601e+00,  1.0672e+00,  1.0376e+00,\n",
      "         1.3224e+00,  1.1681e+00,  1.2768e+00,  1.1949e+00,  1.2805e+00,\n",
      "         1.1898e+00,  1.6523e+00,  1.3198e+00,  1.0242e+00,  1.0140e+00,\n",
      "         1.5921e+00,  1.0601e+00,  1.1097e+00,  1.1431e+00,  1.2403e+00,\n",
      "         9.6825e-01,  3.4248e-01,  1.4437e+00,  1.9059e+00,  1.1306e+00,\n",
      "         1.1979e+00,  1.1492e+00,  1.2240e+00,  1.8190e+00,  1.7401e+00,\n",
      "         9.9963e-01,  1.2808e+00,  1.0041e+00,  1.2013e+00,  1.1123e+00,\n",
      "         1.1380e+00,  6.6614e-01,  1.1594e+00,  1.1048e+00,  1.2551e+00,\n",
      "         1.1039e+00,  1.2350e+00,  9.4066e-01,  1.2180e+00,  1.1492e+00,\n",
      "         1.2587e+00,  1.0984e+00,  1.2983e+00,  1.4281e+00,  1.0979e+00,\n",
      "         1.3485e+00,  6.5511e-01,  1.0265e+00,  2.5259e+00,  1.2546e+00,\n",
      "         1.4732e+00,  1.1358e+00,  1.0501e+00,  1.3151e+00,  1.6441e+00,\n",
      "         1.2762e+00,  1.1567e+00,  1.1053e+00,  2.0496e+00,  9.0119e-01,\n",
      "         1.1511e+00,  9.1006e-01,  1.0967e+00,  1.2937e+00,  1.0129e+00,\n",
      "         1.1356e+00,  1.0727e+00,  2.0183e+00,  1.2769e+00,  2.3924e+00,\n",
      "         1.3797e+00,  1.1751e+00,  1.1361e+00,  1.2391e+00,  1.2405e+00,\n",
      "         1.0738e+00,  7.7692e-01,  1.3204e+00,  9.1010e-01,  9.9473e-01,\n",
      "         1.1274e+00,  1.1026e+00,  1.5084e+00,  1.2020e+00,  1.0416e+00,\n",
      "         1.3780e+00,  1.2772e+00,  1.2942e+00,  1.0332e+00, -1.4101e-01,\n",
      "         9.7821e-01,  1.0859e+00, -1.0357e+00,  1.2379e+00,  1.1541e+00,\n",
      "         9.9462e-01,  1.1278e+00,  9.8788e-01,  1.0873e+00,  1.0631e+00,\n",
      "         1.3829e+00,  1.1609e+00,  1.0344e+00,  1.1546e+00,  1.8796e-01,\n",
      "         2.9580e+00,  1.2646e+00,  1.7151e+00,  9.2578e-01,  1.1160e+00,\n",
      "         9.8000e-01,  1.5973e+00,  1.1215e+00,  9.9604e-01,  1.1364e+00,\n",
      "         1.1338e+00,  1.1683e+00,  9.7618e-01,  1.8690e-01,  1.5778e+00,\n",
      "         4.0271e-01,  1.1610e+00,  1.3533e+00,  2.2622e+00,  2.3420e-01,\n",
      "         2.6926e-01,  1.1083e+00,  1.4327e+00,  8.0689e-01,  1.1706e+00,\n",
      "         9.6931e-01,  1.1702e+00,  1.5006e+00,  1.3830e+00,  1.1704e+00,\n",
      "         1.0711e+00,  1.0627e+00,  1.2564e+00,  1.9710e-01,  1.7821e-03,\n",
      "         1.2708e+00,  1.0819e+00,  1.0249e+00,  1.0698e+00,  9.7436e-01,\n",
      "         1.5330e+00,  8.9970e-01,  1.4268e+00,  6.5875e-01,  1.1989e+00,\n",
      "         7.7336e-01,  1.2765e+00,  5.9638e-01,  9.9278e-01,  1.0885e+00,\n",
      "         1.2077e+00,  2.8203e-01,  4.9359e-01,  1.0681e+00,  1.2020e+00,\n",
      "         1.7826e+00,  1.1467e+00,  2.0094e+00,  1.0709e+00,  9.7707e-01,\n",
      "         1.7808e+00,  1.1873e+00,  1.0254e+00,  1.8911e+00,  9.2104e-01,\n",
      "         1.1707e+00,  1.3003e+00,  9.0211e-01,  4.2324e-01,  9.2768e-01,\n",
      "         1.8292e+00,  1.1625e+00,  2.5914e-01,  2.3268e-01,  1.1614e+00,\n",
      "         1.1023e+00,  1.1700e+00,  1.0069e+00,  1.5069e+00,  1.2648e+00,\n",
      "         1.1965e+00,  9.6959e-01,  2.4827e+00,  1.1336e+00,  1.0388e+00,\n",
      "         2.2360e+00,  1.2796e+00,  1.2279e+00,  1.0939e+00,  1.1191e+00,\n",
      "         6.3185e-01,  1.0355e+00,  1.3108e+00,  1.0120e+00,  1.2270e+00,\n",
      "         1.4654e+00,  1.0506e+00,  8.8245e-01,  2.2366e+00,  1.0690e+00,\n",
      "         9.9878e-01,  1.3059e+00,  2.0417e+00,  6.3553e-01,  1.2810e+00,\n",
      "         1.1513e+00,  1.1175e+00,  1.3541e+00,  1.2677e+00,  1.2441e+00,\n",
      "         2.5446e+00,  1.2252e+00,  9.0257e-01,  1.1045e+00,  7.3241e-01,\n",
      "         1.9439e-01,  1.1315e+00,  1.2398e+00,  1.8790e+00,  1.1510e+00,\n",
      "         1.2489e+00,  1.2738e+00,  1.2631e+00,  1.0183e+00,  1.1283e+00,\n",
      "         1.0234e+00,  1.0686e+00,  1.1739e+00,  6.5649e-01,  1.1133e+00,\n",
      "         1.5133e+00,  1.2099e+00,  1.2917e+00,  7.0337e-01,  1.0232e+00,\n",
      "         1.1082e+00,  1.0344e+00,  1.4571e+00,  1.3888e+00,  1.1487e+00,\n",
      "         8.1538e-01,  1.4383e+00,  7.6653e-01,  1.2308e+00,  1.1444e+00,\n",
      "         1.1992e+00,  1.4026e+00,  2.9724e+00,  1.1135e+00,  1.8146e+00,\n",
      "         9.6796e-01,  1.2107e+00,  1.0312e+00,  4.8760e-01,  9.7196e-01,\n",
      "         1.0122e+00,  2.3435e+00,  5.5047e-01,  1.4330e+00,  1.6668e+00,\n",
      "         2.3249e+00,  1.1599e+00,  3.1581e-01,  1.0286e+00,  1.2679e+00,\n",
      "         1.1635e+00,  8.1361e-01,  9.5338e-01,  1.0844e+00,  2.3111e+00,\n",
      "         1.0533e+00,  1.1687e+00, -4.3139e-02, -8.6468e-02,  1.7938e+00,\n",
      "         2.0178e+00,  1.1048e+00,  1.3845e+00,  1.3740e+00,  2.5247e+00,\n",
      "         3.1710e-01,  3.1084e+00,  1.2031e+00,  1.2065e+00,  3.1634e-01,\n",
      "         1.1872e+00,  1.2261e+00,  1.1843e+00,  1.1624e+00,  1.0430e+00,\n",
      "         1.7335e+00,  2.2303e-01,  1.0927e+00,  1.7234e+00,  5.9645e-01,\n",
      "         1.7761e+00,  2.2995e+00,  1.1784e+00,  1.2542e+00,  1.0246e+00,\n",
      "         1.1455e+00,  1.1634e+00,  1.2713e+00,  1.8578e+00,  1.0144e+00,\n",
      "         1.1912e+00,  1.3002e+00,  1.1364e+00,  1.2932e+00,  2.1765e+00,\n",
      "         1.3014e+00,  9.8238e-01,  9.6223e-01,  1.2204e+00,  1.1010e+00,\n",
      "         1.1410e+00,  1.3594e+00,  1.0363e+00,  1.1900e+00, -1.5652e+00,\n",
      "         1.6008e+00,  8.3104e-01,  1.2786e+00,  1.2367e+00,  1.3620e+00,\n",
      "         1.5858e+00,  1.3952e+00,  1.0800e+00,  1.1586e+00,  7.2412e-01,\n",
      "         1.2115e+00,  1.2228e+00,  1.3041e+00,  1.0999e+00,  5.4699e-01,\n",
      "         5.2402e-01,  1.2209e+00,  1.0804e+00,  9.6275e-01,  4.1443e-01,\n",
      "         9.6844e-01,  1.3086e+00,  1.8788e+00,  1.3252e+00,  1.2212e+00,\n",
      "         1.1593e+00,  9.9580e-01,  1.5224e+00,  1.2245e+00,  7.7386e-01,\n",
      "         1.3723e+00,  1.0034e+00,  1.0880e+00,  2.1983e+00,  1.2486e+00,\n",
      "         1.1160e+00,  1.0866e+00,  1.0637e+00,  9.9879e-01,  2.1420e+00,\n",
      "         1.2438e+00,  9.0904e-01,  1.2158e+00,  1.1586e+00,  8.6216e-01,\n",
      "         1.0082e+00,  1.1142e+00,  1.0342e+00,  1.2546e+00,  1.1555e+00,\n",
      "         1.2554e+00,  1.6589e+00,  1.0116e+00,  1.1488e+00,  1.4281e+00,\n",
      "         6.2983e-01,  1.0804e+00,  1.2138e+00,  1.1646e+00,  9.7132e-01,\n",
      "         1.2806e+00,  1.2765e+00,  1.1117e+00,  1.1713e+00,  9.2798e-01,\n",
      "         1.0243e+00,  1.0384e+00,  1.0094e+00,  1.8292e+00,  1.1460e+00,\n",
      "         8.0888e-01,  1.5547e+00,  9.8302e-01,  1.1333e+00,  1.1561e+00,\n",
      "         9.9884e-01,  1.0119e+00,  1.2207e+00,  2.7388e-01,  1.2418e+00,\n",
      "         9.0348e-01,  1.2693e+00,  9.9699e-01,  1.4688e+00,  1.4342e+00,\n",
      "         1.4729e+00,  1.4628e+00,  5.1475e-01,  1.3295e+00,  1.2717e+00,\n",
      "         1.3857e+00,  1.0580e+00,  1.3370e+00,  1.2873e+00,  1.1117e+00,\n",
      "         1.1151e+00,  1.2289e+00,  1.1210e+00,  1.1425e+00,  2.8696e+00,\n",
      "         7.3913e-01,  1.3101e+00,  1.1827e+00,  1.1659e+00,  1.3681e+00,\n",
      "         1.0868e+00,  1.3345e+00,  7.2446e-01,  1.1240e+00,  1.4263e+00,\n",
      "         1.5682e+00,  3.1512e-01,  2.7681e+00,  4.5302e-01,  1.0199e+00,\n",
      "         9.6160e-01,  1.0927e+00,  1.0349e+00,  1.2980e+00,  1.0410e+00,\n",
      "         1.3307e+00,  1.4459e+00,  1.4383e+00,  1.7478e+00,  9.6817e-01,\n",
      "         1.3913e+00,  1.1285e+00,  9.6232e-01,  1.3022e+00,  8.8738e-01,\n",
      "         1.0174e+00,  1.0971e+00,  1.0859e+00,  1.0253e+00,  5.6959e-01,\n",
      "         1.2125e+00,  8.7072e-01,  1.5991e+00,  1.2223e+00,  1.1643e+00,\n",
      "         1.0395e+00,  9.9927e-01,  1.1314e+00,  1.2533e+00,  1.0204e+00,\n",
      "         9.7910e-01,  9.9705e-01,  1.2139e+00,  1.7898e+00,  1.0420e+00,\n",
      "         2.2509e-01,  1.2800e+00,  2.4777e+00,  1.1250e+00,  1.3158e+00,\n",
      "         1.1788e+00,  1.1147e+00,  5.8361e-01,  1.1797e+00,  1.0833e+00,\n",
      "         1.4803e+00,  1.2494e+00,  2.5038e+00,  1.0567e+00,  1.2287e+00,\n",
      "         2.3029e+00,  8.3101e-01,  1.1423e+00,  3.9324e+00,  1.1263e+00,\n",
      "         1.4492e+00,  1.4140e+00,  1.1293e+00,  7.9182e-01,  1.6473e+00,\n",
      "         1.3532e+00,  1.1945e+00,  1.1780e+00,  1.4572e+00,  1.1140e+00,\n",
      "         1.3527e+00,  1.1098e+00,  1.0366e+00,  1.0267e+00,  5.4602e-01,\n",
      "         2.8626e-01,  1.2026e+00,  1.1458e+00,  1.3547e+00,  9.5027e-01,\n",
      "         1.1361e+00,  1.1208e+00,  4.7827e-01,  1.2398e+00,  6.3517e-01,\n",
      "         8.8133e-01,  9.0416e-01,  1.3936e+00,  1.4244e+00,  1.1277e+00,\n",
      "         1.1150e+00,  1.2583e+00,  1.3246e+00,  1.2154e+00,  9.6042e-01,\n",
      "         1.2977e+00,  9.9339e-01,  1.2697e+00,  1.1012e+00,  1.4065e+00,\n",
      "         1.1090e+00,  1.8057e+00,  1.2233e+00,  1.1009e+00,  1.2366e+00,\n",
      "         2.0002e+00,  1.8593e+00,  7.9442e-01,  1.1775e+00,  1.0617e+00,\n",
      "         9.9421e-01,  9.8183e-01,  1.5957e+00,  3.5367e-01,  1.3907e+00,\n",
      "         6.3793e-01,  1.0800e+00,  7.9232e-01,  9.5443e-01,  1.7948e+00,\n",
      "         6.6467e-01,  9.5250e-01,  1.0552e+00,  1.1833e+00,  9.9135e-01,\n",
      "         3.2570e-01,  1.0018e+00,  1.0473e+00,  1.0162e+00,  1.0401e+00,\n",
      "         2.0824e+00,  1.1427e+00,  3.5964e+00,  1.1696e+00,  9.3508e-01,\n",
      "         1.0557e+00,  1.0902e+00,  1.3469e+00,  1.2226e+00,  1.1637e+00,\n",
      "         1.0360e+00,  1.2902e+00,  6.7427e-01,  1.0896e+00,  9.9460e-01,\n",
      "         1.1872e+00,  1.3693e+00,  1.2479e+00,  1.1428e+00,  1.9846e+00,\n",
      "         1.7652e+00,  1.0915e+00,  1.2130e+00,  1.1818e+00,  1.3045e+00,\n",
      "         1.3693e+00,  4.0361e-01,  1.3246e+00,  1.1090e+00,  1.0868e+00,\n",
      "         1.1703e+00,  1.8272e+00,  1.4180e+00,  2.1169e-01,  9.2349e-01,\n",
      "         1.3129e+00,  1.1153e+00,  1.2037e+00,  1.2047e+00,  1.0798e+00,\n",
      "         9.8543e-01,  2.9734e-01,  1.1604e+00,  1.1386e+00,  1.0598e+00,\n",
      "         1.1677e+00,  1.1765e+00,  1.1465e+00,  1.0132e+00,  1.5858e+00,\n",
      "         1.1102e+00,  2.7012e+00,  1.0592e+00,  1.1062e+00,  1.4124e+00,\n",
      "         1.2473e+00,  1.5275e+00, -1.1226e-03,  4.7899e-01,  1.4264e+00,\n",
      "         2.3332e+00,  1.4088e+00,  1.7559e+00,  1.2963e+00,  1.1757e+00,\n",
      "         1.0148e+00,  1.0678e+00,  1.0916e+00,  1.1543e+00,  1.1761e+00,\n",
      "         1.3575e+00,  3.0002e+00,  1.0480e+00,  1.2034e+00,  7.4207e-01,\n",
      "         1.0368e+00,  1.3931e+00,  8.9572e-01,  1.0132e+00,  1.3904e+00,\n",
      "         9.7292e-01,  9.6852e-01,  1.2878e+00,  1.0391e+00,  1.5291e+00,\n",
      "         1.1929e+00,  1.2148e+00,  1.2471e+00,  7.7219e-01,  1.1106e+00,\n",
      "         1.6686e+00,  1.3714e+00,  1.0882e+00,  1.3793e+00,  1.2161e+00,\n",
      "         1.7056e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.1927e+00,  4.5402e+00, -2.1011e+00,  1.3950e+00, -1.8440e+00,\n",
      "        -1.5158e+00, -1.3053e+00, -1.8319e+00, -7.6323e-01, -2.1942e+00,\n",
      "        -1.8546e+00, -2.1242e+00,  5.2682e-03, -2.1632e+00, -1.2253e+00,\n",
      "        -1.8458e+00, -1.7786e+00, -1.6987e+00, -1.1357e+00, -1.6521e+00,\n",
      "        -1.8309e+00, -1.8764e+00, -2.1349e+00,  2.6740e+00, -1.6008e+00,\n",
      "        -8.3505e-01, -6.7018e-01, -1.5440e+00, -1.6255e+00, -1.7648e+00,\n",
      "         5.9394e-01, -1.9384e+00, -1.6664e+00, -1.6149e+00, -1.7710e+00,\n",
      "        -2.4106e+00,  1.7719e-01,  1.9133e-03, -1.5626e+00, -1.1404e+00,\n",
      "        -1.4293e+00, -1.6723e-02, -2.0579e+00, -2.1556e+00, -1.6184e+00,\n",
      "        -1.7238e+00, -2.2392e+00, -1.5600e+00, -1.6441e+00, -1.2591e+00,\n",
      "        -5.6325e-01, -2.5842e+00, -7.6335e-01,  2.2414e-01, -1.4895e+00,\n",
      "        -1.8260e+00, -1.1213e+00, -1.8286e+00, -1.2154e+00, -1.5035e+00,\n",
      "        -1.7440e+00, -1.2903e+00, -1.7558e+00, -2.1251e+00, -1.9620e+00,\n",
      "        -3.1582e+00,  3.7253e-03, -1.9343e+00, -1.7063e-01, -1.4465e+00,\n",
      "        -1.9059e+00, -2.4891e+00, -1.4005e+00, -8.1972e-03, -1.5085e+00,\n",
      "         7.6162e-01, -2.0720e+00, -1.5322e+00,  7.2797e-01, -1.3981e+00,\n",
      "        -2.6497e+00, -2.0940e+00, -1.4413e+00, -2.0037e+00, -1.7922e+00,\n",
      "        -1.9969e+00, -1.7826e+00, -2.3329e+00, -4.4295e-01, -2.0110e+00,\n",
      "         6.3724e-01,  6.3657e-01, -1.7276e+00, -1.7639e+00, -1.9945e+00,\n",
      "        -2.0372e+00, -1.1012e+00, -2.1423e+00, -1.4440e+00,  1.3011e+00,\n",
      "        -1.8352e+00, -1.5518e+00, -1.9108e+00, -1.6769e+00, -1.5784e+00,\n",
      "        -1.1614e+00, -1.3078e+00, -2.0799e+00, -2.0634e+00, -1.1525e+00,\n",
      "        -5.8862e-01,  1.1018e-01, -1.9115e+00, -1.3726e+00, -1.6092e+00,\n",
      "        -1.4726e+00, -2.0152e+00, -2.0465e+00, -2.5719e+00, -2.1171e+00,\n",
      "        -1.5169e+00, -1.6311e+00, -1.7028e+00, -1.7650e+00, -1.7390e+00,\n",
      "        -1.6914e+00, -1.7564e+00,  5.1179e-01, -1.2902e+00,  1.0046e-02,\n",
      "        -1.8512e+00,  1.5967e-01, -1.2507e+00, -2.3033e-01, -3.2056e-02,\n",
      "         1.4386e+00, -1.0806e+00, -2.8325e-01, -8.9275e-01, -1.4312e+00,\n",
      "        -3.8096e-01, -1.6884e+00, -1.9392e+00, -1.6643e+00, -1.4027e+00,\n",
      "        -1.4747e+00,  9.4658e-01, -1.8598e+00, -9.7634e-01,  6.9580e-01,\n",
      "         1.3664e-01, -1.4012e+00, -1.1184e+00, -2.1410e+00, -1.8008e+00,\n",
      "        -4.1133e-01, -1.5093e+00, -1.8206e+00, -1.0381e+00, -2.4220e+00,\n",
      "        -2.1022e+00, -1.1183e+00, -2.0280e+00, -1.3172e+00,  4.7699e-01,\n",
      "         7.7979e-01, -1.4312e+00, -1.7768e+00, -2.1913e+00, -2.3082e+00,\n",
      "        -1.3275e-01,  1.1097e-01, -1.8666e+00,  1.2928e+00, -1.4817e+00,\n",
      "        -1.8125e+00, -1.6753e+00, -1.5741e+00, -1.2687e+00, -1.2670e+00,\n",
      "        -2.6141e+00, -1.5224e+00, -1.8785e+00, -1.8026e+00, -2.0633e+00,\n",
      "        -2.5012e+00,  4.8146e-01, -1.5078e+00, -2.0886e+00, -1.2999e+00,\n",
      "        -1.2832e+00, -1.8407e+00, -1.7850e+00, -2.8220e+00, -1.9736e+00,\n",
      "        -1.9135e+00, -1.7405e+00, -1.6174e+00, -1.2292e+00, -1.8884e+00,\n",
      "        -2.0438e+00, -1.3144e-01, -1.7200e+00,  2.2139e-01, -2.0014e+00,\n",
      "        -1.0643e+00, -2.1405e+00, -1.8488e+00, -1.9714e+00, -1.5245e+00,\n",
      "        -1.9539e+00, -1.9169e+00, -1.6707e+00,  6.1815e-01,  1.5233e+00,\n",
      "        -1.8713e+00, -1.1458e+00, -1.9775e+00, -1.4602e+00, -1.2545e+00,\n",
      "        -1.8328e+00, -1.9178e+00,  5.9643e-01, -1.9507e+00, -7.4341e-01,\n",
      "        -1.3338e+00, -1.8548e+00, -1.9547e+00, -2.3232e+00, -1.7298e+00,\n",
      "        -2.0409e+00,  1.2089e+00, -1.8645e+00, -1.0160e+00, -2.2081e+00,\n",
      "        -1.6393e+00, -1.6521e+00, -2.3698e+00, -1.9336e+00, -1.5315e+00,\n",
      "        -1.7752e+00, -1.8060e+00, -1.3524e+00, -1.9061e+00, -1.2528e-01,\n",
      "        -1.9123e+00, -1.3739e+00, -1.7714e+00, -1.2189e+00, -2.1381e+00,\n",
      "        -1.7717e+00, -1.6555e+00, -1.5837e+00, -1.5899e+00, -1.7826e+00,\n",
      "        -1.7101e+00, -1.5778e+00, -1.7892e+00, -2.8468e+00,  4.9097e-02,\n",
      "        -4.4715e-01, -2.1917e+00, -1.8868e+00, -1.2640e+00, -2.3860e+00,\n",
      "        -1.9746e+00, -1.5362e+00, -1.4675e+00, -2.0046e+00, -1.9051e+00,\n",
      "        -1.8817e+00, -1.5862e+00, -1.6681e+00,  4.6819e-03, -1.3659e+00,\n",
      "        -1.3004e-01, -2.5850e+00, -1.5564e+00,  2.7373e-01,  3.7251e-01,\n",
      "         2.8874e-01, -1.6953e+00, -3.9758e-01,  7.9428e-01, -1.5311e+00,\n",
      "        -1.9911e+00, -1.9821e+00, -2.2785e+00, -1.3494e+00, -2.1838e+00,\n",
      "        -2.5602e+00, -2.0164e+00, -2.3027e+00, -2.4031e-01, -5.4071e-03,\n",
      "        -1.9564e+00, -1.9291e+00, -1.8864e+00, -2.1709e+00, -1.3240e+00,\n",
      "        -1.3570e+00,  7.2549e-01, -1.6089e+00, -1.3098e+00, -2.0911e+00,\n",
      "        -1.6179e+00, -1.4813e+00,  6.0466e-01, -1.8032e+00, -2.9602e+00,\n",
      "        -2.3229e+00,  6.9740e-02,  3.0490e-01, -1.9490e+00, -2.3186e+00,\n",
      "        -3.6202e-03, -1.6684e+00, -3.9316e-01, -1.6142e+00,  9.8813e-01,\n",
      "        -4.0316e-01, -1.5297e+00, -1.8210e+00, -8.9170e-01,  1.7769e-01,\n",
      "         7.4320e-01, -1.6881e+00, -1.5455e+00,  1.6201e-01, -1.7692e+00,\n",
      "         1.1437e+00, -1.9011e+00, -8.8543e-02,  8.1428e-03, -2.2618e+00,\n",
      "        -1.4602e+00, -1.7887e+00, -1.4499e+00,  1.4564e+00, -1.6036e+00,\n",
      "        -1.6940e+00, -1.9822e+00, -2.5420e+00, -2.1086e+00, -1.6432e+00,\n",
      "        -1.3878e+00, -1.6657e+00, -1.6218e+00, -2.0312e+00, -1.7233e+00,\n",
      "         5.7321e-01, -2.3445e+00, -1.5109e+00, -1.3670e+00, -1.5373e+00,\n",
      "        -1.1072e+00, -1.6976e+00, -1.7907e+00,  6.6777e-01, -1.8241e+00,\n",
      "        -2.0544e+00, -1.5155e+00, -2.3418e+00,  2.7107e-01, -1.9401e+00,\n",
      "        -1.9078e+00, -2.5468e+00, -1.1744e+00, -1.4477e+00, -1.3035e+00,\n",
      "        -2.3162e+00, -1.5913e+00,  1.6679e-01, -2.0116e+00, -4.7816e-02,\n",
      "         1.8030e-01, -1.7650e+00, -8.1898e-01,  3.1300e-01, -1.6337e+00,\n",
      "        -1.9205e+00,  9.3560e-01, -1.6546e+00, -1.9566e+00, -2.3060e+00,\n",
      "        -1.8082e+00, -7.8709e-01, -2.0292e+00, -2.6151e-01, -1.9077e+00,\n",
      "        -1.7601e+00, -1.5354e+00, -3.0183e+00,  2.8270e+00, -2.0987e+00,\n",
      "        -1.9881e+00, -1.2223e+00,  2.5114e-01, -1.7752e+00, -1.8821e+00,\n",
      "        -6.6572e-02, -2.3645e+00, -7.9323e-02, -1.7674e+00, -1.6080e+00,\n",
      "        -2.1941e+00, -1.9545e+00, -7.1770e-01, -1.9618e+00, -9.7605e-01,\n",
      "        -1.9953e+00, -2.1083e+00, -2.0878e+00,  1.0168e+00, -2.1937e+00,\n",
      "        -1.8950e+00, -2.4527e+00, -4.3292e-01, -3.9237e+00, -1.1258e+00,\n",
      "        -7.7346e-01, -1.7782e+00,  4.8688e-01, -1.9603e+00,  6.2204e-02,\n",
      "        -1.9941e-01, -1.9681e+00, -1.5275e+00, -5.4971e-01, -7.5165e-01,\n",
      "        -1.4637e+00, -2.0735e+00, -1.6540e-02,  1.4861e-01, -1.0394e+00,\n",
      "         4.6925e-01, -1.6528e+00, -6.2932e-01, -1.7811e+00, -5.2679e-01,\n",
      "         3.2977e-01,  1.2591e-01, -2.1824e+00, -1.9830e+00,  2.5139e-02,\n",
      "        -1.6115e+00, -1.0273e+00, -1.8907e+00, -1.9338e+00, -1.7637e+00,\n",
      "        -1.8462e+00, -1.5083e-01, -1.8421e+00, -1.7178e+00,  7.8864e-01,\n",
      "        -5.7144e-01,  4.0902e-01, -1.9285e+00, -1.5890e+00, -2.0877e+00,\n",
      "        -1.5135e+00, -1.7034e+00, -1.8158e+00, -1.2584e+00, -1.6215e+00,\n",
      "        -1.4647e+00, -2.1805e+00, -1.7287e+00, -1.3421e+00,  1.4546e-01,\n",
      "        -1.5569e+00, -1.7229e+00, -2.1143e+00, -1.9937e+00, -1.7171e+00,\n",
      "        -1.7598e+00, -1.4615e+00, -2.1851e+00, -2.1273e+00, -1.1189e+00,\n",
      "        -1.6919e+00,  1.6732e-01, -1.4453e+00, -1.8096e+00, -8.4620e-01,\n",
      "        -8.1533e-02, -1.2892e+00, -1.8276e+00, -1.0187e+00,  2.3747e-01,\n",
      "        -1.6332e+00, -2.4996e+00, -1.6950e+00, -1.9126e+00, -5.9841e-02,\n",
      "         7.4971e-01, -2.7607e+00, -2.2777e+00, -1.7677e+00, -4.8659e-01,\n",
      "        -2.3978e+00, -1.6025e+00, -1.1599e+00, -1.8174e+00, -1.6459e+00,\n",
      "        -1.6644e+00, -1.8015e+00, -2.3608e+00, -1.4112e+00, -1.6836e+00,\n",
      "        -1.4926e+00, -1.9646e+00, -1.7560e+00, -1.2317e+00, -2.1486e+00,\n",
      "        -1.8068e+00, -1.7748e+00, -1.5415e+00, -1.9452e+00, -2.6721e-01,\n",
      "        -1.4946e+00,  1.2127e+00, -1.3273e+00, -1.5050e+00, -2.0863e+00,\n",
      "        -1.8680e+00, -1.6222e+00, -2.0632e+00, -1.3817e+00, -1.2588e+00,\n",
      "        -1.7724e+00, -1.0980e+00, -2.1501e+00, -1.9217e+00,  2.0582e-01,\n",
      "         7.6176e-01,  9.3736e-02, -1.8805e+00, -1.7344e+00, -1.7302e+00,\n",
      "        -1.8597e+00, -1.1500e+00, -1.2242e+00, -1.9406e+00, -1.6714e+00,\n",
      "        -2.2335e+00, -1.2704e+00, -2.0848e+00, -1.3526e+00, -2.0909e+00,\n",
      "        -1.4060e+00, -2.1852e+00, -1.9208e+00, -1.7972e+00, -1.9692e+00,\n",
      "        -1.8524e+00, -1.9256e+00, -1.6672e+00,  2.2020e-01, -2.0266e+00,\n",
      "        -1.3000e+00, -1.9557e+00, -2.2389e+00, -1.5718e+00, -1.4208e+00,\n",
      "        -1.3662e+00, -1.3246e+00,  5.5496e-02, -1.7334e+00, -1.7325e+00,\n",
      "        -1.7471e+00, -2.0967e+00, -1.4292e+00,  8.7878e-01, -1.8054e+00,\n",
      "        -2.1544e+00, -1.2355e+00, -2.0190e+00, -1.8609e+00, -1.1710e+00,\n",
      "        -8.0601e-01, -9.3743e-01, -1.6527e+00, -1.7661e+00, -1.7935e+00,\n",
      "        -2.0906e+00, -1.1863e+00, -4.7723e-01, -1.1000e+00, -6.0073e-01,\n",
      "        -7.6183e-01, -1.1021e-01, -3.8029e-01,  1.7044e+00, -1.5126e+00,\n",
      "        -1.8827e+00, -2.0172e+00, -1.7389e+00, -1.2949e+00, -1.6881e+00,\n",
      "        -1.7327e+00, -1.3994e+00, -1.4862e-01,  6.5967e-01, -2.0736e+00,\n",
      "        -9.7107e-01, -1.5428e+00, -1.6592e+00, -1.7502e+00, -1.5932e+00,\n",
      "         7.3391e-01, -1.9937e+00, -1.7142e+00, -2.1750e+00,  4.7448e-01,\n",
      "        -1.9997e+00, -3.1805e+00, -3.4247e-02, -1.3944e+00, -1.2703e+00,\n",
      "         4.9866e-01, -1.6264e+00, -2.1209e+00, -8.1021e-01, -2.0652e+00,\n",
      "        -1.8971e+00, -1.7845e+00, -1.4035e+00, -1.6039e+00, -2.4043e+00,\n",
      "         1.1443e+00, -2.0519e+00, -2.2741e-01, -1.1151e+00, -2.0976e+00,\n",
      "        -1.7727e+00, -1.7166e+00,  6.1267e-01, -1.3454e+00, -2.0866e+00,\n",
      "        -1.6617e+00, -1.6300e+00, -1.0039e+00, -1.4908e+00, -1.9233e+00,\n",
      "         9.4734e-01, -8.7400e-01, -1.9945e+00,  1.1008e+00, -1.7582e+00,\n",
      "        -1.8445e+00, -2.8940e+00, -2.1725e+00, -6.1548e-01, -1.5962e+00,\n",
      "        -1.8458e+00, -1.6729e+00, -2.3713e+00, -2.0088e+00, -2.0334e+00,\n",
      "        -1.9739e+00, -2.0700e+00, -1.9942e+00, -1.6969e+00, -4.4628e-01,\n",
      "         5.2435e-02, -1.9546e+00, -1.9717e+00, -1.4327e+00, -2.4395e+00,\n",
      "        -2.1948e+00, -1.6985e+00,  3.9127e-01, -2.0017e+00,  8.9232e-01,\n",
      "        -1.3061e+00, -1.9435e+00, -1.3744e+00, -1.1734e+00, -1.7071e+00,\n",
      "        -1.5422e+00, -1.2791e+00, -2.3464e+00, -1.4679e+00, -1.8616e+00,\n",
      "        -1.9624e+00, -1.9372e+00, -1.9889e+00, -1.1505e+00, -1.6426e+00,\n",
      "        -1.8029e+00,  1.4383e+00, -1.6419e+00, -1.6166e+00, -1.6072e+00,\n",
      "        -8.3102e-01,  1.4798e-01, -1.4894e+00, -2.0286e+00, -1.9810e+00,\n",
      "        -1.7417e+00, -2.0217e+00, -1.5448e+00,  1.4453e-01, -1.1173e+00,\n",
      "         4.4945e-01, -1.5592e+00, -8.4947e-01, -1.6232e+00, -5.8920e-01,\n",
      "         7.8392e-01, -4.6181e-01, -1.9870e+00, -8.6160e-01, -2.8900e+00,\n",
      "         6.0875e-01,  1.2916e+00, -1.9186e+00, -1.6574e+00, -2.1016e+00,\n",
      "        -1.5524e+00, -1.8502e+00, -4.7319e-01, -1.4982e+00, -2.0093e+00,\n",
      "         8.4293e-01, -2.7403e+00, -2.7234e+00, -6.6814e-01, -1.1668e+00,\n",
      "        -2.2140e+00, -2.2858e+00, -9.2825e-02, -1.3240e+00, -6.7067e-01,\n",
      "        -1.8180e+00, -6.9371e-01, -1.5532e+00, -2.4269e+00, -6.8423e-01,\n",
      "        -7.4474e-01, -1.8625e+00, -2.0063e+00, -1.8147e+00, -1.6643e+00,\n",
      "        -1.6231e+00, -1.3993e-01, -1.8221e+00, -1.5689e+00, -1.9294e+00,\n",
      "        -1.5562e+00, -1.6614e+00, -1.9203e+00, -1.9635e-02, -1.9470e+00,\n",
      "        -1.5385e+00, -1.7016e+00, -1.7129e+00, -1.3803e+00, -1.8577e+00,\n",
      "        -1.8558e+00,  8.3482e-02, -2.1290e+00, -1.8123e+00, -1.8803e+00,\n",
      "        -1.5858e+00, -1.5685e+00, -2.1278e+00, -2.1049e+00, -7.6213e-01,\n",
      "        -8.5543e-01, -4.7346e-01, -1.9596e+00, -1.7412e+00, -2.0436e+00,\n",
      "        -1.4170e+00, -7.7299e-02, -6.6521e-03, -1.4969e-01,  1.9013e-01,\n",
      "        -2.7453e+00, -1.8891e+00,  6.1461e-01, -1.4495e+00, -1.4519e+00,\n",
      "        -1.5778e+00, -2.1726e+00, -1.5951e+00, -1.4405e+00, -1.4899e+00,\n",
      "        -1.2572e+00, -2.6505e-01, -1.8659e+00,  1.8409e-01, -4.7879e-01,\n",
      "        -1.9446e+00,  1.2990e+00, -1.7402e+00, -1.7995e+00, -1.8083e+00,\n",
      "        -1.5482e+00, -7.6191e-01, -1.7809e+00, -1.8770e+00, -1.2620e+00,\n",
      "        -1.4792e+00, -2.5986e+00, -2.0839e+00, -4.2944e-02, -1.6218e+00,\n",
      "        -1.4608e+00, -1.0135e+00, -2.2972e+00,  8.3559e-01, -2.1117e+00,\n",
      "        -1.9101e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2161, -0.1168,  0.0251, -0.1636, -0.1939],\n",
      "          [-0.4362, -0.0363, -0.4947,  0.0211, -0.5057],\n",
      "          [-0.4090, -0.3741, -0.5854, -0.0581, -0.4262],\n",
      "          [-0.3235, -0.4086, -0.7001, -0.4097, -0.6133],\n",
      "          [ 0.4354, -0.0519, -0.1578,  0.0414, -0.1070]]],\n",
      "\n",
      "\n",
      "        [[[-0.1485, -0.1508, -0.8305,  0.5040,  0.4951],\n",
      "          [-0.1591, -0.1806, -0.8676,  0.4730,  0.4794],\n",
      "          [-0.0055,  0.1717,  0.2967, -0.8277, -0.7926],\n",
      "          [-0.0996, -0.0052,  0.1778, -0.2131, -0.1624],\n",
      "          [ 0.1500,  0.1750,  0.4659, -0.1508, -0.1312]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1240,  0.4609,  0.5429,  0.7954,  0.6281],\n",
      "          [ 0.6839, -0.3391,  0.6232, -0.2785,  0.0711],\n",
      "          [-0.1205, -0.0113,  0.0974,  0.1946,  0.0705],\n",
      "          [ 0.1757,  0.1884,  0.1547,  0.0994,  0.2111],\n",
      "          [-0.2918,  0.1163, -0.1904,  0.0469, -0.1754]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1676,  0.3126,  0.3326,  0.3068,  0.6030],\n",
      "          [-0.3799, -0.3176, -0.0741,  0.0606, -0.0129],\n",
      "          [-0.3091, -0.4891, -0.2102, -0.0685, -0.2923],\n",
      "          [-0.1824, -0.2907, -0.3208, -0.0251, -0.0764],\n",
      "          [-0.5325, -0.3112, -0.4859, -0.2059, -0.3746]]],\n",
      "\n",
      "\n",
      "        [[[-0.3948, -0.0374, -0.1516,  0.1758, -0.2966],\n",
      "          [ 0.5835,  1.0123,  0.5103,  0.8035, -0.0303],\n",
      "          [-0.2556,  0.2397,  0.0765,  0.0072, -0.1452],\n",
      "          [ 0.1155,  0.5758,  0.0551,  0.3963, -0.0609],\n",
      "          [-0.0868, -0.3052,  0.0886, -0.4418, -0.1849]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0115, -0.3464, -0.0742, -0.2316,  0.0589],\n",
      "          [-0.4827,  0.6489, -0.4656,  0.8494, -0.2580],\n",
      "          [-0.0715, -0.3725, -0.0654, -0.2704,  0.0144],\n",
      "          [-0.4479,  0.0014, -0.4555, -0.0019, -0.4759],\n",
      "          [-0.2049, -0.0779,  0.2041,  0.0555,  0.1631]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 2.8624e+00,  4.8767e+00,  1.0976e+00,  1.2695e+00,  8.7648e-01,\n",
      "         1.0628e+00,  8.4426e-01,  1.2119e+00,  1.3441e+00,  1.0614e+00,\n",
      "         9.7050e-01,  1.0963e+00,  1.2646e+00,  1.1540e+00,  8.9915e-01,\n",
      "         1.0860e+00,  8.1084e-01,  1.2181e+00,  2.2111e+00,  6.9087e-01,\n",
      "         1.2463e+00,  9.6060e-01,  8.9654e-01,  2.9071e+00,  1.0378e+00,\n",
      "         2.5660e+00,  9.6733e-01,  5.0800e-01,  1.0383e+00,  9.2051e-01,\n",
      "         2.4922e+00,  1.4247e+00,  1.0140e+00,  9.4554e-01,  1.0052e+00,\n",
      "         1.5860e+00,  1.9144e+00,  1.7656e+00,  1.3703e+00,  1.6277e+00,\n",
      "         9.9367e-01,  1.0961e+00,  8.2835e-01,  9.9507e-01,  1.3067e+00,\n",
      "         5.9425e-01,  9.1730e-01,  6.3589e-01,  1.3065e+00,  1.0175e+00,\n",
      "         1.1822e+00,  8.6686e-01,  1.2390e+00,  1.1096e+00,  8.6079e-01,\n",
      "         1.1061e+00,  5.6750e-01,  1.0652e+00,  1.1636e+00,  7.5540e-01,\n",
      "         1.0687e+00,  1.0165e+00,  4.1473e-01,  6.2183e-01,  1.0431e+00,\n",
      "         1.1911e+00,  7.3183e-02,  1.1885e+00,  2.0620e+00,  9.2625e-01,\n",
      "         1.1531e+00,  1.0621e+00,  6.5507e-01, -3.8404e-03,  7.6021e-01,\n",
      "         1.7863e+00,  5.3717e-01,  1.5306e+00,  1.1416e+00,  2.0793e+00,\n",
      "         6.7697e-01,  1.0209e+00,  1.1869e+00,  8.3110e-01,  1.0041e+00,\n",
      "         1.0245e+00,  9.4017e-01,  1.0384e+00,  8.6832e-01,  1.4480e+00,\n",
      "         2.3099e+00,  2.2412e+00,  7.3278e-01,  8.3756e-01,  1.0858e+00,\n",
      "         5.7510e-01,  1.1325e+00,  1.0148e+00,  9.1858e-01,  2.3402e+00,\n",
      "         1.1197e+00,  9.0472e-01,  9.9198e-01,  8.5019e-01,  1.0280e+00,\n",
      "         2.3416e+00,  1.2528e+00,  1.1020e+00,  9.4926e-01,  1.0338e+00,\n",
      "         1.5039e+00,  1.2532e+00,  9.4835e-01,  1.7444e+00,  8.4050e-01,\n",
      "         8.1948e-01,  1.1491e+00,  1.0864e+00,  1.2237e+00,  1.1022e+00,\n",
      "         1.4026e+00,  7.0011e-01,  1.1037e+00,  1.0404e+00,  1.0652e+00,\n",
      "         8.5701e-01,  6.1839e-01,  7.3919e-01,  1.2941e+00,  2.3042e+00,\n",
      "         9.7834e-01,  2.3554e+00,  1.4043e+00,  2.9561e+00,  1.0117e+00,\n",
      "         2.3244e+00,  1.6157e+00,  1.0791e+00,  1.8424e+00,  1.5412e+00,\n",
      "         1.7031e+00,  1.1416e+00,  5.9303e-01,  1.1897e+00,  7.6344e-01,\n",
      "         7.8371e-01,  1.8977e+00,  9.2488e-01,  1.0734e+00,  1.7707e+00,\n",
      "         1.6901e+00,  6.9870e-01,  1.2963e+00,  9.8242e-01,  1.0918e+00,\n",
      "         1.1675e+00,  7.8512e-01,  1.1812e+00,  1.3674e+00,  1.1163e+00,\n",
      "         9.3792e-01,  2.2254e+00,  9.3384e-01,  1.2595e+00,  1.8629e+00,\n",
      "         2.6166e+00,  7.4210e-01,  1.2032e+00,  8.3010e-01,  9.3523e-01,\n",
      "         7.7683e-01,  1.5121e+00,  4.7557e-01,  9.2593e-01,  5.2225e-01,\n",
      "         1.1188e+00,  1.3884e+00,  8.2606e-01,  1.1380e+00,  1.4201e+00,\n",
      "         9.0352e-01,  1.0064e+00,  9.5166e-01,  8.1826e-01,  1.2196e+00,\n",
      "         8.4593e-01,  2.1609e+00,  1.1813e+00,  1.4340e+00,  1.4366e+00,\n",
      "         1.1523e+00,  1.0118e+00,  5.7420e-01,  8.2960e-01,  9.8633e-01,\n",
      "         8.5771e-01,  7.2869e-01,  4.1472e-01,  1.3104e+00,  1.1748e+00,\n",
      "         8.8047e-01,  1.5266e+00,  8.7798e-01,  2.8599e+00,  1.4006e+00,\n",
      "         1.4166e+00,  6.5706e-01,  9.0412e-01,  1.0077e+00,  1.2924e+00,\n",
      "         7.5827e-01,  9.3692e-01,  1.1439e+00,  2.3379e+00,  2.0312e+00,\n",
      "         9.7565e-01,  1.4106e+00,  1.0574e+00,  1.4713e+00,  1.1113e+00,\n",
      "         7.2419e-01,  8.4204e-01,  1.1373e+00,  1.1837e+00,  2.8902e+00,\n",
      "         9.9211e-01,  1.1590e+00,  1.0469e+00,  1.0848e-01,  9.9908e-01,\n",
      "         6.1621e-01,  1.7396e+00,  1.1014e+00,  9.7826e-01,  9.8830e-01,\n",
      "         8.9964e-01,  9.3821e-01,  1.1082e+00,  9.0966e-01,  7.1848e-01,\n",
      "         9.9087e-01,  8.7219e-01,  7.8854e-01,  1.0631e+00,  3.3527e-01,\n",
      "         6.5345e-01,  6.2580e-01,  7.7876e-01,  1.1442e+00,  4.1851e-01,\n",
      "         1.1698e+00,  1.2516e+00,  8.1861e-01,  1.1056e+00,  8.3689e-01,\n",
      "         1.4578e+00,  1.0162e+00,  7.5028e-01,  7.8518e-01,  2.2466e+00,\n",
      "         1.5101e+00,  5.4598e-01,  1.1124e+00,  7.6406e-01,  1.3421e+00,\n",
      "         9.7390e-01,  1.6894e+00,  8.2013e-01,  1.0312e+00,  7.7419e-01,\n",
      "         9.9711e-01,  1.0628e+00,  7.4363e-01,  2.1127e+00,  7.1675e-01,\n",
      "         1.2580e+00,  1.3276e+00,  1.1510e+00,  2.2824e+00,  1.1883e+00,\n",
      "         1.5726e+00,  1.2742e+00,  1.4292e+00,  1.9130e+00,  1.0641e+00,\n",
      "         1.0505e+00,  1.2257e+00,  1.3655e+00,  1.1764e+00,  9.1130e-01,\n",
      "         1.1206e+00,  9.7277e-01,  6.7554e-01,  1.1175e+00,  5.1335e-04,\n",
      "         1.5012e+00,  8.3790e-01,  6.7011e-01,  1.0570e+00,  6.5899e-01,\n",
      "         1.2350e+00,  2.2463e+00,  8.2878e-01,  1.2612e+00,  1.0996e+00,\n",
      "         2.6784e-03,  1.0188e+00,  1.2294e+00,  1.0608e+00,  9.4738e-01,\n",
      "         9.3776e-01,  1.9377e+00,  2.6886e+00,  6.8313e-01,  8.1485e-01,\n",
      "         1.0882e+00,  7.3404e-01,  1.3099e+00,  1.0447e+00,  8.0871e-01,\n",
      "         2.1649e+00,  9.1483e-01,  6.0486e-01,  1.6248e+00,  1.7692e+00,\n",
      "         2.2544e+00,  1.3103e+00,  5.8606e-01,  2.3198e+00,  3.9182e-01,\n",
      "         2.2605e+00,  6.2423e-01,  1.3343e+00,  1.6324e+00,  1.1298e+00,\n",
      "         1.0436e+00,  3.8118e-01,  5.7996e-01,  2.5565e+00,  1.2168e+00,\n",
      "         8.0967e-01,  1.0712e+00,  1.4936e+00,  1.0408e+00,  1.0508e+00,\n",
      "         2.2456e+00,  3.6787e-01,  7.8916e-01,  6.3546e-01,  7.1719e-01,\n",
      "         1.8161e+00,  7.7890e-01,  1.2882e+00,  1.2110e+00,  1.0750e+00,\n",
      "         1.0964e+00,  5.1147e-01,  3.7696e-01,  2.0257e+00,  8.7283e-01,\n",
      "         1.3073e+00,  8.4458e-01,  1.1657e+00,  1.9219e+00,  1.4280e+00,\n",
      "         8.8767e-01,  7.9241e-01,  6.9613e-01,  9.2866e-01,  1.1142e+00,\n",
      "         1.9943e+00,  1.2973e+00,  3.0751e+00,  1.1986e+00,  1.5603e+00,\n",
      "         2.2143e+00,  1.0555e+00,  1.3395e+00,  2.3101e+00,  1.1054e+00,\n",
      "         1.2064e+00,  2.1390e+00,  5.5746e-01,  9.5920e-01,  9.0031e-01,\n",
      "         1.1705e+00,  1.5269e+00,  1.0694e+00,  1.8889e+00,  1.0024e+00,\n",
      "         1.1568e+00,  4.3257e-01,  9.0608e-01,  3.1437e+00,  1.1036e+00,\n",
      "         1.3165e+00,  1.4063e+00,  1.6758e+00,  1.6622e+00,  6.9434e-01,\n",
      "         1.4343e+00,  8.2367e-01,  1.3577e+00,  5.1710e-01,  1.6080e+00,\n",
      "         1.3034e+00,  9.7791e-01,  2.2893e+00,  9.2022e-01,  2.0086e+00,\n",
      "         1.0065e+00,  8.2242e-01,  8.3147e-01,  1.8976e+00,  1.2456e+00,\n",
      "         9.7846e-01,  1.7167e+00,  1.4204e+00,  9.8851e-01,  1.6373e+00,\n",
      "         1.4960e+00,  1.1100e+00,  2.4188e+00,  1.0476e+00,  1.8430e-01,\n",
      "         5.5227e-01,  9.3737e-01,  8.9617e-01,  1.2838e+00,  2.1070e+00,\n",
      "         3.2493e-01,  9.5040e-01,  1.6723e-01,  2.5848e+00,  9.5463e-01,\n",
      "         1.6088e+00,  7.6772e-01,  1.2785e+00,  1.9519e+00,  1.6987e+00,\n",
      "         1.8412e+00,  2.2295e+00,  9.3221e-01,  1.0957e+00,  1.6842e+00,\n",
      "         1.3567e+00,  7.9550e-01,  4.6143e-01,  1.0475e+00,  1.0584e+00,\n",
      "         1.2855e+00,  1.6769e+00,  7.8364e-01,  1.0772e+00,  2.0588e+00,\n",
      "         2.1517e+00,  8.2417e-01,  1.1475e+00,  9.3491e-01,  8.9832e-01,\n",
      "         9.4497e-01,  5.9679e-01,  1.1631e+00,  2.0867e+00,  7.8838e-01,\n",
      "         6.9218e-01,  1.4490e+00,  1.2537e+00,  1.1463e+00,  2.9956e+00,\n",
      "         1.1815e+00,  1.1889e+00,  2.9458e-01,  1.0813e+00,  9.4444e-01,\n",
      "         7.9169e-01,  7.8315e-01,  9.7698e-01,  8.1971e-01,  1.2170e+00,\n",
      "         2.0432e+00,  1.4789e+00,  7.8791e-01,  9.8695e-01,  1.1826e+00,\n",
      "         1.1899e+00,  1.0741e+00,  9.0901e-01,  1.3500e+00,  2.8447e+00,\n",
      "         1.7817e+00,  1.0372e+00,  8.4900e-01,  8.8879e-01,  1.3506e+00,\n",
      "         1.5863e+00,  9.1674e-01,  1.0476e+00,  3.3815e-01,  1.2261e+00,\n",
      "         1.0315e+00,  1.0282e+00,  2.0757e+00,  7.7013e-01,  6.6838e-01,\n",
      "         1.0913e+00,  1.0507e+00,  7.0485e-01,  6.8525e-01,  1.0505e+00,\n",
      "         6.2782e-01,  8.4977e-01,  1.2417e+00,  2.1888e+00,  9.6441e-01,\n",
      "         7.0386e-01,  6.9266e-01,  9.4106e-01,  8.5944e-01,  2.3665e+00,\n",
      "         7.4976e-01,  1.3817e+00,  1.2467e+00,  9.4172e-01,  1.1832e+00,\n",
      "         7.4276e-01,  7.2274e-01,  1.2734e+00,  9.4034e-01,  7.8537e-01,\n",
      "         5.0353e-01,  1.9578e+00,  1.0818e+00,  7.3912e-01,  2.2305e+00,\n",
      "         2.5790e+00,  1.3524e+00,  5.5105e-01,  7.5779e-01,  1.1572e+00,\n",
      "         1.2366e+00,  6.3156e-01,  1.2539e+00,  9.2410e-01,  7.3182e-01,\n",
      "         9.8573e-01,  1.4664e+00,  1.1575e+00,  1.4870e+00,  8.5318e-01,\n",
      "         6.6445e-01,  8.2891e-01,  8.3607e-01,  1.0599e+00,  1.1560e+00,\n",
      "         1.0393e+00,  9.8908e-01,  1.0065e+00,  2.7953e+00,  8.2061e-01,\n",
      "         9.1786e-01,  1.0059e+00,  1.0962e+00,  7.4367e-01,  1.5150e+00,\n",
      "         9.1226e-01,  1.0024e+00,  7.8959e-01,  1.1463e+00,  1.0715e+00,\n",
      "         1.0182e+00,  8.1112e-01,  1.0910e+00,  1.8882e+00,  1.0785e+00,\n",
      "         8.4245e-01,  1.0745e+00,  9.5425e-01,  9.2638e-01,  1.8331e+00,\n",
      "         1.2344e+00,  1.1654e+00,  6.6789e-01,  7.7724e-01,  6.4675e-01,\n",
      "         8.4197e-01,  1.1643e+00,  1.2764e+00,  9.7040e-01,  9.9515e-01,\n",
      "         8.1128e-01,  2.1268e+00,  1.8173e+00,  1.8576e+00,  8.5451e-01,\n",
      "         1.0831e+00,  7.3814e-01,  1.0456e+00,  8.6982e-01,  6.3293e-01,\n",
      "         9.8383e-01,  8.4340e-01,  9.2061e-01,  1.5507e+00,  6.7459e-01,\n",
      "         1.1147e+00,  1.0463e+00,  1.1672e+00,  9.8894e-01,  1.1751e+00,\n",
      "         1.7146e+00,  1.0404e+00,  1.2375e+00,  7.2376e-01,  2.0712e+00,\n",
      "         1.0156e+00,  6.4630e-01,  2.2817e+00,  9.6145e-01,  1.2016e+00,\n",
      "         1.6470e+00,  1.2304e+00,  7.4510e-01,  1.0130e+00,  1.1224e+00,\n",
      "         9.9490e-01,  1.0218e+00,  6.4747e-01,  1.2442e+00,  9.0690e-01,\n",
      "         5.1773e-02,  2.5259e-01,  1.4515e+00,  1.1116e+00,  8.5445e-01,\n",
      "         1.1295e+00,  1.0014e+00,  2.7135e+00,  9.0801e-01,  9.5210e-01,\n",
      "         1.1820e+00,  1.1636e+00,  1.9579e+00,  7.9071e-01,  9.4060e-01,\n",
      "         2.5232e+00,  1.5659e+00,  1.1232e+00,  1.7977e+00,  1.5288e+00,\n",
      "         1.0396e+00,  5.8081e-01,  6.4590e-01,  1.1048e+00,  1.1715e+00,\n",
      "         1.9364e+00,  1.3779e+00,  8.3155e-01,  1.1134e+00,  1.2765e+00,\n",
      "         1.0873e+00,  9.4385e-01,  1.2178e+00,  9.9047e-01,  1.5812e+00,\n",
      "         1.8775e+00,  8.9013e-01,  8.0554e-01,  7.6865e-01,  6.5426e-01,\n",
      "         1.0172e+00,  9.2104e-01,  1.1472e+00,  6.9070e-01,  1.6104e+00,\n",
      "         7.0892e-01,  1.0983e+00,  7.2664e-01,  9.3213e-01,  6.9598e-01,\n",
      "         4.7193e-01,  1.2242e+00,  9.5877e-01,  7.3257e-01,  1.0483e+00,\n",
      "         9.5507e-01,  1.0676e+00,  7.6342e-01,  1.3771e+00,  1.3390e+00,\n",
      "         7.9980e-01,  3.0302e+00,  1.4904e+00,  5.7866e-01,  1.0235e+00,\n",
      "         7.7802e-01,  1.9369e+00,  1.1878e+00,  9.8431e-01,  1.3075e+00,\n",
      "         6.3431e-01,  1.0371e+00,  1.2109e+00,  1.8531e+00,  7.5467e-01,\n",
      "         1.4357e+00,  9.0230e-01,  1.6680e+00,  1.1392e+00,  1.0434e+00,\n",
      "         2.2938e+00,  1.3745e+00,  8.0841e-01,  5.4818e-01,  5.6490e-01,\n",
      "         1.0875e+00,  2.0835e+00,  7.5271e-01,  6.7095e-01,  4.9682e-01,\n",
      "         1.2436e+00,  9.9343e-01,  2.2456e+00,  1.3657e+00,  9.3769e-01,\n",
      "         2.1861e+00,  1.3827e+00,  5.6835e-01,  6.8135e-01,  6.0640e-01,\n",
      "         1.0906e+00,  9.4234e-01,  1.6596e+00,  1.8205e+00,  1.1996e+00,\n",
      "         9.4299e-01,  1.1053e+00,  6.1087e-01,  8.3096e-01,  1.7067e+00,\n",
      "         1.3309e+00,  1.3713e+00,  6.4875e-01,  1.1089e+00,  9.2450e-01,\n",
      "         1.0344e+00,  1.3366e+00,  9.8420e-01,  8.8519e-01,  1.2795e+00,\n",
      "         8.3125e-01,  1.9164e+00,  1.2269e+00,  1.8579e+00,  6.8645e-01,\n",
      "         1.0701e+00,  8.8650e-01,  7.7421e-01,  1.3108e+00,  1.0596e+00,\n",
      "         9.3101e-01,  1.8748e+00,  8.5502e-01,  1.0179e+00,  1.2278e+00,\n",
      "         1.0167e+00,  9.2581e-01,  8.6621e-01,  9.9025e-01,  1.4543e+00,\n",
      "         1.0253e+00,  2.3519e+00,  6.1299e-01,  1.2012e+00,  1.2762e+00,\n",
      "         1.0848e+00,  1.5623e+00,  1.3301e-04,  3.4829e-01,  5.2500e-01,\n",
      "         1.9618e+00,  9.1537e-01,  1.1290e+00,  1.2295e+00,  1.0283e+00,\n",
      "         3.7916e-01,  1.3768e+00,  8.9090e-01,  1.3220e+00,  1.1015e+00,\n",
      "         1.1840e+00,  1.3396e+00,  1.1582e+00,  1.4383e+00,  1.6739e+00,\n",
      "         7.7583e-01,  2.2269e+00,  1.0536e+00,  1.0708e+00,  7.0321e-01,\n",
      "         1.4819e+00,  1.3213e+00,  7.2236e-01,  9.2316e-01,  8.9085e-02,\n",
      "         7.9336e-01,  9.1837e-01,  1.0118e+00,  1.0994e+00,  1.0637e+00,\n",
      "         1.6301e+00,  8.9248e-01,  1.2071e+00,  2.3878e+00,  1.1024e+00,\n",
      "         1.2863e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.5113e+00, -4.9380e+00,  1.2369e+00, -1.5024e+00,  1.3354e+00,\n",
      "         1.6920e-02,  4.2264e-01,  1.2230e+00,  1.8633e-01,  9.2536e-01,\n",
      "         1.1278e+00,  1.1642e+00,  1.0660e+00,  1.8057e+00,  1.1157e+00,\n",
      "         1.4551e+00,  1.0222e+00,  1.3092e+00,  1.7261e+00,  2.1313e+00,\n",
      "         1.4806e+00,  1.3980e+00,  1.1715e+00, -1.5518e+00,  2.0930e+00,\n",
      "        -6.2186e-01, -1.5625e+00,  4.8985e-01,  9.1513e-01,  4.9231e-01,\n",
      "        -8.6147e-01,  2.2677e+00,  1.1711e+00,  2.2760e+00,  1.4562e+00,\n",
      "        -3.0198e+00, -1.4721e+00, -3.8524e-02,  1.0275e+00,  3.1315e+00,\n",
      "         1.3686e+00, -1.5873e+00,  1.7238e+00,  1.5333e+00,  3.0830e-01,\n",
      "         3.4368e-01,  8.1099e-01, -2.1514e-02,  8.3699e-01,  7.7943e-01,\n",
      "         1.6788e+00,  9.6663e-01, -1.3130e+00,  1.3448e+00,  1.4469e+00,\n",
      "         1.0463e+00,  1.5227e+00,  1.3189e+00,  1.6442e+00,  1.8060e+00,\n",
      "         9.6570e-01,  1.6508e+00,  1.2003e+00,  3.1697e-01,  1.8536e+00,\n",
      "        -1.7630e-01, -1.2060e+00,  3.9260e-01, -9.3558e-01,  1.1085e+00,\n",
      "         1.5695e+00,  8.1451e-01,  1.7377e+00, -1.3890e-01,  1.0725e+00,\n",
      "        -6.7136e-01,  1.7231e-01,  1.3790e+00, -8.6278e-01,  1.0159e+00,\n",
      "         2.9272e-01,  1.6385e+00, -1.0292e+00,  8.0698e-01,  2.1133e+00,\n",
      "         1.6513e+00,  2.1933e+00,  1.1058e+00, -1.5835e+00,  8.0965e-01,\n",
      "        -8.4453e-01, -2.2557e+00,  5.2742e-01,  1.3715e+00,  9.6597e-01,\n",
      "         1.1354e+00,  2.9556e+00,  1.7617e+00,  6.0805e-01, -1.5488e+00,\n",
      "         1.7339e+00,  1.1316e+00,  1.3445e+00,  1.3557e+00,  1.1441e+00,\n",
      "        -1.6977e-01,  1.4908e+00,  5.7751e-01,  1.9886e+00,  1.3101e+00,\n",
      "         1.4148e+00, -1.5602e+00,  1.1021e+00,  7.7945e-01,  1.0905e+00,\n",
      "         1.9694e+00,  5.5198e-01,  8.4467e-01, -8.2872e-01,  1.6867e+00,\n",
      "         7.9827e-01,  9.2110e-01,  1.8753e+00,  1.6247e+00,  6.1963e-01,\n",
      "         1.4095e+00,  8.5961e-01, -2.6261e-01,  2.0755e+00, -2.3949e+00,\n",
      "         1.6495e+00, -1.6104e+00,  8.3016e-01, -1.2631e+00,  1.7051e+00,\n",
      "        -1.2823e+00,  1.4538e+00,  3.6506e-01, -6.4314e-01,  7.8990e-01,\n",
      "        -8.7093e-01,  7.9862e-01,  5.1998e-01,  1.6355e+00,  4.9514e-01,\n",
      "         2.1635e+00, -8.4421e-01,  4.3093e-01, -4.9371e-01, -1.0042e+00,\n",
      "        -4.7539e-01,  1.3443e+00,  2.8125e+00,  1.9198e+00, -2.6963e-01,\n",
      "        -2.2096e-01,  8.7814e-01,  4.1436e-01,  2.2720e+00,  1.5531e+00,\n",
      "        -8.1065e-02, -3.3946e-01,  1.8116e+00, -6.0358e-01, -1.2708e+00,\n",
      "        -1.5819e+00,  5.2145e-01,  1.2807e+00,  1.0702e+00,  5.9677e-01,\n",
      "         2.1682e+00, -8.4301e-01,  9.2270e-01,  2.5968e+00,  1.6594e+00,\n",
      "         1.4031e+00,  1.4228e+00,  1.3061e+00,  1.1260e+00,  5.1262e-01,\n",
      "         5.7564e-01,  9.0661e-01,  8.2570e-01,  1.2607e+00,  1.4111e+00,\n",
      "         1.3427e+00, -1.2683e+00,  1.7851e+00,  8.8266e-01,  3.0116e+00,\n",
      "         1.7114e+00,  9.8848e-01,  1.2969e+00,  1.3727e-01,  1.2874e+00,\n",
      "         1.1987e+00,  6.1911e-01,  4.7828e-01,  2.8113e+00,  4.2054e-01,\n",
      "         1.0726e+00,  1.3909e+00,  5.3361e-01, -1.6381e+00,  1.0482e+00,\n",
      "         1.0835e+00,  8.5959e-01,  6.6463e-01,  1.3481e+00,  1.1346e+00,\n",
      "         1.2947e+00,  1.7780e+00,  1.5377e+00, -1.7028e+00, -2.1556e+00,\n",
      "         1.9277e+00, -2.0024e+00,  1.3443e+00,  1.9693e+00,  1.3874e+00,\n",
      "         1.7478e+00,  3.6585e-02, -5.2495e-01,  2.1114e+00,  9.3238e-02,\n",
      "         8.0666e-01,  5.5566e-01,  7.8036e-01,  1.6143e+00,  1.2566e+00,\n",
      "         7.1252e-01, -9.2707e-01,  4.8954e-01, -5.5396e-01,  9.6442e-01,\n",
      "         1.3575e+00,  1.9476e+00,  1.4115e+00,  1.0616e+00,  1.1591e+00,\n",
      "         8.1359e-01,  2.3669e+00,  1.4109e+00,  9.7022e-02, -1.3552e+00,\n",
      "         5.2389e-01,  8.0338e-01,  8.1709e-01,  4.8483e-01,  1.1611e+00,\n",
      "         3.2368e-01,  1.0976e+00,  1.1768e+00,  1.9492e+00,  8.9048e-01,\n",
      "         1.8062e+00,  1.0343e+00,  8.2482e-01,  2.7301e-01, -1.6800e+00,\n",
      "        -4.1493e-01,  1.4695e+00,  1.5698e+00,  8.2235e-01,  7.4322e-01,\n",
      "         1.7820e+00,  6.6940e-01,  1.5962e+00, -6.0730e-01,  8.2028e-03,\n",
      "         1.3039e+00,  1.5082e+00,  1.5421e+00, -2.1366e+00,  1.1688e+00,\n",
      "         8.8662e-01,  3.5202e-01,  1.9665e+00, -1.0928e+00, -1.2229e+00,\n",
      "        -1.6446e+00,  1.5923e+00,  3.0127e+00, -1.7575e+00,  1.2437e+00,\n",
      "         3.6027e-01,  7.6838e-01,  2.3429e+00,  1.8324e+00,  1.0140e+00,\n",
      "         7.7979e-01,  1.9628e+00,  5.0943e-01,  6.3054e-02, -1.2780e+00,\n",
      "         2.1544e+00,  1.3756e+00,  4.1293e-01,  3.5017e-01,  5.9276e-01,\n",
      "         7.6099e-01, -1.3964e+00,  1.6351e+00, -1.0183e+00,  2.0649e+00,\n",
      "        -1.2641e+00,  1.1456e+00, -1.3942e+00,  8.2064e-01, -4.6973e-01,\n",
      "         6.2816e-01, -1.3091e+00, -1.8877e+00,  1.1887e+00,  5.6051e-01,\n",
      "         3.9453e-01,  1.1977e+00,  2.1178e-01,  1.8384e-01,  1.9120e+00,\n",
      "        -1.3214e+00,  4.0353e-01,  5.8860e-01,  4.0496e-01, -2.5875e-01,\n",
      "        -1.3995e+00,  2.1875e+00,  6.9547e-01, -1.1339e+00,  2.8820e-01,\n",
      "        -7.6239e-01,  4.6256e-01,  1.3832e+00, -9.4278e-01,  1.0806e+00,\n",
      "         9.0840e-01,  1.8161e+00,  3.2833e+00, -1.9102e+00,  1.9205e+00,\n",
      "         8.6604e-01,  9.1502e-01,  1.1549e+00,  6.1003e-01,  1.1203e+00,\n",
      "         4.6745e-01,  2.0899e+00,  1.9789e+00,  1.9772e+00,  3.8312e-01,\n",
      "        -1.6024e+00,  1.3570e-01,  1.5105e+00, -6.2702e-01,  9.2547e-01,\n",
      "         1.7553e+00,  1.2238e+00,  1.2385e+00, -4.6111e-01,  9.9581e-01,\n",
      "         1.4466e+00,  1.3480e+00,  1.3537e+00,  6.6047e-01,  2.4604e+00,\n",
      "         2.2043e+00,  9.3014e-01,  1.0887e+00,  2.1134e+00,  2.0029e+00,\n",
      "         3.9829e-01,  1.0798e+00, -1.6603e+00,  1.0425e+00, -1.1083e+00,\n",
      "        -1.5533e+00,  5.6316e-01,  1.7606e+00, -9.2677e-01,  1.1775e+00,\n",
      "         1.5709e+00, -1.4104e+00,  9.3305e-01,  9.8577e-01,  4.8761e-01,\n",
      "         8.0809e-01,  3.3989e+00,  1.3391e+00, -1.1069e+00,  6.5571e-01,\n",
      "         1.4885e+00,  2.5996e+00, -7.7534e-01, -2.4790e+00,  5.5543e-01,\n",
      "         7.9412e-01, -1.3203e+00, -5.8914e-01,  9.4060e-01,  1.1133e+00,\n",
      "         1.7130e+00,  1.2677e+00,  2.6688e+00,  8.6268e-01,  1.5085e+00,\n",
      "         9.2098e-01,  1.2088e+00, -3.5531e-01,  9.5705e-01, -3.1831e-01,\n",
      "         5.5169e-01,  1.0542e+00,  5.7787e-01, -1.4672e+00,  8.2655e-01,\n",
      "         1.3646e+00,  2.0470e+00, -1.3315e+00,  3.9532e-01,  7.4000e-01,\n",
      "        -3.7005e-02,  1.0577e+00, -1.5341e+00,  2.6141e-02, -5.5851e-01,\n",
      "         2.1098e+00,  1.7285e-01, -1.1383e-01,  1.0410e+00,  7.5585e-01,\n",
      "         4.8291e-01,  1.3343e+00, -1.4648e+00, -2.6801e+00,  7.2748e-01,\n",
      "        -2.5265e-01,  7.7975e-01,  3.1048e+00,  1.2024e+00, -3.7102e-01,\n",
      "        -9.9148e-01, -1.2700e+00,  9.7904e-01,  1.6303e+00,  2.6180e+00,\n",
      "         1.2809e+00,  1.2578e+00,  5.6802e-01,  6.0744e-01,  1.8841e+00,\n",
      "         1.6820e+00, -1.3383e-01,  2.2443e-01,  1.8325e+00, -9.5208e-01,\n",
      "        -2.9438e-01, -9.6303e-01,  8.3373e-01,  1.1360e+00,  1.0983e+00,\n",
      "         1.2467e+00,  3.3959e-01,  1.9484e+00,  1.3120e+00,  5.1365e-01,\n",
      "         1.6151e+00,  2.2276e+00,  1.9974e+00,  1.2005e+00, -1.1427e+00,\n",
      "         1.9950e+00,  1.2263e+00, -6.3337e-01,  9.8135e-01,  9.1816e-01,\n",
      "         2.5123e+00,  8.5272e-01,  1.0917e+00,  5.7410e-01,  1.4460e+00,\n",
      "         6.9208e-01, -1.1012e+00,  1.6374e+00,  9.3349e-01,  9.5267e-01,\n",
      "         1.4331e+00,  2.3708e+00,  1.0173e+00,  3.9761e-01, -1.4581e+00,\n",
      "         1.0717e+00,  1.3845e+00,  4.8334e-01,  1.3467e+00,  9.7434e-01,\n",
      "        -1.1838e+00,  3.9609e-01,  8.2691e-01,  2.4495e+00, -2.1858e+00,\n",
      "         1.2825e+00,  1.0792e+00, -4.1086e-01,  1.3803e+00,  2.1567e+00,\n",
      "         1.8668e+00,  7.7412e-01,  7.5522e-01,  2.2421e+00,  4.3414e-01,\n",
      "         9.7867e-01,  9.8755e-01,  2.2379e+00,  2.9300e-02,  1.5727e+00,\n",
      "         8.4210e-01, -1.1955e-01,  1.8075e+00, -1.4761e-04, -1.0044e+00,\n",
      "         7.0776e-01,  9.2775e-02,  1.6840e+00,  1.5638e+00,  2.2100e-01,\n",
      "         1.3429e+00,  2.1208e+00,  1.6258e+00,  2.5656e+00,  1.0089e+00,\n",
      "         1.6224e+00,  7.3882e-01,  1.3695e+00,  1.5348e+00, -5.2315e-01,\n",
      "        -1.7584e+00,  2.2075e+00,  1.0979e+00,  1.0165e+00,  4.8498e-01,\n",
      "         5.7388e-01,  6.2924e-01,  2.8821e+00,  1.5600e+00, -4.3544e-01,\n",
      "         3.9319e-01,  2.3544e+00,  7.9472e-02,  7.4662e-01,  5.9585e-01,\n",
      "        -4.4623e-01,  2.1812e+00,  1.2346e+00,  1.8295e+00,  8.0323e-01,\n",
      "         1.2426e+00,  2.0099e+00,  1.2722e+00, -2.6865e+00,  3.9684e-01,\n",
      "         1.1554e+00,  1.3279e+00,  1.1043e+00,  1.2795e+00,  1.4588e+00,\n",
      "         1.6892e+00,  2.1947e+00,  5.9753e-01,  6.8871e-01,  2.3153e+00,\n",
      "         8.0179e-01, -2.1613e-02,  1.4122e+00,  9.1014e-01,  7.8807e-01,\n",
      "        -9.4186e-03,  1.0891e+00,  8.0615e-01,  1.0996e+00,  1.1699e-01,\n",
      "        -2.0632e+00,  1.8523e+00,  6.6884e-01,  1.2186e+00,  6.0713e-01,\n",
      "         1.2203e+00,  1.3258e+00,  6.6750e-01,  1.7408e+00,  2.3823e+00,\n",
      "         1.4568e+00, -1.2829e+00,  1.8590e-01, -1.0522e+00,  2.0859e+00,\n",
      "         1.7308e+00,  1.4879e+00,  1.1058e+00,  1.0777e+00,  9.5484e-03,\n",
      "         1.2629e+00,  1.0586e+00,  2.3523e+00, -1.1479e-01,  1.0523e+00,\n",
      "         1.4555e+00,  1.7101e+00,  8.9661e-01,  2.9955e+00,  2.0690e+00,\n",
      "        -1.1542e+00,  1.2433e+00,  1.5538e+00,  6.0502e-01, -1.1272e+00,\n",
      "         9.5326e-01, -1.0244e+00, -1.4563e+00,  1.7187e+00,  2.1046e+00,\n",
      "        -9.8079e-01,  1.2216e+00,  8.7571e-02,  3.4137e+00,  3.0566e-01,\n",
      "         7.4829e-01,  1.2687e+00,  2.2658e+00,  1.1726e+00,  1.3304e+00,\n",
      "        -3.5135e-02,  1.3098e+00,  1.0963e-01,  5.8229e-01, -9.9231e-02,\n",
      "         1.2262e+00,  1.0625e+00, -1.9816e+00,  1.4777e+00,  2.9978e-01,\n",
      "         1.5131e+00,  9.3946e-01,  1.1567e-01,  1.4489e+00,  9.9946e-01,\n",
      "        -1.4274e+00, -2.1325e+00,  1.6778e+00, -8.1903e-01,  7.6559e-01,\n",
      "         1.8627e+00,  2.4004e-01,  3.9982e-01, -1.7952e+00,  1.4033e+00,\n",
      "        -3.4547e+00, -4.1269e-01,  8.4492e-01,  2.3139e+00,  2.3950e+00,\n",
      "         1.1149e+00,  1.4666e+00,  1.0502e+00,  1.1011e+00, -1.3382e+00,\n",
      "        -5.6290e-01,  1.4845e+00,  1.0873e+00,  1.3881e+00,  3.5904e-01,\n",
      "         7.1878e-01,  2.7001e-01, -5.2696e-01,  1.6304e+00, -1.0152e+00,\n",
      "         9.9931e-01,  1.1048e+00,  1.7755e+00,  9.9925e-01,  1.4893e+00,\n",
      "         2.0652e+00,  1.5523e+00,  1.7670e+00, -1.6797e-01,  9.3217e-01,\n",
      "         4.3681e-01,  1.1165e+00,  2.4471e+00, -8.9877e-01,  2.4409e+00,\n",
      "         1.4161e+00, -1.5448e+00,  1.7436e+00,  1.0815e+00, -1.7686e-01,\n",
      "        -1.3457e-01, -8.7384e-01,  1.5457e+00,  1.3486e+00,  9.9072e-01,\n",
      "         7.4373e-01, -2.6650e-01,  1.0806e+00,  2.4459e-01, -1.1390e-01,\n",
      "        -8.3956e-01,  6.3612e-01, -2.6561e+00,  1.7766e+00, -3.2963e-01,\n",
      "        -1.7488e+00, -3.3491e-01,  1.3211e+00,  1.0994e+00,  1.3070e-01,\n",
      "         8.6484e-01, -1.6129e+00,  5.5281e-01,  3.6622e-02,  1.2997e+00,\n",
      "         2.9227e-01,  1.7372e+00, -6.0054e-01,  1.0446e+00,  4.9601e-01,\n",
      "        -1.2274e+00,  7.3414e-01,  1.6037e+00,  1.7924e+00,  7.3103e-01,\n",
      "        -1.9313e-02,  7.1184e-01,  2.9868e-01,  2.7517e+00,  1.3958e+00,\n",
      "         7.3112e-01, -1.0385e-01,  1.1764e+00,  5.9243e-01, -3.8555e-01,\n",
      "         1.7872e+00,  1.7934e+00,  1.1195e+00,  5.1270e-01,  1.3340e+00,\n",
      "         2.2324e+00, -2.6797e-01,  1.2869e+00,  6.4732e-01,  1.2614e+00,\n",
      "         2.2169e+00,  1.4609e+00,  1.1565e+00, -2.1162e+00,  2.6931e-01,\n",
      "         3.1569e+00,  6.8004e-01,  8.3589e-01,  1.1884e+00,  6.5422e-01,\n",
      "         1.5349e+00,  3.1041e-02,  8.7092e-01,  5.9746e-01,  1.5778e+00,\n",
      "         8.9997e-01,  6.5278e-03,  3.2410e-01,  1.2534e+00,  2.2449e+00,\n",
      "         1.4300e+00, -5.8006e-01,  7.1804e-01,  1.3189e+00,  2.0227e+00,\n",
      "         1.4108e+00, -4.1056e-01, -3.2105e-02, -6.5158e-01,  8.1722e-01,\n",
      "         1.4865e+00,  8.4715e-01,  2.0375e-02,  1.4359e+00,  2.4698e+00,\n",
      "         1.8407e+00,  1.4077e+00,  7.7501e-01,  1.1779e+00,  4.6457e-02,\n",
      "         3.4365e+00, -4.4938e-01,  9.0768e-01, -2.4517e-01, -7.1209e-01,\n",
      "        -6.1229e-02, -9.5950e-01,  3.4267e-01,  1.2785e+00,  1.2389e+00,\n",
      "        -6.5787e-01,  1.4410e+00,  1.0147e+00,  1.9400e-02,  1.4517e+00,\n",
      "         5.4132e-01,  1.8570e+00,  1.9229e+00, -3.4389e-01,  8.2471e-01,\n",
      "         1.0268e+00,  2.0029e+00, -4.5191e-02, -1.8523e+00,  1.1190e+00,\n",
      "         2.0954e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0190]],\n",
      "\n",
      "         [[-0.0307]],\n",
      "\n",
      "         [[-0.0399]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0133]],\n",
      "\n",
      "         [[-0.0429]],\n",
      "\n",
      "         [[-0.0027]]],\n",
      "\n",
      "\n",
      "        [[[-0.0195]],\n",
      "\n",
      "         [[-0.0428]],\n",
      "\n",
      "         [[-0.0490]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0063]],\n",
      "\n",
      "         [[-0.0536]],\n",
      "\n",
      "         [[-0.0221]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0284]],\n",
      "\n",
      "         [[-0.0163]],\n",
      "\n",
      "         [[-0.0122]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0262]],\n",
      "\n",
      "         [[-0.0514]],\n",
      "\n",
      "         [[ 0.0054]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0804]],\n",
      "\n",
      "         [[ 0.0034]],\n",
      "\n",
      "         [[-0.0344]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0138]],\n",
      "\n",
      "         [[-0.0480]],\n",
      "\n",
      "         [[-0.0705]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0279]],\n",
      "\n",
      "         [[-0.0395]],\n",
      "\n",
      "         [[-0.0019]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0180]],\n",
      "\n",
      "         [[-0.0282]],\n",
      "\n",
      "         [[-0.0209]]],\n",
      "\n",
      "\n",
      "        [[[-0.0164]],\n",
      "\n",
      "         [[-0.0234]],\n",
      "\n",
      "         [[-0.0411]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0153]],\n",
      "\n",
      "         [[-0.0247]],\n",
      "\n",
      "         [[-0.0131]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0254, -0.0447, -0.0286, -0.0469, -0.0492, -0.0395, -0.0274, -0.0427,\n",
      "        -0.0284, -0.0302, -0.0400, -0.0398, -0.0380, -0.0388, -0.0333, -0.0273,\n",
      "        -0.0325, -0.0385, -0.0336, -0.0531, -0.0423, -0.0376, -0.0421, -0.0322,\n",
      "        -0.0436, -0.0430, -0.0253, -0.0387, -0.0542, -0.0334, -0.0293, -0.0361,\n",
      "        -0.0272, -0.0277], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0379]],\n",
      "\n",
      "         [[-0.0859]],\n",
      "\n",
      "         [[-0.0567]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0669]],\n",
      "\n",
      "         [[-0.0201]],\n",
      "\n",
      "         [[-0.0274]]],\n",
      "\n",
      "\n",
      "        [[[-0.0674]],\n",
      "\n",
      "         [[-0.0980]],\n",
      "\n",
      "         [[-0.1685]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0873]],\n",
      "\n",
      "         [[-0.0885]],\n",
      "\n",
      "         [[-0.0583]]],\n",
      "\n",
      "\n",
      "        [[[-0.0280]],\n",
      "\n",
      "         [[-0.0393]],\n",
      "\n",
      "         [[-0.0279]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0272]],\n",
      "\n",
      "         [[-0.0378]],\n",
      "\n",
      "         [[-0.0171]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0323]],\n",
      "\n",
      "         [[-0.0208]],\n",
      "\n",
      "         [[-0.0444]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0436]],\n",
      "\n",
      "         [[-0.0090]],\n",
      "\n",
      "         [[-0.0080]]],\n",
      "\n",
      "\n",
      "        [[[-0.0378]],\n",
      "\n",
      "         [[-0.0335]],\n",
      "\n",
      "         [[-0.0158]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0666]],\n",
      "\n",
      "         [[-0.0085]],\n",
      "\n",
      "         [[ 0.0091]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0135]],\n",
      "\n",
      "         [[-0.0055]],\n",
      "\n",
      "         [[-0.0003]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0187]],\n",
      "\n",
      "         [[ 0.0015]],\n",
      "\n",
      "         [[ 0.0176]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 7.1751e-01,  1.0295e+00,  1.7729e-01, -2.0537e-01,  5.8407e-02,\n",
      "         2.2333e-02, -2.7508e-01,  2.1681e-01, -8.8740e-02,  1.5240e-01,\n",
      "        -4.1794e-02,  1.7163e-01, -1.9912e-02,  3.5867e-01, -2.5503e-02,\n",
      "         1.8076e-01, -4.4225e-02,  2.4640e-01,  4.7795e-01, -9.7289e-02,\n",
      "         1.9856e-01,  7.4327e-02, -1.4202e-01,  2.6191e-01,  1.7898e-01,\n",
      "         4.9280e-01, -3.5088e-01, -3.9523e-01, -3.7093e-02, -1.7140e-02,\n",
      "         5.0806e-01,  6.7773e-01,  1.0596e-01,  1.4491e-01,  9.9946e-02,\n",
      "         8.7244e-03,  3.4783e-01,  3.4616e-01,  2.8180e-01,  7.0304e-01,\n",
      "        -1.4560e-02, -1.2223e+00, -5.2925e-02,  1.3287e-01, -9.0855e-02,\n",
      "        -4.0652e-01,  8.0279e-02, -5.6299e-01,  2.7789e-02, -3.9619e-01,\n",
      "        -3.3578e-03,  1.7298e-02,  6.2271e-02, -3.5866e-02,  1.9523e-02,\n",
      "         1.7050e-01, -2.3750e-01,  1.8510e-02,  2.4254e-01, -1.8722e-01,\n",
      "        -1.3860e-02,  5.9047e-02, -4.6093e-01, -2.3733e-01,  2.6077e-01,\n",
      "         1.9378e-01, -1.4797e+00,  2.4307e-01,  3.5561e-01,  9.0002e-03,\n",
      "         2.1070e-01,  1.3008e-01, -1.3653e-01, -1.8491e+00, -2.2765e-01,\n",
      "         3.5578e-01, -3.2093e-01,  5.5034e-01, -3.8878e-01,  5.1897e-01,\n",
      "        -1.9699e-01,  7.9370e-02,  3.4737e-02, -1.6327e-01,  1.2397e-01,\n",
      "         1.1578e-01,  3.2127e-01,  1.1069e-01, -3.6098e-01,  1.2463e-01,\n",
      "         1.8692e-01,  4.9665e-01, -2.7003e-01, -9.4735e-02,  1.7622e-01,\n",
      "        -4.2448e-01,  5.9577e-01,  1.7558e-01, -1.4625e-01,  6.8813e-01,\n",
      "         2.7214e-01, -7.3381e-02,  3.8499e-02,  4.9027e-02,  7.5882e-02,\n",
      "         3.7981e-01,  1.6230e-01,  9.2959e-02,  1.7582e-01,  4.3628e-03,\n",
      "         3.8673e-01, -3.7707e-01,  1.3475e-01,  3.5745e-01, -3.0010e-02,\n",
      "        -8.2957e-02,  1.6795e-02,  2.8831e-01,  3.2739e-01,  1.9797e-01,\n",
      "         1.2119e-01, -1.8480e-01,  1.3824e-01,  1.9350e-01,  1.5420e-01,\n",
      "        -4.6425e-02, -3.2400e-01, -6.4320e-01,  4.7272e-01,  7.7256e-02,\n",
      "         4.8877e-02,  4.1676e-01,  1.0924e-03,  2.1822e-01,  9.4979e-02,\n",
      "         4.8417e-01,  4.4397e-01, -7.6016e-02,  9.5009e-02,  1.6734e-01,\n",
      "         9.6359e-02, -1.6669e-02, -2.9830e-01,  2.5779e-01, -2.2376e-01,\n",
      "        -5.2563e-02,  1.0387e-01, -4.3356e-02, -5.4473e-01,  6.8071e-02,\n",
      "         2.2556e-01,  7.4892e-02,  3.5533e-01,  2.0344e-02,  1.2763e-01,\n",
      "        -3.2412e-01, -1.2090e-01,  1.7563e-01,  4.4233e-01,  2.8601e-01,\n",
      "         2.9277e-02,  1.3700e-01, -9.1050e-02,  3.9538e-01,  6.8293e-02,\n",
      "         3.0109e-01, -2.6200e-01,  7.6401e-02, -6.1855e-02,  1.1119e-01,\n",
      "        -1.7225e-01, -2.3465e-01, -3.1699e-01, -5.1470e-01, -1.4586e-01,\n",
      "         1.8131e-01,  3.6831e-01,  1.6270e-02,  1.1453e-01,  4.6786e-02,\n",
      "         1.2640e-01,  9.5345e-02, -6.8884e-02, -2.6430e-03,  2.0174e-01,\n",
      "         1.1404e-01,  1.7423e-01,  1.8920e-01,  2.3462e-01,  5.9982e-01,\n",
      "         2.3931e-01,  1.0193e-01, -3.6577e-01, -1.5810e-01,  3.6099e-02,\n",
      "         2.8416e-02, -1.9679e-01, -5.7387e-01,  4.2865e-01,  2.3792e-01,\n",
      "        -2.1518e-02,  2.6013e-01, -1.1862e-01,  3.9213e-01,  1.8519e-01,\n",
      "         3.8411e-01, -2.2749e-01,  3.0782e-02,  9.4738e-02,  3.9447e-01,\n",
      "        -6.8585e-02,  5.0498e-02,  2.2067e-01,  3.1098e-01,  5.2320e-01,\n",
      "         1.1576e-01, -2.4585e-01,  1.2385e-01,  3.3223e-01,  7.5541e-02,\n",
      "        -1.4183e-01, -1.3002e-01, -3.9327e-01,  3.1598e-01,  6.9871e-01,\n",
      "         6.2814e-02,  1.4611e-01,  1.4133e-01, -5.1115e-01,  5.3461e-02,\n",
      "        -3.2559e-01,  1.2866e-01,  2.0239e-01, -1.6130e-01,  4.7098e-02,\n",
      "         8.8683e-04,  6.6017e-02,  1.2248e-01,  1.8763e-02, -2.0215e-01,\n",
      "         7.1073e-03,  3.9900e-01, -4.5471e-02,  1.8413e-01, -1.4389e+00,\n",
      "        -3.0163e-01, -4.8485e-01, -1.1867e-01, -1.0326e-01, -4.1842e-01,\n",
      "         2.0408e-01,  5.6443e-02, -2.2901e-01,  1.7213e-01, -1.7353e-01,\n",
      "         4.1025e-01,  1.2508e-01, -9.0799e-02, -2.7126e-01,  3.0495e-01,\n",
      "        -8.4168e-02, -4.0758e-01,  2.1202e-01, -3.4664e-01,  4.7725e-01,\n",
      "        -7.0246e-02,  2.8318e-01, -6.3249e-05, -3.5300e-02, -1.7357e-01,\n",
      "         1.5556e-01,  3.5102e-01, -2.2972e-01,  2.5243e-01, -1.6284e-01,\n",
      "        -7.5552e-02,  2.8113e-01,  4.2227e-01,  2.3796e-01, -5.4430e-01,\n",
      "         2.3589e-01,  2.4409e-01,  5.9564e-01,  2.6094e-01,  1.0884e-01,\n",
      "         1.4510e-01,  3.5947e-01,  5.6192e-01,  2.1366e-01, -2.7063e-02,\n",
      "         2.0698e-01, -5.5646e-03, -2.6535e-01, -2.6490e-01, -1.5869e+00,\n",
      "         6.1051e-01, -7.0298e-02, -3.4353e-01,  1.3814e-01, -2.5749e-01,\n",
      "        -1.5607e-01,  3.9315e-01,  2.2517e-03, -5.5360e-02,  2.6551e-01,\n",
      "        -1.4020e+00,  4.8526e-02, -4.6907e-01,  5.5681e-02,  2.1936e-03,\n",
      "         4.4967e-02,  2.6813e-01,  5.9560e-01, -2.5686e-01, -1.2743e-01,\n",
      "        -2.3037e-01, -1.1147e-01,  1.2040e-02,  3.3238e-02, -2.7265e-01,\n",
      "         3.2473e-01, -2.8299e-01, -3.9536e-01,  1.2523e-01,  2.6812e-01,\n",
      "         2.6098e-01,  3.8743e-01, -3.6068e-01,  5.0067e-01, -7.3891e-01,\n",
      "         2.6867e-01, -1.9531e-01,  3.2146e-02, -9.0237e-03,  2.2925e-01,\n",
      "         2.7524e-02, -1.3513e-01,  5.8432e-02,  3.8155e-02,  4.6957e-01,\n",
      "        -1.4397e-01,  2.2858e-01,  3.0809e-01,  1.0106e-01,  2.1222e-01,\n",
      "         5.2848e-01, -1.5330e-01,  1.4946e-02,  1.3751e-01, -5.9399e-02,\n",
      "         8.1577e-02, -1.5807e-01,  3.1214e-01,  6.3185e-02,  5.8293e-02,\n",
      "         3.3124e-02, -3.7588e-01, -5.7862e-01,  2.1682e-01, -1.0004e-01,\n",
      "         4.0347e-01,  1.4530e-01,  1.6267e-01,  1.8025e-01,  4.9571e-01,\n",
      "        -6.2109e-02, -1.6834e-01, -8.9941e-02,  2.9754e-01,  2.3895e-01,\n",
      "         3.2154e-01,  2.3056e-01,  5.6582e-01,  1.9534e-01, -2.1780e-01,\n",
      "         2.8288e-01,  1.8291e-01,  3.4730e-01,  2.6197e-01,  1.4055e-01,\n",
      "         3.0340e-01,  5.3196e-01, -4.4142e-01, -2.1722e-02, -1.1515e-02,\n",
      "         1.9760e-01,  4.9286e-01,  9.8511e-02, -1.3867e-01,  7.7219e-02,\n",
      "         6.5881e-02,  5.4256e-02, -1.9003e-01,  7.6615e-01,  1.4025e-01,\n",
      "         4.0776e-01, -5.1228e-02,  6.9296e-02,  2.7678e-01, -1.4077e-01,\n",
      "         4.1698e-01,  5.4305e-03,  3.8151e-02, -2.5534e-01,  5.1344e-01,\n",
      "         3.4059e-01,  2.1176e-03,  3.6216e-01, -1.2603e-02,  1.7422e-01,\n",
      "        -5.3445e-02, -6.6101e-02, -4.7100e-03, -7.1046e-03,  1.8859e-01,\n",
      "        -6.7121e-02,  2.4241e-01, -3.2539e-02,  6.2467e-02,  4.1490e-01,\n",
      "        -1.1191e-01,  1.7066e-01,  4.9296e-01,  9.9555e-02, -1.6512e+00,\n",
      "        -2.9128e-01, -8.3711e-02, -2.3500e-01,  6.3154e-02,  6.0478e-01,\n",
      "        -6.2489e-01,  1.4046e-01, -1.5719e+00,  6.5527e-01, -3.0290e-01,\n",
      "        -3.1633e-02, -1.7055e-01,  6.2278e-01,  6.1728e-01,  1.2873e-01,\n",
      "        -3.8625e-02,  3.0597e-01, -1.4630e-01,  1.5580e-01,  5.9900e-01,\n",
      "         4.3286e-01, -1.9651e-01, -6.3826e-01,  6.3082e-02,  1.2101e-01,\n",
      "         4.7943e-02,  3.6703e-05, -1.9457e-01,  1.3840e-02,  4.2034e-01,\n",
      "         3.5024e-01, -7.9238e-01,  6.5863e-02,  2.8353e-02, -2.1529e-02,\n",
      "        -1.4355e-01, -3.5687e-01,  3.8095e-01,  4.9277e-01, -1.0816e-01,\n",
      "         6.6240e-02,  2.6341e-01,  3.4966e-01,  9.9599e-02,  7.3667e-01,\n",
      "         1.3089e-01,  1.7010e-01, -7.5604e-01,  1.9228e-01, -4.5505e-02,\n",
      "         3.2539e-01, -1.1660e-01,  1.0968e-01, -2.7811e-02,  1.2111e-01,\n",
      "         4.4235e-01, -1.1809e-01, -1.2167e-01,  1.2434e-01,  8.1000e-02,\n",
      "         2.3383e-01,  2.0837e-01, -8.8120e-02,  4.1586e-01,  6.3033e-01,\n",
      "         4.5301e-01,  6.0742e-02, -5.4143e-03,  3.4335e-02, -1.4801e-01,\n",
      "         6.0712e-02, -6.6834e-02,  2.3841e-01, -2.0747e-01, -5.9953e-01,\n",
      "         2.5427e-01,  1.9942e-01,  2.0867e-01, -2.0345e-01,  2.4861e-01,\n",
      "         1.8066e-01,  1.3190e-01, -1.8212e-01, -1.7778e-01, -6.7614e-02,\n",
      "        -2.1761e-01, -7.2037e-02,  3.2977e-01,  3.1141e-01,  1.5016e-01,\n",
      "        -2.1882e-01, -2.1210e-01,  3.6931e-04,  9.0703e-03,  1.2811e-01,\n",
      "        -2.4792e-01, -3.6366e-01,  2.5006e-01,  3.1986e-03,  1.9759e-01,\n",
      "        -1.7502e-01, -1.0992e-01,  4.0892e-01,  4.2401e-01, -3.1129e-01,\n",
      "        -3.1488e-01,  3.1787e-01,  9.0076e-02, -8.1947e-02,  4.4672e-01,\n",
      "         6.7118e-01,  3.4508e-01, -3.0153e-01, -9.5105e-02,  2.4982e-01,\n",
      "         2.4195e-01, -4.7429e-01,  4.6796e-01,  1.8580e-01, -2.6979e-01,\n",
      "         7.6557e-02,  5.8348e-01,  2.2407e-01,  1.7435e-01, -7.9626e-02,\n",
      "        -3.0522e-02,  2.6415e-01, -1.2451e-01,  1.1546e-02,  2.6061e-01,\n",
      "        -1.3204e-02,  2.4528e-01,  1.1189e-01,  3.2386e-01, -3.1761e-02,\n",
      "        -1.8963e-02,  3.2139e-02,  1.9401e-01, -6.9537e-02,  3.5722e-01,\n",
      "         1.1870e-01,  1.4433e-02, -5.1651e-01,  7.8864e-02,  1.0165e-01,\n",
      "         7.9674e-02, -8.3120e-02,  1.3801e-01,  5.0735e-01,  2.9263e-01,\n",
      "        -8.4643e-02, -2.0720e-01, -1.1959e-01, -3.7318e-02,  2.8849e-02,\n",
      "        -1.5217e-01,  1.6878e-01, -2.8884e-01, -7.8667e-02, -3.4997e-01,\n",
      "        -4.9419e-02,  5.9107e-02, -5.3888e-02,  2.1922e-01,  3.7582e-02,\n",
      "         1.2472e-02,  7.0728e-02, -3.0681e-01,  2.8417e-01,  1.8892e-01,\n",
      "         1.9122e-01, -4.6941e-02,  2.0663e-02, -4.5168e-02, -3.4812e-01,\n",
      "         7.6647e-02, -1.0143e-01, -7.8726e-02, -1.3932e-02, -1.7074e-01,\n",
      "         3.9803e-02,  4.6925e-02,  1.0463e-01,  3.2962e-01,  3.7295e-01,\n",
      "         4.5197e-02,  8.4661e-02,  4.9921e-02, -1.5026e-01,  4.7994e-01,\n",
      "         1.5827e-01, -4.5418e-01,  1.6699e-01,  1.3785e-01,  3.3970e-01,\n",
      "         4.1812e-02,  2.6158e-01, -1.5807e-01,  2.3396e-01,  1.9012e-01,\n",
      "         1.2383e-01,  1.9437e-01,  9.7841e-02,  7.3772e-02, -1.2570e-01,\n",
      "        -1.2770e+00, -6.5177e-01, -9.4704e-02, -2.5477e-01, -1.7600e-01,\n",
      "         1.5724e-01,  7.7536e-02,  6.9529e-01,  1.6493e-02,  5.0090e-02,\n",
      "         1.0528e-01,  2.4774e-01,  8.3099e-02, -2.2577e-01,  1.2736e-01,\n",
      "         5.9418e-01, -1.2393e-01,  3.5017e-01, -3.9061e-02,  3.6469e-01,\n",
      "        -2.5493e-02, -2.8487e-01, -2.1312e-01, -1.0459e-01,  2.5022e-01,\n",
      "         1.5647e-01,  1.4475e-01, -5.7628e-02,  4.4563e-01,  4.6523e-01,\n",
      "         1.3383e-01,  6.4936e-02,  3.0499e-01,  1.3338e-01,  1.2133e-01,\n",
      "         2.9701e-01, -5.7939e-04, -2.2450e-02, -8.8557e-02, -3.4350e-01,\n",
      "         1.0856e-02, -1.0643e-01, -4.3978e-01, -1.5594e-01,  8.7438e-02,\n",
      "        -4.1529e-01,  2.8886e-02, -7.2400e-02,  1.9810e-02, -6.4310e-02,\n",
      "        -8.3594e-02,  2.3095e-01,  2.6155e-01, -2.0992e-01,  1.1598e-01,\n",
      "         1.1420e-03,  1.5724e-01,  3.8017e-01,  1.2827e-01,  4.6961e-01,\n",
      "        -1.8149e-01,  8.1301e-01,  3.1535e-01, -3.7750e-01,  3.6770e-02,\n",
      "        -6.1853e-01,  1.1680e-01,  3.3428e-01,  4.9464e-02,  3.7506e-01,\n",
      "        -2.7298e-01,  7.9098e-02,  1.5273e-01,  2.4165e-01, -3.4078e-01,\n",
      "        -3.1342e-01, -2.3965e-01, -1.2357e-01,  1.2523e-01, -4.5956e-01,\n",
      "         3.7389e-01,  1.8960e-01, -6.1364e-02, -1.6675e-01, -2.7417e-01,\n",
      "        -4.9946e-01,  1.8749e-01, -1.2998e-01, -3.9956e-01, -4.2799e-01,\n",
      "        -2.4285e-01,  7.6052e-02,  3.8482e-01,  2.8091e-01, -1.8864e-02,\n",
      "         4.7517e-02,  3.0513e-01, -9.0034e-02, -1.0171e-01, -3.6097e-01,\n",
      "         1.0150e-01, -5.5710e-02,  1.3621e-01,  6.2033e-01,  1.7340e-02,\n",
      "         5.8014e-02, -3.9724e-01, -2.6893e-01, -6.5706e-02,  2.6687e-01,\n",
      "         3.1906e-01,  4.4271e-01, -2.5423e-01,  1.3052e-01,  1.0030e-02,\n",
      "         2.6525e-01, -2.2962e-01,  5.2977e-02,  7.6000e-02,  2.8481e-01,\n",
      "         3.8035e-01,  5.8003e-01, -3.1903e-02,  2.4939e-01, -2.2905e-01,\n",
      "         4.0726e-01, -3.8394e-02, -2.1344e-01,  1.5961e-02,  1.3848e-01,\n",
      "         1.9688e-02,  4.6129e-01,  1.3521e-02,  9.9252e-02,  1.8199e-01,\n",
      "         5.2861e-02, -1.8719e-02, -2.4549e-02, -7.6065e-02,  5.6268e-01,\n",
      "        -7.5497e-02,  3.6657e-01, -3.2316e-01,  1.5833e-01,  2.8446e-01,\n",
      "         1.7915e-01, -1.1714e-01, -1.5413e+00, -1.0568e+00, -4.1321e-01,\n",
      "         6.4285e-01,  3.7368e-02, -4.0714e-01,  2.2605e-01,  1.2495e-01,\n",
      "        -1.5836e-01,  3.6742e-01, -1.5759e-02,  4.3004e-01,  4.9246e-02,\n",
      "         4.5096e-01, -4.3690e-01,  2.1315e-01, -2.9184e-02,  2.6870e-01,\n",
      "        -2.3254e-01,  5.3754e-01,  5.2207e-02,  1.5309e-01, -2.5543e-01,\n",
      "        -3.2911e-01,  3.3797e-01, -1.7515e-01, -1.3470e-01, -7.9060e-01,\n",
      "        -1.2135e-01,  9.9602e-02,  9.4864e-02, -5.0530e-01,  1.4894e-01,\n",
      "         2.4491e-01, -1.8294e-01,  2.5863e-01,  5.2726e-01,  1.2773e-01,\n",
      "         6.1900e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 3.2680e-01]],\n",
      "\n",
      "         [[-5.9053e-01]],\n",
      "\n",
      "         [[-4.4720e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7033e-01]],\n",
      "\n",
      "         [[-3.4416e-01]],\n",
      "\n",
      "         [[ 4.0337e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.9668e-01]],\n",
      "\n",
      "         [[-1.9145e-02]],\n",
      "\n",
      "         [[-1.8362e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.0878e-01]],\n",
      "\n",
      "         [[ 3.1047e-02]],\n",
      "\n",
      "         [[-6.7072e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.3762e-01]],\n",
      "\n",
      "         [[-2.8622e-01]],\n",
      "\n",
      "         [[ 3.3249e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.2986e-01]],\n",
      "\n",
      "         [[ 1.9632e-02]],\n",
      "\n",
      "         [[ 9.9811e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.8028e-02]],\n",
      "\n",
      "         [[ 9.7938e-01]],\n",
      "\n",
      "         [[-4.3995e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8026e-01]],\n",
      "\n",
      "         [[-5.9876e-01]],\n",
      "\n",
      "         [[-1.3878e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1597e-01]],\n",
      "\n",
      "         [[-6.9767e-03]],\n",
      "\n",
      "         [[-4.4107e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0955e-01]],\n",
      "\n",
      "         [[ 3.2533e-01]],\n",
      "\n",
      "         [[-2.4502e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5485e-01]],\n",
      "\n",
      "         [[-7.5607e-01]],\n",
      "\n",
      "         [[ 7.8427e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0952e-02]],\n",
      "\n",
      "         [[-3.5548e-01]],\n",
      "\n",
      "         [[ 4.4581e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([4.1026, 7.5783, 4.6142, 4.9697, 5.1517, 4.4534, 8.0069, 4.3973, 6.3006,\n",
      "        6.2860, 3.6404, 4.4286, 8.0162, 4.4073, 5.1935, 4.0078, 3.9076, 4.2112,\n",
      "        3.9967, 3.3790, 3.3974, 4.6993, 4.2050, 3.8435, 5.8284, 3.9764, 4.0157,\n",
      "        3.9710, 2.8675, 3.8504, 5.7017, 5.7777, 4.2803, 4.2924, 3.5926, 4.8000,\n",
      "        3.9093, 4.1123, 7.2937, 4.0985, 3.7149, 7.3912, 3.8495, 7.2344, 6.4495,\n",
      "        3.9243, 3.6021, 4.0319, 4.2892, 4.7477, 3.2272, 4.3931, 4.2524, 4.5028,\n",
      "        4.0936, 4.4110, 4.1109, 5.1523, 4.0079, 3.5323, 3.4439, 5.0185, 3.8308,\n",
      "        4.8671, 3.5323, 4.2109, 4.6714, 3.7579, 5.2232, 3.9861, 5.7848, 3.5453,\n",
      "        7.8287, 4.1280, 4.6858, 4.0643, 4.7795, 5.0554, 4.1484, 4.7268, 4.1446,\n",
      "        4.4512, 5.0906, 4.5587, 4.3501, 4.0092, 4.2969, 4.7910, 3.5841, 5.1736,\n",
      "        3.7585, 3.5817, 5.2020, 8.1946, 6.6900, 4.3838, 4.8491, 3.7076, 4.0408,\n",
      "        4.9891, 4.3103, 3.9876, 3.2850, 4.4354, 4.1123, 4.7175, 4.4395, 3.8646,\n",
      "        3.6757, 4.7359, 4.7220, 3.6830, 5.1279, 3.6988, 5.2001, 7.7375, 3.7697,\n",
      "        4.3408, 5.2260, 4.6966, 3.9608, 4.7285, 5.2276, 4.0210, 3.9812, 4.7302,\n",
      "        4.8414, 4.3942, 4.1897, 3.5771, 6.8257, 4.3183, 4.2403, 6.1123, 4.7771,\n",
      "        3.8878, 4.1996, 4.1563, 4.4087, 5.2684, 4.0734, 5.3738, 4.5566, 4.3911,\n",
      "        5.3861, 4.8245, 3.9153, 3.9142, 4.8014, 5.2861, 4.0246, 6.1323, 6.1492,\n",
      "        6.3516, 3.9038, 4.5392, 4.6282, 3.9954, 7.6607, 3.9838, 4.5913, 4.4997,\n",
      "        5.2187, 4.9738, 4.5787, 4.6475, 4.2966, 3.7162, 4.2053, 4.8985, 3.8169,\n",
      "        5.3639, 4.1439, 3.8342, 6.6696, 4.7537, 4.3978, 4.3908, 5.4365, 4.4338,\n",
      "        4.1955, 4.5662, 5.3499, 3.6698, 3.7490, 4.1105, 4.1755, 7.1555, 3.5472,\n",
      "        5.1508, 3.7680, 5.0388, 3.8755, 4.7568, 4.7329, 4.0169, 5.6838, 4.8330,\n",
      "        4.0408, 4.3337, 4.3752, 4.1045, 4.9908, 5.8176, 4.9193, 6.6425, 4.3810,\n",
      "        4.2678, 4.0938, 4.9782, 6.0071, 4.5539, 4.7560, 4.2653, 5.7981, 4.5508,\n",
      "        5.2386, 4.3037, 3.6805, 4.5450, 5.3111, 4.1053, 5.9722, 4.4622, 4.5835,\n",
      "        3.5399, 4.0349, 4.7936, 4.0760, 3.5154, 5.3066, 4.1747],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 3.4592e-04, -1.0891e-02, -1.7647e-03, -1.2983e-03, -3.1510e-03,\n",
      "        -2.8490e-03, -2.4897e-03,  1.5776e-02, -5.9267e-03,  3.8566e-03,\n",
      "        -9.4936e-03, -3.9223e-03, -1.1284e-02,  5.0633e-04,  1.0850e-02,\n",
      "         4.5465e-03,  2.5181e-03,  2.7093e-03, -1.0797e-03, -1.6413e-04,\n",
      "         2.6385e-03, -3.3213e-05,  1.7474e-03, -4.5094e-03,  3.3618e-03,\n",
      "         1.0242e-02,  3.2866e-03, -8.3317e-04, -4.0809e-03, -4.7787e-03,\n",
      "        -5.5829e-03, -1.2722e-02,  2.0658e-03, -4.3685e-03, -4.6773e-03,\n",
      "        -1.0538e-02, -7.9394e-04,  3.5926e-05,  6.4248e-03, -2.1678e-04,\n",
      "        -1.9723e-03, -3.9547e-03,  4.1384e-03,  6.0207e-03,  5.1361e-03,\n",
      "         4.0711e-04, -7.8172e-03,  1.8461e-03,  1.3019e-03,  2.9044e-03,\n",
      "         3.0206e-03,  1.1434e-03, -1.2067e-03,  1.4622e-03, -2.6284e-03,\n",
      "        -6.0030e-03, -4.8474e-03, -2.8140e-03, -9.6280e-04, -5.9050e-03,\n",
      "        -2.8872e-04, -1.1587e-03,  5.6582e-04, -7.3533e-03,  5.1501e-04,\n",
      "         2.8288e-03,  4.6416e-03,  6.3102e-04,  4.5469e-03,  3.3846e-03,\n",
      "        -6.2799e-03, -3.1668e-03,  1.2679e-02,  6.6817e-03,  2.9310e-03,\n",
      "         3.0140e-03,  4.6892e-03, -8.7161e-04, -7.7296e-03,  4.5122e-03,\n",
      "         2.0282e-03, -1.7145e-03, -2.8703e-03, -7.4387e-03,  1.5272e-04,\n",
      "         5.9683e-03,  6.6182e-03, -1.1419e-03, -7.9367e-04,  8.4047e-03,\n",
      "        -3.8733e-03,  2.2039e-03,  3.6187e-03,  4.1238e-03,  9.6788e-03,\n",
      "        -4.3615e-04, -7.0855e-04, -1.1498e-03,  5.0219e-03, -9.0379e-03,\n",
      "        -1.4277e-03,  2.3526e-03,  3.7728e-04, -3.4212e-03,  1.3800e-03,\n",
      "        -6.6562e-03, -5.2707e-03,  5.2505e-03,  1.6799e-03, -1.4852e-03,\n",
      "        -5.1263e-04, -2.0599e-03,  5.8184e-03,  3.1678e-04, -1.1148e-03,\n",
      "        -5.9011e-03,  1.1103e-03, -5.3240e-03, -7.4266e-03, -1.5994e-03,\n",
      "         1.0481e-03, -5.8870e-05,  2.9087e-03,  5.1815e-03, -1.5313e-03,\n",
      "         1.1897e-03, -1.1355e-03, -5.2652e-03,  6.8096e-03,  1.5769e-03,\n",
      "         5.2688e-04, -3.1392e-03, -1.1606e-04, -3.3821e-03,  1.5875e-03,\n",
      "         6.7941e-03, -3.4811e-03,  5.9781e-03, -4.6464e-05,  2.0513e-03,\n",
      "        -5.4803e-03, -8.5136e-03, -5.8016e-03,  4.9007e-04,  5.7243e-04,\n",
      "         2.2715e-03,  2.7627e-04,  7.2440e-03, -6.1895e-03, -8.7338e-03,\n",
      "         7.4469e-04,  1.2428e-03, -1.3874e-02,  7.1270e-03, -5.2335e-03,\n",
      "        -5.9912e-03,  2.5778e-03, -3.2809e-03, -1.3350e-02, -5.1603e-03,\n",
      "        -7.2205e-04,  1.0152e-02,  2.2275e-03, -7.1388e-04, -8.0410e-04,\n",
      "         3.3943e-03,  3.2367e-03,  1.4094e-04, -1.0017e-03, -6.1718e-03,\n",
      "        -1.0848e-03,  9.3946e-03, -1.2464e-03,  6.4124e-04,  5.6532e-03,\n",
      "        -3.9079e-03,  3.3416e-03, -2.3709e-03,  2.4122e-03, -1.5351e-03,\n",
      "        -1.4482e-03, -7.8737e-03, -3.3279e-04, -2.1097e-03, -6.8299e-03,\n",
      "         1.0748e-03, -2.5929e-03, -8.0627e-03, -1.7018e-03,  1.6344e-02,\n",
      "         1.8752e-03,  3.5574e-03, -2.6205e-03,  3.0508e-03,  5.6194e-03,\n",
      "         7.2142e-03,  3.6393e-03, -3.5560e-03, -6.9633e-03, -1.8028e-03,\n",
      "         1.0580e-03, -1.7631e-04, -1.3260e-04,  6.5356e-03, -4.2174e-03,\n",
      "        -5.7532e-03,  3.2589e-03,  3.3572e-03, -4.0206e-03,  4.7819e-03,\n",
      "         1.2163e-03, -1.4757e-03, -2.1863e-03,  1.6529e-03,  5.8426e-03,\n",
      "         1.0472e-02,  4.8454e-03,  3.7744e-04, -1.0256e-03,  3.8696e-03,\n",
      "         1.3150e-03,  3.8127e-03,  6.1386e-03,  1.8765e-03,  2.0142e-03,\n",
      "        -1.4435e-03,  1.8705e-03, -7.0950e-04, -4.9880e-03, -2.2410e-03,\n",
      "        -3.7575e-03, -2.3022e-03], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.7979]],\n",
      "\n",
      "         [[-0.1067]],\n",
      "\n",
      "         [[-0.1600]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4828]],\n",
      "\n",
      "         [[-0.2259]],\n",
      "\n",
      "         [[ 0.0720]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5796]],\n",
      "\n",
      "         [[-0.2301]],\n",
      "\n",
      "         [[-0.1093]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1737]],\n",
      "\n",
      "         [[-0.5705]],\n",
      "\n",
      "         [[ 0.6302]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4310]],\n",
      "\n",
      "         [[-0.3632]],\n",
      "\n",
      "         [[-0.4227]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1773]],\n",
      "\n",
      "         [[ 0.0100]],\n",
      "\n",
      "         [[ 0.2662]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2679]],\n",
      "\n",
      "         [[ 0.0750]],\n",
      "\n",
      "         [[ 0.4894]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2491]],\n",
      "\n",
      "         [[ 0.0664]],\n",
      "\n",
      "         [[ 0.2064]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0468]],\n",
      "\n",
      "         [[ 0.5272]],\n",
      "\n",
      "         [[ 0.4906]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4821]],\n",
      "\n",
      "         [[-0.0492]],\n",
      "\n",
      "         [[ 0.3545]]],\n",
      "\n",
      "\n",
      "        [[[-0.1732]],\n",
      "\n",
      "         [[ 0.0684]],\n",
      "\n",
      "         [[-0.1327]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1549]],\n",
      "\n",
      "         [[-0.2933]],\n",
      "\n",
      "         [[-0.0545]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.2417, 0.5829, 0.3550,  ..., 0.2839, 0.3264, 0.4255], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.9745,  0.1952,  0.0043,  ..., -0.6348, -0.2603, -0.2350],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-2.9754e-01, -2.4271e-01, -1.8903e-01, -3.0881e-01, -2.9308e-01],\n",
      "          [-3.4723e-01, -3.8240e-01, -4.0421e-01, -4.1425e-01, -5.5223e-01],\n",
      "          [-1.2835e-01, -1.1507e-02,  8.0016e-02,  2.1564e-01,  9.3186e-02],\n",
      "          [ 2.5838e-01,  1.3180e-01,  3.9936e-01,  5.4045e-01,  4.6903e-01],\n",
      "          [-7.0239e-02, -2.0994e-01, -2.5056e-03,  1.5496e-01,  2.8440e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.3204e-01, -3.0495e-01, -6.2783e-02,  2.3340e-01,  4.0155e-01],\n",
      "          [-2.8015e-01, -2.8349e-01, -3.2638e-01,  2.8298e-01,  3.2438e-01],\n",
      "          [-3.3519e-01, -1.3319e-01, -2.7513e-01,  4.8746e-01,  7.3685e-01],\n",
      "          [-9.1685e-02,  3.7967e-02, -2.3200e-01,  4.6901e-02,  4.9400e-01],\n",
      "          [ 3.9174e-04,  1.3734e-01,  2.1470e-01,  3.0672e-01,  4.5982e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.8696e-01,  3.6337e-01, -5.0532e-02, -2.6430e-01, -8.9211e-01],\n",
      "          [ 4.0567e-01,  1.0000e-01, -3.3997e-01, -3.1298e-01, -4.4338e-01],\n",
      "          [-1.5439e-01, -1.8196e-01, -2.5258e-01, -1.7742e-01, -9.5269e-02],\n",
      "          [-7.8251e-02, -1.0591e-01, -2.0804e-01, -8.1403e-02, -2.3870e-02],\n",
      "          [ 1.0538e-01,  4.3047e-02,  1.2519e-01,  3.3837e-01,  3.6346e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.8059e-01, -1.3062e-01, -6.9824e-02, -1.3754e-01, -8.3814e-03],\n",
      "          [ 1.9453e-01,  1.8389e-01,  5.6845e-01,  6.7570e-01,  7.6174e-01],\n",
      "          [-3.6526e-01, -3.5942e-01, -2.6672e-01,  1.4056e-01,  3.5736e-01],\n",
      "          [-2.5856e-01, -7.4966e-02,  1.7522e-01,  2.6462e-01,  1.7868e-01],\n",
      "          [-6.5630e-01, -5.4062e-01, -3.7804e-01, -4.4190e-02, -2.3159e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1355e-01, -7.3829e-02,  2.0113e-01,  4.8630e-01,  4.0429e-01],\n",
      "          [ 1.4817e-01, -6.1600e-02,  1.3958e-01,  2.5782e-01,  2.6258e-01],\n",
      "          [-3.0572e-01, -3.0199e-01, -1.9531e-01, -2.7376e-01, -1.4653e-01],\n",
      "          [-5.9016e-01, -2.7923e-01, -9.3782e-02, -2.4719e-01, -2.6687e-01],\n",
      "          [-7.0978e-01, -5.0804e-01, -3.9153e-01, -3.7743e-01, -6.4793e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5661e-01,  2.3039e-01,  2.0451e-01, -8.9033e-02,  5.7558e-02],\n",
      "          [ 3.7272e-01,  4.7664e-01,  2.8505e-01,  5.7084e-02,  3.1055e-02],\n",
      "          [ 4.4293e-01,  3.0238e-01, -5.0563e-01,  3.1779e-02,  2.2104e-01],\n",
      "          [ 2.4653e-01,  2.4597e-01,  6.7453e-02,  1.5094e-01,  1.7752e-01],\n",
      "          [-3.0767e-01, -5.3388e-01, -6.9207e-01, -4.5009e-01, -2.2415e-01]]]],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.7489, 1.6216, 2.1816,  ..., 1.1705, 1.8910, 1.3984], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-2.0252, -1.8561, -1.4402,  ..., -0.3440, -1.5679, -1.2184],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.5139]],\n",
      "\n",
      "         [[ 0.0588]],\n",
      "\n",
      "         [[ 0.1616]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3712]],\n",
      "\n",
      "         [[-0.2200]],\n",
      "\n",
      "         [[-0.3545]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2988]],\n",
      "\n",
      "         [[ 0.0534]],\n",
      "\n",
      "         [[-0.2661]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1807]],\n",
      "\n",
      "         [[-0.6377]],\n",
      "\n",
      "         [[ 0.1484]]],\n",
      "\n",
      "\n",
      "        [[[-0.1779]],\n",
      "\n",
      "         [[-0.2898]],\n",
      "\n",
      "         [[-0.0746]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3496]],\n",
      "\n",
      "         [[ 0.1866]],\n",
      "\n",
      "         [[-0.1779]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1420]],\n",
      "\n",
      "         [[-0.0227]],\n",
      "\n",
      "         [[ 0.2037]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1517]],\n",
      "\n",
      "         [[-0.1787]],\n",
      "\n",
      "         [[-0.2799]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4816]],\n",
      "\n",
      "         [[ 0.2845]],\n",
      "\n",
      "         [[ 0.0816]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0755]],\n",
      "\n",
      "         [[ 0.1491]],\n",
      "\n",
      "         [[ 0.7672]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1326]],\n",
      "\n",
      "         [[-0.2153]],\n",
      "\n",
      "         [[ 0.2394]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5022]],\n",
      "\n",
      "         [[ 0.9029]],\n",
      "\n",
      "         [[-0.4274]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.2020,  0.0066,  0.2354,  0.1511,  0.1091,  0.3615, -0.1735,  0.1259,\n",
      "        -0.0209,  0.2084,  0.3698,  0.1471, -0.2246, -0.0166,  0.1487,  0.4077,\n",
      "        -0.0555, -0.1864, -0.2469,  0.2752, -0.2554, -0.0873,  0.2102,  0.2909,\n",
      "        -0.1906, -0.1907, -0.1600, -0.2300,  0.1144,  0.1636,  0.3933,  0.0781,\n",
      "        -0.2378, -0.1987, -0.2371, -0.2563,  0.0372, -0.1703, -0.2132, -0.1173,\n",
      "         0.3460,  0.0660, -0.2746,  0.2277,  0.4390, -0.0367,  0.0494,  0.1196,\n",
      "        -0.1684, -0.2021, -0.2283, -0.0537, -0.2024, -0.2317, -0.2227,  0.2242,\n",
      "        -0.0101,  0.1228], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2260]],\n",
      "\n",
      "         [[-0.1927]],\n",
      "\n",
      "         [[ 0.2317]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0195]],\n",
      "\n",
      "         [[ 0.0589]],\n",
      "\n",
      "         [[-0.4294]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0132]],\n",
      "\n",
      "         [[ 0.0747]],\n",
      "\n",
      "         [[-0.2363]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1322]],\n",
      "\n",
      "         [[ 0.2606]],\n",
      "\n",
      "         [[ 0.3955]]],\n",
      "\n",
      "\n",
      "        [[[-0.1870]],\n",
      "\n",
      "         [[ 0.0342]],\n",
      "\n",
      "         [[ 0.0957]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0596]],\n",
      "\n",
      "         [[ 0.1945]],\n",
      "\n",
      "         [[ 0.1467]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1633]],\n",
      "\n",
      "         [[ 0.5737]],\n",
      "\n",
      "         [[ 0.1520]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2403]],\n",
      "\n",
      "         [[-0.0480]],\n",
      "\n",
      "         [[-0.5859]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1842]],\n",
      "\n",
      "         [[ 0.1549]],\n",
      "\n",
      "         [[-0.1867]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1787]],\n",
      "\n",
      "         [[ 0.2502]],\n",
      "\n",
      "         [[-0.0685]]],\n",
      "\n",
      "\n",
      "        [[[-0.2166]],\n",
      "\n",
      "         [[ 0.0759]],\n",
      "\n",
      "         [[ 0.0931]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0654]],\n",
      "\n",
      "         [[-0.1573]],\n",
      "\n",
      "         [[-0.0170]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1471,  0.3223,  0.2414,  ..., -0.0580,  0.2486, -0.1326],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.4206]],\n",
      "\n",
      "         [[-0.3114]],\n",
      "\n",
      "         [[-0.0436]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1138]],\n",
      "\n",
      "         [[ 0.5521]],\n",
      "\n",
      "         [[ 0.1931]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1932]],\n",
      "\n",
      "         [[ 0.5109]],\n",
      "\n",
      "         [[ 0.6815]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0873]],\n",
      "\n",
      "         [[-0.0806]],\n",
      "\n",
      "         [[-0.0805]]],\n",
      "\n",
      "\n",
      "        [[[-0.0674]],\n",
      "\n",
      "         [[-0.4956]],\n",
      "\n",
      "         [[-0.3516]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4353]],\n",
      "\n",
      "         [[-0.0940]],\n",
      "\n",
      "         [[ 0.0950]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3894]],\n",
      "\n",
      "         [[-0.2018]],\n",
      "\n",
      "         [[-0.1833]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1876]],\n",
      "\n",
      "         [[-0.4899]],\n",
      "\n",
      "         [[-0.1672]]],\n",
      "\n",
      "\n",
      "        [[[-0.0354]],\n",
      "\n",
      "         [[ 0.1021]],\n",
      "\n",
      "         [[-0.2277]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0183]],\n",
      "\n",
      "         [[-0.4365]],\n",
      "\n",
      "         [[ 0.1236]]],\n",
      "\n",
      "\n",
      "        [[[-0.4025]],\n",
      "\n",
      "         [[-0.5508]],\n",
      "\n",
      "         [[-0.6788]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2988]],\n",
      "\n",
      "         [[ 0.2252]],\n",
      "\n",
      "         [[ 0.0321]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.5321, 0.3750, 0.6535, 0.8098, 0.2968, 1.3391, 0.2475, 0.7682, 0.3941,\n",
      "        0.7690, 0.9130, 0.6631, 0.5582, 0.9217, 0.3616, 1.1575, 1.3913, 1.0423,\n",
      "        0.4324, 0.9990, 0.7490, 0.4750, 0.3296, 0.8628, 0.3166, 0.4592, 0.6794,\n",
      "        2.3448, 0.4826, 0.8982, 0.4707, 0.1515, 0.6463, 0.7767, 0.9221, 0.3374,\n",
      "        0.9127, 1.1422, 0.4312, 0.3457, 1.7089, 0.2201, 1.4260, 0.1597, 0.6904,\n",
      "        0.9323, 0.9040, 1.0574, 1.0827, 0.5216, 0.7466, 1.0701, 0.7015, 0.6477,\n",
      "        0.9694, 0.8428, 1.0413, 0.5341, 2.6992, 0.5554, 0.9279, 0.9109, 0.9750,\n",
      "        0.8912, 0.9410, 0.6758, 1.3396, 0.3129, 0.4933, 1.0626, 0.5822, 0.8123,\n",
      "        0.1021, 0.8806, 0.3613, 1.2348, 0.5634, 0.6270, 0.4322, 0.6639, 1.4426,\n",
      "        0.4240, 0.2340, 0.4282, 0.3137, 1.0640, 0.2752, 0.3600, 0.4777, 0.6715,\n",
      "        1.0002, 0.3991, 0.7135, 0.4378, 0.4568, 0.8337, 0.6455, 0.8509, 1.2944,\n",
      "        0.5891, 0.7201, 0.6299, 0.7675, 0.6971, 1.0519, 1.7438, 0.2353, 0.6585,\n",
      "        0.7237, 0.9450, 0.5043, 0.6763, 0.2986, 0.9980, 2.1294, 0.4044, 1.3467,\n",
      "        0.7075, 0.2887, 0.7501, 0.8620, 0.4794, 0.5730, 0.6539, 2.1103, 1.3325,\n",
      "        0.6301, 0.4910, 0.2563, 0.9588, 0.5189, 1.5857, 0.4746, 0.2936, 0.1613,\n",
      "        1.6689, 1.0291, 1.2539, 0.9343, 0.9247, 1.2198, 0.2470, 0.7452, 0.8246,\n",
      "        0.3927, 0.3076, 1.0121, 0.9348, 0.9573, 0.6101, 0.5951, 0.3364, 0.5673,\n",
      "        0.2470, 1.1557, 0.7292, 1.0379, 0.9498, 0.2635, 0.2780, 0.5762, 0.4709,\n",
      "        0.7471, 0.6662, 0.3684, 3.8862, 0.6461, 2.5883, 2.3922, 0.3239, 1.2306,\n",
      "        0.8047, 0.7827, 0.6620, 0.4911, 0.7685, 0.3158, 2.0726, 0.5449, 0.8375,\n",
      "        0.8543, 0.5798, 0.6325, 0.7105, 1.2250, 1.4396, 2.5773, 0.0276, 0.4895,\n",
      "        0.6496, 1.0716, 0.5292, 1.0360, 1.2751, 0.9482, 1.6034, 0.4247, 0.5434,\n",
      "        0.5952, 1.6738, 0.3590, 0.6193, 0.6014, 0.5789, 0.8334, 0.1343, 1.7131,\n",
      "        1.0756, 0.2956, 1.2306, 0.1776, 1.7520, 0.1976, 0.5710, 0.4447, 0.4748,\n",
      "        1.2605, 0.5125, 1.1637, 0.4205, 0.2595, 0.9695, 3.3400, 0.7096, 1.7159,\n",
      "        0.7269, 0.7191, 0.8939, 3.0601, 1.0704, 0.7164, 2.9375],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 3.8759e-01, -2.7861e-01,  4.0218e-01, -1.0121e-01,  8.6417e-02,\n",
      "         7.2081e-01, -5.8297e-02, -1.4282e-01, -9.0848e-02,  5.8085e-01,\n",
      "        -2.1410e-01,  1.0887e-01,  1.2096e-01,  2.8610e-01, -7.4675e-04,\n",
      "         3.4829e-01, -4.1124e-01, -4.9980e-01, -1.7231e-01, -1.8576e-01,\n",
      "        -5.5625e-01,  3.3651e-01,  2.4060e-01, -4.0078e-01,  1.6715e-02,\n",
      "        -4.7566e-02, -2.3862e-01,  4.8222e-02,  1.8404e-01, -8.3961e-02,\n",
      "         2.6887e-01,  5.4808e-01,  2.1118e-01,  1.5211e-01, -2.0884e-02,\n",
      "        -3.8902e-01,  5.9304e-01, -1.5178e-01,  1.8383e-01,  1.4128e-01,\n",
      "        -8.9420e-02, -5.4146e-01, -3.8087e-01, -2.0392e-01, -2.7835e-01,\n",
      "         2.2107e-01, -3.1852e-01, -7.1585e-01,  1.7178e-01,  2.3813e-01,\n",
      "         1.6691e-01,  3.3888e-02, -1.6104e-01,  1.3293e-01, -4.8304e-01,\n",
      "         1.5514e-01, -3.7817e-03,  1.3921e-01,  4.3122e-01, -2.5138e-01,\n",
      "         3.0074e-01,  4.7257e-02, -5.5994e-01,  1.2209e-01, -2.3771e-01,\n",
      "         3.7244e-02,  7.4619e-02, -8.5468e-02, -4.6426e-01, -1.6281e-01,\n",
      "         4.3494e-01,  6.4739e-01,  1.1975e-01, -1.4282e-01,  4.2913e-01,\n",
      "        -3.8309e-01,  1.6526e-01,  3.7612e-01, -1.3293e-02,  3.3808e-01,\n",
      "        -3.0884e-01,  1.1147e-01,  2.2511e-01,  4.6091e-01, -8.8325e-02,\n",
      "        -4.2136e-01, -1.2413e-01,  1.0243e-01,  5.0637e-02, -2.0167e-01,\n",
      "         2.0094e-01,  2.2173e-01, -1.1448e-01,  2.7254e-01, -1.8598e-01,\n",
      "         2.4062e-01, -9.7333e-01,  7.5879e-01, -3.8403e-01, -6.5451e-01,\n",
      "         7.8924e-02,  1.3958e-01, -3.6111e-02,  1.9825e-01, -3.1083e-01,\n",
      "         9.7174e-01, -1.2360e-01, -1.2309e-01, -1.3445e-01, -5.4023e-01,\n",
      "        -6.9824e-02, -7.0964e-01,  1.6938e-01, -5.4082e-01, -7.8055e-01,\n",
      "        -1.2969e-01,  8.6685e-02, -5.7780e-02, -2.1181e-01, -3.1374e-02,\n",
      "        -1.6100e-01,  2.1439e-02, -3.2362e-01,  1.2906e-01, -4.2885e-01,\n",
      "        -3.0785e-01,  2.6628e-01, -1.1924e-02,  9.8206e-02, -2.0703e-01,\n",
      "        -2.9864e-01,  3.6777e-01, -3.8075e-01,  6.4945e-02, -4.3039e-01,\n",
      "         9.0965e-02,  2.4965e-01, -1.6216e-03,  4.8362e-01,  2.9218e-01,\n",
      "        -2.5045e-02,  1.7183e-01, -2.8664e-01,  2.6129e-01,  4.1163e-01,\n",
      "         1.2505e-01,  4.2746e-01, -2.9029e-01,  1.8377e-01,  3.7692e-01,\n",
      "         4.1246e-02,  2.1676e-01,  3.6931e-01, -1.0912e-01, -1.8911e-01,\n",
      "        -1.5152e-01, -3.3232e-01,  1.5841e-01,  4.6572e-01,  5.1890e-02,\n",
      "        -3.8083e-01, -1.5151e-01,  1.0077e-01, -3.3765e-01,  6.1166e-01,\n",
      "         1.2955e+00,  1.6224e-01,  6.1515e-02,  5.3629e-01, -2.3880e-01,\n",
      "        -4.7536e-01,  3.8451e-01, -8.6364e-02,  2.0668e-01, -4.3939e-01,\n",
      "         7.4548e-01, -1.1999e-01, -9.8523e-01, -1.9749e-01, -1.4607e-01,\n",
      "         6.0990e-02,  1.4129e-01,  1.6708e-01, -1.7426e-01, -1.7648e-01,\n",
      "         7.3138e-01,  9.2303e-01, -6.9337e-02,  5.8860e-02, -3.5750e-02,\n",
      "         5.9617e-02, -9.0648e-02, -3.4410e-01,  1.3033e+00,  2.1166e-01,\n",
      "         6.0226e-01,  6.2027e-02,  3.3248e-02, -3.0325e-01,  1.0721e+00,\n",
      "         2.2084e-02,  6.7230e-01, -1.2312e-01,  7.4882e-02, -5.1545e-02,\n",
      "         1.9009e-01,  4.6899e-01, -1.9711e-02,  2.5627e-01, -3.4442e-01,\n",
      "         4.3294e-02, -4.5883e-01,  2.3164e-01,  2.4623e-02, -1.9124e-01,\n",
      "        -3.8047e-01, -2.3702e-01, -1.5145e-01, -7.4097e-02, -4.7054e-02,\n",
      "         2.0090e-01,  5.4110e-01,  1.5409e+00,  3.3921e-01,  1.1060e+00,\n",
      "         1.3809e-02,  9.4180e-04, -2.4841e-01, -5.9779e-01, -6.5357e-01,\n",
      "         7.9739e-02,  3.2533e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.3648]],\n",
      "\n",
      "         [[-0.0038]],\n",
      "\n",
      "         [[-0.3100]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1429]],\n",
      "\n",
      "         [[-0.3835]],\n",
      "\n",
      "         [[ 0.1224]]],\n",
      "\n",
      "\n",
      "        [[[-0.2784]],\n",
      "\n",
      "         [[ 0.0764]],\n",
      "\n",
      "         [[ 0.0345]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4625]],\n",
      "\n",
      "         [[-0.2123]],\n",
      "\n",
      "         [[ 0.3733]]],\n",
      "\n",
      "\n",
      "        [[[-0.2988]],\n",
      "\n",
      "         [[-0.0898]],\n",
      "\n",
      "         [[ 0.1229]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2731]],\n",
      "\n",
      "         [[ 0.2601]],\n",
      "\n",
      "         [[-0.0281]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1977]],\n",
      "\n",
      "         [[-0.6874]],\n",
      "\n",
      "         [[-0.2725]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0440]],\n",
      "\n",
      "         [[ 0.1698]],\n",
      "\n",
      "         [[-0.3494]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2025]],\n",
      "\n",
      "         [[-0.6561]],\n",
      "\n",
      "         [[-0.1288]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3010]],\n",
      "\n",
      "         [[-0.7231]],\n",
      "\n",
      "         [[ 0.6451]]],\n",
      "\n",
      "\n",
      "        [[[-0.0119]],\n",
      "\n",
      "         [[ 0.3330]],\n",
      "\n",
      "         [[-0.1460]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1310]],\n",
      "\n",
      "         [[ 0.4748]],\n",
      "\n",
      "         [[ 0.3546]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.4507, 1.5122, 0.5990,  ..., 1.4266, 0.6187, 1.1767], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.6703, -1.3856, -0.4244,  ..., -1.8219, -0.6602, -1.3980],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 1.0456e-01, -1.0134e-01, -1.5326e-01,  3.2931e-02, -2.1553e-01],\n",
      "          [-2.5610e-01, -1.4762e-01,  2.0498e-01,  4.6362e-02, -4.9476e-01],\n",
      "          [-3.1896e-01, -2.7797e-01,  9.1744e-01, -9.3480e-02, -1.9769e-01],\n",
      "          [-4.9251e-01, -1.2943e-01,  5.7352e-01, -5.1798e-02, -5.2932e-02],\n",
      "          [-2.9354e-01,  1.9473e-02,  4.3940e-01,  1.1212e-01,  1.9390e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7351e-01,  7.8139e-02,  1.2192e-01,  1.2399e-02, -2.6947e-02],\n",
      "          [ 5.0711e-01,  4.2522e-01,  5.2205e-01,  1.4626e-01, -1.5947e-02],\n",
      "          [ 7.7285e-01,  6.3934e-01,  6.0783e-01,  1.3621e-01,  9.1789e-02],\n",
      "          [ 4.5115e-01,  2.6636e-01,  2.8873e-01,  5.4186e-02, -5.0125e-04],\n",
      "          [ 4.7261e-01,  1.9145e-01,  2.9513e-01,  2.6322e-02, -7.9360e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7356e-01, -1.8016e-01, -8.4100e-02,  2.5638e-01,  4.1815e-01],\n",
      "          [-3.8253e-01, -2.1530e-01, -3.5103e-01,  2.0092e-01,  5.5576e-01],\n",
      "          [-2.2066e-01, -1.2535e-01, -3.7173e-01,  2.5866e-01,  7.8338e-01],\n",
      "          [-6.9192e-02, -2.9275e-02, -2.6378e-01, -1.3469e-01,  6.1908e-01],\n",
      "          [-2.8635e-01, -7.7823e-02, -1.6033e-01, -1.3314e-01,  5.1191e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.3522e-02, -1.6306e-01,  9.5519e-02,  2.1771e-01,  2.6272e-01],\n",
      "          [ 1.4003e-01, -1.0687e-01, -7.1044e-03, -2.6723e-01,  3.0294e-02],\n",
      "          [ 6.9347e-01,  2.5288e-01,  6.7049e-01, -2.5103e-02,  4.1759e-01],\n",
      "          [ 6.4033e-01,  5.5304e-01,  5.6944e-01,  1.5010e-01,  4.5427e-01],\n",
      "          [-7.0556e-03, -4.0587e-02,  6.0253e-02, -1.8900e-01,  1.7920e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7838e-01, -5.2982e-01, -4.5030e-01, -4.2715e-01, -4.6942e-01],\n",
      "          [-2.9788e-01, -5.1051e-02,  1.0748e-01, -2.1638e-01, -2.5701e-02],\n",
      "          [-4.7747e-02,  1.9401e-01,  9.5416e-01,  3.8902e-01, -5.1311e-02],\n",
      "          [ 2.5411e-01, -7.2726e-02,  9.8782e-02, -8.5876e-02, -2.8409e-01],\n",
      "          [ 2.0396e-01,  8.9917e-02,  2.2541e-01,  2.9225e-01,  2.8943e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.3393e-01, -5.8956e-01, -3.8429e-01, -8.0275e-02, -1.4144e-01],\n",
      "          [-3.3766e-01, -5.3765e-01, -5.5736e-01,  2.6775e-01, -2.5346e-02],\n",
      "          [-2.5656e-01, -2.9624e-01, -1.2479e-01, -1.9773e-02, -1.6707e-01],\n",
      "          [ 5.1516e-02, -2.5769e-01, -5.3584e-02,  2.2187e-01,  6.6660e-01],\n",
      "          [-1.9846e-01, -2.2821e-01,  2.0040e-02,  2.3608e-01,  5.5242e-01]]]],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([2.0369, 1.8549, 2.4484,  ..., 1.5295, 0.9663, 0.9570], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.7927, -0.9090, -1.6651,  ..., -0.7405, -2.7392, -1.6912],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2818]],\n",
      "\n",
      "         [[ 0.9262]],\n",
      "\n",
      "         [[ 0.2362]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4115]],\n",
      "\n",
      "         [[-0.1163]],\n",
      "\n",
      "         [[ 0.2073]]],\n",
      "\n",
      "\n",
      "        [[[-0.1057]],\n",
      "\n",
      "         [[-0.0349]],\n",
      "\n",
      "         [[-0.2489]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0045]],\n",
      "\n",
      "         [[ 0.2052]],\n",
      "\n",
      "         [[ 0.3712]]],\n",
      "\n",
      "\n",
      "        [[[-0.1904]],\n",
      "\n",
      "         [[-0.0177]],\n",
      "\n",
      "         [[-0.2710]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1149]],\n",
      "\n",
      "         [[ 0.1294]],\n",
      "\n",
      "         [[ 0.1575]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0817]],\n",
      "\n",
      "         [[ 0.7411]],\n",
      "\n",
      "         [[-0.3329]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5650]],\n",
      "\n",
      "         [[-0.1451]],\n",
      "\n",
      "         [[-0.0072]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0763]],\n",
      "\n",
      "         [[-0.1542]],\n",
      "\n",
      "         [[-0.0964]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3635]],\n",
      "\n",
      "         [[ 0.2649]],\n",
      "\n",
      "         [[ 0.3353]]],\n",
      "\n",
      "\n",
      "        [[[-0.3011]],\n",
      "\n",
      "         [[-0.0523]],\n",
      "\n",
      "         [[-0.1634]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1433]],\n",
      "\n",
      "         [[ 0.1209]],\n",
      "\n",
      "         [[ 0.1558]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1766, -0.1976, -0.1636,  0.1494,  0.2933, -0.0839,  0.1070,  0.0055,\n",
      "         0.0267, -0.3484, -0.0959,  0.3503,  0.1190,  0.1836,  0.1578, -0.0994,\n",
      "         0.0501, -0.2807, -0.1942, -0.0451,  0.0294,  0.3897, -0.1793, -0.0086,\n",
      "        -0.1323,  0.2883,  0.2320,  0.0507,  0.1516,  0.1118,  0.3692,  0.1323,\n",
      "         0.2321,  0.2525,  0.2452,  0.1438,  0.0493, -0.2065,  0.2521,  0.1955,\n",
      "        -0.0867,  0.0905,  0.0504, -0.0904,  0.2322, -0.0496,  0.0442, -0.2341,\n",
      "         0.0617, -0.1415, -0.1981,  0.1498, -0.0332,  0.1595,  0.2107,  0.1537,\n",
      "        -0.2380, -0.1400], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0328]],\n",
      "\n",
      "         [[-0.1633]],\n",
      "\n",
      "         [[ 0.1400]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0438]],\n",
      "\n",
      "         [[ 0.0973]],\n",
      "\n",
      "         [[-0.0974]]],\n",
      "\n",
      "\n",
      "        [[[-0.0981]],\n",
      "\n",
      "         [[-0.0121]],\n",
      "\n",
      "         [[-0.1861]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0580]],\n",
      "\n",
      "         [[ 0.0869]],\n",
      "\n",
      "         [[-0.0711]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1203]],\n",
      "\n",
      "         [[ 0.0716]],\n",
      "\n",
      "         [[-0.0451]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0559]],\n",
      "\n",
      "         [[-0.0108]],\n",
      "\n",
      "         [[-0.0794]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1108]],\n",
      "\n",
      "         [[ 0.1144]],\n",
      "\n",
      "         [[-0.2357]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4411]],\n",
      "\n",
      "         [[-0.3397]],\n",
      "\n",
      "         [[-0.0310]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0976]],\n",
      "\n",
      "         [[ 0.1529]],\n",
      "\n",
      "         [[-0.0010]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1278]],\n",
      "\n",
      "         [[-0.1242]],\n",
      "\n",
      "         [[-0.0728]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0300]],\n",
      "\n",
      "         [[ 0.2188]],\n",
      "\n",
      "         [[-0.0123]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1666]],\n",
      "\n",
      "         [[-0.0563]],\n",
      "\n",
      "         [[-0.1903]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.2105, -0.0964,  0.2008,  ..., -0.2793,  0.1773,  0.2455],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1256]],\n",
      "\n",
      "         [[ 0.0115]],\n",
      "\n",
      "         [[-0.6094]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0600]],\n",
      "\n",
      "         [[-0.1339]],\n",
      "\n",
      "         [[ 0.0295]]],\n",
      "\n",
      "\n",
      "        [[[-0.1944]],\n",
      "\n",
      "         [[ 0.0788]],\n",
      "\n",
      "         [[ 0.3251]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0392]],\n",
      "\n",
      "         [[ 0.8211]],\n",
      "\n",
      "         [[-0.3280]]],\n",
      "\n",
      "\n",
      "        [[[-0.2363]],\n",
      "\n",
      "         [[-0.0150]],\n",
      "\n",
      "         [[ 0.4325]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2408]],\n",
      "\n",
      "         [[-0.0262]],\n",
      "\n",
      "         [[ 0.3041]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1089]],\n",
      "\n",
      "         [[-0.0586]],\n",
      "\n",
      "         [[-0.2448]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0734]],\n",
      "\n",
      "         [[ 0.0192]],\n",
      "\n",
      "         [[ 0.2768]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1669]],\n",
      "\n",
      "         [[ 0.0100]],\n",
      "\n",
      "         [[ 0.5699]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0556]],\n",
      "\n",
      "         [[-0.3287]],\n",
      "\n",
      "         [[-0.1670]]],\n",
      "\n",
      "\n",
      "        [[[-0.3109]],\n",
      "\n",
      "         [[-0.0148]],\n",
      "\n",
      "         [[-0.4052]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0267]],\n",
      "\n",
      "         [[-0.2259]],\n",
      "\n",
      "         [[-0.0603]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.5870, 0.1848, 1.1721, 0.6856, 0.7266, 1.1185, 0.3294, 0.6953, 0.2853,\n",
      "        1.0726, 0.7391, 0.7657, 0.0855, 0.5091, 0.2670, 1.3948, 1.7848, 1.1893,\n",
      "        0.6584, 0.9503, 0.6400, 0.3766, 0.5894, 0.8000, 0.3825, 0.6851, 0.7745,\n",
      "        1.9107, 0.2193, 0.8573, 0.2149, 0.2044, 0.4956, 0.7552, 0.9204, 0.6559,\n",
      "        1.0840, 0.8510, 0.4781, 0.5041, 1.8547, 0.1023, 1.2326, 0.1187, 0.1907,\n",
      "        0.8729, 0.9904, 1.2539, 0.9203, 0.3013, 0.7767, 1.3611, 0.6667, 0.3720,\n",
      "        1.0833, 0.8518, 0.5982, 0.2653, 2.2931, 1.1498, 1.1088, 1.2651, 1.1117,\n",
      "        1.0095, 0.7279, 0.9654, 0.8079, 0.5672, 0.4713, 1.0171, 0.8931, 0.5873,\n",
      "        0.0457, 0.8111, 0.8816, 0.9963, 0.5161, 0.6129, 0.6988, 0.7411, 1.2322,\n",
      "        1.0741, 0.1825, 0.9036, 0.6834, 1.3213, 0.4401, 0.5376, 0.6657, 0.4347,\n",
      "        1.1956, 0.8514, 0.6025, 0.2662, 0.4893, 1.3096, 1.0725, 1.4526, 0.7675,\n",
      "        0.5611, 0.9293, 0.9043, 0.6388, 0.6952, 0.6259, 1.7021, 0.7684, 0.5501,\n",
      "        0.7254, 0.5830, 0.4988, 0.8628, 0.6808, 1.2761, 1.8378, 0.5539, 1.5283,\n",
      "        0.6442, 0.5688, 0.7390, 0.8327, 0.6265, 0.4144, 1.0509, 1.7281, 0.8798,\n",
      "        0.5581, 0.2235, 0.8260, 0.7517, 0.3710, 1.0464, 0.5831, 0.5422, 0.1228,\n",
      "        1.5028, 1.0189, 1.3384, 0.7882, 0.9199, 1.0780, 0.5721, 0.5453, 0.3809,\n",
      "        0.5029, 0.2750, 1.0355, 0.9556, 1.0367, 0.5762, 0.7169, 0.2106, 0.3234,\n",
      "        0.1150, 1.4405, 0.6132, 0.9368, 0.8348, 0.1944, 1.2353, 0.5151, 0.0827,\n",
      "        0.4845, 0.5592, 0.3145, 3.9398, 0.6015, 2.5782, 2.0034, 0.0524, 0.9572,\n",
      "        1.1657, 0.6369, 0.5248, 0.4328, 0.8121, 0.6413, 2.0070, 0.6916, 0.5906,\n",
      "        1.2343, 0.2447, 0.5952, 1.0001, 0.9602, 1.6279, 2.8029, 0.1757, 0.9309,\n",
      "        0.3804, 1.0508, 0.5404, 1.0883, 1.1117, 1.0049, 1.8060, 0.6582, 0.8265,\n",
      "        0.7689, 1.4110, 0.5605, 0.9612, 0.6968, 0.3148, 0.7755, 0.1439, 1.3399,\n",
      "        0.9938, 0.6333, 1.0432, 0.3213, 1.9624, 0.3041, 0.9820, 0.2725, 0.5190,\n",
      "        0.9944, 0.5471, 0.8544, 0.4871, 0.3422, 1.2719, 2.8417, 0.6301, 1.8603,\n",
      "        1.0287, 0.9416, 1.1221, 2.7578, 0.9116, 0.9201, 2.5037],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 3.4024e-01, -3.6130e-01, -2.4306e-02, -1.0104e-01,  4.0233e-01,\n",
      "         6.0631e-01,  8.5653e-02, -2.8121e-01, -9.1220e-02,  6.6490e-01,\n",
      "        -1.7421e-01,  1.2958e-01,  3.5116e-01, -4.2012e-01,  5.9768e-02,\n",
      "         6.1907e-01, -3.8577e-01, -1.8913e-01, -9.6804e-02, -2.0950e-01,\n",
      "        -7.2282e-01, -1.3517e-02, -5.3442e-03, -4.7066e-01,  2.6621e-01,\n",
      "        -4.7430e-02, -2.2592e-01,  1.8955e-01, -3.5876e-02, -4.2147e-02,\n",
      "         3.0907e-01,  5.2601e-01,  4.5406e-02,  7.6839e-02, -1.8663e-01,\n",
      "        -5.6112e-02,  4.1950e-01,  5.3845e-02,  1.1444e-01,  1.3312e-01,\n",
      "        -1.9055e-01, -4.8406e-01, -6.6262e-01, -4.5667e-02, -3.4665e-01,\n",
      "         4.0948e-01, -1.2937e-01, -6.8644e-01,  1.1090e-01, -7.7033e-02,\n",
      "         6.2904e-02,  1.4216e-01, -1.1451e-01,  3.7506e-02, -5.9640e-01,\n",
      "         4.0341e-02,  1.0597e-01, -1.6863e-01,  8.8157e-01, -4.0391e-01,\n",
      "         2.4874e-01,  2.3510e-01, -8.6668e-02,  5.2594e-01, -2.2623e-01,\n",
      "         5.2272e-02,  1.5237e-01,  5.4333e-02, -3.0010e-01, -2.7436e-01,\n",
      "         1.5390e-01,  4.1628e-01,  4.0069e-01, -2.8328e-01,  3.0823e-01,\n",
      "        -6.6948e-01,  3.5083e-01,  2.4864e-01,  6.8129e-02,  1.6472e-02,\n",
      "         4.0042e-02,  5.8101e-03,  2.0359e-01,  5.1757e-01,  3.9598e-01,\n",
      "        -5.6983e-01, -1.0896e-01,  2.9170e-01,  2.0193e-02, -1.4131e-01,\n",
      "        -3.5851e-02, -1.0234e-01, -2.2271e-01,  9.5762e-02, -2.2469e-01,\n",
      "         7.7893e-03, -4.7286e-01,  4.1979e-01, -6.0206e-01, -5.6076e-01,\n",
      "        -2.3600e-01, -8.2552e-02,  2.5352e-01,  9.7915e-02, -2.2029e-01,\n",
      "         1.1888e+00, -4.2084e-01, -3.3479e-02, -1.3443e-01, -2.9896e-01,\n",
      "        -2.0379e-01, -1.9512e-01,  7.0591e-02, -8.2587e-01, -1.0993e+00,\n",
      "        -8.7528e-02,  5.5704e-01, -5.7147e-02, -3.1472e-01, -4.6391e-02,\n",
      "        -9.4194e-02,  1.3137e-01, -5.5403e-01, -1.5447e-03, -8.0858e-02,\n",
      "        -5.9488e-01,  3.7220e-01, -1.6987e-01,  2.2726e-01, -3.3378e-01,\n",
      "        -2.3688e-01,  3.5838e-01, -1.0422e-01,  3.6020e-02, -4.5614e-01,\n",
      "        -2.6401e-01,  9.7085e-02,  1.9464e-01,  5.8928e-01,  3.9626e-01,\n",
      "         6.7198e-02,  7.1411e-02, -2.1684e-01,  6.9722e-02,  5.5971e-01,\n",
      "        -3.6153e-01,  5.1497e-01, -2.4173e-01,  2.5839e-01,  8.4829e-02,\n",
      "        -2.9061e-01,  3.3596e-01,  3.2514e-01,  7.6895e-02, -1.5151e-01,\n",
      "        -7.0781e-02, -5.3521e-01, -1.2372e-02,  7.2408e-01,  5.6541e-02,\n",
      "        -2.6122e-01, -5.0752e-02,  1.3393e-01, -3.5261e-01,  3.7899e-01,\n",
      "         1.1676e+00,  3.2022e-01, -5.0423e-02,  9.0479e-01, -3.5816e-01,\n",
      "        -9.9825e-01,  5.3150e-01, -1.8601e-02, -2.7046e-02, -3.9479e-01,\n",
      "         4.6811e-01, -2.0365e-01, -1.1904e+00, -1.1265e-01,  2.3979e-01,\n",
      "         2.7148e-01,  1.0452e-01,  4.1525e-01, -1.4779e-01, -3.5695e-01,\n",
      "         8.0093e-01,  7.7447e-01,  9.0360e-02, -4.7547e-01, -1.5437e-01,\n",
      "         5.8798e-02, -7.8670e-02, -5.6362e-01,  9.6522e-01,  9.1282e-02,\n",
      "         4.7038e-01,  1.1297e-01,  1.2876e-01,  3.9991e-01,  5.7930e-01,\n",
      "        -2.2129e-01,  3.4993e-01,  1.7350e-01, -2.2728e-01, -4.5242e-02,\n",
      "        -5.7855e-02,  2.1881e-01, -1.7562e-01,  1.5837e-01, -6.4026e-01,\n",
      "         4.9849e-02, -6.1797e-01,  9.3950e-04, -1.6132e-01,  2.0219e-01,\n",
      "        -3.4428e-01, -2.9256e-02, -4.7965e-02,  9.8806e-02,  4.9022e-01,\n",
      "         7.6626e-02,  3.1888e-01,  1.6308e+00,  2.1338e-01,  1.2488e+00,\n",
      "        -1.6440e-01,  7.1854e-02, -1.8437e-01, -9.0172e-01, -8.6596e-01,\n",
      "        -6.0329e-02,  2.2310e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.5648]],\n",
      "\n",
      "         [[-0.1260]],\n",
      "\n",
      "         [[ 0.0707]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6064]],\n",
      "\n",
      "         [[ 0.2002]],\n",
      "\n",
      "         [[ 0.0677]]],\n",
      "\n",
      "\n",
      "        [[[-0.0178]],\n",
      "\n",
      "         [[-0.6157]],\n",
      "\n",
      "         [[-0.4014]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4638]],\n",
      "\n",
      "         [[-0.2942]],\n",
      "\n",
      "         [[-0.0208]]],\n",
      "\n",
      "\n",
      "        [[[-0.0140]],\n",
      "\n",
      "         [[ 0.3247]],\n",
      "\n",
      "         [[-0.3915]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1521]],\n",
      "\n",
      "         [[ 0.2977]],\n",
      "\n",
      "         [[ 0.0231]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1566]],\n",
      "\n",
      "         [[-0.2262]],\n",
      "\n",
      "         [[-0.1908]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0128]],\n",
      "\n",
      "         [[-0.3612]],\n",
      "\n",
      "         [[ 0.1596]]],\n",
      "\n",
      "\n",
      "        [[[-0.5300]],\n",
      "\n",
      "         [[-0.1505]],\n",
      "\n",
      "         [[ 0.0881]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6121]],\n",
      "\n",
      "         [[-0.0475]],\n",
      "\n",
      "         [[-0.4998]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2001]],\n",
      "\n",
      "         [[-0.2984]],\n",
      "\n",
      "         [[ 0.3088]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3066]],\n",
      "\n",
      "         [[ 0.5695]],\n",
      "\n",
      "         [[ 0.2861]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.8085, 0.8203, 0.3986,  ..., 1.0089, 0.5686, 1.0752], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.3182e+00, -1.7093e+00,  5.9781e-04,  ..., -3.2507e-01,\n",
      "         1.2154e-01, -1.3745e+00], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1804, -0.1273, -0.1014, -0.1189, -0.1157],\n",
      "          [ 0.1292,  0.2560,  0.3231,  0.3749,  0.3110],\n",
      "          [ 0.1799,  0.5290,  0.4495,  0.6116,  0.4022],\n",
      "          [ 0.1767,  0.4368,  0.3150,  0.3891,  0.2329],\n",
      "          [-0.1553, -0.0655,  0.0119,  0.0281,  0.0644]]],\n",
      "\n",
      "\n",
      "        [[[-0.1548, -0.2051, -0.2719, -0.2677, -0.2218],\n",
      "          [-0.4198, -0.3271,  0.0138, -0.2526, -0.2873],\n",
      "          [-0.4821, -0.5236, -0.4530, -0.6041, -0.6436],\n",
      "          [ 0.0369,  0.1876,  0.3621,  0.2605,  0.0734],\n",
      "          [-0.0291,  0.0461,  0.2006,  0.2357,  0.3396]]],\n",
      "\n",
      "\n",
      "        [[[-0.2832, -0.4353, -0.4006, -0.1886, -0.3285],\n",
      "          [-0.1603, -0.0844, -0.2196, -0.1212, -0.3822],\n",
      "          [-0.2522, -0.3670, -0.4390, -0.3665, -0.4529],\n",
      "          [-0.3549, -0.2491, -0.4999, -0.5397, -0.6206],\n",
      "          [-0.2051, -0.0364, -0.1874, -0.1160, -0.3115]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0977,  0.6442,  0.7142,  0.3635,  0.1531],\n",
      "          [-0.2893,  0.0473,  0.6528,  0.2006,  0.4880],\n",
      "          [ 0.1764,  0.0200,  0.3613,  0.1912,  0.2233],\n",
      "          [-0.0955, -0.1683,  0.0752,  0.3799, -0.0782],\n",
      "          [-0.1540, -0.0823, -0.2955, -0.1760, -0.4148]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5260, -0.0990, -0.4752, -0.4286, -0.1571],\n",
      "          [ 0.3069, -0.3557, -0.2454, -0.4728, -0.1321],\n",
      "          [ 0.4714, -0.0283, -0.2186, -0.5832, -0.1986],\n",
      "          [ 0.5113,  0.1008, -0.0709, -0.2799, -0.1770],\n",
      "          [ 0.5230,  0.0576, -0.1396, -0.2467, -0.1192]]],\n",
      "\n",
      "\n",
      "        [[[-0.2425, -0.3608, -0.3433, -0.1932, -0.0279],\n",
      "          [-0.1960, -0.2468, -0.1428, -0.1794,  0.0128],\n",
      "          [ 0.1271, -0.1515,  0.1911,  0.1217,  0.2808],\n",
      "          [ 0.0407,  0.1503,  0.7876,  0.6603,  0.3417],\n",
      "          [ 0.3086,  0.2150,  0.4944,  0.1474,  0.1013]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([2.9755, 2.2993, 2.5873,  ..., 2.0800, 2.1857, 1.5934], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.2292, -0.7340, -1.4443,  ..., -1.1788, -1.7652, -1.8854],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1674]],\n",
      "\n",
      "         [[-0.2411]],\n",
      "\n",
      "         [[-0.2398]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0269]],\n",
      "\n",
      "         [[-0.2443]],\n",
      "\n",
      "         [[ 0.0971]]],\n",
      "\n",
      "\n",
      "        [[[-0.2779]],\n",
      "\n",
      "         [[ 0.0380]],\n",
      "\n",
      "         [[ 0.0189]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1108]],\n",
      "\n",
      "         [[ 0.0403]],\n",
      "\n",
      "         [[-0.1692]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0522]],\n",
      "\n",
      "         [[-0.2072]],\n",
      "\n",
      "         [[-0.0283]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2969]],\n",
      "\n",
      "         [[ 0.2284]],\n",
      "\n",
      "         [[-0.1107]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0430]],\n",
      "\n",
      "         [[-0.0106]],\n",
      "\n",
      "         [[-0.0296]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2036]],\n",
      "\n",
      "         [[ 0.3101]],\n",
      "\n",
      "         [[-0.2792]]],\n",
      "\n",
      "\n",
      "        [[[-0.3444]],\n",
      "\n",
      "         [[-0.2561]],\n",
      "\n",
      "         [[-0.1825]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4093]],\n",
      "\n",
      "         [[ 0.2006]],\n",
      "\n",
      "         [[-0.4624]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4398]],\n",
      "\n",
      "         [[ 0.1153]],\n",
      "\n",
      "         [[-0.0132]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4840]],\n",
      "\n",
      "         [[ 0.1939]],\n",
      "\n",
      "         [[ 0.1612]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.2213, -0.0919, -0.1878,  0.1602, -0.1627, -0.2163, -0.1242, -0.2249,\n",
      "        -0.0242, -0.1630,  0.2909, -0.2153,  0.2898, -0.0332,  0.2501, -0.1768,\n",
      "         0.2349,  0.4287, -0.1895,  0.0101, -0.3637, -0.0939, -0.1384,  0.2576,\n",
      "        -0.2533,  0.2134,  0.1345,  0.1890,  0.5633,  0.4102, -0.1306,  0.2270,\n",
      "         0.5416,  0.0402, -0.0887,  0.0626, -0.0815,  0.2626, -0.0563,  0.4673,\n",
      "         0.1445, -0.2512, -0.2078, -0.1181,  0.3225,  0.0258, -0.2165,  0.1811,\n",
      "         0.4020, -0.0329,  0.3472, -0.1817,  0.1900, -0.1608, -0.1077, -0.0075,\n",
      "        -0.0739,  0.1535], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0740]],\n",
      "\n",
      "         [[-0.0400]],\n",
      "\n",
      "         [[-0.1275]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1014]],\n",
      "\n",
      "         [[ 0.0269]],\n",
      "\n",
      "         [[-0.1192]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2732]],\n",
      "\n",
      "         [[-0.0401]],\n",
      "\n",
      "         [[-0.1199]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1827]],\n",
      "\n",
      "         [[-0.1612]],\n",
      "\n",
      "         [[-0.4128]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1091]],\n",
      "\n",
      "         [[ 0.0122]],\n",
      "\n",
      "         [[ 0.0479]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0476]],\n",
      "\n",
      "         [[ 0.0214]],\n",
      "\n",
      "         [[ 0.1137]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0820]],\n",
      "\n",
      "         [[ 0.0927]],\n",
      "\n",
      "         [[ 0.0503]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0865]],\n",
      "\n",
      "         [[ 0.0125]],\n",
      "\n",
      "         [[ 0.1532]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0595]],\n",
      "\n",
      "         [[ 0.0145]],\n",
      "\n",
      "         [[ 0.0291]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1358]],\n",
      "\n",
      "         [[-0.0165]],\n",
      "\n",
      "         [[ 0.0896]]],\n",
      "\n",
      "\n",
      "        [[[-0.1802]],\n",
      "\n",
      "         [[-0.1350]],\n",
      "\n",
      "         [[-0.0951]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0905]],\n",
      "\n",
      "         [[ 0.0849]],\n",
      "\n",
      "         [[-0.1371]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0810, -0.0063,  0.1512,  ...,  0.0898,  0.1261, -0.1081],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0948]],\n",
      "\n",
      "         [[-0.2696]],\n",
      "\n",
      "         [[-0.2590]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4923]],\n",
      "\n",
      "         [[ 0.0450]],\n",
      "\n",
      "         [[-0.1247]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0157]],\n",
      "\n",
      "         [[-0.4350]],\n",
      "\n",
      "         [[ 0.2692]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0989]],\n",
      "\n",
      "         [[-0.6086]],\n",
      "\n",
      "         [[ 0.0102]]],\n",
      "\n",
      "\n",
      "        [[[-0.0096]],\n",
      "\n",
      "         [[-0.2503]],\n",
      "\n",
      "         [[-0.6559]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4200]],\n",
      "\n",
      "         [[ 0.6403]],\n",
      "\n",
      "         [[ 0.0473]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0827]],\n",
      "\n",
      "         [[-0.2719]],\n",
      "\n",
      "         [[-0.4618]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5745]],\n",
      "\n",
      "         [[-0.2627]],\n",
      "\n",
      "         [[ 0.1224]]],\n",
      "\n",
      "\n",
      "        [[[-0.0660]],\n",
      "\n",
      "         [[-0.1724]],\n",
      "\n",
      "         [[-0.0816]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0111]],\n",
      "\n",
      "         [[ 0.5828]],\n",
      "\n",
      "         [[ 0.0364]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0457]],\n",
      "\n",
      "         [[-0.3571]],\n",
      "\n",
      "         [[-0.6343]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4214]],\n",
      "\n",
      "         [[ 0.1455]],\n",
      "\n",
      "         [[-0.0091]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.5360, 0.2277, 1.3850, 0.9681, 0.2353, 1.4467, 0.0867, 0.8560, 0.2282,\n",
      "        0.8279, 1.2082, 0.9809, 0.1421, 0.7546, 0.4276, 1.3952, 1.1369, 1.1502,\n",
      "        0.7135, 0.9761, 1.0273, 0.8408, 0.3336, 1.1321, 0.3505, 0.9658, 0.9360,\n",
      "        2.0938, 0.5525, 1.2469, 0.4670, 0.4680, 0.9080, 0.7638, 0.7574, 0.5426,\n",
      "        0.9259, 0.6795, 0.2394, 0.7357, 1.8693, 0.1598, 1.4601, 0.0602, 0.5459,\n",
      "        0.5675, 0.8339, 0.9852, 0.7183, 0.4182, 0.7503, 1.2534, 0.4774, 0.6242,\n",
      "        0.9215, 0.8720, 0.8081, 0.3565, 2.0860, 1.2648, 0.6970, 1.2193, 0.7538,\n",
      "        0.6899, 1.0098, 0.5152, 0.6927, 0.3566, 0.6539, 1.3330, 0.5252, 0.8168,\n",
      "        0.0044, 0.6456, 0.6837, 0.8220, 0.3631, 0.9577, 0.6322, 0.5001, 1.1618,\n",
      "        0.8113, 0.3384, 0.6962, 0.7978, 0.9657, 0.4491, 0.3021, 0.2844, 0.4783,\n",
      "        1.1542, 0.4583, 0.6173, 0.2454, 0.0208, 0.9545, 0.9665, 0.6126, 0.6171,\n",
      "        0.5403, 1.0254, 0.6994, 0.6391, 0.7646, 1.0191, 1.7811, 0.3980, 0.8953,\n",
      "        0.5983, 1.3801, 0.4761, 1.3050, 0.6062, 1.6928, 1.9670, 0.1637, 1.7718,\n",
      "        0.5715, 0.6897, 0.7249, 0.7767, 0.3754, 0.7355, 0.3650, 1.4895, 1.2167,\n",
      "        0.7757, 0.6120, 0.3625, 1.1412, 0.4022, 1.2638, 0.6773, 0.6021, 0.5728,\n",
      "        1.5028, 1.2439, 1.3131, 0.8734, 0.4831, 1.2826, 0.3022, 0.4219, 0.6345,\n",
      "        0.9025, 0.2690, 1.0357, 0.5948, 0.9733, 0.5147, 0.7074, 0.3103, 0.1685,\n",
      "        0.3770, 1.0108, 0.6188, 0.9348, 0.7647, 0.2431, 0.9349, 0.5091, 0.9784,\n",
      "        0.3989, 0.3012, 0.6284, 3.4618, 0.6055, 1.9475, 1.8153, 0.3972, 1.2340,\n",
      "        1.4077, 0.8651, 0.9002, 0.1870, 0.9727, 0.5401, 2.3933, 0.0725, 0.6727,\n",
      "        0.8361, 0.3935, 0.5678, 0.7264, 1.5478, 1.7611, 2.6793, 0.1381, 0.7721,\n",
      "        0.4974, 1.3076, 0.6899, 1.1098, 1.2053, 1.1379, 1.8790, 0.1440, 0.7351,\n",
      "        0.6647, 1.6154, 0.8633, 1.0260, 0.6455, 0.4183, 0.9694, 0.2183, 1.7832,\n",
      "        0.8754, 0.7603, 1.5452, 0.1679, 1.8007, 0.6507, 0.7075, 0.6649, 0.6817,\n",
      "        1.2923, 0.7531, 0.9319, 0.6388, 0.3743, 1.2136, 2.6118, 0.6731, 1.6231,\n",
      "        0.4588, 1.2712, 1.3956, 2.0651, 1.4846, 0.5701, 2.4256],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 4.9681e-01, -3.6292e-01,  1.6308e-01, -1.5386e-01,  1.5681e-01,\n",
      "         2.1134e-01,  1.2856e-02, -3.9779e-01, -9.6039e-02,  8.3578e-01,\n",
      "        -2.1787e-01,  1.2920e-01,  2.8228e-01,  6.0587e-02, -4.7246e-03,\n",
      "         1.4448e-01, -2.0670e-01, -4.5854e-01, -8.0970e-02, -1.0341e-01,\n",
      "        -6.4247e-01,  2.5850e-01,  1.3597e-01, -3.5279e-01,  2.3880e-01,\n",
      "         1.7131e-01, -1.0568e-01,  1.6535e-01,  7.8717e-02,  5.0775e-02,\n",
      "         3.9838e-01,  5.3969e-01,  2.7341e-01,  9.1305e-02, -3.2791e-01,\n",
      "        -1.5663e-01,  4.1470e-01, -2.0432e-01,  2.0179e-01,  1.4380e-01,\n",
      "        -1.9509e-01, -5.2792e-01, -1.8897e-01, -1.4212e-01, -4.0700e-01,\n",
      "         2.9606e-01, -3.5373e-01, -6.6192e-01, -8.4182e-03,  6.7144e-02,\n",
      "         1.2283e-01,  1.3538e-02, -1.7535e-02, -9.4068e-02, -4.2745e-01,\n",
      "         2.4483e-01,  1.8624e-01, -1.3321e-01,  7.7633e-01,  1.1004e-01,\n",
      "         1.1908e-01, -2.1934e-02, -1.0249e-01,  1.4382e-01, -1.9650e-01,\n",
      "        -1.5142e-01,  1.2089e-02,  6.3550e-02, -1.7434e-01,  6.8223e-02,\n",
      "         2.7764e-01,  5.4301e-02,  1.8850e-01, -2.0743e-01,  3.3570e-01,\n",
      "        -4.0539e-01,  3.8370e-01,  4.4283e-01,  7.0918e-02,  1.6210e-01,\n",
      "        -3.3051e-01,  8.6801e-03,  2.1249e-01,  5.6234e-01,  4.2111e-01,\n",
      "        -4.5453e-01, -1.5344e-01,  3.2018e-01, -6.5576e-02, -4.6469e-02,\n",
      "         2.4434e-01, -1.1485e-02, -1.2045e-01,  5.4539e-03, -1.7928e-01,\n",
      "         1.7695e-01, -6.2013e-01,  6.5643e-01, -3.6678e-01, -6.6339e-01,\n",
      "         1.8627e-01, -2.1523e-01, -1.9550e-01,  1.9454e-01, -2.0814e-01,\n",
      "         1.1654e+00, -1.7154e-01, -9.5862e-02, -1.6389e-01, -8.3690e-02,\n",
      "        -2.1458e-01, -3.4823e-01,  2.5904e-01, -4.4424e-01, -1.0365e+00,\n",
      "        -2.1861e-01,  3.8384e-01,  7.9233e-02, -2.6770e-01, -3.2929e-01,\n",
      "        -9.2679e-02, -5.6468e-02, -2.3403e-01, -6.7842e-04, -9.0608e-02,\n",
      "        -1.4584e-01,  3.5396e-01, -3.5090e-02, -1.1899e-01, -3.5802e-01,\n",
      "        -3.2497e-02,  2.4436e-01, -1.7256e-01,  1.1889e-01, -2.7715e-01,\n",
      "        -1.3197e-01,  1.2146e-01, -2.0323e-02,  2.0492e-01,  4.0931e-01,\n",
      "         2.5121e-02,  2.7227e-01, -1.4993e-01,  9.5557e-02,  6.1999e-01,\n",
      "         1.4914e-02,  4.6987e-01, -2.9876e-01,  3.4734e-01,  2.4955e-01,\n",
      "        -1.9949e-01,  2.1417e-01,  2.6562e-01, -4.9576e-02,  6.2329e-02,\n",
      "         2.9836e-02, -3.3087e-01,  1.2886e-01,  8.4781e-01,  3.5814e-02,\n",
      "        -2.2502e-01, -5.5812e-02,  3.2733e-02, -3.5925e-01,  5.2503e-01,\n",
      "         5.6365e-01, -1.7028e-01,  1.1922e-01,  6.2513e-01, -3.4964e-01,\n",
      "        -6.6078e-01,  5.1953e-01, -1.3745e-01, -1.9355e-03, -6.3019e-01,\n",
      "         3.2858e-01, -2.6807e-01, -8.9443e-01, -6.8202e-02,  1.0786e-01,\n",
      "         2.3093e-01, -1.6852e-01,  1.4495e-01, -1.7317e-01, -4.2288e-01,\n",
      "         5.0999e-01,  9.3413e-01,  2.2221e-02, -5.7008e-01,  1.1736e-01,\n",
      "         2.0807e-01, -2.2392e-01, -4.6353e-01,  6.5363e-01,  1.7513e-01,\n",
      "         6.5850e-02,  2.9512e-01,  2.0291e-02,  1.3313e-01,  8.3095e-01,\n",
      "        -1.1334e-01,  1.5996e-01, -4.2807e-02,  1.6231e-02, -1.0566e-01,\n",
      "        -2.9235e-02,  2.0145e-01, -3.4547e-03,  2.7440e-01, -4.4982e-01,\n",
      "        -8.2164e-02, -1.1728e-01,  7.9651e-02,  1.9058e-01, -5.6228e-03,\n",
      "        -2.3776e-01,  1.0567e-01, -3.2868e-03, -1.6959e-03,  2.3473e-01,\n",
      "         8.6821e-02,  2.8981e-01,  1.4060e+00,  3.1327e-01,  1.0109e+00,\n",
      "        -4.3751e-02,  4.8291e-02, -2.4375e-01, -4.6496e-01, -7.7223e-01,\n",
      "        -1.5399e-01,  3.0177e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.2535]],\n",
      "\n",
      "         [[ 0.5051]],\n",
      "\n",
      "         [[ 0.2048]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4827]],\n",
      "\n",
      "         [[-0.1153]],\n",
      "\n",
      "         [[-0.5695]]],\n",
      "\n",
      "\n",
      "        [[[-0.0311]],\n",
      "\n",
      "         [[-0.0087]],\n",
      "\n",
      "         [[ 0.0896]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2443]],\n",
      "\n",
      "         [[ 0.1386]],\n",
      "\n",
      "         [[-0.0343]]],\n",
      "\n",
      "\n",
      "        [[[-0.0294]],\n",
      "\n",
      "         [[-0.0865]],\n",
      "\n",
      "         [[-0.4443]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0618]],\n",
      "\n",
      "         [[-0.0589]],\n",
      "\n",
      "         [[-0.1107]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1752]],\n",
      "\n",
      "         [[-0.2182]],\n",
      "\n",
      "         [[ 0.1843]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3982]],\n",
      "\n",
      "         [[-0.2534]],\n",
      "\n",
      "         [[ 0.1795]]],\n",
      "\n",
      "\n",
      "        [[[-0.0370]],\n",
      "\n",
      "         [[-0.3512]],\n",
      "\n",
      "         [[-0.2027]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4770]],\n",
      "\n",
      "         [[-0.1982]],\n",
      "\n",
      "         [[ 0.2848]]],\n",
      "\n",
      "\n",
      "        [[[-0.0347]],\n",
      "\n",
      "         [[ 0.4626]],\n",
      "\n",
      "         [[-0.5019]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2605]],\n",
      "\n",
      "         [[-0.4259]],\n",
      "\n",
      "         [[ 0.2285]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.4934, 1.1231, 0.6596,  ..., 1.5960, 0.7396, 1.3719], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.2577, -0.8375, -0.7234,  ..., -0.2454, -1.1120, -1.1698],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-3.9179e-01, -1.7980e-01, -5.1516e-02, -1.5172e-01, -4.6935e-01],\n",
      "          [-5.1622e-01, -2.4288e-01, -1.7029e-01, -2.9638e-01, -5.2492e-01],\n",
      "          [-3.6524e-01, -1.3375e-01,  1.0118e-01, -1.4210e-01, -5.6621e-01],\n",
      "          [-5.2275e-01, -4.8982e-01, -2.6395e-01, -3.8659e-01, -5.8918e-01],\n",
      "          [-5.6951e-02,  1.9262e-02,  5.2046e-02,  1.2872e-01,  2.2659e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5172e-01,  3.2885e-01, -1.3896e-01, -1.9157e-01, -2.5458e-01],\n",
      "          [ 5.6626e-01,  4.6242e-01,  4.8658e-01, -2.9544e-01, -4.2402e-01],\n",
      "          [-3.2174e-01, -1.5694e-01,  3.7466e-01,  1.6713e-01, -2.1794e-01],\n",
      "          [-2.5640e-01, -2.6703e-01, -1.0735e-02, -6.8600e-03, -1.3474e-02],\n",
      "          [-7.6625e-02,  7.8989e-02,  7.1282e-02, -5.0021e-02, -2.1220e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9522e-02, -8.5301e-03,  8.8403e-02,  1.5491e-01,  5.4970e-01],\n",
      "          [-9.2916e-03, -7.3603e-02,  7.8056e-02,  2.7843e-01,  7.1842e-01],\n",
      "          [ 2.7175e-01,  4.1723e-01,  3.6588e-01,  1.0844e-01,  5.4091e-01],\n",
      "          [ 3.3505e-01,  1.3296e-01,  3.6041e-01, -9.9182e-03,  1.7224e-01],\n",
      "          [-1.1980e-01,  9.4831e-01,  2.1005e-01, -3.7915e-02,  2.4008e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.2398e-02, -3.5052e-01,  3.6502e-01,  6.2502e-01,  3.4920e-01],\n",
      "          [ 3.0088e-01, -1.0381e-01,  2.7447e-01,  3.0425e-01, -4.3547e-01],\n",
      "          [ 2.6158e-01,  1.5244e-02,  6.7241e-02,  5.5268e-02, -7.9671e-01],\n",
      "          [-3.9803e-01, -3.3959e-01,  3.7322e-02,  2.5328e-01,  4.0145e-01],\n",
      "          [-5.2199e-01, -3.1317e-01,  7.7976e-02, -9.8660e-02,  4.5546e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5604e-01,  1.2939e-01,  3.2982e-01, -4.2751e-02, -2.5721e-01],\n",
      "          [-4.1497e-01, -6.3384e-02,  3.2551e-01,  4.5244e-01, -5.7440e-02],\n",
      "          [-8.0532e-02, -1.1890e-01, -1.9612e-01,  5.7542e-01,  5.9782e-01],\n",
      "          [-8.7043e-02, -7.1298e-02,  7.1213e-02,  6.0264e-01,  6.3977e-01],\n",
      "          [-1.8526e-02, -3.1374e-05,  3.4043e-02,  2.6288e-01,  6.9515e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1988e-01, -1.7498e-01, -1.5045e-01, -1.3343e-01, -1.4831e-01],\n",
      "          [ 9.4799e-02,  6.5607e-01,  7.9486e-01,  3.4261e-01, -6.1786e-03],\n",
      "          [-2.0911e-01,  4.5579e-01,  8.0566e-02, -1.2612e-02, -1.6853e-01],\n",
      "          [-9.1704e-02,  2.3372e-01,  3.8601e-01,  3.3191e-01,  3.2614e-01],\n",
      "          [-1.0520e-01, -1.5279e-01,  2.3831e-02,  2.4527e-01,  4.7729e-01]]]],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.6846, 1.4877, 0.9759,  ..., 0.7631, 1.0708, 2.0504], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.1512, -1.4714, -3.0001,  ..., -2.5162, -1.0191, -0.1637],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1240]],\n",
      "\n",
      "         [[-0.1572]],\n",
      "\n",
      "         [[ 0.0020]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0454]],\n",
      "\n",
      "         [[-0.4524]],\n",
      "\n",
      "         [[ 0.1706]]],\n",
      "\n",
      "\n",
      "        [[[-0.1438]],\n",
      "\n",
      "         [[ 0.0987]],\n",
      "\n",
      "         [[ 0.0921]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2504]],\n",
      "\n",
      "         [[ 0.1110]],\n",
      "\n",
      "         [[-0.1282]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2461]],\n",
      "\n",
      "         [[ 0.0143]],\n",
      "\n",
      "         [[ 0.0589]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0454]],\n",
      "\n",
      "         [[ 0.2280]],\n",
      "\n",
      "         [[-0.3677]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2313]],\n",
      "\n",
      "         [[ 0.2265]],\n",
      "\n",
      "         [[ 0.3284]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0893]],\n",
      "\n",
      "         [[-0.0485]],\n",
      "\n",
      "         [[ 0.2987]]],\n",
      "\n",
      "\n",
      "        [[[-0.1470]],\n",
      "\n",
      "         [[ 0.3581]],\n",
      "\n",
      "         [[ 0.2669]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1545]],\n",
      "\n",
      "         [[ 0.1701]],\n",
      "\n",
      "         [[-0.2496]]],\n",
      "\n",
      "\n",
      "        [[[-0.1052]],\n",
      "\n",
      "         [[ 0.2650]],\n",
      "\n",
      "         [[ 0.1127]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0954]],\n",
      "\n",
      "         [[ 0.0638]],\n",
      "\n",
      "         [[-0.1593]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.1323, -0.2884,  0.1573, -0.0771, -0.0351, -0.2063, -0.1626, -0.1854,\n",
      "        -0.1990, -0.0810,  0.2394,  0.0035,  0.0414,  0.3540, -0.1469, -0.0443,\n",
      "        -0.1897,  0.3168,  0.1731,  0.0279, -0.1514,  0.4329,  0.3540, -0.1871,\n",
      "        -0.2237, -0.1055, -0.1182,  0.1067,  0.1065, -0.3200, -0.1654,  0.5825,\n",
      "        -0.2062,  0.1690,  0.0359,  0.0530,  0.4933, -0.1099, -0.1669,  0.0139,\n",
      "         0.5952,  0.2541, -0.1159, -0.1812, -0.2163, -0.2585, -0.1527, -0.1604,\n",
      "        -0.0713, -0.1583, -0.3173,  0.1049,  0.1512, -0.1854, -0.0068, -0.1315,\n",
      "         0.0042, -0.1937], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0401]],\n",
      "\n",
      "         [[-0.0940]],\n",
      "\n",
      "         [[-0.1356]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0057]],\n",
      "\n",
      "         [[-0.1338]],\n",
      "\n",
      "         [[-0.0071]]],\n",
      "\n",
      "\n",
      "        [[[-0.0551]],\n",
      "\n",
      "         [[-0.0218]],\n",
      "\n",
      "         [[ 0.3134]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0627]],\n",
      "\n",
      "         [[ 0.0149]],\n",
      "\n",
      "         [[-0.1256]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1312]],\n",
      "\n",
      "         [[ 0.0526]],\n",
      "\n",
      "         [[ 0.2276]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0515]],\n",
      "\n",
      "         [[ 0.0343]],\n",
      "\n",
      "         [[ 0.1175]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0316]],\n",
      "\n",
      "         [[ 0.0028]],\n",
      "\n",
      "         [[ 0.1722]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0148]],\n",
      "\n",
      "         [[ 0.2144]],\n",
      "\n",
      "         [[ 0.0326]]],\n",
      "\n",
      "\n",
      "        [[[-0.0848]],\n",
      "\n",
      "         [[ 0.0471]],\n",
      "\n",
      "         [[-0.1072]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0358]],\n",
      "\n",
      "         [[-0.1398]],\n",
      "\n",
      "         [[-0.1424]]],\n",
      "\n",
      "\n",
      "        [[[-0.0156]],\n",
      "\n",
      "         [[ 0.0018]],\n",
      "\n",
      "         [[-0.2222]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0529]],\n",
      "\n",
      "         [[ 0.0729]],\n",
      "\n",
      "         [[ 0.0126]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1343,  0.2152,  0.1509,  ...,  0.1638, -0.1584, -0.1175],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0182]],\n",
      "\n",
      "         [[-0.0101]],\n",
      "\n",
      "         [[ 0.2993]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0347]],\n",
      "\n",
      "         [[-0.0710]],\n",
      "\n",
      "         [[-0.0189]]],\n",
      "\n",
      "\n",
      "        [[[-0.1063]],\n",
      "\n",
      "         [[ 0.5340]],\n",
      "\n",
      "         [[ 0.4779]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4455]],\n",
      "\n",
      "         [[ 0.1015]],\n",
      "\n",
      "         [[-0.0580]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0377]],\n",
      "\n",
      "         [[ 0.2990]],\n",
      "\n",
      "         [[-0.0463]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3104]],\n",
      "\n",
      "         [[ 0.0136]],\n",
      "\n",
      "         [[-0.0226]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0193]],\n",
      "\n",
      "         [[ 0.4825]],\n",
      "\n",
      "         [[-0.1612]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2856]],\n",
      "\n",
      "         [[-0.1705]],\n",
      "\n",
      "         [[-0.0383]]],\n",
      "\n",
      "\n",
      "        [[[-0.0271]],\n",
      "\n",
      "         [[ 0.4501]],\n",
      "\n",
      "         [[ 0.1462]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4569]],\n",
      "\n",
      "         [[-0.0670]],\n",
      "\n",
      "         [[ 0.0051]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0995]],\n",
      "\n",
      "         [[-0.0027]],\n",
      "\n",
      "         [[ 0.0213]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1654]],\n",
      "\n",
      "         [[-0.0742]],\n",
      "\n",
      "         [[-0.0137]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.5124,  0.3956,  1.3567,  0.7297,  0.2999,  1.1004,  0.1706,  0.8958,\n",
      "        -0.0042,  0.6585,  0.9649,  0.8996,  0.5246,  0.6124,  0.4143,  1.6504,\n",
      "         1.2741,  0.7517,  0.5395,  0.6495,  1.1590,  0.6910,  0.4999,  1.3897,\n",
      "         0.2830,  0.1337,  0.5896,  1.1651,  1.2551,  0.4558,  0.6241,  0.5882,\n",
      "         0.6072,  0.7384,  0.8003,  0.3974,  1.0829,  0.8265,  0.4940,  0.8081,\n",
      "         1.4205,  0.2635,  1.2288,  0.2024,  0.3171,  0.8935,  0.8963,  1.1958,\n",
      "         0.8410,  0.8768,  1.1070,  0.9288,  0.5862,  0.9092,  1.0403,  0.8606,\n",
      "         0.7172,  0.8317,  1.8964,  1.0102,  1.0019,  0.9792,  0.6869,  0.7847,\n",
      "         1.1784,  0.9011,  1.2837,  0.7719,  0.6838,  1.1913,  0.6703,  0.7177,\n",
      "        -0.0154,  0.6090,  0.8961,  0.5878,  0.4700,  0.6566,  0.5624,  0.8549,\n",
      "         0.7760,  0.8278,  0.0888,  0.9467,  0.7925,  1.0371,  0.5522,  0.7933,\n",
      "         0.7712,  0.3125,  0.9582,  0.7761,  0.4462,  0.1851,  0.2801,  0.3388,\n",
      "         0.8696,  0.9343,  0.6017,  0.4686,  1.3179,  0.8602,  1.1803,  0.9442,\n",
      "         0.8763,  1.4432,  0.3931,  0.6577,  0.6599,  1.2285,  0.9063,  0.8865,\n",
      "         0.5821,  1.0599,  1.6139,  0.3837,  0.8904,  0.7585,  0.5298,  0.5344,\n",
      "         1.0842,  0.6132,  1.0189,  0.3281,  1.6152,  1.2636,  0.7668,  0.7275,\n",
      "         0.5439,  0.9929,  0.5797,  1.3978,  0.7390,  0.3521,  0.8799,  1.2124,\n",
      "         1.2559,  1.2843,  0.6840,  0.6338,  1.0425,  0.5793,  0.5127,  0.4548,\n",
      "         0.6955,  0.7937,  1.0105,  0.9171,  1.0663,  0.5247,  0.7014,  0.4122,\n",
      "         0.2268,  0.3452,  1.4264,  0.6538,  0.9081,  0.7343,  0.3320,  0.7057,\n",
      "         0.4239,  0.4402,  0.3885,  0.8283,  0.4156,  2.7136,  0.4232,  2.1126,\n",
      "         1.4076,  0.4025,  0.8994,  0.6238,  0.6543,  0.6835,  0.2104,  0.8399,\n",
      "         0.4788,  2.3315,  0.5534,  0.8500,  0.5625,  0.9511,  0.4365,  0.8869,\n",
      "         1.1827,  1.8191,  2.1616,  0.3664,  1.0573,  0.5127,  1.2513,  0.6862,\n",
      "         1.2255,  1.2399,  0.7440,  1.8576,  0.0740,  0.9215,  1.0247,  1.5773,\n",
      "         0.8394,  1.0530,  0.3960,  0.1402,  1.0288,  0.0939,  1.5254,  0.9152,\n",
      "         0.8004,  1.3046,  0.0953,  1.6130,  0.6436,  0.2533,  0.3809,  1.1079,\n",
      "         1.1643,  0.8982,  1.5856,  0.6893,  0.7552,  0.9849,  2.4493,  0.5142,\n",
      "         1.9219,  0.8088,  1.1667,  1.0446,  1.8448,  0.9067,  0.5720,  2.0955],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.3688, -0.4242, -0.1696, -0.2070,  0.1755,  0.2575,  0.1717, -0.2943,\n",
      "        -0.0032,  0.6381, -0.3474,  0.0920,  0.3541, -0.3963,  0.1060,  0.0989,\n",
      "        -0.2866, -0.2227, -0.0907, -0.1270, -0.7225,  0.0145,  0.2136, -0.1601,\n",
      "         0.2867, -0.0702, -0.2173, -0.2070,  0.1887, -0.0090,  0.3602,  0.5238,\n",
      "        -0.0965,  0.0614,  0.2498, -0.2021,  0.3641,  0.1595,  0.1913, -0.0237,\n",
      "         0.0415, -0.5073, -0.0409, -0.1887, -0.2066,  0.0714, -0.0579, -0.2937,\n",
      "         0.0487,  0.0258, -0.0521,  0.2455,  0.1419, -0.0859, -0.3900,  0.0108,\n",
      "         0.0369, -0.0044,  0.7286,  0.0408,  0.0531,  0.0772, -0.2460,  0.1395,\n",
      "        -0.1056, -0.1917, -0.0038, -0.0456, -0.3538,  0.2863,  0.2122,  0.1625,\n",
      "         0.3342, -0.2831,  0.3038, -0.4650,  0.1803,  0.2705, -0.1073, -0.2869,\n",
      "        -0.1126, -0.0779, -0.0747,  0.5121,  0.2636, -0.4325, -0.1579,  0.4008,\n",
      "        -0.0396, -0.1022,  0.0677,  0.2040, -0.1789,  0.0865, -0.2831, -0.1168,\n",
      "        -0.3660,  0.4636, -0.0704, -0.5561, -0.0174, -0.0083,  0.1771,  0.2896,\n",
      "        -0.0706,  0.8876, -0.1349, -0.0795,  0.0370, -0.3142, -0.1797, -0.2820,\n",
      "         0.0205, -0.2492, -0.7685, -0.0101,  0.6508, -0.2415, -0.2682,  0.0734,\n",
      "        -0.1749,  0.1047, -0.4271, -0.3125, -0.0171, -0.4354,  0.3128,  0.1874,\n",
      "        -0.1244, -0.1584, -0.1157,  0.0540, -0.1152,  0.1633, -0.1231, -0.0714,\n",
      "        -0.1806,  0.2992,  0.3504,  0.5205,  0.1592,  0.1820, -0.2881,  0.0017,\n",
      "         0.6251,  0.0857,  0.5717, -0.2541,  0.1582,  0.0626, -0.1603,  0.1716,\n",
      "         0.1951, -0.0158, -0.1625,  0.2696, -0.3605,  0.1917,  0.7635,  0.1880,\n",
      "        -0.1101,  0.1426,  0.1200, -0.3396,  0.2874,  0.4004,  0.1688,  0.0786,\n",
      "         0.5887, -0.1815, -0.3386,  0.6762, -0.0068,  0.2291, -0.6310,  0.4110,\n",
      "         0.0729, -0.7151, -0.2251,  0.1141,  0.1753, -0.1636,  0.1386,  0.0114,\n",
      "        -0.4200,  0.3711,  0.7154, -0.1515, -0.0694,  0.1183,  0.3034,  0.0535,\n",
      "        -0.3092,  0.7141, -0.1426,  0.4393,  0.0474,  0.1844,  0.4394,  0.3421,\n",
      "        -0.1183,  0.5499, -0.1481, -0.0121,  0.1663,  0.0024,  0.0570,  0.0099,\n",
      "         0.1341, -0.5825,  0.0883,  0.0489,  0.0396, -0.3020, -0.0349, -0.3879,\n",
      "         0.2540, -0.0191, -0.2289,  0.1954,  0.0528,  0.2169,  1.3229,  0.2379,\n",
      "         0.5993, -0.1291, -0.0361,  0.0247, -0.4028, -0.6643,  0.2581,  0.3444],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0909]],\n",
      "\n",
      "         [[-0.5640]],\n",
      "\n",
      "         [[ 0.4763]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5015]],\n",
      "\n",
      "         [[-0.2306]],\n",
      "\n",
      "         [[ 0.0242]]],\n",
      "\n",
      "\n",
      "        [[[-0.2860]],\n",
      "\n",
      "         [[-0.2470]],\n",
      "\n",
      "         [[-0.6724]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1403]],\n",
      "\n",
      "         [[ 0.2993]],\n",
      "\n",
      "         [[ 0.2544]]],\n",
      "\n",
      "\n",
      "        [[[-0.3345]],\n",
      "\n",
      "         [[-0.1919]],\n",
      "\n",
      "         [[-0.4080]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1897]],\n",
      "\n",
      "         [[-0.1200]],\n",
      "\n",
      "         [[-0.2984]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2918]],\n",
      "\n",
      "         [[ 0.2555]],\n",
      "\n",
      "         [[ 0.1567]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0582]],\n",
      "\n",
      "         [[-0.6096]],\n",
      "\n",
      "         [[ 0.1693]]],\n",
      "\n",
      "\n",
      "        [[[-0.4400]],\n",
      "\n",
      "         [[ 0.4626]],\n",
      "\n",
      "         [[-0.0506]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0573]],\n",
      "\n",
      "         [[ 0.0171]],\n",
      "\n",
      "         [[-0.5017]]],\n",
      "\n",
      "\n",
      "        [[[-0.6334]],\n",
      "\n",
      "         [[ 0.0537]],\n",
      "\n",
      "         [[ 0.1476]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6253]],\n",
      "\n",
      "         [[-0.4477]],\n",
      "\n",
      "         [[-0.3366]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.4857, 1.2752, 0.9770,  ..., 1.0903, 1.1069, 0.5969], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.6669, -2.4322, -1.4822,  ..., -0.3632, -0.9759, -0.8111],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1921, -0.0676, -0.3012, -0.1429,  0.0377],\n",
      "          [-0.1400,  0.0506, -0.1809, -0.1954,  0.0174],\n",
      "          [ 0.1644,  0.5103,  0.2277, -0.0571,  0.2199],\n",
      "          [ 0.2565,  0.6011,  0.7973,  0.1850,  0.1042],\n",
      "          [ 0.1528,  0.3795,  0.7391,  0.3522,  0.2044]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2240,  0.0248,  0.1835,  0.4255,  0.4333],\n",
      "          [-0.1176, -0.0503,  0.2361, -0.0425, -0.0857],\n",
      "          [-0.1723, -0.2756,  1.0259,  0.5967,  0.0415],\n",
      "          [-0.2258,  0.1894,  0.2513,  0.0072, -0.1052],\n",
      "          [ 0.2113,  0.1612, -0.1588, -0.1219, -0.0486]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9655,  0.7206,  0.3690,  0.2654,  0.0537],\n",
      "          [ 0.1751, -0.0384, -0.1677, -0.0890, -0.3754],\n",
      "          [ 0.1111,  0.1037,  0.0316,  0.0427, -0.0165],\n",
      "          [-0.0084, -0.0669, -0.2247, -0.1237,  0.1269],\n",
      "          [ 0.3547,  0.4215,  0.4911,  0.2410,  0.2739]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4033, -0.3337, -0.3188, -0.2233, -0.1633],\n",
      "          [-0.3678, -0.3052, -0.2242,  0.0385,  0.1472],\n",
      "          [ 0.1546,  0.0795, -0.0363,  0.1245,  0.3816],\n",
      "          [ 0.3592,  0.2683,  0.1759,  0.1454,  0.4110],\n",
      "          [ 0.7115,  0.5238,  0.2018,  0.2014,  0.2944]]],\n",
      "\n",
      "\n",
      "        [[[-0.0074, -0.0273,  0.1516,  0.1641,  0.0999],\n",
      "          [-0.0125,  0.1301,  0.0760,  0.1162, -0.0179],\n",
      "          [-0.5010, -0.5506, -0.5399, -0.3415, -0.1200],\n",
      "          [-0.3634, -0.4285, -0.4655, -0.4818, -0.4113],\n",
      "          [-0.0696, -0.2017, -0.2863, -0.3487, -0.4140]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1812,  0.1898,  0.3303,  0.1413,  0.0015],\n",
      "          [-0.0629, -0.2215, -0.4216, -0.7910, -0.6934],\n",
      "          [ 0.2189, -0.1434, -0.3430, -0.4535, -0.4358],\n",
      "          [ 0.0202, -0.1637, -0.0796, -0.2707, -0.4798],\n",
      "          [ 0.0076,  0.0459,  0.0817, -0.2991, -0.6506]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.7261, 2.6068, 1.4463,  ..., 1.9469, 1.4919, 0.9527], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.1526, -0.0606, -0.9547,  ..., -0.6624, -1.1604, -1.4568],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0145]],\n",
      "\n",
      "         [[ 0.0696]],\n",
      "\n",
      "         [[ 0.6650]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0144]],\n",
      "\n",
      "         [[-0.1712]],\n",
      "\n",
      "         [[-0.0497]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0169]],\n",
      "\n",
      "         [[-0.0647]],\n",
      "\n",
      "         [[-0.3468]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0122]],\n",
      "\n",
      "         [[-0.1572]],\n",
      "\n",
      "         [[ 0.0348]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1012]],\n",
      "\n",
      "         [[-0.0502]],\n",
      "\n",
      "         [[-0.0087]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0161]],\n",
      "\n",
      "         [[ 0.1778]],\n",
      "\n",
      "         [[ 0.0556]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0450]],\n",
      "\n",
      "         [[-0.1188]],\n",
      "\n",
      "         [[ 0.6769]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1913]],\n",
      "\n",
      "         [[ 0.2933]],\n",
      "\n",
      "         [[-0.1619]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2082]],\n",
      "\n",
      "         [[ 0.3477]],\n",
      "\n",
      "         [[-0.3604]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3954]],\n",
      "\n",
      "         [[-0.3104]],\n",
      "\n",
      "         [[-0.3107]]],\n",
      "\n",
      "\n",
      "        [[[-0.0586]],\n",
      "\n",
      "         [[ 0.0014]],\n",
      "\n",
      "         [[-0.1129]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0929]],\n",
      "\n",
      "         [[-0.0449]],\n",
      "\n",
      "         [[ 0.1293]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.2125, -0.1884, -0.3302,  0.4792,  0.1521, -0.3583,  0.3333,  0.1201,\n",
      "         0.3369,  0.1683,  0.0199, -0.0434, -0.1733,  0.2495,  0.1164,  0.2979,\n",
      "         0.0308,  0.1756, -0.3419, -0.1824,  0.0537, -0.3186,  0.0975,  0.1833,\n",
      "        -0.0828,  0.2105,  0.1687, -0.1873,  0.2776,  0.2066, -0.2883,  0.4034,\n",
      "         0.0597,  0.1408, -0.3315, -0.0839,  0.0151,  0.2250,  0.2585,  0.1158,\n",
      "         0.1831,  0.1337,  0.0999,  0.1723, -0.2472,  0.2470, -0.2859,  0.2625,\n",
      "        -0.1606, -0.2735,  0.0961, -0.0133,  0.4212,  0.3376,  0.2060, -0.1944,\n",
      "         0.4024, -0.2852], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0468]],\n",
      "\n",
      "         [[-0.0831]],\n",
      "\n",
      "         [[-0.1043]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0529]],\n",
      "\n",
      "         [[-0.1512]],\n",
      "\n",
      "         [[-0.0384]]],\n",
      "\n",
      "\n",
      "        [[[-0.4214]],\n",
      "\n",
      "         [[ 0.1870]],\n",
      "\n",
      "         [[-0.0408]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1359]],\n",
      "\n",
      "         [[ 0.1098]],\n",
      "\n",
      "         [[ 0.0043]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2229]],\n",
      "\n",
      "         [[-0.1055]],\n",
      "\n",
      "         [[ 0.1474]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0921]],\n",
      "\n",
      "         [[ 0.0887]],\n",
      "\n",
      "         [[-0.0755]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0730]],\n",
      "\n",
      "         [[ 0.0083]],\n",
      "\n",
      "         [[-0.1449]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0435]],\n",
      "\n",
      "         [[-0.1035]],\n",
      "\n",
      "         [[ 0.1559]]],\n",
      "\n",
      "\n",
      "        [[[-0.2145]],\n",
      "\n",
      "         [[-0.0436]],\n",
      "\n",
      "         [[-0.3010]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1320]],\n",
      "\n",
      "         [[-0.0395]],\n",
      "\n",
      "         [[-0.0018]]],\n",
      "\n",
      "\n",
      "        [[[-0.0521]],\n",
      "\n",
      "         [[-0.2352]],\n",
      "\n",
      "         [[ 0.0967]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0391]],\n",
      "\n",
      "         [[ 0.0921]],\n",
      "\n",
      "         [[-0.1974]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.0847, -0.4116,  0.1376,  ..., -0.1255, -0.1540, -0.0135],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0625]],\n",
      "\n",
      "         [[-0.1235]],\n",
      "\n",
      "         [[ 0.1603]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1428]],\n",
      "\n",
      "         [[ 0.0278]],\n",
      "\n",
      "         [[-0.0390]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0277]],\n",
      "\n",
      "         [[-0.1895]],\n",
      "\n",
      "         [[-0.0649]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0539]],\n",
      "\n",
      "         [[-0.0947]],\n",
      "\n",
      "         [[ 0.3267]]],\n",
      "\n",
      "\n",
      "        [[[-0.0370]],\n",
      "\n",
      "         [[ 0.3831]],\n",
      "\n",
      "         [[ 0.6768]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0307]],\n",
      "\n",
      "         [[-0.0594]],\n",
      "\n",
      "         [[-0.1408]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0534]],\n",
      "\n",
      "         [[-0.5106]],\n",
      "\n",
      "         [[-0.3504]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0244]],\n",
      "\n",
      "         [[-0.2504]],\n",
      "\n",
      "         [[-0.5240]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0237]],\n",
      "\n",
      "         [[ 0.2624]],\n",
      "\n",
      "         [[-0.1033]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0804]],\n",
      "\n",
      "         [[ 0.0641]],\n",
      "\n",
      "         [[ 0.5251]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0339]],\n",
      "\n",
      "         [[ 0.1386]],\n",
      "\n",
      "         [[ 0.0481]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0169]],\n",
      "\n",
      "         [[ 0.0025]],\n",
      "\n",
      "         [[-0.0748]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.3144, 0.4622, 1.1577, 0.8810, 0.5744, 1.5108, 0.1966, 1.0221, 0.4396,\n",
      "        0.5791, 0.1609, 0.9829, 0.3659, 1.0424, 0.6155, 1.6790, 1.1747, 1.4960,\n",
      "        0.8124, 0.8788, 1.0180, 0.9686, 0.5867, 1.1197, 0.4010, 0.5370, 0.7932,\n",
      "        0.9892, 0.7268, 0.7907, 0.5055, 0.5882, 0.5355, 1.1315, 0.9762, 0.6377,\n",
      "        1.3993, 0.8700, 0.2407, 1.1274, 1.4624, 0.3193, 1.2378, 0.1025, 0.1612,\n",
      "        0.9665, 0.9082, 1.3655, 1.0552, 0.6167, 0.8763, 0.9077, 1.2372, 1.0558,\n",
      "        1.4986, 1.0272, 1.2338, 0.9695, 1.2684, 1.3929, 0.8749, 0.9340, 0.6893,\n",
      "        0.8441, 1.2114, 1.3121, 1.1209, 0.8960, 0.7963, 1.0317, 0.7289, 1.4362,\n",
      "        0.5536, 0.8869, 0.8189, 0.7995, 0.8129, 0.6107, 0.8220, 0.4465, 0.6972,\n",
      "        0.7334, 0.2867, 0.8918, 1.1126, 1.1511, 1.0683, 0.5823, 1.0561, 0.6049,\n",
      "        0.8533, 0.7798, 0.7568, 0.1521, 0.6278, 1.0528, 1.4752, 0.7269, 0.4381,\n",
      "        0.5975, 1.0880, 1.0282, 0.8225, 0.4435, 0.9700, 2.0308, 0.6774, 1.0647,\n",
      "        0.7155, 1.1659, 0.7827, 0.9751, 0.8681, 0.9572, 1.1619, 0.2045, 1.0447,\n",
      "        1.1649, 0.6093, 1.1505, 1.3462, 0.6314, 0.6805, 1.3677, 1.0857, 0.7628,\n",
      "        0.9024, 0.4949, 0.7593, 0.9771, 0.2285, 0.9302, 0.7276, 0.5202, 0.6117,\n",
      "        0.9315, 1.1031, 1.0361, 0.5957, 0.7264, 0.7271, 0.3585, 0.6786, 0.9758,\n",
      "        0.5286, 0.6084, 1.7739, 1.0287, 1.3289, 0.9009, 0.7071, 0.4190, 0.2081,\n",
      "        0.3128, 1.1574, 0.8630, 0.9133, 1.0696, 0.4724, 0.9008, 0.5502, 0.5121,\n",
      "        0.5716, 0.6016, 1.0274, 1.8409, 0.7066, 1.3428, 1.2856, 0.3597, 1.2921,\n",
      "        0.8612, 0.8329, 0.9374, 0.2907, 0.7750, 0.7113, 1.8001, 0.3145, 0.9357,\n",
      "        1.5077, 0.5642, 0.6348, 0.9402, 1.4244, 1.3655, 1.4074, 0.2886, 0.9657,\n",
      "        0.2895, 1.3146, 1.1153, 1.1835, 0.9834, 0.9370, 1.5711, 0.6207, 0.9003,\n",
      "        1.0350, 1.5708, 0.8768, 0.7707, 0.5406, 0.2474, 0.8198, 0.3337, 1.1712,\n",
      "        1.0193, 0.9161, 1.5465, 0.8700, 1.5510, 1.2238, 0.6135, 0.4668, 1.1142,\n",
      "        1.4139, 0.6040, 1.0278, 0.7145, 0.5395, 0.9263, 2.1281, 0.9020, 1.5029,\n",
      "        0.9469, 1.1448, 0.6197, 1.3395, 0.8361, 0.6508, 1.7487],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 1.9192e-01, -1.9077e-01, -5.7819e-02,  2.4122e-02,  3.5577e-01,\n",
      "         1.9450e-01,  1.5211e-03, -3.3574e-01, -5.2969e-03,  4.4863e-01,\n",
      "        -4.0981e-01,  1.5843e-01,  2.9686e-01,  1.4433e-02, -5.0600e-02,\n",
      "         1.4075e-01,  1.1461e-01, -4.5179e-01,  3.5057e-02,  1.0330e-01,\n",
      "        -2.8494e-01,  3.5975e-02, -3.1472e-01, -2.8190e-01,  1.8128e-01,\n",
      "         8.6490e-02,  2.7133e-02,  3.8205e-01, -1.8025e-01, -2.0988e-01,\n",
      "         2.7522e-01,  2.2253e-01,  1.8461e-01,  5.3536e-02, -7.9027e-02,\n",
      "        -1.2394e-02,  9.9486e-02,  1.0565e-01,  2.5486e-01,  2.0454e-01,\n",
      "        -1.2202e-01, -3.4820e-01,  1.2624e-01, -2.6468e-01, -1.8232e-01,\n",
      "        -3.1200e-02, -1.2326e-01, -2.8125e-01,  1.7240e-02,  1.3097e-01,\n",
      "         9.2137e-02,  9.3503e-02, -1.2555e-02, -1.4678e-01, -2.9649e-01,\n",
      "         1.3443e-01,  1.4414e-01, -2.6461e-02,  4.6139e-01,  3.8643e-01,\n",
      "         2.0507e-01, -4.3297e-02,  3.0675e-01, -5.7463e-02,  1.1706e-01,\n",
      "        -1.9945e-01,  3.6033e-01,  1.4976e-01, -3.6902e-02,  2.6349e-01,\n",
      "         4.9663e-01,  8.4155e-02,  1.4250e-01, -7.9094e-03,  1.7228e-01,\n",
      "        -4.6299e-01,  4.7074e-02,  1.5806e-01,  1.6459e-01,  3.4995e-02,\n",
      "         7.4563e-02,  1.3382e-01,  9.5392e-02,  4.0930e-01,  1.5641e-01,\n",
      "        -3.0939e-01, -4.7544e-02,  3.2869e-01, -3.5671e-01, -1.2172e-01,\n",
      "         1.1766e-01, -1.0670e-02, -1.0873e-01, -3.6882e-02, -1.6172e-01,\n",
      "        -4.7393e-02, -2.4804e-01,  1.4423e-01, -8.5557e-02, -2.9526e-01,\n",
      "         1.6758e-01, -2.4358e-01, -2.0574e-01,  1.2974e-01,  2.2952e-01,\n",
      "         1.7616e-01, -2.1543e-02, -1.4998e-01,  6.6709e-03, -1.4909e-02,\n",
      "        -1.7129e-01, -4.9184e-01, -1.1617e-01, -3.1447e-02, -5.7782e-01,\n",
      "        -2.7261e-01,  2.1660e-01,  2.0314e-01, -1.6736e-01,  1.1224e-01,\n",
      "         1.4884e-01, -2.7582e-02, -2.3151e-01, -1.8852e-01, -3.1641e-01,\n",
      "         1.6524e-02, -6.2937e-02, -1.2080e-01,  2.6547e-02, -2.9470e-01,\n",
      "         2.0501e-01,  1.7104e-01, -1.5920e-01,  2.7884e-02, -1.4301e-01,\n",
      "         1.9555e-01,  3.7648e-02, -6.7125e-02,  1.3550e-02,  2.1598e-01,\n",
      "        -1.6339e-01,  7.8892e-02, -9.5775e-02,  1.2571e-01,  5.2343e-01,\n",
      "         3.2586e-02,  3.3846e-01, -1.7504e-01, -5.3283e-02, -1.4061e-01,\n",
      "        -1.3983e-01,  8.9169e-03,  3.5532e-02, -8.7463e-02, -7.7357e-03,\n",
      "        -1.0790e-02, -7.1024e-02, -1.0278e-01,  7.7096e-01, -6.1697e-02,\n",
      "         1.3987e-01,  2.5953e-01,  1.0004e-03, -1.0031e-01,  3.7497e-01,\n",
      "         3.5688e-01, -1.4267e-02, -1.0730e-01,  3.1005e-01, -1.4415e-01,\n",
      "        -1.1048e-02,  3.4393e-01, -2.0467e-01,  7.7179e-03, -3.7744e-01,\n",
      "         3.6286e-01,  3.3333e-02, -7.2341e-01, -4.3568e-02, -4.4791e-02,\n",
      "         9.1879e-02, -2.0302e-01, -2.7211e-02,  8.5221e-02, -2.3262e-01,\n",
      "        -8.8112e-02,  6.8957e-01, -7.4447e-02, -2.6927e-01,  1.5800e-02,\n",
      "         4.0365e-01, -9.0433e-02, -3.8149e-01,  2.5802e-01, -5.6792e-02,\n",
      "         2.1758e-01,  1.8516e-01,  6.6114e-02,  4.9298e-01,  1.8493e-01,\n",
      "        -5.2919e-03,  2.1425e-01, -8.2792e-02, -1.2978e-01,  1.1910e-01,\n",
      "         7.9934e-02,  3.0995e-01,  4.5154e-02,  6.1227e-02, -3.0574e-01,\n",
      "         4.7124e-02,  4.0153e-02,  6.2828e-02, -1.4877e-01,  1.0141e-01,\n",
      "        -2.1318e-01,  2.3881e-01,  2.1778e-01,  3.1692e-01,  2.0515e-01,\n",
      "         2.1078e-01, -3.3443e-02,  1.0499e+00,  1.9661e-01,  5.3557e-01,\n",
      "        -7.9009e-02, -1.9896e-02, -1.8644e-01,  4.7754e-02, -5.0372e-01,\n",
      "        -2.1274e-01,  3.4133e-01], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1288]],\n",
      "\n",
      "         [[-0.2382]],\n",
      "\n",
      "         [[ 0.2771]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0700]],\n",
      "\n",
      "         [[-0.1015]],\n",
      "\n",
      "         [[-0.5952]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2630]],\n",
      "\n",
      "         [[-0.1309]],\n",
      "\n",
      "         [[-0.1687]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3936]],\n",
      "\n",
      "         [[ 0.1334]],\n",
      "\n",
      "         [[-0.0932]]],\n",
      "\n",
      "\n",
      "        [[[-0.1761]],\n",
      "\n",
      "         [[-0.1876]],\n",
      "\n",
      "         [[-0.2752]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1002]],\n",
      "\n",
      "         [[-0.3193]],\n",
      "\n",
      "         [[-0.1166]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1708]],\n",
      "\n",
      "         [[-0.3083]],\n",
      "\n",
      "         [[-0.1330]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2948]],\n",
      "\n",
      "         [[-0.6011]],\n",
      "\n",
      "         [[ 0.4190]]],\n",
      "\n",
      "\n",
      "        [[[-0.4215]],\n",
      "\n",
      "         [[-0.6555]],\n",
      "\n",
      "         [[ 0.2052]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4106]],\n",
      "\n",
      "         [[-0.3462]],\n",
      "\n",
      "         [[-0.5183]]],\n",
      "\n",
      "\n",
      "        [[[-0.1895]],\n",
      "\n",
      "         [[-0.1986]],\n",
      "\n",
      "         [[ 0.1014]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0984]],\n",
      "\n",
      "         [[-0.3045]],\n",
      "\n",
      "         [[ 0.0192]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.2639, 1.1172, 0.6150,  ..., 0.4713, 0.9823, 0.7601], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.4790, -0.5765,  2.2155,  ..., -1.1827, -1.6333, -0.4837],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.5348,  0.1903,  0.2843],\n",
      "          [ 0.7899,  0.4068,  0.0888],\n",
      "          [ 0.4267,  0.0352, -0.0141]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2609,  0.4026,  0.7194],\n",
      "          [ 0.2082,  0.1991,  0.5144],\n",
      "          [ 0.0854,  0.1686,  0.1392]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0041, -0.4025,  0.1774],\n",
      "          [-0.0359, -0.3084,  0.1151],\n",
      "          [-0.6693, -0.8462, -0.3966]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.4871,  0.3896,  0.4127],\n",
      "          [ 0.2899,  0.1494, -0.0117],\n",
      "          [ 0.6455,  0.2088,  0.1778]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1063,  0.1855,  0.0052],\n",
      "          [ 0.6900, -0.2226, -0.0424],\n",
      "          [ 0.7192, -0.0109,  0.0102]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2141,  0.4279,  0.1928],\n",
      "          [ 0.8215,  0.4665,  0.0637],\n",
      "          [ 0.3355,  0.1473,  0.0353]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.4747, 0.9180, 2.3954,  ..., 1.2059, 0.9992, 1.8031], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.4051, -0.5835, -0.9104,  ..., -0.7482, -0.2635, -0.5021],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1220]],\n",
      "\n",
      "         [[ 0.1760]],\n",
      "\n",
      "         [[-0.1947]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1069]],\n",
      "\n",
      "         [[-0.2936]],\n",
      "\n",
      "         [[-0.1508]]],\n",
      "\n",
      "\n",
      "        [[[-0.2233]],\n",
      "\n",
      "         [[ 0.2530]],\n",
      "\n",
      "         [[-0.2164]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0278]],\n",
      "\n",
      "         [[-0.1419]],\n",
      "\n",
      "         [[-0.0791]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0197]],\n",
      "\n",
      "         [[-0.0816]],\n",
      "\n",
      "         [[-0.2073]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4248]],\n",
      "\n",
      "         [[-0.1144]],\n",
      "\n",
      "         [[-0.2540]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0690]],\n",
      "\n",
      "         [[-0.0276]],\n",
      "\n",
      "         [[ 0.1821]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1107]],\n",
      "\n",
      "         [[ 0.1161]],\n",
      "\n",
      "         [[-0.4343]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5118]],\n",
      "\n",
      "         [[ 0.1403]],\n",
      "\n",
      "         [[ 0.0105]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1041]],\n",
      "\n",
      "         [[ 0.2547]],\n",
      "\n",
      "         [[-0.3432]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3329]],\n",
      "\n",
      "         [[-0.0018]],\n",
      "\n",
      "         [[-0.2886]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0932]],\n",
      "\n",
      "         [[-0.1432]],\n",
      "\n",
      "         [[-0.1015]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1676, -0.1389, -0.1644,  0.0353, -0.1760, -0.2001, -0.1577, -0.1511,\n",
      "        -0.1681, -0.0266,  0.0143, -0.1032, -0.2481, -0.1512, -0.1455, -0.1918,\n",
      "        -0.1771, -0.1119, -0.1704, -0.0860, -0.0308, -0.1697,  0.3242,  0.0127,\n",
      "        -0.0954,  0.1024, -0.1470, -0.1586, -0.1043, -0.2035, -0.2162, -0.1917,\n",
      "        -0.1576, -0.1984, -0.1819, -0.1969, -0.1178, -0.1827, -0.2486, -0.2083,\n",
      "        -0.1892, -0.1115, -0.2216, -0.1977, -0.0397, -0.2617, -0.0676, -0.1382,\n",
      "        -0.1817, -0.1418,  0.1320,  0.0421, -0.2323, -0.0342, -0.0912, -0.0400,\n",
      "         0.3426, -0.2269], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.2156]],\n",
      "\n",
      "         [[ 0.2540]],\n",
      "\n",
      "         [[-0.1237]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2173]],\n",
      "\n",
      "         [[ 0.1937]],\n",
      "\n",
      "         [[ 0.2814]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0645]],\n",
      "\n",
      "         [[ 0.0762]],\n",
      "\n",
      "         [[ 0.4217]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3623]],\n",
      "\n",
      "         [[-0.0757]],\n",
      "\n",
      "         [[ 0.1653]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0188]],\n",
      "\n",
      "         [[ 0.0471]],\n",
      "\n",
      "         [[-0.7015]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4006]],\n",
      "\n",
      "         [[ 0.1690]],\n",
      "\n",
      "         [[ 0.0195]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0456]],\n",
      "\n",
      "         [[ 0.0433]],\n",
      "\n",
      "         [[-0.0440]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1302]],\n",
      "\n",
      "         [[-0.0191]],\n",
      "\n",
      "         [[ 0.2027]]],\n",
      "\n",
      "\n",
      "        [[[-0.2908]],\n",
      "\n",
      "         [[-0.1050]],\n",
      "\n",
      "         [[ 0.2068]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0388]],\n",
      "\n",
      "         [[-0.0609]],\n",
      "\n",
      "         [[-0.2150]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0189]],\n",
      "\n",
      "         [[-0.1727]],\n",
      "\n",
      "         [[-0.0976]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1186]],\n",
      "\n",
      "         [[ 0.5569]],\n",
      "\n",
      "         [[-0.1889]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1330, -0.1705,  0.1726,  ..., -0.5834,  0.1571, -0.0759],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.0095]],\n",
      "\n",
      "         [[ 0.0228]],\n",
      "\n",
      "         [[-0.5913]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0440]],\n",
      "\n",
      "         [[ 0.2567]],\n",
      "\n",
      "         [[ 0.4500]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0993]],\n",
      "\n",
      "         [[-0.1945]],\n",
      "\n",
      "         [[-0.2935]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1022]],\n",
      "\n",
      "         [[-0.4116]],\n",
      "\n",
      "         [[ 0.2390]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8434]],\n",
      "\n",
      "         [[ 0.4118]],\n",
      "\n",
      "         [[-0.1616]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2047]],\n",
      "\n",
      "         [[ 0.1852]],\n",
      "\n",
      "         [[-0.5425]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2005]],\n",
      "\n",
      "         [[ 0.4109]],\n",
      "\n",
      "         [[ 0.5512]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3946]],\n",
      "\n",
      "         [[ 0.5697]],\n",
      "\n",
      "         [[-0.5384]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3272]],\n",
      "\n",
      "         [[ 0.4358]],\n",
      "\n",
      "         [[ 0.1936]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0442]],\n",
      "\n",
      "         [[ 0.3931]],\n",
      "\n",
      "         [[-0.3411]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1871]],\n",
      "\n",
      "         [[-0.3286]],\n",
      "\n",
      "         [[-0.0422]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0486]],\n",
      "\n",
      "         [[-0.4391]],\n",
      "\n",
      "         [[ 0.0873]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([2.5002, 3.2075, 2.7121, 3.0267, 2.3332, 3.0772, 3.2369, 4.9947, 3.6313,\n",
      "        2.2972, 2.8977, 2.6335, 2.1383, 2.8079, 2.7888, 4.8767, 3.1859, 2.4665,\n",
      "        2.6227, 3.1895, 2.6869, 3.1919, 3.4031, 3.0453, 3.2024, 3.3093, 3.0339,\n",
      "        2.8808, 2.4285, 2.5865, 2.9975, 2.7806, 4.5292, 2.6231, 2.6993, 2.6604,\n",
      "        2.8646, 3.5010, 3.2778, 2.9298, 3.6644, 2.2253, 4.5759, 3.6293, 4.0220,\n",
      "        3.2360, 3.0604, 2.7342, 3.4837, 3.1942, 2.7383, 3.9240, 2.7373, 2.7624,\n",
      "        3.3838, 2.8665, 2.9012, 3.4099, 3.5889, 2.5942, 3.1627, 3.5120, 3.4141,\n",
      "        4.1107, 3.2867, 2.3991, 2.1344, 2.4950, 2.9951, 2.6266, 3.8714, 3.4934,\n",
      "        2.9801, 3.5537, 3.4947, 2.6340, 2.4036, 2.9198, 2.6551, 2.8538, 2.8153,\n",
      "        3.0345, 2.7721, 2.5177, 3.1681, 2.7711, 3.4503, 2.8617, 3.5787, 2.4391,\n",
      "        2.7674, 2.3680, 3.6108, 2.6516, 2.4741, 3.1153, 3.2751, 2.3265, 2.6176,\n",
      "        4.5447, 2.6278, 2.5641, 2.3683, 2.8285, 2.3446, 2.8637, 2.6149, 3.3779,\n",
      "        2.7747, 2.7828, 2.8603, 2.9322, 2.3692, 2.9246, 2.6603, 3.0055, 2.4557,\n",
      "        2.7400, 2.4984, 2.7884, 2.3463, 2.8962, 3.9038, 2.8559, 2.5260, 3.1886,\n",
      "        3.0938, 2.8490, 3.0513, 2.6133, 3.8529, 3.7032, 4.1469, 2.5194, 2.5724,\n",
      "        3.8655, 2.5818, 2.4355, 1.9218, 2.6604, 2.7745, 3.0611, 2.7093, 3.3441,\n",
      "        2.7677, 2.4445, 2.4719, 2.9526, 3.0531, 2.7678, 2.5572, 2.9759, 2.5842,\n",
      "        3.5463, 2.7235, 2.5279, 2.4559, 4.3986, 3.3566, 2.8844, 2.3743, 2.9268,\n",
      "        2.7510, 3.1356, 2.7053, 3.6260, 2.6639, 2.3757, 3.0802, 2.8308, 2.6628,\n",
      "        2.6085, 2.7954, 3.0700, 2.3420, 3.4477, 3.7933, 2.3421, 3.2970, 2.9796,\n",
      "        3.0164, 2.9651, 2.7757, 2.6310, 2.2649, 2.5237, 2.5612, 3.3440, 3.0145,\n",
      "        3.7527, 2.7754, 2.5226, 3.2980, 2.3698, 3.6478, 2.9434, 2.7522, 2.8360,\n",
      "        2.9911, 3.2934, 2.5299, 2.7850, 2.6744, 2.4880, 3.2200, 2.6531, 3.0609,\n",
      "        2.7558, 3.0683, 2.4565, 2.9150, 3.2619, 2.6701, 2.8551, 2.9213, 2.6688,\n",
      "        2.6555, 2.3723, 2.8304, 2.7738, 4.9278, 3.4584, 2.6070, 2.7664, 4.7858,\n",
      "        3.0727, 2.3810, 2.7947, 2.3612, 2.5891, 3.5447, 2.7548, 3.2149, 2.8920,\n",
      "        3.2762, 2.7137, 3.4174, 2.5610, 2.9590, 3.0396, 3.0972, 2.6232, 2.7459,\n",
      "        2.7832, 2.4978, 2.3783, 3.8354, 3.1595, 3.9594, 2.7356, 2.4007, 3.2730,\n",
      "        2.9409, 4.0789, 3.7528, 3.3364, 2.4447, 2.7140, 2.9680, 2.5893, 2.8290,\n",
      "        2.8953, 2.5984, 2.3715, 2.7676, 3.7584, 2.5966, 2.9775, 2.6538, 2.5800,\n",
      "        3.1112, 2.7239, 2.6131, 3.3348, 2.7066, 2.3630, 2.2182, 2.3192, 3.2363,\n",
      "        2.5201, 2.8803, 2.8987, 2.5349, 2.5739, 3.1567, 2.5838, 2.7247, 3.1837,\n",
      "        2.5438, 2.6747, 2.4568, 2.6944, 2.8140, 2.8615, 2.8270, 3.4636, 2.5336,\n",
      "        3.0016, 2.9183, 3.1881, 2.5516, 2.4899, 2.4265, 3.0562, 3.8970, 2.8270,\n",
      "        2.7205, 2.6147, 2.7592, 2.2868, 2.1860, 3.4693, 2.6463, 3.5856, 2.4390,\n",
      "        2.4097, 3.3585, 3.3824, 3.4946, 3.4254, 2.4071, 3.0274, 2.8662, 2.2314,\n",
      "        3.2133, 3.2490, 3.0523, 2.7306, 2.6147, 2.6884, 2.0984, 2.2468, 2.8664,\n",
      "        2.5338, 2.9571, 2.8515, 2.9038, 2.6975, 2.3121, 3.6780, 2.0085, 3.0471,\n",
      "        2.5295, 4.7678, 3.2165, 4.0458, 2.5744, 2.8215, 3.3290, 2.9036, 3.1486,\n",
      "        2.5034, 2.6253, 3.3450, 2.5117, 4.3831, 2.7135, 2.8636, 2.2095, 3.0062,\n",
      "        3.4399, 3.4498, 3.8957, 2.5227, 2.8353, 3.3462, 2.6569, 3.0268, 2.7883,\n",
      "        2.6646, 2.3506, 2.8947, 2.1872, 2.6935, 2.8291, 2.7622, 2.8346, 3.1487,\n",
      "        2.2925, 3.0221, 2.7696, 3.9835, 3.2043, 2.1271], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-2.8579e-03, -7.3395e-03, -6.4465e-03, -2.6492e-03,  3.2176e-03,\n",
      "         9.3351e-03,  7.0279e-04, -2.0732e-02,  1.0527e-02, -7.1133e-03,\n",
      "         1.1351e-02,  2.9944e-02,  1.1863e-02,  2.9989e-02, -7.8840e-03,\n",
      "         2.0579e-02,  2.6581e-02,  1.2646e-02, -9.8090e-03,  4.2767e-03,\n",
      "         9.4640e-04,  3.7611e-02, -7.6821e-03,  1.8673e-02,  4.0691e-04,\n",
      "         2.6853e-02, -5.7681e-03, -5.3556e-03,  8.5527e-03,  2.2768e-03,\n",
      "         2.9784e-02,  2.5337e-03, -1.9612e-02,  3.9333e-03, -6.3277e-03,\n",
      "         2.7485e-03,  3.2164e-03,  3.8790e-03,  1.3337e-02, -4.4372e-03,\n",
      "         1.0146e-03,  7.1516e-03,  2.5562e-02,  1.3218e-02, -2.0486e-02,\n",
      "         9.0934e-03,  5.0042e-03, -3.4833e-03,  3.0206e-03,  3.9497e-02,\n",
      "         2.7157e-03, -1.5357e-02, -3.3630e-03, -5.3980e-03,  5.2577e-03,\n",
      "         9.7553e-03,  1.7947e-02,  4.2933e-03, -1.3234e-02, -1.5605e-03,\n",
      "         2.9800e-04,  9.8893e-03,  1.8417e-02,  1.9602e-02, -2.1997e-03,\n",
      "        -1.0693e-02, -9.3497e-03, -2.0823e-02,  1.2025e-03,  2.2038e-03,\n",
      "        -1.3808e-02,  1.0127e-02, -6.3711e-03, -1.3134e-02, -2.1748e-02,\n",
      "         5.6656e-03,  2.8691e-03,  8.1005e-03, -5.0846e-03, -5.7386e-02,\n",
      "         1.5050e-02,  1.0114e-02,  7.9001e-05,  3.2806e-03,  1.1852e-02,\n",
      "        -2.3535e-02,  1.2655e-02,  1.9799e-03,  3.0094e-03,  2.3692e-03,\n",
      "         1.6374e-02, -1.3227e-02,  2.5192e-03,  1.2288e-02,  2.2672e-04,\n",
      "        -3.3157e-03,  1.9411e-02, -1.0746e-03, -1.0424e-02,  1.9077e-02,\n",
      "         2.2801e-02, -3.8303e-03, -1.6415e-03,  5.5056e-03, -2.2425e-03,\n",
      "         5.1019e-04,  2.1586e-03,  1.3543e-02, -1.2365e-02,  2.0907e-03,\n",
      "        -1.2586e-03, -4.1360e-03, -1.0059e-03,  8.3431e-03,  6.1363e-03,\n",
      "         1.4694e-02, -1.1345e-03,  3.7633e-03,  5.9299e-03,  5.3690e-03,\n",
      "         1.8746e-02,  2.5964e-03,  6.3643e-03,  3.4197e-03, -7.4544e-03,\n",
      "        -5.6249e-04, -9.6794e-03, -1.1827e-02, -3.4612e-03, -2.0082e-02,\n",
      "         1.3621e-02, -3.1329e-02,  1.5697e-02, -1.0097e-02, -1.2297e-02,\n",
      "         4.2092e-03, -7.0273e-03,  3.5670e-03, -3.5887e-03, -2.5094e-03,\n",
      "        -7.9955e-03,  1.2917e-02, -1.6725e-02, -6.1317e-03, -4.5124e-03,\n",
      "         8.8287e-03,  4.9828e-03,  1.4226e-02, -3.0800e-04, -4.8501e-04,\n",
      "        -1.0176e-02,  5.3799e-03, -1.9085e-02, -2.7075e-04, -2.8720e-02,\n",
      "         1.6459e-03,  6.6521e-03, -1.6547e-02, -1.4006e-02, -1.4897e-02,\n",
      "         1.7968e-03, -6.4037e-03,  1.4118e-02, -1.8332e-02, -1.0035e-02,\n",
      "         9.1294e-03, -1.4993e-02, -5.2706e-03, -2.4711e-02,  1.3556e-02,\n",
      "        -1.6148e-03,  6.3886e-03,  3.1818e-03,  2.4677e-02,  2.8713e-03,\n",
      "         1.3713e-02, -6.8675e-03,  8.9243e-03, -2.6574e-03, -1.1951e-03,\n",
      "         3.0844e-03,  1.1641e-04,  8.8468e-03, -1.8593e-03,  5.4720e-03,\n",
      "         7.9806e-04, -7.8251e-03,  3.5880e-03,  4.0270e-03, -1.0628e-02,\n",
      "        -1.1948e-02, -4.1495e-04, -1.3528e-02, -8.7326e-03,  1.3308e-02,\n",
      "         7.6316e-03,  4.2031e-02,  1.9746e-02,  9.9665e-03, -1.5156e-02,\n",
      "         1.1649e-02,  2.3727e-03, -5.2560e-03,  1.1573e-02, -1.3295e-02,\n",
      "        -4.2347e-04, -4.1849e-03, -1.4812e-02, -1.2188e-02, -6.5161e-03,\n",
      "        -4.1569e-03, -3.0672e-03, -4.2007e-03, -2.8069e-02, -4.2478e-03,\n",
      "        -3.4727e-03,  1.5647e-03,  1.2774e-02,  5.7961e-02,  3.6458e-03,\n",
      "        -1.5615e-02,  1.5161e-02, -1.3429e-02,  3.3565e-02, -1.3027e-02,\n",
      "         1.4036e-02, -1.4184e-02, -1.8012e-02, -1.3597e-02,  7.8473e-03,\n",
      "         7.4597e-03,  9.1280e-03,  1.5346e-02, -2.9884e-03,  4.9973e-02,\n",
      "        -1.7078e-02,  1.5615e-02,  1.5784e-02,  5.8610e-03,  5.3967e-03,\n",
      "         9.1232e-03, -6.5752e-03, -4.9166e-03,  2.2264e-02, -9.6107e-03,\n",
      "        -4.3010e-03, -2.1365e-02,  2.3762e-03, -1.2905e-02, -1.0297e-02,\n",
      "        -1.7822e-03,  1.4048e-02,  1.4159e-02, -9.6360e-03, -1.6990e-02,\n",
      "        -1.9383e-02, -2.0393e-02,  7.2958e-04, -4.5016e-03,  4.0519e-03,\n",
      "        -1.0161e-02,  1.2741e-02, -1.1591e-03,  7.5103e-04,  5.8820e-05,\n",
      "         7.9363e-03,  2.7728e-03,  2.7311e-02, -8.6337e-03,  9.2695e-03,\n",
      "         1.1098e-02,  1.3691e-02, -2.6176e-02,  4.8990e-03,  2.8474e-02,\n",
      "         4.5097e-03, -9.6993e-03,  1.4066e-02, -5.0375e-02, -4.2129e-03,\n",
      "        -2.7140e-04,  6.9335e-03, -2.4774e-03, -1.3322e-02, -8.3096e-03,\n",
      "        -1.7863e-02, -1.0240e-03, -3.1410e-03,  3.9543e-03,  5.6617e-03,\n",
      "        -1.8657e-03, -2.7395e-02, -2.0918e-03, -9.3492e-04, -1.7969e-03,\n",
      "         1.1221e-02,  3.7047e-02,  7.4228e-03, -2.4634e-02,  1.4533e-02,\n",
      "         3.8678e-04, -2.8698e-03, -1.7634e-03, -1.2346e-03, -2.9588e-02,\n",
      "        -7.1912e-03,  1.0006e-02, -1.4651e-02, -3.3523e-04, -1.6126e-03,\n",
      "         3.5488e-03, -1.1799e-02,  4.9140e-03,  1.7927e-02,  1.1588e-02,\n",
      "         9.9030e-03, -6.5447e-03, -8.4628e-03, -1.5441e-02,  1.2591e-02,\n",
      "         8.0972e-03,  9.2878e-03, -6.1336e-03, -4.2609e-03, -1.0040e-02,\n",
      "        -9.2174e-03,  1.7330e-02,  1.9228e-02, -1.7514e-02,  2.4081e-02,\n",
      "        -2.1564e-04,  5.2537e-03, -9.6121e-03,  4.7490e-03, -1.5037e-03,\n",
      "        -6.5320e-03, -1.6784e-02, -8.4256e-03, -3.6671e-03,  1.1887e-02,\n",
      "        -1.5550e-03, -1.3659e-02, -7.7516e-03, -8.7428e-03,  8.1074e-03,\n",
      "         1.8434e-02,  3.3444e-03, -9.9003e-03, -3.1829e-02, -1.1014e-02,\n",
      "        -3.8633e-03,  1.2602e-02, -2.8536e-02,  7.9035e-03, -2.9467e-04,\n",
      "        -1.7588e-02, -4.9199e-04, -1.6305e-03,  9.3750e-03,  5.8566e-03,\n",
      "        -2.9577e-02, -2.1163e-02, -1.1634e-02, -1.9162e-02,  2.7782e-06,\n",
      "         8.6303e-04,  1.9287e-02, -2.0351e-02, -1.2361e-02, -9.0025e-03,\n",
      "        -1.7022e-02,  1.2601e-02,  2.7546e-02,  3.7237e-03,  9.7523e-03,\n",
      "        -2.6961e-03,  1.4066e-02, -6.4748e-03, -3.5970e-03,  3.8545e-03,\n",
      "        -6.4690e-03, -9.0666e-03, -5.7444e-03,  8.3783e-03], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-1.1973e-01]],\n",
      "\n",
      "         [[ 3.8572e-01]],\n",
      "\n",
      "         [[-2.0428e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3947e-01]],\n",
      "\n",
      "         [[ 3.0316e-04]],\n",
      "\n",
      "         [[-4.7981e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7040e-01]],\n",
      "\n",
      "         [[ 4.2220e-01]],\n",
      "\n",
      "         [[ 2.6227e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.8838e-01]],\n",
      "\n",
      "         [[-4.5502e-02]],\n",
      "\n",
      "         [[ 1.9355e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1762e-01]],\n",
      "\n",
      "         [[-8.7236e-02]],\n",
      "\n",
      "         [[ 4.0713e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3893e-01]],\n",
      "\n",
      "         [[-1.5001e-01]],\n",
      "\n",
      "         [[-2.2771e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.1717e-01]],\n",
      "\n",
      "         [[ 1.4376e-01]],\n",
      "\n",
      "         [[-7.2915e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7011e-01]],\n",
      "\n",
      "         [[-3.2438e-01]],\n",
      "\n",
      "         [[ 2.3274e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2454e-01]],\n",
      "\n",
      "         [[-6.0063e-01]],\n",
      "\n",
      "         [[ 2.1859e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6456e-01]],\n",
      "\n",
      "         [[ 1.4576e-01]],\n",
      "\n",
      "         [[-3.2886e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6900e-03]],\n",
      "\n",
      "         [[-1.1031e-01]],\n",
      "\n",
      "         [[ 1.3528e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6585e-01]],\n",
      "\n",
      "         [[ 4.3504e-01]],\n",
      "\n",
      "         [[ 1.0742e-01]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([1.0864, 1.0521, 1.6052,  ..., 1.5311, 1.4856, 0.9897], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1347, -1.2392, -0.3618,  ..., -0.9194,  0.1922, -1.5559],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-1.4144e-01, -3.1884e-02, -6.9614e-02],\n",
      "          [-1.6329e-01,  7.5277e-05,  1.3264e-01],\n",
      "          [ 3.3854e-01,  4.1664e-01,  6.7353e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3735e-02, -7.1496e-02,  1.2619e-02],\n",
      "          [-1.3178e-01,  1.0757e-01,  5.6491e-01],\n",
      "          [ 2.6886e-01,  5.5341e-01,  7.2856e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7138e-01,  4.5069e-02,  1.5946e-01],\n",
      "          [ 9.7867e-01,  1.0167e-01,  5.8214e-01],\n",
      "          [ 3.0916e-01,  1.2206e-01,  2.2541e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.9940e-01,  9.0328e-03,  3.1285e-01],\n",
      "          [ 2.9484e-01,  1.4437e-01,  2.7128e-01],\n",
      "          [ 5.9301e-01,  3.0085e-01,  2.6141e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.4734e-01, -2.6557e-01, -5.3961e-01],\n",
      "          [ 2.4412e-01,  1.1320e-01,  7.5773e-02],\n",
      "          [ 1.4461e-01,  2.9967e-01, -1.6837e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.9641e-01, -5.3250e-01, -6.2803e-02],\n",
      "          [-7.2753e-02,  1.2664e-01, -2.5599e-01],\n",
      "          [ 7.4828e-03,  1.0895e-01,  1.9662e-01]]]], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.9971, 1.4989, 1.4002,  ..., 0.9985, 0.1209, 0.7359], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.3196, -0.9757, -0.5904,  ..., -0.0844, -0.0237, -0.1640],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.3016]],\n",
      "\n",
      "         [[-0.2179]],\n",
      "\n",
      "         [[-0.0345]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1164]],\n",
      "\n",
      "         [[-0.0300]],\n",
      "\n",
      "         [[ 0.1857]]],\n",
      "\n",
      "\n",
      "        [[[-0.2485]],\n",
      "\n",
      "         [[-0.8419]],\n",
      "\n",
      "         [[-0.0145]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3475]],\n",
      "\n",
      "         [[-0.3686]],\n",
      "\n",
      "         [[-0.2560]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1049]],\n",
      "\n",
      "         [[-0.0141]],\n",
      "\n",
      "         [[ 0.4660]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3407]],\n",
      "\n",
      "         [[-0.0733]],\n",
      "\n",
      "         [[-0.4438]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2916]],\n",
      "\n",
      "         [[-0.3290]],\n",
      "\n",
      "         [[-0.2164]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.8497]],\n",
      "\n",
      "         [[ 0.1324]],\n",
      "\n",
      "         [[-0.0839]]],\n",
      "\n",
      "\n",
      "        [[[-0.2828]],\n",
      "\n",
      "         [[ 0.3078]],\n",
      "\n",
      "         [[ 0.5174]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0031]],\n",
      "\n",
      "         [[-0.0762]],\n",
      "\n",
      "         [[-0.1299]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2444]],\n",
      "\n",
      "         [[-0.0533]],\n",
      "\n",
      "         [[-0.1309]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1361]],\n",
      "\n",
      "         [[-0.1696]],\n",
      "\n",
      "         [[ 0.0075]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.1244, -0.2470, -0.0620,  0.0041,  0.3016, -0.2372, -0.0876, -0.4156,\n",
      "        -0.0494, -0.3886,  0.2065, -0.0743,  0.0047,  0.1135, -0.1474, -0.0811,\n",
      "        -0.5486, -0.2857,  0.2420, -0.3106, -0.3903,  0.3364, -0.4616, -0.3904,\n",
      "        -0.3301, -0.0374, -0.1941, -0.2829, -0.3386, -0.3554,  0.3238, -0.1229,\n",
      "        -0.1344, -0.1627, -0.4860, -0.2899,  0.2850, -0.1988, -0.2003, -0.3931,\n",
      "        -0.1509, -0.0107,  0.0051, -0.2843, -0.2688,  0.3942, -0.1208,  0.2615,\n",
      "        -0.5018, -0.2237, -0.1963, -0.3815, -0.2930, -0.3915, -0.3453, -0.4455,\n",
      "        -0.2031, -0.3705, -0.1054, -0.2064, -0.2038, -0.0660,  0.2490, -0.2920,\n",
      "        -0.1364, -0.1626, -0.2850, -0.1743, -0.5116,  0.2104, -0.1383, -0.3585,\n",
      "        -0.4109, -0.0123, -0.3842, -0.1377, -0.3092, -0.2336,  0.4812,  0.2394,\n",
      "        -0.1304, -0.0610, -0.2235, -0.1070, -0.1471, -0.0259, -0.2403, -0.1335,\n",
      "        -0.2137, -0.3561,  0.4633, -0.1845, -0.2235,  0.1258,  0.3657, -0.3746],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.0103]],\n",
      "\n",
      "         [[-0.1095]],\n",
      "\n",
      "         [[ 0.0635]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0673]],\n",
      "\n",
      "         [[-0.3217]],\n",
      "\n",
      "         [[ 0.0635]]],\n",
      "\n",
      "\n",
      "        [[[-0.1912]],\n",
      "\n",
      "         [[ 0.5454]],\n",
      "\n",
      "         [[ 0.6470]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2398]],\n",
      "\n",
      "         [[ 0.1991]],\n",
      "\n",
      "         [[ 0.3075]]],\n",
      "\n",
      "\n",
      "        [[[-0.0659]],\n",
      "\n",
      "         [[-0.0550]],\n",
      "\n",
      "         [[-0.1360]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1487]],\n",
      "\n",
      "         [[ 0.0068]],\n",
      "\n",
      "         [[-0.0628]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1153]],\n",
      "\n",
      "         [[-0.0819]],\n",
      "\n",
      "         [[ 0.1381]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1759]],\n",
      "\n",
      "         [[-0.4438]],\n",
      "\n",
      "         [[ 0.0441]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1679]],\n",
      "\n",
      "         [[ 0.0747]],\n",
      "\n",
      "         [[ 0.2316]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1195]],\n",
      "\n",
      "         [[ 0.1648]],\n",
      "\n",
      "         [[ 0.2690]]],\n",
      "\n",
      "\n",
      "        [[[-0.0726]],\n",
      "\n",
      "         [[ 0.0057]],\n",
      "\n",
      "         [[ 0.1220]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0124]],\n",
      "\n",
      "         [[-0.1847]],\n",
      "\n",
      "         [[-0.0981]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-0.3351, -0.0319, -0.1267,  ..., -0.0859, -0.0780, -0.1265],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[-0.1313]],\n",
      "\n",
      "         [[ 0.1202]],\n",
      "\n",
      "         [[ 0.0628]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1080]],\n",
      "\n",
      "         [[-0.3100]],\n",
      "\n",
      "         [[-0.0121]]],\n",
      "\n",
      "\n",
      "        [[[-0.1115]],\n",
      "\n",
      "         [[ 0.4689]],\n",
      "\n",
      "         [[-0.0068]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1138]],\n",
      "\n",
      "         [[-0.2194]],\n",
      "\n",
      "         [[ 0.0390]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2709]],\n",
      "\n",
      "         [[ 0.1200]],\n",
      "\n",
      "         [[-0.0150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0148]],\n",
      "\n",
      "         [[ 0.1050]],\n",
      "\n",
      "         [[-0.0091]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0416]],\n",
      "\n",
      "         [[ 0.3343]],\n",
      "\n",
      "         [[-0.0047]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0053]],\n",
      "\n",
      "         [[ 0.0634]],\n",
      "\n",
      "         [[ 0.0168]]],\n",
      "\n",
      "\n",
      "        [[[-0.0387]],\n",
      "\n",
      "         [[ 0.5308]],\n",
      "\n",
      "         [[-0.0166]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0481]],\n",
      "\n",
      "         [[ 0.4378]],\n",
      "\n",
      "         [[ 0.0636]]],\n",
      "\n",
      "\n",
      "        [[[-0.0219]],\n",
      "\n",
      "         [[-0.2499]],\n",
      "\n",
      "         [[-0.0342]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0066]],\n",
      "\n",
      "         [[-0.2570]],\n",
      "\n",
      "         [[ 0.1149]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([0.9631, 0.6878, 0.5954, 0.7374, 1.3161, 1.1651, 1.2875, 1.5540, 0.5475,\n",
      "        0.8218, 0.8487, 1.2204, 1.0313, 1.2386, 0.7734, 1.4614, 0.7136, 0.9621,\n",
      "        0.8260, 0.7886, 0.9002, 1.1176, 1.3693, 0.7496, 1.3301, 1.0387, 1.3133,\n",
      "        0.9660, 0.6747, 0.7806, 0.8657, 1.3569, 2.4648, 0.7938, 0.6760, 0.5831,\n",
      "        0.5945, 1.3482, 1.2935, 1.7468, 0.9740, 0.7449, 1.4374, 1.1120, 1.2331,\n",
      "        0.7774, 1.1172, 1.5087, 0.8214, 0.7463, 0.9067, 0.8941, 1.1457, 0.9418,\n",
      "        1.6973, 0.7191, 1.2330, 1.0629, 0.9926, 0.7828, 1.2039, 0.9547, 0.9546,\n",
      "        1.6370, 0.8270, 0.6570, 1.0013, 1.5645, 1.1274, 0.9550, 0.7960, 0.7412,\n",
      "        1.5797, 2.2705, 0.5705, 0.8496, 0.9056, 1.5002, 1.1162, 0.7552, 0.6018,\n",
      "        1.2215, 1.3563, 1.3000, 1.9204, 0.9043, 0.5658, 0.6611, 1.0665, 0.9451,\n",
      "        0.4696, 0.9099, 0.7495, 0.9915, 0.6986, 0.9790, 1.0901, 0.9324, 0.8456,\n",
      "        1.1898, 0.8638, 0.9652, 0.8524, 0.6057, 1.3896, 1.0616, 1.2668, 0.9963,\n",
      "        1.3852, 1.7475, 0.7045, 1.1770, 0.8877, 0.7592, 0.9081, 0.9729, 0.9628,\n",
      "        1.7455, 0.8592, 0.7563, 0.8416, 0.9490, 1.1542, 0.8654, 1.1309, 0.8689,\n",
      "        0.6510, 0.8493, 1.3722, 0.7607, 1.5888, 0.7296, 1.3518, 1.0305, 1.3774,\n",
      "        1.0205, 0.7129, 0.6822, 1.0280, 1.0749, 1.5566, 0.9596, 1.0167, 1.4954,\n",
      "        1.1439, 0.7909, 1.0097, 0.9058, 0.9930, 1.2002, 0.8793, 0.7405, 1.1543,\n",
      "        1.6479, 0.7680, 0.7556, 1.2527, 1.1076, 0.9597, 1.5958, 1.0068, 0.9654,\n",
      "        0.8934, 1.0033, 0.7272, 1.0583, 1.0228, 1.3634, 0.5517, 0.9796, 0.8418,\n",
      "        1.4679, 1.0574, 0.6537, 0.9789, 1.5763, 1.1920, 1.4218, 0.7504, 1.3737,\n",
      "        0.1492, 1.3677, 0.9561, 1.0718, 1.2231, 0.7890, 0.6154, 0.9747, 0.4708,\n",
      "        0.9722, 0.8287, 1.0156, 0.6470, 1.4011, 1.4692, 0.9380, 0.9543, 1.1765,\n",
      "        1.8416, 0.8113, 1.1400, 0.9275, 1.3366, 0.6513, 0.8879, 0.9569, 1.1293,\n",
      "        0.6246, 1.1395, 0.9964, 1.0232, 0.8766, 0.9539, 0.9211, 1.4067, 1.3155,\n",
      "        0.8827, 1.2641, 0.8739, 1.3104, 1.3407, 0.8979, 0.9808, 0.9392, 1.6008,\n",
      "        1.0169, 1.1285, 0.8916, 1.6369, 1.3634, 1.1423, 0.9460, 0.8323, 1.2255,\n",
      "        0.5441, 0.9832, 0.7071, 0.9613, 0.8060, 1.0235, 1.1197, 1.2345, 0.5578,\n",
      "        0.8893, 1.0911, 1.2802, 1.1468, 0.1219, 0.9553, 0.9370, 0.6329, 1.1885,\n",
      "        0.5073, 0.8595, 0.9652, 0.9008, 0.9573, 1.3734, 0.9140, 0.8455, 1.2796,\n",
      "        0.9608, 0.9907, 1.0906, 1.6033, 0.9936, 0.8050, 1.1807, 0.8403, 0.8631,\n",
      "        1.0157, 0.9191, 0.9363, 1.1910, 0.8495, 0.7462, 0.8368, 0.9754, 0.8838,\n",
      "        1.5993, 0.8204, 1.1160, 1.0078, 1.2100, 1.0590, 1.3632, 0.8920, 1.1304,\n",
      "        1.4435, 0.9857, 1.3047, 1.0285, 1.1465, 1.1503, 0.8869, 0.8216, 1.1138,\n",
      "        0.8163, 0.5863, 1.5694, 0.9983, 0.7941, 1.1153, 1.0279, 0.9370, 0.8593,\n",
      "        0.8582, 1.1285, 0.5730, 0.3785, 0.7047, 1.4852, 0.9543, 0.8153, 1.1088,\n",
      "        0.9276, 1.1130, 1.2452, 1.1410, 1.0908, 1.3505, 1.0206, 0.6125, 1.1659,\n",
      "        1.3559, 1.0431, 0.7543, 1.1688, 1.1433, 1.1705, 0.8038, 1.0719, 1.1795,\n",
      "        0.9872, 0.7772, 1.1578, 0.9501, 1.1343, 0.8991, 1.5942, 0.9320, 0.6979,\n",
      "        0.7943, 1.2382, 1.8207, 1.6824, 1.2101, 0.9290, 0.8603, 0.9975, 0.8761,\n",
      "        1.3456, 1.1570, 1.0651, 0.8340, 1.3091, 0.8437, 1.0492, 0.9415, 0.8690,\n",
      "        1.2479, 0.8632, 0.9264, 1.0260, 0.7142, 0.8125, 0.8957, 0.7400, 1.0480,\n",
      "        0.9793, 1.0243, 0.7201, 0.8825, 1.1871, 0.7249, 1.0771, 1.3173, 0.9791,\n",
      "        0.8599, 0.7764, 0.8136, 1.3649, 1.2637, 0.7288], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-3.0086e-02, -2.1736e-01, -1.2529e-01, -9.4584e-03,  1.1330e-01,\n",
      "        -1.3360e-03, -3.2739e-01,  6.2108e-01, -1.1243e-01, -1.5569e-01,\n",
      "        -1.6002e-02,  4.9374e-02,  8.1915e-02,  1.3072e-01,  5.7655e-02,\n",
      "        -3.6388e-01,  1.7313e-02, -2.6376e-01,  6.6963e-03, -1.5089e-01,\n",
      "         5.6457e-04, -4.0012e-02,  4.6675e-01,  2.7009e-02,  3.8279e-02,\n",
      "        -1.9702e-01,  1.5345e-01, -9.6925e-02, -1.0752e-01, -2.3640e-01,\n",
      "        -1.2079e-01,  2.6338e-02,  5.8267e-01,  1.0307e-01,  1.6513e-01,\n",
      "         1.9428e-02, -2.2964e-01, -1.2830e-01, -2.2897e-01,  2.9738e-01,\n",
      "        -3.4002e-01,  4.7092e-02, -4.8238e-01, -1.7438e-01,  3.4499e-01,\n",
      "        -1.3382e-01,  3.3006e-02, -6.8901e-02, -3.6517e-03,  1.0688e-01,\n",
      "        -1.7128e-02,  3.1775e-01,  1.0234e-01, -2.4464e-01, -3.4142e-02,\n",
      "        -9.7509e-02,  1.3492e-01,  5.8230e-02,  3.2158e-01, -7.0442e-03,\n",
      "        -8.2538e-02,  7.4888e-02, -1.5530e-01, -5.3360e-01, -2.1215e-01,\n",
      "        -1.5794e-01, -3.7638e-02,  9.1030e-02, -5.0558e-02,  9.2824e-03,\n",
      "         2.5489e-01, -2.9528e-01, -8.0103e-02,  1.7486e-01,  2.9711e-01,\n",
      "        -1.1399e-01, -4.3347e-02,  2.0453e-01,  1.2708e-01,  1.1232e-01,\n",
      "        -6.8054e-02, -9.9245e-02,  9.7232e-02,  3.8768e-02, -5.1462e-01,\n",
      "         2.6190e-01, -2.1114e-01,  1.6531e-02, -4.7623e-01,  2.1096e-01,\n",
      "         5.1059e-02,  2.9912e-02, -2.1376e-01,  1.1808e-01,  1.6807e-02,\n",
      "        -1.0952e-01,  1.2623e-01,  6.0436e-02, -6.8854e-03, -6.5562e-01,\n",
      "         2.1237e-02, -1.6649e-02, -6.8032e-02,  3.0153e-02,  1.8871e-01,\n",
      "        -1.3199e-01, -2.1007e-03, -1.8318e-01,  1.1836e-01, -2.2071e-02,\n",
      "         2.7375e-02,  6.7851e-02, -1.5995e-01, -2.5029e-02,  4.4585e-02,\n",
      "        -1.2464e-01, -1.1175e-01, -1.7981e-01,  2.4137e-02, -4.2375e-02,\n",
      "        -9.3033e-02,  1.6717e-01, -3.8049e-01,  1.9237e-01,  5.7825e-02,\n",
      "        -9.7416e-02,  3.4300e-01, -1.9725e-02, -1.1565e-01,  3.1514e-02,\n",
      "        -3.7399e-01, -9.9285e-03, -5.1632e-01, -5.1070e-02, -6.7837e-02,\n",
      "        -4.0964e-02, -1.3602e-01,  7.9960e-02, -1.1946e-01, -2.1333e-01,\n",
      "        -1.2587e-01, -6.4532e-02,  9.8414e-02, -3.9872e-02,  1.2216e-01,\n",
      "         9.7484e-02,  9.2681e-02,  1.1721e-01, -8.4180e-02,  6.6973e-02,\n",
      "         1.5860e-01,  5.8986e-03,  2.9027e-01,  1.1665e-01, -6.3056e-02,\n",
      "         1.8456e-02,  1.0589e-01,  6.3155e-01,  1.2760e-01,  1.2879e-01,\n",
      "         9.3172e-02, -2.8329e-02, -1.3234e-02,  1.1608e-01,  1.1917e-01,\n",
      "        -1.6005e-01, -2.7335e-02, -4.4203e-02,  1.3924e-01,  3.6224e-03,\n",
      "         1.2612e-01,  2.0538e-01,  1.5902e-01,  1.7144e-01,  1.5856e-02,\n",
      "        -4.6817e-01,  3.2328e-01, -8.6946e-02,  1.2598e-01, -1.2950e-01,\n",
      "         7.2908e-02, -1.3846e-02,  1.1201e-01, -9.1867e-02, -3.3803e-02,\n",
      "         1.2210e-01, -3.1962e-03, -4.4655e-02, -3.1715e-02,  3.0721e-02,\n",
      "        -8.6035e-03,  1.3798e-01,  3.3510e-01, -2.8647e-02,  2.8153e-02,\n",
      "         1.0465e-01,  1.4636e-01,  1.2889e-02,  1.6036e-01,  1.2997e-01,\n",
      "         6.4780e-02, -8.8258e-02,  1.1081e-01, -3.6655e-02,  4.7145e-02,\n",
      "        -6.8892e-02, -1.1665e-01,  1.1746e-01,  2.6427e-01,  5.3302e-02,\n",
      "        -1.3760e-01, -2.0369e-02, -3.2949e-02, -7.9633e-02, -1.2186e-01,\n",
      "        -5.4780e-03,  2.7728e-02,  2.4181e-02, -4.4479e-02, -1.4833e-01,\n",
      "         5.1432e-01, -1.6200e-01, -7.8470e-02,  2.2017e-02,  6.5772e-01,\n",
      "        -1.5281e-01,  1.2607e-01, -1.1747e-01,  1.0030e-01,  8.3053e-04,\n",
      "        -1.2036e-01, -1.5389e-01, -2.0801e-01,  4.8792e-02, -2.1484e-01,\n",
      "        -1.1345e-01, -1.6588e-01, -1.2797e-01, -7.9622e-03, -1.0977e-01,\n",
      "        -1.9680e-01, -1.3323e-01, -5.1122e-02, -1.2155e-02, -1.2884e-01,\n",
      "        -4.7111e-02,  3.7552e-01, -1.2739e-01,  2.5570e-01, -2.4766e-01,\n",
      "        -9.2626e-02, -1.2550e-01,  1.2453e-01,  5.2822e-01,  3.1199e-01,\n",
      "         3.7949e-02, -4.0249e-02, -3.0078e-02,  1.0164e-01, -6.9022e-03,\n",
      "         2.7251e-01, -1.0735e-01, -3.4737e-02, -4.9363e-02, -9.7898e-03,\n",
      "        -3.4101e-01, -8.6172e-03, -2.4519e-02,  5.1592e-02, -1.7930e-02,\n",
      "         1.6245e-01,  9.3876e-02,  1.3454e-01,  1.4986e-01, -8.9830e-02,\n",
      "        -8.1997e-02,  1.2679e-01,  5.9230e-02,  1.5017e-01,  6.5634e-02,\n",
      "         7.5212e-02,  4.1936e-02,  3.0925e-02, -8.9865e-02,  2.4515e-01,\n",
      "         2.9100e-01, -2.5638e-02, -5.3286e-02, -7.5788e-03,  6.7221e-02,\n",
      "        -1.6575e-01, -7.0683e-02, -1.0520e-02, -1.0996e-01,  4.2846e-02,\n",
      "         2.4287e-02, -1.6409e-01, -1.9320e-01, -2.4654e-01,  3.3507e-02,\n",
      "         2.1997e-02, -2.0101e-02, -2.1401e-01, -1.8076e-01,  3.1757e-01,\n",
      "        -1.4269e-01, -7.2692e-03, -2.1405e-03, -2.6301e-02, -1.2040e-02,\n",
      "        -1.3160e-01,  2.9090e-01,  1.7731e-02, -1.3298e-01,  1.5365e-01,\n",
      "        -7.7651e-03,  1.3866e-01,  8.9428e-02,  3.9709e-01, -2.0845e-01,\n",
      "        -5.4684e-02, -1.4223e-01, -9.2859e-03,  5.9381e-02,  3.8662e-02,\n",
      "         2.8717e-02,  2.1554e-02, -1.9467e-02, -4.3194e-02, -3.0781e-03,\n",
      "        -1.9261e-01, -2.0131e-01,  4.3190e-03, -8.4238e-02, -1.1396e-01,\n",
      "         8.2431e-02,  1.4621e-02, -9.7177e-02, -9.2320e-02, -3.0410e-01,\n",
      "        -9.0893e-02,  5.7469e-02,  1.3395e-01,  6.2997e-01, -1.7595e-01,\n",
      "        -5.3581e-01, -3.0065e-01,  5.6684e-02,  2.1884e-01, -1.1415e-01,\n",
      "         8.5147e-02, -1.4623e-03, -9.6243e-02,  2.8373e-02,  1.6626e-01,\n",
      "         8.5405e-01, -3.3346e-02,  1.5566e-02, -3.0412e-02, -2.2809e-01,\n",
      "        -2.7330e-01, -6.9349e-03, -2.9782e-02, -2.9724e-02,  4.3579e-02,\n",
      "         3.7501e-02,  1.9089e-01, -2.1880e-02,  3.1438e-02,  7.0048e-02,\n",
      "         3.5066e-02, -1.3019e-01,  2.7973e-02, -6.6611e-02, -1.5988e-02,\n",
      "        -4.1912e-03,  8.5759e-03,  7.7840e-02,  4.4311e-02,  7.3055e-02,\n",
      "         3.8231e-02,  3.4585e-01, -3.1907e-02, -9.0106e-02], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[[[ 0.7099]],\n",
      "\n",
      "         [[-0.1066]],\n",
      "\n",
      "         [[-0.6843]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5506]],\n",
      "\n",
      "         [[-0.1999]],\n",
      "\n",
      "         [[ 0.2234]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1136]],\n",
      "\n",
      "         [[-0.0812]],\n",
      "\n",
      "         [[-0.5348]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7203]],\n",
      "\n",
      "         [[-0.6744]],\n",
      "\n",
      "         [[-0.0079]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2934]],\n",
      "\n",
      "         [[ 0.0057]],\n",
      "\n",
      "         [[-0.1512]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1348]],\n",
      "\n",
      "         [[ 0.0709]],\n",
      "\n",
      "         [[ 0.3077]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0115]],\n",
      "\n",
      "         [[ 0.2468]],\n",
      "\n",
      "         [[ 0.0040]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1937]],\n",
      "\n",
      "         [[-0.3878]],\n",
      "\n",
      "         [[ 0.1477]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3255]],\n",
      "\n",
      "         [[ 0.1591]],\n",
      "\n",
      "         [[-0.4582]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0440]],\n",
      "\n",
      "         [[-0.1161]],\n",
      "\n",
      "         [[ 0.2523]]],\n",
      "\n",
      "\n",
      "        [[[-0.0381]],\n",
      "\n",
      "         [[-0.1592]],\n",
      "\n",
      "         [[-0.0769]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5263]],\n",
      "\n",
      "         [[-0.5194]],\n",
      "\n",
      "         [[ 0.2096]]]], device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([2.3625, 2.0067, 1.9790,  ..., 1.7114, 2.3850, 1.8828], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([-1.8361, -1.4299, -1.3250,  ..., -1.0615, -1.9246, -1.1077],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([[-0.0414, -0.0119,  0.0430,  ...,  0.1375,  0.0765,  0.0998],\n",
      "        [-0.0159,  0.1403,  0.1239,  ...,  0.1446,  0.2251,  0.0785],\n",
      "        [ 0.0356, -0.0695, -0.3301,  ..., -0.1959,  0.0301, -0.0407],\n",
      "        [-0.0571, -0.0750, -0.1119,  ..., -0.0870, -0.1788, -0.0823],\n",
      "        [-0.0785,  0.1393,  0.2611,  ..., -0.0239,  0.0595, -0.0240],\n",
      "        [ 0.2094, -0.0465,  0.1615,  ...,  0.1133,  0.1832,  0.1312]],\n",
      "       device='cuda:0', requires_grad=True); skipping it\n",
      "  warnings.warn(\n",
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\torchcontrib\\optim\\swa.py:190: UserWarning: SWA wasn't applied to param Parameter containing:\n",
      "tensor([ 0.0006, -0.3141,  0.1087,  0.0952, -0.0914, -0.0323], device='cuda:0',\n",
      "       requires_grad=True); skipping it\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Model\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Epoch : [1] loss : 0.405\n",
      "Epoch : [2] loss : 0.281\n",
      "Epoch : [3] loss : 0.239\n",
      "Epoch : [4] loss : 0.198\n",
      "Epoch : [5] loss : 0.167\n",
      "Epoch : [6] loss : 0.143\n",
      "Epoch : [7] loss : 0.118\n",
      "Epoch : [8] loss : 0.100\n",
      "Epoch : [9] loss : 0.091\n",
      "Epoch : [10] loss : 0.078\n",
      "Epoch : [11] loss : 0.072\n",
      "Epoch : [12] loss : 0.068\n",
      "Epoch : [13] loss : 0.060\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12960/2169162385.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mlr_sched\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch : [%d] loss : %.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Ensemble 적용\n",
    "# 연속해서 계속 더하는 방식으로 진행해야 함\n",
    "ensemble_array = []\n",
    "for i in range(4):\n",
    "    print(f'{i+1} Model')\n",
    "    model = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "    model._fc = nn.Linear(model._fc.in_features, 6)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    lr_sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0.001, last_epoch=-1)\n",
    "    opt = SWA(optimizer)\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    for ep in range(1, 60):\n",
    "        running_loss = 0.0\n",
    "        for data in trainloader:\n",
    "            image, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(image)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            running_loss += loss.item()\n",
    "        lr_sched.step()\n",
    "        print('Epoch : [%d] loss : %.3f' % (ep, running_loss / len(trainloader)))\n",
    "    \n",
    "    opt.swap_swa_sgd()\n",
    "    opt.swap_swa_sgd()\n",
    "    \n",
    "    predicted = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data in testloader:\n",
    "            outputs = model(data.to(device))\n",
    "            predicted += outputs.cpu()\n",
    "    \n",
    "    ensemble_array.append(predicted)\n",
    "    \n",
    "    pred = torch.zeros(2999, 6)\n",
    "    for ensem in ensemble_array:\n",
    "        for jp, en in enumerate(ensem):\n",
    "            pred[jp] += en\n",
    "    \n",
    "    pred = pred / len(ensemble_array)\n",
    "    _, predict = torch.max(pred, 1)\n",
    "    \n",
    "    array = label_encoder.inverse_transform(predict)\n",
    "    array.reshape(len(array) , 1)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        \"image\" : test_df['image'],\n",
    "        \"label\" : array\n",
    "    })\n",
    "    \n",
    "    submission.to_csv(f'efff_count{i+1}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "701a22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for data in testloader:\n",
    "        outputs = model(data.to(device))\n",
    "        predicted += outputs.cpu()\n",
    "    \n",
    "    ensemble_array.append(predicted)\n",
    "    \n",
    "    pred = torch.zeros(2999, 6)\n",
    "    for ensem in ensemble_array:\n",
    "        for jp, en in enumerate(ensem):\n",
    "            pred[jp] += en\n",
    "    \n",
    "    pred = pred / len(ensemble_array)\n",
    "    _, predict = torch.max(pred, 1)\n",
    "    \n",
    "    array = label_encoder.inverse_transform(predict)\n",
    "    array.reshape(len(array) , 1)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        \"image\" : test_df['image'],\n",
    "        \"label\" : array\n",
    "    })\n",
    "    \n",
    "    submission.to_csv(f'efff_count1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aac8bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.zeros(2999, 6)\n",
    "for ensem in ensemble_array:\n",
    "    for i, en in enumerate(ensem):\n",
    "        pred[i] += en\n",
    "pred = pred/4\n",
    "_, predict = torch.max(pred, 1)\n",
    "array = label_encoder.inverse_transform(predict)\n",
    "array.reshape(len(array), 1)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"image\" : test_df['image'],\n",
    "    'label' : array\n",
    "})\n",
    "\n",
    "submission.to_csv('effi3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "716a40cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ensemble_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "976800b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -1.8475,   5.0942,  -7.6548, -13.3824, -15.1757,  -2.2182],\n",
      "        [ -4.1651, -32.6009, -17.6570, -16.8526, -12.4342,   0.3358],\n",
      "        [ -5.0877,   7.7175,  -2.2342,  -7.1096, -13.5485,  -7.0840],\n",
      "        [  6.8462, -30.0660, -22.7014, -23.7308, -17.5268,   5.5991],\n",
      "        [  0.6871, -19.5490,  -3.7956,  -7.3334,  -3.9915, -11.3906],\n",
      "        [ -0.2169, -11.2033,  -9.4602,  -8.1970, -13.5689,  -7.6913],\n",
      "        [ -6.0467, -33.9441,  12.7885,  -4.7089, -18.9170, -12.8843],\n",
      "        [-10.4018, -18.1524,   9.1608,  -9.4386,   0.3697,  -9.4445],\n",
      "        [ -5.4801,  11.4644,  -0.8701, -11.7897, -10.2636,  -6.2561],\n",
      "        [ -4.9319,   8.7122,  -4.7535, -10.9694,  -8.4948,  -2.8923],\n",
      "        [ -2.1003,  -2.4019, -13.4432, -15.0787, -12.2403,   2.6391],\n",
      "        [-17.9104, -25.0116,  12.7905, -12.3737,   0.6863,  -8.7606],\n",
      "        [ -6.6551,  -4.2869,  -5.1904,  -0.2691,   3.8746,  -8.2089],\n",
      "        [-13.0304, -11.3614,  -3.0795, -23.6867, -15.2502,   9.6999],\n",
      "        [  2.5504, -23.0938, -19.3281, -16.5663, -15.0532,   5.7130],\n",
      "        [ -6.5406,  -8.9797,   3.1712,  -9.2328,  -8.1461,  -7.4672],\n",
      "        [ -5.7008, -17.1660,   2.2774,   7.4007, -11.7600, -14.9355],\n",
      "        [ -4.2074, -13.0818, -15.2949, -19.3129, -11.6735,   6.3357],\n",
      "        [ -4.0203,  -6.4695,  -3.2116,  -5.8321,  -4.3908,  -3.6813],\n",
      "        [ -6.1371, -15.6597,  -1.8410,   5.8444,  -1.2032, -16.0477],\n",
      "        [ -8.0108, -15.8887,  -3.1603,  10.3777, -14.0652, -11.7548],\n",
      "        [ 19.0693, -53.9338, -22.6012, -30.1740, -13.7639,  -3.1562],\n",
      "        [ -8.1488, -10.7532,  -4.7957,  -0.5535,   3.3163, -14.1622],\n",
      "        [ -9.2237,  -5.2662,  -6.1217,   0.1944,   2.9306,  -6.6058],\n",
      "        [ 10.5822,  -9.9200, -18.6796, -25.5745, -28.1042,   0.7723],\n",
      "        [ -8.4320, -14.2905,   5.2073, -10.2161,   3.4171,  -6.4037],\n",
      "        [  4.2823,  -5.3803, -11.0061, -16.8118, -15.6843,  -4.4433],\n",
      "        [ -2.8757, -13.5463,  -7.2582, -12.2555,  -7.8994,   1.0677],\n",
      "        [ 12.8616, -30.8151, -24.0405, -16.2973,  -3.9758, -10.6305],\n",
      "        [ -1.7806,  13.1292, -13.0559, -15.7214, -23.8793,  -5.5063],\n",
      "        [ -8.2254,  -0.2055,  -3.5669,   3.5930,   0.7091, -10.9771],\n",
      "        [ -0.5657,   6.6933,  -9.2154,  -8.5768, -15.0251,  -5.1158]],\n",
      "       device='cuda:0')\n",
      "tensor([1, 5, 1, 0, 0, 0, 2, 2, 1, 1, 5, 2, 4, 5, 5, 2, 3, 5, 2, 3, 3, 0, 4, 4,\n",
      "        0, 2, 0, 5, 0, 1, 3, 1], device='cuda:0')\n",
      "tensor([[  6.5561, -23.4428, -14.8622,  -3.9032,  -1.7267, -12.7235],\n",
      "        [ -9.2833,  -9.7017,  -1.6086,   1.9349,   1.9873, -12.1044],\n",
      "        [-13.8379, -10.4513,   3.7931,  -8.0996,  -0.8523,  -6.5685],\n",
      "        [ -7.1530, -17.2284, -25.3901, -24.2645, -21.6443,   0.9592],\n",
      "        [ -3.9998, -14.3245,  -0.1892,   4.5527,  -8.8793, -15.8329],\n",
      "        [  1.6066, -21.8875, -12.5366, -23.9158, -15.3624,   6.3124],\n",
      "        [ -7.8758, -16.9863,   1.3599,   9.3242, -12.0211, -18.2464],\n",
      "        [-10.7210,  -4.7553, -12.9418, -15.3639, -17.0993,   5.7782],\n",
      "        [ -5.8315, -11.4514,  -0.3301,   7.2723,  -8.9849, -11.3240],\n",
      "        [ -9.5097,  -9.1616,  -1.4108,   7.6471,  -3.0312, -11.2412],\n",
      "        [ -7.8175, -13.4560,  -8.5662,  -5.8200,  14.8724, -12.6112],\n",
      "        [ -7.8794,  10.1653,  -5.6104,  -9.8173,  -4.2737,  -8.1296],\n",
      "        [ -4.6364,   8.9214,   0.2860,  -9.2966,  -9.0475,  -7.9256],\n",
      "        [-10.9869, -18.0347,  -3.2385, -14.0061,  13.4754,  -5.9157],\n",
      "        [-14.8647, -17.6885, -26.4724, -25.2339, -22.2603,   3.0609],\n",
      "        [ -5.2191, -19.4812,  -1.8438,   9.6575, -11.6227, -17.5620],\n",
      "        [ -5.0413,  15.0483,  -9.4700, -11.6536, -18.6768,  -5.3071],\n",
      "        [ -5.3991,  15.6006,  -5.8876, -15.7528, -17.6201,  -5.1121],\n",
      "        [  0.0697,  -2.1098,  -8.7354, -11.8357, -11.6653,  -5.1274],\n",
      "        [ -1.7794,  10.2289,  -9.8572, -11.9348, -14.9732,  -1.9062],\n",
      "        [ -2.7818, -21.1274, -21.8260, -21.4581, -13.1558,  -1.2258],\n",
      "        [  1.5803,   2.2482, -17.1880,  -6.7361,  -8.0209,  -4.6381],\n",
      "        [ -9.6458, -20.4197,   7.5460,   4.9021,  -8.3790, -15.0204],\n",
      "        [-12.4516, -17.4780,   5.0937,  -8.4998,   4.4467, -11.2200],\n",
      "        [ -7.4361, -15.7742,   3.5222,   5.4715, -10.7769, -14.8151],\n",
      "        [ -7.6648, -10.1210,  -2.7069,  12.3074, -16.5204, -15.6527],\n",
      "        [ -6.8509, -10.5634,   2.6779,   4.1427, -11.9249, -10.9963],\n",
      "        [  4.7232, -12.9821, -15.0647, -10.7756,  -2.0358,  -8.7464],\n",
      "        [  0.9411, -18.3216,  -3.8985,   4.9533,  -6.2655, -16.9380],\n",
      "        [ -4.4078,   3.5046,  -4.3534, -11.9754,  -8.9337,  -2.8874],\n",
      "        [ -7.7412,  11.2553,  -5.1741,  -8.8315, -12.6457,  -7.2539],\n",
      "        [-10.6758,  -9.0082,   1.9259,  -0.9973,  -5.6320,  -7.3051]],\n",
      "       device='cuda:0')\n",
      "tensor([0, 4, 2, 5, 3, 5, 3, 5, 3, 3, 4, 1, 1, 4, 5, 3, 1, 1, 0, 1, 5, 1, 2, 2,\n",
      "        3, 3, 3, 0, 3, 1, 1, 2], device='cuda:0')\n",
      "tensor([[-13.1668,  -9.4161,   2.2375,   3.0588,  -9.5658,  -5.2770],\n",
      "        [ -6.5135,  -9.4496,  -5.8332,  -6.5633,   6.6343,  -5.6113],\n",
      "        [-11.1659, -17.4032,  10.9365, -11.3892,  -6.8040, -10.6222],\n",
      "        [  2.4801, -37.9244, -25.7186, -25.1148, -13.9390,  11.5996],\n",
      "        [ -1.5727,   5.5517,  -6.2782,  -6.0869,  -7.2810,  -0.3632],\n",
      "        [ -3.1180,   7.2850,  -5.7599,  -8.4864, -11.7711,  -4.0793],\n",
      "        [-16.7562, -17.7050,  12.2778,  -7.4960,  -1.9516,  -7.4390],\n",
      "        [ -7.3437, -21.0450, -14.7268, -21.5318, -16.5107,  10.7181],\n",
      "        [-11.8624, -27.9698,  13.5979,   0.3006, -15.0824, -13.5901],\n",
      "        [ -5.4485,   8.5537,  -6.0621, -15.7112,  -9.2908,  -4.7986],\n",
      "        [ -9.9877, -11.2781,   0.4621,  -1.7032,  -2.6289,  -7.3178],\n",
      "        [-11.1333, -23.0104, -19.0613, -21.9700, -12.7785,   5.9895],\n",
      "        [ -2.5309,   9.8886,  -7.7099, -14.0635, -17.1295,  -2.8713],\n",
      "        [ -7.6018,  -8.2967,  -4.5339,  12.1064,  -4.0561, -19.9499],\n",
      "        [ -6.8622, -13.8748,  -1.8124,  11.3500,  -8.3010, -15.4478],\n",
      "        [-12.8957,  -8.1851,   4.4098,  -5.0842,  -1.7016,  -8.1977],\n",
      "        [-10.8053, -24.8487,   9.1872,   2.7395, -14.0896, -12.7150],\n",
      "        [ -2.0091,  11.7531, -10.8915, -16.6277, -21.3715,  -1.3675],\n",
      "        [  3.5226, -18.5133, -12.9976, -15.5775,  -7.5827,  -2.8631],\n",
      "        [ -4.2673,   5.9109,  -2.3850, -10.3028,  -7.3015,  -9.2679],\n",
      "        [ -9.2477, -23.6055,  -3.1052, -17.4575,  -4.6653,  -7.4824],\n",
      "        [ -8.1712, -22.1455, -11.4844, -25.1073,  -8.8933,   9.5641],\n",
      "        [ 15.8309, -16.2912, -22.2087, -17.9188, -24.6405, -12.9877],\n",
      "        [ -2.4655, -16.7781, -13.0444, -17.5420, -18.1914,   5.8049],\n",
      "        [ -4.0861,   2.8880,  -3.1042,  -9.7925,  -6.0156,  -8.4120],\n",
      "        [ 10.4892, -31.7579,  -8.3194,  -5.8510,  -7.0525, -15.7667],\n",
      "        [ -2.9571,   7.1591,  -7.1440,  -7.1740, -11.7785,  -3.5419],\n",
      "        [-12.3659, -24.1048,  13.6756,  -5.1357, -14.4205, -15.6544],\n",
      "        [  3.7275, -28.0965, -21.4574, -18.1930, -14.8339,   1.5905],\n",
      "        [ -6.3340, -33.7815,   6.7580,   8.0919, -20.0088, -20.0702],\n",
      "        [ -8.0169,  11.9871,  -5.5837, -13.4500, -12.4169,  -4.1160],\n",
      "        [ -1.0658, -10.1012,  -8.9279, -14.3938,  -8.0336,  -0.2715]],\n",
      "       device='cuda:0')\n",
      "tensor([3, 4, 2, 5, 1, 1, 2, 5, 2, 1, 2, 5, 1, 3, 3, 2, 2, 1, 0, 1, 2, 5, 0, 5,\n",
      "        1, 0, 1, 2, 0, 3, 1, 5], device='cuda:0')\n",
      "tensor([[ -8.1750, -23.1442,   7.0821,   2.1071, -12.4684, -13.0150],\n",
      "        [ -6.3010, -10.5960,  -2.2476,   0.1787,  -2.6210, -11.5731],\n",
      "        [ -8.2076, -14.6709,  -0.4323,   3.1489,  -6.5705,  -9.6783],\n",
      "        [ -1.4347,   9.2852,  -6.1778,  -9.9785, -14.6674,  -5.6158],\n",
      "        [ -5.2648, -13.3771,  -1.8851,  -6.5245,   6.8420, -11.7153],\n",
      "        [ -1.4058,  10.4752, -12.0696, -11.7390, -13.9044,  -0.8869],\n",
      "        [ -7.1199,   2.6121,  -5.1504,   3.1731,  -5.7168,  -5.7041],\n",
      "        [  2.5513,  -5.2059,  -9.5685,  -8.4146,  -5.2531,  -6.5965],\n",
      "        [  6.1845, -13.9204, -15.5927, -14.3006, -12.6511,  -1.7470],\n",
      "        [ -9.9966, -30.6180,  17.4924,  -7.8434, -21.9542, -12.9778],\n",
      "        [  0.7962,  -0.5355, -10.4538, -19.3147, -12.6318,   3.3818],\n",
      "        [ -0.8466,  12.3782, -13.6663, -22.3648, -26.6371,   0.8731],\n",
      "        [ -6.7352, -24.0489, -18.6853, -21.0257, -16.2185,   1.6639],\n",
      "        [  7.7870, -26.5185, -10.3048, -12.3481,  -6.8237, -10.3563],\n",
      "        [ -3.3369,  15.0505, -12.4293, -20.9910, -24.4873,  -2.1325],\n",
      "        [ -9.7388, -10.5838,  -0.6502, -10.1767,  -8.4008,  -0.3288],\n",
      "        [-11.6564, -15.4262,   8.7867,   5.5660, -16.3068, -15.1355],\n",
      "        [ -8.9118, -14.2577, -21.8023, -18.9551, -20.4777,   3.2127],\n",
      "        [  9.4382, -24.4791, -21.2116, -18.2670,  -8.7484,  -0.3955],\n",
      "        [ -9.3580, -25.9507,  13.8223,  -5.3050, -12.8741, -13.9036],\n",
      "        [ -4.2139,  11.5711,  -1.7521, -10.3117, -11.2813,  -8.1820],\n",
      "        [ -8.8891, -18.5699,  -3.8771,   0.9896,  -1.2803,  -8.4856],\n",
      "        [  1.6109, -10.4527,  -9.8873,  -7.7503,  -4.5938,  -4.3490],\n",
      "        [ -7.0386,  -9.6637,  15.0195, -10.9349, -14.8305, -15.9101],\n",
      "        [-12.1040,   7.6521,   1.6138, -14.3269, -14.1724,  -4.5414],\n",
      "        [-12.6089, -16.1324,  10.6497, -15.4817,  -1.2433,  -6.7542],\n",
      "        [  2.8438, -17.4524, -16.5768, -20.7458, -20.3594,   3.8334],\n",
      "        [  1.1016, -33.9154,  -8.0221,  -8.0683, -10.5901,  -7.7186],\n",
      "        [ -5.2718, -10.9937,  -2.4891,   6.5189,  -9.4566, -11.5759],\n",
      "        [ -0.2352, -28.9048, -14.1928, -21.7329, -17.0184,   8.3347],\n",
      "        [-17.0112, -27.7785,  10.7853,  -3.2961, -17.7001,  -7.6760],\n",
      "        [ -6.3061, -15.4855,  -0.4471,  13.8497, -12.4658, -19.0652]],\n",
      "       device='cuda:0')\n",
      "tensor([2, 3, 3, 1, 4, 1, 3, 0, 0, 2, 5, 1, 5, 0, 1, 5, 2, 5, 0, 2, 1, 3, 0, 2,\n",
      "        1, 2, 5, 0, 3, 5, 2, 3], device='cuda:0')\n",
      "tensor([[-3.8136e+00, -2.4118e+01, -1.5275e+01, -2.4578e+01, -2.0147e+01,\n",
      "          9.1045e+00],\n",
      "        [-6.4408e+00, -1.1581e+01, -1.4751e+01, -7.2909e+00, -7.1495e+00,\n",
      "         -1.8625e+00],\n",
      "        [-9.1280e+00, -9.0524e+00, -5.0806e+00,  5.9047e+00,  6.8896e-02,\n",
      "         -1.0279e+01],\n",
      "        [-1.1390e+01, -1.8441e+01,  3.4744e+00, -3.2208e+00, -1.6259e+00,\n",
      "         -1.0158e+01],\n",
      "        [-4.9619e+00, -8.5400e+00, -5.9518e+00,  1.8610e+00,  3.5252e+00,\n",
      "         -7.2256e+00],\n",
      "        [-9.3310e+00,  1.0468e+01, -7.7810e+00, -1.0883e+01, -2.0836e+01,\n",
      "         -1.0734e+00],\n",
      "        [-5.0084e+00, -2.0556e+00, -5.1125e+00, -3.0601e+00, -5.6516e+00,\n",
      "         -1.7238e+00],\n",
      "        [-8.1252e+00, -7.7226e+00, -1.3964e+01, -2.5849e+01, -1.4479e+01,\n",
      "          6.7484e+00],\n",
      "        [ 2.5634e+00, -2.3301e+01, -5.6256e+00, -1.7100e+00, -1.0382e+01,\n",
      "         -1.3943e+01],\n",
      "        [-6.0959e+00, -8.6604e+00, -2.1907e-01,  6.5106e+00, -7.1999e+00,\n",
      "         -1.2618e+01],\n",
      "        [-4.6292e+00,  5.6697e+00, -8.6472e+00, -8.6152e+00, -1.3173e+01,\n",
      "         -5.5920e+00],\n",
      "        [-3.7367e+00, -2.0449e+01, -3.9974e+00, -8.1289e+00,  1.7974e-01,\n",
      "         -1.2656e+01],\n",
      "        [-2.2362e+00, -1.0576e+01, -1.6520e+01, -1.3214e+01, -1.4387e+01,\n",
      "          5.3295e+00],\n",
      "        [-9.4861e+00, -1.7722e+01,  6.0771e+00,  3.6614e+00, -1.2489e+01,\n",
      "         -1.2418e+01],\n",
      "        [-1.1371e+01, -2.1106e+01,  9.4235e+00, -1.1652e-02, -7.8900e+00,\n",
      "         -1.3460e+01],\n",
      "        [-3.3432e+00, -1.0083e+01, -1.1667e+01, -2.0177e+01, -1.9449e+01,\n",
      "          3.1186e+00],\n",
      "        [-1.2464e+01, -1.2108e+01, -7.7087e+00, -5.3445e+00,  4.3757e+00,\n",
      "         -7.2804e+00],\n",
      "        [-7.1827e+00, -1.5561e+01,  8.0361e+00, -7.6276e+00, -1.2836e+01,\n",
      "         -8.0061e+00],\n",
      "        [-9.2129e+00, -1.3786e+01, -8.7179e+00, -3.8754e+00,  9.0200e+00,\n",
      "         -1.1949e+01],\n",
      "        [-1.3862e+01, -1.2790e+01,  6.1831e-01, -8.4006e+00,  2.6558e+00,\n",
      "         -7.0933e+00],\n",
      "        [-1.1957e+01, -2.9348e+01,  1.4262e+01, -4.3158e+00, -1.6478e+01,\n",
      "         -1.3346e+01],\n",
      "        [-6.8248e+00, -1.9564e+01, -1.1092e+01, -1.1794e+01,  1.1829e+01,\n",
      "         -1.0075e+01],\n",
      "        [-7.3912e+00, -7.4674e+00, -2.4884e+00, -7.7845e-01,  6.5535e+00,\n",
      "         -1.0630e+01],\n",
      "        [-1.1614e+01, -1.8393e+01,  7.1869e+00,  3.5962e+00, -1.7319e+01,\n",
      "         -1.0779e+01],\n",
      "        [-1.2032e+01, -1.5898e+01,  1.5325e+01, -1.6869e+01, -1.0299e+01,\n",
      "         -9.8105e+00],\n",
      "        [-1.3280e+01, -1.8005e+01,  1.0938e+01, -8.2552e+00, -6.1772e+00,\n",
      "         -5.7670e+00],\n",
      "        [-3.0428e+00,  2.3743e-01, -1.5136e+00, -6.0283e+00, -1.3932e+01,\n",
      "         -1.0847e+01],\n",
      "        [-3.7468e+00, -1.7041e+01, -2.3550e+01, -2.5142e+01, -2.1468e+01,\n",
      "          1.3813e+01],\n",
      "        [-6.3559e-01, -2.0947e+01,  9.8935e-02,  6.0042e+00, -1.6316e+01,\n",
      "         -1.7244e+01],\n",
      "        [-7.0247e+00, -5.1715e+00, -1.6016e+00,  8.0016e+00, -7.9838e+00,\n",
      "         -1.3908e+01],\n",
      "        [ 6.8336e+00, -3.4442e+01, -1.0939e+01, -1.8676e+01, -1.8927e+01,\n",
      "         -5.5896e+00],\n",
      "        [ 8.6289e-02,  1.7024e-01, -1.8320e+00, -1.5123e+01, -1.1022e+01,\n",
      "         -7.5375e+00]], device='cuda:0')\n",
      "tensor([5, 5, 3, 2, 4, 1, 5, 5, 0, 3, 1, 4, 5, 2, 2, 5, 4, 2, 4, 4, 2, 4, 4, 2,\n",
      "        2, 2, 1, 5, 3, 3, 0, 1], device='cuda:0')\n",
      "tensor([[-1.0639e+01, -2.7035e+01, -4.8160e+00, -1.1228e+01, -1.3317e+01,\n",
      "          8.3510e-01],\n",
      "        [ 1.9641e+00,  1.1474e+01, -1.1143e+01, -1.8147e+01, -2.0106e+01,\n",
      "         -4.5434e+00],\n",
      "        [ 2.0224e+01, -6.0902e+01, -2.0319e+01, -2.1490e+01, -1.6746e+01,\n",
      "         -6.7248e+00],\n",
      "        [-1.0346e+01, -5.1231e+00,  8.9074e+00, -1.3261e+01, -9.0906e+00,\n",
      "         -4.7315e+00],\n",
      "        [ 1.4257e+01, -1.8201e+01, -2.4823e+01, -1.6546e+01, -1.1976e+01,\n",
      "         -1.0804e+01],\n",
      "        [-1.0136e+01, -3.1266e+01,  7.4606e+00,  1.3656e+01, -2.1029e+01,\n",
      "         -2.3201e+01],\n",
      "        [-6.3298e+00, -8.7261e+00, -5.6772e+00, -2.3558e+00,  5.0437e+00,\n",
      "         -5.4570e+00],\n",
      "        [ 7.8770e+00, -2.2400e+01, -1.3281e+01, -1.7258e+01, -1.2073e+01,\n",
      "         -5.4457e+00],\n",
      "        [ 2.2641e+00, -1.3711e+01, -2.8723e+00, -1.7965e+01, -1.0421e+01,\n",
      "         -1.6737e+00],\n",
      "        [-1.2051e+01,  1.8868e+00, -1.4492e+00, -1.0259e+01, -1.1711e+01,\n",
      "         -2.7585e+00],\n",
      "        [ 2.3947e-01, -1.2826e+01, -2.1978e+01, -2.4511e+01, -1.8439e+01,\n",
      "          1.0124e+01],\n",
      "        [-6.8305e+00, -1.7269e+01, -2.0399e+00,  1.6015e+01, -1.5162e+01,\n",
      "         -2.0556e+01],\n",
      "        [-1.1239e+00, -5.4276e+00, -1.1167e+01, -1.1905e+00, -1.1097e+00,\n",
      "         -1.1273e+01],\n",
      "        [-4.9628e+00, -2.4313e+01,  3.8620e+00,  1.3190e+01, -2.3192e+01,\n",
      "         -1.9089e+01],\n",
      "        [-7.5719e+00, -1.2091e+01,  1.7364e+00, -3.1095e+00, -7.6259e+00,\n",
      "         -4.2222e+00],\n",
      "        [ 1.1727e+00, -7.0101e+00, -1.1626e+01, -1.0705e+01, -3.2660e+00,\n",
      "         -3.7898e+00],\n",
      "        [-2.1989e+00, -1.7121e+01, -7.3999e+00, -1.2397e+01, -1.6230e+01,\n",
      "         -4.6234e+00],\n",
      "        [-3.5599e+00,  1.1183e+01, -1.0476e+01, -1.1652e+01, -1.4124e+01,\n",
      "         -4.6774e+00],\n",
      "        [-9.5610e+00, -9.2521e+00, -4.2368e+00, -3.2212e+00,  1.1007e+01,\n",
      "         -7.8549e+00],\n",
      "        [-3.4462e+00,  7.4353e+00, -4.1266e+00, -1.0248e+01, -1.2557e+01,\n",
      "         -6.3216e+00],\n",
      "        [ 6.5519e-02, -1.3138e+01, -8.5153e+00, -2.4327e+01, -7.5600e+00,\n",
      "         -6.3730e-01],\n",
      "        [-9.3575e+00, -1.1932e+01,  4.6835e+00, -6.7563e+00, -1.8443e+00,\n",
      "         -6.7590e+00],\n",
      "        [-7.8924e+00, -1.2062e+01, -8.1556e-01,  2.9130e+00, -6.1647e+00,\n",
      "         -9.0312e+00],\n",
      "        [ 5.2150e+00, -2.9895e+01, -5.9642e+00, -1.3893e+01, -1.9880e+01,\n",
      "         -8.9292e+00],\n",
      "        [-3.8219e+00, -1.0047e+01, -1.4658e+00, -1.7700e+00, -4.7201e+00,\n",
      "         -1.4816e+01],\n",
      "        [ 1.0247e+01, -1.4753e+01, -2.0986e+01, -2.8353e+01, -1.6051e+01,\n",
      "         -1.5415e+00],\n",
      "        [-8.1984e+00, -3.7814e-01, -7.7092e+00, -1.3774e+01, -1.3268e+01,\n",
      "          5.0682e+00],\n",
      "        [-2.4079e+00, -2.2856e+01, -3.0004e+00, -1.8214e-01, -1.4384e+01,\n",
      "         -8.6267e+00],\n",
      "        [ 1.4718e+00, -3.5689e+00, -9.6385e+00, -1.1184e+01, -1.6506e+01,\n",
      "         -7.6219e-01],\n",
      "        [-8.2943e+00, -1.8888e+01, -1.3832e+01, -5.7623e+00,  1.5733e+01,\n",
      "         -1.0740e+01],\n",
      "        [-5.9421e+00, -1.2991e+01,  4.7544e-02,  3.5315e+00, -3.4935e+00,\n",
      "         -1.4528e+01],\n",
      "        [-4.3754e+00, -8.4490e+00, -1.0674e+01,  1.7654e-03,  7.0508e+00,\n",
      "         -7.5614e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 1, 0, 2, 0, 3, 4, 0, 0, 1, 5, 3, 4, 3, 2, 0, 0, 1, 4, 1, 0, 2, 3, 0,\n",
      "        2, 0, 5, 3, 0, 4, 3, 4], device='cuda:0')\n",
      "tensor([[-11.0825, -34.3343,  15.4893,  -3.0214, -16.1781, -16.2121],\n",
      "        [ -6.1614,  13.1163,  -4.0776, -11.8834,  -9.5709,  -6.5548],\n",
      "        [ -5.2902, -13.9823,  -5.1651, -13.7566,   7.0958,  -7.2445],\n",
      "        [  8.3638, -28.4212, -10.5773, -10.4551, -16.4944,  -7.6744],\n",
      "        [  5.5176, -29.9863, -10.1080, -13.5701,  -3.9622,  -7.5976],\n",
      "        [ -2.5815,  11.0763, -11.1970, -16.8085, -22.1459,  -0.1830],\n",
      "        [  7.9397, -19.7396, -18.4479, -13.9837, -18.5945,  -5.1187],\n",
      "        [  2.9918, -19.7505,  -6.6426,  -5.7284,  -6.0159,  -9.9844],\n",
      "        [  4.6993, -17.3837, -12.3771, -13.0051, -12.9315,  -7.0456],\n",
      "        [ -2.6461, -21.0969,  -4.6425,  14.6597,  -7.6892, -20.7926],\n",
      "        [-11.5377, -11.6219,   3.5754,   3.7324,  -6.4684, -13.5908],\n",
      "        [ -5.3735, -13.5649,  -2.8491,   5.5961,  -9.8026, -13.0961],\n",
      "        [ -7.7155, -10.2437,  -4.8903,  -4.3961,  10.1609, -10.3959],\n",
      "        [ -5.9440, -20.3023, -10.1110, -24.8899, -11.1690,   5.2700],\n",
      "        [ -2.4674, -26.3966,   0.7218,  10.5371, -12.9599, -21.9954],\n",
      "        [ -3.7842, -16.0951,  -9.5048, -15.5108, -15.6802,   2.7185],\n",
      "        [ -7.0692, -28.8273,   9.4635,   2.0808, -12.7934, -15.6701],\n",
      "        [ -6.4534,  -7.0929,  -2.5160,  -3.4046,   8.1860,  -6.8996],\n",
      "        [-14.9764, -30.8173,  18.1654, -15.1700,  -6.2471, -12.7495],\n",
      "        [  8.6691, -24.8335, -17.1109, -17.1063, -14.0380,  -4.1644],\n",
      "        [ -7.4577, -17.0063,  -6.9265,  -6.5599,  15.8218, -11.8922],\n",
      "        [ -6.2295, -11.7693,   7.1915, -16.0400,  -6.0799, -13.6413],\n",
      "        [ -7.9838, -18.2323,   4.4520,   7.9283, -13.7262, -14.3935],\n",
      "        [  7.5283, -34.0488, -19.2354, -29.5795, -23.1685,   3.6391],\n",
      "        [ -8.1285, -14.1072,  -6.2161,  -6.1835,  12.0607, -14.8090],\n",
      "        [ -6.3062,  17.8742,  -6.1869, -14.0934, -17.4542,  -7.6580],\n",
      "        [ -1.4111, -19.3105,   2.0981,   8.1947, -19.6110, -16.1725],\n",
      "        [ -5.1026,  -9.9147,  -0.5497,   2.8986, -16.0237, -10.6798],\n",
      "        [-12.2775, -10.0929,  10.4851, -18.3708,  -3.4447,  -5.9779],\n",
      "        [ -3.8596,  -9.5573, -12.9174, -12.0155,  -3.6755,  -1.5749],\n",
      "        [ -4.3515, -16.7935,  -1.1743,  -2.2177,   2.7975, -15.1180],\n",
      "        [ 21.7141, -38.1262, -25.6860, -20.3970, -17.3977, -11.3235]],\n",
      "       device='cuda:0')\n",
      "tensor([2, 1, 4, 0, 0, 1, 0, 0, 0, 3, 3, 3, 4, 5, 3, 5, 2, 4, 2, 0, 4, 2, 3, 0,\n",
      "        4, 1, 3, 3, 2, 5, 4, 0], device='cuda:0')\n",
      "tensor([[ -6.4771, -15.0200,  -8.2567,   0.8865,   7.5891, -11.0532],\n",
      "        [ -7.7810,  15.5195,  -1.5741, -14.9387, -15.4142,  -7.4714],\n",
      "        [ -8.7845,  -7.3852,  -2.3117,   5.9438,  -1.9554, -11.4685],\n",
      "        [ -9.3085, -13.0963,   2.4656,  -7.4043,   4.6474,  -9.8137],\n",
      "        [-11.7912, -22.4812,  13.7106,  -4.8623,  -9.8687, -12.9519],\n",
      "        [-16.2150, -20.5905,   7.5074, -21.4529, -12.1651,   2.5272],\n",
      "        [ 14.2196, -35.1019, -26.5553, -22.6565, -16.3831,  -2.8361],\n",
      "        [-22.4930, -34.0768, -32.1413, -34.3451, -30.4456,   0.9654],\n",
      "        [-11.1049, -30.9042, -19.3734, -26.0593, -22.0410,   9.9073],\n",
      "        [ -0.6796, -22.0893,   1.1317,   0.5565, -12.2442, -12.6724],\n",
      "        [ 17.1289, -40.3322, -23.1338, -21.5421, -24.3244,  -4.8862],\n",
      "        [ -9.0153, -15.7195,   1.5918,  11.2316, -12.2670, -14.8520],\n",
      "        [  0.1221,   5.4444, -12.8383, -12.7717, -18.3713,  -4.6298],\n",
      "        [  6.9369, -24.2888,  -9.0555, -10.2880, -20.4312, -11.0338],\n",
      "        [ -4.3759,  12.4149,  -1.7873, -12.8051, -17.3277,  -9.7866],\n",
      "        [ -3.7410,  11.1108, -12.2870, -13.3344, -22.1687,  -1.3263],\n",
      "        [-12.2441, -24.2505,   5.0988, -16.0409,   9.9559,  -9.0605],\n",
      "        [ 11.9656, -25.1557, -20.5513, -10.4090,  -8.3362,  -8.8159],\n",
      "        [  6.8867, -26.6043, -22.3248, -18.4269,  -7.9260,  -1.7308],\n",
      "        [-10.1121,  -8.4951,  -5.7638,  -7.9407,  10.8904, -11.9986],\n",
      "        [-12.4715, -18.5042,   0.3885,  17.4959, -20.2398, -17.0429],\n",
      "        [ -8.0668, -13.4144,   6.2923,   2.9207, -12.3189, -11.9321],\n",
      "        [ -3.1594,  10.0860,  -8.2775, -13.5102, -19.4391,  -3.3629],\n",
      "        [ -4.4104,  18.4237, -13.5066, -17.4155, -30.9343,  -2.0459],\n",
      "        [  0.0502, -12.5712, -20.1362, -10.8927, -16.1239,   3.7005],\n",
      "        [  1.8464,  -3.2285, -15.5959, -12.2067, -19.3923,   1.1183],\n",
      "        [ -9.2526, -18.6130, -17.2377, -24.4013, -13.0292,   8.2377],\n",
      "        [ -2.3623,  15.3312,  -9.2557, -15.1532, -19.3133,  -4.5960],\n",
      "        [ -8.5749,  -8.6997,  -1.6629,  -7.7642,   8.3817,  -7.7124],\n",
      "        [ -9.2045, -13.7241,  -3.4732,   9.3200,  -4.7129, -12.6492],\n",
      "        [ -5.9869, -21.6869,  -3.2405, -18.6632, -16.8262,   1.1545],\n",
      "        [ -4.7878, -22.8196,  -1.2144,  11.4218, -10.8219, -20.1266]],\n",
      "       device='cuda:0')\n",
      "tensor([4, 1, 3, 4, 2, 2, 0, 5, 5, 2, 0, 3, 1, 0, 1, 1, 4, 0, 0, 4, 3, 2, 1, 1,\n",
      "        5, 0, 5, 1, 4, 3, 5, 3], device='cuda:0')\n",
      "tensor([[-1.0184e+01, -3.4193e+01,  1.6205e+01, -3.4837e+00, -1.7687e+01,\n",
      "         -1.5309e+01],\n",
      "        [ 3.6112e+00, -1.6721e+01, -1.3573e+01, -1.4209e+01, -4.8906e+00,\n",
      "         -4.2176e+00],\n",
      "        [-5.4205e+00, -2.1086e+01, -2.0093e+00, -1.2727e+01,  5.8728e+00,\n",
      "         -8.0694e+00],\n",
      "        [-6.1225e+00, -1.8788e+01,  1.0275e+00,  8.1903e+00, -7.7048e+00,\n",
      "         -1.6855e+01],\n",
      "        [-5.7109e+00,  1.2919e+01, -7.4044e+00, -2.2712e+01, -2.0284e+01,\n",
      "         -3.8764e+00],\n",
      "        [ 6.8491e-01,  1.0992e+01, -6.5934e+00, -1.5508e+01, -1.8328e+01,\n",
      "         -7.3551e+00],\n",
      "        [-1.2239e+01, -1.2448e+01,  5.2053e+00, -7.6712e+00, -7.6747e-01,\n",
      "         -4.6840e+00],\n",
      "        [ 1.5139e+01, -3.0976e+01, -1.4449e+01, -7.0398e+00, -1.0661e+01,\n",
      "         -1.6995e+01],\n",
      "        [-3.9861e+00, -9.7202e+00, -4.3509e+00,  6.3079e+00, -4.1871e+00,\n",
      "         -1.1741e+01],\n",
      "        [-6.0024e+00, -1.0501e+01, -4.1533e+00, -2.0072e-02,  9.2254e-01,\n",
      "         -6.3244e+00],\n",
      "        [-1.2747e+01, -1.4551e+01,  1.3108e+01, -7.3853e+00, -1.0103e+01,\n",
      "         -1.2437e+01],\n",
      "        [-3.4277e+00, -9.4243e+00, -4.3513e+00,  1.5722e+00, -1.5022e+00,\n",
      "         -1.0237e+01],\n",
      "        [ 3.6632e+00, -1.1567e+01, -1.0339e+01, -1.2821e+01, -1.1476e+01,\n",
      "         -3.2525e+00],\n",
      "        [-3.4694e+00,  5.4625e+00, -5.3108e+00, -5.6486e+00, -1.0989e+01,\n",
      "         -9.9286e+00],\n",
      "        [-1.1133e+01, -1.2724e+01, -2.9355e+00, -2.5006e+00,  8.0452e+00,\n",
      "         -1.3972e+01],\n",
      "        [-1.0259e+01, -1.5575e+01,  5.0550e+00,  2.7856e+00, -5.5320e+00,\n",
      "         -9.9497e+00],\n",
      "        [-3.1943e+00,  1.2138e+01, -6.4128e+00, -1.4253e+01, -1.6485e+01,\n",
      "         -4.8143e+00],\n",
      "        [-9.2221e+00, -1.9527e+01,  2.7115e+00,  8.9438e+00, -1.3938e+01,\n",
      "         -1.7181e+01],\n",
      "        [-8.0475e+00, -1.9501e+01, -4.4363e+00, -1.1557e+01,  1.3449e+01,\n",
      "         -1.1275e+01],\n",
      "        [-5.0562e+00,  1.1270e+01, -4.5581e+00, -1.1022e+01, -1.2946e+01,\n",
      "         -6.0757e+00],\n",
      "        [-4.8970e+00, -2.2912e+01, -6.4891e+00, -7.6668e+00,  1.3245e+01,\n",
      "         -1.1737e+01],\n",
      "        [-1.9814e+00, -8.6151e+00, -1.6816e+01, -2.1706e+01, -2.0261e+01,\n",
      "          8.8446e+00],\n",
      "        [ 1.1160e+01, -1.4900e+01, -1.8489e+01, -1.6942e+01, -1.8874e+01,\n",
      "         -5.6773e+00],\n",
      "        [-8.8204e+00, -2.5686e+01,  8.1089e+00, -2.1478e+00, -8.3096e+00,\n",
      "         -1.5503e+01],\n",
      "        [ 2.2954e+00, -2.3564e+01, -1.1184e+01, -2.3970e+01, -2.1836e+01,\n",
      "          3.5048e+00],\n",
      "        [-4.9733e+00,  1.5937e+01, -9.2934e+00, -1.1742e+01, -1.4079e+01,\n",
      "         -8.0427e+00],\n",
      "        [-1.1480e+00, -1.8795e+01, -3.0349e+00,  1.2239e+01, -1.0000e+01,\n",
      "         -2.2724e+01],\n",
      "        [-5.2705e+00,  1.7536e+01, -1.0222e+01, -1.5852e+01, -2.8328e+01,\n",
      "         -4.1082e+00],\n",
      "        [-3.5076e+00,  9.6091e+00, -5.2434e+00, -1.2197e+01, -1.3783e+01,\n",
      "         -6.6799e+00],\n",
      "        [-1.2898e+01, -2.7203e+01,  7.1169e+00, -2.2727e+00, -8.8634e+00,\n",
      "         -1.2663e+01],\n",
      "        [-8.0502e+00, -8.3401e+00,  3.5159e+00, -1.3006e+01,  5.2504e+00,\n",
      "         -9.5723e+00],\n",
      "        [ 5.4926e+00, -2.0333e+01, -1.6975e+01, -2.3540e+01, -9.7422e+00,\n",
      "          3.0285e+00]], device='cuda:0')\n",
      "tensor([2, 0, 4, 3, 1, 1, 2, 0, 3, 4, 2, 3, 0, 1, 4, 2, 1, 3, 4, 1, 4, 5, 0, 2,\n",
      "        5, 1, 3, 1, 1, 2, 4, 0], device='cuda:0')\n",
      "tensor([[-1.0658e+01, -1.1596e+01,  9.6315e+00, -8.6642e+00, -1.5684e+00,\n",
      "         -6.8048e+00],\n",
      "        [-1.4457e+01, -1.6683e+01,  9.4717e+00, -7.8556e-01, -1.1766e+01,\n",
      "         -9.4734e+00],\n",
      "        [-3.4468e+00,  9.1573e+00, -8.1057e-01, -1.0473e+01, -1.0087e+01,\n",
      "         -8.0463e+00],\n",
      "        [-4.8268e+00,  2.0124e+00, -1.4463e+00, -8.1441e-01, -1.3238e+01,\n",
      "         -9.3996e+00],\n",
      "        [ 6.6870e+00, -3.5161e+00, -1.4768e+01, -2.4555e+01, -2.3301e+01,\n",
      "         -2.7319e+00],\n",
      "        [-7.6711e+00, -4.4586e+00, -3.2572e+00,  3.7818e+00, -2.8257e+00,\n",
      "         -1.2448e+01],\n",
      "        [-1.5573e+00, -2.2535e+01, -1.7671e+01, -1.6201e+01, -1.3651e+01,\n",
      "          1.2224e+00],\n",
      "        [-6.6231e+00, -1.5821e+01,  6.2243e-01, -3.5755e+00, -3.1829e+00,\n",
      "         -7.9580e+00],\n",
      "        [-1.5800e+01, -2.2790e+01,  1.2598e+01, -2.0623e+00, -1.4650e+01,\n",
      "         -1.3535e+01],\n",
      "        [-7.5242e+00, -3.4708e+01,  1.2117e+01,  3.8439e+00, -2.2797e+01,\n",
      "         -1.5471e+01],\n",
      "        [-5.4944e+00, -2.9853e+01,  9.8117e+00,  1.8071e+00, -1.8105e+01,\n",
      "         -1.4338e+01],\n",
      "        [-6.4514e+00,  1.1189e+01, -9.1110e+00, -1.0149e+01, -1.9884e+01,\n",
      "         -2.8021e+00],\n",
      "        [-7.2603e+00, -2.4836e+01,  8.8636e+00,  1.4530e+00, -1.4334e+01,\n",
      "         -1.5036e+01],\n",
      "        [-1.2458e+01, -1.0344e+01,  5.2846e+00, -1.4878e+01,  8.1558e+00,\n",
      "         -9.2007e+00],\n",
      "        [-3.2344e+00,  1.3500e+01, -9.0389e+00, -1.8249e+01, -1.4879e+01,\n",
      "         -5.1670e+00],\n",
      "        [-1.1599e+01, -8.9209e+00, -4.7625e+00, -1.1595e+01, -1.8037e+01,\n",
      "          2.7511e+00],\n",
      "        [-1.0063e+01, -2.8865e+01,  1.1637e+01, -3.4803e+00, -1.3483e+01,\n",
      "         -1.0096e+01],\n",
      "        [-6.8426e+00, -3.7822e+01,  8.5092e+00,  5.5153e-01, -1.7519e+01,\n",
      "         -1.6269e+01],\n",
      "        [-1.5821e+01, -1.8172e+01,  1.1861e+01, -3.4898e+00, -9.8484e+00,\n",
      "         -1.0135e+01],\n",
      "        [-5.3136e+00, -2.6954e+01,  5.7981e+00, -4.0834e+00, -3.7535e+00,\n",
      "         -1.8475e+01],\n",
      "        [ 1.8405e-01, -1.8050e+01, -2.1980e+01, -2.6652e+01, -1.9772e+01,\n",
      "          1.1093e+01],\n",
      "        [-9.3549e+00, -8.0720e+00, -1.5441e+01, -2.3556e+01, -1.5009e+01,\n",
      "          8.0156e+00],\n",
      "        [-2.4366e+00,  1.4209e+01, -7.7182e+00, -1.4152e+01, -2.2790e+01,\n",
      "         -4.9103e+00],\n",
      "        [ 8.4524e+00, -1.3315e+01, -1.9579e+01, -1.5350e+01, -2.2917e+01,\n",
      "         -2.5206e+00],\n",
      "        [-1.0920e+01, -1.5007e+01,  2.8403e+00, -1.7838e+00, -7.4556e-01,\n",
      "         -1.1371e+01],\n",
      "        [ 5.0139e+00, -1.7128e+01, -1.2504e+01, -8.9666e+00, -5.0857e+00,\n",
      "         -7.1760e+00],\n",
      "        [-1.1331e+00, -1.7679e+01, -9.7913e+00, -1.1383e+01, -1.0132e+01,\n",
      "          1.2530e+00],\n",
      "        [-1.1853e+01, -1.9619e+01,  9.7188e+00,  3.3498e+00, -1.1682e+01,\n",
      "         -1.5572e+01],\n",
      "        [-8.1454e+00, -1.6026e+01, -2.3799e+00,  1.0292e+00,  1.5440e+00,\n",
      "         -1.7201e+01],\n",
      "        [-2.5154e+00, -1.2562e+01, -7.8705e+00, -6.7276e-03,  1.1465e+00,\n",
      "         -9.7454e+00],\n",
      "        [-8.0851e+00, -3.0064e+01, -1.5400e+01, -2.5912e+01, -1.6518e+01,\n",
      "          1.3024e+01],\n",
      "        [ 2.9075e+00, -3.1282e+01, -1.7325e+01, -2.3844e+01, -1.8472e+01,\n",
      "          6.0374e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 1, 1, 0, 3, 5, 2, 2, 2, 2, 1, 2, 4, 1, 5, 2, 2, 2, 2, 5, 5, 1, 0,\n",
      "        2, 0, 5, 2, 4, 4, 5, 5], device='cuda:0')\n",
      "tensor([[-8.9082e+00, -1.0199e+01, -6.4563e-03,  3.5100e+00, -1.6232e+00,\n",
      "         -1.2872e+01],\n",
      "        [ 4.6843e+00, -2.8639e+01, -8.6135e+00, -1.9387e+01, -4.0772e+00,\n",
      "         -7.0585e+00],\n",
      "        [ 1.0920e+01, -2.8041e+01, -1.4631e+01, -1.3891e+01, -1.6470e+01,\n",
      "         -6.8213e+00],\n",
      "        [-3.9693e+00, -2.1163e+01,  3.8365e-01,  5.3526e-01,  1.0349e+00,\n",
      "         -1.7161e+01],\n",
      "        [-1.1611e+01, -1.9216e+01, -2.0573e+01, -2.1387e+01, -1.8652e+01,\n",
      "         -1.1184e+00],\n",
      "        [-5.5771e+00, -8.7393e+00, -2.5557e+00, -2.7977e+00,  5.2886e+00,\n",
      "         -8.9036e+00],\n",
      "        [ 2.0105e+00, -2.3688e+01, -1.6845e+01, -1.3332e+01, -1.7585e+01,\n",
      "          3.0148e+00],\n",
      "        [-1.1901e+00, -1.5709e+01, -8.0402e+00, -5.3065e+00, -7.8137e+00,\n",
      "         -2.2421e+00],\n",
      "        [-5.5658e+00,  5.3333e+00, -6.3628e+00, -8.3020e+00, -7.5851e+00,\n",
      "         -2.7253e+00],\n",
      "        [ 2.0321e+00, -2.1669e+01, -4.8067e-01, -1.9703e+00, -1.4168e+01,\n",
      "         -1.5946e+01],\n",
      "        [-6.2604e+00, -5.1669e+00, -1.9343e+00,  4.6756e+00, -3.5752e+00,\n",
      "         -1.2333e+01],\n",
      "        [-8.3368e+00, -1.8972e+01, -2.4278e+00, -1.5872e+01,  1.6317e+01,\n",
      "         -1.2055e+01],\n",
      "        [-9.1684e+00, -1.9503e+01, -2.7542e+00, -1.9437e-01,  5.6348e+00,\n",
      "         -1.2795e+01],\n",
      "        [-9.5651e+00, -9.8870e+00, -8.7788e-01, -3.0097e+00,  5.2467e+00,\n",
      "         -1.1764e+01],\n",
      "        [-3.5126e+00, -2.8126e-01,  1.9418e+00, -1.3188e+01, -8.9282e+00,\n",
      "         -6.1301e+00],\n",
      "        [-6.3650e+00,  1.0847e+01, -4.8482e+00, -1.5205e+01, -1.1847e+01,\n",
      "         -3.5115e+00],\n",
      "        [-1.0233e+01, -2.4808e+01,  5.2590e+00,  9.8968e+00, -2.1668e+01,\n",
      "         -1.5925e+01],\n",
      "        [ 1.3960e+01, -2.1839e+01, -1.6106e+01, -1.6566e+01, -2.0172e+01,\n",
      "         -9.3304e+00],\n",
      "        [-7.5842e+00,  9.0818e+00, -2.9963e+00, -7.1329e+00, -1.1151e+01,\n",
      "         -5.5406e+00],\n",
      "        [-5.2743e+00, -1.6977e+01, -1.3173e+00,  1.0309e+00, -1.0768e+00,\n",
      "         -1.1581e+01],\n",
      "        [-8.9281e-01, -1.4421e+01, -1.2561e+01, -1.1150e+01, -1.4292e+01,\n",
      "         -1.0193e-01],\n",
      "        [-5.5575e+00,  8.0593e+00, -1.6548e+00, -1.4606e+01, -1.2810e+01,\n",
      "         -4.5321e+00],\n",
      "        [-7.2858e+00, -1.1693e+01, -1.8859e+00,  4.9950e+00, -5.5004e+00,\n",
      "         -1.2729e+01],\n",
      "        [-5.8829e+00, -1.8517e+01, -5.4394e+00, -1.1332e+01,  1.0729e+01,\n",
      "         -1.1161e+01],\n",
      "        [-4.4942e+00, -7.3352e+00, -1.0472e+01, -1.1738e+01, -1.4464e+01,\n",
      "          1.5128e+00],\n",
      "        [-1.7497e+01, -1.7799e+01,  8.1143e+00, -7.5393e+00, -1.5552e+00,\n",
      "         -8.0957e+00],\n",
      "        [-2.9412e+00, -9.5008e+00, -3.5584e+00,  6.4178e+00, -1.2621e+01,\n",
      "         -1.5520e+01],\n",
      "        [ 1.2010e+00, -6.9948e+00, -8.8525e+00, -1.5671e+01, -4.1646e+00,\n",
      "         -3.2417e+00],\n",
      "        [-8.3746e+00, -2.4713e+01,  6.8771e+00,  1.0267e-01, -7.2777e+00,\n",
      "         -1.3897e+01],\n",
      "        [-5.0958e+00,  1.4333e+01, -1.1953e+01, -1.3621e+01, -1.4821e+01,\n",
      "         -3.9781e+00],\n",
      "        [-1.1084e+01, -2.2464e+01,  9.8403e+00, -1.0115e+00, -9.0753e+00,\n",
      "         -1.2626e+01],\n",
      "        [-9.1553e+00, -1.0970e+01,  1.1239e+00,  1.0114e+01, -1.2291e+01,\n",
      "         -1.2502e+01]], device='cuda:0')\n",
      "tensor([3, 0, 0, 4, 5, 4, 5, 0, 1, 0, 3, 4, 4, 4, 2, 1, 3, 0, 1, 3, 5, 1, 3, 4,\n",
      "        5, 2, 3, 0, 2, 1, 2, 3], device='cuda:0')\n",
      "tensor([[-1.0697e+01, -1.4308e+01, -3.8965e+00, -2.2737e+00,  4.2442e+00,\n",
      "         -6.7155e+00],\n",
      "        [-1.2782e+01, -2.0848e+01,  7.8914e+00, -5.1348e+00, -7.7425e+00,\n",
      "         -5.3951e+00],\n",
      "        [-1.2797e+01, -1.6981e+01,  3.1406e+00,  7.4117e+00, -1.2096e+01,\n",
      "         -1.2168e+01],\n",
      "        [-7.0617e+00,  2.2830e+01, -1.2900e+01, -1.9188e+01, -3.1047e+01,\n",
      "         -1.0636e+00],\n",
      "        [ 2.8682e-03, -3.1015e-01, -8.8608e+00, -5.1099e+00, -1.2068e+00,\n",
      "         -8.8031e+00],\n",
      "        [-9.0947e+00, -1.0691e+01,  8.4235e+00, -1.0125e+01, -7.1169e+00,\n",
      "         -5.1320e+00],\n",
      "        [-3.9489e+00, -1.4710e+01, -1.6901e+00, -1.1412e+01,  2.3521e+00,\n",
      "         -1.0326e+01],\n",
      "        [-9.0698e-01,  1.2669e+01, -3.9036e+00, -1.5272e+01, -1.5690e+01,\n",
      "         -9.4591e+00],\n",
      "        [ 4.4855e+00, -1.1907e+01, -1.2685e+01, -1.7026e+01, -1.8667e+01,\n",
      "         -3.8551e+00],\n",
      "        [-1.5494e+00, -1.2246e+01, -9.7407e+00, -1.0894e+01, -1.7290e+00,\n",
      "         -4.7354e+00],\n",
      "        [-3.5976e+00, -1.7145e+01,  1.8173e+00,  3.9954e+00, -1.6023e+01,\n",
      "         -1.4989e+01],\n",
      "        [-5.5187e+00, -6.7028e+00, -4.6836e+00,  9.7459e+00, -1.2494e+01,\n",
      "         -1.4482e+01],\n",
      "        [-1.5559e+01, -3.0282e+01, -2.4359e+01, -3.2818e+01, -2.4222e+01,\n",
      "          1.2513e+01],\n",
      "        [-7.9134e+00, -1.4926e+01, -7.6382e+00, -2.5419e+00,  6.6715e+00,\n",
      "         -8.5292e+00],\n",
      "        [ 1.3061e+01, -4.9129e+01, -1.8499e+01, -2.2241e+01, -8.1403e+00,\n",
      "         -7.3138e+00],\n",
      "        [-2.0604e+00,  1.0833e+01, -8.6156e+00, -1.5492e+01, -2.0705e+01,\n",
      "         -5.7215e+00],\n",
      "        [-4.7784e-01, -2.5683e+01, -5.2279e+00, -1.4740e+01, -1.4091e+01,\n",
      "         -2.7395e-01],\n",
      "        [-4.1628e+00,  6.3593e+00, -5.7378e+00, -9.2260e+00, -8.8015e+00,\n",
      "         -5.4682e+00],\n",
      "        [-1.1624e+01, -1.9206e+01,  8.3737e+00,  5.0340e+00, -1.2861e+01,\n",
      "         -1.3225e+01],\n",
      "        [-9.4338e+00, -2.4450e+01,  7.3657e+00,  1.2550e+01, -2.4074e+01,\n",
      "         -2.1060e+01],\n",
      "        [ 1.1793e+01, -2.4199e+01, -1.3457e+01, -1.5319e+01, -1.4852e+01,\n",
      "         -9.3161e+00],\n",
      "        [-3.9567e+00,  1.1209e+01, -5.6891e+00, -1.8988e+01, -1.2539e+01,\n",
      "         -6.2452e+00],\n",
      "        [ 1.4608e+01, -3.3010e+01, -1.8675e+01, -1.8957e+01, -9.3013e+00,\n",
      "         -8.8444e+00],\n",
      "        [-5.5021e+00, -8.2362e+00, -1.2793e+01, -1.8342e+01, -1.6694e+01,\n",
      "          6.6522e+00],\n",
      "        [-7.0487e-01, -3.3345e+01,  4.4063e+00, -3.1901e+00, -1.0373e+01,\n",
      "         -1.2380e+01],\n",
      "        [-7.1052e+00, -1.5181e+01,  4.4010e+00,  8.9019e-01, -5.0072e+00,\n",
      "         -1.3948e+01],\n",
      "        [-9.6254e+00, -4.8200e+00, -2.0151e+01, -2.2716e+01, -1.8285e+01,\n",
      "          6.4701e+00],\n",
      "        [ 1.6399e+00, -2.2488e+01, -1.4111e+01, -1.9296e+01, -1.0721e+01,\n",
      "          4.6850e+00],\n",
      "        [-4.4147e+00,  1.1068e+01, -1.2188e+01, -1.3577e+01, -1.4301e+01,\n",
      "         -2.6566e+00],\n",
      "        [ 6.0117e+00, -2.2080e+01, -1.3910e+01, -9.2271e+00, -1.0863e+01,\n",
      "         -5.4740e+00],\n",
      "        [ 1.4116e+00, -1.3562e+01, -1.2937e+01, -7.1201e+00, -1.0507e+01,\n",
      "         -9.3044e-01],\n",
      "        [ 1.8559e+00, -1.7872e+01, -7.4047e+00,  5.6351e+00, -5.3170e+00,\n",
      "         -1.7249e+01]], device='cuda:0')\n",
      "tensor([4, 2, 3, 1, 0, 2, 4, 1, 0, 0, 3, 3, 5, 4, 0, 1, 5, 1, 2, 3, 0, 1, 0, 5,\n",
      "        2, 2, 5, 5, 1, 0, 0, 3], device='cuda:0')\n",
      "tensor([[ -7.9311,  10.7428,  -6.1226, -16.0303, -17.2920,   0.5763],\n",
      "        [ -5.2086, -14.3970,  -7.6449,  -4.2952,   9.2902,  -9.0425],\n",
      "        [ -6.2308,  -9.9666,  -4.9843, -12.0076,   6.4188,  -6.2305],\n",
      "        [ -4.9202,  10.9463,  -9.0409, -12.1798, -13.2747,  -4.6842],\n",
      "        [ -4.0137,  -2.7110,  -0.1593,  -7.1420, -11.2898,  -0.3924],\n",
      "        [ -6.5488, -16.0321,   4.1867,   6.8925, -14.6128, -12.8127],\n",
      "        [-10.9297, -15.6319,  -6.0072,  -5.8581,  10.3510,  -7.5341],\n",
      "        [ -6.3267, -18.6467,  -9.5274, -11.0029,   5.6510,  -3.6073],\n",
      "        [ 13.0012, -23.2919, -17.2251, -16.5828, -18.0069, -10.5994],\n",
      "        [-13.5004, -22.1079,  12.4220,  -0.9797, -12.0474,  -9.1795],\n",
      "        [-11.3224, -16.6353,   1.8003, -17.8143,  11.1307,  -5.3726],\n",
      "        [  4.9749, -24.1650, -12.9281, -16.0149, -10.0799,  -1.3814],\n",
      "        [ -1.1656, -18.9546, -18.3895, -17.9651, -22.8605,   6.4513],\n",
      "        [ -9.7868, -14.3570,  -4.8038,  -5.5533,  11.1591,  -7.5275],\n",
      "        [  3.8874, -22.6798,  -4.4327, -15.0552,  -3.5644,  -7.8023],\n",
      "        [ -2.3039,  15.8423, -10.6213, -14.8407, -21.9270,  -7.0090],\n",
      "        [ -1.8366,   7.3715,  -5.1748, -14.9620, -12.2048,  -5.2581],\n",
      "        [ -4.5440, -17.3181,  -8.2911,   1.8721,  -4.4820,  -9.6781],\n",
      "        [ -2.4181, -21.2109,   6.2731,   2.0329, -10.3770, -15.7803],\n",
      "        [ -9.8686,  -9.7605,  -5.1895,  -0.7831,   9.6237,  -8.7119],\n",
      "        [ -5.6602,  -5.2932,  -1.2036,   4.3255,  -7.3563,  -7.3653],\n",
      "        [ -2.6033, -17.2791,  -2.0931,  -3.5526,  -0.8343, -15.9686],\n",
      "        [ -8.9175, -18.9247,  -9.7340, -12.2430,  19.8940,  -9.8290],\n",
      "        [-14.9099, -12.4728,  12.7178, -10.5553,  -7.5569,  -4.5811],\n",
      "        [ -6.8864, -12.9397,   7.6610, -16.3733,  -3.0415,  -6.3110],\n",
      "        [ -6.6661,  10.9507,  -8.2577, -11.4927, -12.8442,  -4.6467],\n",
      "        [ -3.5304, -13.0578,  -6.3333,  13.9975,  -9.2276, -18.4647],\n",
      "        [ -5.2718, -20.5319,   0.6490,  -5.7624,   1.1510, -10.8939],\n",
      "        [ -6.3742, -17.3669,  -1.7357,  -6.7248,   8.2616,  -8.0116],\n",
      "        [ -6.6410,  -7.5410,  -6.4775, -15.5220, -16.3216,   3.3333],\n",
      "        [ -6.3788,  -6.1563,  -6.8585,   3.0453,   3.9369,  -8.3478],\n",
      "        [ -7.9465,  -4.6906,  -4.9753, -19.0962, -13.3765,   3.0596]],\n",
      "       device='cuda:0')\n",
      "tensor([1, 4, 4, 1, 2, 3, 4, 4, 0, 2, 4, 0, 5, 4, 0, 1, 1, 3, 2, 4, 3, 4, 4, 2,\n",
      "        2, 1, 3, 4, 4, 5, 4, 5], device='cuda:0')\n",
      "tensor([[-11.7994, -13.6287,   3.3541,  -2.2971,  -2.1675,  -9.6117],\n",
      "        [ -3.0671,   5.0014,  -6.4104,  -5.9563,  -7.7300,  -5.3884],\n",
      "        [-10.5986,  -5.6571,  -5.5582,  -8.6320,   7.6453,  -5.5744],\n",
      "        [  3.5879,   9.3078,  -9.9242, -20.5200, -23.2744,  -3.7510],\n",
      "        [-10.4496, -20.5474,   5.2977,  -2.6942, -10.5413, -10.3423],\n",
      "        [ 10.8875, -30.1438, -13.2939, -10.2252, -15.0385, -10.8145],\n",
      "        [ -5.3632,  12.9326,  -6.2175,  -9.5174, -14.1767,  -4.5774],\n",
      "        [ -6.1909,   2.8379,  -4.6803,   3.5970,  -6.4548, -10.6778],\n",
      "        [ -6.6912,  -9.3706, -10.4240, -17.8578, -17.3368,   3.1963],\n",
      "        [ -3.2919, -16.2555,  -3.6917,  10.9018,  -3.4484, -19.4347],\n",
      "        [ -8.2425,   7.1725,  -5.3697, -11.1663,  -9.7217,  -2.1041],\n",
      "        [  4.8658, -23.4256,  -8.6714, -14.4657,  -7.2530,  -8.1510],\n",
      "        [ -3.3856,  -9.9867, -13.2825, -18.7043, -14.1790,   4.7348],\n",
      "        [ -2.0243,   8.6155,  -6.2488,  -8.1280, -10.1701,  -6.6911],\n",
      "        [ -7.8593, -21.0275,   6.1279,   8.5172, -17.9883, -17.2581],\n",
      "        [ -8.3740, -15.8039,  -0.4717,   8.4457,  -8.8769, -13.3280],\n",
      "        [  6.9325, -15.8850, -16.5642, -12.8456,  -6.5949,  -6.8357],\n",
      "        [ -5.7465, -12.9994,  -5.0132, -12.2325, -12.3303,   3.9920],\n",
      "        [ -6.3403,   2.3140,  -5.9508,   5.2218,  -0.2115, -11.6113],\n",
      "        [ -3.6533, -10.8246,  -4.7921,   0.1637,  -3.9902,  -9.6284],\n",
      "        [-11.5081, -11.5353,   2.9773,  -1.0646,  -0.5381,  -8.0222],\n",
      "        [-10.2106, -14.2321,  -3.6803,  -8.1776,  13.1166, -13.7386],\n",
      "        [  9.6134, -33.3951, -21.7098, -21.4321,  -5.3253,  -2.9177],\n",
      "        [ -3.5578, -12.6543,  -7.7713,  -8.4624,   2.8897,  -7.8703],\n",
      "        [ -9.5529, -24.8720,   3.6939,  11.8435, -13.3962, -21.4365],\n",
      "        [ -3.5648,   8.6694,  -3.1722, -11.8829, -13.2670,  -6.8502],\n",
      "        [ -4.3258,   6.1983,  -7.0061, -11.3152,  -9.5696,  -3.5755],\n",
      "        [ -7.3588, -23.0918,   9.9937,  -6.6784, -11.2533, -14.3484],\n",
      "        [ -3.7930, -13.7479,  -3.1874,   5.3610,  -5.3791, -13.4380],\n",
      "        [-16.0523, -19.1615,  15.5917, -12.3339,  -0.9912, -12.2834],\n",
      "        [ -2.6551,   7.6663,  -3.9364, -13.6367, -16.8644,  -4.3480],\n",
      "        [ -2.9922,   7.0107,  -9.9104,  -8.7362, -22.4028,  -3.2563]],\n",
      "       device='cuda:0')\n",
      "tensor([2, 1, 4, 1, 2, 0, 1, 3, 5, 3, 1, 0, 5, 1, 3, 3, 0, 5, 3, 3, 2, 4, 0, 4,\n",
      "        3, 1, 1, 2, 3, 2, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -7.3438,  -7.2584,   1.1396,  -2.9577,  -5.9023, -12.5245],\n",
      "        [ -5.7848, -12.5904,  -3.1984, -10.1412,  11.2931,  -8.7062],\n",
      "        [ -8.1700,  16.5527,  -7.1048, -14.2803, -14.3317,  -5.7571],\n",
      "        [ -6.1251,  11.0241,  -6.8024,  -8.6546, -11.5816,  -5.0889],\n",
      "        [ -3.0899, -15.1874, -14.3849, -11.8404, -16.9113,   5.7209],\n",
      "        [ -5.3335,  -6.0250,   0.5191,   4.1512,  -1.1326, -10.6485],\n",
      "        [ 15.4229, -33.8209, -20.8843, -16.1621, -21.8872,  -5.7198],\n",
      "        [  3.4115, -20.8035, -12.1918, -12.1089, -14.8861,  -6.9719],\n",
      "        [ -6.0290,  -4.1021,  -4.3507,   2.2424,   6.1247,  -8.1163],\n",
      "        [-10.8145, -17.8785,  -0.5300,   7.5407,  -8.5561, -13.3060],\n",
      "        [ -7.9064, -19.8984,  -5.1599,  -9.5536,   7.2237,  -8.7110],\n",
      "        [  6.0223, -29.9916, -23.2355, -19.1217, -14.9148,  -3.3421],\n",
      "        [ -6.1542,  -8.3833,  -2.8925,  -4.3449,   6.3335,  -8.3656],\n",
      "        [ -7.8730, -27.7581,  10.2498,  -0.2665, -11.7496, -15.9562],\n",
      "        [ -7.4648,   4.3341,  -1.2876, -10.7993, -10.2848,  -1.6702],\n",
      "        [  8.4443, -28.3595, -19.2488, -17.4431,  -4.6400,  -2.5808],\n",
      "        [ -3.2124, -24.5218, -14.8212, -15.5671, -12.9091,   8.1241],\n",
      "        [ -3.4817, -15.0727,   0.6684,  10.3788, -16.4398, -15.2365],\n",
      "        [ -8.5922, -14.9615,   7.8433,  -4.5820, -13.0474, -10.1054],\n",
      "        [ -9.2101, -17.6605,   3.8431,  -2.1915,  -5.8849,  -9.3677],\n",
      "        [ -1.9282, -30.5317,   1.5340,   5.8556, -19.9607, -17.2713],\n",
      "        [-10.1326, -13.7402,  -3.3870,  15.4826,  -8.3588, -22.1619],\n",
      "        [ -7.4452, -34.1561,   5.9116,  11.0400, -13.7889, -23.1455],\n",
      "        [ -3.2671, -21.7118, -10.7707, -13.4021,   8.5096,  -4.8885],\n",
      "        [ -8.9351, -17.6936,  -3.3375,  13.1526, -11.4600, -15.1079],\n",
      "        [ -7.6879, -19.8804, -19.4413, -21.2705, -16.9798,   6.5322],\n",
      "        [ -6.0486, -13.4754,  -5.3983,  -1.8400,   4.7710,  -7.2875],\n",
      "        [ -8.1437,  -7.6989,   5.4968,  -4.5113,  -4.6512,  -8.5717],\n",
      "        [-11.2336, -29.5720,  13.0858, -11.4621, -13.8003,  -5.6091],\n",
      "        [ -7.8489, -21.1841,   9.5757,   3.8218, -20.0226, -15.2433],\n",
      "        [ 10.2903, -38.3086, -17.8530, -13.2457, -21.0140,  -4.3483],\n",
      "        [ -0.5082,  10.0272, -11.6982, -15.9488, -20.6222,  -6.3153]],\n",
      "       device='cuda:0')\n",
      "tensor([2, 4, 1, 1, 5, 3, 0, 0, 4, 3, 4, 0, 4, 2, 1, 0, 5, 3, 2, 2, 3, 3, 3, 4,\n",
      "        3, 5, 4, 2, 2, 2, 0, 1], device='cuda:0')\n",
      "tensor([[-1.0854e+01, -9.5026e+00, -3.3119e+00, -2.7068e+01,  2.0059e+01,\n",
      "         -1.4309e+01],\n",
      "        [-6.3095e+00, -8.3973e+00, -3.0735e+00,  3.9461e+00, -3.1446e+00,\n",
      "         -9.0863e+00],\n",
      "        [-7.4585e+00, -9.4536e+00, -3.0687e+00, -5.5084e+00,  9.5869e+00,\n",
      "         -7.2119e+00],\n",
      "        [ 7.2346e+00, -1.0230e+01, -1.0998e+01, -1.0870e+01, -1.6790e+01,\n",
      "         -9.7955e+00],\n",
      "        [-6.3183e+00, -2.3358e+00, -6.7632e+00,  8.8325e+00, -8.4630e+00,\n",
      "         -1.1952e+01],\n",
      "        [-8.9909e+00, -2.1668e+01,  5.8463e+00,  8.8388e+00, -1.3932e+01,\n",
      "         -1.7278e+01],\n",
      "        [-1.1488e+01, -2.5542e+01,  1.8056e+01, -1.3087e+01, -1.3294e+01,\n",
      "         -1.3727e+01],\n",
      "        [-7.7868e+00,  4.2580e-02, -4.6368e+00, -4.1077e+00,  1.4021e+00,\n",
      "         -9.0967e+00],\n",
      "        [-4.6972e+00, -2.1881e+01,  7.3976e+00, -1.5109e+00, -1.2346e+01,\n",
      "         -1.4103e+01],\n",
      "        [-1.0970e+01, -2.1581e+01,  2.3974e+00, -1.5278e+01,  2.4047e-01,\n",
      "         -2.0708e+00],\n",
      "        [-8.3536e+00, -1.3776e+01,  5.2064e+00, -7.4878e+00, -2.5623e-02,\n",
      "         -9.0269e+00],\n",
      "        [-1.0801e+01, -1.3482e+01, -1.8604e+01, -1.9084e+01, -1.9362e+01,\n",
      "          4.2295e+00],\n",
      "        [-5.6007e+00, -1.7699e+01,  5.7199e+00,  2.6455e+00, -8.8787e+00,\n",
      "         -1.2133e+01],\n",
      "        [-3.6352e+00,  8.3809e+00, -4.5678e+00, -5.1556e+00, -1.2644e+01,\n",
      "         -6.9580e+00],\n",
      "        [ 1.9864e+00, -2.2424e+01, -2.2268e+00,  1.1897e+01, -1.3979e+01,\n",
      "         -2.4212e+01],\n",
      "        [-4.8317e+00, -9.1868e+00, -9.1352e+00,  1.3384e+00,  7.4287e+00,\n",
      "         -1.5115e+01],\n",
      "        [-1.1068e+01, -8.2560e+00,  6.7351e+00, -2.8019e+00, -2.8676e+00,\n",
      "         -6.1680e+00],\n",
      "        [ 5.8533e+00, -1.3579e+01, -1.3159e+01, -9.2215e+00, -9.7504e+00,\n",
      "         -8.8534e+00],\n",
      "        [ 1.4209e+00, -8.0253e+00, -1.0053e+01, -1.3575e+01, -1.0468e+01,\n",
      "         -3.1482e+00],\n",
      "        [-9.3543e+00, -1.5979e+01,  1.0234e+01, -1.4146e+00, -9.7479e+00,\n",
      "         -1.8585e+01],\n",
      "        [ 5.9994e+00, -3.8333e+01, -6.8303e+00, -1.5671e+01, -1.8630e+01,\n",
      "         -6.1877e+00],\n",
      "        [-1.0925e+01, -2.4142e+00, -5.3882e+00, -1.3665e+00,  1.1204e+00,\n",
      "         -4.3242e+00],\n",
      "        [-4.6877e+00, -1.0006e+01, -6.9932e+00,  1.0276e+01, -4.4564e+00,\n",
      "         -1.4674e+01],\n",
      "        [-6.3942e+00, -1.3644e+01,  5.5071e+00,  7.2387e+00, -1.5960e+01,\n",
      "         -1.2913e+01],\n",
      "        [ 4.7099e+00, -2.4155e+01, -2.4109e+01, -1.3815e+01, -3.5375e+00,\n",
      "         -1.9707e+00],\n",
      "        [-7.1003e+00, -5.9496e+00, -3.9026e+00, -1.0981e+00, -4.1987e+00,\n",
      "         -4.6210e+00],\n",
      "        [-3.5806e+00, -1.6464e+01, -1.0311e+01, -1.9935e+01, -1.3482e+01,\n",
      "          3.7954e+00],\n",
      "        [-1.2805e+01, -1.1194e+01,  2.9278e+00,  4.7071e+00, -7.4683e+00,\n",
      "         -1.0227e+01],\n",
      "        [-9.2099e+00, -1.9095e+01, -1.5404e+00,  1.4872e+01, -1.4006e+01,\n",
      "         -1.8736e+01],\n",
      "        [-1.0694e+01, -1.7647e+01, -1.2578e+01, -8.9078e+00,  1.9404e+01,\n",
      "         -1.0956e+01],\n",
      "        [-1.3081e+01, -1.9564e+01,  9.3046e+00,  1.2062e+00, -1.1546e+01,\n",
      "         -1.1399e+01],\n",
      "        [-3.7876e+00, -1.1590e+01, -9.8254e+00, -2.1645e+01, -7.8652e+00,\n",
      "          4.7864e+00]], device='cuda:0')\n",
      "tensor([4, 3, 4, 0, 3, 3, 2, 4, 2, 2, 2, 5, 2, 1, 3, 4, 2, 0, 0, 2, 0, 4, 3, 3,\n",
      "        0, 3, 5, 3, 3, 4, 2, 5], device='cuda:0')\n",
      "tensor([[ -2.6996,   7.0390,  -2.6918,  -7.2891,  -9.4614,  -7.9838],\n",
      "        [ -5.6483,  13.1513,  -8.2224, -14.6571, -15.1749,  -0.8093],\n",
      "        [-10.2952,  -8.3656,  -4.3951,  13.4504,  -6.9473, -16.6176],\n",
      "        [-13.2422, -21.3379,  13.2869,  -9.0319,  -8.3033,  -9.8190],\n",
      "        [-11.9974, -17.1814,   7.6797, -11.2608,   1.1264,  -8.5762],\n",
      "        [-11.1405,  -5.0597,  -4.9278, -13.6146,  11.9988,  -7.1350],\n",
      "        [  0.7205,  11.2926,  -5.8020, -19.1125, -22.1290,  -6.2279],\n",
      "        [-11.4345, -24.9360,  12.5431,  -0.9138, -19.2572,  -9.2581],\n",
      "        [  4.7051, -12.5262, -13.9851, -31.3193, -17.8118,   3.0158],\n",
      "        [  2.8409, -11.2791, -19.1148, -21.7634,  -7.9820,   3.2343],\n",
      "        [  0.6589, -14.2589,  -0.6239, -10.7919, -15.9111,  -9.2439],\n",
      "        [  7.2293, -26.6648, -10.8980,  -3.2504, -11.6553, -12.0399],\n",
      "        [-14.9937, -15.6714, -29.0912, -24.9918, -22.3021,  -1.1407],\n",
      "        [  7.4352, -23.4759,  -7.8115, -12.7812, -14.1807,  -8.8830],\n",
      "        [ -2.0617,  19.0562,  -8.7207, -21.1912, -26.9621,  -5.0647],\n",
      "        [ -3.2088,  11.8222,  -8.7538, -18.0607, -20.8304,  -3.3433],\n",
      "        [-11.6105, -21.6222,  11.3409,  -8.6140,  -4.5261,  -8.5503],\n",
      "        [  0.2138,  -8.0800,   6.2965,  -7.2169, -13.3789,  -8.4405],\n",
      "        [ -9.1346,  -2.7235,  -4.7783,   3.1725,   5.0977,  -9.3875],\n",
      "        [ -0.5326, -24.6964,   2.9699,   2.9849, -11.4257, -15.2685],\n",
      "        [ -8.2272,  -8.7404,  -5.9519,  -1.4208,   9.1515,  -8.6456],\n",
      "        [ -5.1120,   7.1636,  -2.3357,  -8.5736, -10.3474,  -3.1416],\n",
      "        [-13.7101, -23.9124,  -0.1555,  10.2119, -10.5697, -13.1253],\n",
      "        [ -5.3640,  -8.9077,  -8.9222,  -4.3632,  -1.3099,  -9.1124],\n",
      "        [ -7.0805, -18.4034,  -4.4326,   7.8626,  -3.2729, -17.0354],\n",
      "        [ 13.4592, -31.9464, -15.0290, -12.7779, -21.9513, -10.0948],\n",
      "        [  0.6573, -29.7094, -12.3134, -19.1401,  -9.5530,   4.5553],\n",
      "        [ -8.3467, -20.8498,   7.5596,   0.3880,  -9.4238,  -8.2618],\n",
      "        [  2.4815, -23.9779,  -7.1477,   9.1221,  -9.9204, -22.2127],\n",
      "        [ -7.8630,  -6.7386,  -3.9439,  -2.5932,   1.5321,  -9.1367],\n",
      "        [ -6.9565, -19.3625,  -0.4013,   6.4305,  -7.0144, -13.4953],\n",
      "        [ -6.7392,  -9.5741,  -4.1677,  -2.8859, -10.8847,   0.2123]],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 3, 2, 2, 4, 1, 2, 0, 5, 0, 0, 5, 0, 1, 1, 2, 2, 4, 3, 4, 1, 3, 4,\n",
      "        3, 0, 5, 2, 3, 4, 3, 5], device='cuda:0')\n",
      "tensor([[-8.0784e+00, -1.5427e+01, -2.1673e-02, -5.0319e+00,  1.7326e+00,\n",
      "         -1.0600e+01],\n",
      "        [-1.0807e+01, -2.5952e+01,  9.6416e+00,  5.0374e+00, -1.6093e+01,\n",
      "         -1.4738e+01],\n",
      "        [-2.6773e+00,  1.0561e+01, -1.0692e+01, -2.0711e+01, -1.9846e+01,\n",
      "         -4.6580e+00],\n",
      "        [-1.8649e+00, -5.9084e+00, -7.9230e+00,  6.6995e+00, -5.2609e+00,\n",
      "         -1.4469e+01],\n",
      "        [-8.2145e-01, -1.0037e+01, -1.1946e+01, -1.5933e+01, -1.1103e+01,\n",
      "          5.4156e+00],\n",
      "        [-5.5330e+00, -4.5826e+00, -5.5467e+00,  5.8578e+00,  2.2306e+00,\n",
      "         -1.0836e+01],\n",
      "        [-1.1578e+01, -2.6480e+01,  8.1030e+00, -1.4723e+00, -8.9650e+00,\n",
      "         -8.0692e+00],\n",
      "        [-3.3003e+00, -1.7624e+01, -1.2014e+01, -1.0715e+01, -5.4755e+00,\n",
      "         -1.4980e+00],\n",
      "        [-6.0212e+00, -1.5746e+01, -8.6591e+00, -6.0525e+00,  8.5617e+00,\n",
      "         -1.0007e+01],\n",
      "        [-6.5733e+00,  5.2186e+00, -1.1425e+00, -1.3256e+01, -7.3642e+00,\n",
      "         -5.3053e+00],\n",
      "        [-2.2646e+00, -2.3518e+01, -2.0798e+01, -2.2080e+01, -2.3245e+01,\n",
      "          7.2425e+00],\n",
      "        [-4.5493e+00, -3.0058e+01,  1.1425e+01, -4.2790e-01, -1.7867e+01,\n",
      "         -1.0127e+01],\n",
      "        [-1.1759e+01, -2.1446e+01,  5.9592e+00,  7.5827e+00, -1.9949e+01,\n",
      "         -1.5033e+01],\n",
      "        [-1.1295e+01, -1.9188e+01,  1.9374e+01, -1.7719e+01, -1.4124e+01,\n",
      "         -1.2313e+01],\n",
      "        [-6.0331e+00, -1.9629e+01, -6.2946e-01, -9.1885e+00, -2.1059e+00,\n",
      "         -1.0621e+01],\n",
      "        [ 2.2329e+00, -9.8750e+00, -1.8530e+01, -7.2580e+00, -7.0713e+00,\n",
      "         -4.2117e+00],\n",
      "        [-2.4385e+00,  6.5252e+00, -6.7176e+00, -6.9084e+00, -1.2959e+01,\n",
      "         -2.7814e+00],\n",
      "        [-8.7899e+00,  1.4583e+01, -2.9730e+00, -1.3362e+01, -1.5355e+01,\n",
      "         -8.7148e+00],\n",
      "        [-7.4336e+00,  1.2863e+00, -5.6839e+00, -1.2830e+01, -4.1259e+00,\n",
      "          1.4597e+00],\n",
      "        [-1.1291e+01, -3.2719e+01,  1.6180e+01, -6.2511e+00, -1.6866e+01,\n",
      "         -1.5616e+01],\n",
      "        [-7.1081e+00, -1.8270e+00, -6.8961e+00, -1.7877e+01,  3.4342e+00,\n",
      "         -5.1026e+00],\n",
      "        [-9.7337e+00, -9.5647e+00, -7.2644e+00, -4.6761e+00,  1.0834e+01,\n",
      "         -8.0589e+00],\n",
      "        [-6.7022e+00, -1.5774e+01,  3.6480e+00,  7.2937e+00, -1.2761e+01,\n",
      "         -1.4784e+01],\n",
      "        [-8.4877e+00, -3.1375e+01,  5.6226e+00,  3.8447e+00, -9.5669e+00,\n",
      "         -1.9310e+01],\n",
      "        [ 1.0485e+01, -2.6709e+01, -1.5121e+01, -1.6759e+01, -1.2828e+01,\n",
      "         -5.3579e+00],\n",
      "        [-3.9579e+00, -5.5438e+00, -6.4615e+00, -9.6326e-01,  8.9134e-01,\n",
      "         -9.7574e+00],\n",
      "        [-9.8736e+00, -3.0405e+01,  1.4984e+01, -5.3139e+00, -1.4240e+01,\n",
      "         -1.7569e+01],\n",
      "        [-7.6796e+00, -2.3821e+01, -1.0216e+00,  1.6771e+01, -1.2095e+01,\n",
      "         -2.6640e+01],\n",
      "        [-5.5257e+00,  5.3112e+00,  1.9828e-01, -5.9419e+00, -1.1697e+01,\n",
      "         -7.0356e+00],\n",
      "        [-7.2038e+00, -7.3310e+00,  1.4939e-01, -7.7901e+00,  7.3607e+00,\n",
      "         -8.5821e+00],\n",
      "        [-3.4818e+00, -1.7055e+01,  3.6464e-01, -2.8478e+00, -1.5995e+01,\n",
      "         -1.0750e+01],\n",
      "        [-7.8518e+00, -4.9411e+00, -6.6073e+00, -3.6021e+00,  6.4303e+00,\n",
      "         -8.1808e+00]], device='cuda:0')\n",
      "tensor([4, 2, 1, 3, 5, 3, 2, 5, 4, 1, 5, 2, 3, 2, 2, 0, 1, 1, 5, 2, 4, 4, 3, 2,\n",
      "        0, 4, 2, 3, 1, 4, 2, 4], device='cuda:0')\n",
      "tensor([[ 11.6953, -29.0813, -21.2368, -15.6180, -18.7126,  -2.0485],\n",
      "        [ -4.9232,   7.8875,  -5.1609,  -5.9355,  -4.8794,  -5.6661],\n",
      "        [ -8.1346,   9.4571,  -9.0608, -12.2202, -17.0644,  -2.7876],\n",
      "        [ -1.7981, -22.4433, -10.9823, -15.8811,  -9.6167,   1.7400],\n",
      "        [ -6.9454,   5.0488,  -2.1548,  -5.6021,  -4.0224,  -8.4872],\n",
      "        [ -6.1164, -15.7901,   1.0562,   7.9654,  -7.1555, -15.5123],\n",
      "        [ -7.4294,   8.3165, -14.6647,  -8.8107, -13.7261,  -0.7827],\n",
      "        [ -8.0814, -25.0025,   4.3654,  -6.5934,  -4.4516, -12.9902],\n",
      "        [  9.8280, -16.9425, -18.0118, -12.1084, -10.1410,  -9.4840],\n",
      "        [-12.0078, -16.9307,  11.7215,  -5.0368,  -9.7511, -10.4425],\n",
      "        [ -9.1535, -11.6442,  -4.5984,  -3.9701,   5.9929,  -8.0676],\n",
      "        [ -9.6524, -10.8239,  -9.4715,  -4.3721,  12.4784, -10.5192],\n",
      "        [-12.4451,  -8.3832,  13.5337, -15.6185,  -8.7668,  -8.8848],\n",
      "        [ -5.7492, -17.3054,  -2.2315,   1.7948,  -4.0528, -12.1128],\n",
      "        [-14.5077, -19.9953,  15.3449, -10.8388,  -9.3661,  -6.9088],\n",
      "        [ -4.7384,   4.7099,  -3.9523, -11.9753, -17.2008,  -5.1682],\n",
      "        [ -9.7879, -15.0240,  -0.9815,  -5.5048,   2.0082,  -7.3048],\n",
      "        [ 16.6351, -15.6130, -15.4620, -19.7443, -25.4396,  -8.7498],\n",
      "        [-10.8441, -14.4459,  -3.7987,  -0.3011,  11.9965, -12.0659],\n",
      "        [ -0.1539, -15.5122,  -3.8397,  11.7664, -12.6545, -20.7483],\n",
      "        [ -3.6487,  -3.8311,  -6.5755,   0.7027,   1.8326, -10.3405],\n",
      "        [ -4.4142,  -2.9922,  -5.8799,   6.8121,  -2.5204, -13.1932],\n",
      "        [  3.2085, -16.0844,  -7.2244,  -9.4163,  -1.7715,  -8.4794],\n",
      "        [ -3.9168,  10.6065,  -6.5437,  -9.5008,  -9.6460,  -7.0020],\n",
      "        [ -2.0824,   3.3097,  -5.2531,  -2.0338,  -6.6416,  -6.8735],\n",
      "        [-15.6980, -28.3671,  15.6887,  -9.2272,  -1.9088, -12.1559],\n",
      "        [ -3.4747,   4.8595,  -9.5228,  -8.3683,  -8.0738,  -2.2933],\n",
      "        [ -9.7826, -29.6636,  10.0036,   6.5310, -19.9217, -13.6875],\n",
      "        [ -9.0668,  -7.2428,  -2.6329,  -1.1819,   5.8245,  -8.9065],\n",
      "        [ -4.4305,   6.6360,  -5.8163,  -5.2025,  -7.1944,  -6.1622],\n",
      "        [ -8.9939,   6.2616,  -5.6883, -19.4761, -10.4801,  -2.9572],\n",
      "        [-14.7833, -21.7531,  12.1547,  -2.1354, -16.1536, -13.9134]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1, 5, 1, 3, 1, 2, 0, 2, 4, 4, 2, 3, 2, 1, 4, 0, 4, 3, 4, 3, 0, 1,\n",
      "        1, 2, 1, 2, 4, 1, 1, 2], device='cuda:0')\n",
      "tensor([[-5.4466e+00, -2.1858e+01,  6.0971e+00,  1.0197e+00, -1.0112e+01,\n",
      "         -1.3067e+01],\n",
      "        [-7.8781e+00, -1.4187e+01,  1.3555e-02,  2.5773e+00, -3.9603e+00,\n",
      "         -1.1004e+01],\n",
      "        [-5.2152e+00, -9.1797e+00, -9.2321e+00,  7.5311e-01,  7.8250e+00,\n",
      "         -1.1114e+01],\n",
      "        [-8.4557e+00, -1.1406e+01, -8.5331e-01,  8.0548e+00, -9.0612e+00,\n",
      "         -1.1565e+01],\n",
      "        [-3.9732e+00, -1.5412e+01, -4.2357e+00, -6.2258e+00,  4.6196e+00,\n",
      "         -1.0321e+01],\n",
      "        [-5.9624e+00, -3.0240e+00, -6.3240e+00, -4.8901e+00, -1.5096e+00,\n",
      "         -2.0016e+00],\n",
      "        [-9.7621e+00, -2.0473e+01,  7.3034e+00,  5.0746e+00, -1.3772e+01,\n",
      "         -9.5229e+00],\n",
      "        [ 7.0432e+00, -3.2385e+01, -1.0799e+01, -9.6440e+00, -1.6354e+01,\n",
      "         -8.5449e+00],\n",
      "        [-7.1702e+00, -1.0149e+01, -1.5896e+00,  9.1902e+00, -1.9149e+01,\n",
      "         -1.6089e+01],\n",
      "        [-3.9951e+00, -2.0035e+01, -1.8600e+01, -2.3242e+01, -1.4717e+01,\n",
      "          9.2017e+00],\n",
      "        [-1.0083e+01, -1.4701e+01,  3.4624e+00,  6.6545e+00, -1.2800e+01,\n",
      "         -1.2319e+01],\n",
      "        [-1.1320e+01, -1.8923e+01,  8.9168e+00, -6.0046e+00, -9.3163e+00,\n",
      "         -1.1044e+01],\n",
      "        [-8.8334e+00, -7.2657e+00,  4.7904e+00, -3.9045e+00, -6.9434e+00,\n",
      "         -9.2760e+00],\n",
      "        [-1.3584e+01, -2.4241e+01,  1.2604e+01, -4.3690e+00, -1.3504e+01,\n",
      "         -8.0527e+00],\n",
      "        [-9.1593e+00,  1.6936e+01, -8.4749e+00, -1.7460e+01, -1.8798e+01,\n",
      "         -6.3870e+00],\n",
      "        [-9.5482e+00, -2.6255e+01,  7.9348e+00, -7.0106e-01, -7.9232e+00,\n",
      "         -1.1199e+01],\n",
      "        [-4.5412e+00, -3.1941e+01, -2.7987e+01, -2.9039e+01, -1.8459e+01,\n",
      "          9.6568e+00],\n",
      "        [-8.6665e+00, -1.7315e+01,  7.8053e-01,  2.8530e+00, -1.8947e-01,\n",
      "         -1.4329e+01],\n",
      "        [-1.3846e+01, -2.0066e+01,  8.1892e+00,  3.6842e+00, -1.4033e+01,\n",
      "         -1.5098e+01],\n",
      "        [-3.2376e+00, -8.3511e+00, -1.4806e+00,  7.5210e+00, -6.7632e+00,\n",
      "         -1.6155e+01],\n",
      "        [ 8.5123e-01, -2.1764e+01, -1.1695e+01, -1.7375e+01, -1.0439e+01,\n",
      "          2.3615e+00],\n",
      "        [-6.2979e+00,  1.3279e+01, -1.0317e+01, -1.5413e+01, -1.5858e+01,\n",
      "         -4.5512e+00],\n",
      "        [-8.5279e+00, -2.0286e+01,  4.3103e+00, -2.0458e+00, -6.5635e+00,\n",
      "         -8.2693e+00],\n",
      "        [-9.0910e+00, -2.9696e+01,  9.9983e+00,  3.1908e+00, -2.1137e+01,\n",
      "         -1.3294e+01],\n",
      "        [-7.3597e+00, -1.8288e+01, -1.4559e+01, -2.3181e+01, -1.3168e+01,\n",
      "          1.3124e+01],\n",
      "        [-3.5603e+00, -9.5417e+00, -1.2101e+01, -1.2718e+01, -8.5895e+00,\n",
      "          6.6281e+00],\n",
      "        [-2.6513e-01, -1.4708e+01, -2.2470e+00, -5.1948e-02, -8.3964e+00,\n",
      "         -1.2275e+01],\n",
      "        [-8.8000e+00, -7.9668e+00,  6.2740e-01,  7.8202e+00, -6.2741e+00,\n",
      "         -1.2518e+01],\n",
      "        [-5.7154e+00, -1.6610e+01, -8.9677e+00,  6.6886e+00, -6.0638e+00,\n",
      "         -9.9441e+00],\n",
      "        [-1.3851e+00,  7.6566e+00, -1.0604e+01, -1.2105e+01, -1.4277e+01,\n",
      "         -3.3344e+00],\n",
      "        [-8.6662e+00, -1.9268e+01,  5.7211e+00, -3.6612e+00, -2.6104e+00,\n",
      "         -1.4382e+01],\n",
      "        [ 7.1606e+00, -1.9976e+01, -9.5138e+00, -9.6967e+00, -7.2572e+00,\n",
      "         -1.0951e+01]], device='cuda:0')\n",
      "tensor([2, 3, 4, 3, 4, 4, 2, 0, 3, 5, 3, 2, 2, 2, 1, 2, 5, 3, 2, 3, 5, 1, 2, 2,\n",
      "        5, 5, 3, 3, 3, 1, 2, 0], device='cuda:0')\n",
      "tensor([[-1.1648e+01, -2.3392e+01,  5.1629e+00,  1.5978e+00, -8.4272e+00,\n",
      "         -1.2028e+01],\n",
      "        [ 2.0722e+01, -2.9765e+01, -2.6065e+01, -2.9912e+01, -2.1248e+01,\n",
      "         -3.2743e+00],\n",
      "        [-1.1258e+01, -1.6861e+01,  6.5132e+00,  5.4324e-02, -3.3105e+00,\n",
      "         -1.3238e+01],\n",
      "        [ 5.3096e+00, -3.4713e+01, -7.0356e+00, -2.2226e+01, -1.7843e+01,\n",
      "         -3.8354e+00],\n",
      "        [ 4.9316e+00, -3.7481e+01, -2.1195e+01, -3.1842e+01, -2.3284e+01,\n",
      "          1.3933e+01],\n",
      "        [-5.7774e+00, -5.2872e+00, -2.6209e+00,  7.7951e+00, -1.0201e+01,\n",
      "         -1.2735e+01],\n",
      "        [-5.5108e+00, -2.1259e+01, -1.1430e+01, -1.0639e+01, -1.5246e+01,\n",
      "         -4.0808e+00],\n",
      "        [-3.9451e+00, -2.0678e+01, -1.7166e+01, -9.9746e+00, -7.8624e+00,\n",
      "          3.3199e+00],\n",
      "        [ 1.4057e+01, -2.3893e+01, -2.1433e+01, -2.0468e+01, -1.1335e+01,\n",
      "         -6.4370e+00],\n",
      "        [-7.3509e+00, -2.4611e+01,  8.3021e-01,  1.4535e+01, -1.9169e+01,\n",
      "         -1.8650e+01],\n",
      "        [-2.4671e+00,  7.8947e+00, -6.4247e+00, -5.0384e+00, -7.8001e+00,\n",
      "         -6.3921e+00],\n",
      "        [-9.9549e+00, -1.2111e+01,  3.5299e+00,  8.6177e-01, -6.1386e+00,\n",
      "         -1.1792e+01],\n",
      "        [-1.7355e+00,  1.2194e+01, -1.0011e+01, -2.0666e+01, -2.2594e+01,\n",
      "         -1.6747e+00],\n",
      "        [-7.4238e+00, -8.2157e+00, -2.8704e+00, -2.2784e+00,  8.9108e+00,\n",
      "         -1.0921e+01],\n",
      "        [ 9.1610e+00, -3.1062e+01, -1.0049e+01, -7.4835e+00, -1.7445e+01,\n",
      "         -1.1396e+01],\n",
      "        [-1.1614e+01, -1.9109e+01,  9.3760e+00, -3.8390e+00, -1.1564e+01,\n",
      "         -7.2710e+00],\n",
      "        [ 3.2549e+00, -2.3293e+01, -1.9374e+01, -2.5400e+01, -2.0676e+01,\n",
      "          5.8758e+00],\n",
      "        [-4.5106e+00, -1.2504e+01, -7.6714e+00,  4.0458e+00, -3.8976e+00,\n",
      "         -1.2173e+01],\n",
      "        [-5.7024e+00, -1.7195e+01, -6.4880e-01,  1.2860e+01, -1.4440e+01,\n",
      "         -1.8487e+01],\n",
      "        [-1.0836e+00, -3.0064e+01, -1.4728e+01, -1.9061e+01, -1.3913e+01,\n",
      "          1.0000e+01],\n",
      "        [-4.8081e+00, -6.0952e-01, -2.7923e+00,  1.8684e-01,  3.4700e+00,\n",
      "         -4.3219e+00],\n",
      "        [-7.6153e+00, -1.1495e+01, -9.0610e+00, -2.9494e-01,  1.1551e+01,\n",
      "         -1.0834e+01],\n",
      "        [-8.6886e+00,  7.7832e+00, -1.1203e+01, -8.1146e+00, -1.3593e+01,\n",
      "         -4.5778e+00],\n",
      "        [-7.4033e+00, -6.3912e+00, -2.7050e-01, -2.4899e+00,  7.3140e-01,\n",
      "         -6.9896e+00],\n",
      "        [-1.6230e+00, -1.2316e+01,  1.6205e+00, -1.3156e+01, -1.2536e+01,\n",
      "         -6.3977e+00],\n",
      "        [-9.5188e+00, -4.9379e+00, -4.3361e+00,  2.7122e-01,  4.4108e+00,\n",
      "         -5.6673e+00],\n",
      "        [-6.2878e+00, -2.9138e+01,  1.0601e+01, -5.1630e+00, -8.4433e+00,\n",
      "         -1.4606e+01],\n",
      "        [ 1.9163e-01,  6.3680e+00, -9.0184e+00, -1.4590e+01, -1.2721e+01,\n",
      "         -4.3042e+00],\n",
      "        [-7.6375e+00, -2.4674e+01,  7.2332e+00, -9.5019e+00,  1.1699e+00,\n",
      "         -1.2274e+01],\n",
      "        [-1.1266e+01, -7.5837e-01, -3.0930e-01, -2.1578e+00, -5.5665e+00,\n",
      "         -6.8281e+00],\n",
      "        [-5.1055e+00, -9.8726e+00, -3.9247e+00,  9.2408e+00, -6.5722e+00,\n",
      "         -1.5070e+01],\n",
      "        [-7.7583e+00,  9.3872e+00, -6.2366e+00, -1.4248e+01, -1.0943e+01,\n",
      "         -1.1421e-02]], device='cuda:0')\n",
      "tensor([2, 0, 2, 0, 5, 3, 5, 5, 0, 3, 1, 2, 1, 4, 0, 2, 5, 3, 3, 5, 4, 4, 1, 4,\n",
      "        2, 4, 2, 1, 2, 2, 3, 1], device='cuda:0')\n",
      "tensor([[ -3.5776, -18.1341,  -0.1501,  10.4795, -10.0944, -18.1035],\n",
      "        [ 13.2572, -27.2421, -24.0892, -23.3798, -12.2959,  -4.9917],\n",
      "        [ -2.8128,   8.0612, -11.4235, -11.1061, -13.8779,  -3.3955],\n",
      "        [ -4.3854, -24.3417,  -7.8861, -16.3377, -12.9722,   3.7372],\n",
      "        [ -5.7832,  13.9259,  -8.3572, -11.0659, -22.2399,  -6.3845],\n",
      "        [ -4.6136,   9.2229,  -5.3980,  -6.8287,  -7.6396,  -6.1465],\n",
      "        [ 15.6358, -24.2720, -25.1923, -21.9317, -19.5355,  -5.0797],\n",
      "        [ -7.5178,  10.1212, -13.9749, -18.7479, -23.6610,   2.7510],\n",
      "        [ -2.1114,  -9.0139,  -8.6829,   8.8726,  -4.7516, -16.7547],\n",
      "        [ -6.4162, -25.8530,   4.2988,   7.3038, -11.6619, -15.8426],\n",
      "        [ -7.7400, -15.6049,  -3.3308,   3.5443,  -4.2587,  -9.1843],\n",
      "        [ -7.3036, -12.6005,  -5.8251,  -4.4328,   5.7855, -11.5015],\n",
      "        [-17.3957, -20.7563,  18.9190, -21.3003,  -4.8340,  -8.2778],\n",
      "        [ -9.6474, -12.0996,   2.7282,   5.3854,  -9.4267,  -8.7117],\n",
      "        [-12.2966, -20.3231,   2.9256, -19.6101,  11.5611,  -6.3267],\n",
      "        [  9.5010, -22.3513, -17.5417,  -5.1397, -20.0921, -10.1103],\n",
      "        [-11.0977, -15.9953,   9.2956, -14.8952,  -2.6202, -16.4424],\n",
      "        [ -3.6560,  10.0795,  -6.8270, -11.0143, -12.5511,  -6.6376],\n",
      "        [ -4.6610,   8.7416,  -5.3744, -13.0066,  -8.9178,  -7.0336],\n",
      "        [ -8.4784, -16.3175,   7.3787,  -8.7717,  -5.2720,  -7.1504],\n",
      "        [ -5.4747, -14.0663,  -6.7838,  -8.4897,  14.0273, -12.7993],\n",
      "        [ -8.9402,  -5.0422,  -5.6684,  -1.0275,   7.3143,  -6.0975],\n",
      "        [ -2.3586, -15.1556,  -7.6088, -11.0700,  -6.2389,  -3.4205],\n",
      "        [ -3.8922,  -7.0555,  -2.9251,   2.8206,  -5.4954, -10.5374],\n",
      "        [  6.1181, -25.0803, -12.1825, -20.3830,  -9.6252,  -2.7852],\n",
      "        [ -1.8127,  -8.2338,  -8.7683, -10.1748,  -8.0938,  -8.0975],\n",
      "        [ -7.6734,  -8.6042,  -3.1645,   7.5505,  -1.6300, -13.3607],\n",
      "        [ -9.2229, -17.2377,   4.6142,   2.4704, -10.6569, -10.5807],\n",
      "        [ -7.7138,  -3.6636,  -7.6998,  -5.9992,  10.9271, -10.0986],\n",
      "        [ -7.5120,  -5.6589,  -6.9732,   5.3935,   5.1384, -11.0516],\n",
      "        [  3.7712, -17.8566, -18.2522,  -7.6585,   1.1054,  -8.4122],\n",
      "        [-11.7081,   0.6539,  -7.4244, -19.9265, -12.2514,   4.8294]],\n",
      "       device='cuda:0')\n",
      "tensor([3, 0, 1, 5, 1, 1, 0, 1, 3, 3, 3, 4, 2, 3, 4, 0, 2, 1, 1, 2, 4, 4, 0, 3,\n",
      "        0, 0, 3, 2, 4, 3, 0, 5], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -8.6216,   8.1482,  -0.7112, -11.2658,  -8.8278,  -6.4420],\n",
      "        [-10.1394, -11.0456,   2.5300,  10.2232, -12.6207, -17.9621],\n",
      "        [ -6.8783,  12.5800,  -5.6457, -11.8416, -14.0482,  -3.9153],\n",
      "        [-16.1406, -27.9513, -37.0390, -36.4129, -32.8432,  -3.5960],\n",
      "        [ -8.2763, -10.1271,  -1.8215, -10.4742,  11.3975,  -9.9887],\n",
      "        [ -2.2591, -12.6828,   1.2276,   5.9108, -10.1241, -13.7614],\n",
      "        [  6.0556, -16.2368, -12.4658, -18.7876, -11.2385,  -6.6050],\n",
      "        [-12.4934, -10.0472,   2.2431, -13.7981,  11.4459,  -7.1784],\n",
      "        [ -9.1661, -13.8256,   4.5011,  -2.7517, -10.0279,  -4.8765],\n",
      "        [ -6.6308,  -1.0922,  -0.1029, -16.0120,  -9.0503,  -3.9619],\n",
      "        [ -0.7081, -10.2278,  -9.7011,  10.2298, -10.7624, -20.0761],\n",
      "        [ -6.3267, -19.5925,  -2.3898,  -3.2203,   8.9468, -15.8254],\n",
      "        [ -7.8213, -18.0695, -21.6466, -20.5155, -20.9389,   3.3162],\n",
      "        [ -7.1307, -17.7888,   2.6790,   9.1920, -13.5679, -17.3958],\n",
      "        [ -7.6543, -37.1973,  15.1078,   3.0198, -23.1863, -17.3576],\n",
      "        [ -8.9921, -10.5973,  -6.3014,   4.2464,   7.6120,  -9.6878],\n",
      "        [  6.3469, -23.3136,  -7.1824,  -9.0171, -15.6074, -10.4941],\n",
      "        [-10.2747, -39.2978,  13.8485,   1.7178, -21.1737, -13.2994],\n",
      "        [-10.8491, -12.1655, -10.0700, -12.8563,  16.6937,  -7.0505],\n",
      "        [ -5.7587, -25.5321,   5.0975,   9.6503, -18.4351, -15.8076],\n",
      "        [ -8.7850, -21.5300,  12.5229,  -7.0740, -12.2340,  -8.7515],\n",
      "        [ -4.3127, -19.7460,   2.1640,  10.8993, -17.8561, -18.0027],\n",
      "        [  2.4076, -31.7941, -23.2277, -25.6403, -16.9495,  13.4228],\n",
      "        [  9.1747, -37.3776, -16.4287, -26.1851, -14.3336,   2.4955],\n",
      "        [ -3.0943,  -9.9985, -16.6997, -26.2778, -20.6276,   9.5601],\n",
      "        [ -8.6886, -21.9212,   2.9063,   8.5122, -15.4380, -17.6833],\n",
      "        [ -7.1895,  -8.8095,   1.0006,  -7.1407,   9.1687, -11.6346],\n",
      "        [ -8.9519, -10.3494,  -1.2519,   0.6113,   1.9481, -12.0077],\n",
      "        [ -3.9394, -23.7285,   7.9167,  -1.1928, -15.6484, -18.0678],\n",
      "        [ -8.4886, -11.4528,  -3.6936,  11.5142, -11.8169, -21.5894],\n",
      "        [ -3.8710, -17.3963,  -6.5837,  -4.0942,   9.3287, -11.5037],\n",
      "        [-10.3661, -19.7997,  10.4295,  -3.9113, -14.5162,  -7.4136]],\n",
      "       device='cuda:0')\n",
      "tensor([1, 3, 1, 5, 4, 3, 0, 4, 2, 2, 3, 4, 5, 3, 2, 4, 0, 2, 4, 3, 2, 3, 5, 0,\n",
      "        5, 3, 4, 4, 2, 3, 4, 2], device='cuda:0')\n",
      "tensor([[-1.1336e+01, -1.2912e+01, -1.3297e+00, -1.3563e+01,  1.4063e+01,\n",
      "         -7.2708e+00],\n",
      "        [-9.6660e+00, -1.0408e+01, -8.5758e-01,  2.4232e+00, -6.6261e+00,\n",
      "         -1.1852e+01],\n",
      "        [-8.8397e+00, -1.7667e+01, -2.8077e-01, -5.9969e+00,  5.2512e-01,\n",
      "         -8.2674e+00],\n",
      "        [-1.7744e+01, -2.8761e+01,  1.9132e+01, -1.6855e+01, -5.1891e+00,\n",
      "         -1.5355e+01],\n",
      "        [-7.0526e+00,  1.2609e+01, -9.4249e+00, -1.3314e+01, -1.9222e+01,\n",
      "         -2.9943e+00],\n",
      "        [-3.1363e+00, -2.0377e+01, -6.8468e+00, -1.4876e+00,  3.5435e+00,\n",
      "         -1.2848e+01],\n",
      "        [-8.0237e+00, -2.0147e+01,  5.9938e+00,  9.4994e+00, -1.5145e+01,\n",
      "         -1.5835e+01],\n",
      "        [ 1.6911e+00, -1.2365e+01, -8.1731e+00, -7.2958e+00, -6.2704e+00,\n",
      "         -7.6997e+00],\n",
      "        [-8.3111e+00,  4.0653e+00,  3.5553e-01, -1.2447e+01, -7.9558e+00,\n",
      "         -3.4183e+00],\n",
      "        [-8.6904e+00, -2.5380e+01,  1.1842e+01, -4.5587e+00, -1.4293e+01,\n",
      "         -1.1599e+01],\n",
      "        [ 2.3937e+00, -1.3591e+01, -1.6076e+01, -2.2250e+01, -1.0019e+01,\n",
      "         -1.9433e+00],\n",
      "        [-1.8838e+00,  5.3280e+00, -9.6339e+00, -1.0549e+01, -1.5476e+01,\n",
      "         -4.8824e+00],\n",
      "        [ 5.9900e+00, -2.3876e+01, -1.5058e+01, -2.8905e+01, -1.3377e+01,\n",
      "          3.5997e+00],\n",
      "        [-5.1830e+00, -6.9945e+00,  1.2206e+00, -6.2413e+00, -1.0697e+00,\n",
      "         -3.1974e+00],\n",
      "        [ 2.1030e+00, -2.9135e+01, -2.6308e+01, -2.2424e+01, -1.2414e+01,\n",
      "          1.0940e+01],\n",
      "        [-4.0930e+00, -1.3740e+01, -9.6742e+00,  4.7606e+00,  4.7042e+00,\n",
      "         -1.5144e+01],\n",
      "        [-6.8458e+00, -1.9807e+01, -9.8449e+00, -1.5701e+00,  5.5054e+00,\n",
      "         -9.4354e+00],\n",
      "        [ 2.0934e-01, -1.8365e+01, -1.3593e+00,  6.4679e+00, -8.9650e+00,\n",
      "         -1.8618e+01],\n",
      "        [-3.5503e+00, -1.5534e+01, -6.2613e+00, -9.4273e-01,  4.8839e+00,\n",
      "         -1.2826e+01],\n",
      "        [-1.0459e+01, -2.4553e+01,  9.5566e+00,  8.1554e-02, -1.3882e+01,\n",
      "         -1.1841e+01],\n",
      "        [ 1.0422e+01, -2.3539e+01, -1.2392e+01, -6.6819e+00, -1.2461e+01,\n",
      "         -1.4564e+01],\n",
      "        [-6.0702e+00, -1.6146e+01, -2.0931e+00,  1.4932e+01, -1.2566e+01,\n",
      "         -1.9668e+01],\n",
      "        [-6.1120e+00, -1.3730e+01, -4.2413e+00, -1.0246e+01,  5.8302e+00,\n",
      "         -7.8825e+00],\n",
      "        [-1.0723e+01, -2.4311e+01,  2.2355e+00,  1.7080e+01, -1.7466e+01,\n",
      "         -2.2642e+01],\n",
      "        [-1.4545e+01, -1.9920e+01, -2.7533e+00, -2.0384e+01,  2.0228e+01,\n",
      "         -1.1581e+01],\n",
      "        [-1.7820e+00, -7.6439e+00, -5.8884e+00,  8.1292e+00, -7.2753e+00,\n",
      "         -1.3915e+01],\n",
      "        [-5.4877e+00, -1.6341e+01, -1.7176e+00,  5.5852e+00, -1.3959e+01,\n",
      "         -1.4759e+01],\n",
      "        [-5.9970e+00, -2.1461e+01,  1.2056e+00,  1.9333e+00, -6.4684e+00,\n",
      "         -1.2637e+01],\n",
      "        [-1.0023e+01, -7.4174e+00, -4.2939e+00,  6.3857e-01,  5.1206e+00,\n",
      "         -8.6694e+00],\n",
      "        [-9.0390e+00, -1.3856e+01, -5.7826e+00,  8.1213e-01,  3.4479e+00,\n",
      "         -1.5479e+01],\n",
      "        [ 5.7111e+00, -8.6012e+00, -9.6114e+00, -4.9712e+00, -1.9308e+01,\n",
      "         -7.3402e+00],\n",
      "        [-4.9337e+00, -7.2916e+00, -6.6087e+00, -1.0405e-02,  2.0412e+00,\n",
      "         -8.1672e+00]], device='cuda:0')\n",
      "tensor([4, 3, 4, 2, 1, 4, 3, 0, 1, 2, 0, 1, 0, 2, 5, 3, 4, 3, 4, 2, 0, 3, 4, 3,\n",
      "        4, 3, 3, 3, 4, 4, 0, 4], device='cuda:0')\n",
      "tensor([[-1.7990e-01, -1.5099e+01, -4.5609e+00, -7.4125e+00, -1.5311e+01,\n",
      "         -5.4216e+00],\n",
      "        [-8.4082e+00, -3.6228e+00, -3.3485e+00,  5.0851e+00, -2.8784e-01,\n",
      "         -8.5944e+00],\n",
      "        [-4.3872e+00, -4.8546e+00, -7.8538e+00, -8.6169e+00,  6.5579e+00,\n",
      "         -1.0467e+01],\n",
      "        [-3.9715e+00, -1.5502e+01, -2.3187e+00, -1.0576e+01,  4.4920e+00,\n",
      "         -8.9584e+00],\n",
      "        [-4.1071e+00, -8.0207e+00, -6.8163e+00,  2.8550e+00,  3.4221e+00,\n",
      "         -9.6725e+00],\n",
      "        [-9.2893e+00, -5.1394e+00, -4.1138e+00, -5.7281e+00,  1.2111e+01,\n",
      "         -1.3168e+01],\n",
      "        [-2.4576e+00, -2.5917e+00, -6.0548e+00,  4.2296e+00, -4.6579e-01,\n",
      "         -1.2171e+01],\n",
      "        [-9.7402e+00, -1.4303e+01,  3.5640e+00, -2.9508e+00, -6.4908e+00,\n",
      "         -1.3765e+01],\n",
      "        [ 2.3948e+00, -1.5582e+01, -1.0590e+01, -7.9749e+00, -4.7999e+00,\n",
      "         -7.9970e+00],\n",
      "        [-6.6927e+00, -1.7331e+01,  1.6101e+00,  9.4916e+00, -8.6580e+00,\n",
      "         -2.0707e+01],\n",
      "        [-3.3244e+00, -2.1063e+01, -1.8765e+01, -1.8221e+01, -1.2566e+01,\n",
      "          7.1931e+00],\n",
      "        [-7.5268e+00, -2.0629e+01,  4.6558e+00,  7.9709e+00, -1.3111e+01,\n",
      "         -1.4463e+01],\n",
      "        [-1.0992e+01, -5.4136e+00, -7.8735e+00, -1.0812e+01,  1.8555e+01,\n",
      "         -1.4389e+01],\n",
      "        [-1.2746e+01, -3.3425e+01,  1.5165e+01,  1.3259e+00, -1.9480e+01,\n",
      "         -1.2536e+01],\n",
      "        [-9.7890e+00, -1.1128e+01, -3.1722e+00,  6.7475e+00, -1.1215e+00,\n",
      "         -1.4903e+01],\n",
      "        [-3.2607e-01, -1.7334e+01, -1.8486e+01, -2.4962e+01, -1.6999e+01,\n",
      "          6.6899e+00],\n",
      "        [-1.0453e+01, -1.3444e+01, -3.7915e+00, -1.3017e+01,  1.3959e+01,\n",
      "         -7.1709e+00],\n",
      "        [ 2.6474e+00, -2.8197e+01, -1.6452e+01, -1.4214e+01, -1.0791e+01,\n",
      "          1.4376e+00],\n",
      "        [-5.7708e+00,  1.5839e+01, -9.2712e+00, -1.8314e+01, -2.5115e+01,\n",
      "         -1.1734e+00],\n",
      "        [-7.8124e+00, -1.9401e+01,  9.1553e+00,  1.0826e+00, -1.1622e+01,\n",
      "         -1.2637e+01],\n",
      "        [-1.1049e+01, -1.2068e+01,  3.7646e-01, -2.1380e-02,  6.5139e-01,\n",
      "         -9.0134e+00],\n",
      "        [ 9.6117e+00, -1.4450e+01, -1.3886e+01, -2.4798e+01, -1.4061e+01,\n",
      "         -6.5010e+00],\n",
      "        [-2.9531e+00,  9.4153e+00, -8.9009e+00, -1.6983e+01, -1.9558e+01,\n",
      "         -1.5036e-02],\n",
      "        [-4.7725e+00, -7.3028e+00, -5.1411e+00,  5.5476e+00, -2.3304e+00,\n",
      "         -1.3862e+01],\n",
      "        [-1.1706e+01, -1.4465e+01,  4.9184e+00, -2.8364e+00,  2.7204e-01,\n",
      "         -9.4480e+00],\n",
      "        [-4.8239e+00, -1.9122e+01, -1.4266e+01, -1.3553e+01, -1.6832e+01,\n",
      "         -8.2236e-01],\n",
      "        [-2.4852e+00, -2.4241e+01, -1.5848e+00,  9.2189e+00, -1.1614e+01,\n",
      "         -1.6702e+01],\n",
      "        [-5.2810e+00, -1.1235e+01, -1.4654e+01, -1.8580e+01, -2.2313e+01,\n",
      "          8.8136e+00],\n",
      "        [-1.1924e+01, -4.6663e+00, -8.0774e-01, -2.8224e+00,  8.9983e+00,\n",
      "         -1.1013e+01],\n",
      "        [-7.5958e+00, -1.9928e+01,  7.1956e+00,  2.2729e+00, -1.1644e+01,\n",
      "         -1.2560e+01],\n",
      "        [-8.7503e+00,  1.3076e+01,  2.0758e-01, -1.3130e+01, -1.7783e+01,\n",
      "         -9.0110e+00],\n",
      "        [-1.1699e+01, -4.2597e+00, -1.5702e+01, -1.5978e+01, -1.6176e+01,\n",
      "          3.2048e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 3, 4, 4, 4, 4, 3, 2, 0, 3, 5, 3, 4, 2, 3, 5, 4, 0, 1, 2, 4, 0, 1, 3,\n",
      "        2, 5, 3, 5, 4, 2, 1, 5], device='cuda:0')\n",
      "tensor([[ -7.6096,  -2.6629,  -4.3305,  -2.5219,   7.7500,  -6.1024],\n",
      "        [ -4.0532,  11.0978,  -7.8053,  -9.4588, -12.3292,  -6.9198],\n",
      "        [ -5.7055,   8.8824,  -3.6289, -13.1200, -10.3332,  -5.2764],\n",
      "        [ -8.5814, -14.0735,  -4.7806,  -3.6802,   8.2146, -16.7914],\n",
      "        [ -8.0275, -17.7163,   0.9618, -19.6631,  11.1793,  -3.9148],\n",
      "        [  7.6043, -24.3770,  -9.9734,  -6.7998,  -7.2809,  -6.7471],\n",
      "        [ -7.5021, -17.2764,   6.1307,   3.4821, -13.5022, -11.2548],\n",
      "        [ -6.0476,  -9.0233,  -0.8574,   5.6902,  -3.6811, -10.8493],\n",
      "        [-10.1802, -15.4209,  -8.3620,  -2.8320,  11.2212,  -8.4150],\n",
      "        [ -6.4994, -20.4690,   3.3327,  -3.3922,  -7.4855,  -9.9472],\n",
      "        [-12.0350, -12.1068,   9.3258,  -6.9341,  -4.1852,  -8.9442],\n",
      "        [-12.8497, -13.4833,   6.7223,   3.3980,  -8.9725,  -7.8879],\n",
      "        [ -6.7990,  10.1313,  -6.8893,  -9.6376, -11.7428,  -9.7270],\n",
      "        [ -5.1858,  10.1340,  -6.9617, -13.9660, -18.2528,  -1.7911],\n",
      "        [-10.8479, -26.1526,   9.9882, -10.0335,  -4.7350,  -9.8136],\n",
      "        [ -4.4710,  11.7173,  -0.9699, -14.6377, -13.0459,  -9.1498],\n",
      "        [ -4.0598,   1.6746,  -9.7983,  -6.8464,  -7.9606,   3.3929],\n",
      "        [ -8.4473, -16.8588,   5.0828,  -4.5865,  -5.3601, -10.9069],\n",
      "        [ -9.5111, -25.3772,   6.3116,   2.6169, -11.4065, -14.2668],\n",
      "        [-11.6222, -21.0867,  18.2822,  -8.2715, -14.4885, -14.5742],\n",
      "        [-10.8215, -13.1624,  11.4930,  -6.3532, -10.9996,  -8.6934],\n",
      "        [  4.6368, -21.5934,  -9.4374, -10.9139, -15.9351,  -7.7373],\n",
      "        [ -9.6418, -16.6936,  -1.9689, -10.2253,   3.4327,  -9.2218],\n",
      "        [  5.6262, -23.8493, -12.5534, -24.5288, -13.6043,   1.3659],\n",
      "        [  4.9952, -34.7819, -28.4834, -24.8487,  -6.6238,   9.0465],\n",
      "        [ 10.9992, -24.4719, -26.0424, -22.0278,  -3.7783, -10.2772],\n",
      "        [ -3.8097, -12.8937,  -3.8561,   9.5081,  -9.2376, -13.7004],\n",
      "        [  3.7937, -18.0033, -17.0102, -19.0286, -12.1301,   3.6170],\n",
      "        [ -0.1741, -10.7090, -13.8293,  -8.5972,  -6.5592,  -0.6025],\n",
      "        [-12.0317, -33.8944, -23.3416, -29.4283, -22.4618,  13.7024],\n",
      "        [ -6.3937, -25.4978,   1.1788,  15.5744, -16.1894, -24.5040],\n",
      "        [  4.3993, -27.6949,  -8.3321, -13.4954, -11.1315,  -4.7806]],\n",
      "       device='cuda:0')\n",
      "tensor([4, 1, 1, 4, 4, 0, 2, 3, 4, 2, 2, 2, 1, 1, 2, 1, 5, 2, 2, 2, 2, 0, 4, 0,\n",
      "        5, 0, 3, 0, 0, 5, 3, 0], device='cuda:0')\n",
      "tensor([[ -3.9743, -17.9509,  -4.3343,  -0.0515,  -2.6762, -13.7327],\n",
      "        [ -7.5355, -10.2055,   0.1819,   8.5482,  -9.9200, -15.6757],\n",
      "        [ -4.1015, -17.8710,  -2.5690,  10.7929, -13.5967, -16.4477],\n",
      "        [  3.2249,  -4.5581, -15.4469, -21.0592, -13.4231,   2.7572],\n",
      "        [ -7.0558, -16.5315,  -6.9970, -20.4512,  18.5420, -10.0782],\n",
      "        [ -9.8565, -23.3978,   8.9103,   3.9786, -14.6266, -12.9486],\n",
      "        [  8.8167, -24.2536, -20.7543, -10.1601, -12.1514,  -7.5766],\n",
      "        [ -7.1140,  14.0308,  -3.3235, -20.1534, -16.0202,  -5.3516],\n",
      "        [ -5.8317,   8.5289,  -4.5955,  -7.6037, -10.4780,  -6.1132],\n",
      "        [-14.6484, -11.1066,  16.2803, -12.9627, -11.9590, -12.4463],\n",
      "        [ -5.2790, -32.7615,  -7.4918, -22.6031,  -8.4021,   7.1553],\n",
      "        [ 13.2213, -12.8178, -14.0104, -15.3171, -14.3777,  -8.5884],\n",
      "        [ -6.8861, -16.5505,   3.7767,   6.5628, -12.5275, -13.5831],\n",
      "        [ -6.9742,  13.1475,  -6.2955, -17.9437, -19.4666,  -0.3734],\n",
      "        [-14.6965, -34.3442,  18.4493,  -6.5888, -17.4561,  -9.0655],\n",
      "        [ -3.4653,  13.5080, -10.6692, -18.8376, -25.5490,  -1.9189],\n",
      "        [-14.3370, -17.3498,  13.7148, -11.0138,  -6.3672, -10.9263],\n",
      "        [ -8.5661, -12.0800,  -5.8227,  -3.8070,   9.0433,  -7.5726],\n",
      "        [  3.1895, -34.0808, -22.0821, -27.8177, -13.1812,  11.3609],\n",
      "        [ -8.4444,  11.3900,  -2.6194, -13.2996,  -9.5088,  -5.2494],\n",
      "        [-10.4659, -11.9829,  -5.6900,  -6.8269,  13.4213,  -7.8505],\n",
      "        [ -9.9599, -22.5979,   8.3843,   0.1651, -10.3360, -14.7247],\n",
      "        [-13.4075, -23.1823,   1.1830,  -9.3375,   7.8843,  -9.9652],\n",
      "        [-11.8511, -19.4402,   9.6237,   4.7148, -16.8419, -11.7754],\n",
      "        [ 22.8299, -31.7873, -26.3321, -19.4335, -24.7876, -15.0584],\n",
      "        [-10.3823, -12.3337,  -5.7666,   0.0450,  12.1650, -10.8731],\n",
      "        [-10.9952,  -9.6736,  -2.0593, -15.3213,  14.5371,  -8.4941],\n",
      "        [ -2.4270,  11.2445,  -8.7150, -15.4794, -15.3755,  -3.4338],\n",
      "        [-14.7580,  -9.6017,  -4.3135, -15.2556, -14.9416,   5.7438],\n",
      "        [-13.1314, -33.4230,  16.6107,  -1.7490, -15.7907, -16.8160],\n",
      "        [ -9.6503, -11.0769,  -4.2490,   6.7703,  -5.5644,  -9.5488],\n",
      "        [-10.6090, -15.1067,  10.8988,  -8.4390,  -7.4963,  -9.2128]],\n",
      "       device='cuda:0')\n",
      "tensor([3, 3, 3, 0, 4, 2, 0, 1, 1, 2, 5, 0, 3, 1, 2, 1, 2, 4, 5, 1, 4, 2, 4, 2,\n",
      "        0, 4, 4, 1, 5, 2, 3, 2], device='cuda:0')\n",
      "tensor([[  1.2719, -25.5248,  -7.6089, -16.7685, -15.4168,  -3.6044],\n",
      "        [ 13.1778, -51.1365, -25.8696, -34.7933, -18.7029,   9.0477],\n",
      "        [ -6.8682,   3.3948,  -5.5152,   5.1344,  -1.8823,  -7.4611],\n",
      "        [  0.4459, -10.8051,  -5.0801,  -5.7695,  -8.3344,  -6.9558],\n",
      "        [-24.6839, -39.2622, -39.3240, -36.1847, -31.5623,   5.5545],\n",
      "        [ -7.4554, -20.5794,   4.2891,  -6.2367, -16.2208,  -2.2126],\n",
      "        [  1.9144, -29.2996, -12.9898, -14.2196, -17.1429,   0.8733],\n",
      "        [ -9.9732, -12.0598,  -6.3621, -12.7107,  13.4869,  -7.3048],\n",
      "        [ -8.7381,  -9.0054,  -9.8499,  -9.2666,   5.6166,  -6.2147],\n",
      "        [-11.6414, -26.8188,  12.6345,  -3.8232,  -9.2516, -10.6142],\n",
      "        [-12.0936, -10.8585,  -2.8962,  -8.0794,   6.5421,  -7.3495],\n",
      "        [ -7.2543,  -9.0794,  -7.7017,  -4.3351,   9.2658, -12.3257],\n",
      "        [ -2.6954,  -6.6906, -14.5204, -10.0933, -12.4550,   2.0458],\n",
      "        [-10.3714, -13.5401,  -1.2495, -17.4894,  12.8149,  -7.3470],\n",
      "        [ -0.3051, -11.3175, -15.2026, -17.9985, -13.4090,   5.5947],\n",
      "        [ -2.7701,  11.7744, -10.8910, -12.5172, -14.2208,  -4.3529],\n",
      "        [  5.1185,  -7.4489, -13.3665, -11.3540, -11.1095,  -8.0136],\n",
      "        [ -6.8367,  -6.0039, -11.2559,  -3.9530,  -3.4342,   3.0327],\n",
      "        [  7.2242, -30.9347, -21.2308, -13.4379, -17.3873,   0.2175],\n",
      "        [ -8.0510,  -1.1280,  -9.6884, -16.1492, -17.9904,   1.9627],\n",
      "        [-10.6248, -21.1396,   6.5918,  12.1745, -18.0441, -20.3030],\n",
      "        [ -8.7449, -12.5124,   0.0781,  -0.3877,   1.8879, -10.8040],\n",
      "        [ -4.3318, -24.2506,  -2.4190,  11.0238, -14.1868, -15.8785],\n",
      "        [ -5.3277, -26.2697,   3.1603,  -3.7118,  -8.7013, -12.4120],\n",
      "        [ -4.6277,  10.6282,  -6.3856, -10.9780, -13.4019,  -0.7242],\n",
      "        [ -9.7296, -19.2060,   1.5441,  12.7084, -10.2999, -17.4577],\n",
      "        [  7.9152, -33.6475,  -9.8146, -11.6771, -21.3154,  -6.0653],\n",
      "        [-11.5702,  -4.7182,   6.1430,  -5.4720,  -5.8331,  -5.1877],\n",
      "        [ -7.5494, -14.6106,   1.5740,  -5.1587,   4.7964,  -8.2588],\n",
      "        [  7.2382, -17.0634, -18.5877, -11.3514, -17.2114,  -9.4516],\n",
      "        [ -8.7544, -13.5700,  -3.4424,  -6.1785,   9.6801,  -7.6372],\n",
      "        [ -0.3331,   8.6105, -13.4792,  -6.4848, -15.3517,  -9.5307]],\n",
      "       device='cuda:0')\n",
      "tensor([0, 0, 3, 0, 5, 2, 0, 4, 4, 2, 4, 4, 5, 4, 5, 1, 0, 5, 0, 5, 3, 4, 3, 2,\n",
      "        1, 3, 0, 2, 4, 0, 4, 1], device='cuda:0')\n",
      "tensor([[  5.4354, -20.8238,  -9.9553,  -4.7517,  -9.4482, -11.4657],\n",
      "        [  7.8406, -25.5798,  -9.5454,  -8.9690, -15.9200,  -8.0758],\n",
      "        [-11.5966, -32.4763,   9.8674,   3.6426, -14.1688, -17.8409],\n",
      "        [ -0.7822, -23.3035,  -6.9387,  -5.5394, -15.2159,  -6.7546],\n",
      "        [-12.2146, -18.3067,  -8.0052, -12.5709,  18.4206,  -8.2526],\n",
      "        [ -6.0950, -10.6658, -12.4006, -17.1708, -16.3320,   9.6038],\n",
      "        [-10.6007, -16.4431,   1.7790,   8.3886, -12.2526, -11.1207],\n",
      "        [-16.1447, -13.6992, -19.0311, -22.8406, -20.3593,   3.0052],\n",
      "        [ -7.0383, -11.3429,   6.3951,  -1.7679, -12.2947, -13.0416],\n",
      "        [ -7.6755,   7.3639,   0.1348,  -6.4583,  -5.8945,  -7.7251],\n",
      "        [  9.8559, -36.8119, -23.9032, -19.1141, -21.9008,   3.4596],\n",
      "        [  0.1476, -21.3124,   1.9737,   4.7919,  -7.4530, -14.6522],\n",
      "        [ -8.5260, -25.0954,  11.2087,  -8.1290,  -3.2391, -12.1942],\n",
      "        [ -4.8503, -18.0207,   1.5249,   1.8303,  -5.8300,  -8.1439],\n",
      "        [ 10.8778, -37.4827, -13.9200,  -2.3539,  -7.5529, -18.6800],\n",
      "        [ -4.9083, -22.1961,  -5.4906, -12.1929,  13.4172, -13.1544],\n",
      "        [ -8.2770, -12.2566,   2.6862,   7.1184, -10.2611, -13.1932],\n",
      "        [  2.8909,   7.4656, -10.0102, -13.8338, -17.4149,  -6.9207],\n",
      "        [  2.7595, -15.7454, -13.6648, -15.0687, -21.6028,   0.6525],\n",
      "        [ -2.9582, -23.5526, -10.0902, -17.0722,  -8.4204,   2.3517],\n",
      "        [ -6.2153, -18.8641,   0.4847,  11.2522, -10.7915, -16.3296],\n",
      "        [  6.2151, -25.6374, -19.2463, -18.6031, -10.9153,   0.1328],\n",
      "        [ 12.0011, -29.3637, -11.4813, -14.7285, -13.2693,  -7.7456],\n",
      "        [ -5.0704, -18.6651,  -1.7133,   3.3074, -10.4761,  -9.0818],\n",
      "        [ -8.7282, -16.0362,   1.5105,   8.9648, -17.0162, -15.7142],\n",
      "        [ 10.3082, -34.9285, -11.4298,  -2.9002,  -5.2513, -15.2787],\n",
      "        [ -9.5659,  -4.1502,   0.1916,  -6.2759, -18.3254,  -3.4253],\n",
      "        [ -5.1903, -12.9139, -10.4518,  -9.2355,  12.0720,  -7.2998],\n",
      "        [ -5.0195, -19.2519,  -8.2086, -11.3850,  11.9559,  -7.9832],\n",
      "        [ -2.2381,  15.2488, -11.8141, -19.1893, -21.1712,  -4.9692],\n",
      "        [  0.9414, -26.5736, -14.5663, -21.9189, -15.6502,   7.4065],\n",
      "        [ -6.8383,  -5.4277,  -5.6236,   3.5132,   6.2333, -14.8025]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 2, 0, 4, 5, 3, 5, 2, 1, 0, 3, 2, 3, 0, 4, 3, 1, 0, 5, 3, 0, 0, 3,\n",
      "        3, 0, 2, 4, 4, 1, 5, 4], device='cuda:0')\n",
      "tensor([[ -6.8930, -24.8815,   2.3823,   4.8361, -17.4549, -15.3951],\n",
      "        [-14.8423, -22.3824,  16.8970, -10.1903, -11.1349, -10.5406],\n",
      "        [ 12.4328, -14.9799, -25.0739, -27.0080, -14.2311,  -0.2164],\n",
      "        [ -1.2653,  19.3199,  -8.4184, -23.0415, -30.1916,  -6.1717],\n",
      "        [ -4.1355,  12.0328,  -3.3149, -13.1384, -13.7827,  -9.7984],\n",
      "        [ -9.4927, -13.6613,  -4.6035,  11.1665,   0.6254, -19.3481],\n",
      "        [ -2.5497, -10.4636,  -0.5455,   1.4677, -11.6642, -10.3134],\n",
      "        [ -7.0823,   9.7554, -13.5115, -12.5899, -17.5039,  -4.0531],\n",
      "        [  0.3259, -27.4562, -13.5297, -19.8258, -10.8797,   0.8010],\n",
      "        [ -5.4853,  15.9789, -10.9806, -21.2674, -29.0868,  -2.6331],\n",
      "        [-10.3299, -24.3420,  10.0116,  -3.6043,  -9.3123, -11.6351],\n",
      "        [ -0.4695, -16.1555, -10.3659,   4.7210,  -7.2281, -13.3008],\n",
      "        [ -6.1986,   1.4697,  -5.4189,  -1.9057,   0.7351,  -8.8121],\n",
      "        [ -8.6261, -32.2219,   7.0591,   7.2231, -10.4496, -21.3777],\n",
      "        [-13.3563, -14.6079,  -2.9399,  -7.2417,  12.3051,  -9.4518],\n",
      "        [ -5.2679, -12.4044,  -2.1553,  -0.2643,  -1.0646,  -5.2702],\n",
      "        [  3.1492, -15.0530, -16.3677, -13.0013, -14.5076,   0.3893],\n",
      "        [ -4.2503,  -7.7759,  -2.5159,   0.2287,  -8.0762,  -7.6412],\n",
      "        [  7.9999, -37.4144,  -3.8107,  -8.0872, -22.6768,  -9.0854],\n",
      "        [  3.0687, -24.8182,   0.9083,  -0.3577, -22.2702, -17.5532],\n",
      "        [ -3.1561,   6.2560,  -7.2724, -17.4240, -11.4573,  -2.2535],\n",
      "        [ -0.9239, -19.2864, -15.2567, -18.4468, -11.0961,   5.3126],\n",
      "        [ -9.6004,  -8.3298,   7.1627,  -5.7062,  -6.9931,  -7.2261],\n",
      "        [ -7.4967, -18.1653,   1.6451,  10.0240, -17.6565, -16.0708],\n",
      "        [-11.0781, -13.4154,  13.3217,  -6.6872, -10.9894, -12.1574],\n",
      "        [ -5.9115, -16.8853,  -5.4740,  -1.0807,  11.4338, -13.6828],\n",
      "        [ -3.7530,   3.7796, -11.5797,  -8.3895,  -4.6055,  -6.8464],\n",
      "        [ -6.9740, -24.1359,   6.9339,  -2.7650,  -7.5248, -13.1910],\n",
      "        [  4.6403,  -2.2862,  -8.0638,  -9.4111,  -8.9906,  -3.0181],\n",
      "        [-10.8721, -17.8385,   5.1367,   4.4977, -10.5378, -16.4697],\n",
      "        [ -7.7188,  -9.5384,  -5.3077,  -8.7862,  10.7574,  -9.4927],\n",
      "        [ -9.8099, -20.7852,   6.1872,  -5.2973,  -5.6600,  -7.8652]],\n",
      "       device='cuda:0')\n",
      "tensor([3, 2, 0, 1, 1, 3, 3, 1, 5, 1, 2, 3, 1, 3, 4, 3, 0, 3, 0, 0, 1, 5, 2, 3,\n",
      "        2, 4, 1, 2, 0, 2, 4, 2], device='cuda:0')\n",
      "tensor([[ -7.4638,  -7.7249, -10.1985, -20.4467, -14.5457,   7.8855],\n",
      "        [  0.9161, -14.6925,  -0.3410,  -7.6781, -10.8185,  -5.3957],\n",
      "        [-11.3764, -19.7358,  11.4316,  -1.1952, -10.8938, -10.9151],\n",
      "        [ -4.1452,  -6.5751,  -6.1885,   9.0587,  -7.0171, -11.5504],\n",
      "        [ -9.3262, -13.2946,  -8.0600,  -2.9554,  13.2742,  -9.9884],\n",
      "        [-17.1358, -28.5325, -21.1816, -36.1434, -26.3618,   4.0426],\n",
      "        [-11.8587, -26.4833,   9.8507,  -0.1308, -15.6187, -10.2075],\n",
      "        [-11.9610,  -8.4084, -10.6410,  -6.9423,  17.6356, -14.4021],\n",
      "        [-14.1780, -31.5278,  13.7155,  10.7584, -24.8369, -18.0770],\n",
      "        [ -3.8528, -10.2882,  -7.4339,   4.9894,  -5.6345, -10.4412],\n",
      "        [ -6.0546,   6.9300,   0.5961,  -4.9320,  -7.6564,  -8.9026],\n",
      "        [ 14.3206, -36.8769, -12.7136, -11.8248, -14.2522, -11.9263],\n",
      "        [ -3.9876, -21.7246, -16.2829, -15.5902, -18.7083,   9.1940],\n",
      "        [ -4.8293, -18.5632,   1.3038,  13.2140, -15.8621, -20.2708],\n",
      "        [ -1.2601, -25.1106,  -2.5510, -14.1017, -10.9758,  -5.4384],\n",
      "        [ -2.6925,  12.6434,  -6.9598, -13.6027, -16.8757,  -6.1217],\n",
      "        [ -7.6595, -14.3208,  -0.9365,  -5.9362,   7.1193, -12.3467],\n",
      "        [  4.1508, -15.7722, -14.0989, -16.4153, -22.0290,   2.3435],\n",
      "        [ -6.7141,   4.8242,  -2.4990, -10.5638,  -9.1783,  -1.4125],\n",
      "        [-10.6458, -26.7786,   3.3030,  11.0526, -16.2500, -14.1355],\n",
      "        [-11.8274, -22.2027,   6.6589,   1.7811,  -5.8597, -13.5172],\n",
      "        [ -2.8944, -17.0965,  -6.0834, -10.8909,  -7.2262,  -7.5639],\n",
      "        [ -2.3606,  -1.6857, -15.5950,  -7.5371,  -9.7248,   1.5725],\n",
      "        [-10.4597, -12.3330,   5.3396,  -2.5672,  -7.4287,  -9.0092],\n",
      "        [-10.7789, -10.3743,   2.6176,   3.9638, -13.9443,  -8.0949],\n",
      "        [ -5.6996, -30.5436,   8.9740,  -4.8069, -14.5001, -11.3621],\n",
      "        [ -6.9737, -17.0578,   7.3227,  -3.8375, -16.5235,  -4.9232],\n",
      "        [ -1.6195, -21.6679,  -7.6428, -16.9658,  -9.1441,  -0.9516],\n",
      "        [ -6.7966, -17.0163,   6.4243,  -2.1569,  -9.0605, -13.3214],\n",
      "        [-10.6669, -24.9658,  11.6207,  -2.1883, -13.0052,  -9.1708],\n",
      "        [ -5.6208,  12.8448,  -6.5757, -14.1237, -17.2032,  -5.6284],\n",
      "        [  3.9557, -21.7213,  -4.0623, -11.5314, -11.6363,  -6.5457]],\n",
      "       device='cuda:0')\n",
      "tensor([5, 0, 2, 3, 4, 5, 2, 4, 2, 3, 1, 0, 5, 3, 0, 1, 4, 0, 1, 3, 2, 0, 5, 2,\n",
      "        3, 2, 2, 5, 2, 2, 1, 0], device='cuda:0')\n",
      "tensor([[  2.6253, -21.7098, -13.7235, -14.7347, -11.9911,  -2.0646],\n",
      "        [ -2.8897,  10.6488,  -8.2625, -14.3663, -16.1349,  -2.9957],\n",
      "        [-15.7781, -31.2722,  13.8917,  -6.8207,  -8.1253, -19.1805],\n",
      "        [ -4.3797, -18.2920,  -2.5666,   8.2565,  -7.8978, -16.8326],\n",
      "        [-12.0863, -11.3848,   2.1957,   4.2588, -10.9623,  -7.4193],\n",
      "        [  9.8890, -31.2574, -15.5756, -13.7532,  -8.8963, -11.5057],\n",
      "        [-17.1507, -14.6578,   9.9248,  -9.2422,  -4.2098,  -5.6532],\n",
      "        [-11.1928, -15.7891,   4.0064,   3.3900,  -7.2626, -11.7867],\n",
      "        [  3.7920, -20.7479, -15.3533, -11.5942, -12.9850,  -2.7619],\n",
      "        [-12.5273, -17.9755,  12.9880,  -9.8146,  -9.5267, -13.8391],\n",
      "        [-16.1706, -19.5001,  11.1429, -11.7735,  -3.0786,  -5.5485],\n",
      "        [ -2.4242,   6.5682, -10.6993, -16.6698, -14.9459,  -2.8129],\n",
      "        [  2.8172,  12.5433, -19.4187, -22.0157, -26.4986,  -2.6225],\n",
      "        [ -9.0373,  -6.7032,  -5.8913,   5.9148,   7.4248, -11.6466],\n",
      "        [-10.1318, -24.5431,  -2.0110, -20.0821,  18.3221, -10.2257],\n",
      "        [ -3.5589,  -9.9729,  -6.9314,   1.4154,   4.4081, -10.9648],\n",
      "        [ -9.7910, -18.1105,   6.6427,  -6.7657,  -0.8512,  -7.8690],\n",
      "        [-11.7215, -28.9120,  11.7203,   2.0589, -14.9116, -17.7746],\n",
      "        [ -1.2321, -10.9300, -17.4330, -21.3606, -18.4436,   7.6935],\n",
      "        [ -3.8176,  14.4694, -11.0577, -21.0844, -24.9038,  -0.6823],\n",
      "        [ -2.9801,   3.4546,  -8.3231,  -7.5684, -11.6234,  -4.3414],\n",
      "        [ -6.5679, -16.7922,  -8.6608, -11.5427,  -9.9675,   4.4197],\n",
      "        [ -0.6945, -15.0706,  -4.2895,  -9.2645,  -2.8502,  -5.0608],\n",
      "        [ -7.7832,   8.0051,  -2.6866,  -8.6397,  -7.3738,  -4.9848],\n",
      "        [ -7.5738, -15.5387,   1.9511,   2.6417,  -6.5856, -15.4768],\n",
      "        [  7.5460, -38.3408,  -5.5838,  -6.1720, -15.6679, -14.0983],\n",
      "        [ -5.6428,  -3.1720,  -5.5879,   2.0706,   2.7135,  -7.5975],\n",
      "        [ -2.4995,  -0.5976, -11.9675, -12.8508, -16.9811,   0.5170],\n",
      "        [ -7.0756,   7.8775,  -2.0845,  -7.7873,  -8.8118,  -3.8953],\n",
      "        [ -7.4288, -18.4737,  -7.1024, -14.3628,  -0.2425,  -0.1169],\n",
      "        [ -7.0827, -13.0313,   0.5820, -12.9416,   0.7194,  -8.5860],\n",
      "        [-10.0802, -24.4319,   6.3191,   4.9008, -18.9940, -15.3667]],\n",
      "       device='cuda:0')\n",
      "tensor([0, 1, 2, 3, 3, 0, 2, 2, 0, 2, 2, 1, 1, 4, 4, 4, 2, 2, 5, 1, 1, 5, 0, 1,\n",
      "        3, 0, 4, 5, 1, 5, 4, 2], device='cuda:0')\n",
      "tensor([[ -7.7824,  -9.9175,  -3.8961,  -6.6360,  11.3814,  -7.0649],\n",
      "        [ -0.5063, -18.9710,  -1.3942,   2.6214, -16.0057, -10.2309],\n",
      "        [  8.1430,  -3.3274, -15.3998, -14.4630, -15.6844,  -2.4261],\n",
      "        [ -9.5186,  -5.3046,  -0.8105,   6.9358,  -5.9654, -10.4303],\n",
      "        [-16.2259, -15.1061,  14.8442, -13.9447,  -3.0467,  -6.5736],\n",
      "        [-16.1062, -15.2520,   4.3785,  -5.1613,   4.5934, -11.4231],\n",
      "        [ -4.3589,   9.1660,  -9.1668,  -7.9846,  -8.4269,  -5.0891],\n",
      "        [  3.4553, -16.7344, -16.1161, -22.0579,  -8.9417,  -2.1302],\n",
      "        [ -1.9624,  -5.5408, -13.9834, -14.8696, -15.6692,   4.1576],\n",
      "        [ -5.7068,   8.6078,  -6.2559, -11.5809,  -8.3967,  -6.9658],\n",
      "        [-10.4630, -25.0754,   4.2414,   4.9407,  -9.6642, -13.7079],\n",
      "        [ -0.9048,  13.8106,  -9.9027, -14.5309, -20.1139,  -4.6293],\n",
      "        [ -8.2932, -16.9814, -17.3252, -19.2699, -19.0379,   2.6217],\n",
      "        [ -5.0256,  13.0659,  -7.5491,  -8.6211, -21.2812,  -8.8077],\n",
      "        [ -6.6040,   6.9625, -11.2672,  -9.3472, -10.0757,  -3.1820],\n",
      "        [  4.6746, -39.2512,  -8.8957, -10.5713, -13.0616,  -6.6858],\n",
      "        [  1.0896, -29.4175, -11.8315,  -5.4366, -10.9860,  -8.7702],\n",
      "        [ -4.1449,   6.4889,  -6.1287,  -7.1655, -11.6814,  -5.7017],\n",
      "        [ -6.5865, -14.5009, -14.1580, -15.3803, -12.7117,   2.2160],\n",
      "        [ -7.3243, -31.5281,  13.7474,   3.3646, -18.0403, -17.8967],\n",
      "        [  1.8202, -21.5921, -10.7244, -16.7423,  -6.1085,   0.1975],\n",
      "        [-14.4963, -22.6442,  11.1941,  -6.3137,  -9.3786, -11.8039],\n",
      "        [ -1.7795, -11.4538, -13.0717, -23.7685, -12.8659,   3.1673],\n",
      "        [ -4.2512, -18.3402,  -1.7041,  14.3850, -13.7250, -20.1890],\n",
      "        [  2.5090, -14.5493,  -9.3266, -17.4627, -13.9925,  -0.8591],\n",
      "        [ -5.7873, -10.6757,  -0.1484,   2.7889, -10.0431,  -9.0842],\n",
      "        [ -9.9673,  13.4565,  -1.9445, -17.0164, -19.8310,  -6.4399],\n",
      "        [ -5.8452,  12.9394, -10.8514, -16.1611, -21.4442,  -1.6624],\n",
      "        [-10.2061, -25.9993,   7.6057,  10.3162, -19.5638, -16.8804],\n",
      "        [ 24.3922, -33.2567, -29.0110, -32.0137, -24.3163,  -4.0161],\n",
      "        [-10.0211, -20.6626,   8.8498,  -0.9651,  -8.2093, -13.5448],\n",
      "        [ -5.7528, -13.9254,  -7.8511,  -5.0497,   8.5477, -11.7547]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 3, 0, 3, 2, 4, 1, 0, 5, 1, 3, 1, 5, 1, 1, 0, 0, 1, 5, 2, 0, 2, 5, 3,\n",
      "        0, 3, 1, 1, 3, 0, 2, 4], device='cuda:0')\n",
      "tensor([[ -5.3449, -12.7391,  -3.5705,   4.6132,  -0.7823, -13.3239],\n",
      "        [  5.0637, -29.0237, -13.3612, -18.6154, -15.8980,   1.8153],\n",
      "        [ -4.9365,  12.8774,  -3.0202, -12.5121, -12.7475,  -6.9903],\n",
      "        [ -1.9179, -11.1986, -15.8336, -19.7978, -20.3135,   5.8163],\n",
      "        [ -3.5108, -30.1206,   1.6353,  -0.2783, -11.6558, -14.9063],\n",
      "        [ -6.2118, -26.7086, -10.1244, -24.3122, -13.5914,  11.1077],\n",
      "        [ -4.6109, -11.0189,  -1.7803,   3.8379,  -0.3919, -13.5552],\n",
      "        [ 10.0003, -19.9063, -12.0168,  -4.2697,  -9.8573, -13.3731],\n",
      "        [ -4.3263,  14.3186,  -6.0409, -18.4154, -20.0228,  -6.8110],\n",
      "        [ -9.8920, -16.2838,   1.4753,   8.3327, -13.6003, -13.0570],\n",
      "        [ -1.7511, -12.4605, -13.6812,  -9.3924,   3.7764,  -6.5276],\n",
      "        [ -9.7989, -14.0569,  -3.9568,  -5.8703,  10.9967,  -7.8714],\n",
      "        [  4.7492, -33.4934,  -0.7428,  -3.9469, -11.5394, -14.8040],\n",
      "        [ -5.9276, -16.3409,   2.1760,   5.6729, -14.9687, -13.0803],\n",
      "        [-13.0465, -24.2412, -17.9317, -22.7485, -19.3573,   7.7966],\n",
      "        [ -2.7226, -35.4228, -19.1571, -18.0778, -16.5180,   9.9756],\n",
      "        [ -6.5851, -17.5958,   1.1227,  14.3032, -20.5506, -20.1568],\n",
      "        [ -6.8588, -13.8941,  -3.6550,   0.6067,   6.0446, -11.8363],\n",
      "        [ -5.8186, -17.5657,   2.0691,  11.6007, -14.5393, -18.0915],\n",
      "        [ -5.7941,  -9.1273,  -2.3671,  10.3606,  -6.4972, -16.2408],\n",
      "        [-15.5830, -37.9014,  24.2646,  -8.6914, -20.4588, -14.5237],\n",
      "        [-15.7340, -10.0227,  -3.3400, -21.6970,  -4.1897,   7.3919],\n",
      "        [ -9.9278, -10.6117,  -2.4670,  -6.2489,   7.9766,  -6.2140],\n",
      "        [ -3.0436, -15.5990, -10.8439,  -7.5634,  10.2302,  -7.1036],\n",
      "        [ -7.8622, -21.4383,   0.3270, -13.9105,  12.0631, -11.8063],\n",
      "        [  8.8345, -21.8963, -12.2322,  -6.7142, -17.0390,  -7.8423],\n",
      "        [  2.1927, -14.2314,  -8.6429, -27.9057, -16.5959,  -0.9825],\n",
      "        [-14.1283,  -9.4009,  -1.6781,  -4.9913,   9.0781, -12.5259],\n",
      "        [ -3.6974, -14.5337,  -8.0767, -14.3552, -20.7654,  -0.2297],\n",
      "        [ -3.6624,  -5.4764, -11.9668, -13.8608, -14.5133,   2.9107],\n",
      "        [  6.7308, -16.3578, -18.5196, -13.0143, -12.1030,  -7.5458],\n",
      "        [ -6.6372, -21.4358,   5.7062,   9.2249, -21.1043, -16.9142]],\n",
      "       device='cuda:0')\n",
      "tensor([3, 0, 1, 5, 2, 5, 3, 0, 1, 3, 4, 4, 0, 3, 5, 5, 3, 4, 3, 3, 2, 5, 4, 4,\n",
      "        4, 0, 0, 4, 5, 5, 0, 3], device='cuda:0')\n",
      "tensor([[ -7.5172, -22.9978,  -1.2845,   9.8331,  -9.5833, -15.3925],\n",
      "        [-12.6749, -15.7608,   4.4458,   9.6804,  -9.8679, -17.1731],\n",
      "        [  3.0309, -21.3456, -21.2212, -19.6882, -12.6195,   6.7053],\n",
      "        [ -6.2880, -19.4506,   2.4379,   8.9108, -11.4511, -14.9601],\n",
      "        [ -9.8001, -20.9891,   9.5354,   0.5640, -14.3066, -12.8172],\n",
      "        [ -8.3192,  14.5119, -10.9353, -15.5299, -13.3804,  -5.2694],\n",
      "        [ -4.9870, -18.0603, -22.8241, -23.7293, -13.9370,   8.6269],\n",
      "        [-11.3964, -21.3302,  13.5576, -12.9798,  -2.7597, -10.0529],\n",
      "        [ -5.7985, -12.1575,  -5.7428,   3.9151,  -3.2009,  -9.7512],\n",
      "        [ -4.9769, -28.8115,  -8.5379, -21.4113,   3.0210,  -5.2634],\n",
      "        [ -5.8282,  -7.9680,  -0.8632,  -4.7266,   4.6594, -10.2254],\n",
      "        [-10.5512,  -9.5546,   5.4243,   6.4804, -13.2894,  -9.7078],\n",
      "        [ -4.5262,  -7.6146,   1.5265,   0.6203,  -4.9116,  -8.3994],\n",
      "        [ -9.1182, -12.1145,   4.1485,   3.2239, -11.9432, -10.1105],\n",
      "        [ 22.6781, -37.1406, -21.4818, -24.0483, -23.1626, -10.7895],\n",
      "        [ -1.2966, -17.2404, -10.6574,  -9.8104,   6.2165,  -7.5764],\n",
      "        [ 10.6997, -25.9184, -17.7544, -14.5108, -19.7415,  -7.2141],\n",
      "        [ -7.3797, -21.7119,   5.1431,   7.2617, -21.4333, -12.8540],\n",
      "        [  7.4229, -32.3817,  -5.9160, -11.3031,  -9.5861, -13.1053],\n",
      "        [  8.8863, -28.2265, -20.4655, -11.7007,  -7.5960,  -3.6866],\n",
      "        [ -8.0016, -11.9946,  -6.0599,  -3.5995,  12.4049,  -9.5091],\n",
      "        [ -7.1182, -13.5227,   3.4537,   0.3465,  -9.5342,  -6.1324],\n",
      "        [ -3.1635,   3.9122,  -5.5748,  -7.6543,  -7.3827,  -3.0287],\n",
      "        [-10.7396, -28.6179,   7.9458,  -3.8543,  -9.7613,  -9.2743],\n",
      "        [-10.0435, -24.7956,  -1.9869, -17.6694,  11.3142,  -4.4660],\n",
      "        [ -7.2724,  -3.3376,  -3.5740,  -0.7807,   7.0087, -11.2822],\n",
      "        [  8.5550, -21.1190, -14.1524, -11.4584,  -6.9188,  -8.6969],\n",
      "        [ -0.2295, -32.1264,   2.6582,   9.3685, -14.6231, -24.8028],\n",
      "        [ -2.6340, -15.6860,  -8.7953,  -5.1832,   7.1733,  -9.9039],\n",
      "        [ -9.9578, -24.0508,  12.2122,  -9.0831, -12.9731,  -8.1861],\n",
      "        [-11.8027, -19.9437,   7.7042,   0.8200, -13.9508, -10.2890],\n",
      "        [ -0.2748,  -4.1536, -14.3716, -15.4398, -20.7173,   1.9258]],\n",
      "       device='cuda:0')\n",
      "tensor([3, 3, 5, 3, 2, 1, 5, 2, 3, 4, 4, 3, 2, 2, 0, 4, 0, 3, 0, 0, 4, 2, 1, 2,\n",
      "        4, 4, 0, 3, 4, 2, 2, 5], device='cuda:0')\n",
      "tensor([[ -8.1844, -23.7018,  11.1027,  -5.8137, -10.9236, -13.1076],\n",
      "        [ -7.5201,  -6.7061,  -6.1962,  -1.0232,   7.4919,  -8.1888],\n",
      "        [ -0.4748,  -4.3623, -24.1182, -21.7952, -23.2664,   7.9828],\n",
      "        [ -6.7030, -10.2926, -13.2082, -15.2888, -27.5442,   8.7669],\n",
      "        [-10.0389, -23.9483,  10.3109,   2.3924, -18.6990, -13.9533],\n",
      "        [ -4.8657,  15.2155, -12.1134, -14.6200, -25.3280,  -1.7296],\n",
      "        [-10.8230, -15.6401,  11.3720, -12.3564,  -7.0518,  -7.4214],\n",
      "        [ -3.4703,  11.3067,  -6.4274, -13.3431, -19.9759,  -6.5168],\n",
      "        [ -4.1624, -15.3482,  -4.5130,  -6.5142,   7.9276, -10.0960],\n",
      "        [ -6.9799,  12.0566,  -8.1743, -15.3683, -13.3271,  -5.0455],\n",
      "        [ -1.4992,  -9.1853,  -8.6140, -14.2016,  -7.1035,  -1.0827],\n",
      "        [-11.7898, -22.5999,   5.4589,  11.4809, -20.6973, -16.7261],\n",
      "        [  8.7748, -11.9987, -22.0780, -27.0587, -18.0475,   2.2312],\n",
      "        [ -8.5035, -20.9086,   6.9067,   6.9435, -16.7835, -16.2225],\n",
      "        [ -8.2325, -11.9526,  -3.2982,  -3.1402,   9.6030,  -9.1760],\n",
      "        [ -9.4944, -11.4715,  -8.1172,  -0.8157,  13.1357, -17.5968],\n",
      "        [  2.3655, -18.2011, -10.9797, -18.3079, -12.3561,  -4.6026],\n",
      "        [-16.6321, -33.4618,  22.7647, -10.5306, -17.7785, -14.9333],\n",
      "        [ -3.7922,   4.6645,  -7.7210, -12.9194, -12.6097,  -0.6726],\n",
      "        [ -0.4039,  -7.7331,  -5.0573,  -2.4624, -14.9299,  -8.3803],\n",
      "        [-13.5789, -18.3768,  14.8639,  -8.9336,  -7.0379, -13.5254],\n",
      "        [ -9.2719,   2.0626, -13.2376, -17.0594, -15.6370,   5.6077],\n",
      "        [ 11.7375, -16.0300, -17.8008, -11.9007, -16.9214, -10.3404],\n",
      "        [ -2.6434, -16.1939,  -5.6164,  -4.1184,   3.9834,  -9.4237],\n",
      "        [ -5.5331,  10.5102,  -8.0434, -11.1062, -16.4870,  -5.2229],\n",
      "        [ -2.0343,  -9.1761, -17.4284, -17.3294, -21.7202,   9.0713],\n",
      "        [  0.4204,  15.6012,  -8.1183, -19.3354, -20.9274,  -4.6264],\n",
      "        [  0.7847, -13.3899, -13.1974, -10.4443, -13.0638,   1.4425],\n",
      "        [ -8.5071, -20.5317,   5.7021,   8.5240, -20.3339, -12.8155],\n",
      "        [ -1.3223, -19.0076,  -5.7885,   1.9376,  -5.3853, -11.1836],\n",
      "        [ -7.2339,  -8.4927,  -0.2101,  -0.1689,  -1.6399,  -8.1433],\n",
      "        [ -4.5697, -16.7121,  -9.4851, -18.4383,  -8.8271,   6.3032]],\n",
      "       device='cuda:0')\n",
      "tensor([2, 4, 5, 5, 2, 1, 2, 1, 4, 1, 5, 3, 0, 3, 4, 4, 0, 2, 1, 0, 2, 5, 0, 4,\n",
      "        1, 5, 1, 5, 3, 3, 3, 5], device='cuda:0')\n",
      "tensor([[-12.7225, -22.6302,   6.1896,  -6.2763,  -9.2890,  -2.6698],\n",
      "        [ -8.5235,  -6.8949,   0.6942,  -2.2890,  -1.4766,  -7.5874],\n",
      "        [ -8.5539,  -9.9959, -12.0457,  -8.2616,   8.0480,  -3.3858],\n",
      "        [ -5.7126,  10.4761,  -0.1948, -10.2452,  -8.1062,  -6.6584],\n",
      "        [-12.3430, -13.8317,  -7.6946, -11.3639,  16.9651,  -6.7807],\n",
      "        [ -9.6873, -14.0088,  -0.8559,   3.9333, -18.0642,  -8.8075],\n",
      "        [-12.9728, -14.3746,   1.1463,   2.7760,  -1.6003, -11.0246],\n",
      "        [-10.8969, -21.2889,   7.4254,   3.4855, -12.6773, -13.8513],\n",
      "        [ -6.1984, -14.6705,  -0.2187,   5.4305,  -5.9823, -13.6872],\n",
      "        [  2.4286, -18.8569, -11.1029, -12.3830,  -4.0020,  -6.1866],\n",
      "        [  9.7806, -23.9564, -14.5779, -13.7677, -18.1705,  -8.5478],\n",
      "        [ -3.5279,   7.6850,  -5.8491, -15.0989, -19.5051,  -5.5177],\n",
      "        [ -8.2095, -19.4842,  -8.3067, -14.3430,  15.2902,  -8.4614],\n",
      "        [ -1.2201, -14.6781, -10.0504,  -3.8213,  -1.2669,  -9.7498],\n",
      "        [ -8.6980,  -4.6045,  -5.7932,  -7.8137,   7.5785,  -7.8963],\n",
      "        [ -9.7411, -31.2347,  13.7025,  -1.3275, -13.6197, -14.9479],\n",
      "        [-11.3996, -13.5220,   4.1920,  -9.4572,  -2.0007,  -3.3447],\n",
      "        [-12.4691,  -5.4510,  -3.6267,  -1.4730,  -5.6708,  -2.9600],\n",
      "        [ -8.3268, -17.5430,  -4.1344,  10.2684,  -8.0864, -15.3468],\n",
      "        [ -2.6179,   8.5612,  -9.7283,  -6.0965, -14.9091,  -3.0034],\n",
      "        [ -5.2630, -10.5522,  -5.0434,  -3.7109,   1.2856, -13.3514],\n",
      "        [ -7.2780,  10.0786,  -3.0393, -22.9391, -10.4880,  -8.6701],\n",
      "        [  7.7178, -21.2980, -10.9096, -18.0508, -12.0503,  -7.2294],\n",
      "        [  3.2991, -30.0967, -20.0224, -26.1022, -18.9176,   8.3284],\n",
      "        [ -7.3267, -16.6676, -17.2943, -22.8772, -20.4833,   8.2064],\n",
      "        [-10.7997, -15.9345,  -7.0758,  -5.5260,  13.9375,  -7.6244],\n",
      "        [ -7.8400,  -6.7464,  -5.0773, -16.2386, -16.8000,   3.6144],\n",
      "        [ -3.9927, -13.9862,  -0.1005,  10.8199, -11.7346, -18.2236],\n",
      "        [-12.7335, -28.0268,  13.7593,   2.5451, -14.6280, -14.0362],\n",
      "        [  3.7144, -12.5743, -22.3248, -15.2036,  -7.7637,  -3.7952],\n",
      "        [ -3.8639,   9.9314,  -1.7112, -10.8382, -11.9849,  -4.8338],\n",
      "        [ -5.8659, -18.2270,   2.5887,  11.5679, -17.9492, -18.1598]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 4, 1, 4, 3, 3, 2, 3, 0, 0, 1, 4, 0, 4, 2, 2, 3, 3, 1, 4, 1, 0, 5,\n",
      "        5, 4, 5, 3, 2, 0, 1, 3], device='cuda:0')\n",
      "tensor([[ -3.2326, -18.8344, -13.0840, -17.0661, -17.7348,   9.1258],\n",
      "        [-15.2310, -20.4208,  13.0467,  -9.9438,  -3.7129,  -7.3619],\n",
      "        [ -6.0699,  10.6434,  -2.9045,  -6.5123,  -8.6603,  -8.6302],\n",
      "        [ -1.3538, -11.8805, -18.9207, -21.8632, -14.2440,   7.2970],\n",
      "        [ -8.5721, -23.7738, -15.4269, -20.3471, -12.5416,  10.5330],\n",
      "        [-15.5423, -27.2015,  19.6275, -10.1385, -13.7647,  -7.6938],\n",
      "        [ -4.0012,   3.6615,  -6.3697,  -6.4213,  -8.0942,  -3.3186],\n",
      "        [ -2.1755, -28.6710, -29.3593, -24.7678, -14.3250,   3.4678],\n",
      "        [ -4.0985, -34.8398, -29.1241, -33.8969, -14.4255,  14.5217],\n",
      "        [ -0.1541, -30.7559,  -6.6151, -14.4175, -15.7221,  -1.9474],\n",
      "        [ -4.8037,   4.7772,  -2.1934,  -4.5912, -14.2025, -11.5642],\n",
      "        [ -8.8556, -14.3381,   7.0554,  -4.7626,  -3.1402,  -9.8414],\n",
      "        [ -4.0444,  14.1528,  -7.0780, -15.9938, -16.2758,  -6.1686],\n",
      "        [-12.2529, -12.3145,   6.0590, -10.7100,   1.3755,  -6.4526],\n",
      "        [ -6.4550,  12.8961,  -8.7110, -13.3194, -14.1198,  -3.7719],\n",
      "        [ -8.3499,  -8.0854,  -3.9019,   2.2510,   1.8819,  -6.1516],\n",
      "        [ -4.7202,   4.3115,  -5.0313,  -7.9221,  -7.6280,  -7.7391],\n",
      "        [-11.0252, -20.5724,   8.9317,  -1.0697,  -2.7472, -15.0222],\n",
      "        [-12.9972, -12.1029,   5.7428,   0.4846,  -3.2839,  -9.2737],\n",
      "        [-10.6586, -17.2234,   3.9829,   4.8762,  -9.8780, -11.5553],\n",
      "        [ -6.9791, -12.4424,  -4.3853,  -9.2485,  10.1893,  -7.6814],\n",
      "        [  1.8481,   3.4422,  -7.0788, -19.3346, -23.8641,  -5.0358],\n",
      "        [ -5.4746, -17.6279, -10.6411,  -4.1601,   5.9900,  -8.4141],\n",
      "        [ -5.5465, -19.3101,   0.7077,  12.6986, -17.3558, -18.8234],\n",
      "        [ -1.5141, -19.2816, -14.8967, -23.6923, -16.6947,   6.5295],\n",
      "        [ -5.6667, -17.4030,   2.1018,   4.7329,  -4.5071, -15.7117],\n",
      "        [ -4.5618,  -9.1526,   4.2470,  -6.5664,  -2.6171,  -8.8987],\n",
      "        [ -6.0199,   9.8715, -10.3836, -20.6985, -26.9838,  -3.4274],\n",
      "        [ -9.7277, -21.3493, -13.8226, -18.5710, -14.4718,  11.3046],\n",
      "        [ 12.5823, -24.6198, -19.2331, -15.4678, -12.7043,  -7.5140],\n",
      "        [ -2.1053,   3.8650,  -5.1644,  -4.8376,  -5.9205,  -7.0367],\n",
      "        [ 14.6481, -16.2971, -22.2600, -14.5687, -12.4746, -12.7407]],\n",
      "       device='cuda:0')\n",
      "tensor([5, 2, 1, 5, 5, 2, 1, 5, 5, 0, 1, 2, 1, 2, 1, 3, 1, 2, 2, 3, 4, 1, 4, 3,\n",
      "        5, 3, 2, 1, 5, 0, 1, 0], device='cuda:0')\n",
      "tensor([[-6.0380e+00, -8.3820e+00, -6.3559e+00, -4.6103e+00,  3.3773e-01,\n",
      "         -4.4341e+00],\n",
      "        [-1.0426e-02,  1.3449e+01, -8.8501e+00, -1.8701e+01, -2.1477e+01,\n",
      "         -5.8034e+00],\n",
      "        [-7.4271e+00, -6.6958e+00, -2.1378e+00, -1.0352e+00,  2.8946e+00,\n",
      "         -1.0106e+01],\n",
      "        [-1.0492e+01, -2.5384e+01,  1.0285e+01,  5.6229e+00, -1.8361e+01,\n",
      "         -1.3964e+01],\n",
      "        [-4.3860e+00, -2.0338e+01, -1.0253e+01, -1.5926e+01, -1.6725e+01,\n",
      "          2.8296e+00],\n",
      "        [-4.7322e+00,  1.4467e+01, -6.6783e+00, -1.3880e+01, -1.7584e+01,\n",
      "         -6.0559e+00],\n",
      "        [-5.9290e+00, -9.6784e+00, -3.9815e+00,  3.1792e+00, -2.1416e+00,\n",
      "         -1.0977e+01],\n",
      "        [-2.2601e+01, -3.1214e+01, -3.1947e+01, -3.3508e+01, -3.1973e+01,\n",
      "          9.1641e+00],\n",
      "        [ 1.1199e+01, -2.5017e+01, -1.8354e+01, -1.3982e+01, -1.1330e+01,\n",
      "         -8.9772e+00],\n",
      "        [-6.9930e+00, -2.5272e+01,  7.3939e+00, -4.8352e+00, -1.1147e+01,\n",
      "         -8.7087e+00],\n",
      "        [ 4.3308e+00, -1.7974e+01, -7.8583e+00, -1.3422e+01, -9.9982e+00,\n",
      "         -3.5546e+00],\n",
      "        [ 5.5990e+00, -2.1825e+01, -1.0081e+01, -2.5157e+01, -1.3893e+01,\n",
      "         -6.4568e+00],\n",
      "        [-6.8202e+00, -7.0919e+00, -4.8252e+00,  6.7000e+00,  4.6584e+00,\n",
      "         -1.1991e+01],\n",
      "        [-9.2762e+00, -2.5942e+01, -4.9697e+00, -2.4197e+01, -7.0228e+00,\n",
      "          1.2551e+00],\n",
      "        [-3.5551e+00,  6.1139e+00, -7.6499e+00, -1.1966e+01, -9.3836e+00,\n",
      "          4.9181e-01],\n",
      "        [-3.7887e+00, -1.6700e+01, -1.1074e+01, -2.3668e+01, -1.6841e+01,\n",
      "          3.1315e+00],\n",
      "        [-5.6758e+00, -1.3081e+01,  5.7222e-01,  9.0593e+00, -7.0023e+00,\n",
      "         -1.5781e+01],\n",
      "        [-3.4820e+00, -4.9761e+01, -1.6835e+01, -3.3559e+01, -1.7035e+01,\n",
      "          1.6342e+01],\n",
      "        [-1.0682e+01, -2.6371e+01,  1.0640e+01,  4.6102e+00, -1.7788e+01,\n",
      "         -1.3298e+01],\n",
      "        [ 2.9725e+00, -2.3706e+01, -1.6738e+01, -1.7147e+01, -1.7658e+01,\n",
      "          3.3938e+00],\n",
      "        [-4.8433e+00, -1.0086e+01, -6.2107e+00,  3.5341e+00, -7.8062e+00,\n",
      "         -6.3959e+00],\n",
      "        [ 5.3004e-01,  1.1917e+01, -1.2940e+01, -1.8023e+01, -3.2855e+01,\n",
      "         -4.4433e+00],\n",
      "        [-9.1572e+00, -2.5660e+01,  8.2130e-01,  2.1736e+00, -4.4976e-02,\n",
      "         -1.7707e+01],\n",
      "        [-3.3049e+00, -1.7134e+01, -1.2360e+01, -8.4604e+00,  1.0003e+01,\n",
      "         -9.5548e+00],\n",
      "        [-5.8799e+00,  9.5708e+00, -3.0826e+00, -1.2846e+01, -1.2616e+01,\n",
      "         -6.2481e+00],\n",
      "        [-1.9403e+00,  7.0863e+00, -8.8668e+00, -1.7960e+01, -1.4535e+01,\n",
      "         -3.1997e+00],\n",
      "        [-5.4399e+00,  6.9040e+00, -2.3020e+00, -1.4654e+01, -8.5830e+00,\n",
      "         -1.8226e+00],\n",
      "        [ 1.9177e+00,  8.6402e+00, -9.5488e+00, -1.0245e+01, -2.1349e+01,\n",
      "         -5.7271e+00],\n",
      "        [-8.1422e+00, -1.1947e+01, -8.3900e-02,  6.1468e+00, -7.1106e+00,\n",
      "         -1.2455e+01],\n",
      "        [-3.7369e+00, -1.7681e+01, -1.7978e+00,  7.6857e+00, -1.2472e+01,\n",
      "         -1.5225e+01],\n",
      "        [ 9.5739e+00, -2.2329e+01, -1.7365e+01, -2.2917e+01, -1.4882e+01,\n",
      "         -3.2341e+00],\n",
      "        [-2.1381e+00,  8.3847e+00, -7.1036e+00, -1.1544e+01, -1.0629e+01,\n",
      "         -7.9705e+00]], device='cuda:0')\n",
      "tensor([4, 1, 4, 2, 5, 1, 3, 5, 0, 2, 0, 0, 3, 5, 1, 5, 3, 5, 2, 5, 3, 1, 3, 4,\n",
      "        1, 1, 1, 1, 3, 3, 0, 1], device='cuda:0')\n",
      "tensor([[ -7.1405, -11.5706,  -3.5555,   6.8872,  -8.3447, -12.0170],\n",
      "        [ -8.7888, -23.3178,   7.6442,  -5.6843,  -9.0192,  -4.8915],\n",
      "        [  8.8231, -24.8518, -25.9322, -20.3746,  -7.8647,  -4.3596],\n",
      "        [ -9.1583,  -7.1737,   3.1790,  -7.6679,   1.8591,  -9.2083],\n",
      "        [ -4.3463, -14.0314,   8.2693,  -2.0260, -14.6177, -12.9078],\n",
      "        [ -0.9326,  11.8622,  -7.5543, -18.2527, -18.5814,  -5.5666],\n",
      "        [ -6.6820,   1.3320,   2.4673,  -8.6112,  -5.2685,  -5.9629],\n",
      "        [ -7.4125, -23.2634,   3.5031,  -1.0882,  -5.9756, -13.2602],\n",
      "        [-15.3516,  -5.4186,   3.6700, -13.1892,   6.6973,  -9.5174],\n",
      "        [-12.5412,  -3.8517,  -2.0690,  -2.5777,   9.8493, -13.3588],\n",
      "        [ -6.4846,  11.5598,  -1.9032,  -8.3164,  -7.9415,  -7.7800],\n",
      "        [  4.5664, -19.2303,  -9.0383, -16.2041, -19.3716,  -2.3755],\n",
      "        [ -3.4602, -32.1408,  -6.0187, -12.6670, -14.3931,  -2.7950],\n",
      "        [-13.1969, -29.6103,  13.8743,   1.4129, -19.7449, -12.1797],\n",
      "        [  8.1302, -12.7697, -15.9931, -15.4868, -20.2989,  -2.3033],\n",
      "        [-11.2080, -18.3072,  11.7617, -11.0816, -12.1282,  -7.3989],\n",
      "        [  0.6101, -24.6544, -15.5254, -11.4966, -14.1735,   0.7726],\n",
      "        [ 11.6211, -22.2007, -14.0867, -11.0492, -14.5209,  -9.0004],\n",
      "        [ -8.9514,  -1.1180,  -7.9218, -19.4439,  -7.1682,   3.6879],\n",
      "        [-15.0816,   8.9361, -14.4425, -23.2579, -21.6737,  -4.8161],\n",
      "        [ -9.9647, -18.4396,  -6.0412,  -8.0256,  13.3309, -11.4872],\n",
      "        [ -8.1141, -22.9300,   4.8127,   9.2427, -15.9216, -19.2710],\n",
      "        [  2.4717, -14.6819, -14.7536, -18.6279, -17.7277,   4.2120],\n",
      "        [ -2.3069,  11.8795,  -2.1080, -18.0067, -17.0768,  -9.2370],\n",
      "        [ 11.9202, -16.7612, -24.4419, -19.7549, -10.5132,  -6.4189],\n",
      "        [ -0.7270,  -6.0337, -11.7523,  -7.8119, -11.1996,   0.8644],\n",
      "        [ -4.8554, -22.9262,  -6.6550,  -6.9242,  10.2558, -13.9584],\n",
      "        [ -6.9358, -12.7838,   1.2596,   7.3769, -12.1116, -14.0107],\n",
      "        [ -0.4706,  -2.7730, -14.4630, -13.8583, -10.6417,   3.4916],\n",
      "        [-10.5254, -14.5797,  -6.9026,  -9.4981,  19.0547, -17.2179],\n",
      "        [ -1.5389, -18.4634,  -6.5070,  -5.1450,   2.3750,  -9.1059],\n",
      "        [  1.6747,  14.8495, -14.3949, -28.7915, -27.0612,  -2.0424]],\n",
      "       device='cuda:0')\n",
      "tensor([3, 2, 0, 2, 2, 1, 2, 2, 4, 4, 1, 0, 5, 2, 0, 2, 5, 0, 5, 1, 4, 3, 5, 1,\n",
      "        0, 5, 4, 3, 5, 4, 4, 1], device='cuda:0')\n",
      "tensor([[  1.7694, -21.5537,  -9.8672, -23.4605, -11.5772,  -0.7617],\n",
      "        [ -0.5512, -13.7949, -11.1399, -15.2262, -19.8884,  -2.8409],\n",
      "        [ -9.3420, -15.8840,  -2.5206, -11.7168,  14.2331,  -9.9814],\n",
      "        [ 21.8501, -26.6725, -23.9761, -17.6070, -10.0826, -16.7450],\n",
      "        [ -2.4901, -15.9179,  -1.7267,   7.9518,  -6.8885, -14.3246],\n",
      "        [ 11.0843, -27.6755, -27.0160, -32.3610,  -7.0166,  -2.2266],\n",
      "        [-10.6641,   6.6617,  -4.0866,  -9.8746, -12.4839,  -1.8494],\n",
      "        [ -4.5595,  12.6944,  -2.1530, -10.3060, -14.3541,  -7.1069],\n",
      "        [ 10.8786, -32.1237, -15.3928, -35.1667, -12.1248,   1.1696],\n",
      "        [ -5.7053,  11.5852,  -3.8015,  -9.0209, -11.1011,  -5.3675],\n",
      "        [ -7.5128,  -5.4267,   1.9626,   2.0076,  -6.3715, -10.9007],\n",
      "        [ -6.0968,   8.4768,  -6.0542, -17.7523, -19.6778,  -0.7043],\n",
      "        [-12.3005, -22.0121,   7.2610,  -0.8638, -11.4975,  -7.3416],\n",
      "        [ -1.5055, -23.7347, -18.0619, -17.8515, -14.9362,   9.3030],\n",
      "        [ -9.2338,  -1.3830,   4.1368, -15.0372,   0.6391,  -9.1300],\n",
      "        [ -9.7086,  -7.4050,  -6.5600,  -0.1723,   7.3916,  -5.8980],\n",
      "        [ -7.7283, -10.5542,  -9.6287,  -3.7722,  13.0346,  -9.1798],\n",
      "        [  3.3177, -10.4173, -20.5834, -21.4863, -14.2053,   5.0137],\n",
      "        [ -9.7249, -15.4603, -12.8837,  -1.3246,  15.8106, -14.5027],\n",
      "        [-13.0753, -20.2310,   9.2535,  -9.9669,   2.1503, -11.9457],\n",
      "        [-11.3947, -17.3663,   8.1542,  -3.3552,  -8.7217, -10.1658],\n",
      "        [ -9.8570, -25.1863,   0.7878,   3.5336,  -5.3504, -12.8274],\n",
      "        [-11.4946, -16.0302,   5.4988,  -9.3200,  -6.5808, -12.8917],\n",
      "        [ -3.1976, -14.7537, -11.5402,  -8.3160,  10.3694,  -8.7885],\n",
      "        [ -7.6449, -12.6505,  -7.1010,  -5.4659,  12.5659,  -9.9251],\n",
      "        [ -7.1506,  -9.4438,  -4.7065,   5.8613,  -3.3701,  -9.7530],\n",
      "        [ -9.7340,  -8.4088,  -2.9294,   9.4858,  -4.6842, -11.9594],\n",
      "        [ -7.6724, -24.2875, -20.8632, -28.8335, -24.0213,  -8.3656],\n",
      "        [ -8.2035,   1.7823,  -8.1027,  -6.1666,  -8.5382,   4.2762],\n",
      "        [ -9.5619, -26.0348,  12.6861,   0.8918, -18.3978,  -8.0540],\n",
      "        [ -6.6582,  -2.9900,  -4.0318,  -1.2185,  -3.5708,  -8.2747],\n",
      "        [ -7.1861,  -9.6088,  -0.0588,   5.3871,  -2.3660, -14.6923]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 4, 0, 3, 0, 1, 1, 0, 1, 3, 1, 2, 5, 2, 4, 4, 5, 4, 2, 2, 3, 2, 4,\n",
      "        4, 3, 3, 0, 5, 2, 3, 3], device='cuda:0')\n",
      "tensor([[-12.1636, -10.1739,   2.7772,   8.2098, -10.9308, -12.5156],\n",
      "        [ 10.0254, -26.1043, -10.9506, -13.5480,  -7.5893, -13.5154],\n",
      "        [ -0.5001, -19.9616,  -9.0693, -22.4498, -18.7799,   6.7362],\n",
      "        [  7.9113, -26.4897, -10.2876, -13.3008, -14.7335, -10.1505],\n",
      "        [ -3.5837,  15.4771, -11.1569, -16.4211, -21.2838,  -0.8678],\n",
      "        [ -4.8892, -21.0005,  -2.4793,   7.4250,  -7.1564, -17.9084],\n",
      "        [  3.5591, -25.7870,  -6.2490,   3.4278,  -4.5186, -20.8379],\n",
      "        [ -4.5089, -13.1343,  -5.6727,  -1.5440,   8.5187, -11.1431],\n",
      "        [-11.4886, -18.1065,   6.0681,   4.2210, -12.7651,  -9.9274],\n",
      "        [ -0.1590,  -7.1594,  -9.6055,   2.3812, -19.4134, -12.6158],\n",
      "        [ -5.0774,   5.6739,  -4.0956, -11.6571, -12.6525,  -1.6378],\n",
      "        [ -3.6643, -13.3619,  -7.5049,  -7.3671,   9.1299,  -8.6069],\n",
      "        [ -6.0175, -20.3740,   4.0969,   9.3072, -19.5747, -20.4080],\n",
      "        [-11.0657, -17.4571,  10.0816,  -0.5014, -14.1420, -13.5116],\n",
      "        [ 19.0726, -39.3430, -21.3751, -24.1248,  -8.8012,  -9.2881],\n",
      "        [  6.6064, -19.1189, -12.7160,  -4.5856,  -6.0449, -12.3205],\n",
      "        [ -3.7445,  -8.1245,  -7.9522,  -1.5843,   4.6088, -11.2756],\n",
      "        [  6.8867, -24.5478,  -9.6966,  -6.4389, -19.8069, -15.9587],\n",
      "        [-10.7144,  -3.6026,  -7.2672,  -4.5824,  11.6342, -10.7130],\n",
      "        [ -3.2559, -11.4101,  -9.2921,  10.6281,  -2.4048, -17.6934],\n",
      "        [ -3.3520,   3.7272,  -3.2969, -14.0715, -11.8075,  -7.0214],\n",
      "        [ -4.1695, -17.3428,  -8.1733,  -5.2083,   6.4768, -13.1977],\n",
      "        [ -7.6077, -11.5533,  -1.5689,  -1.4568,   3.8885, -11.2091],\n",
      "        [ 17.4092, -37.7799, -22.3144, -15.5334, -15.7686,  -8.0022],\n",
      "        [ -3.0251,  -8.0496, -17.1230, -22.2108, -17.8814,   6.7949],\n",
      "        [ -7.2496,  -8.5621,  -0.4332,   5.9905,  -9.3352,  -7.5507],\n",
      "        [ -4.5624,  -9.2566, -11.5697, -24.4951, -17.0308,   8.1803],\n",
      "        [ -9.0936, -18.0741,   0.9491,   5.1911, -15.2258,  -9.5736],\n",
      "        [ -2.3036,  -6.5159, -11.6198, -15.0400, -11.0305,   0.1982],\n",
      "        [ -7.2717, -17.2486,   2.6453,  10.2430, -15.9672, -16.2250],\n",
      "        [ -7.9896, -11.8296,  -1.9932,   8.5419,  -6.4746, -16.1279],\n",
      "        [ -7.4690, -12.2556, -13.4050, -21.2903, -11.9522,   6.2212]],\n",
      "       device='cuda:0')\n",
      "tensor([3, 0, 5, 0, 1, 3, 0, 4, 2, 3, 1, 4, 3, 2, 0, 0, 4, 0, 4, 3, 1, 4, 4, 0,\n",
      "        5, 3, 5, 3, 5, 3, 3, 5], device='cuda:0')\n",
      "tensor([[  0.8848, -18.3607, -20.3049, -21.9905, -18.5150,   7.9766],\n",
      "        [ -9.4986, -12.9870, -13.3750, -24.7089, -23.3930,   7.2118],\n",
      "        [ 11.5087, -52.2767, -19.2916, -15.4745, -12.9111,  -4.9554],\n",
      "        [ -6.8093,  14.0122,  -1.9480, -15.0422, -14.7691,  -6.4574],\n",
      "        [-15.4598, -42.8270,  19.5752,   3.6401, -24.5323, -20.5410],\n",
      "        [ -8.2419, -14.8373,   7.4048,  -6.2854,  -9.9650,  -6.0894],\n",
      "        [-10.3293, -30.5843, -23.5264, -18.0996, -21.3847,  -2.6957],\n",
      "        [ -5.3888,  13.2697,  -1.7042, -10.7790, -12.2099,  -8.7119],\n",
      "        [ -8.6223, -23.4659,   8.1700,   4.9646, -16.4414, -17.2018],\n",
      "        [ -8.8430,  16.8376,  -4.8970, -16.8344, -17.4139,  -4.2163],\n",
      "        [  3.1886,  -4.1266,  -8.1078, -13.5531, -12.7316,  -6.6051],\n",
      "        [ -1.5350, -18.0985, -15.0381, -24.6729, -13.4134,   3.8456],\n",
      "        [ -8.0959,  10.5192,  -5.6366, -11.9365, -15.7639,  -3.7796],\n",
      "        [  2.6871, -19.3387, -14.4518,  -5.8840, -10.0196,  -2.5566],\n",
      "        [  0.5945, -11.5796,  -5.5512,   0.9488, -14.7200, -11.6646],\n",
      "        [  0.1676, -19.5507, -11.6599, -12.8554,   0.1116,  -5.3792],\n",
      "        [-10.0511, -19.8959,   8.3468,  -4.0658,  -9.1285, -11.8587],\n",
      "        [-12.3731, -25.2135,  14.7686,  -8.4090,  -8.0156, -10.6983],\n",
      "        [ -8.4574, -14.4660,  -0.8064,   1.2696,  -7.4499, -13.9067],\n",
      "        [ -4.9881, -17.5602,   0.4262,   5.9746,  -9.1801, -13.4239],\n",
      "        [ -1.3349, -29.1356, -18.8133,  -9.5955,  -9.6952,   5.0639],\n",
      "        [-10.9742, -18.8349,  -5.8439,  -5.6255,  12.4403, -12.0981],\n",
      "        [ -2.8182, -14.0122,  -3.6922,   2.3161,  -4.0841, -15.4766],\n",
      "        [ -7.5278,  11.2804,  -8.2096, -11.6761, -11.5599,  -3.8291],\n",
      "        [ -1.1290, -15.8903,  -5.6178, -22.2824, -15.3064,   3.7065],\n",
      "        [-12.6237, -16.7550,   7.9092,  -7.4205,  -1.5450,  -9.8271],\n",
      "        [ -8.4561, -13.6709,  -0.8258, -11.0348,   4.3141, -12.1689],\n",
      "        [ -3.3309, -18.6369,  -3.6395,  -4.2866,  -1.7565,  -9.0299],\n",
      "        [ -5.7021,  10.3245,  -5.8557, -13.7878, -24.8388,  -3.9289],\n",
      "        [-12.9770, -17.8919,   5.3770, -11.5615,  -0.0888, -10.6593],\n",
      "        [ -6.0686,  -5.6029,  -3.7052,  -1.0300,   6.3263,  -6.6982],\n",
      "        [ -2.5237, -24.5021, -12.5919, -20.0358, -11.5788,   5.8266]],\n",
      "       device='cuda:0')\n",
      "tensor([5, 5, 0, 1, 2, 2, 5, 1, 2, 1, 0, 5, 1, 0, 3, 0, 2, 2, 3, 3, 5, 4, 3, 1,\n",
      "        5, 2, 4, 4, 1, 2, 4, 5], device='cuda:0')\n",
      "tensor([[ -2.8902, -21.4752,  -7.2792,  -7.5705,   5.0214,  -7.8811],\n",
      "        [ -8.7680, -18.6348,  -2.0263,   4.9697, -18.5773,  -5.3946],\n",
      "        [ -4.6783,  -1.4325,  -5.7491,  -2.9381,   0.4228,  -9.4806],\n",
      "        [ -4.4303, -30.5007,   7.7570,   7.9358, -13.6361, -23.8158],\n",
      "        [ -9.0139, -12.7285,  -6.1937,   0.3835,  -2.5158,  -5.1172],\n",
      "        [  6.0553, -16.5357,  -7.6863,  -8.1543, -10.2318, -11.6950],\n",
      "        [ -9.6661,  -5.1685,  -4.9981,   0.3830,   6.2211, -12.0876],\n",
      "        [ -8.4439, -15.4627,   7.3695,   0.3396,  -8.8741, -10.2343],\n",
      "        [-13.4004,  -4.7398,  -2.3150,  -6.0402,   5.6187,  -7.4381],\n",
      "        [ -3.8048, -12.7582,  -8.6231,  -6.8969,   9.4334,  -9.9729],\n",
      "        [ -5.6957,   4.2272,  -8.7832,  -1.5641,   1.4445,  -9.4885],\n",
      "        [-15.8326, -20.5631,   3.2964,  -7.2180,   6.9822,  -8.8502],\n",
      "        [ 11.8738, -25.9901,  -4.6947,  -8.8624, -17.5039,  -8.2428],\n",
      "        [ 11.1463, -16.2979, -19.8103, -23.2846, -11.4805,  -2.1067],\n",
      "        [ -5.4224,   0.3888,  -9.2117, -14.9647, -12.2141,   3.9460],\n",
      "        [ -5.6858, -15.6323,  -2.6498, -17.2294,  -9.8483,  -1.4862],\n",
      "        [-10.0670, -10.1692,  -7.1887,  -1.7389,  11.7606,  -9.3170],\n",
      "        [-13.7326, -30.4046,  19.1029,  -6.4253, -15.2827, -13.2854],\n",
      "        [ 12.5073, -23.2834, -18.4706, -17.5259, -18.8954, -10.4794],\n",
      "        [-13.6679, -21.6358,  11.6105,   4.4191, -15.6173, -13.3261],\n",
      "        [  6.7011, -24.7234,  -5.5057,  -9.1052, -18.7468,  -6.8236],\n",
      "        [ -1.7673, -15.4057,  -8.9433, -21.4596,  -8.9753,   1.5646],\n",
      "        [  3.4752, -17.2611, -13.5370, -14.0920,  -5.3726,  -5.9018],\n",
      "        [ -6.5639, -18.3990,   4.2580,   0.7585, -10.2889, -11.5626],\n",
      "        [ -4.1887,  -8.0720,  -0.7638,   1.8351,  -4.3111, -11.3380],\n",
      "        [ -3.4423,   8.6084,  -3.9404, -13.1999, -19.5905,  -8.6363],\n",
      "        [ -1.5463,  -3.6041, -12.7445,  -8.6176,  -8.5343,  -4.1569],\n",
      "        [ -7.8439, -21.1149,  -3.1182,  -9.4195,   4.7588,  -5.2862],\n",
      "        [ -6.8893,   8.3144,  -2.3008,  -9.1222, -13.5142,  -6.2455],\n",
      "        [ -6.0015, -18.7529,   3.1540,   7.5313, -12.1780, -12.9620],\n",
      "        [ 11.8567, -17.1679, -12.9416, -15.4006, -29.6542,  -6.8770],\n",
      "        [  3.9007, -33.8078,  -2.9810,  -9.7298, -17.2926, -11.9738]],\n",
      "       device='cuda:0')\n",
      "tensor([4, 3, 4, 3, 3, 0, 4, 2, 4, 4, 1, 4, 0, 0, 5, 5, 4, 2, 0, 2, 0, 5, 0, 2,\n",
      "        3, 1, 0, 4, 1, 3, 0, 0], device='cuda:0')\n",
      "tensor([[ -4.2778,  12.0269, -17.0363, -17.1042, -20.9895,   0.2796],\n",
      "        [  8.7066, -18.4666, -13.9415, -10.1615, -17.1474,  -6.9776],\n",
      "        [ -6.9184, -13.8997,  -1.8753,   3.7602,   2.6867, -12.4727],\n",
      "        [ -4.5962,  12.1897,  -3.8426, -14.0585, -12.4716,  -6.0978],\n",
      "        [  0.6719, -18.8706,  -7.4123, -12.6347, -11.2197,  -1.0360],\n",
      "        [ -3.2974, -20.4661,  -6.2315,   6.2974, -13.2308, -14.5040],\n",
      "        [ -4.7630, -20.8738,  -0.8648,   2.2336,  -8.5269, -10.2206],\n",
      "        [ -6.7240,  13.5299,  -3.9660, -13.0348, -15.4682,  -8.2662],\n",
      "        [ -4.8651, -17.3763,  -5.1073, -16.4722,  12.8680,  -6.9353],\n",
      "        [-12.1863, -23.9333,  11.6015,  -5.2752,  -8.6188,  -7.8659],\n",
      "        [-11.2264, -12.6955,  -5.5759,  -0.9214,   9.4799, -11.6158],\n",
      "        [ -8.4759, -24.7267,   8.9461,  -2.1000,  -6.0949, -19.5180],\n",
      "        [ -9.9397, -20.6203,   8.8114,   1.0278, -10.7680, -13.0367],\n",
      "        [ -5.4080,  -5.0636,  -7.5797,   0.8339,   2.4732,  -8.2558],\n",
      "        [-13.5991, -14.5023,  -2.8559,   1.9572,   4.8578, -10.9910],\n",
      "        [  2.8369, -39.2148,  -8.7045, -17.7673, -12.2567,  -5.5023],\n",
      "        [  7.0668, -23.2088, -10.3396, -17.6161, -15.8315,  -4.9470],\n",
      "        [ -2.3222, -17.2753, -18.0346, -16.1563, -21.0352,   8.5097],\n",
      "        [  0.7795, -15.4073, -13.2690, -23.8460, -14.7157,   5.7677],\n",
      "        [  0.9034,   4.6406, -10.3141,  -9.8049, -14.4946,  -1.4530],\n",
      "        [ -5.2941,  10.4197,  -7.9694, -21.2029, -19.1724,  -0.3737],\n",
      "        [ 17.7332, -24.0507, -32.7102, -36.8945, -19.9456,   1.8609],\n",
      "        [-10.4078, -26.2680,  12.1417,  -5.4576, -13.3629, -14.3383],\n",
      "        [ -6.3336,  -6.4991,  -5.7873, -17.7137,  -5.7270,   4.8769],\n",
      "        [  1.4900, -28.8005,  -2.9622,   6.6783, -14.5510, -18.1902],\n",
      "        [-10.4087,  14.6085,  -6.8141,  -8.3067, -14.8229,  -8.1800],\n",
      "        [ 10.6539, -30.6474, -12.5414, -10.4601, -21.8195,  -8.0239],\n",
      "        [-12.5457,  -7.6051,  -8.8766, -10.0811,  10.8916,  -7.1759],\n",
      "        [  1.9384, -38.2700, -15.9979, -26.4176,  -6.3059,   0.8379],\n",
      "        [ -2.7605, -18.1636,   1.1838,   2.7611,  -5.5727, -13.4383],\n",
      "        [  0.2284,   9.2376, -12.6017, -16.0049, -16.9620,  -1.4036],\n",
      "        [ -5.3685, -21.1125,   4.4919,  12.2456, -20.9812, -17.7543]],\n",
      "       device='cuda:0')\n",
      "tensor([1, 0, 3, 1, 0, 3, 3, 1, 4, 2, 4, 2, 2, 4, 4, 0, 0, 5, 5, 1, 1, 0, 2, 5,\n",
      "        3, 1, 0, 4, 0, 3, 1, 3], device='cuda:0')\n",
      "tensor([[ -1.6295,  10.6553, -13.3777, -14.3343, -19.6937,  -0.7456],\n",
      "        [ 10.8472, -26.6479, -15.6856, -11.5307,  -9.9552, -13.0100],\n",
      "        [-12.8510, -26.5107,  13.4821,  -3.0101, -10.9117, -12.9950],\n",
      "        [  1.6966, -23.5695, -10.3628, -13.8515, -11.7682,   0.1142],\n",
      "        [ -4.2131,   6.2543,  -3.8737, -12.8744, -14.6854,  -2.6522],\n",
      "        [ -4.0973, -17.2123, -10.9903,   1.1782,   4.1455, -15.5952],\n",
      "        [ -7.3249, -14.1696,  -0.2884,  -8.7099,  -5.9627,  -6.3053],\n",
      "        [-15.1213, -16.0776,  20.2079, -19.7540,  -4.6694,  -9.6456],\n",
      "        [ -8.8861, -15.4801,  -3.4790,   3.9019,  -0.8618, -10.7170],\n",
      "        [  3.5952, -23.2383,  -1.8173,  -2.2045, -10.8799, -12.3531],\n",
      "        [-13.9629, -34.3888,  20.9954, -10.2375, -14.7962, -13.9117],\n",
      "        [ -8.4148, -25.7032,   0.6229,   7.4768,  -6.8424, -15.6919],\n",
      "        [ -2.6954, -14.6303,  -8.2094, -11.5758,  -6.2112,  -2.0698],\n",
      "        [-12.0098, -35.3143,  18.3789,  -6.7954, -17.1607, -15.9836],\n",
      "        [ -6.6044,  -9.3028, -15.1141, -24.6900, -12.3299,   9.9489],\n",
      "        [-11.8026, -21.0435,  11.2056,  -2.6099,  -5.8118, -17.9795],\n",
      "        [ -4.4179,   7.6010,  -9.9004, -20.9861, -24.6568,   1.3895],\n",
      "        [-13.0686, -23.7807,  14.5217,  -7.9980,  -8.3739, -11.6058],\n",
      "        [  5.1504, -13.0441, -13.8274, -18.3476, -15.4969,  -2.3706],\n",
      "        [ -4.8405,  14.7510,  -7.3007, -13.3629, -16.3364,  -5.5573],\n",
      "        [  8.2821, -30.3158,  -8.9522, -13.7597, -27.0070,  -8.9387],\n",
      "        [ -4.2576, -14.5695,  -7.5834,  10.0072,  -9.6867, -18.2951],\n",
      "        [ -7.7470, -15.5546,  -3.5678,   7.7661,  -5.9721, -16.3240],\n",
      "        [ -4.4968, -30.8828, -19.4343, -23.2051, -16.6590,  10.8093],\n",
      "        [ -6.8840, -20.0346,   7.9964,  -7.1835, -17.9904,  -9.5631],\n",
      "        [-15.0939, -27.7439,  17.4027,  -3.9340, -16.8798, -14.0857],\n",
      "        [  9.5022, -30.6414, -23.7301, -18.8913,  -3.8541,  -6.7638],\n",
      "        [  5.3602, -18.3381, -19.9063, -21.3475, -21.1652,   7.1415],\n",
      "        [-12.6423, -20.5487,   9.7602,  -3.5631, -12.3094,  -9.7919],\n",
      "        [ -3.9154, -10.0485,  -6.8765,   6.3276,  -0.9478, -14.3789],\n",
      "        [ -2.0187,   5.1787, -10.2882,  -6.5007, -16.7823,  -2.2256],\n",
      "        [-12.2112, -13.5511,   2.1690,  -9.8499,   9.9273, -10.4843]],\n",
      "       device='cuda:0')\n",
      "tensor([1, 0, 2, 0, 1, 4, 2, 2, 3, 0, 2, 3, 5, 2, 5, 2, 1, 2, 0, 1, 0, 3, 3, 5,\n",
      "        2, 2, 0, 5, 2, 3, 1, 4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.9071, -13.2019, -13.5000,  -9.6451,  -4.6613,  -2.8935],\n",
      "        [ -7.5633, -19.6841,   8.2669,  -0.0895, -20.3600, -19.8261],\n",
      "        [  3.3780, -16.2235, -11.4370,  -8.6996, -11.6312,  -7.3041],\n",
      "        [  6.1331, -19.5097, -27.8856, -21.7882, -13.9970,   6.1865],\n",
      "        [-11.4408, -13.1360,  -2.9449,  -5.8675, -11.6581, -10.1437],\n",
      "        [ 21.9500, -25.5445, -17.7272,  -8.8269, -17.3897, -19.6346],\n",
      "        [ -9.2933,  -4.3265,  -6.5455,   9.7765,  -4.6372, -11.5139],\n",
      "        [  5.2278, -14.0497, -17.8815, -11.1574,  -5.0617,  -7.2710],\n",
      "        [ -6.1006, -18.6079,  -1.9952, -11.8530,  -2.7452,  -7.6406],\n",
      "        [ -7.0733,  12.7106,  -8.2084, -11.6274, -13.0204,  -4.2833],\n",
      "        [ -7.0330,  -1.0073,  -0.4806,  -6.7202,   2.6239,  -9.8423],\n",
      "        [ -6.2855, -18.7020,   3.1140,   4.9773, -15.4225, -11.1653],\n",
      "        [ -6.3897, -23.8411,   6.6434,   0.4075, -11.1194, -18.6087],\n",
      "        [ 12.4085, -35.5720,  -9.5625,  -5.3819, -20.4610, -11.5361],\n",
      "        [ -5.9459,  -4.1287,  -3.8709,   4.3620,   1.4556, -12.1516],\n",
      "        [  3.1010,  -7.3095,  -5.0399, -11.3743, -14.4788,  -7.0306],\n",
      "        [ -1.1316, -17.1545, -20.5706, -18.8685, -19.7209,   6.3874],\n",
      "        [ -7.3074,  11.8590,  -7.4100, -10.4604, -16.5682,  -5.2857],\n",
      "        [ -0.3584, -19.2380,  -5.7258,  -6.7943, -10.7045,  -3.5034],\n",
      "        [-16.3061, -24.0558,  12.9807,  -6.6330,  -7.0320,  -8.8969],\n",
      "        [-12.2177, -24.5427,  11.8997,  -9.4180,   0.1743, -17.4639],\n",
      "        [ -8.0256, -14.4850,  -0.5014,   4.9971,  -9.4918, -14.6648],\n",
      "        [ 21.3779, -40.8022, -12.9095, -13.3461, -17.0070, -15.6298],\n",
      "        [ -9.3089, -13.6811,  -6.6514, -20.2903, -13.0121,   6.2096],\n",
      "        [ -5.0213,  -8.0229,  -4.1087,   1.8916,   1.4618,  -9.1925],\n",
      "        [ -4.4015, -19.6845, -12.1705, -22.2989, -12.3127,   7.4783],\n",
      "        [-10.8573,  -7.6421,  -3.1524,   3.7210,   1.0065,  -9.3686],\n",
      "        [ -8.5423,  -4.1356,  -2.7359,  -2.1625,   9.4657,  -9.5185],\n",
      "        [ -8.9450, -20.6958,   6.8088,   8.7924, -16.4949, -22.7014],\n",
      "        [ -9.1292, -12.0331,   3.7157,   2.2721,  -4.6461, -13.7775],\n",
      "        [ 14.1016, -25.5874, -13.9386,  -7.5405, -18.0883, -12.7131],\n",
      "        [ -8.4239,  -6.8600,  -2.4982,  -2.9589,   5.7663,  -7.3619]],\n",
      "       device='cuda:0')\n",
      "tensor([0, 2, 0, 5, 2, 0, 3, 0, 2, 1, 4, 3, 2, 0, 3, 0, 5, 1, 0, 2, 2, 3, 0, 5,\n",
      "        3, 5, 3, 4, 3, 2, 0, 4], device='cuda:0')\n",
      "tensor([[ -8.3967, -10.7119,  -9.9892,  -1.3475,   2.5751,  -5.0002],\n",
      "        [ -3.3407, -19.5618,  -2.1004, -14.3195,   4.5834,  -5.3737],\n",
      "        [ -6.3392,  10.1017,  -9.3451, -12.3941, -16.6957,   1.3839],\n",
      "        [  8.8623, -13.5115, -17.3388,  -9.5158,  -5.1636, -10.5193],\n",
      "        [  6.1043, -18.7450, -12.3637,  -8.3327, -19.3337,  -8.7919],\n",
      "        [ -1.0596,  -7.5558,  -6.7205,  -8.1178,  -4.5413,  -6.2843],\n",
      "        [ -3.1268, -12.3954,  -2.2572,  -2.2272,  -7.8372,  -8.1111],\n",
      "        [ -3.8214, -19.1654,  -0.8730,   7.9838, -13.3280, -14.3457],\n",
      "        [-11.2188, -15.0568,  -7.1392, -14.8933,  -1.4023,   1.1508],\n",
      "        [ -2.4652, -19.3058,  -5.0999,  -0.3893,  -3.9037, -11.1771],\n",
      "        [ -3.1694,   5.1109,  -6.9555,  -8.6708,  -9.3637,  -1.8782],\n",
      "        [ -3.7710, -12.9883,  -1.8671,   5.9267,  -8.9797, -10.1329],\n",
      "        [-11.0098,  -7.8708,  -7.7683,  -4.9892,   8.5128,  -3.5867],\n",
      "        [ -4.6697,  10.3952,  -6.3932, -14.3796, -15.2144,  -5.6182],\n",
      "        [ -3.0501, -12.4976,  -4.9894,  -4.7927,   8.0354,  -9.1907],\n",
      "        [ -4.0293, -24.2115,   1.9157,  10.6712, -16.6785, -21.0153],\n",
      "        [  0.9595,  -8.3501, -15.1575, -19.7457, -13.2123,   2.8101],\n",
      "        [ 20.1004, -28.4535, -22.0056, -17.4797, -14.1447, -13.0625],\n",
      "        [-14.2024, -27.5385,   5.9247,  13.6969, -24.1613, -16.9364],\n",
      "        [ -5.6460, -18.1512,  -5.5904,  -9.4175, -19.5746,  -1.9732],\n",
      "        [ -4.6731,   7.3724,  -5.6992,  -9.3588, -21.1539,  -4.4218],\n",
      "        [  4.8468, -19.2167, -25.0777, -22.4137, -14.2246,   6.7166],\n",
      "        [ -6.8567,  -4.4602,  -1.4242,   2.7083,  -4.4777,  -8.2500],\n",
      "        [-11.5621, -12.3330,   3.7455,   8.4971, -16.1458, -14.3089],\n",
      "        [ -3.3386,   9.6282,  -7.6537, -15.0458, -16.7765,  -1.0900],\n",
      "        [-10.6857, -14.4329,   4.0753,  -1.9597,   4.2184, -10.8931],\n",
      "        [  3.4460, -27.3414,  -6.4184,  -5.6207, -13.1365, -13.4794],\n",
      "        [ -6.2032, -23.9982,   0.0508,  10.9809, -12.1980, -17.6370],\n",
      "        [-13.7346, -11.6918,   5.3870, -11.9759,   5.6135,  -8.9460],\n",
      "        [-14.8982, -29.0342,  18.5182,  -7.3106, -14.7482, -11.7666],\n",
      "        [ -6.6432,  11.0096,  -6.7853,  -6.0371, -10.7024,  -4.9842],\n",
      "        [  5.3810, -23.1686, -13.9399,  -4.1201, -17.8821, -11.3482]],\n",
      "       device='cuda:0')\n",
      "tensor([4, 4, 1, 0, 0, 0, 3, 3, 5, 3, 1, 3, 4, 1, 4, 3, 5, 0, 3, 5, 1, 5, 3, 3,\n",
      "        1, 4, 0, 3, 4, 2, 1, 0], device='cuda:0')\n",
      "tensor([[-10.0567, -14.0993, -17.6376, -16.0385, -10.9104,   3.5758],\n",
      "        [ -6.6250, -10.8882,   5.5751,  -8.5380, -12.4259,  -5.1302],\n",
      "        [-14.0311, -14.2348,  -6.9837,  -9.2281, -15.5680,   5.4921],\n",
      "        [ -6.8187,  -9.2431,  -2.8020,   8.5355,  -1.5765, -16.7630],\n",
      "        [-12.7331, -11.5096,   5.8488,  -2.5498,  -2.0624,  -6.4412],\n",
      "        [ -2.2679,  -4.1221, -10.2276,   4.5372,  -0.7269,  -9.1127],\n",
      "        [  1.8527, -18.9322, -19.5871, -19.4418, -11.8540,   5.3212],\n",
      "        [  0.8671,   9.5571,  -5.5448, -13.0966, -15.2335,  -9.6491],\n",
      "        [-12.5768, -22.4992,   7.2694,  -3.7663,  -2.7640, -11.1838],\n",
      "        [ -7.2368, -21.3577,  10.1247,   1.9555, -15.8634, -16.1503],\n",
      "        [ -7.7051, -36.5957,  11.3890,   2.3398, -15.8990, -22.3280],\n",
      "        [ -4.7263, -18.0866,  -2.0112,   9.7332, -12.8770, -14.7134],\n",
      "        [-10.8435, -10.5907,  -3.0764,  -7.1217,   8.2528,  -7.9869],\n",
      "        [ -6.1400, -12.9669,  -8.7164,  -8.3036,  12.6423,  -8.4299],\n",
      "        [ -1.3369, -13.8513, -16.1680, -10.5896,  -6.0405,   3.9460],\n",
      "        [  9.8957, -21.3664, -18.5919, -12.7506, -17.9066,  -6.6952],\n",
      "        [ -8.5852, -19.5800,   2.3898,  11.9213, -13.0027, -17.3394],\n",
      "        [ -6.3139,  16.1210,  -9.0313, -12.4458, -20.3238,  -4.3715],\n",
      "        [ -8.4372, -13.6115,   0.4444, -16.4574,  -4.5260,  -0.0823],\n",
      "        [ -5.9366, -16.0124,  -6.8208, -10.1427,  13.1923,  -7.1899],\n",
      "        [  1.9188, -30.1458, -23.1852, -25.6878, -19.2983,  10.8816],\n",
      "        [-10.1670, -10.3028,  -2.6033,   5.4981,  -7.7195, -13.3796],\n",
      "        [ -6.6120, -21.1899,  -3.7501,  10.6245, -11.5023, -15.9731],\n",
      "        [ -2.4004,  -8.0431, -11.0300,  -6.9322,  -9.0585,  -3.8596],\n",
      "        [ -6.5794, -24.1249,   3.1832,   5.4437, -11.8035, -18.4996],\n",
      "        [-13.6877, -15.5200,   2.3951,   9.6429, -14.9721, -15.5051],\n",
      "        [ -2.9701, -21.1726,  -1.4320,  -1.8027,  -2.4703, -15.1729],\n",
      "        [-12.2320, -11.7901,   8.1912, -18.0284,  -5.2864,  -4.8520],\n",
      "        [ -5.3240, -15.4977,   7.8287,  -1.2962,  -9.2800, -12.4512],\n",
      "        [ -6.3691, -14.2978,  -3.9056,  12.0650,  -7.4966, -18.0135],\n",
      "        [  3.4118, -29.2801, -17.3825, -19.5619, -21.7392,   6.1520],\n",
      "        [-16.7412, -27.2579,  15.3961,  -9.2784,  -6.2664,  -9.8415]],\n",
      "       device='cuda:0')\n",
      "tensor([5, 2, 5, 3, 2, 3, 5, 1, 2, 2, 2, 3, 4, 4, 5, 0, 3, 1, 2, 4, 5, 3, 3, 0,\n",
      "        3, 3, 2, 2, 2, 3, 5, 2], device='cuda:0')\n",
      "tensor([[-4.6822e+00, -1.9860e+01, -1.8970e+00, -1.6898e+01,  1.1632e+01,\n",
      "         -9.4222e+00],\n",
      "        [-5.9373e+00, -9.6306e+00, -4.8917e+00,  5.9316e+00, -3.4494e-01,\n",
      "         -1.3523e+01],\n",
      "        [-1.1811e+00, -2.3170e+01, -7.0366e-01,  2.7303e+00, -9.5997e+00,\n",
      "         -1.0470e+01],\n",
      "        [-1.7769e+00, -1.7942e+01, -2.9167e+00,  1.1756e+01, -8.5406e+00,\n",
      "         -2.1364e+01],\n",
      "        [-2.8568e+00, -1.0368e+01, -1.0661e+01, -4.6379e+00,  2.4599e+00,\n",
      "         -6.6376e+00],\n",
      "        [-3.7819e+00,  6.8120e+00, -4.6602e-02, -9.4219e+00, -2.1563e+01,\n",
      "         -1.1058e+01],\n",
      "        [-2.5440e+00,  8.4807e+00, -5.4494e+00, -1.7424e+01, -1.6811e+01,\n",
      "         -6.5481e+00],\n",
      "        [-2.4017e+00, -1.3170e+01, -1.2982e+01, -1.1279e+01, -1.7371e+01,\n",
      "          5.8822e+00],\n",
      "        [-8.0869e+00, -9.7334e+00,  2.1991e-01, -9.4367e+00,  8.7977e+00,\n",
      "         -1.0795e+01],\n",
      "        [-3.2970e-01, -1.8652e+01, -5.2110e+00,  1.8716e+00, -1.1821e+01,\n",
      "         -1.3471e+01],\n",
      "        [-7.6479e+00, -1.6236e+01, -6.1160e+00,  5.7171e+00,  2.1941e+00,\n",
      "         -1.4266e+01],\n",
      "        [-2.3066e+00,  1.2779e+01, -4.3576e+00, -1.4350e+01, -1.7311e+01,\n",
      "         -7.3338e+00],\n",
      "        [-7.4012e+00, -1.2579e+01, -7.8185e+00, -1.7946e+00,  5.6747e+00,\n",
      "         -1.0707e+01],\n",
      "        [ 2.3093e+00, -1.5829e+01, -1.3481e+01, -8.8690e+00, -1.8100e+00,\n",
      "         -1.0169e+01],\n",
      "        [-1.9746e+00, -2.4101e+01,  7.6213e-01,  1.9038e+01, -2.4705e+01,\n",
      "         -2.6904e+01],\n",
      "        [ 1.1505e+01, -3.0297e+01, -1.6415e+01, -1.2873e+01, -1.5359e+01,\n",
      "         -4.2738e+00],\n",
      "        [ 8.7192e-01,  1.4155e+01, -1.1156e+01, -1.4982e+01, -1.8443e+01,\n",
      "         -5.1175e+00],\n",
      "        [ 1.7625e+01, -4.2405e+01, -1.9545e+01, -1.5944e+01, -2.2410e+01,\n",
      "         -8.5963e+00],\n",
      "        [ 1.3867e+00, -1.6781e+01, -7.2001e+00,  4.4716e+00, -1.2240e+01,\n",
      "         -1.6459e+01],\n",
      "        [-4.1053e+00, -1.3341e+01, -3.4361e+00,  7.0873e+00, -7.9569e+00,\n",
      "         -1.3706e+01],\n",
      "        [-8.7155e+00, -1.3914e+01, -3.8665e+00, -1.0206e+01,  1.1787e+01,\n",
      "         -6.8224e+00],\n",
      "        [-2.1092e+00, -8.6098e+00, -8.0563e+00,  6.2296e+00,  1.0935e-02,\n",
      "         -1.4643e+01],\n",
      "        [-4.9722e+00,  1.5558e+01, -9.0568e+00, -1.5673e+01, -2.0205e+01,\n",
      "         -7.3395e+00],\n",
      "        [-7.9377e+00, -6.0729e+00,  8.6344e-01, -5.9708e+00,  4.4831e+00,\n",
      "         -4.8662e+00],\n",
      "        [-5.4778e+00,  5.0727e+00, -3.1342e+00, -7.7489e+00, -7.1022e+00,\n",
      "         -7.2244e+00],\n",
      "        [-5.3246e+00, -1.8069e+01, -5.4932e-01,  1.0967e+01, -1.1237e+01,\n",
      "         -1.9911e+01],\n",
      "        [-1.1135e+01, -1.3517e+01, -2.8839e+00, -1.0781e+01,  1.4822e+01,\n",
      "         -9.7384e+00],\n",
      "        [-6.5590e+00,  1.1180e+00, -1.0208e+01,  4.6725e+00,  3.0546e+00,\n",
      "         -1.3667e+01],\n",
      "        [-6.7647e+00, -9.1493e+00, -5.2737e+00,  7.5606e-01,  1.9956e+00,\n",
      "         -8.8381e+00],\n",
      "        [-8.0990e+00, -8.0317e+00,  6.4748e-01,  7.3271e+00, -1.0591e+01,\n",
      "         -1.3483e+01],\n",
      "        [-9.8069e+00, -2.3949e+01, -1.0874e+01, -2.3072e+01, -1.7956e+01,\n",
      "          6.4694e+00],\n",
      "        [-9.5007e+00, -1.2806e+01, -5.0524e+00,  7.7555e+00,  3.5793e-02,\n",
      "         -1.7693e+01]], device='cuda:0')\n",
      "tensor([4, 3, 3, 3, 4, 1, 1, 5, 4, 3, 3, 1, 4, 0, 3, 0, 1, 0, 3, 3, 4, 3, 1, 4,\n",
      "        1, 3, 4, 3, 4, 3, 5, 3], device='cuda:0')\n",
      "tensor([[-1.0052e+01, -2.5740e+01,  1.0271e+01,  3.3547e+00, -1.6045e+01,\n",
      "         -1.4870e+01],\n",
      "        [-1.2263e+01, -2.3263e+01,  9.0399e+00, -8.9465e-01, -1.2047e+01,\n",
      "         -1.1513e+01],\n",
      "        [-6.6586e+00, -1.5055e+01, -7.3355e+00,  1.1704e+01, -6.7020e+00,\n",
      "         -1.4605e+01],\n",
      "        [-1.0460e+01, -2.0453e+01,  5.5092e+00, -5.8067e+00, -8.2421e+00,\n",
      "         -6.2452e+00],\n",
      "        [-5.1469e+00,  1.2830e+01, -1.5394e+01, -9.2413e+00, -2.1775e+01,\n",
      "         -8.3166e-01],\n",
      "        [-1.6829e+01, -2.5666e+01,  1.6689e+01, -3.4893e+00, -1.3890e+01,\n",
      "         -1.3156e+01],\n",
      "        [-1.0361e+01, -9.8229e+00,  2.6026e+00, -7.2415e+00,  1.4871e+00,\n",
      "         -9.2036e+00],\n",
      "        [ 3.8440e+00, -3.8789e+00, -9.1343e+00, -1.0773e+01, -2.2557e+01,\n",
      "         -2.6242e+00],\n",
      "        [-1.0881e+01, -8.1339e+00, -7.0034e+00, -8.3198e-03,  1.0964e+01,\n",
      "         -1.1636e+01],\n",
      "        [-8.5802e+00, -1.2606e+01, -2.0643e+00,  6.3936e+00, -8.2891e+00,\n",
      "         -1.0687e+01],\n",
      "        [-6.8697e+00, -2.2878e+01,  1.4884e+00, -1.3746e+01,  8.7967e+00,\n",
      "         -1.1514e+01],\n",
      "        [-6.7061e-01, -2.6555e+01, -3.3924e+00,  1.7834e+01, -1.5203e+01,\n",
      "         -2.8115e+01],\n",
      "        [-4.0309e+00, -1.8411e+01,  1.6940e+00,  7.2283e+00, -1.4760e+01,\n",
      "         -1.7053e+01],\n",
      "        [-8.0680e+00,  1.1674e+00, -6.3277e+00, -1.2608e+01, -1.4026e+01,\n",
      "          2.2452e+00],\n",
      "        [-3.8548e+00, -1.8341e+01,  1.2993e+00,  3.3069e+00, -1.8484e+01,\n",
      "         -1.2304e+01],\n",
      "        [-1.0839e+01, -1.9704e+01, -2.6156e+00, -1.3073e+01,  1.3856e+01,\n",
      "         -9.7771e+00],\n",
      "        [ 4.0952e+00, -1.5304e+01, -6.7029e+00, -1.2254e+01, -1.9064e+01,\n",
      "         -1.6843e+00],\n",
      "        [-7.4653e+00,  8.3606e+00, -7.4747e+00, -1.5762e+01, -1.4498e+01,\n",
      "         -3.8202e+00],\n",
      "        [-9.6499e+00, -1.7717e+01,  9.0404e+00, -3.6851e-01, -1.0667e+01,\n",
      "         -1.2577e+01],\n",
      "        [-7.4013e+00,  7.5341e+00, -1.0677e+01, -1.8253e+01, -1.3082e+01,\n",
      "         -2.2772e+00],\n",
      "        [-1.0047e-01, -1.3819e+01, -1.4263e+01, -1.7431e+01, -9.6208e+00,\n",
      "          3.6405e+00],\n",
      "        [-1.9712e-01, -1.6723e+01, -1.2528e+01, -9.7891e+00,  7.0289e+00,\n",
      "         -9.1806e+00],\n",
      "        [-8.9712e+00, -1.3690e+01,  5.1006e+00, -1.9365e+00, -5.8431e+00,\n",
      "         -9.6881e+00],\n",
      "        [-1.3625e+01, -5.9824e+00, -1.2888e+01, -1.9574e+01, -1.9895e+01,\n",
      "         -4.0742e-01],\n",
      "        [-1.2193e+01, -1.8197e+01,  1.5109e+00,  6.4545e+00, -5.7908e+00,\n",
      "         -1.5830e+01],\n",
      "        [-1.2033e+01, -1.0509e+01,  1.0626e+01, -1.0810e+01, -4.0054e+00,\n",
      "         -5.9658e+00],\n",
      "        [ 9.1674e+00, -2.0244e+01, -2.0584e+01, -2.8670e+01, -2.2167e+01,\n",
      "          5.6132e-01],\n",
      "        [ 1.0610e+01, -2.4501e+01, -2.1592e+01, -1.6203e+01, -6.3755e+00,\n",
      "         -6.5371e+00],\n",
      "        [-1.4797e+01, -2.4646e+01,  1.4755e+01, -1.6369e+01, -4.5116e+00,\n",
      "         -1.0942e+01],\n",
      "        [-1.3663e+01, -2.4056e+01,  3.8602e+00,  6.8554e+00, -2.0578e+01,\n",
      "         -9.4743e+00],\n",
      "        [-5.3135e-01, -1.5593e+01, -6.9510e+00,  9.3577e+00, -6.9651e+00,\n",
      "         -1.6168e+01],\n",
      "        [-4.2217e+00, -4.7881e+00, -4.0976e+00, -3.1456e+00,  2.1050e-01,\n",
      "         -5.2497e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 3, 2, 1, 2, 2, 0, 4, 3, 4, 3, 3, 5, 3, 4, 0, 1, 2, 1, 5, 4, 2, 5,\n",
      "        3, 2, 0, 0, 2, 3, 3, 4], device='cuda:0')\n",
      "tensor([[ 25.2447, -62.0696, -28.5909, -32.0668, -13.9133,  -5.7782],\n",
      "        [  0.8694, -11.5116,  -8.4603,  -8.2017,  -5.3926,  -6.1910],\n",
      "        [ -9.8300, -20.4994,  10.7638,   1.6850, -17.7238, -12.5342],\n",
      "        [ -7.7293, -13.2126,  -0.3112,   9.8364, -10.9779, -15.8022],\n",
      "        [-11.9773, -25.3440,  19.7703,  -9.6367, -14.2354, -12.4230],\n",
      "        [ -2.5040,  -9.5615,  -5.9076,   5.9967,  -6.0052, -15.9691],\n",
      "        [ -7.9386, -18.3313,   5.5692,  -0.5302, -17.8557, -10.7019],\n",
      "        [  8.3835, -33.0896, -23.6554, -17.5696, -15.1286,   2.9329],\n",
      "        [ -7.6696, -28.0075,   8.7985,  -0.9909, -14.1646, -14.8652],\n",
      "        [ -8.8135, -18.3286,   6.7281,   3.1490, -13.6941, -15.6846],\n",
      "        [  6.3498, -25.0172,  -6.2257,  -6.9528,  -9.5684, -17.6938],\n",
      "        [ -9.2575, -16.2149,  -3.5656,   0.2981,   5.7217, -13.4836],\n",
      "        [ -5.7076, -16.2440,   1.8429,   1.6928,  -7.6083, -11.9589],\n",
      "        [  1.6763, -19.8128, -12.0594, -13.5465,  -0.9988,  -6.5391],\n",
      "        [ -9.6318, -19.0587,  -5.2039, -19.8892,  -8.1426,   6.1683],\n",
      "        [ -9.6081,   6.3087,  -5.2611, -14.2144,  -5.6158,  -4.2537],\n",
      "        [ -2.0625, -19.6130, -11.1046,  -9.8719,   7.5173,  -5.5290],\n",
      "        [ -9.5505, -10.1113,   1.3058,  -0.9007,   5.4682, -11.3446],\n",
      "        [-10.8984, -11.9917,   3.5784, -10.7123,   7.9245,  -8.6992],\n",
      "        [ -9.1096,  15.9319,  -7.2564, -11.5703, -23.5609,  -5.1734],\n",
      "        [ -2.5714, -18.5967, -14.6643, -14.7308, -11.6497,   5.5843],\n",
      "        [ -6.4598,  -6.4247,  -7.2191,   1.4040,   2.1656,  -9.8044],\n",
      "        [ -4.5637, -10.9506,  -9.5499,   9.8276,   2.3364, -16.4174],\n",
      "        [ -4.2791,  10.1793,  -7.4340,  -6.7516, -16.6314,  -5.6537],\n",
      "        [-13.6968, -25.3747,  13.2435,   2.7108, -18.4639, -10.1695],\n",
      "        [  4.7956, -19.5289, -24.4601, -23.5917, -11.0190,   7.8104],\n",
      "        [ -6.7119, -11.8341,  -2.7087,   5.3177,  -2.2681, -11.9768],\n",
      "        [ -8.6992, -12.2812,   0.5354,  13.4049, -12.4954, -20.4576],\n",
      "        [ -5.9249, -12.5726, -11.7825, -15.7135, -20.0385,   4.6963],\n",
      "        [ 12.6627, -26.7937, -21.1808, -25.3628,  -8.1841,  -4.2016],\n",
      "        [ -7.6444, -19.9811,   5.5625,  10.4740, -16.2312, -18.4018],\n",
      "        [-10.6462, -24.1588,   8.4327,  -2.3265,  -5.5874, -11.9454]],\n",
      "       device='cuda:0')\n",
      "tensor([0, 0, 2, 3, 2, 3, 2, 0, 2, 2, 0, 4, 2, 0, 5, 1, 4, 4, 4, 1, 5, 4, 3, 1,\n",
      "        2, 5, 3, 3, 5, 0, 3, 2], device='cuda:0')\n",
      "tensor([[ 1.5864e+01, -2.7178e+01, -2.2953e+01, -2.0789e+01, -1.0506e+01,\n",
      "         -7.7779e+00],\n",
      "        [-5.3527e+00, -2.1325e+01,  1.0145e+00,  6.4958e+00, -8.8151e+00,\n",
      "         -1.4976e+01],\n",
      "        [ 1.6821e+00, -9.8275e+00, -1.5769e+01, -1.6339e+01, -1.5171e+01,\n",
      "          5.5942e+00],\n",
      "        [-5.3456e+00, -7.5851e+00,  8.4320e+00, -5.3463e+00, -1.2340e+01,\n",
      "         -9.1058e+00],\n",
      "        [-7.4477e+00, -1.4111e+01, -3.0017e+00, -6.5933e+00,  8.3983e+00,\n",
      "         -8.9416e+00],\n",
      "        [-9.1084e+00, -2.5501e+01,  1.6544e+01, -1.4954e+01, -1.2928e+01,\n",
      "         -1.3210e+01],\n",
      "        [ 4.8524e+00, -1.5881e+01, -6.7367e+00, -1.5088e+01, -1.9537e+01,\n",
      "         -8.8181e+00],\n",
      "        [-1.5260e+00, -1.5794e+01, -4.5799e+00, -3.7778e+00,  6.4456e-01,\n",
      "         -1.1067e+01],\n",
      "        [ 9.8710e-01, -2.1213e+01,  7.8656e-01,  1.0349e+01, -1.1382e+01,\n",
      "         -2.1389e+01],\n",
      "        [ 1.6318e+00, -2.6452e+01, -1.2044e+01, -1.7994e+01, -9.3504e+00,\n",
      "          2.3558e+00],\n",
      "        [-6.7645e+00, -9.7766e+00, -8.9133e+00, -4.1185e+00,  6.5263e+00,\n",
      "         -4.5776e+00],\n",
      "        [-4.9111e+00,  4.8245e+00, -8.6729e+00, -1.0209e+01, -1.0822e+01,\n",
      "         -7.1847e+00],\n",
      "        [-1.5690e+01, -2.1283e+01,  1.8631e+01, -1.0761e+01, -8.0482e+00,\n",
      "         -1.0758e+01],\n",
      "        [-9.3128e+00, -7.2597e+00, -2.2335e+00, -3.3616e+00,  7.0478e+00,\n",
      "         -9.6175e+00],\n",
      "        [-4.0926e+00, -1.1323e+01,  1.3262e-02,  4.4125e+00, -7.0502e+00,\n",
      "         -1.0633e+01],\n",
      "        [-4.8215e+00, -1.2925e+01, -1.5765e+01, -1.3795e+01, -1.2162e+01,\n",
      "          3.3960e+00],\n",
      "        [-7.4104e+00, -1.2304e+01, -4.5679e+00,  6.2067e+00, -1.5507e+00,\n",
      "         -1.2367e+01],\n",
      "        [-8.0849e+00, -1.8270e+01, -6.1203e-01,  4.7409e+00, -6.6069e+00,\n",
      "         -1.2348e+01],\n",
      "        [-7.4079e+00, -1.6285e+01, -1.0230e+00,  1.1361e+01, -1.1601e+01,\n",
      "         -1.3594e+01],\n",
      "        [-1.0599e+01, -2.7201e+01,  9.5067e+00, -7.7214e+00, -6.4616e+00,\n",
      "         -1.0907e+01],\n",
      "        [ 1.6814e+00, -8.0317e+00, -9.0957e+00, -2.2297e+01, -1.3975e+01,\n",
      "         -1.4915e+00],\n",
      "        [-2.7334e+00, -1.0040e+00, -1.3694e+01, -1.8346e+01, -1.4872e+01,\n",
      "          3.2948e+00],\n",
      "        [-3.5250e+00, -1.0519e+01, -3.2501e+00,  6.4963e+00, -1.3543e+01,\n",
      "         -1.5604e+01],\n",
      "        [-2.2748e+00, -1.0920e+01, -1.1939e+01, -1.7977e+01, -2.2401e+01,\n",
      "          3.7968e+00],\n",
      "        [-4.3193e+00, -1.8683e+01, -1.2607e+01, -1.8675e+01, -1.8828e+01,\n",
      "          5.0351e+00],\n",
      "        [-6.4863e-01, -2.0047e+01, -2.1869e+00,  6.1453e+00, -9.6153e+00,\n",
      "         -1.7240e+01],\n",
      "        [ 7.5013e+00, -2.0721e+01, -1.1724e+01, -7.4964e+00, -1.0425e+01,\n",
      "         -1.0155e+01],\n",
      "        [-4.6206e+00, -1.0608e+01, -4.7559e+00,  5.5388e+00, -4.9776e+00,\n",
      "         -1.1815e+01],\n",
      "        [-1.0780e+01, -2.6199e+01,  1.1888e+01,  1.6117e+00, -1.3237e+01,\n",
      "         -1.7726e+01],\n",
      "        [ 7.8555e+00, -4.0662e+01, -1.5756e+00, -1.8711e+01, -1.4471e+01,\n",
      "         -8.2357e+00],\n",
      "        [-8.0614e+00, -2.5060e+01,  4.0028e+00,  5.6120e+00, -1.4463e+01,\n",
      "         -1.2283e+01],\n",
      "        [-1.1252e+01, -1.8380e+01,  4.7703e+00,  1.0372e+01, -1.9481e+01,\n",
      "         -1.5288e+01]], device='cuda:0')\n",
      "tensor([0, 3, 5, 2, 4, 2, 0, 4, 3, 5, 4, 1, 2, 4, 3, 5, 3, 3, 3, 2, 0, 5, 3, 5,\n",
      "        5, 3, 0, 3, 2, 0, 3, 3], device='cuda:0')\n",
      "tensor([[-12.1364, -21.9565,  17.0035, -11.3650, -13.3955,  -9.9449],\n",
      "        [ -7.9667,  -7.1942,  -0.6117,  -5.7785,   5.9014, -10.3962],\n",
      "        [ -5.1050, -16.8356, -13.3900,   2.2601,   8.6355, -11.9093],\n",
      "        [ -7.6324, -15.7858,  -4.4470,  -0.8847,   8.1167, -13.8425],\n",
      "        [ -9.1870, -27.8839,  10.2609,  -9.9146, -13.2166,  -3.8051],\n",
      "        [ -7.8077, -18.8257,   4.7283,   8.1370, -14.9179, -13.9234],\n",
      "        [ -7.4884, -18.3717,  -0.1786,  10.7091, -14.8660, -16.9746],\n",
      "        [ 15.1746, -20.2969, -24.7963, -14.2802, -18.8347, -10.7689],\n",
      "        [  1.0576, -23.9607,  -4.0854,  -7.8586,  -8.4839,  -6.0500],\n",
      "        [-12.2350, -13.3096,   9.5516,  -7.5157,  -9.0905,  -7.3192],\n",
      "        [  8.9308, -28.3695, -13.1646, -13.9416, -16.7050,  -9.0439],\n",
      "        [ -8.7768,  -8.5494,  -4.0175,  -5.7717,   8.3851, -13.2252],\n",
      "        [ -0.7640, -18.5130,  -6.5525, -11.4126,  -1.1713,  -6.6424],\n",
      "        [ -6.7086,  14.5723,  -3.0693, -19.6390, -22.4362,  -5.4060],\n",
      "        [-17.6355, -31.2857, -22.5759, -33.9476, -23.0129,   3.3860],\n",
      "        [ -1.1926, -14.1690,  -9.1802, -14.2327,  -5.0309,  -5.2853],\n",
      "        [  6.9551, -28.0458, -21.3788, -21.3709, -11.1252,   2.8614],\n",
      "        [ -9.1656, -14.2790,   2.0331,   8.1447, -10.3296, -12.5922],\n",
      "        [-11.6163, -30.7451,  11.3503,   5.0850, -12.6979, -17.3375],\n",
      "        [ -4.2419,   0.6098,  -8.3958, -14.7780, -15.1546,  -0.8950],\n",
      "        [ -8.9094, -16.9644, -13.2051, -16.5482, -14.4223,   7.4591],\n",
      "        [ -9.5043,  -3.9130,   1.1886, -12.8994,   2.1543,  -7.8197],\n",
      "        [ -8.6462, -18.6201,   5.7129, -13.1002,   5.8002, -13.8967],\n",
      "        [ -6.1997,   2.9116,  -3.9081,  -6.8620,  -7.7819,  -3.5292],\n",
      "        [-14.8565, -16.9240,   9.6952,  -3.9708, -10.4804,  -4.9494],\n",
      "        [-11.7894, -15.7360,  15.9342, -16.9249, -14.5631, -14.6173],\n",
      "        [ -4.0755,  12.5111, -10.7529,  -5.4902, -11.5541,  -8.4843],\n",
      "        [ -7.9947, -26.9406,   8.0434,  -0.9530, -11.9024, -10.7879],\n",
      "        [ -6.2965,  -6.9557,  -6.1055,   9.0929,  -6.5438, -14.7742],\n",
      "        [ -8.2411, -12.6551,   3.6675,   2.6929, -11.1900,  -9.6126],\n",
      "        [ -5.1149,   5.6895, -10.4177,  -7.4683,  -9.2637,  -1.9589],\n",
      "        [-13.4370, -11.3989,  14.4725, -14.5455,  -5.8329,  -5.7924]],\n",
      "       device='cuda:0')\n",
      "tensor([2, 4, 4, 4, 2, 3, 3, 0, 0, 2, 0, 4, 0, 1, 5, 0, 0, 3, 2, 1, 5, 4, 4, 1,\n",
      "        2, 2, 1, 2, 3, 2, 1, 2], device='cuda:0')\n",
      "tensor([[ -0.4747, -12.6738, -13.6127, -12.8170,  -2.5205,  -3.8537],\n",
      "        [ -6.0113,  -9.2726,  -0.6161,  -1.4203,  -0.5344,  -8.1477],\n",
      "        [ -5.9599,  10.0320,  -6.9849,  -9.2018, -14.5353,  -3.1010],\n",
      "        [ -6.7557,  -6.2160,  -3.6626,  10.1497,  -7.5868, -14.6903],\n",
      "        [-10.5572, -25.8467,  10.8387,   4.3435, -16.4397, -15.3681],\n",
      "        [  7.4929, -14.3536, -13.1365, -13.6359, -18.9830,  -2.0635],\n",
      "        [ -8.5089,   0.3035,  -0.8787,  -0.6447,   2.4546,  -4.7839],\n",
      "        [-15.2830, -23.3032,  11.2785,  -6.1518,  -7.0629,  -9.1283],\n",
      "        [ -8.2887,  -5.7377, -11.1241,  -1.7675,   8.4866,  -3.0833],\n",
      "        [ -3.1930,  -4.6092,  -2.0521,   1.2251,  -4.5707, -10.4426],\n",
      "        [ -8.9840, -23.8664,  11.0309,  -5.9087, -16.2566, -11.9853],\n",
      "        [ 11.3255, -25.1038, -26.7251, -29.0598, -13.6334,   3.7651],\n",
      "        [-10.0737, -13.6239,  -7.9064, -12.5194,  11.5557, -10.4791],\n",
      "        [ -6.4365, -18.0050,   1.9157,  11.6684, -15.9867, -17.8652],\n",
      "        [-19.6394, -11.5171,  16.4368, -22.8719,  -3.7341,  -4.7953],\n",
      "        [ -4.2167, -13.6168,  -7.6958, -13.2434, -14.9939,   3.1520],\n",
      "        [ -9.8768, -16.3797,   1.4581,   3.8253,  -3.1300, -15.2082],\n",
      "        [  2.6802,  -4.7207, -21.4861, -21.2980, -18.7701,   4.8006],\n",
      "        [ -9.5251, -21.1770,   3.5660,   8.8872, -17.3007, -13.5628],\n",
      "        [ -3.3945,   8.3118, -13.1572, -11.6172, -11.6281,  -2.1252],\n",
      "        [-12.2319, -26.8092,   8.8516, -11.9733,   0.2257,  -5.7863],\n",
      "        [  1.0011, -25.1441,  -8.4050,   4.2186,  -7.1810, -20.2752],\n",
      "        [  1.3569,  -8.7833, -11.9446, -17.5851, -14.8046,   3.6826],\n",
      "        [  5.0447, -23.1582, -12.4563,   6.1921, -11.0776, -20.0552],\n",
      "        [ -5.9568, -17.3909,  -1.6457, -11.4883,  13.8766, -11.3898],\n",
      "        [  0.9388, -32.9676, -14.8187, -22.8002,  -7.7472,   2.8135],\n",
      "        [ -3.5817, -27.2841, -29.3955, -27.7302, -13.6940,  15.4864],\n",
      "        [ -6.2932,   9.9515,  -3.5749, -12.3145,  -6.3873,  -7.6909],\n",
      "        [ -5.7234,   9.1378,  -6.9569, -10.4298, -11.3096,  -5.3878],\n",
      "        [ -9.1743,  -5.5696,  -1.5130,   1.8241,   5.8761,  -8.0278],\n",
      "        [-10.9138, -38.1492,  12.1805,  -8.3904, -12.6244,  -9.1343],\n",
      "        [ -9.3013, -28.7093,  10.7881,   1.1022, -10.4294, -16.4936]],\n",
      "       device='cuda:0')\n",
      "tensor([0, 4, 1, 3, 2, 0, 4, 2, 4, 3, 2, 0, 4, 3, 2, 5, 3, 5, 3, 1, 2, 3, 5, 3,\n",
      "        4, 5, 5, 1, 1, 4, 2, 2], device='cuda:0')\n",
      "tensor([[ -6.1911,   2.4202,  -8.5816,   0.4398, -11.0491,  -7.6413],\n",
      "        [ -9.4389, -20.0169,   3.3340,   9.9335, -16.9270, -11.2626],\n",
      "        [ -8.2372, -15.2166,  -1.6034, -20.6961, -13.6935,   4.8332],\n",
      "        [ -3.0241,  10.5217, -11.1331, -15.7525, -18.8514,  -3.9052],\n",
      "        [ -0.7085,  13.9258, -11.9058, -18.7485, -20.0442,  -6.3581],\n",
      "        [ -3.8706, -14.4105,   1.6335,   4.9366,  -8.2389, -12.9402],\n",
      "        [ -7.4728, -26.7514,  -3.2674,  17.6958, -18.3229, -23.4210],\n",
      "        [ -9.3162,  -7.5652,  -0.2475,   5.8912,  -2.6997, -11.2016],\n",
      "        [ -9.8903,  -7.7163,   4.5402,  -0.5142,  -3.2153,  -7.5201],\n",
      "        [ -9.3060,  12.6242,  -5.0841, -11.4799, -20.9045,  -2.8395],\n",
      "        [-10.7577,  -1.5379,   1.0886,  -4.5510,  -0.2114,  -9.5804],\n",
      "        [ -2.4072,  -8.4230, -13.5487, -17.8381, -14.2538,   6.1525],\n",
      "        [  2.9135, -18.7880, -14.7485, -12.5669,  -5.6986,  -6.2055],\n",
      "        [ -2.3584,  10.9962,  -5.7595, -24.6385, -22.6011,  -0.2987],\n",
      "        [ -6.2224, -12.9345,  -2.7224,   5.2459, -11.4395,  -9.8516],\n",
      "        [ -5.7256,  -2.2701,  -3.7216,   3.0790,  -0.1623,  -5.0369],\n",
      "        [ -9.6303, -25.1097, -14.1675, -20.1926, -13.7294,   8.2912],\n",
      "        [ -9.4492,  14.8191,  -6.5677, -10.1642, -15.7871,  -4.1092],\n",
      "        [ -8.9148, -19.2353,   2.8101,   4.2364,  -6.0929, -14.3680],\n",
      "        [ -0.6849,  10.7865,  -7.6979, -14.4242, -21.8747,  -7.6766],\n",
      "        [  9.9945, -30.3829, -14.0365, -15.8473, -13.7178,  -5.7702],\n",
      "        [-10.0477, -10.2634, -20.0416, -21.1304, -21.0926,   1.6260],\n",
      "        [ 16.7886, -57.9280, -24.8085, -31.1447, -11.7438,  -0.8449],\n",
      "        [  8.0040, -26.6628,  -1.9529,  -0.8550, -19.9498, -16.9992],\n",
      "        [ -2.9280,  -8.7093,  -6.1801,   4.6305,  -4.3092, -14.6745],\n",
      "        [ 14.9776, -35.6985, -19.1061,  -8.5458,  -5.6425, -15.0430],\n",
      "        [-12.0514, -18.4678,  10.7483,  -7.7339,  -1.7323, -13.5050],\n",
      "        [-11.2075, -10.0624,   1.2985, -11.1510,  10.1941,  -9.1452],\n",
      "        [ -5.6728,  -2.9245,  -1.4149,  -3.3324,   4.4216,  -8.4703],\n",
      "        [  0.8921,  -6.7782,  -6.2042,  -7.2998, -13.3894,  -3.2596],\n",
      "        [ -8.3188,  -0.7821,  -5.5853,  -2.6749,   5.1883,  -5.2585],\n",
      "        [-11.9481,  -8.2630,   7.2127,  -5.1748,  -5.4382,  -9.4290]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 3, 5, 1, 1, 3, 3, 3, 2, 1, 2, 5, 0, 1, 3, 3, 5, 1, 3, 1, 0, 5, 0, 0,\n",
      "        3, 0, 2, 4, 4, 0, 4, 2], device='cuda:0')\n",
      "tensor([[ -7.4022, -20.5646,   4.1483,   5.2459, -15.0636, -13.3222],\n",
      "        [-15.6222, -30.4587,  17.8156,   2.3921, -21.0626, -15.1322],\n",
      "        [ -7.5189, -14.2001,  -4.5248,  -8.4941,   9.0542,  -6.2733],\n",
      "        [ -4.1246, -22.5821,  -1.2914,   6.5252, -12.5274, -15.7317],\n",
      "        [ -2.1020, -11.2990,  -2.9877,   8.2890,  -7.5268, -17.4384],\n",
      "        [ -7.6791,  -9.6437,  -8.6317,  -7.8859,   4.0272, -10.2246],\n",
      "        [-13.4912, -13.1903,   3.2912,   8.2632,  -6.2676, -16.6920],\n",
      "        [ -8.1305, -13.3467,   3.8273,   3.2435,  -5.7810,  -9.9491],\n",
      "        [ -1.1090,  15.1784, -18.5445, -19.1115, -22.3159,  -2.4327],\n",
      "        [ -0.5999, -24.3208,  -6.2630, -11.4698,   2.1191, -12.2839],\n",
      "        [ -7.2513, -17.6821,   7.3175,  -8.1708,  -4.4681,  -9.2713],\n",
      "        [ 13.4417, -25.4752, -21.2054, -15.2245, -15.8175,  -4.0865],\n",
      "        [ -4.0735,  16.7085,  -6.3088, -20.5672, -19.4840,  -5.6600],\n",
      "        [ -8.5125, -13.7916,  -4.6627, -10.9527,   9.4636, -11.5322],\n",
      "        [ 15.0745, -35.7741, -23.9018,  -6.9515, -11.7668, -14.1888],\n",
      "        [  8.3470, -22.3835, -20.8799, -10.1472,  -4.0312,  -9.2632],\n",
      "        [ -4.3025,  13.7720,  -8.6107, -19.9240, -19.8208,  -2.8855],\n",
      "        [  0.4619,  -6.2079,  -5.9511, -12.0958,  -7.3722,  -4.9879],\n",
      "        [ 16.3840, -31.0299, -18.7619, -23.5418, -16.2500,  -7.8276],\n",
      "        [ -5.0625, -31.2739,   2.7578,   8.4989,  -9.1162, -24.5100],\n",
      "        [ -5.0306, -22.5064,  -5.6466,  13.4598,  -8.4724, -20.6442],\n",
      "        [  8.9384, -31.4610, -10.0971,  -8.2842, -17.8588, -13.6698],\n",
      "        [ -4.5195, -11.3691,  -2.6164,  -0.9588,   6.2018, -13.2341],\n",
      "        [-11.5156,  -9.4073,  -3.7600,  -3.3272,   6.1009,  -7.8496],\n",
      "        [ -9.9511, -23.9114,  10.3948,  -0.3555,  -9.4820, -12.2653],\n",
      "        [ -9.0060, -14.4352,   2.2998,  -3.8633,  -0.4389,  -7.2508],\n",
      "        [ -2.7571, -14.1177, -15.5773, -13.3465, -15.1630,   5.5260],\n",
      "        [ -9.3879, -13.4489,   0.8159, -10.9332,   9.9084, -11.5433],\n",
      "        [  7.7281, -13.9083, -16.5489, -13.9958,  -6.1360,  -5.3458],\n",
      "        [ -9.9155, -14.7844,   3.0678,   1.1476,  -8.8152,  -6.2479],\n",
      "        [ -4.6347,   7.1721,   1.1410,  -5.7318,  -9.1469,  -6.8995],\n",
      "        [-10.7330, -14.2511,  -7.1337, -19.3110, -12.3176,   6.9875]],\n",
      "       device='cuda:0')\n",
      "tensor([3, 2, 4, 3, 3, 4, 3, 2, 1, 4, 2, 0, 1, 4, 0, 0, 1, 0, 0, 3, 3, 0, 4, 4,\n",
      "        2, 2, 5, 4, 0, 2, 1, 5], device='cuda:0')\n",
      "tensor([[-2.0068e+00, -1.3442e+01, -5.0969e+00,  7.9803e+00, -1.0833e+01,\n",
      "         -1.5122e+01],\n",
      "        [-9.1905e+00, -1.2294e+01, -6.8189e-01, -3.9991e+00,  8.7014e+00,\n",
      "         -1.7387e+01],\n",
      "        [-8.2038e+00, -1.4592e+01,  7.0556e+00,  1.1136e+01, -2.3837e+01,\n",
      "         -1.9003e+01],\n",
      "        [-5.1260e+00,  4.9339e+00, -1.0170e+01, -1.1571e+01, -2.3619e+01,\n",
      "         -1.4396e+00],\n",
      "        [-9.1528e+00, -1.6189e+01,  2.0007e+00, -2.6154e+00, -1.9292e-01,\n",
      "         -8.5512e+00],\n",
      "        [-7.0554e+00, -4.6488e+00, -2.1569e+00, -2.0568e+00,  4.0249e+00,\n",
      "         -1.1635e+01],\n",
      "        [-4.2948e+00,  1.1630e+01, -7.9135e+00, -9.5585e+00, -1.6142e+01,\n",
      "         -4.2658e+00],\n",
      "        [ 2.1519e+00,  4.1483e+00, -1.1733e+01, -8.8976e+00, -1.6179e+01,\n",
      "         -2.8515e+00],\n",
      "        [ 1.1536e+01, -2.1071e+01, -1.9247e+01, -1.6851e+01, -2.1773e+01,\n",
      "         -1.0607e+01],\n",
      "        [ 6.7462e+00, -5.4307e+00, -1.6553e+01, -2.1984e+01, -1.2881e+01,\n",
      "         -5.5367e-01],\n",
      "        [ 2.0389e+00, -1.8646e-01, -1.3635e+01, -1.6351e+01, -2.0863e+01,\n",
      "          3.7694e+00],\n",
      "        [-6.9938e+00, -3.8279e+00, -5.7789e+00,  4.7503e+00, -3.2130e-01,\n",
      "         -1.0655e+01],\n",
      "        [-6.1030e+00, -1.6608e+01,  6.4993e+00,  6.5017e-01, -9.3047e+00,\n",
      "         -1.2556e+01],\n",
      "        [ 7.0045e+00, -1.1038e+01, -2.2182e+01, -2.2020e+01, -1.7003e+01,\n",
      "         -3.7035e-01],\n",
      "        [ 9.5104e+00, -1.4583e+01, -1.6573e+01, -1.5167e+01, -1.9875e+01,\n",
      "         -3.5652e+00],\n",
      "        [-6.7323e+00,  2.2034e+00, -4.3509e+00,  9.5094e-01, -2.0004e+00,\n",
      "         -7.6422e+00],\n",
      "        [-1.0545e+01, -2.4940e+01,  1.1024e+01, -2.9724e+00, -1.4294e+01,\n",
      "         -1.4723e+01],\n",
      "        [-1.3513e+01, -2.8851e+01,  1.0412e+01, -1.4301e+00, -1.3292e+01,\n",
      "         -1.3541e+01],\n",
      "        [-4.6233e+00,  1.6356e+01, -6.1669e+00, -1.9115e+01, -2.1116e+01,\n",
      "         -4.1463e+00],\n",
      "        [-8.1109e+00, -6.8723e+00, -3.8908e+00,  2.4185e-01,  5.3345e+00,\n",
      "         -7.3764e+00],\n",
      "        [ 1.1044e+01, -2.4301e+01, -1.4484e+01, -1.7617e+01, -1.1859e+01,\n",
      "         -1.2928e+01],\n",
      "        [-7.0550e+00,  6.0878e+00, -1.0201e+00, -7.4230e+00, -2.8161e+00,\n",
      "         -6.6873e+00],\n",
      "        [-7.0244e+00, -9.5518e+00, -6.7826e+00,  1.0317e+01, -5.5431e+00,\n",
      "         -1.3546e+01],\n",
      "        [-1.2700e+01, -1.8480e+01,  9.2799e+00, -2.0666e+00, -1.6492e+01,\n",
      "         -6.3980e+00],\n",
      "        [-9.9092e+00, -2.9884e+01,  8.3421e+00, -2.7338e-02, -1.3467e+01,\n",
      "         -1.0439e+01],\n",
      "        [-1.4244e+00,  1.0753e+01, -1.1854e+01, -1.4151e+01, -1.7791e+01,\n",
      "         -5.0670e+00],\n",
      "        [ 1.1921e+00,  5.4379e+00, -1.4163e+01, -1.9565e+01, -1.6677e+01,\n",
      "         -2.2589e-01],\n",
      "        [-1.6790e+01, -1.2679e+01,  1.0157e+01, -6.5383e+00, -6.2063e+00,\n",
      "         -6.9472e+00],\n",
      "        [-1.1004e+01, -2.2103e+01, -5.0431e-01, -1.5606e+01,  1.3532e+01,\n",
      "         -7.7839e+00],\n",
      "        [-9.4323e+00, -1.7467e+01, -5.8876e+00, -1.9556e+00,  6.5452e+00,\n",
      "         -1.2097e+01],\n",
      "        [-2.6898e+00, -1.5888e+01, -1.1008e+01, -5.7180e+00,  1.0406e+01,\n",
      "         -7.9130e+00],\n",
      "        [-5.0268e+00, -5.7062e+00, -2.3658e+00, -1.2815e+00,  5.0408e+00,\n",
      "         -1.2977e+01]], device='cuda:0')\n",
      "tensor([3, 4, 3, 1, 2, 4, 1, 1, 0, 0, 5, 3, 2, 0, 0, 1, 2, 2, 1, 4, 0, 1, 3, 2,\n",
      "        2, 1, 1, 2, 4, 4, 4, 4], device='cuda:0')\n",
      "tensor([[-11.2318,  -5.6492,  -5.7647, -10.0242,  -9.7654,   4.6424],\n",
      "        [ -1.8544, -33.9474, -10.1605, -18.1186, -18.6504,   5.0898],\n",
      "        [ -3.3231, -18.5930,  -2.7975,  15.4846, -12.4397, -21.2914],\n",
      "        [ -9.1941, -24.5264,  11.7185,   5.7806, -21.9861, -19.2782],\n",
      "        [  5.0579, -22.6060,  -7.7128,  -6.3023, -10.8862,  -7.6864],\n",
      "        [ 12.1789, -12.9846, -18.6140, -12.1812, -18.0462, -10.6614],\n",
      "        [  1.2495, -23.9672,  -2.7801, -11.7101, -11.4753,  -6.4402],\n",
      "        [ -7.1358,  -7.5703,  -1.4909,   5.6716,  -4.8287, -10.0148],\n",
      "        [ -4.6304, -16.4860,  -3.0946,   8.4731,  -4.2750, -18.3788],\n",
      "        [ -6.4496, -17.5398,  -3.4446, -16.8823,  13.1031,  -9.6046],\n",
      "        [ -4.8770, -15.3791,  -2.3155,  13.1497, -14.4733, -18.6586],\n",
      "        [ -8.5542,  11.0554,  -2.7986, -11.3811,  -5.4223,  -9.6558],\n",
      "        [ -3.8542,  13.3924,  -8.4850, -21.0578, -23.3995,  -2.1741],\n",
      "        [-11.4495, -21.2223,   8.8928,   1.6657,  -9.2422, -11.7527],\n",
      "        [-10.9240, -25.5956,  11.1480,   2.5032, -18.3897, -11.3437],\n",
      "        [ -8.8953, -14.9398,  -7.9506, -19.5800,   9.9552,  -2.4985],\n",
      "        [  0.6866,  -8.8262,  -8.0110, -15.5168, -10.8753,  -0.6699],\n",
      "        [  0.3465,   4.4226, -10.3438,  -6.0564, -19.4786,  -8.5071],\n",
      "        [ -9.8682, -25.0811,   7.5779,  -0.1171,  -9.4239, -16.9856],\n",
      "        [-14.2237, -13.6520,   3.4495,  -6.4259,  -0.8329,  -5.7315],\n",
      "        [ -6.4572, -11.9364,  -0.6571,   7.0021,  -9.2912, -12.6100],\n",
      "        [  1.4949, -18.6402, -12.9515, -11.1260,  -4.3493,  -3.2293],\n",
      "        [  9.3982, -40.5725, -13.6398, -12.3659, -19.1395,  -6.6657],\n",
      "        [-10.3190, -15.5333,   8.6722,  -7.6805,  -9.4586, -13.4907],\n",
      "        [ -6.7912,  14.7322,  -4.5760, -16.5560, -15.5116,  -6.7515],\n",
      "        [ -8.9371,  -9.8541,  -4.8473, -10.8915,  14.3020,  -8.2035],\n",
      "        [ -7.7352, -38.0018, -26.1879, -22.1351, -16.5892,   1.7934],\n",
      "        [  6.8548, -28.5234, -11.8042, -23.8768, -16.8756,   0.9129],\n",
      "        [ -7.2464, -14.1253, -12.3099, -19.9477, -11.9421,   8.2604],\n",
      "        [ -5.0735,   7.6046,  -6.6147, -12.1036, -14.6950,  -4.1381],\n",
      "        [  3.5506, -17.1954, -10.0148, -12.0477,   0.8987,  -8.9816],\n",
      "        [  9.3884, -24.3097, -17.1476, -18.5844,  -9.4883,  -4.2716]],\n",
      "       device='cuda:0')\n",
      "tensor([5, 5, 3, 2, 0, 0, 0, 3, 3, 4, 3, 1, 1, 2, 2, 4, 0, 1, 2, 2, 3, 0, 0, 2,\n",
      "        1, 4, 5, 0, 5, 1, 0, 0], device='cuda:0')\n",
      "tensor([[ -3.1884,  13.1858,  -3.2100, -15.0508, -18.4041,  -7.3520],\n",
      "        [ -7.5135,  13.9258,  -5.2932, -12.0314, -12.9433,  -5.3948],\n",
      "        [ -5.3050,   1.1356,  -0.6472,  -7.4655,  -3.1864,  -5.8232],\n",
      "        [ -8.0357, -19.5170,   0.2327,   7.3594,  -8.1619, -16.8009],\n",
      "        [ -7.9796, -24.3489,  -1.8243, -18.1237,  13.0590,  -8.3691],\n",
      "        [ -6.5734, -16.3647, -10.3536, -17.3148, -14.7978,   8.5647],\n",
      "        [  6.9795, -19.9762, -15.3377, -27.2840, -12.2288,  -2.7843],\n",
      "        [-12.7139, -12.7101,  -4.6770, -21.3193,  18.1768, -13.9130],\n",
      "        [ -7.7657, -13.1494,  -2.0417,   8.8013, -11.6338, -12.5355],\n",
      "        [ -4.9859,  -1.5503,   0.5274,   0.8294,   1.1590,  -5.5782],\n",
      "        [ -6.7268, -17.5743,   0.2828,  12.8414, -13.3548, -19.7580],\n",
      "        [  3.2968, -22.8053,  -8.3345, -18.8875, -13.9076,  -3.2821],\n",
      "        [-11.2278, -25.3658,  -1.3036, -17.1532,  20.4832, -14.0459],\n",
      "        [ -8.7530, -20.2455,  -3.5463,  -6.0573,  12.9255, -12.3963],\n",
      "        [ -9.8489,  -7.2319,  -7.7800,   1.7252,   7.8276,  -6.4100],\n",
      "        [-13.2471,  -7.0752,   4.7890, -14.2236,   4.8712,  -9.6799],\n",
      "        [ -3.6246, -12.8118,   2.3741,   5.5562, -13.8085, -12.7574],\n",
      "        [ -6.9686, -14.3990,  -7.3152, -15.7438,  17.4748,  -8.1878],\n",
      "        [ -4.5295, -11.3882, -10.6012,  -3.8617,   9.0050, -10.3897],\n",
      "        [ -4.8585, -23.3398,   7.9653,   2.0946, -13.2858, -13.2568],\n",
      "        [  7.1714, -21.3215, -19.6032, -13.0874, -12.6191,  -0.8440],\n",
      "        [ -4.9474,   7.2406,  -5.7528,  -5.3826, -11.9067,  -4.9499],\n",
      "        [ -9.7843, -11.6106,   4.5826,  -5.7980,  -8.4484,  -9.1737],\n",
      "        [ -5.1970,   2.8177,  -1.6490, -12.4559,  -9.2061,  -2.6997],\n",
      "        [ -6.0180,   0.5439,  -1.2177,  -1.6743, -14.2947,  -6.2887],\n",
      "        [ -0.4136, -16.8029, -14.4179, -19.4175, -17.7228,   7.8751],\n",
      "        [ -6.4821,   6.0085,  -8.8925,  -5.9108,  -7.3715,   2.5760],\n",
      "        [ -1.3997,  -8.2037,  -9.6510, -11.5112,  -5.8238,  -4.8172],\n",
      "        [ -6.7501, -21.7776,  -0.2835,  -1.4296,  -9.8724,  -6.5190],\n",
      "        [-14.4893, -23.1791,  11.8613,   0.8090, -12.3024, -16.5080],\n",
      "        [ 11.5945, -32.3777, -15.2778, -18.1573, -15.7305,  -9.4894],\n",
      "        [ -3.6419, -23.6040,  -0.1828,   2.9454,  -4.6125, -12.5548]],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 1, 3, 4, 5, 0, 4, 3, 4, 3, 0, 4, 4, 4, 4, 3, 4, 4, 2, 0, 1, 2, 1,\n",
      "        1, 5, 1, 0, 2, 2, 0, 3], device='cuda:0')\n",
      "tensor([[  8.8186, -23.2746,  -9.5176, -11.4931,  -3.5080,  -8.2992],\n",
      "        [-10.3447,  13.9795,  -0.6441, -14.6796, -10.3518,  -6.4189],\n",
      "        [ -9.6675,  10.1966,  -2.3642, -12.4604, -12.4161,  -2.3379],\n",
      "        [ -4.0826,  -9.5386,  -5.7993,   5.3487,  -1.7484, -11.5408],\n",
      "        [ -7.7223,  -6.0383,  -2.7999,  -8.1449,   8.3891,  -3.9530],\n",
      "        [-13.9950, -18.2905,  -0.2788,  -4.6287,   9.9623, -14.0412],\n",
      "        [ -4.4421,   4.4621,  -0.2618,  -6.8144,  -6.3336,  -6.6486],\n",
      "        [-11.4818,   7.7266,   1.8851, -12.7863, -19.1182,  -5.0924],\n",
      "        [ -6.9545,  -9.1216,  -5.1020,   8.3808,  -5.3419, -11.9043],\n",
      "        [ -9.1927,  16.0956,  -7.9952, -12.2541, -11.0818,  -5.6250],\n",
      "        [ -5.1570,  -4.4096,  -5.0265,  -7.1690,  -1.1541,  -5.7034],\n",
      "        [ -7.6196, -11.3278,  -5.0940, -12.9989,  -6.5247,   2.7645],\n",
      "        [-10.0150, -20.4739,  -8.9065,  -4.8564,  14.7051, -11.6911],\n",
      "        [ -6.9304,  -7.9022,  -6.0796,   6.2499,   1.4656, -11.7621],\n",
      "        [ -6.4537,  13.4287,  -2.4099, -15.9463, -13.0122,  -6.9529],\n",
      "        [  0.7648, -10.7051, -19.0254, -27.0370, -13.6707,   5.8040],\n",
      "        [ -7.1187, -20.4146, -12.0356, -13.7487, -16.7142,   8.1015],\n",
      "        [ -5.1600,  -6.9825,  -7.3542, -18.8248, -18.0342,   5.1492],\n",
      "        [ -7.7363, -30.2208,  10.8282,   5.0884, -15.5904, -17.2449],\n",
      "        [-11.0367, -12.4669,   1.8324,  -6.9529,   3.8148,  -6.2784],\n",
      "        [ -7.3611,  11.5630,  -4.8125, -13.8098, -11.7919,  -4.6584],\n",
      "        [  1.5294, -20.7360,  -6.9084,  -1.4426,  -2.0197, -10.5746],\n",
      "        [  7.4038, -26.7624,  -6.2928,  -3.1272, -12.4097, -12.7375],\n",
      "        [-10.6577, -16.2153,  12.9262,  -7.3695, -11.0136, -13.1213],\n",
      "        [  1.0037, -21.4316,  -6.7709, -16.6674, -10.2898,  -1.1386],\n",
      "        [ -8.8372,   1.2625,  -7.8071, -13.4248, -10.2110,  -2.0458],\n",
      "        [  7.0000, -12.6951, -13.8113, -11.1188, -16.5457,  -6.7692],\n",
      "        [ -8.7644, -18.0436, -12.8928, -14.0694, -16.4610,   7.5928],\n",
      "        [ -9.8738, -21.6542,   2.0860,   2.8060,   0.6055, -18.0018],\n",
      "        [ -5.1260, -13.4271, -10.6652,  -6.1931,  11.2982, -15.1529],\n",
      "        [ -8.4991, -13.4265, -19.4612, -16.5479,  23.1390, -12.7818],\n",
      "        [  6.2602, -33.6783, -11.7077, -14.0372,  -6.6891,  -8.4192]],\n",
      "       device='cuda:0')\n",
      "tensor([0, 1, 1, 3, 4, 4, 1, 1, 3, 1, 4, 5, 4, 3, 1, 5, 5, 5, 2, 4, 1, 0, 0, 2,\n",
      "        0, 1, 0, 5, 3, 4, 4, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 10.6868, -36.5835, -27.0482, -28.7530, -15.5987,   7.6860],\n",
      "        [-10.0799, -15.9227,   3.4334,  -2.4816,  -2.8474,  -7.5674],\n",
      "        [  7.0588, -13.8395, -18.7172, -16.6813, -14.1595,  -6.9626],\n",
      "        [ -7.4259,  11.1588,  -1.7343, -11.2064,  -9.8297,  -6.8620],\n",
      "        [ -5.2968,  -0.8385, -13.9304, -22.2341, -24.3923,   4.4626],\n",
      "        [ -3.4849,  -7.4465,  -7.1201,  10.3084,  -3.0119, -15.8929],\n",
      "        [ -9.4301, -21.9883,   8.5934,   2.3423, -10.0625, -11.1268],\n",
      "        [ -6.7744,  -9.4048,   1.9544,   4.4820, -13.5960, -11.1408],\n",
      "        [ -4.8459, -16.4632,  -4.7330,  15.0573, -11.3196, -19.8339],\n",
      "        [ -7.1407, -18.0008, -10.7307, -19.5890,  19.1157, -10.6687],\n",
      "        [ -8.4172,  11.1481,  -5.2998,  -2.3594,  -4.3755, -10.5346],\n",
      "        [ -9.9305, -12.9741,   2.4524,   7.8510, -11.9578,  -9.8395],\n",
      "        [ -3.1703, -24.0101,   3.9708,   5.8624, -11.4952, -16.0159],\n",
      "        [ -0.8350,  10.7921,  -9.3050, -21.6947, -20.0092,  -3.3189],\n",
      "        [ -4.2343, -29.6802, -10.5183, -20.7157, -19.8607,   8.5962],\n",
      "        [ -5.5289,  -4.7104, -12.9415, -11.9936, -20.3563,   4.1492],\n",
      "        [ 10.2330, -35.1539, -22.3614, -23.7356, -15.0932,  -2.3014],\n",
      "        [  6.9206, -26.0278, -16.0412, -16.0897, -17.6602,  -1.6447],\n",
      "        [ -8.2781, -11.2138, -11.2238, -15.2970,  -4.1115,   6.1952],\n",
      "        [  7.1792, -16.3567, -16.0763, -14.4989,  -6.4911,  -4.5429],\n",
      "        [ -0.5548,  -8.3155, -18.2360, -12.8476, -25.3442,   0.1146],\n",
      "        [-11.2240, -22.8401,  11.2937,  -0.2625, -16.2739, -13.3748],\n",
      "        [-12.8037,  -0.8487,  -0.3608, -14.6566,   6.5499,  -6.8712],\n",
      "        [  5.1706, -10.9544, -17.5366, -15.6454, -17.2721,  -1.7637],\n",
      "        [-12.3512, -16.7215,   5.3277,  10.6800, -13.3205, -15.3282],\n",
      "        [  6.7242,  -8.5387, -13.1065,  -9.8006,  -8.2020,  -9.5432],\n",
      "        [  4.2220, -18.7473, -10.0194,  -6.1636,  -5.6233, -11.0455],\n",
      "        [ -1.7262,  -8.2580, -19.5963, -16.9061, -16.2425,   5.5251],\n",
      "        [ -6.4118, -20.2545,   0.4679,   6.1169,  -7.8860, -13.1246],\n",
      "        [  0.4436, -27.6913, -12.2254, -19.6797,  -9.6647,   3.5610],\n",
      "        [ -7.8960,   7.9123,  -2.1013, -23.1983, -16.8325,  -3.3871],\n",
      "        [ -6.6512, -16.1721,  -3.8466,  -9.7276,  11.7205,  -9.3889]],\n",
      "       device='cuda:0')\n",
      "tensor([0, 2, 0, 1, 5, 3, 2, 3, 3, 4, 1, 3, 3, 1, 5, 5, 0, 0, 5, 0, 5, 2, 4, 0,\n",
      "        3, 0, 0, 5, 3, 5, 1, 4], device='cuda:0')\n",
      "tensor([[ -8.2463, -15.0321,  -3.6963,  -9.5069,  12.2087,  -9.9023],\n",
      "        [ 12.5618, -27.8504, -19.1277, -20.4563,  -7.6964,  -5.0800],\n",
      "        [ -1.7364, -19.7474,  -9.9111, -22.6748, -11.5000,   6.3559],\n",
      "        [-10.2560, -21.5874,   7.3020,  -0.9978, -15.7313, -11.5027],\n",
      "        [-10.3353, -14.0943,  -2.2978,  -5.0842,   4.9154,  -9.3555],\n",
      "        [ -5.0609, -13.7115,  -2.5670,  10.5189, -13.2671, -16.2211],\n",
      "        [ -2.8202, -18.7950,  -8.0885,   1.8334,   2.2950, -16.0991],\n",
      "        [  8.5708, -27.6763,  -4.4996,  -2.7610, -24.9892, -16.8023],\n",
      "        [ -0.8831, -25.8884, -21.8024, -24.5405, -16.0056,   6.7857],\n",
      "        [ -8.0725, -22.8757,   6.9551,   0.7688, -11.9206, -12.0970],\n",
      "        [ -2.0008, -17.1283, -10.2774, -10.5952,   9.3237,  -8.3478],\n",
      "        [ -6.5209,  -8.9157,  -4.6577,  10.1028,  -6.7655, -13.3053],\n",
      "        [ -3.6268,  -0.9881,  -1.8003,   3.4522,  -1.7517, -10.6100],\n",
      "        [ -4.6534,  -4.3930,  -6.0660,  -5.7279,  -8.6746,   1.1132],\n",
      "        [ -8.5333, -21.8268,   9.8480,  -3.5903, -10.1337,  -8.5846],\n",
      "        [ 13.6135, -25.3427, -22.3962, -22.1164, -19.3905,  -4.3424],\n",
      "        [-12.0596, -17.2165,   9.1145,  -9.1552,  -7.4369,  -6.0939],\n",
      "        [ -8.1355, -12.2563,   2.6717,   5.8142,  -9.7215,  -9.4379],\n",
      "        [-12.8234, -21.0309,   8.1570,  -3.9045,  -5.0530, -13.2435],\n",
      "        [ -4.1544, -11.7783,   1.8506,   0.1338, -14.7304, -12.9993],\n",
      "        [-10.4803, -20.5238,   2.1611,  -1.7270,  -5.7028, -10.5360],\n",
      "        [  1.0606,  -7.4683,  -8.1435,  -2.6487,  -6.2932,  -6.2801],\n",
      "        [ -4.1219, -19.3763,  -6.8120, -10.1572,   3.8820,  -6.3374],\n",
      "        [ -4.7115,  -2.9205,  -6.3005, -13.9809, -12.2753,   3.1002],\n",
      "        [ 20.2280, -30.2753, -18.4889, -19.4801, -25.8958,  -9.4984],\n",
      "        [ -6.4349, -12.3279,  -4.5778, -14.9813,  11.1873,  -7.6165],\n",
      "        [ -9.7474, -16.5081,  -0.6651,  -2.1700,  -7.0095, -13.2669],\n",
      "        [-11.2913, -15.4524, -15.0924, -15.9509, -17.1674,   0.5997],\n",
      "        [ -5.1216,  -5.0176,  -1.0277,   1.3045,  -3.4382,  -5.8822],\n",
      "        [-10.5005, -11.3753,   2.7145,   1.1104,  -8.3902,  -8.6538],\n",
      "        [ -9.3123, -20.3433,  -9.4757, -14.8025,  -7.8665,  -2.1136],\n",
      "        [ -1.9114,   7.5789,  -5.5945, -15.7533, -14.6735,  -4.5745]],\n",
      "       device='cuda:0')\n",
      "tensor([4, 0, 5, 2, 4, 3, 4, 0, 5, 2, 4, 3, 3, 5, 2, 0, 2, 3, 2, 2, 2, 0, 4, 5,\n",
      "        0, 4, 2, 5, 3, 2, 5, 1], device='cuda:0')\n",
      "tensor([[-10.5616, -18.7738, -11.0112, -21.9135,  -6.4453,   7.9339],\n",
      "        [ -4.7188,  -5.9369,  -2.0782,   2.8832,  -2.1000,  -6.8522],\n",
      "        [  0.6335, -20.8430, -13.4832, -19.6159,   3.2138,  -3.2302],\n",
      "        [ -3.4733,   7.4643,  -8.7476, -12.3205, -16.2514,  -4.3199],\n",
      "        [ -5.1998,  10.3428,  -3.3581, -11.1847, -10.8095,  -5.0049],\n",
      "        [ -3.0366, -43.7806, -21.0293, -23.7320, -18.1698,   9.9156],\n",
      "        [ -3.0715, -28.5991, -12.8832, -19.0835, -22.2586,   8.0760],\n",
      "        [-16.2035,  -5.9108,  -1.1611, -15.4477,   9.2115,  -9.8987],\n",
      "        [ -3.9956, -24.4892,  -6.2508, -18.9884, -20.8278,   7.0485],\n",
      "        [-13.0936, -22.1230,  11.2555,   2.1576, -23.3687,  -8.8175],\n",
      "        [ -5.4816, -18.8968,  -6.2254,   6.7380,  -6.4834, -16.6125],\n",
      "        [ -0.5717, -21.4959, -11.0636,  -5.9862,  -9.6969,  -4.1190],\n",
      "        [ -0.4827,  -3.2358, -17.0467, -13.9985, -10.7000,   3.3800],\n",
      "        [ -7.8970, -14.5193,  -0.4158, -13.9949,  12.9134,  -8.3315],\n",
      "        [  2.8742, -26.4553,  -0.8916,   2.4366, -17.0984, -16.6671],\n",
      "        [  1.2660, -18.3036,  -4.6824, -14.3326,  -2.7851,  -7.5627],\n",
      "        [ -8.4713, -28.0060,   8.2887,  -3.0392, -12.3587, -13.4337],\n",
      "        [ -9.7140, -15.0608,  10.8405,  -3.3522, -17.8714, -13.1785],\n",
      "        [ -8.7598,  -6.2685,  -0.8559,   4.8045,  -2.6243,  -9.6149],\n",
      "        [ 10.2947, -44.3293,  -9.8916, -10.7752, -24.2093, -14.1737],\n",
      "        [-11.1876,  -6.3562,   6.4487, -10.8016,  -6.9058,  -8.1463],\n",
      "        [ -2.7411,   9.7352,  -6.7547,  -9.0064, -15.0536,  -4.5488],\n",
      "        [ -4.9928, -10.8541,  -9.9393, -11.0640,   9.7516,  -7.5564],\n",
      "        [ -4.7332,  10.1960,  -4.7520,  -6.9578, -12.7224,  -7.0495],\n",
      "        [ -9.0109, -13.2246,  -6.0689,   2.9997,   3.3574, -10.4403],\n",
      "        [  6.5073, -17.1718, -23.1293, -19.8391, -13.4438,   5.4924],\n",
      "        [  2.4517,  -8.2924,  -1.4804,  -8.9115, -11.4037,  -7.4203],\n",
      "        [  3.0655, -26.1266, -11.8927, -19.2614,  -9.4977,  -0.7983],\n",
      "        [ -8.8723,  -5.9980,  -3.3654,   0.0594,   5.8615,  -8.9831],\n",
      "        [ -6.4580,  -9.1842,  -6.1318,   8.4132,  -9.4881, -14.2992],\n",
      "        [ 10.7282, -33.9791, -17.5201, -14.9637, -10.1899,  -3.9850],\n",
      "        [ -6.2289,  -8.8561,  -6.3452,  -2.4547,   6.0669,  -6.6471]],\n",
      "       device='cuda:0')\n",
      "tensor([5, 3, 4, 1, 1, 5, 5, 4, 5, 2, 3, 0, 5, 4, 0, 0, 2, 2, 3, 0, 2, 1, 4, 1,\n",
      "        4, 0, 0, 0, 4, 3, 0, 4], device='cuda:0')\n",
      "tensor([[ -8.2137, -12.4964,   3.4274,   7.6490, -13.4710, -10.7922],\n",
      "        [ -5.7056, -19.8942,  -2.0876, -24.2966,  -5.9021,   2.0021],\n",
      "        [-10.1408,  -6.2604,  -9.7826,   0.3150,  -1.5820, -11.4070],\n",
      "        [ -2.0246, -35.2067, -12.6231, -18.5058, -11.8258,  10.6455],\n",
      "        [ 14.4150, -15.6893, -18.7281, -21.7638, -18.8227, -11.1667],\n",
      "        [  1.1908,   8.8451, -14.9701, -16.8094, -22.3924,  -0.8348],\n",
      "        [  0.5631, -32.6274, -23.4294, -26.4588,  -5.6743,   6.8635],\n",
      "        [-14.2067, -16.0278,  11.5096, -12.8418,  -2.5969,  -8.5495],\n",
      "        [ -4.4353, -21.8237,   1.8850,   3.9487, -13.0582, -14.8135],\n",
      "        [-12.5948, -20.9250,  -5.1793,  -5.3983,  11.1482, -16.7530],\n",
      "        [ -7.4142,   7.0337, -10.1519, -16.0904, -18.3604,   1.0119],\n",
      "        [ -4.4992, -10.1208,  -6.1202, -16.3332, -15.1492,   5.2485],\n",
      "        [ -2.7911,  11.7465, -12.6679, -10.5719, -20.9824,  -4.3627],\n",
      "        [-10.1670, -24.1199,   7.1339,   0.6989, -12.7008, -10.2850],\n",
      "        [ -2.6216,   6.7073,  -5.1248, -10.6828, -12.2521,  -7.2872],\n",
      "        [ -1.2149, -28.7762, -11.0848, -12.2444, -20.8366,  -8.1919],\n",
      "        [ -6.3435, -27.0073,   6.0231,   4.8168, -16.8279, -15.9675],\n",
      "        [ -3.4471,  -6.9765,  -5.2940,   7.4657,  -5.0590, -13.7502],\n",
      "        [-11.2179,  -9.0465,   6.8713,  -0.3478,  -6.5636, -12.7468],\n",
      "        [-12.9021, -21.1291,   6.4258,  10.9354, -15.5873, -19.0907],\n",
      "        [ -9.8349, -14.7122,  -4.0480, -13.8718,  14.0454, -11.4979],\n",
      "        [ -1.0257, -11.8167,  -3.4061,   5.5802, -12.3456, -14.9420],\n",
      "        [ -5.0960,   7.7160,  -8.5062, -12.4684,  -3.5583,  -7.1392],\n",
      "        [-13.3819, -17.6354,  -8.0696,  -7.3360, -10.2720,   4.0161],\n",
      "        [  1.1701,  -9.1696,  -8.8570, -12.1067, -11.5437,  -3.0116],\n",
      "        [ 17.0893, -30.8302, -23.9751, -34.3721, -19.3105,   0.0836],\n",
      "        [ -5.9083, -17.9464,  -2.1722, -16.6994,   4.8694, -10.9748],\n",
      "        [ -9.5996, -19.2818,   2.0562,  -7.3591,   9.2187, -12.1557],\n",
      "        [ -3.4583, -18.8104, -17.4752, -17.1762, -13.7351,  10.5760],\n",
      "        [ -3.8232, -15.8109,   1.2663,  -3.6385,  -8.4726, -12.6936],\n",
      "        [  8.0204, -32.1099, -11.1313, -11.3341, -17.1045,  -9.3712],\n",
      "        [-13.7012, -12.6152,  12.2581, -10.6857,  -8.1814, -10.2158]],\n",
      "       device='cuda:0')\n",
      "tensor([3, 5, 3, 5, 0, 1, 5, 2, 3, 4, 1, 5, 1, 2, 1, 0, 2, 3, 2, 3, 4, 3, 1, 5,\n",
      "        0, 0, 4, 4, 5, 2, 0, 2], device='cuda:0')\n",
      "tensor([[  1.8016, -24.9764, -11.4809, -11.7245, -14.5741,  -1.6399],\n",
      "        [ -5.8832,   4.8520,  -1.4799, -12.4489, -12.8163,  -5.4388],\n",
      "        [ -6.2388,   3.3814,  -6.5726,  -6.9449,  -2.2165,  -5.6651],\n",
      "        [ -1.3290, -25.6624, -14.0266, -14.8266, -22.8159,   4.7146],\n",
      "        [ -9.0413, -16.1351,  -1.4670,  13.3948, -13.6287, -17.5736],\n",
      "        [  2.7388,  -5.5477,  -7.5641,  -3.4749,  -4.4403,  -8.7081],\n",
      "        [ -5.9124,  16.5545,  -4.3540, -16.7486, -16.9270,  -8.9469],\n",
      "        [  6.6639, -15.8599,  -7.3834, -13.2525, -15.6897,  -8.4252],\n",
      "        [ -7.7698, -18.6034,  -5.2862,  -5.4035,   3.2847,  -7.2211],\n",
      "        [ -4.4001, -14.2632, -12.4484, -17.5127, -11.2889,   5.5566],\n",
      "        [  3.4183, -20.5909, -15.0711, -27.5483, -13.2401,   3.9638],\n",
      "        [ -3.0218,  10.4414,  -5.7085, -10.5587, -17.2429,  -5.1960],\n",
      "        [ -6.2615, -16.5542,   5.1851,   3.2089, -13.4367, -10.4459],\n",
      "        [ -5.7520,  -9.9261,  -1.4352,   3.0734,  -5.2706,  -7.8077],\n",
      "        [-12.3966, -15.8323,   5.5208,   4.1838,  -9.8892, -12.5806],\n",
      "        [  3.4041, -35.3348, -12.4867,  -8.8721,  -4.2868,  -7.3780],\n",
      "        [ -6.5411, -12.1049,   2.5785,   2.4044,  -7.2625,  -8.7621],\n",
      "        [ -9.8329,  -7.7338,   7.8779,  -3.8771,  -7.0155,  -9.3008],\n",
      "        [  3.6238, -16.1824, -14.2242,  -9.0077,  -7.3170,  -4.5415],\n",
      "        [ -9.4901, -12.0948,  -2.4258, -16.2408,  15.1590,  -9.4355],\n",
      "        [ -2.3396,   7.0099,  -2.0025, -10.0580, -15.1162,  -6.7475],\n",
      "        [  3.6852, -17.0195,  -7.4185, -15.3779, -16.4208,  -2.3560],\n",
      "        [ -5.1957,  14.7740,  -2.9917, -17.6437, -17.9738,  -8.2276],\n",
      "        [ -5.3207, -18.1236, -18.0866, -20.2608, -11.7477,   6.2998],\n",
      "        [ -7.9617, -16.3617, -12.5559, -19.9546, -21.2769,   7.0702],\n",
      "        [ -2.0961,  -7.7205, -10.5163, -15.4003, -15.7917,  -0.2160],\n",
      "        [-10.5005,   1.1270,   2.6110,  -5.8000,  -3.4779,  -7.8402],\n",
      "        [ -8.5918, -13.5891,   5.1444,   4.6560, -12.8523, -14.1397],\n",
      "        [ -9.8010, -23.2952,   6.6444,  -9.0795,  -0.5253, -15.4268],\n",
      "        [ -8.8618, -11.4621,  -1.9225,  -6.0273,  11.4641, -11.9280],\n",
      "        [ -7.1966, -31.4318,   9.7156,   1.6297, -18.2746, -21.3021],\n",
      "        [  3.6276,  -7.4540, -21.7888, -20.1845, -16.3917,   7.5135]],\n",
      "       device='cuda:0')\n",
      "tensor([0, 1, 1, 5, 3, 0, 1, 0, 4, 5, 5, 1, 2, 3, 2, 0, 2, 2, 0, 4, 1, 0, 1, 5,\n",
      "        5, 5, 2, 2, 2, 4, 2, 5], device='cuda:0')\n",
      "tensor([[-10.2654, -17.6299,   1.3791,  13.5611, -13.1805, -20.5584],\n",
      "        [ -6.0152, -11.0259, -10.9611, -21.8720, -13.2929,   6.4520],\n",
      "        [  1.8362,   5.2810,  -8.8503, -12.7202, -14.9468,  -8.6618],\n",
      "        [  6.8157, -27.3702, -21.9916, -23.5910, -14.6619,   4.8138],\n",
      "        [ -8.3819,  -9.2608,   0.9352,   5.5255,  -4.5287, -10.6117],\n",
      "        [ -4.8585, -23.1793,   2.1054,   6.4043,  -6.9891, -15.8742],\n",
      "        [ -2.6277,  -1.7639,  -3.7119,  -3.7512,  -7.5115,  -6.7148],\n",
      "        [  0.2758, -19.3119,   0.7649,  -0.9870, -15.5830, -17.1798],\n",
      "        [ -2.0362, -18.1428,  -8.5189, -20.8637,  11.6223, -11.9037],\n",
      "        [-10.1497, -11.2135,  -3.8287,  13.5661,  -7.4532, -14.5969],\n",
      "        [ -6.9031,  12.4689,  -2.2349, -16.1938, -13.3967,  -7.1116],\n",
      "        [ -8.4869, -18.0957,   5.0046,   9.1568, -12.2711, -16.8293],\n",
      "        [  7.2886, -24.8458, -11.1573, -17.9957, -15.8160,  -5.6342],\n",
      "        [ -7.6053,  -7.0883,  -1.4847,   7.9743,  -9.2690, -10.9362],\n",
      "        [ -3.6439, -13.2736,  -9.6277, -13.6102, -14.3800,   3.7337],\n",
      "        [  2.4516, -29.0382, -16.0866, -19.3607,  -4.3657,   0.5834],\n",
      "        [  5.5196, -24.4218,  -4.0669,   8.4889,  -7.7179, -20.5787],\n",
      "        [ -8.1965, -15.4820,  -0.6463,   4.3694,  -4.4340, -14.3431],\n",
      "        [ -0.8236,   6.6603,  -7.2494,  -8.7447,  -9.4862,  -2.5493],\n",
      "        [  1.6688, -28.2661, -17.7520, -15.6258,  -4.4320,   0.5662],\n",
      "        [  5.5999, -21.0034, -13.6869, -17.3092, -10.5500,  -2.1395],\n",
      "        [ -4.1786,  11.3461, -11.7529, -17.7092, -17.8301,  -3.3764],\n",
      "        [ -9.8621,  14.4790, -15.8861,  -6.6101, -17.4968,  -4.1998],\n",
      "        [ -5.4163,   9.1830,  -6.1758, -16.0677,  -9.6342,  -5.6174],\n",
      "        [-14.6284, -17.6329,  -5.0781, -12.4336,  22.1825, -16.2131],\n",
      "        [ -1.5024, -22.5440,   0.4570,  -0.5405, -13.0466, -10.1416],\n",
      "        [ 16.5431, -29.9659, -30.0788, -29.2728, -15.3660,  -0.2501],\n",
      "        [ -8.6129, -15.8262,  -8.8076, -19.1113, -19.0503,   7.7577],\n",
      "        [-11.7780, -19.8353,  -9.3886,  -4.9527,  15.1953,  -8.6828],\n",
      "        [ 10.6331, -38.7654, -12.7090, -11.9960,  -9.3006,  -8.3283],\n",
      "        [  7.9752, -31.4182, -10.4441, -27.7032, -13.3113,  -1.2413],\n",
      "        [  1.0216, -22.2533, -10.7886,  -6.3096, -10.3769,  -4.0580]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 5, 1, 0, 3, 3, 1, 2, 4, 3, 1, 3, 0, 3, 5, 0, 3, 3, 1, 0, 0, 1, 1, 1,\n",
      "        4, 2, 0, 5, 4, 0, 0, 0], device='cuda:0')\n",
      "tensor([[ -7.3435, -18.2387,  -0.7766,   9.6224, -10.2775, -13.6462],\n",
      "        [ -7.6337, -16.3959,  -9.5906,  -3.2845,   8.9600,  -6.7296],\n",
      "        [ -5.2001, -11.8886,  -6.6216, -16.1696, -12.4309,   2.8233],\n",
      "        [-11.5600,  -9.0007,  -4.0966,   8.3898,  -6.2250,  -8.4379],\n",
      "        [ -9.9597,  -4.6763,  -3.1436,  -2.6998,   7.6129,  -6.1313],\n",
      "        [  2.4947, -24.3175, -10.3607,  -8.7625,  -3.8202,  -3.6450],\n",
      "        [ -2.7848,  -8.0009,  -6.3326,   0.5163,  -7.3367, -11.9349],\n",
      "        [  1.4181, -26.2332,   1.0652,  -1.3860, -11.2201, -13.4400],\n",
      "        [ -7.6791, -20.1413,  -5.2109,  -4.6226,   8.6080, -12.5350],\n",
      "        [ -6.2470, -13.3609,  -0.5552,   0.5946,  -9.8541,  -8.4708],\n",
      "        [ -3.2958,   8.7390, -13.8554, -15.8220, -19.9627,  -0.2142],\n",
      "        [  2.0109, -15.6312, -19.7279, -20.0342, -20.1225,   6.9412],\n",
      "        [ 11.8509, -19.1467, -11.2330,  -5.8707, -18.8174, -14.6643],\n",
      "        [-10.5999, -15.3361,  -4.6662, -10.1727,  12.6217,  -9.6475],\n",
      "        [-10.5754,  -1.6611,  -0.4080,  -3.5286,   6.5088,  -7.1503],\n",
      "        [ -4.3977,  11.5138,  -4.5023, -10.7522,  -9.8084,  -4.6078],\n",
      "        [-11.2142, -14.8931,   4.0800, -10.3808,   2.7449,  -9.7402],\n",
      "        [ -4.0780,   7.4587,  -5.5565, -13.0560, -13.4261,  -1.6715],\n",
      "        [  4.4461, -14.5637,  -5.2194,  -5.9550, -12.2175, -12.4463],\n",
      "        [-15.1616, -25.1883, -18.3214, -28.5870, -18.2653,   8.8688],\n",
      "        [-15.4104, -23.7973,  13.1465,  -3.6992, -10.8091, -14.7755],\n",
      "        [ -5.3302,  12.2674,  -2.6306, -10.7047, -13.6594,  -9.6353],\n",
      "        [-10.3135,  -8.4106,   2.8743,   2.8343,  -6.6009,  -9.5587],\n",
      "        [ -0.3520,  -2.5087,  -4.5996, -12.5911,  -9.6648,  -8.1686],\n",
      "        [-11.2080, -18.9126,   0.1179,  -1.3203,   3.8747, -10.9404],\n",
      "        [ -1.3904, -30.7688,  -0.9017,  -5.7143,  -8.0858, -10.9035],\n",
      "        [ -0.6448,  -2.9577,  -9.3431,  -8.6387,  -6.2925,  -5.7904],\n",
      "        [  6.3317, -14.8165, -15.2564, -16.9515,  -8.0980,  -4.7742],\n",
      "        [ -5.0939,  -4.8907,  -5.5902,   5.4394,   1.2415, -12.0143],\n",
      "        [-15.2598, -15.4944,  11.9547, -12.4115,  -2.3421, -10.1029],\n",
      "        [ -5.7092,   7.9286,  -5.8751, -10.1212, -21.3774,  -1.5131],\n",
      "        [ -8.5130,  -1.2609,  -5.4812,   7.7403,  -1.6559, -14.2642]],\n",
      "       device='cuda:0')\n",
      "tensor([3, 4, 5, 3, 4, 0, 3, 0, 4, 3, 1, 5, 0, 4, 4, 1, 2, 1, 0, 5, 2, 1, 2, 0,\n",
      "        4, 2, 0, 0, 3, 2, 1, 3], device='cuda:0')\n",
      "tensor([[ -6.9903, -13.2593,  -6.0719,   5.4563,  -2.8982, -10.8529],\n",
      "        [ -8.0036,   6.8787,  -3.3075,  -6.6973,  -7.1984,  -4.8302],\n",
      "        [ -9.4110,  13.5074,  -0.1551, -15.9393, -14.0387,  -7.0905],\n",
      "        [ -7.0145, -13.0542,  -1.5840,  11.0792,  -9.5916, -14.0887],\n",
      "        [ -3.4120,   2.5549,  -5.3405, -11.3525, -17.4734,  -4.3697],\n",
      "        [-14.3236, -13.8112,   8.9244,  -9.3632,  -4.5930,  -6.1700],\n",
      "        [ -8.5869,  -7.3338,  -1.8138,   8.5937,  -3.0454, -15.7711],\n",
      "        [ -1.0327, -22.4276,  -2.2026, -14.6287, -20.7525,  -1.4529],\n",
      "        [-11.1415,   6.1126,  -3.2567,  -7.5607,  -6.9811,  -6.7007],\n",
      "        [ -9.4855, -25.7437,  10.5258,   2.9096, -16.5643, -15.6765],\n",
      "        [ -2.7817, -25.8907, -10.0330,  -1.6263,  -6.2077, -10.0874],\n",
      "        [ -7.0754, -12.3659,   1.2471,  -0.3855,  -6.4637, -12.6856],\n",
      "        [  5.1862, -23.8100,  -9.3846, -12.7515, -13.6025,  -1.5365],\n",
      "        [ 12.4071, -18.7587, -25.2614, -22.5069, -12.9185,  -2.6749],\n",
      "        [-11.1064, -15.6358,   2.3393, -16.7570,  11.1496,  -4.7227],\n",
      "        [  9.3585, -23.2951, -10.1689,  -9.4739, -19.8072,  -9.5940],\n",
      "        [ 11.0156, -28.5366, -16.6310, -19.5673, -15.5620,  -7.8569],\n",
      "        [ -2.6764, -13.4216,   2.9600,   0.6322,  -7.4798, -12.3809],\n",
      "        [ -6.2824, -14.5545,  -6.0005,  -5.1095,   5.0350,  -7.5969],\n",
      "        [ -4.8183,   5.0506,  -1.5770,  -5.4622,  -6.3432,  -6.8592],\n",
      "        [ -6.5709, -25.6484,  -0.6800,   2.1889, -19.4043, -12.8384],\n",
      "        [ -8.9509,  -6.9222, -10.8548,  -9.5589,  -7.5472,   5.9917],\n",
      "        [ -0.9117, -12.6836,  -4.4830,   1.1823,  -1.8614, -11.1567],\n",
      "        [ 16.5804, -41.4751, -24.4484, -14.5830,  -7.8040, -10.3504],\n",
      "        [ -1.5416,   5.9337,  -4.8292,  -3.3981,  -7.2432,  -3.6670],\n",
      "        [  7.5627, -25.0739, -17.4551, -12.9990,  -6.9759,  -6.3201],\n",
      "        [ -2.7556, -30.1124, -15.9988, -16.3179, -12.1616,   8.3630],\n",
      "        [  7.1413, -27.5494, -15.3530, -18.7030,  -7.8719,  -3.1092],\n",
      "        [-13.5128,  -8.5820,  12.8094, -10.1009,  -4.9066, -10.2734],\n",
      "        [  2.2865, -14.0217, -15.9325, -13.3053,  -9.2428,   0.4868],\n",
      "        [ -6.4885,   7.0515,   0.0497,  -8.4200,  -6.0216,  -5.9890],\n",
      "        [ -2.9007,  16.5688,  -8.7326, -18.9741, -19.2957,  -2.5145]],\n",
      "       device='cuda:0')\n",
      "tensor([3, 1, 1, 3, 1, 2, 3, 0, 1, 2, 3, 2, 0, 0, 4, 0, 0, 2, 4, 1, 3, 5, 3, 0,\n",
      "        1, 0, 5, 0, 2, 0, 1, 1], device='cuda:0')\n",
      "tensor([[ -6.6882,   5.1484,  -4.8071, -15.4748, -11.0156,  -1.8117],\n",
      "        [-11.0268, -29.9492,  10.2475,  -4.3116,  -7.3222, -17.0405],\n",
      "        [ 12.6338, -36.4879, -13.1547, -13.2481, -13.9829, -11.9066],\n",
      "        [ -7.3797, -10.1076,  -7.0035,  11.5991, -10.6561, -13.0743],\n",
      "        [ -7.6229, -21.7935,   4.1787,   7.5888,  -6.8335, -19.3734],\n",
      "        [ -4.8797,  -6.1214,  -2.5288,   0.4032,  -1.3940,  -8.2102],\n",
      "        [  3.9919, -18.9330,  -7.6652, -14.4256,  -6.1650,  -4.2435],\n",
      "        [  2.3856, -21.6045, -20.3425, -18.1067, -17.0781,   6.6927],\n",
      "        [ -9.2545, -35.2765,  17.6731,  -9.5655, -15.0942, -12.1603],\n",
      "        [  9.5587, -35.6655,  -4.4244,  -7.2372, -14.6301, -16.4572],\n",
      "        [ -0.9188, -14.7311, -16.4197, -31.1409, -18.7954,   5.2673],\n",
      "        [-13.2489, -36.0730, -17.7407, -28.0068, -25.8650,  -1.6297],\n",
      "        [-14.8528, -17.1305,   7.6478,   0.8377,  -8.4597,  -5.7554],\n",
      "        [ -5.9758, -17.4863,  -6.0734,  -6.2183,   8.0258, -12.4787],\n",
      "        [ -6.2818, -11.5809,  -1.0594, -26.4013,  -3.8763,  -4.7060],\n",
      "        [-13.9807, -11.4571, -10.5384, -14.7473,  21.3881, -14.6446],\n",
      "        [ -9.7102, -26.3934,   9.5612,   6.8946, -16.4536, -19.3250],\n",
      "        [  1.2532, -17.4543, -16.7734, -12.9046,  -3.5658,  -1.8189],\n",
      "        [ -2.6768,   6.4762,  -6.7616, -13.2912, -14.7784,  -4.5993],\n",
      "        [ -2.1170,   8.8084,  -8.4107,  -9.2412, -13.4830,  -5.7868],\n",
      "        [ -4.5652,  -4.3830,  -9.5073, -12.2715, -12.9512,   4.1780],\n",
      "        [ -5.9242, -10.4844,   2.4510,   3.8004,  -5.3945,  -9.4850],\n",
      "        [  6.9348, -41.8396, -16.3289, -24.4366, -17.2999,   3.9679],\n",
      "        [ -5.2540,  -5.7412,  -6.3620,  -8.6398,  -6.4817,   3.7584],\n",
      "        [-10.2773,   9.0834,  -1.6767,  -8.7509, -12.5107,  -3.4283],\n",
      "        [ -9.4785,  -8.5303,  -1.0117,  -8.5225,   2.9167,  -4.1029],\n",
      "        [ -3.2453,   6.8666, -15.6740,  -9.4364, -10.3031,  -8.1751],\n",
      "        [-11.1442,  -7.7309,  12.2031, -14.3012,  -8.1475,  -7.7063],\n",
      "        [ -4.1458, -14.2439,  -3.2914,  -0.8714,  -8.1830,  -8.5133],\n",
      "        [ -2.6335,  11.8815,  -4.3041, -11.1353, -14.3486,  -9.5010],\n",
      "        [  3.3035, -31.0147, -16.8472, -30.2017, -17.3835,   9.8768],\n",
      "        [ -8.4063,  -9.9155,  -2.8855, -11.6218,  13.6148,  -8.6627]],\n",
      "       device='cuda:0')\n",
      "tensor([1, 2, 0, 3, 3, 3, 0, 5, 2, 0, 5, 5, 2, 4, 2, 4, 2, 0, 1, 1, 5, 3, 0, 5,\n",
      "        1, 4, 1, 2, 3, 1, 5, 4], device='cuda:0')\n",
      "tensor([[-3.4255e+00, -8.9303e+00, -1.2964e+01,  8.2653e+00,  1.8395e+00,\n",
      "         -1.6069e+01],\n",
      "        [-6.2830e+00, -6.7641e+00, -6.4612e+00, -6.1314e+00,  1.0923e+01,\n",
      "         -8.1807e+00],\n",
      "        [-4.4620e+00, -3.1289e+01, -1.8751e+01, -2.4205e+01, -1.4730e+01,\n",
      "          8.1173e+00],\n",
      "        [-4.4492e+00, -9.2888e+00, -9.2377e+00, -2.0162e+00,  7.3542e+00,\n",
      "         -7.6726e+00],\n",
      "        [-6.4611e+00, -2.0849e+00, -9.1086e+00,  6.3243e+00,  3.1205e+00,\n",
      "         -1.4048e+01],\n",
      "        [-6.9840e+00, -1.3613e+01, -8.2578e+00,  1.0889e+00, -8.5468e+00,\n",
      "         -1.0972e+01],\n",
      "        [-9.3215e-01, -1.4403e+01, -9.8439e+00, -2.8494e-02,  6.7693e-01,\n",
      "         -1.0585e+01],\n",
      "        [-1.0187e+00, -1.3465e+01, -6.5044e+00,  1.4236e+00, -8.0777e+00,\n",
      "         -9.4485e+00],\n",
      "        [-3.1641e+00,  1.4295e+01, -1.3746e+01, -1.4293e+01, -2.2661e+01,\n",
      "         -3.6073e+00],\n",
      "        [-6.7075e+00,  7.4603e+00,  3.3774e+00, -1.7007e+01, -9.8961e+00,\n",
      "         -8.3290e+00],\n",
      "        [-1.0453e+01, -1.1619e+01, -4.0254e-02, -1.1672e+01,  1.0497e+01,\n",
      "         -4.5501e+00],\n",
      "        [-2.2902e-01, -2.9787e+01, -1.7317e+01, -2.1197e+01, -1.5912e+01,\n",
      "          9.3516e+00],\n",
      "        [-7.4223e+00, -1.6309e+01,  3.1409e+00,  8.6373e+00, -1.4065e+01,\n",
      "         -1.4173e+01],\n",
      "        [-8.9046e+00,  5.0915e+00, -5.5183e+00, -3.0898e+00, -6.8485e+00,\n",
      "         -3.9564e+00],\n",
      "        [-9.2520e+00, -1.3254e+01,  3.7056e+00, -1.6560e+01,  5.5227e+00,\n",
      "         -6.3129e+00],\n",
      "        [-4.1335e+00,  6.8647e+00, -3.9173e+00, -1.4297e+01, -1.0882e+01,\n",
      "         -6.2485e+00],\n",
      "        [-3.5516e+00, -8.2181e+00, -1.3121e+01, -8.6485e+00, -9.4367e+00,\n",
      "          5.9141e+00],\n",
      "        [-5.9074e+00, -1.4318e+01, -4.0267e+00,  8.6243e+00, -2.2252e+00,\n",
      "         -1.3604e+01],\n",
      "        [-3.1107e+00, -1.6318e+01, -9.4256e+00, -2.0685e+01, -2.1631e+01,\n",
      "          4.0462e+00],\n",
      "        [-9.6105e+00, -9.0291e+00, -3.9043e+00, -9.6709e+00,  7.6942e+00,\n",
      "         -5.5922e+00],\n",
      "        [-1.1649e-01, -1.9940e+01, -1.2157e+01, -5.8881e+00,  7.5034e+00,\n",
      "         -1.2153e+01],\n",
      "        [-5.4640e-01, -2.3041e+01, -2.0107e+01, -1.7796e+01, -9.3989e+00,\n",
      "          7.6147e+00],\n",
      "        [-7.3831e+00, -2.1723e+01,  6.9443e+00,  3.9616e+00, -2.2285e+01,\n",
      "         -1.3107e+01],\n",
      "        [ 3.6583e+00, -2.3664e+01, -1.4151e+01, -2.1878e+01, -1.9546e+01,\n",
      "          4.5781e+00],\n",
      "        [-4.0922e+00,  1.6808e+01, -1.1234e+01, -1.4861e+01, -2.1796e+01,\n",
      "         -8.0074e+00],\n",
      "        [ 9.3408e-01, -2.6218e+01, -1.8545e+01, -1.6564e+01, -1.8781e+01,\n",
      "          7.3702e+00],\n",
      "        [ 7.8983e+00, -2.3415e+01, -2.1547e+01, -2.6624e+01, -1.3777e+01,\n",
      "          4.7267e+00],\n",
      "        [-9.5768e+00, -2.3792e+01, -8.3657e+00, -1.1902e+01, -1.6940e+01,\n",
      "          6.1431e+00],\n",
      "        [-6.5178e-01, -7.3315e+00, -1.1040e+01, -1.2148e+01, -1.4143e+01,\n",
      "         -1.4321e+00],\n",
      "        [-7.1425e+00,  1.3535e+01, -1.1888e+01, -1.1033e+01, -1.2416e+01,\n",
      "         -4.2443e+00],\n",
      "        [-8.9688e+00, -1.0349e+00, -3.8846e+00,  3.9510e-01,  3.0975e+00,\n",
      "         -6.6874e+00],\n",
      "        [ 1.2056e+01, -1.6992e+01, -2.1424e+01, -2.4267e+01, -1.7522e+01,\n",
      "         -8.4943e-01]], device='cuda:0')\n",
      "tensor([3, 4, 5, 4, 3, 3, 4, 3, 1, 1, 4, 5, 3, 1, 4, 1, 5, 3, 5, 4, 4, 5, 2, 5,\n",
      "        1, 5, 0, 5, 0, 1, 4, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -4.4015,   4.9013,  -3.0831,  -1.5271, -11.7061,  -8.6752],\n",
      "        [-10.0998, -18.2570,   6.1424,  -6.9806,  -0.2715, -10.6710],\n",
      "        [ -9.3748,  -9.8752,  -3.6779,   4.6520,   0.5516,  -8.6000],\n",
      "        [ -6.2340, -18.7786,   5.4138,  -1.6056, -13.5591,  -9.0142],\n",
      "        [ -7.4458,  -9.4622,  -6.8744,  -1.7695,   5.1139,  -7.9001],\n",
      "        [ -3.0169, -13.8282,  -6.1630,   7.6194,  -4.6602, -15.0163],\n",
      "        [ -7.5187, -13.5384,  -2.6352,  -6.8126,   8.5465, -13.8848],\n",
      "        [ -2.6067,  -1.7350,  -8.6710,  -1.6691, -10.8853, -10.8725],\n",
      "        [-11.7238, -20.4139,   7.7888,  -1.4059,  -8.1521,  -8.4015],\n",
      "        [  1.7766, -12.5670, -16.7224, -14.3573,  -7.6238,   0.2566],\n",
      "        [-11.0028, -10.1289,   2.0639, -10.5863,   4.6669,  -7.2053],\n",
      "        [ -1.5416,   1.7865,  -7.2469,  -8.1399,  -7.3862,  -0.4286],\n",
      "        [-13.9983,  -5.6030,  -9.5756,  -6.6816,  17.6211, -14.1630],\n",
      "        [ -9.9381, -31.2610, -27.5779, -28.4161, -21.1251,   6.4526],\n",
      "        [ -7.4455,  14.0801,  -6.2433, -11.9795, -11.6839,  -5.0297],\n",
      "        [  1.5820, -19.1840,  -1.3893,  -7.1876, -15.9287,  -6.0398],\n",
      "        [ -5.3612, -17.4623,  -2.6307,  17.4051, -13.7839, -25.8288],\n",
      "        [ -8.1652,   5.0437,  -3.0386,  -5.6845,  -3.8838,  -3.5644],\n",
      "        [ -5.4615, -11.4161,  -5.7211,   0.6589,  -1.6561,  -8.7041],\n",
      "        [  7.6840, -15.6073, -11.6620,  -2.4816, -16.3787, -13.6297],\n",
      "        [-13.4649, -10.7597,   1.7112,  -7.7791,   8.5847,  -8.4968],\n",
      "        [ -7.2553,  -4.8868,  -4.8010,   0.2878,  -0.2870,  -5.1723],\n",
      "        [ -9.9877, -21.1472,  -6.7349,  -6.0758,  12.6777, -11.1276],\n",
      "        [  8.9244, -26.1425, -13.8524, -18.6480, -16.6753,  -4.9077],\n",
      "        [ -5.3410,  14.3450,  -9.4159, -15.7723, -18.4542,  -3.9914],\n",
      "        [ -2.9571, -19.7774,   0.4843,   7.4836, -14.5156, -17.8254],\n",
      "        [ -8.8291, -16.9998,   2.1374,  11.8370, -20.9592, -15.4127],\n",
      "        [ -2.9723, -13.2537,  -4.0534,   0.9683, -11.2556, -13.9839],\n",
      "        [  5.9375, -16.8692, -13.6304, -13.6149, -15.4299,  -5.8600],\n",
      "        [ -4.9471, -20.6621,   2.2092,   3.7779, -12.7023, -12.6889],\n",
      "        [ -1.7422, -20.4272,  -3.9318,   9.0619, -12.6008, -19.5037],\n",
      "        [ -3.2582, -11.7682,  -1.4279,   1.4128,  -5.9508, -12.7945]],\n",
      "       device='cuda:0')\n",
      "tensor([1, 2, 3, 2, 4, 3, 4, 3, 2, 0, 4, 1, 4, 5, 1, 0, 3, 1, 3, 0, 4, 3, 4, 0,\n",
      "        1, 3, 3, 3, 0, 3, 3, 3], device='cuda:0')\n",
      "tensor([[-8.5634e+00, -1.4852e+01, -2.4264e+00, -1.0451e+01,  1.1303e+01,\n",
      "         -9.8499e+00],\n",
      "        [-6.1713e-01, -1.9248e+01, -8.3408e+00, -3.8264e+00, -2.2474e+00,\n",
      "         -7.3473e+00],\n",
      "        [ 8.8999e+00, -5.3672e+00, -2.0319e+01, -2.3329e+01, -1.9755e+01,\n",
      "          3.8282e-01],\n",
      "        [-8.2327e+00, -1.9343e+01, -6.1643e+00, -4.4624e+00,  6.9714e+00,\n",
      "         -9.3928e+00],\n",
      "        [-9.9766e-01,  7.4906e+00, -8.1684e+00, -1.4640e+01, -1.5428e+01,\n",
      "         -1.1063e+01],\n",
      "        [-1.3265e+01, -2.6212e+01,  1.2915e+01,  2.0317e+00, -1.5278e+01,\n",
      "         -1.5016e+01],\n",
      "        [-9.1569e+00, -9.8053e+00, -1.4038e+00, -1.1237e+01,  8.1291e+00,\n",
      "         -6.8976e+00],\n",
      "        [-5.3688e+00,  1.6903e+01, -1.0237e+01, -1.7703e+01, -1.8410e+01,\n",
      "         -4.2316e+00],\n",
      "        [-7.8125e+00,  1.5814e+01, -6.0188e+00, -2.0432e+01, -2.2958e+01,\n",
      "         -2.8512e+00],\n",
      "        [-4.0812e+00, -1.7651e+01, -5.4589e+00, -1.1131e+01,  9.3484e+00,\n",
      "         -1.0728e+01],\n",
      "        [-1.0237e+01, -1.5306e+01, -5.1079e-01, -9.4621e+00,  7.6646e+00,\n",
      "         -1.4016e+01],\n",
      "        [-3.5495e+00, -3.2000e+01,  5.5868e+00, -2.9054e+00, -1.2710e+01,\n",
      "         -1.2787e+01],\n",
      "        [-5.5747e-01, -1.7612e+01, -3.7506e+00,  7.5566e+00, -1.0538e+01,\n",
      "         -1.6138e+01],\n",
      "        [-4.8047e+00, -1.3606e+01, -7.3097e+00, -9.2079e+00,  6.3740e+00,\n",
      "         -5.1636e+00],\n",
      "        [-6.9651e+00, -1.0954e+01, -5.5769e+00,  4.5332e+00,  1.2155e+00,\n",
      "         -1.1435e+01],\n",
      "        [-1.0727e+01, -1.8153e+01,  4.1964e+00,  1.0180e+01, -1.4772e+01,\n",
      "         -1.7640e+01],\n",
      "        [-1.2902e+00, -1.6409e+01, -1.4631e+01, -1.3717e+01, -1.4776e+01,\n",
      "          2.8069e+00],\n",
      "        [ 1.1239e+01, -2.7527e+01, -1.3252e+01, -1.9735e+01, -1.7208e+01,\n",
      "         -1.0459e+01],\n",
      "        [-1.0066e+01, -8.2309e+00, -3.3493e+00,  9.8483e+00, -3.0643e+00,\n",
      "         -1.5146e+01],\n",
      "        [-8.5660e+00, -1.6549e+01, -1.5336e+00,  2.2723e-01,  3.9698e-02,\n",
      "         -1.0638e+01],\n",
      "        [-1.8774e+00,  5.3926e+00, -4.2369e+00, -6.7912e+00, -1.1629e+01,\n",
      "         -5.9770e+00],\n",
      "        [ 8.9415e+00, -1.3555e+01, -1.7205e+01, -1.1091e+01, -1.5424e+01,\n",
      "         -9.9994e+00],\n",
      "        [-9.2579e+00, -1.3569e+01, -9.0491e+00, -1.1146e+00,  1.2814e+01,\n",
      "         -1.1068e+01],\n",
      "        [ 1.8308e+00, -4.5452e+00, -2.1782e+00, -1.1556e+01, -1.2771e+01,\n",
      "         -4.0308e+00],\n",
      "        [ 1.0581e+01, -2.1927e+01, -1.5959e+00, -6.4552e+00, -1.8730e+01,\n",
      "         -1.2680e+01],\n",
      "        [ 8.4999e-02, -1.7703e+01, -1.2589e+01, -1.2679e+01, -1.2052e+01,\n",
      "          3.8875e-01],\n",
      "        [-5.8191e+00,  5.6467e+00, -8.0607e+00, -9.4931e+00, -1.2934e+01,\n",
      "         -3.1671e+00],\n",
      "        [ 1.5460e+01, -2.1881e+01, -2.0761e+01, -2.3776e+01, -1.1088e+01,\n",
      "         -6.9986e+00],\n",
      "        [-5.4820e+00, -1.8241e+01, -5.0621e+00, -1.5405e+01, -1.5327e+01,\n",
      "          3.5191e+00],\n",
      "        [-4.6474e+00, -2.6103e+00, -1.5360e+01, -2.0328e+01, -1.0004e+01,\n",
      "          4.1164e+00],\n",
      "        [-6.5758e-03, -1.2107e+01, -1.6896e+01, -1.2580e+01, -1.1556e+01,\n",
      "          6.1646e-01],\n",
      "        [-4.1797e+00, -5.1286e+00, -1.5394e+01, -6.8203e+00, -9.1232e+00,\n",
      "         -7.9451e-01]], device='cuda:0')\n",
      "tensor([4, 0, 0, 4, 1, 2, 4, 1, 1, 4, 4, 2, 3, 4, 3, 3, 5, 0, 3, 3, 1, 0, 4, 0,\n",
      "        0, 5, 1, 0, 5, 5, 5, 5], device='cuda:0')\n",
      "tensor([[ 12.3851, -37.6127, -20.9119, -17.5270,  -7.5315,  -2.6218],\n",
      "        [ -2.8609,  11.4538,  -5.4942, -13.8543, -15.9490,  -3.8630],\n",
      "        [ -8.3064, -17.1440,   0.2392, -14.7945,  11.6906,  -6.1958],\n",
      "        [ -5.3838, -11.3941,  -5.3558,   1.0424,   3.9668, -11.1471],\n",
      "        [ -3.0213,  14.4861,  -6.5626, -16.6936, -23.7397,  -7.1618],\n",
      "        [ -1.3210,  10.7693,  -8.9117, -14.8797, -16.3978,  -4.5218],\n",
      "        [ -7.6254, -14.5797, -28.0910, -16.9192, -19.5694,   3.2583],\n",
      "        [ -1.0315, -19.3326, -14.2826, -22.8918,  -9.6169,   4.6067],\n",
      "        [ -3.6962, -23.3374, -15.4319, -25.1478, -10.9810,  10.9722],\n",
      "        [  1.7113, -16.6511, -15.1343, -16.7428,  -9.0950,   1.7414],\n",
      "        [ -3.3373, -27.1455, -15.2721, -18.5916,  -6.6749,   6.0308],\n",
      "        [ -2.7559, -35.5102,   8.1911,  -3.2601, -10.3447, -14.3327],\n",
      "        [  7.0845, -16.3618, -15.4434,  -8.8078, -12.0201,  -4.4617],\n",
      "        [  1.2753,   9.2772, -15.9928, -23.2783, -25.0752,   3.2530],\n",
      "        [ -7.5420, -12.3709,   1.4169,   5.3663, -16.8630, -12.1415],\n",
      "        [ -5.2098,  -9.1553,  -0.6778, -10.6432, -10.6715,  -4.1518],\n",
      "        [  2.1996,  -4.7828, -12.8503, -11.3826, -12.6193,   0.4139],\n",
      "        [ -7.0504,  -8.2676,  -7.2194,   2.3176,   7.0576,  -8.4219],\n",
      "        [ 15.4242, -38.8038, -25.0391, -17.5536,  -3.3203, -12.7528],\n",
      "        [-11.0532, -13.1008,   1.7123, -25.8272,  11.0260,  -6.9154],\n",
      "        [ -1.9769, -29.8405, -24.4648, -27.9749, -27.4172,  12.6353],\n",
      "        [ -7.1377, -21.2026, -24.3514, -22.8270, -22.7776,   7.6942],\n",
      "        [ -4.6986, -18.2799, -17.8779, -21.3433, -12.2611,   6.4255],\n",
      "        [ -8.7184,  -8.7928,   3.5190,  -1.1785,  -5.0994,  -7.8856],\n",
      "        [ -3.5544,   7.1506, -11.5120,  -5.4352,  -8.7712,  -4.0697],\n",
      "        [ -9.1475,  -9.4077,  -8.1260,   6.2797,  -1.6085,  -9.1157],\n",
      "        [ 11.6410, -22.8846, -13.4784, -11.9308, -19.1322, -12.8102],\n",
      "        [ -0.2808,   9.5003,  -7.0171, -15.2154, -15.0764,  -4.7050],\n",
      "        [ -9.3782, -17.9972,   0.7162,  11.1034, -13.0787, -14.7057],\n",
      "        [  3.6639, -11.8083,  -4.9265,  -7.0085, -11.2792,  -7.8196],\n",
      "        [ -4.8184, -12.7861,  -2.3897, -10.6094,  10.6525,  -9.7685],\n",
      "        [ -3.5175,   6.8415,  -2.5085,  -9.1767,  -7.1805,  -8.2782]],\n",
      "       device='cuda:0')\n",
      "tensor([0, 1, 4, 4, 1, 1, 5, 5, 5, 5, 5, 2, 0, 1, 3, 2, 0, 4, 0, 4, 5, 5, 5, 2,\n",
      "        1, 3, 0, 1, 3, 0, 4, 1], device='cuda:0')\n",
      "tensor([[ -6.0827,  -9.4438,  -3.1820,  -4.4012,   6.0005,  -4.7298],\n",
      "        [ -1.9576, -17.0925,  -0.9474,   3.9135, -12.6501, -16.4864],\n",
      "        [ -4.8104, -19.4006,  -5.4834, -11.2443,   7.2806, -12.8776],\n",
      "        [  6.1617, -30.0081,  -4.5062,   3.5152, -13.4631, -20.4134],\n",
      "        [ -2.5001, -21.4464,  -4.5507, -20.1138, -16.6407,  -0.4729],\n",
      "        [ 16.1421, -38.8370, -18.6268, -22.8990, -23.4014,  -5.0697],\n",
      "        [ -8.3578, -28.0931,   9.7706,   1.7114, -18.8243, -16.0733],\n",
      "        [ -1.3032,  11.8448,  -9.2018, -11.4448, -17.4511,  -7.9780],\n",
      "        [ -6.2794, -10.4974,  -2.8244,  -7.4784,   6.6090,  -8.8018],\n",
      "        [ -8.8641,  -9.8092,   5.6884,   1.8573,  -7.7729, -10.9766],\n",
      "        [-11.9779, -12.0470,  11.3212, -10.1201,  -5.8968,  -7.4398],\n",
      "        [ -7.3282,  -4.8570,  -4.9119,   7.0614,  -3.5271, -11.4438],\n",
      "        [ 12.6489, -20.7079, -23.0770, -20.1294,  -9.6268,  -6.4258],\n",
      "        [  1.6509, -20.5274, -21.4571, -11.6066,  -4.5220,  -2.2556],\n",
      "        [ -7.6910,   0.6058,  -1.1967,  -0.2595, -10.1429,  -9.0684],\n",
      "        [-11.8591, -18.2003,  -3.5136, -12.5545,  18.2618, -10.4007],\n",
      "        [  1.8369, -15.0271, -13.1880, -12.8979, -21.0105,  -0.6973],\n",
      "        [ -0.2559, -33.6593,   2.3082,   3.7559, -13.4303, -14.1850],\n",
      "        [ -9.1280,  -7.4714,  -2.8165,   3.9928,  -0.6816,  -9.8167],\n",
      "        [-11.6886, -16.0641, -13.3058,  -4.9082,  12.6519,  -7.7109],\n",
      "        [  0.9856, -17.5679, -15.7841, -19.1326,  -7.8055,   2.4526],\n",
      "        [ 12.6780, -36.9147, -15.9838, -19.7575, -16.4620,  -6.2974],\n",
      "        [  4.4766, -31.8366, -19.8106, -27.0716, -14.0607,   9.4421],\n",
      "        [  0.6708, -22.2398, -10.5902,  -6.7043,   0.3925,  -8.6786],\n",
      "        [ -5.5761,   8.8417,  -7.8250, -15.3295, -17.5934,  -5.7816],\n",
      "        [-12.2617, -24.3647,  14.3023, -14.0795, -12.3516, -12.2672],\n",
      "        [ -8.8159, -13.0152,  -3.6417,   2.1559,  -7.3003,  -4.3351],\n",
      "        [ -5.5028, -19.6146,   1.3644,   9.5799, -15.3110, -18.5583],\n",
      "        [ 14.9878, -39.3439, -12.6377, -13.3505, -17.8695, -10.8975],\n",
      "        [ -9.7340, -16.3931,  -3.8267,   1.9420,  -0.9873, -11.2663],\n",
      "        [-13.4938, -14.5843,  -1.7897, -15.1532,  18.0280, -11.7046],\n",
      "        [ 11.6196, -37.9169, -18.1975, -12.5450, -24.0480,  -5.3509]],\n",
      "       device='cuda:0')\n",
      "tensor([4, 3, 4, 0, 5, 0, 2, 1, 4, 2, 2, 3, 0, 0, 1, 4, 0, 3, 3, 4, 5, 0, 5, 0,\n",
      "        1, 2, 3, 3, 0, 3, 4, 0], device='cuda:0')\n",
      "tensor([[ 6.2198e+00, -2.5064e+01, -7.8377e+00, -1.4379e+01, -6.1242e+00,\n",
      "         -1.2616e+01],\n",
      "        [-1.3388e+01, -1.2478e+01,  5.3750e+00, -1.3134e+01,  8.2431e+00,\n",
      "         -1.0531e+01],\n",
      "        [-3.1833e+00, -1.3395e+01, -9.2822e+00, -1.5301e+01, -1.5427e+01,\n",
      "          3.5778e+00],\n",
      "        [-1.0327e+01, -6.7698e+00, -1.3127e+00, -2.5031e+00,  6.6654e+00,\n",
      "         -1.0054e+01],\n",
      "        [-5.2039e+00, -2.5704e+01, -1.1333e+01, -2.4846e+01, -1.6955e+01,\n",
      "          1.0520e+01],\n",
      "        [-4.1683e+00,  5.2369e+00, -9.6398e+00, -1.2719e+01, -1.7612e+01,\n",
      "          2.2711e-02],\n",
      "        [-1.6649e+00, -2.4522e+01, -2.0966e+01, -2.8631e+01, -2.1461e+01,\n",
      "          4.9489e+00],\n",
      "        [-6.1429e+00, -6.6834e+00, -6.7144e+00,  7.1892e+00, -3.0300e+00,\n",
      "         -1.5282e+01],\n",
      "        [-5.7807e+00, -1.1999e+01, -1.3224e-01, -2.1176e-02, -7.5552e+00,\n",
      "         -1.3063e+01],\n",
      "        [-4.0605e+00, -1.7140e+01, -1.3992e+01, -2.1714e+01, -1.9919e+01,\n",
      "          4.6927e+00],\n",
      "        [-2.2051e+00, -1.3094e+01, -1.0863e+01, -1.7073e+01, -6.3506e+00,\n",
      "          1.2148e+00],\n",
      "        [ 3.8037e+00, -1.8875e+01, -1.5510e+01, -2.3350e+01, -1.6348e+01,\n",
      "         -1.2598e+00],\n",
      "        [-1.1471e+01, -2.0901e+01,  4.0591e+00, -5.0975e+00, -5.4197e+00,\n",
      "         -4.1060e+00],\n",
      "        [ 1.0909e+01, -2.1046e+01, -1.7503e+01, -1.7351e+01, -1.9090e+01,\n",
      "         -5.8932e+00],\n",
      "        [-1.1605e+01, -1.4265e+01,  4.0569e+00, -9.9253e+00,  4.5824e-01,\n",
      "         -7.2495e+00],\n",
      "        [-6.0948e+00, -1.5429e+01, -4.2844e+00, -1.4849e-01, -2.3482e+00,\n",
      "         -9.0414e+00],\n",
      "        [ 2.4730e+00, -2.1954e+01, -4.5593e+00, -8.9545e+00, -2.7906e+01,\n",
      "         -6.7341e+00],\n",
      "        [ 1.1128e+00, -2.6735e+01, -1.7132e+01, -2.2085e+01, -1.2499e+01,\n",
      "          5.4052e+00],\n",
      "        [-8.3205e+00, -1.2116e+01,  3.6661e+00, -3.4769e+00,  2.4315e-01,\n",
      "         -6.5834e+00],\n",
      "        [-8.4170e+00, -2.1781e+01,  5.8768e+00, -7.8129e+00, -5.4406e+00,\n",
      "         -7.5865e+00],\n",
      "        [-1.0607e+01, -1.1831e+01,  3.4685e+00,  3.3199e+00, -8.0436e+00,\n",
      "         -9.3031e+00],\n",
      "        [-1.0573e+01, -1.1747e+01,  2.1950e+00, -1.8317e+01,  1.2224e+01,\n",
      "         -8.7187e+00],\n",
      "        [-2.7891e+00,  5.2625e+00, -3.9756e+00, -4.7107e+00, -1.5755e+01,\n",
      "         -1.0007e+01],\n",
      "        [-1.2982e+01, -2.3825e+01,  1.3886e+01, -4.5713e+00, -1.1452e+01,\n",
      "         -9.1518e+00],\n",
      "        [ 2.2288e+01, -2.5146e+01, -1.7595e+01, -2.4655e+01, -2.2318e+01,\n",
      "         -1.0109e+01],\n",
      "        [ 3.8682e+00, -3.7370e+01, -1.8491e+01, -2.7732e+01, -2.1706e+01,\n",
      "          1.0015e+01],\n",
      "        [-1.2788e+01, -2.9001e+01,  1.5627e+01, -9.4848e+00, -7.7046e+00,\n",
      "         -1.4959e+01],\n",
      "        [ 5.7455e+00, -1.6948e+01, -1.5361e+01, -1.5670e+01, -1.2551e+01,\n",
      "         -4.1735e+00],\n",
      "        [-1.1841e+01, -2.0742e+01,  7.7269e+00, -4.2265e+00, -6.5944e+00,\n",
      "         -9.1477e+00],\n",
      "        [-2.4888e+00, -2.2310e+01, -1.8605e+01, -2.4051e+01, -1.8617e+01,\n",
      "          6.7314e+00],\n",
      "        [-5.9322e+00,  1.3846e+01, -4.7437e+00, -1.4598e+01, -2.2747e+01,\n",
      "         -7.1218e+00],\n",
      "        [-7.9149e-01, -2.3789e+01, -1.2015e+01, -2.3329e+01, -1.1862e+01,\n",
      "          5.0568e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 4, 5, 4, 5, 1, 5, 3, 3, 5, 5, 0, 2, 0, 2, 3, 0, 5, 2, 2, 2, 4, 1, 2,\n",
      "        0, 5, 2, 0, 2, 5, 1, 5], device='cuda:0')\n",
      "tensor([[ 1.3138e+01, -3.7051e+01, -1.9906e+01, -2.4754e+01, -4.2871e+00,\n",
      "         -6.1446e+00],\n",
      "        [ 1.3649e+01, -3.0035e+01, -2.2733e+01, -1.7538e+01, -7.6300e+00,\n",
      "         -7.8220e+00],\n",
      "        [-9.6418e+00, -3.1719e+01,  1.3080e+01,  2.8431e+00, -1.6012e+01,\n",
      "         -1.4886e+01],\n",
      "        [ 6.0011e+00, -1.9158e+01, -1.4377e+01, -6.2914e+00, -9.3949e+00,\n",
      "         -9.2527e+00],\n",
      "        [-7.0630e+00, -2.3448e+00, -3.6614e+00,  6.8725e+00, -2.8910e+00,\n",
      "         -1.3172e+01],\n",
      "        [-9.5356e+00, -1.2754e+01,  5.3477e+00, -9.9637e-01, -9.3875e+00,\n",
      "         -1.3491e+01],\n",
      "        [ 2.2022e+01, -3.8569e+01, -3.1213e+01, -2.9651e+01, -1.8128e+01,\n",
      "         -3.2456e+00],\n",
      "        [-5.6823e+00, -2.0873e+01, -6.0178e+00,  1.4895e+01, -1.2402e+01,\n",
      "         -2.4919e+01],\n",
      "        [-4.2324e+00,  9.0460e+00, -1.3641e+01, -5.6367e+00, -1.7766e+01,\n",
      "         -8.2430e+00],\n",
      "        [-2.8463e+00, -1.8940e+01, -1.1495e+01, -8.4661e+00,  9.5959e+00,\n",
      "         -8.7246e+00],\n",
      "        [-8.8339e+00, -3.1289e+01,  1.3773e+01, -8.3300e+00, -6.0569e+00,\n",
      "         -1.6362e+01],\n",
      "        [-3.6536e+00, -2.0072e+01, -7.3186e+00, -4.4283e+00,  3.4728e-01,\n",
      "         -8.3312e+00],\n",
      "        [-2.6177e+00, -1.7888e+01, -2.8165e+00,  3.2568e+00, -1.3548e+01,\n",
      "         -1.3558e+01],\n",
      "        [-1.0931e+01, -1.2051e+01, -2.3615e-02,  8.4532e+00, -8.1050e+00,\n",
      "         -1.3134e+01],\n",
      "        [-9.6937e+00, -1.8734e+01,  1.2613e+00, -5.1839e+00,  4.1990e+00,\n",
      "         -1.0216e+01],\n",
      "        [ 8.5494e+00, -2.1138e+01, -1.3614e+01, -1.0349e+01, -1.6145e+01,\n",
      "         -9.6285e+00],\n",
      "        [-4.9079e+00, -8.9327e+00, -5.0133e+00, -1.7617e+01, -1.4035e+01,\n",
      "          1.1870e+00],\n",
      "        [-5.3955e+00, -2.5542e+01, -1.6283e+01, -8.1118e+00,  1.8775e+01,\n",
      "         -9.4154e+00],\n",
      "        [ 1.7076e+00, -6.3284e+00, -1.2879e+01, -8.7370e+00, -4.7151e+00,\n",
      "         -2.7608e+00],\n",
      "        [ 4.8689e+00, -3.2468e+00, -1.5194e+01, -2.0028e+01, -1.8151e+01,\n",
      "          1.4194e+00],\n",
      "        [-7.8662e+00, -1.1194e+01, -8.1923e+00,  4.1330e+00,  7.0463e+00,\n",
      "         -1.2714e+01],\n",
      "        [ 4.8550e+00, -2.2866e+01, -9.6274e+00, -7.7044e+00,  1.9964e+00,\n",
      "         -1.9538e+01],\n",
      "        [-1.1983e+01, -2.5745e+01,  1.4884e+01, -4.9198e+00, -9.2699e+00,\n",
      "         -1.4591e+01],\n",
      "        [ 1.1033e+01, -2.0944e+01, -2.2957e+01, -2.4790e+01, -1.7621e+01,\n",
      "         -4.1083e-01],\n",
      "        [-1.6909e+00, -6.2809e+00, -7.6676e+00, -8.1299e+00, -1.4352e+01,\n",
      "         -1.6205e+00],\n",
      "        [-1.1941e+01, -1.4605e+01,  5.3079e+00, -7.2617e+00,  2.5946e+00,\n",
      "         -1.0939e+01],\n",
      "        [-7.4980e+00, -1.0785e+01, -5.4996e+00, -2.5668e+00,  9.0161e+00,\n",
      "         -9.5234e+00],\n",
      "        [-1.0848e+01, -1.9467e+01,  7.5720e+00, -1.0307e+01, -7.9488e+00,\n",
      "         -3.9380e+00],\n",
      "        [-1.3654e+01, -1.3124e+01,  2.9245e+00, -1.1453e+01,  9.9278e+00,\n",
      "         -1.1173e+01],\n",
      "        [ 1.6614e+01, -3.1650e+01, -1.9472e+01, -1.1420e+01, -1.4757e+01,\n",
      "         -1.3762e+01],\n",
      "        [ 3.7243e+00, -2.2849e+01, -2.0546e+01, -1.7174e+01, -1.4354e+01,\n",
      "          5.8576e+00],\n",
      "        [-8.9028e+00, -1.4235e+01, -1.3116e+00, -1.0417e+01,  8.6482e+00,\n",
      "         -1.1897e+01]], device='cuda:0')\n",
      "tensor([0, 0, 2, 0, 3, 2, 0, 3, 1, 4, 2, 4, 3, 3, 4, 0, 5, 4, 0, 0, 4, 0, 2, 0,\n",
      "        5, 2, 4, 2, 4, 0, 5, 4], device='cuda:0')\n",
      "tensor([[ -6.1010, -16.0274,   1.8427,   6.4266, -12.5535, -12.8416],\n",
      "        [ -3.6199, -15.1616,  -6.5162,  -8.8989,  11.0450, -16.1294],\n",
      "        [  0.5221, -14.3504,  -6.4596,  10.4555,  -6.7978, -18.5962],\n",
      "        [ -4.7440,  13.6731,  -5.4597, -15.6297, -19.3857,  -6.4328],\n",
      "        [ -3.1892,  16.1066,  -7.2811, -20.4914, -23.5933,  -5.6124],\n",
      "        [  4.9591,  11.0141, -14.7251, -20.9976, -21.6545,  -7.4010],\n",
      "        [-14.0026, -15.7287,  12.8751, -13.1463,  -5.3748,  -5.9695],\n",
      "        [ -7.7000,  14.7648,  -6.7717,  -8.9716, -12.2241,  -6.1340],\n",
      "        [  1.0780, -25.1121, -18.2659, -24.1030, -13.9134,   9.4573],\n",
      "        [ -5.0929, -12.6317,  -5.5341,  -8.8760, -10.8508,  -0.8758],\n",
      "        [ -7.1547,   0.8766, -13.5090, -13.0855, -11.5937,   5.2328],\n",
      "        [ -7.5417, -10.1551,  -2.7826,   3.8793,  -0.8351,  -9.7896],\n",
      "        [ -4.6544,  -4.0609,  -0.2995,  -3.6976, -12.0525,  -8.6463],\n",
      "        [ -0.5170, -16.7039,  -3.2599, -18.4659, -12.5306,  -4.0902],\n",
      "        [  4.9883, -29.6878, -19.6173, -16.0197, -14.4254,   0.5133],\n",
      "        [  3.5690, -30.4371,  -8.4185, -11.0867, -10.0491,  -4.6278],\n",
      "        [-10.6474, -17.1931,   4.9945,  10.5681, -20.8487, -13.4412],\n",
      "        [ -9.2713, -10.7781,   3.2820,  -1.2858,  -1.0822,  -8.0968],\n",
      "        [ -7.0326, -28.7056,   6.2748,   8.0636, -15.4613, -18.1759],\n",
      "        [-10.3337, -19.9699,   6.7922,   6.3121, -13.0318, -13.5087],\n",
      "        [-10.1655, -17.6546,   4.7058,   2.9237, -11.1765,  -6.4274],\n",
      "        [-10.8455, -36.6448,  24.9574, -16.1700, -19.6309, -15.2770],\n",
      "        [ -8.6946, -18.6991,  -4.5031, -22.6168,  16.3840, -10.5975],\n",
      "        [ -9.1741, -14.1014,  -7.2067, -11.8586,  18.9253, -10.8325],\n",
      "        [  4.0994, -13.0077, -17.6423, -18.9772, -15.3090,   4.6317],\n",
      "        [-15.6868, -17.6014,  11.4369, -10.5201,   1.4612,  -9.2546],\n",
      "        [ -7.5294, -16.1505,  -2.1042, -13.1562,  12.7026, -10.9696],\n",
      "        [ -9.1178, -15.8995,   1.2698,  -6.1939,   0.8811,  -9.0341],\n",
      "        [-11.5836, -16.8061,  -1.0012,   8.3755,  -8.6205, -11.6822],\n",
      "        [ -5.1714,  -9.7047,  -2.2632,   7.0177,  -3.5943, -13.9849],\n",
      "        [ 14.8888, -24.7223, -27.7691, -27.1843, -24.8158,   0.3372],\n",
      "        [ 11.6130, -15.6258, -17.2785, -20.1011, -17.8263,  -5.7114]],\n",
      "       device='cuda:0')\n",
      "tensor([3, 4, 3, 1, 1, 1, 2, 1, 5, 5, 5, 3, 2, 0, 0, 0, 3, 2, 3, 2, 2, 2, 4, 4,\n",
      "        5, 2, 4, 2, 3, 3, 0, 0], device='cuda:0')\n",
      "tensor([[ -7.4327, -21.8373,   9.8867,  -0.8959, -12.3970, -14.8088],\n",
      "        [-22.7554, -44.0400, -28.1582, -32.2841, -36.1075,   6.1991],\n",
      "        [ -5.7788,   8.6517,   1.1784,  -6.4023,  -3.8247, -12.5803],\n",
      "        [ -8.4224, -14.4643,  -1.0489,  -6.8679,   6.1214,  -9.5354],\n",
      "        [-13.0472,  -9.8132,   9.2045, -12.0972,  -0.4939, -10.8518],\n",
      "        [  4.9458, -25.7413, -14.1222, -18.0098, -11.2960,  -2.0979],\n",
      "        [-10.3206, -20.0199,   2.7478,  10.5849, -11.7883, -14.6156],\n",
      "        [-13.2514, -24.1623,  12.1433,  -2.3156,  -9.9847, -12.0925],\n",
      "        [ -6.8037,   8.1621,  -1.3258,  -7.3543,  -4.9447,  -7.1843],\n",
      "        [ -7.0894, -14.5598,  -4.4931, -10.7327,   4.4338,  -7.2208],\n",
      "        [  2.9925, -26.4388,  -8.9715, -15.2171, -14.1542,  -3.9974],\n",
      "        [ -6.9476,  -1.8666,  -6.6452,   8.6316,  -2.4213,  -9.6126],\n",
      "        [-12.7091, -18.9208,  13.5880,  -0.8526, -14.3188, -14.0186],\n",
      "        [ -3.3399,   8.9033,  -5.1383, -14.9763, -18.1783,  -4.1447],\n",
      "        [  0.3641,  -8.9703, -13.8781, -28.3748, -22.1622,   5.8174],\n",
      "        [ -4.3147, -41.0086, -15.1106, -24.5465, -21.6728,  10.1724],\n",
      "        [ -8.6840, -36.3836,   9.0200,  -0.7588, -11.9473, -12.8558],\n",
      "        [-12.9153, -13.0650,   9.6739, -11.1420,  -2.1722, -10.9337],\n",
      "        [-12.3409, -26.4820,  14.9566, -12.7074,  -3.3101, -14.6881],\n",
      "        [ -0.8744, -21.5133, -24.7853, -21.1501, -14.5716,  -0.3665],\n",
      "        [ -9.9374, -19.4720,   4.9113,  12.3909, -18.5317, -18.5290],\n",
      "        [ -8.6726,  -8.4988,  -0.3661,   2.4778,   1.0821, -11.9512],\n",
      "        [  6.1525, -41.5318, -23.0084, -26.7901, -20.1876,   8.1477],\n",
      "        [ -9.3212, -12.3019,   4.3429,  -2.8851,  -4.5047,  -9.6494],\n",
      "        [-10.6477, -12.5431,   2.3048, -12.7271,   9.1303,  -7.1362],\n",
      "        [  4.9254, -53.8396, -30.7372, -28.0910, -21.1988,  11.1860],\n",
      "        [  6.3907, -22.8455,  -9.6696,   7.9225, -10.4274, -20.8814],\n",
      "        [ -8.1423,  -4.6019,  -2.5422,   6.5980,  -1.6798, -12.3590],\n",
      "        [ -5.2795,  13.8198, -14.2749, -11.6856, -19.3855,  -1.1680],\n",
      "        [ -5.1843, -24.3694,   5.6795,  -2.1906, -10.3770, -15.2660],\n",
      "        [-13.3011, -22.7102, -30.6424, -37.3748, -29.4624,   0.8774],\n",
      "        [-14.1953, -14.4570, -11.1077,  -8.4921, -15.3421,   7.0457]],\n",
      "       device='cuda:0')\n",
      "tensor([2, 5, 1, 4, 2, 0, 3, 2, 1, 4, 0, 3, 2, 1, 5, 5, 2, 2, 2, 5, 3, 3, 5, 2,\n",
      "        4, 5, 3, 3, 1, 2, 5, 5], device='cuda:0')\n",
      "tensor([[-1.1941e+01, -2.1202e+01,  8.8913e+00, -7.1680e+00, -6.3909e+00,\n",
      "         -1.4338e+01],\n",
      "        [-1.3612e+01, -2.1721e+01,  8.9602e+00,  1.3000e+00, -1.0766e+01,\n",
      "         -1.0139e+01],\n",
      "        [-5.0049e+00,  1.0535e+01, -7.7502e+00, -1.2958e+01, -1.4943e+01,\n",
      "         -4.5520e+00],\n",
      "        [-5.6648e+00, -1.3314e+01,  2.8975e-02,  8.3734e+00, -8.8452e+00,\n",
      "         -1.2812e+01],\n",
      "        [ 9.2008e+00, -2.4276e+01, -1.0139e+01, -1.0580e+01, -1.3632e+01,\n",
      "         -1.0724e+01],\n",
      "        [-7.1762e+00, -7.3785e+00, -9.4907e-01, -5.2556e+00,  7.9812e+00,\n",
      "         -5.7463e+00],\n",
      "        [-8.5142e+00, -9.7675e+00, -6.1220e+00, -1.7610e+00,  9.5547e+00,\n",
      "         -8.1619e+00],\n",
      "        [ 4.5192e+00, -1.9054e+01, -1.7307e+01, -1.5350e+01, -1.3308e+01,\n",
      "          8.1481e-01],\n",
      "        [-6.0877e+00, -6.6662e+00, -8.3677e+00, -6.7220e+00, -4.7170e+00,\n",
      "          1.8739e+00],\n",
      "        [-1.1138e+01, -1.0606e+01, -1.5049e+01, -3.2887e+01, -2.3563e+01,\n",
      "         -5.2169e-01],\n",
      "        [ 1.1178e+01, -4.0816e+01, -7.3019e+00, -3.0815e+00, -1.9997e+01,\n",
      "         -1.6428e+01],\n",
      "        [-4.5131e+00, -1.4137e+01, -5.7121e+00, -8.5865e+00,  9.2289e+00,\n",
      "         -8.8491e+00],\n",
      "        [-8.7934e+00, -1.8210e+01,  7.7762e-01,  2.1713e+00, -4.6734e+00,\n",
      "         -1.0613e+01],\n",
      "        [-8.0805e-01, -1.0273e+01, -7.8510e+00,  7.0783e+00, -1.6927e+01,\n",
      "         -1.6741e+01],\n",
      "        [ 1.6127e+01, -4.0662e+01, -1.8543e+01, -2.0679e+01, -8.7154e+00,\n",
      "         -9.7651e+00],\n",
      "        [-3.1678e+00, -1.6010e+01, -2.5298e+00,  1.1076e+01, -1.0389e+01,\n",
      "         -1.7555e+01],\n",
      "        [-1.6097e+01, -2.5709e+01,  1.4788e+01, -4.0745e+00, -1.1453e+01,\n",
      "         -1.8223e+01],\n",
      "        [-1.0818e+01, -1.5795e+01,  5.3233e+00, -1.3541e+01,  9.3862e+00,\n",
      "         -1.1800e+01],\n",
      "        [-6.0671e+00, -1.2516e+01, -2.6068e+00, -7.2479e+00,  7.9116e+00,\n",
      "         -1.0563e+01],\n",
      "        [ 9.5973e+00, -3.9019e+01, -1.4059e+01, -5.5271e+00, -1.8094e+01,\n",
      "         -1.2227e+01],\n",
      "        [-8.8219e+00, -2.1293e+01,  5.7341e+00,  5.3208e+00, -1.4173e+01,\n",
      "         -1.5375e+01],\n",
      "        [ 7.0853e+00, -3.0477e+01, -3.6340e+00, -6.3252e+00, -1.6220e+01,\n",
      "         -1.2700e+01],\n",
      "        [-6.0405e+00, -1.7651e+01,  4.4619e+00,  2.6044e+00, -8.9529e+00,\n",
      "         -1.3460e+01],\n",
      "        [-3.1651e+00, -2.2839e+01,  4.0284e+00,  7.4800e+00, -1.2740e+01,\n",
      "         -1.6743e+01],\n",
      "        [-7.4804e+00,  5.8129e+00, -3.8634e+00, -5.3533e+00, -3.5120e+00,\n",
      "         -7.8025e+00],\n",
      "        [-6.5067e+00, -1.8816e+01, -5.3747e+00, -4.3220e+00,  1.1206e+01,\n",
      "         -1.1964e+01],\n",
      "        [-7.1314e+00, -1.0045e+01, -2.2121e+00,  5.5390e+00, -1.4424e+00,\n",
      "         -1.4215e+01],\n",
      "        [-7.8138e+00, -1.6970e+01,  1.6705e+01, -1.4773e+01, -1.1083e+01,\n",
      "         -1.4984e+01],\n",
      "        [ 1.0968e+01, -2.9293e+01, -7.7213e+00, -8.0708e+00, -9.9269e+00,\n",
      "         -1.4121e+01],\n",
      "        [-4.4375e+00, -2.6411e+01,  6.3897e+00,  6.0306e+00, -2.3842e+01,\n",
      "         -1.6340e+01],\n",
      "        [ 8.2489e-01,  1.1030e+01, -6.7581e+00, -1.9096e+01, -1.7199e+01,\n",
      "         -8.4716e+00],\n",
      "        [-1.4263e+00, -2.3893e+01, -1.5509e+01, -2.0812e+01, -1.5797e+01,\n",
      "          6.6184e+00]], device='cuda:0')\n",
      "tensor([2, 2, 1, 3, 0, 4, 4, 0, 5, 5, 0, 4, 3, 3, 0, 3, 2, 4, 4, 0, 2, 0, 2, 3,\n",
      "        1, 4, 3, 2, 0, 2, 1, 5], device='cuda:0')\n",
      "tensor([[-10.4438, -12.6359,   4.4098,   4.0024,  -8.5938, -11.3527],\n",
      "        [-11.0642, -21.0404,   9.0013,  -0.9536,  -6.5835, -11.6737],\n",
      "        [-12.2664,  -8.7376,   7.5223,  -7.2736,  -2.6119,  -6.3713],\n",
      "        [-10.5432, -17.4405,   2.6255,   3.3286, -10.2484, -11.7653],\n",
      "        [-14.0787, -11.3896,   3.4599, -12.6377,   9.5420,  -4.9319],\n",
      "        [  4.3682, -14.2891, -21.3768, -21.9770, -17.6801,   4.0722],\n",
      "        [ 20.3856, -25.2684, -22.0845, -22.4232, -19.1895,  -9.0302],\n",
      "        [-12.0411, -19.9615,   7.1930,  -8.1601,  -0.5026, -12.6448],\n",
      "        [  7.8185, -21.7754, -15.6197, -24.2255, -20.4688,   1.9070],\n",
      "        [ -6.8603, -11.9150,  -1.5757,  -3.7932,   5.5144,  -5.6109],\n",
      "        [  2.2485, -21.9549,  -9.0864, -13.7943, -13.3496,  -0.8740],\n",
      "        [ -5.2173,   7.9090, -15.0791, -14.2469, -18.9100,  -6.8985],\n",
      "        [-14.5762, -16.7523,  11.9274, -12.9164,  -5.2695, -12.4085],\n",
      "        [-15.9118,  -9.4053,  -5.8959, -11.8506,  17.9087, -11.6178],\n",
      "        [  9.7244, -20.3273,  -9.9044, -11.8944, -11.8162, -11.4939],\n",
      "        [ -6.7707, -17.0242,  -6.6103, -10.4407,  14.5286, -10.2718],\n",
      "        [  0.2810, -18.5165, -18.7819, -14.8344, -22.6419,  -6.5208],\n",
      "        [ -8.0438, -15.4946,  -5.3418,  -6.4875,  12.8678, -11.3205],\n",
      "        [ -2.3400, -11.0970,  -3.1694,   7.9595,  -7.2170, -17.2143],\n",
      "        [ -8.7245, -17.6958,   8.2482,   2.3307, -10.3247, -13.2050],\n",
      "        [ -3.9266,  -4.8017, -10.2697,   7.0318,  -8.3834, -15.4587],\n",
      "        [ -8.7696,  -8.7229,  -6.4235,   5.8683,   6.9966, -12.2691],\n",
      "        [-11.6635,  -4.6701,  -1.2632,  -3.4126,  10.0038, -11.4314],\n",
      "        [  5.3481,  -9.9277, -14.7882,  -4.3150,  -6.6341, -10.4010],\n",
      "        [ -5.1814, -18.8731, -14.1076, -24.5142, -22.6105,  10.7483],\n",
      "        [ -7.5949, -25.1752,  12.3617, -10.5716, -13.5662,  -8.8832],\n",
      "        [-12.4963, -23.2304,   9.6623,   2.6769, -11.5420, -15.6005],\n",
      "        [ -9.2429, -17.8338,   2.9195,   1.1847, -11.7861, -11.2687],\n",
      "        [ -9.0403, -22.8526,   8.4819,   2.6901, -15.1514, -15.9816],\n",
      "        [ -6.4169, -13.5167,  -2.2928,   4.6797,  -4.9411, -11.0869],\n",
      "        [  0.1233, -23.7939, -17.7941, -16.1652, -15.4706,   8.3564],\n",
      "        [ -8.8503, -32.8533,  13.7507,  -3.1872, -12.0943, -13.6412]],\n",
      "       device='cuda:0')\n",
      "tensor([2, 2, 2, 3, 4, 0, 0, 2, 0, 4, 0, 1, 2, 4, 0, 4, 0, 4, 3, 2, 3, 4, 4, 0,\n",
      "        5, 2, 2, 2, 2, 3, 5, 2], device='cuda:0')\n",
      "tensor([[ -3.6287,  -9.4919,  -4.8210,  -8.7600,   6.8921, -10.8594],\n",
      "        [  8.0782, -33.2124,  -7.2486, -10.2627, -18.1235,  -7.7382],\n",
      "        [ -6.1772,  -9.0769,  -4.5646,   0.3273,   1.8036,  -7.5051],\n",
      "        [  1.5030, -30.4293, -15.5689, -24.4324, -13.1647,   7.9779],\n",
      "        [ -3.1872, -16.5530, -15.6270, -22.1330, -14.0172,   5.4477],\n",
      "        [ -6.1713, -10.7611,   5.0484,  -3.4914,  -6.5643,  -6.6351],\n",
      "        [  4.0328, -20.3936, -17.3882, -14.8924, -13.1048,   0.4114],\n",
      "        [  0.3320,  12.6048,  -7.4252, -17.4620, -21.4348,  -3.9492],\n",
      "        [ -6.8938,  -2.5328,  -4.7639, -16.7297,   9.3406,  -7.9956],\n",
      "        [ -6.9428, -16.0934,  -3.5916,   7.4051,  -9.3648, -16.1000],\n",
      "        [ -1.5340, -11.2286, -16.9539, -19.7171, -11.8614,   8.4945],\n",
      "        [-17.8117, -35.8065, -25.7427, -23.4645, -18.8217,  -0.0625],\n",
      "        [ -1.2391,  -9.9624, -13.7715, -19.3727, -15.0874,   3.4956],\n",
      "        [  8.0446, -26.9887, -14.0062,  -3.4676, -10.6950, -13.2488],\n",
      "        [-10.1806, -23.5572,   6.5800,   7.5720, -15.0754, -14.8041],\n",
      "        [-12.2578, -14.6243,  11.0476,  -7.3667,  -6.4294,  -7.4250],\n",
      "        [ -3.0708, -10.7536,  -8.5218,  -4.3404,  -8.1691,  -1.8982],\n",
      "        [  7.0725, -28.4026, -10.8665, -13.6580, -27.6931,  -7.0199],\n",
      "        [ -8.7145, -13.7685,   1.0245,  -3.7785,   0.0611, -10.2888],\n",
      "        [  4.1096, -13.4513, -15.4741, -14.6672, -12.6111,  -1.7403],\n",
      "        [ -5.2882, -13.5340,  -5.5042,  15.9571, -12.2303, -22.3457],\n",
      "        [-12.3258, -32.0324,  17.0966,   0.2543, -16.5043, -15.3484],\n",
      "        [ -2.7128,  11.1075,  -7.9329, -16.8535, -20.2670,  -2.0015],\n",
      "        [ -9.9815, -16.5016,  -3.5248,  -8.7051,   8.2432,  -4.7961],\n",
      "        [-10.4922, -22.6562,   8.2349,  -0.7820,  -8.0939, -11.7131],\n",
      "        [ -4.2678, -16.2249,  -4.0356,  -4.8377,   9.1442, -14.4632],\n",
      "        [ -6.5592,  -8.0955,  -2.6337,  -4.2910,   6.2274,  -6.3104],\n",
      "        [ -6.9567, -10.1724,  -6.5177,  -0.1726,   7.7698, -10.0858],\n",
      "        [ -1.1287,  10.4763,  -5.5278, -15.7839, -20.2129,  -9.9246],\n",
      "        [ -7.6220, -17.4662,   0.5720,  10.3823, -10.1246, -15.6973],\n",
      "        [  9.2629, -11.4169, -16.2561, -15.5342, -11.2012,  -4.1987],\n",
      "        [  0.2934,  16.3133,  -8.4712, -18.5409, -27.8690,  -5.3226]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 0, 4, 5, 5, 2, 0, 1, 4, 3, 5, 5, 5, 0, 3, 2, 5, 0, 2, 0, 3, 2, 1, 4,\n",
      "        2, 4, 4, 4, 1, 3, 0, 1], device='cuda:0')\n",
      "tensor([[-3.0322e+00,  1.5417e+01, -9.8777e+00, -1.9204e+01, -1.8568e+01,\n",
      "         -6.7475e+00],\n",
      "        [-1.8479e-01, -5.0587e-01, -8.9323e+00, -1.2625e+01, -1.5417e+01,\n",
      "          2.3517e+00],\n",
      "        [-5.5608e+00, -1.3082e+01, -7.4310e+00, -1.3052e-02,  4.9858e+00,\n",
      "         -1.4723e+01],\n",
      "        [-7.6104e+00, -1.2949e+01, -2.3908e+00,  9.1687e+00, -9.7965e+00,\n",
      "         -1.4517e+01],\n",
      "        [-9.1602e+00, -3.0359e+01, -2.7648e+00, -5.8159e+00, -1.4744e+01,\n",
      "          1.0788e+00],\n",
      "        [-6.1390e+00,  7.0006e+00, -4.3993e+00, -5.9863e+00, -3.3343e+00,\n",
      "         -6.9198e+00],\n",
      "        [-3.8217e+00, -1.3902e+01, -4.5425e+00,  7.2114e+00, -6.6004e+00,\n",
      "         -1.4998e+01],\n",
      "        [-5.3064e+00, -1.7963e+01, -8.5018e+00, -1.0145e+01, -1.1565e+01,\n",
      "          2.7847e+00],\n",
      "        [-8.7242e+00,  6.0342e+00, -3.4221e+00, -8.9043e+00, -9.9742e+00,\n",
      "         -6.7776e+00],\n",
      "        [-4.1824e+00, -2.1708e+01, -3.6376e-01,  1.3770e+01, -1.3067e+01,\n",
      "         -2.2927e+01],\n",
      "        [-9.3616e+00,  9.8389e+00, -3.5176e+00, -3.9371e+00, -1.5849e+01,\n",
      "         -9.8961e+00],\n",
      "        [-4.4159e+00,  5.3708e+00, -5.0750e+00, -1.1460e+01, -1.2850e+01,\n",
      "         -3.3235e+00],\n",
      "        [ 2.1841e+00, -4.3596e+00, -1.5178e+01, -7.6631e+00, -7.6349e+00,\n",
      "         -4.6895e+00],\n",
      "        [-1.2001e+01, -2.8494e+01,  1.1810e+01, -7.1924e+00, -1.0723e+01,\n",
      "         -7.3175e+00],\n",
      "        [-2.3550e+00, -1.8033e+01, -7.7270e+00, -9.1921e+00,  5.9378e+00,\n",
      "         -7.2930e+00],\n",
      "        [-5.2058e+00, -9.9698e+00, -4.2834e+00,  6.2097e+00, -2.6214e+00,\n",
      "         -1.0942e+01],\n",
      "        [-4.4402e+00,  1.0700e+01, -6.7862e+00, -1.1209e+01, -1.6837e+01,\n",
      "         -4.6991e+00],\n",
      "        [ 1.0162e+01, -2.3768e+01, -1.2752e+01, -1.9142e+01, -1.3312e+01,\n",
      "         -6.9212e+00],\n",
      "        [-1.2783e+00, -1.4099e+01, -2.2630e+01, -1.6170e+01, -1.4301e+01,\n",
      "          9.5535e+00],\n",
      "        [-1.3974e+01, -2.1904e+01,  1.2330e+01, -8.7673e+00, -2.5287e-02,\n",
      "         -1.3290e+01],\n",
      "        [-2.6080e+00, -2.1397e+01,  8.4821e-01,  1.3043e+01, -1.8278e+01,\n",
      "         -1.9362e+01],\n",
      "        [-3.6118e+00, -1.6866e+01, -7.0511e+00,  5.1753e+00, -4.9611e+00,\n",
      "         -1.6800e+01],\n",
      "        [-5.2174e+00, -9.3193e+00, -9.9997e+00, -1.3348e+01, -1.7950e+01,\n",
      "         -9.9484e-01],\n",
      "        [-1.1122e+01, -2.3865e+01,  1.8191e+01, -1.8497e+01, -9.9411e+00,\n",
      "         -1.1440e+01],\n",
      "        [-2.2403e+00,  1.4569e+01, -1.4434e+01, -1.5728e+01, -2.7829e+01,\n",
      "         -1.3217e+00],\n",
      "        [-1.1342e+01, -1.5475e+01,  9.4384e+00, -8.6319e+00, -8.6701e+00,\n",
      "         -1.0345e+01],\n",
      "        [-9.5054e+00, -1.0121e+01, -3.2393e+00, -9.7638e+00,  8.2940e+00,\n",
      "         -6.5155e+00],\n",
      "        [ 3.4325e+00, -3.6722e+01, -1.3717e+01, -1.7332e+01,  1.2321e+01,\n",
      "         -1.1794e+01],\n",
      "        [-6.7194e+00,  1.6343e+01, -1.0509e+01, -1.7597e+01, -2.0976e+01,\n",
      "         -2.8398e+00],\n",
      "        [-6.4134e+00, -1.5832e+01, -1.9937e+00,  1.0765e+01, -1.0432e+01,\n",
      "         -1.4787e+01],\n",
      "        [-6.4421e+00,  1.8447e-01, -6.2504e+00,  1.3122e+00, -1.1146e+00,\n",
      "         -7.5036e+00],\n",
      "        [-4.4003e-01, -2.1029e+01, -2.5432e-01,  9.9215e+00, -1.9502e+01,\n",
      "         -1.9921e+01]], device='cuda:0')\n",
      "tensor([1, 5, 4, 3, 5, 1, 3, 5, 1, 3, 1, 1, 0, 2, 4, 3, 1, 0, 5, 2, 3, 3, 5, 2,\n",
      "        1, 2, 4, 4, 1, 3, 3, 3], device='cuda:0')\n",
      "tensor([[ 11.3513, -25.8070, -10.2222,  -8.3916, -15.5244, -13.6836],\n",
      "        [-10.0795, -18.2612,   0.7163,  -5.1854,   8.9656, -12.4543],\n",
      "        [-10.0836, -22.6943,  12.6966,  -6.9276, -11.7489, -13.1648],\n",
      "        [ 10.9250, -27.8860, -16.7534, -19.5727, -20.7930,  -4.2249],\n",
      "        [  4.6551, -12.0925, -12.1476,  -4.2433,  -6.8499,  -9.8797],\n",
      "        [ -7.0309,  -7.3551, -11.8102, -27.0513, -10.9805,   8.7647],\n",
      "        [-12.6707,  -8.0650,  13.9880, -16.9582,  -6.3742, -11.3268],\n",
      "        [ -8.2977, -17.5385, -16.6517, -23.2732, -17.0907,  11.6926],\n",
      "        [ -6.0569,  12.5758,  -8.5245,  -9.4089, -15.1472,  -5.0233],\n",
      "        [  5.6832, -16.1181, -10.8413, -20.0250,  -3.4686,  -5.2155],\n",
      "        [ -4.5242,   6.5036,  -7.5034,  -6.6083,  -8.5527,  -6.1839],\n",
      "        [ -6.5237, -11.8337,  -7.3103,  10.0427,   0.8719, -17.7238],\n",
      "        [ -2.6840, -25.2120,  -7.4439, -12.0572, -11.2744,   2.5091],\n",
      "        [-14.5549, -13.1227,  13.6340,  -7.7236,  -9.7392, -11.9650],\n",
      "        [ -3.8945,  11.5950,  -4.8830,  -9.9633, -13.3047,  -7.5832],\n",
      "        [ -7.7347, -17.3165, -12.8300,  -9.4196,  12.8417,  -7.2483],\n",
      "        [  4.8766, -22.1026,  -8.3521, -14.5214, -14.8013,  -7.0557],\n",
      "        [-19.0592, -27.9942, -38.9546, -19.9124, -13.9975,  -1.4081],\n",
      "        [-10.8437, -17.0917,  12.0703,  -6.0527, -14.6923,  -9.3253],\n",
      "        [ -1.7666,  11.4120, -11.5222, -17.5669, -21.5234,  -2.1237],\n",
      "        [ -0.4554, -19.1661,  -4.9879,  11.3673, -10.5686, -17.3675],\n",
      "        [-14.6273, -13.7914,   0.4723,  -1.2107,   3.8506, -10.6750],\n",
      "        [-10.1034, -22.2945, -19.5119, -22.5235, -21.8316,  11.8651],\n",
      "        [ -5.4606,  -5.4409,  -8.9361,   2.0297,  -1.5108,  -8.1052],\n",
      "        [ -5.8891, -15.6660,   6.1288,   3.0081, -10.1868, -18.6023],\n",
      "        [ -5.3418, -25.3086, -21.0464, -16.9027, -13.8345,  -1.7628],\n",
      "        [ -4.5124, -17.0064,   1.1469,  10.6547, -17.5392, -20.6361],\n",
      "        [  3.3363, -30.9729, -23.0003, -23.6003, -12.5224,   7.6203],\n",
      "        [ -9.6968, -14.6096,  -1.2714, -10.4084,   9.5723,  -7.4145],\n",
      "        [ 18.6514, -22.0667, -24.9790, -23.6245, -16.3701,  -7.2147],\n",
      "        [  4.5259, -29.0260, -17.1375, -10.7758,  -6.2257,  -8.9144],\n",
      "        [  1.1863, -17.1135, -13.4910, -19.7077, -12.7511,   3.4579]],\n",
      "       device='cuda:0')\n",
      "tensor([0, 4, 2, 0, 0, 5, 2, 5, 1, 0, 1, 3, 5, 2, 1, 4, 0, 5, 2, 1, 3, 4, 5, 3,\n",
      "        2, 5, 3, 5, 4, 0, 0, 5], device='cuda:0')\n",
      "tensor([[ -8.2269,   7.8410,  -2.6254,  -9.1219, -15.2650,  -4.8144],\n",
      "        [ -9.3374, -11.2276,  -4.1229,  -3.8054,   8.0633, -10.9622],\n",
      "        [  0.8703, -10.9489, -21.4369, -27.4969, -18.4772,   9.4010],\n",
      "        [  7.5376, -13.4993, -16.0269,  -9.8809, -13.5066,  -8.5037],\n",
      "        [-13.4166, -17.5552,   8.6116,  -2.3126,  -3.6250, -10.3837],\n",
      "        [ -9.9328, -17.7104,   5.4631,  -4.2946,   4.1452, -11.5227],\n",
      "        [  2.5183, -16.7809, -14.9386,  -4.4347,  -0.6602,  -8.0630],\n",
      "        [ -1.7444, -30.1767, -26.4830, -32.5977, -16.4242,   8.1847],\n",
      "        [ -8.3511, -15.7095,   1.8585,   8.5408, -10.0439, -17.2964],\n",
      "        [-13.9081, -19.3282, -16.7119, -19.1012, -24.0149,   3.1858],\n",
      "        [  4.2420, -10.6424,  -6.1671, -15.4104, -14.2054,  -3.6842],\n",
      "        [ -7.7227, -37.2641,  12.8185,  -2.6227, -17.0634,  -9.8808],\n",
      "        [-10.7796, -25.1782,  12.6575,   0.7405, -16.4299, -15.8847],\n",
      "        [ -6.8017,  11.7431,  -6.2230, -12.6394, -11.9093,  -7.0829],\n",
      "        [ -7.3098,  -6.2108,  -2.8370,   5.7446,  -5.9129, -12.9256],\n",
      "        [ -6.0411, -10.0804,  -6.4331,  -5.6642,  12.6057, -11.2869],\n",
      "        [ -5.1243, -11.3142,  -9.0355,  -4.6873,   9.9458, -10.4969],\n",
      "        [-10.3800, -12.7629,   0.6860,  -6.6812,  10.5605,  -9.1351],\n",
      "        [ -5.4079, -18.0680,  -5.7186, -10.2556, -10.7138,   3.4405],\n",
      "        [ -9.1403,  10.2561,  -3.5354, -10.4977, -15.3348,  -3.6793],\n",
      "        [ 15.6642, -22.6208, -14.7686, -21.2628, -25.3960,  -6.9674],\n",
      "        [ -5.3927,  -9.0847,  -6.7165,  -6.4073,   7.3411,  -6.6694],\n",
      "        [ -9.8221, -21.4456,  10.0035,  -3.1003,  -6.4605, -13.3293],\n",
      "        [ -4.8719,   2.2885,  -6.1120, -11.5977, -18.4426,   0.4976],\n",
      "        [ -4.2516, -14.4932,   0.8543,   4.6879, -11.1309, -12.6827],\n",
      "        [-12.0352,  -8.2886,  -4.1441,  -8.5184,   5.8266,  -2.7037],\n",
      "        [ -2.6380,  -8.1094,  -5.5873,   3.1349,  -0.9080, -10.7130],\n",
      "        [ -1.5823, -18.1761, -10.6865, -18.5636, -16.9614,   5.3610],\n",
      "        [ -5.5222,  -2.5207,  -4.0858,   3.9905,  -1.5098,  -8.7439],\n",
      "        [-11.8585, -11.9308,  -1.3743, -19.3795,   9.0673,  -2.3707],\n",
      "        [-10.7518,   7.6302,  -2.1348, -12.5574, -23.5336,  -0.3277],\n",
      "        [  8.3465, -24.9741, -14.1231, -18.8509,  -9.3343,  -1.3016]],\n",
      "       device='cuda:0')\n",
      "tensor([1, 4, 5, 0, 2, 2, 0, 5, 3, 5, 0, 2, 2, 1, 3, 4, 4, 4, 5, 1, 0, 4, 2, 1,\n",
      "        3, 4, 3, 5, 3, 4, 1, 0], device='cuda:0')\n",
      "tensor([[ -5.7115,   6.2624,  -5.1364, -15.2092, -20.0065,  -2.5576],\n",
      "        [  7.5220, -32.5521, -13.2489, -19.9644, -15.1204,   0.3922],\n",
      "        [  8.2689, -17.4724, -13.9614, -16.8273, -14.1576,  -9.2980],\n",
      "        [ -7.9906, -18.6223,   4.9310,   3.8693, -11.8718, -15.0230],\n",
      "        [-12.4880, -15.8388,  16.9005, -15.6608, -13.4868, -10.6324],\n",
      "        [ -6.7749,  -4.6769,   1.8053,  -0.9180,   2.8666,  -5.9599],\n",
      "        [ -3.3355,   2.1618, -12.3354, -11.0538, -11.2495,  -6.6277],\n",
      "        [  8.1147, -18.8534,  -6.5303, -16.8904, -18.5289,  -5.1726],\n",
      "        [ -1.0012, -25.8299, -18.6425, -20.9591, -21.5719,   7.4603],\n",
      "        [-10.8298,  -9.7687,  -2.8080,  -3.5418,  10.0460,  -9.1793],\n",
      "        [-14.0662, -27.7742,  15.1573,  -5.7164,  -9.7821, -12.6197],\n",
      "        [  6.6412, -24.4757,  -4.2072,  -1.2345,  -8.3664, -13.3083],\n",
      "        [ -9.6347, -22.0358,   4.8919,  -0.6640,  -7.3866, -13.0423],\n",
      "        [  0.2327,  10.3471, -14.8562, -13.4106, -18.3432,  -4.7109],\n",
      "        [ -6.7372, -10.8374,  -2.7388,  -5.7758,   2.4704,  -7.7809],\n",
      "        [ -8.4064, -20.6065,  10.3951,  -1.7282, -14.7122, -11.4660],\n",
      "        [ -8.9190, -18.6900,  -4.8312, -11.3827,   3.6181,  -8.3435],\n",
      "        [ -4.7297, -14.6454,  -1.5074,   3.7018,  -3.6329, -19.9587],\n",
      "        [  0.5769,  -1.4191,  -8.7121,  -6.3203, -15.1468,  -5.2985],\n",
      "        [ -3.6561,  -6.3933, -17.7924, -15.5256, -14.2649,   7.9643],\n",
      "        [ -3.5393, -15.2851,  -3.9982,   7.0824,  -9.2544, -13.4147],\n",
      "        [-16.8548, -23.5080,  14.2959,  -2.6369, -15.3408,  -6.7019],\n",
      "        [-15.8363, -22.4404,  13.4277, -13.6114,   1.0232,  -8.9201],\n",
      "        [ -7.4266,   9.7668,  -1.4862,  -4.2049,  -9.6725,  -8.1323],\n",
      "        [ -5.6587, -10.1201,  -3.3849,   3.7723,  -1.8635,  -8.1405],\n",
      "        [ -6.0662, -16.7975,  -0.2801,   7.1786,  -4.9473, -14.6951],\n",
      "        [-13.8577, -10.9010,   4.8446,   1.1937,  -4.9463,  -9.5571],\n",
      "        [  1.6047,  -7.6240, -11.7993, -14.7570,  -7.6891,  -0.2764],\n",
      "        [ -8.6297,  -8.0789,  -0.0826,   2.3026, -10.2565,  -5.1887],\n",
      "        [ -5.1268, -26.0898, -15.4041, -23.5806, -11.6433,   9.0955],\n",
      "        [ -1.6055,  18.0986, -11.9385, -18.6178, -22.5511,  -4.0378],\n",
      "        [ -4.2488,  13.6359, -12.7228, -17.0013, -21.6856,  -1.5150]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 2, 2, 4, 1, 0, 5, 4, 2, 0, 2, 1, 4, 2, 4, 3, 0, 5, 3, 2, 2, 1,\n",
      "        3, 3, 2, 0, 3, 5, 1, 1], device='cuda:0')\n",
      "tensor([[ 13.4952, -37.7381, -13.3520,  -8.0637,  -9.8282, -12.6737],\n",
      "        [ -9.3062, -26.3244,   9.2052,   2.6422, -13.7694, -13.2766],\n",
      "        [ -7.4005,  17.6366, -15.1507,  -9.3336, -23.2437,  -5.0624],\n",
      "        [  9.8316, -32.3638, -21.8723, -17.8739, -14.0570,  -2.1381],\n",
      "        [ -5.3075,   0.4339,  -3.4825,   0.7959,   1.1569,  -6.0701],\n",
      "        [-12.8115, -19.2253,   9.6926,  -3.9520,  -5.4719, -10.7333],\n",
      "        [ -4.7348,  10.5738, -16.1883, -12.8562, -17.3296,  -0.1481],\n",
      "        [  1.7345, -17.9092,  -7.8144,  -6.3761, -12.7330,  -8.4102],\n",
      "        [-13.0090, -27.4700,  11.5474,  -1.2066, -13.4837,  -9.8439],\n",
      "        [ -5.2989, -12.7281,  -1.0023,   8.3890,  -6.9228, -14.1198],\n",
      "        [  0.6831, -14.3400, -12.7388, -15.9922, -10.2336,   3.4507],\n",
      "        [ -9.2492,  -9.2759,  -7.8608,  -4.3918,  11.8267, -14.7242],\n",
      "        [ -2.5830,   8.4518,  -6.1781,  -7.0166, -13.2455,  -5.3518],\n",
      "        [ -8.0209, -10.9920,  -5.6641,  -9.6735,  10.6852,  -7.3261],\n",
      "        [ 12.2502, -34.1907, -13.5691, -13.9150, -18.4360,  -9.3350],\n",
      "        [  5.6107, -26.6829, -15.6014, -27.5549,  -8.3861,  -1.7152],\n",
      "        [  3.0842, -18.9984,  -4.4905,  -8.2991, -14.9914,  -9.1187],\n",
      "        [ -9.5663, -17.2561,  10.4353,  -0.0890, -13.8434, -15.4689],\n",
      "        [-10.8471, -13.2758,  -0.6473, -18.8277,  14.5952,  -6.0178],\n",
      "        [  4.4089, -22.5361, -10.4094,  -9.0559, -11.5717,  -6.9173],\n",
      "        [ -0.1899, -19.9185, -20.8667, -24.8318, -16.4739,   7.7042],\n",
      "        [ -0.2443, -27.0105,   0.3496,   6.4883, -16.5093, -16.8696],\n",
      "        [ -6.5894, -11.0867,  -3.3332,   2.0899,  -6.4546,  -6.6612],\n",
      "        [ -6.4814,  -8.2880,  -4.5741,  -5.2008, -10.9794,  -2.0936],\n",
      "        [ -2.3987, -18.3219,  -2.5025,   9.2996,  -5.8824, -19.8287],\n",
      "        [ -4.0441,  15.7854,  -9.0464, -13.4476, -19.4164,  -6.3765],\n",
      "        [ -8.5449, -16.4933,   3.7947,   4.3837,  -9.1351, -14.3451],\n",
      "        [-12.3824, -11.9468,  -0.9675,  -5.2034,   6.3237,  -9.7990],\n",
      "        [-14.0806, -12.5281,   9.1937,  -8.0190,  -1.6199,  -8.7158],\n",
      "        [ -4.0342,  -8.8234, -11.2134, -14.1447,  -2.0131,  -1.0957],\n",
      "        [ -3.7705,   4.5339, -11.8459,  -9.5741, -22.0672,  -3.6414],\n",
      "        [ -4.1445, -11.7223,  -2.8793,   2.8429,  -7.1387, -10.6524]],\n",
      "       device='cuda:0')\n",
      "tensor([0, 2, 1, 0, 4, 2, 1, 0, 2, 3, 5, 4, 1, 4, 0, 0, 0, 2, 4, 0, 5, 3, 3, 5,\n",
      "        3, 1, 3, 4, 2, 5, 1, 3], device='cuda:0')\n",
      "tensor([[-13.3423, -24.5847,  14.1720,  -2.1847, -17.0772, -11.1984],\n",
      "        [ -4.4283, -20.7932, -12.3843, -14.4495,  -3.4426,   2.4177],\n",
      "        [ -2.4487, -17.2759,  -2.8584,  13.1448, -16.4952, -19.4353],\n",
      "        [ -5.8171, -18.4288,  -1.3359,   4.3776,  -8.9806, -11.2339],\n",
      "        [ -1.3057, -18.6946,   3.5579,   1.9048, -16.1489, -15.3844],\n",
      "        [ -8.7158, -21.6181,   5.8398,   7.7615, -18.1055, -13.8340],\n",
      "        [ -4.7560,  -0.9019,  -0.9284,  -0.3086,  -1.0420,  -5.3479],\n",
      "        [  5.9880,  -6.1263,  -7.2795,  -8.4772, -10.8629,  -4.7237],\n",
      "        [ -6.0842,  14.4310,  -6.8452, -14.2652, -17.1473,  -6.4299],\n",
      "        [ -9.9897, -19.4328,   0.0518,   6.8873, -16.8796, -11.3713],\n",
      "        [-12.0253, -21.4404,   9.7065,   2.3816, -12.3175, -11.6450],\n",
      "        [ -9.5556, -19.4732,  -5.2509, -10.4310,  12.4511,  -9.9524],\n",
      "        [  3.7632, -35.3871, -12.5935, -20.4974, -13.7304,   1.5260],\n",
      "        [-10.2575, -27.1940,  14.2925, -17.4192,  -5.7772, -11.4171],\n",
      "        [ -8.8482, -11.5598,  -3.3069,   7.0651,  -2.1099, -15.8331],\n",
      "        [-11.2422, -27.6890,   1.5499, -12.5649,   2.7497,  -5.8451],\n",
      "        [-12.5281, -29.3477,  10.9373,  11.9756, -25.1976, -17.8641],\n",
      "        [ 14.0869, -40.5268, -14.6638, -12.7310, -27.3356, -11.9820],\n",
      "        [ -8.5304,  -4.7892,  -8.6599,   3.5559,   1.4811,  -9.2770],\n",
      "        [ -8.1089, -21.0847,   3.0005,  -5.1026,  -2.8959, -11.2674],\n",
      "        [ -8.1245, -10.3032,  -0.0947,   6.2315,  -9.4766, -11.1489],\n",
      "        [ -4.8261, -13.9660,  -9.0970,  -6.3216,   3.4887,  -6.1707],\n",
      "        [ -9.8272,  15.6814,  -3.7598, -13.4013, -18.4877,  -5.7122],\n",
      "        [ -4.2030, -15.3935,  -7.7310, -12.0221,  -9.1908,   3.0241],\n",
      "        [ -1.5662, -18.3407,  -2.4051,  -9.4170, -12.8336,  -1.9270],\n",
      "        [-10.0041,  -2.7596,  -0.8511,  -8.6404,  -6.5273,  -0.0880],\n",
      "        [  1.3399, -16.9200, -12.5610, -20.1763, -11.6869,   0.7723],\n",
      "        [ -7.7111,  -9.9242,  -3.8157,  -5.3838,  12.2479, -12.5981],\n",
      "        [ -3.9824, -12.6712,  -4.8553,  11.0640, -10.6143, -15.3693],\n",
      "        [  4.3553, -14.5154, -14.3782, -13.6977,  -4.8053,  -5.6420],\n",
      "        [ -3.0449,   6.3174,  -5.8745, -13.3276, -17.9879,  -3.3400],\n",
      "        [ -4.3481,   7.3771,  -4.9685, -12.3129,  -9.2456,  -5.1144]],\n",
      "       device='cuda:0')\n",
      "tensor([2, 5, 3, 3, 2, 3, 3, 0, 1, 3, 2, 4, 0, 2, 3, 4, 3, 0, 3, 2, 3, 4, 1, 5,\n",
      "        0, 5, 0, 4, 3, 0, 1, 1], device='cuda:0')\n",
      "tensor([[  8.8226, -22.0720, -11.2332,  -5.7820, -12.9056, -13.2545],\n",
      "        [ -7.6607, -15.0176,  -0.3289, -11.5025,   7.5605,  -7.6430],\n",
      "        [-12.7509, -25.6141,  11.8876,  -1.1253, -10.4777, -12.7471],\n",
      "        [ -4.2559, -14.5949,  -9.8566, -15.9271, -12.8166,  -1.3263],\n",
      "        [-13.9029,  -5.0592,  -1.0324, -19.0858,  10.6537,  -7.7914],\n",
      "        [ -5.0318, -29.5585,   7.7145,  -6.1988,  -8.9650, -14.2844],\n",
      "        [  4.1441, -20.5831, -14.8010, -15.2914, -15.4446,  -2.5578],\n",
      "        [-12.5028, -22.6115,  12.0973, -12.9636,   0.6368, -10.2055],\n",
      "        [  0.4102,  12.0593,  -8.3301, -18.6877, -22.9348,  -3.5835],\n",
      "        [  5.5943, -14.9055, -16.0244,  -9.3249,  -2.4226, -10.1485],\n",
      "        [-11.5294, -18.7637,   5.3140,  -8.4853,   3.2755,  -9.0527],\n",
      "        [ -6.2196, -11.7044,  -3.2242,   7.0671,  -7.2480, -12.4374],\n",
      "        [ -8.0136,  -9.5934,   0.0913,   9.8334, -12.5602, -11.6642],\n",
      "        [ -1.6055, -17.4718, -15.7359, -22.6130, -15.8591,  10.3537],\n",
      "        [-11.9412, -14.8287,   4.6984, -14.9106,   8.6153, -10.8187],\n",
      "        [ -9.4659, -11.3204,  -7.7095,  -6.7719,  13.3118,  -7.9329],\n",
      "        [ -2.1325, -30.3079, -12.0482,  15.9460, -12.0675, -23.6085],\n",
      "        [  3.6808, -24.1538, -14.2569, -25.1128, -14.3038,   2.2379],\n",
      "        [ -4.2569,  -3.6201,  -1.7678,  -8.2899,  -7.2007,  -5.2999],\n",
      "        [ -5.1950, -10.4670,  -3.7613,   9.5473,  -1.5431, -15.5818],\n",
      "        [  5.1010, -22.7192, -11.3619,  -3.3906,  -8.7556, -13.5814],\n",
      "        [ -8.5667, -11.2715,   3.9612,   5.8188, -11.8465, -14.9266],\n",
      "        [ -7.7016, -15.3683,  -6.8268,  17.4490, -10.3319, -22.3345],\n",
      "        [ -0.5467, -11.2575, -12.1200, -15.6992, -14.6845,   1.8020],\n",
      "        [ -5.6254, -19.1747, -11.7724, -18.2791,  -7.7863,   3.5451],\n",
      "        [-15.6628, -32.5023,  17.8227,  -4.8123, -12.2121, -13.7646],\n",
      "        [ -9.4867, -19.6774, -16.4571, -15.2868, -23.1606,  -4.2814],\n",
      "        [-15.1058, -15.5156,  -8.7690, -28.4493, -17.4049,   6.2353],\n",
      "        [ -7.4401,  -8.6232,  -0.7956,   0.0756,   0.7305, -11.4685],\n",
      "        [ -8.5374,   1.7878,  -2.8915,  -1.9583,   0.4741,  -6.8603],\n",
      "        [ -6.8619,  -5.2254,  -6.4942,  -7.8140,  13.2152, -13.3522],\n",
      "        [ -9.9673, -23.2483,   9.1840,  -5.9022,  -5.6064,  -9.0357]],\n",
      "       device='cuda:0')\n",
      "tensor([0, 4, 2, 5, 4, 2, 0, 2, 1, 0, 2, 3, 3, 5, 4, 4, 3, 0, 2, 3, 0, 3, 3, 5,\n",
      "        5, 2, 5, 5, 4, 1, 4, 2], device='cuda:0')\n",
      "tensor([[-12.8383, -23.9178, -21.8024, -31.5803, -24.5818,  13.5497],\n",
      "        [ -3.9951, -23.5635, -10.3805, -10.2193,  16.6548, -17.9618],\n",
      "        [ -6.5043, -21.1893, -11.8656, -17.0367, -18.2784,   6.8120],\n",
      "        [-12.0786, -27.2624,  16.3279,  -9.0483, -12.9800, -10.5275],\n",
      "        [  7.4926, -25.8261, -17.6236, -16.8664,  -3.5231,  -8.3734],\n",
      "        [ -3.4453, -29.6652,   1.8597,   5.1708,  -9.6454, -17.4119],\n",
      "        [-10.2481,  -5.2821,  -3.3458,  -0.3542,   7.1865,  -8.0352],\n",
      "        [ -0.6273,   0.8545, -13.6080, -11.8638, -11.4553,   1.6759],\n",
      "        [  8.2485, -34.1310, -12.8373, -15.7614, -23.5409,  -3.2053],\n",
      "        [ -8.2914, -13.6658,  -2.9166,   4.3962,  -7.0418, -14.9183],\n",
      "        [ 12.2579, -22.0114, -14.2622,  -9.7219,  -8.4792, -15.1883],\n",
      "        [-14.2036, -30.2276,  22.3349, -15.1318, -11.3889, -13.5387],\n",
      "        [ -5.0945,  10.0277,  -2.6882,  -9.1327, -10.5014,  -6.0283],\n",
      "        [ -8.9682, -26.3033,   9.8825,   6.6807, -16.5846, -15.4812],\n",
      "        [ -8.3566, -13.3979,   4.5366, -14.2790,   0.4135,  -9.7233],\n",
      "        [ -7.2856, -14.2577,   1.0277,  12.3721, -14.6368, -18.2383],\n",
      "        [ -8.6774, -14.0260,   2.8895,  10.3871, -17.1817, -15.1065],\n",
      "        [  1.3552, -21.5967, -18.0976, -17.4252,  -9.5296,   0.6952],\n",
      "        [ -3.7536,  10.0961,  -2.0527, -13.1332, -14.7793,  -4.9455],\n",
      "        [ -4.6544,   3.9505,  -1.4702, -13.1482, -12.2523,  -3.9887],\n",
      "        [-17.4311, -28.6951,  16.6822,  -5.4850, -13.4020, -13.8122],\n",
      "        [ -3.7597, -13.0754,  -5.7316, -15.9047, -11.0568,   2.9161],\n",
      "        [ 14.5565, -40.9128, -25.7502, -23.9517,  -6.5765,  -2.7535],\n",
      "        [ -9.4945, -10.5046,   1.2880, -10.6700,   2.2515,  -9.0083],\n",
      "        [ -4.8684,  -4.6009,  -9.5337, -26.1162, -15.0317,   2.5068],\n",
      "        [-14.9049, -20.8824,   8.3088,   5.3877, -13.5468, -11.1064],\n",
      "        [-10.4786, -14.3229,   7.9980,  -1.5219,  -7.4859, -11.0596],\n",
      "        [-11.1566, -21.5813,  10.3632, -12.9297,  -3.6116, -10.1933],\n",
      "        [ -1.6226,  12.1179,  -7.0043, -12.4287, -17.5425,  -3.9086],\n",
      "        [ -7.4672,  14.9032,  -9.2219, -14.2020, -18.9583,  -4.0478],\n",
      "        [-16.1928, -16.0060,   7.4290,  -3.9638,  -2.5839,  -6.6290],\n",
      "        [ -3.6713, -21.1966,  -0.2852,   4.8722,  -3.5243, -15.7635]],\n",
      "       device='cuda:0')\n",
      "tensor([5, 4, 5, 2, 0, 3, 4, 5, 0, 3, 0, 2, 1, 2, 2, 3, 3, 0, 1, 1, 2, 5, 0, 4,\n",
      "        5, 2, 2, 2, 1, 1, 2, 3], device='cuda:0')\n",
      "tensor([[ -7.7159,  18.0950,  -6.2521, -17.1444, -17.0128,  -7.6986],\n",
      "        [ -2.8571, -18.3251, -15.7420, -13.7690, -15.6303,   6.0985],\n",
      "        [ -9.8308,  -2.2549,  -8.2223,   3.8648,   4.4636,  -7.7463],\n",
      "        [ -2.9991, -36.9496, -27.4003, -23.3015, -22.4036,  -4.4570],\n",
      "        [  6.1362, -25.1365,  -9.3987, -16.6066,  -8.4374,  -8.4358],\n",
      "        [ -2.9537,  10.6019,  -9.8038, -16.2931, -18.3780,  -4.0862],\n",
      "        [ -6.9520,  18.4822,  -8.8992, -16.6987, -20.8418,  -5.4377],\n",
      "        [ -9.5975, -13.7417, -10.5631,  -7.7416,   5.3104,  -6.5487],\n",
      "        [  7.4003, -20.5794, -16.1001, -11.2838,  -6.9707,  -7.3525],\n",
      "        [  4.0168, -18.7128, -20.6597, -25.2292, -14.1629,   4.2147],\n",
      "        [-12.4690, -23.1823,  14.4385, -10.2204,  -8.2698,  -9.0427],\n",
      "        [ 10.8989, -19.5462, -16.8061, -11.8129,  -9.0852,  -9.1499],\n",
      "        [ -2.8141, -15.1584, -18.4276, -23.3121, -16.3705,  10.8878],\n",
      "        [  2.0182, -26.6147,  -8.1366, -14.5371,  -2.1841,  -5.7411],\n",
      "        [-11.9987, -21.7566,  13.4316,  -6.3457,  -6.9652, -15.7411],\n",
      "        [ -6.7117, -10.0131,  -2.3848,  10.0857,  -2.7692, -17.7119],\n",
      "        [ -8.5386,  15.4317,  -4.3211, -15.0299, -14.1855,  -3.7704],\n",
      "        [  8.0756, -34.1925, -21.0714, -25.4368,  -9.7080,   1.2730],\n",
      "        [-10.1202,  -9.2436,  -3.1970,  -0.6710,   8.7284, -13.0464],\n",
      "        [-12.3738,  -9.5844,   2.1383, -12.9242,  11.5163,  -7.0308],\n",
      "        [ -5.3196,  -9.7054,  -4.4338,  11.9597,  -6.6661, -20.1383],\n",
      "        [  0.3750, -24.8066, -20.7729, -23.2752, -18.5631,   9.6472],\n",
      "        [ -1.7447,  -3.9970, -11.9361, -14.9307, -17.4615,   5.5817],\n",
      "        [ -4.2861,   3.6421,  -7.0086,  -6.2239,  -4.2264,  -1.9534],\n",
      "        [ 15.0809, -27.1048, -18.5605, -22.2018, -21.4275,  -6.8686],\n",
      "        [ -9.9891,   1.3286,  -4.8761,  -0.6341,   4.6742, -10.0443],\n",
      "        [  9.3507, -20.1900, -19.8146, -14.6294, -10.9199,  -5.2076],\n",
      "        [  5.4358, -24.9434, -31.4350, -27.6781, -25.4344,  13.5961],\n",
      "        [ -6.8220, -21.6219,   1.2703,  -6.4317,   5.2881, -14.3935],\n",
      "        [ -9.2594, -19.9571,   3.6950,  14.9843, -21.5289, -19.3353],\n",
      "        [ -2.3361,   9.1589,  -7.2947,  -8.3660, -10.6639,  -4.2794],\n",
      "        [ -8.9702,  16.8043,  -8.4505, -20.8261, -25.6658,  -6.1602]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 5, 4, 0, 0, 1, 1, 4, 0, 5, 2, 0, 5, 0, 2, 3, 1, 0, 4, 4, 3, 5, 5, 1,\n",
      "        0, 4, 0, 5, 4, 3, 1, 1], device='cuda:0')\n",
      "tensor([[ -4.3750, -28.4701,   4.1552,   7.7141, -18.2672, -16.1150],\n",
      "        [  2.9292,   7.2398, -11.3717, -13.8614, -15.7147,  -3.9893],\n",
      "        [  2.4474, -25.2957,  -7.7406, -15.9421, -13.7629,  -6.3614],\n",
      "        [ -2.4190,  10.8504, -10.3238, -13.7367, -19.4505,  -5.4390],\n",
      "        [ -9.7973, -12.5532,  -0.5838,   7.2289,  -3.8716, -15.4191],\n",
      "        [ -6.4128, -26.7147,   7.9808,   2.6027, -13.5649, -11.4071],\n",
      "        [ -4.1041,  14.7816, -11.0052, -13.7739, -16.3911,  -5.5216],\n",
      "        [ -0.8839,  -9.9395, -10.9714,  -1.2737,   4.8098, -11.3445],\n",
      "        [ -5.4782,  -4.4599,  -8.8226, -12.7151,  -8.7147,   2.3722],\n",
      "        [ -7.6033,   4.1606,  -0.7512,  -6.4817, -15.1461,  -9.2305],\n",
      "        [ -7.3743, -10.2599,  -4.1236,   9.8405, -11.2358, -12.0584],\n",
      "        [ 17.4701, -21.9620, -18.7297, -31.4522, -22.4941,  -2.9484],\n",
      "        [  2.6145,  -3.2487,  -8.1920, -14.4970, -17.8014,  -0.5517],\n",
      "        [  1.2660, -22.4627, -14.8002, -15.2537, -20.0923,   7.0672],\n",
      "        [-12.3031, -28.5089,   6.4963,  11.1305, -21.1237, -14.7444],\n",
      "        [ -6.0948,   3.4581,  -4.6290,  -3.4944,  -4.4915,   0.2581],\n",
      "        [ -6.2433,  16.3322,  -6.1350, -20.3613, -20.5976,  -4.8173],\n",
      "        [ -0.9029, -17.5313, -20.4297, -13.5233, -16.5373,   9.8751],\n",
      "        [ -6.7619, -11.3112,  -2.8720,   1.0021,   7.4298, -12.5697],\n",
      "        [ -6.5082, -11.7587, -10.7849, -21.8826,  -6.8744,   4.5646],\n",
      "        [ -6.8763, -12.3998,   0.0835,   5.8083,  -6.2455, -11.0044],\n",
      "        [-10.2860, -12.1264,  -4.0444,  -7.5862,  12.2016,  -8.8372],\n",
      "        [ -3.6121,  14.3212,  -8.6304, -15.8950, -18.9248,  -8.2365],\n",
      "        [ -9.4361, -13.4632,  -8.2550, -24.1585, -19.1931,   2.0496],\n",
      "        [-10.5553,  -8.4159, -14.7299, -19.0394, -22.7600,  -0.1147],\n",
      "        [-13.4483, -11.4810,  -9.6993, -25.9287, -13.7372,   6.9488],\n",
      "        [  0.9955,  -7.0925, -14.8605, -15.1766, -14.0212,   4.1264],\n",
      "        [ -2.5482, -21.5842,   0.9718,  -0.7132, -21.7915, -15.4297],\n",
      "        [-10.3199,  -8.9467,  -3.3235,  -3.5517,   5.3961,  -5.7150],\n",
      "        [ 10.3514, -35.8019, -13.9664, -15.2167, -12.9753,  -7.6402],\n",
      "        [ -7.8161,  -9.5120,  -1.7680,   8.5875,  -7.0454, -13.0777],\n",
      "        [ -7.5271, -13.5003,   4.3712,   7.4945, -13.3059, -15.9615]],\n",
      "       device='cuda:0')\n",
      "tensor([3, 1, 0, 1, 3, 2, 1, 4, 5, 1, 3, 0, 0, 5, 3, 1, 1, 5, 4, 5, 3, 4, 1, 5,\n",
      "        5, 5, 5, 2, 4, 0, 3, 3], device='cuda:0')\n",
      "tensor([[ -5.6071, -17.1504,  -4.8284,  -3.1689,   3.1135,  -9.7777],\n",
      "        [ -6.7846, -13.9674,   1.4226,  12.9002, -13.0290, -20.7378],\n",
      "        [ -4.9335,   8.8887,  -3.8081,  -7.1351,  -8.7733,  -8.0708],\n",
      "        [  0.5728, -14.1277, -10.9102, -18.5551, -16.4078,   3.0172],\n",
      "        [ -2.7077, -10.4808,  -7.1774,   4.0465,   1.5287, -11.4840],\n",
      "        [ -8.6971,  -6.8805,  -5.6023,   2.2536,   6.6743,  -8.9532],\n",
      "        [ -2.5838, -10.1209,   0.1155,   6.1412, -10.0326, -13.1654],\n",
      "        [ -3.5187, -29.3684,  -8.5728, -11.3751, -16.9204,   4.9495],\n",
      "        [ -5.4894,  -7.8565,  -6.2330,  -3.5026,   8.5773, -11.5729],\n",
      "        [ -5.6788,  19.7578, -10.4444, -18.9323, -23.3756,  -4.7500],\n",
      "        [-17.5585, -16.0195, -25.1911, -31.1019, -26.8849,   0.3624],\n",
      "        [-15.6964, -14.3209,  12.5763,  -7.8293,  -4.8109,  -6.9293],\n",
      "        [ -4.7429,   7.1087,  -8.9727, -15.6508, -16.8263,   1.8669],\n",
      "        [-12.3345, -28.7266,  -5.8193, -11.7287, -20.2029,   8.7446],\n",
      "        [-15.2854, -20.8562,  12.0933,  -9.5166,  -5.1560, -12.5043],\n",
      "        [ -0.8942,  -8.5370, -19.0368, -20.0221, -18.5232,   7.3948],\n",
      "        [-13.1965, -18.8024,   6.6273,   0.7998,  -3.6931, -11.9751],\n",
      "        [ -7.5179,   4.6765,  -4.2360, -11.5055, -20.8462,  -3.3487],\n",
      "        [ -6.0556,  -5.4910,  -6.2503,   0.6785,  -2.4468,  -5.0229],\n",
      "        [-13.2737,  -8.1757,  -2.4281,  -9.1901,  13.1805, -11.2218],\n",
      "        [  4.5009, -26.8014,  -2.5099,  -1.2508, -11.1316, -19.0576],\n",
      "        [ -8.7266, -19.8378,   9.6556,  -5.1961,  -7.6089,  -9.1298],\n",
      "        [ -9.2267,  -5.8891,  -5.2766,   7.1395,   1.2115, -12.0168],\n",
      "        [ -4.3657,   5.3063,  -1.1921,  -4.6015,  -8.4008,  -7.9493],\n",
      "        [ -3.3352, -20.8917,   1.8867,  10.0312, -13.9366, -22.7547],\n",
      "        [ -6.7600, -31.2823, -26.9645, -20.1555, -31.6507,   0.3628],\n",
      "        [ -7.8692,  -1.2205,  -4.9001,   5.7275,  -0.5221,  -9.4186],\n",
      "        [ 12.4437, -30.0590, -16.3409,  -9.0957, -20.2345, -10.3178],\n",
      "        [ -6.3182,  12.1764,  -2.2010,  -9.4971, -10.3407,  -5.8249],\n",
      "        [ -5.9156,  -4.8222,  -0.9044,  -3.0861,   5.3619,  -6.1403],\n",
      "        [ -7.7633,   5.9480,   2.7639, -12.8294,  -0.8901,  -9.1803],\n",
      "        [ -6.0599,  -5.3424,  -3.5589,   2.0666,   1.3647, -10.1933]],\n",
      "       device='cuda:0')\n",
      "tensor([4, 3, 1, 5, 3, 4, 3, 5, 4, 1, 5, 2, 1, 5, 2, 5, 2, 1, 3, 4, 0, 2, 3, 1,\n",
      "        3, 5, 3, 0, 1, 4, 1, 3], device='cuda:0')\n",
      "tensor([[ -6.7968,  12.0070, -10.4673, -27.1314, -18.9551,   1.8509],\n",
      "        [ -9.2290, -26.4849,  10.0193,   0.5549, -13.9446, -10.9504],\n",
      "        [-11.9422, -14.9034,  -5.0464, -12.4223,  20.4171, -13.7371],\n",
      "        [-11.1500,  -6.5892,  -6.5904, -14.0266,  16.5852, -10.7549],\n",
      "        [  3.1336, -20.2400,  -8.3991,  -2.1875, -19.8683, -11.5691],\n",
      "        [ -7.8166, -21.9308,  12.6461, -16.8130,  -5.5887, -10.2829],\n",
      "        [ 12.9019, -36.1042, -23.7452, -31.0442, -17.0697,   3.9648],\n",
      "        [ -1.6689, -15.9948,  -2.9235,   4.8722,  -4.5315, -16.0641],\n",
      "        [ -7.8678,  -9.7778,  -5.6742,  -0.5174,   7.9180,  -9.5174],\n",
      "        [ -8.1305, -16.3772,   2.0759,  -4.1136,   0.2929, -10.6230],\n",
      "        [ 11.1507, -35.4469, -15.5195, -21.8177,  -9.4490,  -7.3633],\n",
      "        [ -7.0256,  10.0182,  -7.4927, -12.0241, -21.8246,  -0.9653],\n",
      "        [  3.9740, -29.4998, -22.5935,  -8.5134,   3.1776, -10.4021],\n",
      "        [-14.5470, -20.3279,   9.6402,  -4.0884,  -8.9328,  -9.9356],\n",
      "        [ -4.2728, -16.5524, -14.2400, -21.4506, -15.0586,   7.8787],\n",
      "        [ -2.5243, -14.6592,  -9.6798,  -7.5228,   3.1028,  -6.4270],\n",
      "        [ -8.4665,  -8.6591,  -6.1345,   4.1760,  -3.4065, -15.1934],\n",
      "        [-14.0776, -19.6729,   9.1088, -12.7459,  -7.6232,  -1.4307],\n",
      "        [  6.6721, -21.6270, -14.3432, -18.9498, -12.5165,  -3.5946],\n",
      "        [ -5.9260,   8.3069,  -3.8113,  -9.6426,  -5.7016,  -7.9797],\n",
      "        [  1.6182, -14.9912, -13.8029, -12.0172, -11.8195,   0.5849],\n",
      "        [ -2.2785,  10.6016,  -9.5483, -15.8617, -15.1723,  -3.6124],\n",
      "        [-10.2287, -11.8840,   3.7102,   2.4130,  -1.7342, -11.9148]],\n",
      "       device='cuda:0')\n",
      "tensor([1, 2, 4, 4, 0, 2, 0, 3, 4, 2, 0, 1, 0, 2, 5, 4, 3, 2, 0, 1, 0, 1, 2],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['forest'],\n",
       "       ['street'],\n",
       "       ['forest'],\n",
       "       ...,\n",
       "       ['buildings'],\n",
       "       ['forest'],\n",
       "       ['glacier']], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "predicted = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for data in testloader:\n",
    "        dat = data \n",
    "        outputs = model(data.to(device))\n",
    "        print(outputs)\n",
    "        _, predict = torch.max(outputs, 1)\n",
    "        print(predict)\n",
    "        predicted += predict.cpu()\n",
    "        \n",
    "array = label_encoder.inverse_transform(predicted)\n",
    "array.reshape(len(array), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3c44e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# array = predicted.cpu()\n",
    "submission = pd.DataFrame({\n",
    "    \"image\" : test_df['image'],\n",
    "    'label' : array\n",
    "})\n",
    "\n",
    "submission.to_csv('ebsen.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "459f0479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20e0bac8280>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23a89086",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = torch.tensor([[1, 2, 3, 4, 5],[5, 4, 3, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b48ee4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, tmp = torch.max(array, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d74d9eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5254534e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1523,  0.1802,  0.3730,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.0376,  0.0500,  0.2318,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.0331,  0.0143,  0.1772,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 0.3026,  0.3275,  0.5108,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.1854,  0.1944,  0.3664,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.1132,  0.1578,  0.3106,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 0.4364,  0.4723,  0.6958,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.3197,  0.3398,  0.5521,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.2478,  0.3034,  0.4966,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8654,  1.6822,  1.6287,  ..., -0.5581,  0.1165,  0.6535],\n",
      "          [ 1.9589,  1.8901,  1.6732,  ..., -0.5243, -0.1098,  0.1186],\n",
      "          [ 1.8500,  1.9589,  1.7850,  ..., -0.5573, -0.6337, -0.8377],\n",
      "          ...,\n",
      "          [-1.1937, -1.3146, -1.5315,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.4058, -1.4344, -1.5460,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.4601, -1.4200, -1.4445,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.0378,  1.8430,  1.7483,  ..., -0.6507, -0.0353,  0.4372],\n",
      "          [ 2.1571,  2.0784,  1.8151,  ..., -0.6192, -0.2783, -0.0769],\n",
      "          [ 2.0858,  2.1859,  1.9605,  ..., -0.6150, -0.7799, -1.0336],\n",
      "          ...,\n",
      "          [-1.3243, -1.4272, -1.6306,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.4488, -1.4745, -1.5747,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.4532, -1.4053, -1.4039,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.5812,  1.3872,  1.2992,  ..., -1.2970, -0.7294, -0.2837],\n",
      "          [ 1.5618,  1.4842,  1.2299,  ..., -0.9944, -0.6760, -0.5092],\n",
      "          [ 1.2654,  1.3688,  1.1582,  ..., -0.6908, -0.8391, -1.1019],\n",
      "          ...,\n",
      "          [-1.5045, -1.5981, -1.7328,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.5625, -1.5836, -1.6583,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.5557, -1.5008, -1.4735,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.2932,  1.3042,  1.3448],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.3605,  1.4970,  1.5007],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.2794,  1.4075,  1.2833]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.0377,  1.0902,  1.1495],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.0451,  1.2043,  1.2480],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.9139,  1.0887,  0.9722]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.4062,  0.4076,  0.4578],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.4858,  0.6198,  0.6235],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.4150,  0.5577,  0.4046]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  0.5980,  0.4214,  0.4236],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.9470,  0.5972,  0.3502],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.3283,  0.7845,  0.3301],\n",
      "          ...,\n",
      "          [-0.1672, -0.3047, -0.1908,  ..., -1.1394, -1.2018, -1.1837],\n",
      "          [-0.0631, -0.1673, -0.0697,  ..., -1.0977, -1.1903, -1.1900],\n",
      "          [-0.3815, -0.1240,  0.0157,  ..., -0.9610, -1.0893, -1.2318]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.3302,  1.1242,  1.1065],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.6743,  1.2972,  1.0275],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.0476,  1.4566,  0.9801],\n",
      "          ...,\n",
      "          [ 0.2227,  0.1018,  0.2071,  ..., -0.8953, -0.9591, -0.9406],\n",
      "          [ 0.3684,  0.2561,  0.3495,  ..., -0.8477, -0.9473, -0.9471],\n",
      "          [ 0.0533,  0.3003,  0.4369,  ..., -0.7067, -0.8441, -0.9898]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  1.2868,  1.2847,  1.3710],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.6311,  1.4344,  1.2867],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.9863,  1.5927,  1.2212],\n",
      "          ...,\n",
      "          [-0.5355, -0.6225, -0.4406,  ..., -0.9037, -0.9592, -0.9408],\n",
      "          [-0.4147, -0.4702, -0.3050,  ..., -0.8882, -0.9533, -0.9472],\n",
      "          [-0.7318, -0.4262, -0.2065,  ..., -0.7552, -0.8522, -0.9897]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.0829,  0.0529,  0.0736],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.5523,  0.5010,  0.4811],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.5235,  0.5573,  0.6102]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.1267,  0.0960,  0.1171],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.5928,  0.5403,  0.5200],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.5596,  0.5942,  0.6482]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.8936,  0.8631,  0.8841],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.3975,  1.3453,  1.3251],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.3927,  1.4387,  1.4925]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[ 2.2489,  2.2489,  2.2489,  ...,  0.3326,  0.3322,  0.3469],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.3628,  0.3525,  0.3483],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.4129,  0.3824,  0.3558],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.3932, -1.3572, -1.3110],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.3413, -1.3452, -1.3368],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.3396, -1.3882, -1.4098]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  0.9072,  0.9067,  0.9218],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.9381,  0.9275,  0.9232],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.9767,  0.9456,  0.9184],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.2424, -1.2055, -1.1583],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.1893, -1.1932, -1.1847],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.1875, -1.2372, -1.2592]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  1.2125,  1.2121,  1.2271],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.2433,  1.2328,  1.2285],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.2880,  1.2570,  1.2299],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.3109, -1.2742, -1.2272],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.2581, -1.2620, -1.2535],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.2563, -1.3058, -1.3277]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  1.7111,  1.7178,  1.7180],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.7009,  1.7115,  1.7178],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.6987,  1.7009,  1.7111],\n",
      "          ...,\n",
      "          [-0.9395, -0.9670, -0.9674,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.9072, -0.9323, -0.9582,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.9044, -0.9424, -0.9868,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.9663,  1.9731,  1.9734],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.9559,  1.9667,  1.9731],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.9536,  1.9559,  1.9663],\n",
      "          ...,\n",
      "          [-0.9011, -0.9291, -0.9296,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.8680, -0.8937, -0.9202,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.8652, -0.9040, -0.9494,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.2321,  2.2389,  2.2391],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.2217,  2.2325,  2.2389],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.2195,  2.2217,  2.2321],\n",
      "          ...,\n",
      "          [-0.6923, -0.7202, -0.7206,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.6594, -0.6849, -0.7113,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.6565, -0.6952, -0.7404,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  1.9701,  2.0026,  1.9371],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.9090,  1.8786,  1.7797],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.7303,  1.6739,  1.5512],\n",
      "          ...,\n",
      "          [-0.0426,  0.1304,  0.1645,  ..., -1.6471, -1.5031, -1.3504],\n",
      "          [ 0.0795,  0.2290,  0.2416,  ..., -1.6628, -1.4915, -1.3380],\n",
      "          [ 0.0533,  0.2020,  0.2664,  ..., -1.6777, -1.6603, -1.6353]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.9860,  2.0192,  1.9522],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.9235,  1.8925,  1.7914],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.7408,  1.6832,  1.5578],\n",
      "          ...,\n",
      "          [ 0.1560,  0.3328,  0.3677,  ..., -1.6932, -1.5647, -1.4087],\n",
      "          [ 0.2807,  0.4336,  0.4464,  ..., -1.7092, -1.5529, -1.3960],\n",
      "          [ 0.2540,  0.4060,  0.4718,  ..., -1.7245, -1.7255, -1.6999]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.0425,  2.0756,  2.0089],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.9878,  1.9569,  1.8562],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.8457,  1.7884,  1.6635],\n",
      "          ...,\n",
      "          [ 0.5692,  0.7453,  0.7800,  ..., -1.3825, -1.2484, -1.0930],\n",
      "          [ 0.6934,  0.8456,  0.8584,  ..., -1.3985, -1.2367, -1.0804],\n",
      "          [ 0.6668,  0.8181,  0.8837,  ..., -1.4137, -1.4085, -1.3829]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.4659,  0.5669,  0.7470,  ...,  2.0141,  1.9954,  1.9909],\n",
      "          [-0.1230,  0.1234,  0.5072,  ...,  1.9982,  1.9920,  1.9761],\n",
      "          [-1.2391, -0.9179, -0.4182,  ...,  2.0021,  1.9933,  1.9818],\n",
      "          ...,\n",
      "          [ 1.2177,  1.0307,  0.7661,  ..., -0.8262, -0.8641, -0.8360],\n",
      "          [ 0.8840,  0.7570,  0.4450,  ..., -0.8262, -0.8641, -0.8360],\n",
      "          [ 0.7125,  0.6089,  0.2394,  ..., -0.8160, -0.8607, -0.8212]],\n",
      "\n",
      "         [[ 0.6058,  0.7090,  0.8931,  ...,  2.1885,  2.1694,  2.1648],\n",
      "          [ 0.0038,  0.2556,  0.6479,  ...,  2.1722,  2.1660,  2.1497],\n",
      "          [-1.1373, -0.8090, -0.2981,  ...,  2.1762,  2.1673,  2.1555],\n",
      "          ...,\n",
      "          [ 1.3743,  1.1832,  0.9127,  ..., -0.7152, -0.7540, -0.7252],\n",
      "          [ 1.0332,  0.9033,  0.5844,  ..., -0.7152, -0.7540, -0.7252],\n",
      "          [ 0.8579,  0.7519,  0.3742,  ..., -0.7047, -0.7505, -0.7101]],\n",
      "\n",
      "         [[ 0.8253,  0.9281,  1.1114,  ...,  2.4010,  2.3820,  2.3774],\n",
      "          [ 0.2260,  0.4767,  0.8673,  ...,  2.3848,  2.3786,  2.3624],\n",
      "          [-0.9100, -0.5832, -0.0745,  ...,  2.3888,  2.3799,  2.3682],\n",
      "          ...,\n",
      "          [ 1.5904,  1.4001,  1.1309,  ..., -0.4898, -0.5284, -0.4997],\n",
      "          [ 1.2508,  1.1215,  0.8041,  ..., -0.4898, -0.5284, -0.4997],\n",
      "          [ 1.0763,  0.9708,  0.5947,  ..., -0.4794, -0.5249, -0.4847]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0057,  2.0241,  2.0351,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.9616,  1.9970,  1.9848,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.0229,  1.9712,  1.9518,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.0423,  2.0719,  2.1225,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.0298,  2.0690,  2.0673,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.0862,  2.0334,  2.0157,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.2231,  2.2448,  2.2548,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.2580,  2.2865,  2.2391,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.3938,  2.3351,  2.2803,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-1.1773, -1.1773, -1.1773,  ..., -0.3748, -0.3553, -0.3516],\n",
      "          [-1.1932, -1.1932, -1.1932,  ..., -0.3430, -0.3235, -0.3198],\n",
      "          [-1.1809, -1.1809, -1.1809,  ..., -0.3430, -0.3235, -0.3198],\n",
      "          ...,\n",
      "          [-1.8524, -1.7513, -1.5674,  ..., -1.9763, -1.9037, -1.8712],\n",
      "          [-1.9099, -1.9187, -1.8209,  ..., -1.9909, -1.9055, -1.8436],\n",
      "          [-1.8354, -1.8512, -1.7668,  ..., -2.0572, -2.0022, -1.9282]],\n",
      "\n",
      "         [[-0.2688, -0.2688, -0.2688,  ...,  0.7054,  0.7254,  0.7291],\n",
      "          [-0.2850, -0.2850, -0.2850,  ...,  0.6891,  0.7091,  0.7129],\n",
      "          [-0.2850, -0.2850, -0.2850,  ...,  0.6891,  0.7091,  0.7129],\n",
      "          ...,\n",
      "          [-1.9710, -1.8782, -1.7055,  ..., -1.8734, -1.7992, -1.7660],\n",
      "          [-2.0357, -2.0084, -1.9484,  ..., -1.8883, -1.8011, -1.7378],\n",
      "          [-1.9742, -1.9830, -1.8985,  ..., -1.9561, -1.8999, -1.8243]],\n",
      "\n",
      "         [[ 1.4536,  1.4536,  1.4536,  ...,  2.3549,  2.3748,  2.3786],\n",
      "          [ 1.4374,  1.4374,  1.4374,  ...,  2.3549,  2.3748,  2.3786],\n",
      "          [ 1.4436,  1.4436,  1.4436,  ...,  2.3549,  2.3748,  2.3786],\n",
      "          ...,\n",
      "          [-1.7586, -1.6801, -1.5720,  ..., -1.6080, -1.5341, -1.5010],\n",
      "          [-1.7399, -1.7689, -1.7300,  ..., -1.6229, -1.5360, -1.4730],\n",
      "          [-1.5940, -1.6550, -1.6644,  ..., -1.6904, -1.6344, -1.5591]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.8754, -1.6442, -1.0126,  ...,  0.6090,  0.6269,  0.5132],\n",
      "          [-1.9950, -1.7807, -1.3940,  ...,  0.6965,  0.7171,  0.6083],\n",
      "          [-2.0806, -2.0402, -1.9303,  ...,  0.8621,  0.9348,  0.8552],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.2755, -0.3934, -0.1354],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.2666, -0.3165, -0.0827],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.0386, -0.1100, -0.2015]],\n",
      "\n",
      "         [[-1.8054, -1.5689, -0.9232,  ...,  0.6821,  0.7004,  0.5841],\n",
      "          [-1.9275, -1.7085, -1.3132,  ...,  0.7715,  0.7926,  0.6814],\n",
      "          [-2.0151, -1.9738, -1.8614,  ...,  0.9407,  1.0151,  0.9338],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.2222, -0.3427, -0.0790],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.2131, -0.2641, -0.0251],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.0200, -0.0530, -0.1466]],\n",
      "\n",
      "         [[-1.6100, -1.3746, -0.7317,  ...,  0.8490,  0.8672,  0.7514],\n",
      "          [-1.7247, -1.5136, -1.1200,  ...,  0.9380,  0.9590,  0.8483],\n",
      "          [-1.7971, -1.7652, -1.6556,  ...,  1.1065,  1.1806,  1.0996],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.0513, -0.1713,  0.0913],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.0422, -0.0930,  0.1450],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.1899,  0.1171,  0.0240]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  0.1487,  0.1426,  0.1426],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.1474,  0.1426,  0.1426],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.1426,  0.1378,  0.1364],\n",
      "          ...,\n",
      "          [-1.9356, -1.9380, -1.9528,  ..., -1.9467, -1.9480, -1.9308],\n",
      "          [-1.9295, -1.9332, -1.9528,  ..., -1.9223, -1.9332, -1.9298],\n",
      "          [-1.9295, -1.9332, -1.9528,  ..., -1.9014, -1.9261, -1.9295]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  0.4740,  0.4678,  0.4678],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.4727,  0.4678,  0.4678],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.4678,  0.4629,  0.4615],\n",
      "          ...,\n",
      "          [-1.8669, -1.8693, -1.8844,  ..., -1.8782, -1.8795, -1.8619],\n",
      "          [-1.8606, -1.8644, -1.8844,  ..., -1.8532, -1.8644, -1.8609],\n",
      "          [-1.8606, -1.8644, -1.8844,  ..., -1.8319, -1.8572, -1.8606]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  0.7290,  0.7228,  0.7228],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.7277,  0.7228,  0.7228],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.7228,  0.7179,  0.7166],\n",
      "          ...,\n",
      "          [-1.6712, -1.6736, -1.6887,  ..., -1.6824, -1.6838, -1.6663],\n",
      "          [-1.6650, -1.6687, -1.6887,  ..., -1.6576, -1.6687, -1.6653],\n",
      "          [-1.6650, -1.6687, -1.6887,  ..., -1.6364, -1.6615, -1.6650]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.9179, -0.8984, -0.8788,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.9145, -0.8984, -0.8788,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.8955, -0.8861, -0.8688,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-2.1008, -2.1008, -2.1008,  ..., -0.7478, -0.6717, -0.5099],\n",
      "          [-2.1008, -2.1008, -2.1008,  ..., -0.5797, -0.4973, -0.1398],\n",
      "          [-2.1008, -2.1008, -2.1008,  ..., -0.5201, -0.4791, -0.0443]],\n",
      "\n",
      "         [[ 0.0839,  0.1039,  0.1239,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.0874,  0.1039,  0.1239,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.0943,  0.1039,  0.1217,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.7381, -1.7381, -1.7381,  ..., -0.8781, -0.8284, -0.6715],\n",
      "          [-1.7381, -1.7381, -1.7381,  ..., -0.7183, -0.6590, -0.3191],\n",
      "          [-1.7381, -1.7381, -1.7381,  ..., -0.6690, -0.6404, -0.2285]],\n",
      "\n",
      "         [[ 1.4386,  1.4585,  1.4785,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4421,  1.4585,  1.4785,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4553,  1.4648,  1.4825,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.0662, -1.0662, -1.0662,  ..., -0.9100, -0.9786, -0.8795],\n",
      "          [-1.0724, -1.0724, -1.0724,  ..., -0.7469, -0.8086, -0.5160],\n",
      "          [-1.0724, -1.0724, -1.0724,  ..., -0.6920, -0.7901, -0.4223]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6826,  1.6826,  1.6773,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.6669,  1.6703,  1.6738,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.6744,  1.6960,  1.6921,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.0383, -1.0543, -1.0389],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.1290, -0.9792, -0.7765],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.8726, -0.8516, -0.9021]],\n",
      "\n",
      "         [[ 1.9696,  1.9696,  1.9513,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.9061,  1.9096,  1.8984,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.8213,  1.8433,  1.8393,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.1071, -1.1235, -1.1077],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.1998, -1.0467, -0.8394],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.9377, -0.9162, -0.9679]],\n",
      "\n",
      "         [[ 2.0462,  2.0623,  2.0503,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.0063,  2.0225,  2.0163,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.9607,  1.9827,  1.9787,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.9148, -0.9311, -0.9154],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.0071, -0.8546, -0.6483],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.7461, -0.7248, -0.7612]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.5002, -1.4965, -1.4791,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.5445, -1.5312, -1.5222,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.5516, -1.5357, -1.5295,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.6668, -1.6631, -1.6453,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.7121, -1.6985, -1.6893,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.7193, -1.7031, -1.6968,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.7920, -1.7907, -1.7818,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.8044, -1.8044, -1.8031,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[ 2.2489,  2.2489,  2.2489,  ..., -0.3472, -0.3538, -0.3541],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.3369, -0.3475, -0.3538],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.3347, -0.3369, -0.3472],\n",
      "          ...,\n",
      "          [ 1.6508,  1.6667,  1.6728,  ...,  1.5921,  1.5921,  1.5921],\n",
      "          [ 1.6508,  1.6667,  1.6728,  ...,  1.5982,  1.5982,  1.5982],\n",
      "          [ 1.6508,  1.6667,  1.6728,  ...,  1.6141,  1.6141,  1.6141]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  0.9300,  0.9232,  0.9230],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.9405,  0.9297,  0.9232],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.9427,  0.9405,  0.9300],\n",
      "          ...,\n",
      "          [ 1.9221,  1.9384,  1.9446,  ...,  1.9334,  1.9334,  1.9334],\n",
      "          [ 1.9221,  1.9384,  1.9446,  ...,  1.9209,  1.9209,  1.9209],\n",
      "          [ 1.9221,  1.9384,  1.9446,  ...,  1.9046,  1.9046,  1.9046]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.0544,  2.0477,  2.0474],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.0648,  2.0541,  2.0477],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.0671,  2.0648,  2.0544],\n",
      "          ...,\n",
      "          [ 2.4147,  2.4308,  2.4371,  ...,  2.4022,  2.4022,  2.4022],\n",
      "          [ 2.4147,  2.4308,  2.4371,  ...,  2.3960,  2.3960,  2.3960],\n",
      "          [ 2.4147,  2.4308,  2.4371,  ...,  2.3960,  2.3960,  2.3960]]],\n",
      "\n",
      "\n",
      "        [[[-1.0964, -1.0047, -0.9376,  ..., -1.8104, -1.5367, -1.4233],\n",
      "          [-1.2028, -1.0515, -0.8120,  ..., -1.5076, -1.3037, -1.3921],\n",
      "          [-0.9563, -1.0143, -1.1556,  ..., -1.4029, -1.3039, -1.3328],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.3424,  0.0569, -1.0042],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.3801, -0.1196, -0.9835],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.3313, -0.1760, -0.9790]],\n",
      "\n",
      "         [[-0.9940, -0.9202, -0.8716,  ..., -1.4173, -1.0509, -0.8742],\n",
      "          [-1.1262, -0.9880, -0.7618,  ..., -1.1354, -0.8224, -0.8527],\n",
      "          [-0.9070, -0.9700, -1.1260,  ..., -1.0146, -0.8294, -0.8313],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.6018,  0.2893, -0.8096],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.6292,  0.1223, -0.7569],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.6093,  0.0878, -0.7477]],\n",
      "\n",
      "         [[-1.3799, -1.1777, -0.9712,  ..., -1.7662, -1.5371, -1.4610],\n",
      "          [-1.3753, -1.1456, -0.8056,  ..., -1.5071, -1.3136, -1.4367],\n",
      "          [-0.9480, -0.9740, -1.0665,  ..., -1.4315, -1.3458, -1.4042],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.7540, -0.4075, -1.3975],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.7960, -0.5711, -1.3139],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.7866, -0.5765, -1.2954]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.0027,  0.0077,  0.0435],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.0972,  0.0863,  0.0931],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.2262,  0.2071,  0.2037]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.1267,  0.1374,  0.1739],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.2289,  0.2177,  0.2247],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.3607,  0.3412,  0.3377]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.3483,  0.3590,  0.3954],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.4501,  0.4389,  0.4459],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.5813,  0.5619,  0.5585]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2856, -0.2856, -0.2860,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.2892, -0.2892, -0.2953,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.3210, -0.3223, -0.3311,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.1259, -1.1431, -1.1396,  ..., -1.5638, -1.5430, -1.5039],\n",
      "          [-1.1797, -1.1927, -1.1760,  ..., -1.4966, -1.4912, -1.4424],\n",
      "          [-1.2569, -1.2577, -1.2450,  ..., -1.4970, -1.5014, -1.4500]],\n",
      "\n",
      "         [[-0.2850, -0.2850, -0.2855,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.2888, -0.2888, -0.2950,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.3025, -0.3039, -0.3128,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.1616, -1.1792, -1.1756,  ..., -1.5218, -1.5005, -1.4605],\n",
      "          [-1.2166, -1.2299, -1.2129,  ..., -1.4531, -1.4475, -1.3977],\n",
      "          [-1.2955, -1.2964, -1.2834,  ..., -1.4534, -1.4580, -1.4055]],\n",
      "\n",
      "         [[-0.2358, -0.2358, -0.2363,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.2396, -0.2396, -0.2458,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.2595, -0.2608, -0.2697,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.1260, -1.1435, -1.1399,  ..., -1.4148, -1.3936, -1.3538],\n",
      "          [-1.1807, -1.1940, -1.1770,  ..., -1.3464, -1.3409, -1.2913],\n",
      "          [-1.2592, -1.2601, -1.2472,  ..., -1.3468, -1.3513, -1.2990]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4679,  0.4236,  0.4610,  ...,  0.6392,  0.6392,  0.6392],\n",
      "          [ 0.5335,  0.4782,  0.5059,  ...,  0.6392,  0.6392,  0.6392],\n",
      "          [ 0.5678,  0.4776,  0.4856,  ...,  0.6392,  0.6392,  0.6392],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 0.6078,  0.5626,  0.6008,  ...,  0.7829,  0.7829,  0.7829],\n",
      "          [ 0.6748,  0.6183,  0.6466,  ...,  0.7829,  0.7829,  0.7829],\n",
      "          [ 0.7099,  0.6178,  0.6259,  ...,  0.7829,  0.7829,  0.7829],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 0.8274,  0.7823,  0.8203,  ...,  1.0017,  1.0017,  1.0017],\n",
      "          [ 0.8941,  0.8378,  0.8660,  ...,  1.0017,  1.0017,  1.0017],\n",
      "          [ 0.9290,  0.8372,  0.8453,  ...,  1.0017,  1.0017,  1.0017],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0777,  2.0777,  2.0777,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.0777,  2.0777,  2.0777,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.0777,  2.0777,  2.0777,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.9416, -1.9105, -1.6982,  ...,  0.5579,  0.5529,  0.4591],\n",
      "          [-1.9031, -1.8887, -1.7274,  ...,  0.4388,  0.4969,  0.5309],\n",
      "          [-1.9521, -1.8210, -1.5801,  ...,  0.3467,  0.3696,  0.4362]],\n",
      "\n",
      "         [[ 2.2535,  2.2535,  2.2535,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.2535,  2.2535,  2.2535,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.2535,  2.2535,  2.2535,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.7738, -1.7536, -1.5384,  ...,  0.0688,  0.0793, -0.0035],\n",
      "          [-1.7461, -1.7314, -1.5728,  ..., -0.0599,  0.0296,  0.0767],\n",
      "          [-1.7962, -1.6622, -1.4222,  ..., -0.1471, -0.0957, -0.0198]],\n",
      "\n",
      "         [[ 2.4657,  2.4657,  2.4657,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.4657,  2.4657,  2.4657,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.4657,  2.4657,  2.4657,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.7874, -1.7749, -1.6203,  ..., -0.3427, -0.3002, -0.3709],\n",
      "          [-1.7609, -1.7645, -1.6523,  ..., -0.6156, -0.5065, -0.4561],\n",
      "          [-1.7962, -1.7015, -1.5024,  ..., -0.8024, -0.7129, -0.6304]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1940,  0.1988,  0.2245,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.1988,  0.2184,  0.2441,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.2184,  0.2380,  0.2615,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.7048, -1.6945, -1.6721,  ..., -1.3974, -1.3339, -1.3159],\n",
      "          [-1.8970, -1.8699, -1.8413,  ..., -1.2325, -1.2151, -1.2252],\n",
      "          [-2.0669, -1.9655, -1.9258,  ..., -1.0297, -1.0542, -1.0917]],\n",
      "\n",
      "         [[ 0.8530,  0.8579,  0.8842,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.8579,  0.8780,  0.9042,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.8780,  0.8980,  0.9220,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.6309, -1.6204, -1.5975,  ..., -0.5314, -0.4664, -0.3993],\n",
      "          [-1.8274, -1.7997, -1.7704,  ..., -0.2427, -0.2249, -0.2248],\n",
      "          [-2.0173, -1.9137, -1.8731,  ...,  0.0522,  0.0271, -0.0112]],\n",
      "\n",
      "         [[ 1.7338,  1.7387,  1.7648,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.7387,  1.7586,  1.7847,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.7586,  1.7785,  1.8024,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.2745, -1.2640, -1.2412,  ...,  0.2920,  0.3567,  0.4074],\n",
      "          [-1.4576, -1.4301, -1.4009,  ...,  0.6143,  0.6320,  0.6286],\n",
      "          [-1.5981, -1.4950, -1.4545,  ...,  0.9190,  0.8941,  0.8559]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.0429,  1.8436,  2.0121],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.0566,  1.9707,  1.9904],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.5448,  1.7258,  1.6980],\n",
      "          ...,\n",
      "          [-1.7158, -1.7214, -1.7270,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.6883, -1.7232, -1.7582,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.8035, -1.8461, -1.8864,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.0813,  1.9049,  2.0815],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.0755,  2.0228,  2.0587],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.5481,  1.7511,  1.7462],\n",
      "          ...,\n",
      "          [-1.6422, -1.6479, -1.6536,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.6140, -1.6498, -1.6855,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.7318, -1.7753, -1.8165,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.1270,  1.9172,  2.0853],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.1268,  2.0394,  2.0629],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.5860,  1.7653,  1.7461],\n",
      "          ...,\n",
      "          [-1.4475, -1.4532, -1.4589,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.4195, -1.4551, -1.4906,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.5368, -1.5801, -1.6211,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3823,  0.3823,  0.3823,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.3823,  0.3823,  0.3823,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.3884,  0.3884,  0.3884,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.7164, -1.8069, -1.7474,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.6193, -1.8122, -1.7840,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.4870, -1.6448, -1.6752,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 0.9230,  0.9230,  0.9230,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.9230,  0.9230,  0.9230,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.9292,  0.9292,  0.9292,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.5903, -1.6827, -1.6219,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.4909, -1.6882, -1.6593,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.3557, -1.5170, -1.5481,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.3851,  1.3851,  1.3851,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.3851,  1.3851,  1.3851,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.3913,  1.3913,  1.3913,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.4133, -1.5053, -1.4447,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.3144, -1.5107, -1.4820,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.1797, -1.3403, -1.3713,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [-2.1069, -2.1093, -2.1179,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.1008, -2.1016, -2.1093,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.1008, -2.1008, -2.1069,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.7790, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.7698, -1.7790, -1.8044,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  0.5495,  0.5198,  0.5716],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.6482,  0.5494,  0.5973],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.7176,  0.2961, -0.0142],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  0.7358,  0.6854,  0.7313],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.8159,  0.7087,  0.7576],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.8869,  0.4497,  0.1325],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  0.8585,  0.7965,  0.8133],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.9459,  0.8232,  0.8395],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.0068,  0.5653,  0.2172],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-0.2207, -0.3755, -0.6316,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.1634, -0.2954, -0.4943,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.3132, -0.3547, -0.4510,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.4359,  0.4446,  0.4561],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.4141,  0.4202,  0.4361],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.3945,  0.4132,  0.4177]],\n",
      "\n",
      "         [[-0.1262, -0.2370, -0.4071,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.0241, -0.1142, -0.2386,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.0999, -0.1184, -0.1571,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.5926,  0.6015,  0.6133],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.5703,  0.5766,  0.5928],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.5503,  0.5693,  0.5740]],\n",
      "\n",
      "         [[-0.3391, -0.4290, -0.5930,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.2567, -0.3269, -0.4646,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.3602, -0.3761, -0.3945,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.8993,  0.9082,  0.9199],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.8772,  0.8834,  0.8996],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.8572,  0.8762,  0.8808]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[ 2.1107,  2.0945,  2.0879,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.1070,  2.0882,  2.0764,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.0818,  2.0702,  2.0615,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 0.0373,  0.0775,  0.2126,  ..., -0.6345, -0.3418, -0.1605],\n",
      "          [ 0.3704,  0.3451,  0.4319,  ..., -0.5668, -0.4159, -0.4340],\n",
      "          [ 0.5754,  0.5492,  0.5903,  ..., -0.1076, -0.4323, -0.5508]],\n",
      "\n",
      "         [[ 2.2347,  2.2182,  2.2114,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.2310,  2.2118,  2.1996,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.2052,  2.1934,  2.1845,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-0.0888, -0.0477,  0.0825,  ..., -0.9331, -0.6388, -0.4548],\n",
      "          [ 0.2318,  0.1971,  0.2506,  ..., -0.8426, -0.6884, -0.7069],\n",
      "          [ 0.4051,  0.3775,  0.4165,  ..., -0.3657, -0.6976, -0.8188]],\n",
      "\n",
      "         [[ 2.3599,  2.3434,  2.3367,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.3562,  2.3370,  2.3249,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.3305,  2.3187,  2.3098,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-0.7625, -0.7216, -0.5880,  ..., -1.5558, -1.2530, -1.0672],\n",
      "          [-0.6015, -0.6273, -0.5403,  ..., -1.4670, -1.3134, -1.3318],\n",
      "          [-0.5175, -0.5141, -0.4724,  ..., -0.9959, -1.3263, -1.4470]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -1.6568, -1.5856, -1.5132],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -1.9664, -1.9115, -1.8478],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -1.9928, -1.9827, -1.9603]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-2.0182, -2.0182, -2.0182,  ..., -1.3892, -1.3115, -1.2362],\n",
      "          [-2.0182, -2.0182, -2.0182,  ..., -1.7333, -1.6772, -1.6121],\n",
      "          [-2.0182, -2.0182, -2.0182,  ..., -1.7677, -1.7574, -1.7345]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.6999, -1.6999, -1.6999,  ..., -1.1372, -1.0598, -0.9848],\n",
      "          [-1.6999, -1.6999, -1.6999,  ..., -1.4722, -1.4164, -1.3516],\n",
      "          [-1.6999, -1.6999, -1.6999,  ..., -1.5028, -1.4925, -1.4697]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4786,  1.0368,  0.5639,  ...,  2.0605,  2.0605,  2.0605],\n",
      "          [ 1.4530,  1.1195,  0.6745,  ...,  2.0605,  2.0605,  2.0605],\n",
      "          [ 1.4262,  1.2586,  0.9582,  ...,  2.0667,  2.0667,  2.0667],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.1487, -1.0597, -0.9721],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.9147, -0.9181, -0.9146],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.6389, -0.8673, -1.0643]],\n",
      "\n",
      "         [[ 1.6411,  1.1894,  0.7059,  ...,  2.2535,  2.2535,  2.2535],\n",
      "          [ 1.6149,  1.2739,  0.8190,  ...,  2.2535,  2.2535,  2.2535],\n",
      "          [ 1.5875,  1.4161,  1.1090,  ...,  2.2598,  2.2598,  2.2598],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.0974, -1.0064, -0.9169],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.8582, -0.8617, -0.8581],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.5762, -0.8097, -1.0111]],\n",
      "\n",
      "         [[ 1.8560,  1.4064,  0.9250,  ...,  2.3786,  2.3786,  2.3786],\n",
      "          [ 1.8299,  1.4905,  1.0376,  ...,  2.3786,  2.3786,  2.3786],\n",
      "          [ 1.8027,  1.6320,  1.3263,  ...,  2.3848,  2.3848,  2.3848],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.1790, -1.0584, -0.9529],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.9311, -0.9045, -0.8935],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.6477, -0.8528, -1.0458]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.3473, -1.3473, -1.3534,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.3473, -1.3473, -1.3521,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.3412, -1.3412, -1.3412,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-2.1122, -2.1179, -2.0751,  ..., -0.1489, -0.1511, -0.1475],\n",
      "          [-2.1179, -2.1179, -2.0799,  ..., -0.2163, -0.1669, -0.2362],\n",
      "          [-2.1179, -2.1179, -2.0812,  ..., -0.2736, -0.1840, -0.3078]],\n",
      "\n",
      "         [[ 0.1527,  0.1527,  0.1589,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.1564,  0.1564,  0.1613,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.1764,  0.1764,  0.1764,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.9961, -2.0145, -1.9569,  ...,  0.0473,  0.0450,  0.0487],\n",
      "          [-2.0020, -2.0174, -1.9707,  ..., -0.0216,  0.0289, -0.0420],\n",
      "          [-2.0020, -2.0182, -1.9744,  ..., -0.0802,  0.0114, -0.1152]],\n",
      "\n",
      "         [[ 1.8557,  1.8557,  1.8557,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.8482,  1.8482,  1.8482,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.8271,  1.8271,  1.8271,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.7825, -1.8007, -1.7434,  ...,  0.0253,  0.0230,  0.0267],\n",
      "          [-1.7883, -1.8036, -1.7571,  ..., -0.0433,  0.0069, -0.0636],\n",
      "          [-1.7883, -1.8044, -1.7609,  ..., -0.1016, -0.0105, -0.1365]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ..., -0.2912, -0.9726, -1.2985],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.6809, -1.2975, -1.5381],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.2083, -1.5627, -1.4831],\n",
      "          ...,\n",
      "          [-2.0263, -2.0311, -2.0524,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.0570, -2.0265, -2.0311,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.0811, -2.0570, -2.0206,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -0.6393, -1.3094, -1.6194],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.0168, -1.6258, -1.8566],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.5560, -1.8645, -1.7719],\n",
      "          ...,\n",
      "          [-1.9770, -1.9819, -2.0037,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0085, -1.9773, -1.9819,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0331, -2.0085, -1.9712,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ..., -0.6234, -1.0254, -1.1721],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.9992, -1.3492, -1.4126],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.5160, -1.6124, -1.3438],\n",
      "          ...,\n",
      "          [-1.7286, -1.7335, -1.7552,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.7599, -1.7289, -1.7335,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.7844, -1.7599, -1.7228,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-1.2421, -1.2421, -1.2364,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.2064, -1.2030, -1.2030,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.1985, -1.1883, -1.1861,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.2852,  0.2544,  0.0073],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.4085,  0.1847, -0.2391],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.0460, -0.1374, -0.3235]],\n",
      "\n",
      "         [[ 0.0851,  0.0851,  0.0909,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.1217,  0.1252,  0.1252,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.1422,  0.1527,  0.1549,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.2891,  0.2557, -0.0143],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.4133,  0.1782, -0.2550],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.0322, -0.1673, -0.3575]],\n",
      "\n",
      "         [[ 1.5619,  1.5619,  1.5677,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.5983,  1.6017,  1.6017,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.6187,  1.6291,  1.6313,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.1275,  0.0797, -0.2157],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.3026,  0.0610, -0.3772],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.0382, -0.2431, -0.4325]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  6.0354e-01,\n",
      "            7.4490e-01,  4.3997e-01],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  1.4728e-01,\n",
      "            3.9760e-01,  5.8432e-01],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -2.1819e-01,\n",
      "           -3.8468e-02,  3.4090e-01],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  7.7242e-01,\n",
      "            6.6897e-01,  5.1205e-01],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  5.7322e-01,\n",
      "            6.0467e-01,  5.7225e-01],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  4.6252e-01,\n",
      "            5.2350e-01,  5.8449e-01]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  8.1900e-01,\n",
      "            8.0515e-01,  4.2446e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  3.5122e-01,\n",
      "            4.8842e-01,  5.7551e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -3.1342e-02,\n",
      "            3.6365e-02,  3.2622e-01],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  6.0400e-01,\n",
      "            4.9824e-01,  3.3782e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  4.0035e-01,\n",
      "            4.3251e-01,  3.9937e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.8718e-01,\n",
      "            3.4952e-01,  4.1187e-01]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  1.2866e+00,\n",
      "            1.3253e+00,  9.4456e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  8.2488e-01,\n",
      "            9.9730e-01,  1.1238e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  4.7069e-01,\n",
      "            5.6593e-01,  8.8855e-01],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  1.0407e+00,\n",
      "            9.2740e-01,  7.6769e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  8.6000e-01,\n",
      "            8.6782e-01,  8.2896e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  7.5213e-01,\n",
      "            7.8681e-01,  8.4141e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4134e-01,  1.4134e-01,  1.4134e-01,  ...,  2.4531e-01,\n",
      "            2.4531e-01,  2.4531e-01],\n",
      "          [ 1.1810e-01,  1.1810e-01,  1.1810e-01,  ...,  2.4898e-01,\n",
      "            2.4898e-01,  2.4898e-01],\n",
      "          [ 9.1189e-02,  9.1189e-02,  9.1189e-02,  ...,  2.6244e-01,\n",
      "            2.6244e-01,  2.6244e-01],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -6.8851e-01,\n",
      "           -6.8423e-01, -6.7165e-01],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -7.0267e-01,\n",
      "           -6.7864e-01, -6.4369e-01],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -7.9886e-01,\n",
      "           -7.6627e-01, -7.1236e-01]],\n",
      "\n",
      "         [[ 8.1383e-02,  8.1383e-02,  8.1383e-02,  ...,  1.3515e-01,\n",
      "            1.3515e-01,  1.3515e-01],\n",
      "          [ 5.7623e-02,  5.7623e-02,  5.7623e-02,  ...,  1.3891e-01,\n",
      "            1.3891e-01,  1.3891e-01],\n",
      "          [ 3.0112e-02,  3.0112e-02,  3.0112e-02,  ...,  1.5266e-01,\n",
      "            1.5266e-01,  1.5266e-01],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -9.5957e-01,\n",
      "           -9.5519e-01, -9.4233e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -9.7404e-01,\n",
      "           -9.4948e-01, -9.1375e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -1.0724e+00,\n",
      "           -1.0391e+00, -9.8395e-01]],\n",
      "\n",
      "         [[ 8.6098e-01,  8.6098e-01,  8.6098e-01,  ...,  7.9251e-01,\n",
      "            7.9251e-01,  7.9251e-01],\n",
      "          [ 8.3732e-01,  8.3732e-01,  8.3732e-01,  ...,  7.9624e-01,\n",
      "            7.9624e-01,  7.9624e-01],\n",
      "          [ 8.0993e-01,  8.0993e-01,  8.0993e-01,  ...,  8.0993e-01,\n",
      "            8.0993e-01,  8.0993e-01],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -9.7709e-01,\n",
      "           -9.7273e-01, -9.5993e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -9.9150e-01,\n",
      "           -9.6704e-01, -9.3147e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -1.0894e+00,\n",
      "           -1.0562e+00, -1.0014e+00]]],\n",
      "\n",
      "\n",
      "        [[[-4.0193e-01, -4.4929e-01, -4.2264e-01,  ..., -4.9498e-01,\n",
      "           -3.5344e-01, -2.5209e-01],\n",
      "          [-2.8730e-01, -3.8778e-01, -4.4361e-01,  ..., -4.2771e-01,\n",
      "           -4.3950e-01, -4.5916e-01],\n",
      "          [-2.0238e-01, -3.3807e-01, -4.4579e-01,  ..., -4.4457e-01,\n",
      "           -6.0341e-01, -7.1123e-01],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[-7.1357e-02, -1.1977e-01, -9.2526e-02,  ..., -1.3147e-01,\n",
      "            1.3231e-02,  1.1684e-01],\n",
      "          [ 4.5833e-02, -5.6887e-02, -1.1396e-01,  ..., -6.2693e-02,\n",
      "           -7.4751e-02, -9.4849e-02],\n",
      "          [ 1.3891e-01,  1.8936e-04, -1.0994e-01,  ..., -7.9934e-02,\n",
      "           -2.4232e-01, -3.5254e-01],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 3.6033e-01,  3.1214e-01,  3.3926e-01,  ...,  1.4363e-01,\n",
      "            2.8768e-01,  3.9084e-01],\n",
      "          [ 4.7700e-01,  3.7474e-01,  3.1792e-01,  ...,  2.1210e-01,\n",
      "            2.0009e-01,  1.8008e-01],\n",
      "          [ 5.5099e-01,  4.1289e-01,  3.0324e-01,  ...,  1.9493e-01,\n",
      "            3.3268e-02, -7.6466e-02],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.5810e+00,  1.5810e+00,  1.5872e+00,  ...,  1.8387e+00,\n",
      "            1.8516e+00,  1.8550e+00],\n",
      "          [ 1.5810e+00,  1.5810e+00,  1.5872e+00,  ...,  1.8502e+00,\n",
      "            1.8579e+00,  1.8587e+00],\n",
      "          [ 1.5810e+00,  1.5810e+00,  1.5872e+00,  ...,  1.8612e+00,\n",
      "            1.8698e+00,  1.8778e+00],\n",
      "          ...,\n",
      "          [-2.1148e+00, -2.0526e+00, -1.9350e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [-1.9419e+00, -1.7031e+00, -1.4779e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [-1.7953e+00, -1.4552e+00, -1.2326e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[ 1.7633e+00,  1.7633e+00,  1.7696e+00,  ...,  2.0267e+00,\n",
      "            2.0399e+00,  2.0434e+00],\n",
      "          [ 1.7633e+00,  1.7633e+00,  1.7696e+00,  ...,  2.0385e+00,\n",
      "            2.0464e+00,  2.0472e+00],\n",
      "          [ 1.7633e+00,  1.7633e+00,  1.7696e+00,  ...,  2.0497e+00,\n",
      "            2.0585e+00,  2.0667e+00],\n",
      "          ...,\n",
      "          [-1.7896e+00, -1.6888e+00, -1.5628e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [-1.5996e+00, -1.3415e+00, -1.1238e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [-1.4457e+00, -1.1281e+00, -9.0142e-01,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 2.0474e+00,  2.0474e+00,  2.0536e+00,  ...,  2.3096e+00,\n",
      "            2.3228e+00,  2.3263e+00],\n",
      "          [ 2.0474e+00,  2.0474e+00,  2.0536e+00,  ...,  2.3214e+00,\n",
      "            2.3292e+00,  2.3300e+00],\n",
      "          [ 2.0474e+00,  2.0474e+00,  2.0536e+00,  ...,  2.3325e+00,\n",
      "            2.3413e+00,  2.3495e+00],\n",
      "          ...,\n",
      "          [-1.4495e+00, -1.3433e+00, -1.2178e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [-1.2757e+00, -1.0187e+00, -7.9711e-01,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [-1.1287e+00, -7.9755e-01, -5.7142e-01,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5797e-01,  8.6573e-01,  6.7728e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 6.9388e-01,  7.5329e-01,  6.3158e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 7.3485e-01,  6.9143e-01,  6.1358e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          ...,\n",
      "          [-1.5100e-01, -2.3881e-01, -3.7607e-01,  ..., -1.0683e+00,\n",
      "           -1.1998e+00, -1.3820e+00],\n",
      "          [-2.5891e-01, -3.2662e-01, -4.2159e-01,  ..., -1.0591e+00,\n",
      "           -1.2226e+00, -1.3472e+00],\n",
      "          [-4.4728e-01, -4.5051e-01, -4.6869e-01,  ..., -1.2006e+00,\n",
      "           -1.3416e+00, -1.2889e+00]],\n",
      "\n",
      "         [[ 5.4300e-01,  7.8845e-01,  6.2303e-01,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 5.8578e-01,  6.4822e-01,  5.6113e-01,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 6.0356e-01,  6.0097e-01,  5.3862e-01,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          ...,\n",
      "          [-2.3660e-01, -3.4620e-01, -4.8259e-01,  ..., -1.2366e+00,\n",
      "           -1.3248e+00, -1.4880e+00],\n",
      "          [-3.7237e-01, -4.3499e-01, -5.3896e-01,  ..., -1.2569e+00,\n",
      "           -1.3947e+00, -1.4749e+00],\n",
      "          [-5.7165e-01, -5.5870e-01, -5.8978e-01,  ..., -1.4081e+00,\n",
      "           -1.5387e+00, -1.4660e+00]],\n",
      "\n",
      "         [[-9.9354e-01, -7.4775e-01, -8.4148e-01,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [-8.4619e-01, -7.5754e-01, -8.0271e-01,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [-6.3224e-01, -6.4220e-01, -6.5376e-01,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          ...,\n",
      "          [-7.0969e-01, -8.1827e-01, -1.0027e+00,  ..., -1.3104e+00,\n",
      "           -1.4700e+00, -1.6891e+00],\n",
      "          [-8.3464e-01, -9.3405e-01, -1.0539e+00,  ..., -1.2071e+00,\n",
      "           -1.4255e+00, -1.5456e+00],\n",
      "          [-1.0304e+00, -1.0660e+00, -1.1032e+00,  ..., -1.2970e+00,\n",
      "           -1.4819e+00, -1.4640e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]]], device='cuda:0')\n",
      "tensor([[[[-2.0996, -2.0996, -2.0996,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.0800, -2.0800, -2.0800,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.0665, -2.0652, -2.0604,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.6762, -1.6981, -1.7424,  ..., -1.6338, -1.6598, -1.8331],\n",
      "          [-1.5890, -1.6568, -1.7011,  ..., -1.6228, -1.5851, -1.5923],\n",
      "          [-1.5430, -1.6142, -1.6250,  ..., -1.5828, -1.6147, -1.5722]],\n",
      "\n",
      "         [[-1.4742, -1.4742, -1.4742,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.4542, -1.4542, -1.4542,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.4405, -1.4391, -1.4342,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.4441, -1.4665, -1.5118,  ..., -1.4345, -1.4611, -1.6382],\n",
      "          [-1.3412, -1.4134, -1.4695,  ..., -1.4420, -1.4035, -1.4108],\n",
      "          [-1.2904, -1.3670, -1.3918,  ..., -1.4011, -1.4338, -1.3903]],\n",
      "\n",
      "         [[-0.8795, -0.8795, -0.8795,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.8595, -0.8595, -0.8595,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.8458, -0.8445, -0.8396,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.6338, -1.6560, -1.7011,  ..., -1.5831, -1.6096, -1.7397],\n",
      "          [-1.5724, -1.6355, -1.6591,  ..., -1.5968, -1.5585, -1.5658],\n",
      "          [-1.5330, -1.5981, -1.5817,  ..., -1.5723, -1.6048, -1.5615]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  1.2899,  1.2899,  1.2899],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.2899,  1.2899,  1.2899],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.2899,  1.2899,  1.2899],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.6232,  1.6232,  1.6232],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.6232,  1.6232,  1.6232],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.6232,  1.6232,  1.6232],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  1.9951,  1.9951,  1.9951],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.9951,  1.9951,  1.9951],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.9951,  1.9951,  1.9951],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-0.8774, -0.6158, -0.5254,  ..., -1.5010, -1.6368, -1.6447],\n",
      "          [-0.0985,  0.0586, -0.0924,  ..., -1.1870, -1.5121, -1.7379],\n",
      "          [ 0.4608,  0.2794, -0.1680,  ..., -0.9022, -1.2652, -1.6845]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.4812, -1.1368, -0.9271,  ..., -1.9108, -1.9491, -1.8837],\n",
      "          [-0.8944, -0.6327, -0.6493,  ..., -1.5978, -1.7878, -1.9389],\n",
      "          [-0.4409, -0.5608, -0.8423,  ..., -1.3093, -1.5266, -1.8312]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.7948, -1.6014, -1.3087,  ..., -1.8044, -1.8044, -1.7640],\n",
      "          [-1.6878, -1.3607, -1.1947,  ..., -1.7105, -1.7927, -1.8044],\n",
      "          [-1.4207, -1.3918, -1.4733,  ..., -1.4722, -1.6069, -1.7929]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.6727, -1.6727, -1.6727,  ..., -1.5185, -1.5185, -1.5185],\n",
      "          [-1.6727, -1.6727, -1.6727,  ..., -1.5185, -1.5185, -1.5185],\n",
      "          [-1.6665, -1.6665, -1.6665,  ..., -1.5124, -1.5124, -1.5124],\n",
      "          ...,\n",
      "          [ 1.5373,  1.5156,  1.4632,  ...,  1.1305,  0.4991,  0.1972],\n",
      "          [ 1.4822,  1.4856,  1.4926,  ...,  1.1052,  1.0044,  0.9057],\n",
      "          [ 1.6316,  1.5374,  1.4633,  ...,  1.1305,  1.2749,  1.0503]],\n",
      "\n",
      "         [[-0.5301, -0.5301, -0.5301,  ..., -0.4076, -0.4076, -0.4076],\n",
      "          [-0.5301, -0.5301, -0.5301,  ..., -0.4076, -0.4076, -0.4076],\n",
      "          [-0.5239, -0.5239, -0.5239,  ..., -0.4013, -0.4013, -0.4013],\n",
      "          ...,\n",
      "          [ 1.3572,  1.3401,  1.3132,  ...,  1.0613,  0.4159,  0.1072],\n",
      "          [ 1.2946,  1.2989,  1.3166,  ...,  1.1080,  1.0050,  0.9040],\n",
      "          [ 1.4474,  1.3510,  1.2815,  ...,  1.1451,  1.3183,  1.0956]],\n",
      "\n",
      "         [[ 0.9494,  0.9494,  0.9494,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 0.9494,  0.9494,  0.9494,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 0.9556,  0.9556,  0.9556,  ...,  1.1125,  1.1125,  1.1125],\n",
      "          ...,\n",
      "          [ 1.3630,  1.3361,  1.2607,  ...,  0.9838,  0.3412,  0.0339],\n",
      "          [ 1.3468,  1.3428,  1.3078,  ...,  0.9705,  0.8679,  0.7674],\n",
      "          [ 1.5364,  1.4029,  1.2872,  ...,  0.9639,  1.1236,  0.8984]]],\n",
      "\n",
      "\n",
      "        [[[-0.6417, -0.6876, -0.7557,  ..., -1.0142, -0.9781, -0.9192],\n",
      "          [-0.5534, -0.6398, -0.7567,  ..., -0.9914, -0.9331, -0.8715],\n",
      "          [-0.5187, -0.5997, -0.7249,  ..., -0.9885, -0.9424, -0.8894],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.0948,  2.0948,  2.0948],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.0948,  2.0948,  2.0948],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.0948,  2.0948,  2.0948]],\n",
      "\n",
      "         [[ 0.3488,  0.3019,  0.2385,  ...,  0.1655,  0.2149,  0.2752],\n",
      "          [ 0.4388,  0.3469,  0.2351,  ...,  0.1840,  0.2594,  0.3240],\n",
      "          [ 0.4674,  0.3742,  0.2565,  ...,  0.1649,  0.2341,  0.2932],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.3410,  2.3410,  2.3410],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.3410,  2.3410,  2.3410],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.3410,  2.3410,  2.3410]],\n",
      "\n",
      "         [[ 1.4585,  1.4211,  1.3959,  ...,  1.4216,  1.4665,  1.5270],\n",
      "          [ 1.5581,  1.5026,  1.4023,  ...,  1.4472,  1.5386,  1.6079],\n",
      "          [ 1.6333,  1.5832,  1.4722,  ...,  1.4612,  1.5271,  1.5835],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6051,  2.6051,  2.6051],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6051,  2.6051,  2.6051],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6051,  2.6051,  2.6051]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.7121,  0.1046, -0.9536,  ..., -1.5120, -1.5303, -1.5812],\n",
      "          [ 0.6554,  0.0472, -0.8663,  ..., -1.5943, -1.5850, -1.5753],\n",
      "          [ 0.3855,  0.1413, -0.3752,  ..., -1.7239, -1.7435, -1.7130],\n",
      "          ...,\n",
      "          [-0.5326, -0.7595, -1.1774,  ..., -1.6773, -1.7363, -1.8443],\n",
      "          [-0.8725, -1.0154, -1.1297,  ..., -1.8561, -1.8807, -1.9608],\n",
      "          [-1.1548, -1.0916, -0.8874,  ..., -1.9438, -1.9403, -1.9635]],\n",
      "\n",
      "         [[ 0.0435, -0.4822, -1.4189,  ..., -1.5163, -1.5088, -1.5118],\n",
      "          [ 0.0615, -0.4646, -1.2916,  ..., -1.6005, -1.5618, -1.5473],\n",
      "          [-0.0584, -0.2513, -0.6953,  ..., -1.7289, -1.7117, -1.6743],\n",
      "          ...,\n",
      "          [-0.9727, -1.1147, -1.4064,  ..., -1.5565, -1.6168, -1.7273],\n",
      "          [-1.2002, -1.2579, -1.2420,  ..., -1.7330, -1.7582, -1.8401],\n",
      "          [-1.3548, -1.2329, -0.9031,  ..., -1.8227, -1.8191, -1.8429]],\n",
      "\n",
      "         [[-0.9347, -1.0902, -1.5544,  ..., -1.3695, -1.3359, -1.3501],\n",
      "          [-0.9301, -1.0938, -1.4395,  ..., -1.4608, -1.3961, -1.3780],\n",
      "          [-1.0290, -0.8684, -0.8852,  ..., -1.6325, -1.5865, -1.5443],\n",
      "          ...,\n",
      "          [-1.1657, -1.3380, -1.6844,  ..., -1.5004, -1.5604, -1.6704],\n",
      "          [-1.4196, -1.5031, -1.5479,  ..., -1.7222, -1.7473, -1.7907],\n",
      "          [-1.6133, -1.5156, -1.2400,  ..., -1.8016, -1.8027, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  1.9710,  1.7100,  1.7012],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.1107,  1.2196,  1.3269],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.0327,  0.3977,  0.8740],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.4880, -1.4231, -1.3540],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.7869, -1.3043, -1.4684],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.2728, -1.1769, -1.4279]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.4554,  1.3667,  1.4432],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.5223,  0.7877,  1.0185],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.7533, -0.1506,  0.4432],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.8347, -1.6253, -1.4741],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.1864, -1.5445, -1.6306],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.7000, -1.4389, -1.5828]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  1.0047,  1.0363,  1.1661],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.0449,  0.4333,  0.7079],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.2653, -0.5514,  0.1128],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.6927, -1.3735, -1.1232],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.1541, -1.3636, -1.3403],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.7262, -1.3036, -1.3548]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  1.0196,  1.0392,  ...,  1.8375,  1.8379,  1.8379],\n",
      "          [ 1.0000,  1.0196,  1.0392,  ...,  1.8245,  1.8363,  1.8379],\n",
      "          [ 1.0000,  1.0196,  1.0392,  ...,  1.7997,  1.8258,  1.8318],\n",
      "          ...,\n",
      "          [-0.1291, -0.2320, -0.3674,  ..., -0.9443, -1.2238, -1.1320],\n",
      "          [-0.1658, -0.1795, -0.2732,  ..., -0.6184, -0.7566, -0.8573],\n",
      "          [-0.0668, -0.0255, -0.1012,  ..., -0.3833, -0.4559, -0.9394]],\n",
      "\n",
      "         [[ 1.3794,  1.3994,  1.4194,  ...,  2.0255,  2.0259,  2.0259],\n",
      "          [ 1.3794,  1.3994,  1.4194,  ...,  2.0197,  2.0259,  2.0259],\n",
      "          [ 1.3794,  1.3994,  1.4194,  ...,  2.0219,  2.0308,  2.0322],\n",
      "          ...,\n",
      "          [-0.3814, -0.4117, -0.4901,  ..., -0.9171, -1.2082, -1.1141],\n",
      "          [-0.4809, -0.4383, -0.4538,  ..., -0.5977, -0.7590, -0.8786],\n",
      "          [-0.4089, -0.3375, -0.3413,  ..., -0.3612, -0.4554, -0.9697]],\n",
      "\n",
      "         [[ 1.8744,  1.8943,  1.9142,  ...,  2.3088,  2.3088,  2.3088],\n",
      "          [ 1.8744,  1.8943,  1.9142,  ...,  2.3112,  2.3126,  2.3126],\n",
      "          [ 1.8744,  1.8943,  1.9142,  ...,  2.3223,  2.3312,  2.3325],\n",
      "          ...,\n",
      "          [-0.8787, -0.8586, -0.8149,  ..., -1.1179, -1.2868, -1.1396],\n",
      "          [-1.0884, -0.9844, -0.8907,  ..., -0.7999, -0.8562, -0.8882],\n",
      "          [-1.0987, -0.9457, -0.8437,  ..., -0.5910, -0.5668, -0.9759]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.4166,  0.4166,  0.4227,  ...,  0.3994,  0.3994,  0.3994],\n",
      "          [ 0.4166,  0.4166,  0.4227,  ...,  0.3994,  0.3994,  0.3994],\n",
      "          [ 0.4166,  0.4166,  0.4227,  ...,  0.3994,  0.3994,  0.3994],\n",
      "          ...,\n",
      "          [-2.1179, -2.1153, -2.1035,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.0920, -2.1073, -2.1179,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.9747, -2.0124, -2.0498,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 1.2031,  1.2031,  1.2093,  ...,  1.1856,  1.1856,  1.1856],\n",
      "          [ 1.2031,  1.2031,  1.2093,  ...,  1.1856,  1.1856,  1.1856],\n",
      "          [ 1.2031,  1.2031,  1.2093,  ...,  1.1856,  1.1856,  1.1856],\n",
      "          ...,\n",
      "          [-1.1882, -1.1715, -1.1506,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.1276, -1.1425, -1.1553,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.9965, -1.0350, -1.0736,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.8905,  1.8905,  1.8968,  ...,  1.8731,  1.8731,  1.8731],\n",
      "          [ 1.8905,  1.8905,  1.8968,  ...,  1.8731,  1.8731,  1.8731],\n",
      "          [ 1.8905,  1.8905,  1.8968,  ...,  1.8731,  1.8731,  1.8731],\n",
      "          ...,\n",
      "          [-0.4204, -0.4038, -0.3910,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.3600, -0.3808, -0.4177,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.2295, -0.2754, -0.3412,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  0.2453,  0.2453,  0.2453],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.2453,  0.2453,  0.2453],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.2514,  0.2514,  0.2514],\n",
      "          ...,\n",
      "          [ 0.4224,  0.2918,  0.0797,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.4626,  0.4797,  0.6002,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.0401,  0.6829,  1.4322,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.2556,  1.2556,  1.2556],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.2556,  1.2556,  1.2556],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.2619,  1.2619,  1.2619],\n",
      "          ...,\n",
      "          [ 0.5568,  0.4176,  0.2122,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.5141,  0.5552,  0.6879,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.0465,  0.7250,  1.5031,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.3611,  2.3611,  2.3611],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.3611,  2.3611,  2.3611],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.3674,  2.3674,  2.3674],\n",
      "          ...,\n",
      "          [ 1.0416,  0.9345,  0.7555,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.9534,  1.0323,  1.1887,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.4003,  1.1629,  1.9821,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0559,  0.0530,  0.0802,  ...,  1.6442,  1.4931,  1.5177],\n",
      "          [ 0.1376,  0.1375,  0.1199,  ...,  1.9012,  1.7129,  1.6801],\n",
      "          [ 0.4537,  0.3764,  0.2655,  ...,  1.9743,  1.9022,  1.9088],\n",
      "          ...,\n",
      "          [ 0.8498,  0.5804,  0.3093,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.0777,  0.9427,  0.7320,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.1515,  1.1189,  1.1473,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 1.3132,  1.3729,  1.4807,  ...,  1.8454,  1.6928,  1.7186],\n",
      "          [ 1.1362,  1.1774,  1.2411,  ...,  2.1156,  1.9447,  1.9171],\n",
      "          [ 1.1297,  1.0695,  1.0459,  ...,  2.2179,  2.1442,  2.1509],\n",
      "          ...,\n",
      "          [ 0.4180,  0.1052, -0.1914,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.6382,  0.4700,  0.1953,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.7102,  0.6494,  0.6063,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.1499,  1.1894,  1.2710,  ...,  2.0087,  1.8577,  1.9134],\n",
      "          [ 1.0611,  1.0849,  1.1254,  ...,  2.3012,  2.1409,  2.1134],\n",
      "          [ 1.1689,  1.1014,  1.0443,  ...,  2.4128,  2.3394,  2.3461],\n",
      "          ...,\n",
      "          [-0.0874, -0.3922, -0.7414,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.1824, -0.0249, -0.3924,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.2622,  0.1274,  0.0046,  ...,  2.6400,  2.6400,  2.6400]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[ 1.2422e-01,  1.2422e-01,  1.2422e-01,  ...,  9.1189e-02,\n",
      "            9.1189e-02,  9.1189e-02],\n",
      "          [ 1.0464e-01,  1.0464e-01,  1.0464e-01,  ...,  8.7520e-02,\n",
      "            8.7520e-02,  8.7520e-02],\n",
      "          [ 8.5073e-02,  8.5073e-02,  8.5073e-02,  ...,  7.4065e-02,\n",
      "            7.4065e-02,  7.4065e-02],\n",
      "          ...,\n",
      "          [-8.1843e-01, -8.2734e-01, -8.0594e-01,  ..., -1.9626e-01,\n",
      "           -1.6804e-01, -1.5633e-01],\n",
      "          [-6.6012e-01, -6.6064e-01, -6.3303e-01,  ..., -1.0452e-01,\n",
      "           -8.2067e-02, -6.5117e-02],\n",
      "          [-5.9747e-01, -5.9380e-01, -5.6768e-01,  ..., -4.4148e-02,\n",
      "           -1.8897e-02,  6.7389e-04]],\n",
      "\n",
      "         [[ 7.2914e-01,  7.2914e-01,  7.2914e-01,  ...,  7.4790e-01,\n",
      "            7.4790e-01,  7.4790e-01],\n",
      "          [ 7.0913e-01,  7.0913e-01,  7.0913e-01,  ...,  7.4415e-01,\n",
      "            7.4415e-01,  7.4415e-01],\n",
      "          [ 6.8913e-01,  6.8913e-01,  6.8913e-01,  ...,  7.3039e-01,\n",
      "            7.3039e-01,  7.3039e-01],\n",
      "          ...,\n",
      "          [-7.2974e-01, -7.3885e-01, -7.1697e-01,  ..., -2.4625e-01,\n",
      "           -2.1740e-01, -2.0543e-01],\n",
      "          [-5.8040e-01, -5.8094e-01, -5.5271e-01,  ..., -1.5246e-01,\n",
      "           -1.2950e-01, -1.1218e-01],\n",
      "          [-5.1636e-01, -5.1260e-01, -4.8590e-01,  ..., -9.0739e-02,\n",
      "           -6.4925e-02, -4.4917e-02]],\n",
      "\n",
      "         [[ 1.4187e+00,  1.4187e+00,  1.4187e+00,  ...,  1.3851e+00,\n",
      "            1.3851e+00,  1.3851e+00],\n",
      "          [ 1.3988e+00,  1.3988e+00,  1.3988e+00,  ...,  1.3814e+00,\n",
      "            1.3814e+00,  1.3814e+00],\n",
      "          [ 1.3789e+00,  1.3789e+00,  1.3789e+00,  ...,  1.3677e+00,\n",
      "            1.3677e+00,  1.3677e+00],\n",
      "          ...,\n",
      "          [-7.0098e-01, -7.1005e-01, -6.8826e-01,  ..., -2.3208e-01,\n",
      "           -2.0336e-01, -1.9144e-01],\n",
      "          [-5.7844e-01, -5.7898e-01, -5.5088e-01,  ..., -1.3871e-01,\n",
      "           -1.1586e-01, -9.8606e-02],\n",
      "          [-5.1842e-01, -5.1468e-01, -4.8809e-01,  ..., -7.7263e-02,\n",
      "           -5.1564e-02, -3.1645e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.0943e+00,\n",
      "           -1.2380e+00, -1.2264e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.3464e+00,\n",
      "           -1.4774e+00, -1.2541e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.4223e+00,\n",
      "           -1.4354e+00, -1.4182e+00],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -1.0042e+00,\n",
      "           -1.1512e+00, -1.1404e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -1.2182e+00,\n",
      "           -1.3521e+00, -1.1367e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -1.2233e+00,\n",
      "           -1.2367e+00, -1.2191e+00],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -6.8044e-01,\n",
      "           -7.9506e-01, -7.7399e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -9.1849e-01,\n",
      "           -1.0442e+00, -7.9159e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -9.8874e-01,\n",
      "           -9.8429e-01, -9.6411e-01],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 7.2017e-01,  7.7321e-01,  8.2633e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 8.5499e-01,  9.5468e-01,  9.9408e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 8.0921e-01,  9.4384e-01,  1.0469e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          ...,\n",
      "          [ 5.6195e-01,  1.6528e-01,  2.5043e-02,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 7.7627e-01,  3.4693e-01,  9.7745e-02,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 4.3167e-01,  4.4312e-01,  4.5728e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[ 6.5563e-01,  7.1012e-01,  7.7121e-01,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 7.9720e-01,  9.0207e-01,  9.5584e-01,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 7.7041e-01,  9.0805e-01,  1.0281e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          ...,\n",
      "          [ 3.2836e-01, -2.5360e-02, -1.1754e-01,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 5.1218e-01,  1.0988e-01, -7.6982e-02,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 1.3675e-01,  1.9134e-01,  2.7263e-01,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 9.4466e-01,  9.9890e-01,  1.0597e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 1.0931e+00,  1.1975e+00,  1.2497e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 1.1062e+00,  1.2433e+00,  1.3566e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          ...,\n",
      "          [ 2.7488e-01, -4.5966e-02, -3.4231e-02,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 5.4485e-01,  1.8631e-01,  9.2050e-02,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.3396e-01,  3.2405e-01,  4.9782e-01,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -3.7371e-01,\n",
      "           -1.3327e-01, -5.1574e-02],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.1728e-01,\n",
      "           -6.3195e-02, -8.5126e-02],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  1.1723e-01,\n",
      "            3.1601e-02, -1.1125e-01],\n",
      "          ...,\n",
      "          [-1.1928e+00, -1.0355e+00, -1.0506e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [-1.1971e+00, -1.0203e+00, -1.0658e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [-1.1980e+00, -1.0376e+00, -1.1152e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -7.1072e-01,\n",
      "           -4.6348e-01, -3.7969e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -4.8822e-01,\n",
      "           -4.1158e-01, -4.2677e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -2.6590e-01,\n",
      "           -3.2226e-01, -4.4696e-01],\n",
      "          ...,\n",
      "          [-1.5627e+00, -1.4018e+00, -1.4173e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [-1.5670e+00, -1.3863e+00, -1.4328e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [-1.5679e+00, -1.4039e+00, -1.4834e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -1.7242e+00,\n",
      "           -1.5732e+00, -1.5025e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -1.4997e+00,\n",
      "           -1.5264e+00, -1.6244e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -1.2312e+00,\n",
      "           -1.4863e+00, -1.7233e+00],\n",
      "          ...,\n",
      "          [-1.4904e+00, -1.3302e+00, -1.3500e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [-1.4947e+00, -1.3148e+00, -1.3611e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [-1.4956e+00, -1.3323e+00, -1.4114e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          ...,\n",
      "          [-1.1677e+00, -1.3033e+00, -1.4837e+00,  ..., -1.0168e+00,\n",
      "           -1.0342e+00, -1.0378e+00],\n",
      "          [-1.1315e+00, -1.3261e+00, -1.5124e+00,  ..., -1.0916e+00,\n",
      "           -1.1063e+00, -1.1100e+00],\n",
      "          [-9.2773e-01, -1.1342e+00, -1.3614e+00,  ..., -1.1075e+00,\n",
      "           -1.1085e+00, -1.1088e+00]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          ...,\n",
      "          [-9.9432e-01, -1.1254e+00, -1.2635e+00,  ..., -5.2154e-02,\n",
      "           -6.9929e-02, -7.3680e-02],\n",
      "          [-9.5725e-01, -1.1488e+00, -1.2929e+00,  ..., -8.7346e-02,\n",
      "           -1.0244e-01, -1.0619e-01],\n",
      "          [-7.4895e-01, -9.5251e-01, -1.1386e+00,  ..., -9.2437e-02,\n",
      "           -9.3419e-02, -9.3687e-02]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          ...,\n",
      "          [-7.7266e-01, -9.0684e-01, -1.0643e+00,  ...,  8.8490e-01,\n",
      "            8.6720e-01,  8.6347e-01],\n",
      "          [-7.4820e-01, -9.4259e-01, -1.1060e+00,  ...,  8.3617e-01,\n",
      "            8.2114e-01,  8.1740e-01],\n",
      "          [-5.4082e-01, -7.4722e-01, -9.5237e-01,  ...,  8.2736e-01,\n",
      "            8.2639e-01,  8.2612e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.4743e-01,  9.4743e-01,  9.4743e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 9.4743e-01,  9.4743e-01,  9.4743e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 9.5354e-01,  9.5354e-01,  9.5354e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -9.5517e-01,\n",
      "           -9.4608e-01, -9.2651e-01],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -9.6207e-01,\n",
      "           -9.5342e-01, -9.2135e-01],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -9.8601e-01,\n",
      "           -9.6050e-01, -9.2162e-01]],\n",
      "\n",
      "         [[ 1.3957e+00,  1.3957e+00,  1.3957e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 1.3957e+00,  1.3957e+00,  1.3957e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 1.4019e+00,  1.4019e+00,  1.4019e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -4.2686e-01,\n",
      "           -4.1757e-01, -3.9756e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -4.3391e-01,\n",
      "           -4.2507e-01, -3.9229e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -4.5839e-01,\n",
      "           -4.3230e-01, -3.9256e-01]],\n",
      "\n",
      "         [[ 2.3611e+00,  2.3611e+00,  2.3611e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.3611e+00,  2.3611e+00,  2.3611e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.3674e+00,  2.3674e+00,  2.3674e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -1.2136e+00,\n",
      "           -1.2044e+00, -1.1845e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -1.2207e+00,\n",
      "           -1.2119e+00, -1.1792e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -1.2450e+00,\n",
      "           -1.2191e+00, -1.1795e+00]]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.2489,  2.2489,  2.2489,  ...,  0.1597,  0.1597,  0.1597],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.1634,  0.1634,  0.1634],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.1829,  0.1829,  0.1829],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.5125,  1.5125,  1.5125],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.5125,  1.5125,  1.5125],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.5125,  1.5125,  1.5125]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  0.7479,  0.7479,  0.7479],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.7517,  0.7517,  0.7517],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.7717,  0.7717,  0.7717],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.6933,  1.6933,  1.6933],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.6933,  1.6933,  1.6933],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.6933,  1.6933,  1.6933]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  1.3677,  1.3677,  1.3677],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.3714,  1.3714,  1.3714],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.3913,  1.3913,  1.3913],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.9951,  1.9951,  1.9951],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.9951,  1.9951,  1.9951],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.9951,  1.9951,  1.9951]]],\n",
      "\n",
      "\n",
      "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1069, -2.1008, -2.1008],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1069, -2.1008, -2.1008],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1069, -2.1008, -2.1008],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.1069, -2.1008, -2.1008],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.1069, -2.1008, -2.1008],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.1069, -2.1008, -2.1008]],\n",
      "\n",
      "         [[-2.0182, -2.0220, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0182, -2.0220, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0182, -2.0220, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-1.8044, -1.7970, -1.7696,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.7970, -1.7696,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.7970, -1.7696,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.7696, -1.7696, -1.7696],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.7696, -1.7696, -1.7696],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.7696, -1.7696, -1.7696]]],\n",
      "\n",
      "\n",
      "        [[[-1.0721, -1.0525, -1.0329,  ..., -1.1760, -1.1760, -1.1760],\n",
      "          [-1.0687, -1.0525, -1.0329,  ..., -1.1760, -1.1760, -1.1760],\n",
      "          [-1.0557, -1.0464, -1.0290,  ..., -1.1760, -1.1760, -1.1760],\n",
      "          ...,\n",
      "          [-1.1814, -1.1638, -1.1103,  ..., -1.4202, -1.4527, -1.2631],\n",
      "          [-1.3363, -1.3130, -1.2665,  ..., -1.3409, -1.4714, -1.4275],\n",
      "          [-1.5711, -1.5479, -1.4913,  ..., -1.2431, -1.4137, -1.6433]],\n",
      "\n",
      "         [[-0.7039, -0.6839, -0.6639,  ..., -0.6702, -0.6702, -0.6702],\n",
      "          [-0.7004, -0.6839, -0.6639,  ..., -0.6702, -0.6702, -0.6702],\n",
      "          [-0.6872, -0.6777, -0.6599,  ..., -0.6702, -0.6702, -0.6702],\n",
      "          ...,\n",
      "          [-1.2008, -1.1829, -1.1094,  ..., -1.3925, -1.4257, -1.2319],\n",
      "          [-1.3592, -1.3354, -1.2691,  ..., -1.3114, -1.4449, -1.3999],\n",
      "          [-1.5993, -1.5755, -1.4989,  ..., -1.2114, -1.3858, -1.6206]],\n",
      "\n",
      "         [[ 0.2709,  0.2908,  0.3107,  ...,  0.3219,  0.3219,  0.3219],\n",
      "          [ 0.2743,  0.2908,  0.3107,  ...,  0.3219,  0.3219,  0.3219],\n",
      "          [ 0.2875,  0.2970,  0.3147,  ...,  0.3219,  0.3219,  0.3219],\n",
      "          ...,\n",
      "          [-1.1127, -1.0948, -1.0279,  ..., -1.2164, -1.2495, -1.0565],\n",
      "          [-1.2704, -1.2467, -1.1869,  ..., -1.1356, -1.2685, -1.2238],\n",
      "          [-1.5094, -1.4857, -1.4157,  ..., -1.0360, -1.2097, -1.4434]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ..., -0.5253, -0.5253, -0.5253],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.5253, -0.5253, -0.5253],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.5192, -0.5192, -0.5192],\n",
      "          ...,\n",
      "          [-1.6739, -1.6984, -1.7507,  ..., -1.4056, -1.3951, -1.4040],\n",
      "          [-1.6864, -1.6942, -1.7241,  ..., -1.4341, -1.4219, -1.4378],\n",
      "          [-1.7046, -1.6900, -1.6976,  ..., -1.4929, -1.4931, -1.4977]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -0.7227, -0.7227, -0.7227],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.7227, -0.7227, -0.7227],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.7164, -0.7164, -0.7164],\n",
      "          ...,\n",
      "          [-1.5643, -1.5894, -1.6428,  ..., -1.3570, -1.3753, -1.3884],\n",
      "          [-1.5770, -1.5851, -1.6156,  ..., -1.3742, -1.3805, -1.3967],\n",
      "          [-1.5956, -1.5808, -1.5885,  ..., -1.4142, -1.4332, -1.4379]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ..., -0.7413, -0.7413, -0.7413],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.7413, -0.7413, -0.7413],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.7350, -0.7350, -0.7350],\n",
      "          ...,\n",
      "          [-1.3002, -1.3252, -1.3784,  ..., -1.1048, -1.0999, -1.1090],\n",
      "          [-1.3130, -1.3210, -1.3514,  ..., -1.2791, -1.2791, -1.2953],\n",
      "          [-1.3315, -1.3167, -1.3243,  ..., -1.4135, -1.4517, -1.4632]]],\n",
      "\n",
      "\n",
      "        [[[-0.3541, -0.3541, -0.3541,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.3541, -0.3541, -0.3541,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.3541, -0.3541, -0.3541,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.5967, -0.7016, -0.6762],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.8075, -0.8037, -0.6702],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.0752, -0.9021, -0.5882]],\n",
      "\n",
      "         [[ 0.0126,  0.0126,  0.0126,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.0126,  0.0126,  0.0126,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.0126,  0.0126,  0.0126,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.4401, -0.5215, -0.4918],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.6712, -0.6504, -0.4877],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.9472, -0.7578, -0.4043]],\n",
      "\n",
      "         [[ 0.4614,  0.4614,  0.4614,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.4614,  0.4614,  0.4614,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.4614,  0.4614,  0.4614,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.0799, -0.1252, -0.0881],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.2591, -0.2107, -0.0569],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.5241, -0.3094,  0.0301]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5019,  1.7339,  2.0533,  ..., -1.0257, -1.1460, -1.2129],\n",
      "          [ 1.6612,  1.6967,  1.9406,  ..., -0.9658, -1.0328, -1.0577],\n",
      "          [ 1.7206,  1.6516,  1.7461,  ..., -0.9899, -1.0086, -1.0166],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.2456, -0.2834, -0.2745],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.2098, -0.2522, -0.2290],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.1632, -0.2012, -0.1583]],\n",
      "\n",
      "         [[ 1.8024,  2.0390,  2.3395,  ..., -0.9541, -1.0909, -1.1630],\n",
      "          [ 1.9102,  1.9415,  2.1596,  ..., -0.8929, -0.9752, -1.0043],\n",
      "          [ 1.8697,  1.8003,  1.8905,  ..., -0.9175, -0.9504, -0.9623],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.0534,  0.0148,  0.0239],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.0900,  0.0467,  0.0704],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.1377,  0.0989,  0.1427]],\n",
      "\n",
      "         [[ 0.5339,  0.7692,  1.0918,  ..., -0.9430, -1.0319, -1.0925],\n",
      "          [ 0.6101,  0.6359,  0.8495,  ..., -0.8821, -0.9167, -0.9345],\n",
      "          [ 0.4830,  0.3924,  0.4478,  ..., -0.9044, -0.8920, -0.8927],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.1360,  0.0976,  0.1065],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.1724,  0.1293,  0.1529],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.2198,  0.1812,  0.2249]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[ 0.3520, -0.1862, -0.8162,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.3299, -0.0623, -0.5226,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.2900,  0.1611, -0.1619,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-0.6190,  0.1457,  1.1245,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.5637,  0.3790,  1.5466,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.2717,  0.3624,  1.4205,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 1.5260,  0.9598,  0.3216,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.5909,  1.1758,  0.7033,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.6644,  1.5170,  1.1682,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.0153, -0.3139,  0.6701,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.2519, -0.2674,  1.0535,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.1140, -0.3667,  0.8955,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[-0.8667, -1.3158, -1.7465,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.7928, -1.1149, -1.4543,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.7335, -0.7683, -0.9690,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-0.8964, -0.3985,  0.2683,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.9616, -0.2130,  0.7149,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.6860, -0.2387,  0.6137,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  0.6121,  0.9286,  0.7228],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.1254,  0.0028, -0.0795],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.3178, -1.5432, -1.6881],\n",
      "          ...,\n",
      "          [-1.1439, -1.2795, -1.4232,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.4731, -1.5138, -1.4860,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.6449, -1.5998, -1.4991,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.0178,  1.2961,  1.0622],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.2476,  0.3432,  0.2417],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.9714, -1.2481, -1.4038],\n",
      "          ...,\n",
      "          [-0.4927, -0.6670, -0.8828,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.8488, -0.9217, -0.9720,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.9991, -1.0296, -1.0066,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  0.7824,  1.2650,  1.1679],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.0740,  0.3605,  0.3608],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.1011, -1.1934, -1.2500],\n",
      "          ...,\n",
      "          [-1.2954, -1.3969, -1.4945,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.5157, -1.5038, -1.4278,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.5881, -1.5047, -1.3572,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0190,  1.9373,  1.9488,  ...,  0.8585,  0.8827,  0.9977],\n",
      "          [ 1.9975,  1.9407,  1.9590,  ...,  1.1879,  1.3278,  0.9908],\n",
      "          [ 1.9668,  1.9407,  1.9546,  ...,  1.4546,  1.4823,  1.1364],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.1015,  1.0906,  1.0734],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.1701,  1.1688,  1.1654],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.2553,  1.2792,  1.2826]],\n",
      "\n",
      "         [[ 2.1761,  2.0925,  2.1042,  ...,  1.2347,  1.2870,  1.4120],\n",
      "          [ 2.1540,  2.0959,  2.1147,  ...,  1.5715,  1.7362,  1.3974],\n",
      "          [ 2.1226,  2.0959,  2.1102,  ...,  1.8441,  1.8725,  1.5188],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.9580,  0.9468,  0.9292],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.0006,  0.9993,  0.9958],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.0802,  1.1046,  1.1080]],\n",
      "\n",
      "         [[ 2.4932,  2.4100,  2.4217,  ...,  1.5909,  1.6292,  1.7500],\n",
      "          [ 2.4712,  2.4134,  2.4321,  ...,  1.9261,  2.0793,  1.7392],\n",
      "          [ 2.4400,  2.4134,  2.4276,  ...,  2.1976,  2.2258,  1.8737],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.8846,  0.8735,  0.8560],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.9532,  0.9519,  0.9484],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.0362,  1.0604,  1.0639]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  1.6043,  1.5982,  1.5982],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.6043,  1.5982,  1.5982],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.6043,  1.5982,  1.5982],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.5789, -0.5914, -0.5938],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.5888, -0.6036, -0.6073],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.6097, -0.6107, -0.6109]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.2969,  1.2906,  1.2906],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.2969,  1.2906,  1.2906],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.2969,  1.2906,  1.2906],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.8125, -0.8253, -0.8277],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.8226, -0.8377, -0.8415],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.8440, -0.8450, -0.8452]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  1.2170,  1.2108,  1.2108],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.2170,  1.2108,  1.2108],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.2170,  1.2108,  1.2108],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.7783, -0.7912, -0.7936],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.7885, -0.8035, -0.8072],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.8097, -0.8107, -0.8110]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.9235,  1.9235,  1.9174,  ..., -1.5687, -0.9713, -0.7035],\n",
      "          [ 1.9235,  1.9228,  1.9151,  ..., -1.3984, -0.8896, -0.4983],\n",
      "          [ 1.9174,  1.9151,  1.9064,  ..., -1.0520, -0.7151, -0.3258],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.7413,  1.7413,  1.7413],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.7217,  1.7217,  1.7217],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.7339,  1.7339,  1.7339]],\n",
      "\n",
      "         [[ 1.8859,  1.8859,  1.8796,  ..., -1.6493, -1.0386, -0.7648],\n",
      "          [ 1.8859,  1.8851,  1.8772,  ..., -1.4752, -0.9551, -0.5550],\n",
      "          [ 1.8796,  1.8772,  1.8683,  ..., -1.1211, -0.7766, -0.3787],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.7170,  1.7170,  1.7170],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.6970,  1.6970,  1.6970],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.7095,  1.7095,  1.7095]],\n",
      "\n",
      "         [[ 2.2740,  2.2740,  2.2678,  ..., -1.4546, -0.8466, -0.5741],\n",
      "          [ 2.2740,  2.2732,  2.2654,  ..., -1.2813, -0.7635, -0.3652],\n",
      "          [ 2.2678,  2.2654,  2.2566,  ..., -0.9287, -0.5858, -0.1897],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.0711,  2.0711,  2.0711],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.0511,  2.0511,  2.0511],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.0636,  2.0636,  2.0636]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0574,  1.1348,  1.2385,  ...,  0.5699,  0.5570,  0.5536],\n",
      "          [ 1.0920,  1.1607,  1.2753,  ...,  0.5560,  0.5499,  0.5499],\n",
      "          [ 1.1003,  1.1799,  1.2914,  ...,  0.5342,  0.5255,  0.5242],\n",
      "          ...,\n",
      "          [-1.3445, -1.3045, -1.3028,  ..., -1.3421, -1.4222, -1.4159],\n",
      "          [-1.3696, -1.3057, -1.3154,  ..., -1.2678, -1.3961, -1.4569],\n",
      "          [-1.4232, -1.3378, -1.3363,  ..., -1.2213, -1.3583, -1.4612]],\n",
      "\n",
      "         [[ 1.6982,  1.7411,  1.8083,  ...,  1.0097,  0.9965,  0.9930],\n",
      "          [ 1.7370,  1.7675,  1.8459,  ...,  0.9955,  0.9892,  0.9892],\n",
      "          [ 1.7583,  1.7872,  1.8646,  ...,  0.9733,  0.9643,  0.9630],\n",
      "          ...,\n",
      "          [-1.2625, -1.2216, -1.2199,  ..., -1.2776, -1.3595, -1.3530],\n",
      "          [-1.2882, -1.2229, -1.2328,  ..., -1.2016, -1.3328, -1.3950],\n",
      "          [-1.3430, -1.2557, -1.2542,  ..., -1.1541, -1.2942, -1.3994]],\n",
      "\n",
      "         [[ 2.5553,  2.5504,  2.5371,  ...,  1.6806,  1.6674,  1.6640],\n",
      "          [ 2.5830,  2.5673,  2.5641,  ...,  1.6739,  1.6677,  1.6677],\n",
      "          [ 2.5641,  2.5654,  2.5761,  ...,  1.6792,  1.6703,  1.6689],\n",
      "          ...,\n",
      "          [-0.9476, -0.9068, -0.9052,  ..., -0.8232, -0.9046, -0.8982],\n",
      "          [-0.9731, -0.9081, -0.9180,  ..., -0.7475, -0.8781, -0.9400],\n",
      "          [-1.0277, -0.9407, -0.9392,  ..., -0.7002, -0.8396, -0.9444]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-2.0543, -2.0519, -2.0254,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.0271, -2.0417, -2.0249,  ..., -2.0506, -2.0612, -2.0516],\n",
      "          [-1.8778, -1.9667, -2.0215,  ..., -1.9789, -1.9855, -1.9699]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-0.9778, -1.0416, -1.1180,  ...,  0.2349,  0.3141,  0.3602],\n",
      "          [-0.8910, -0.9862, -1.0852,  ...,  0.2264,  0.3127,  0.3730],\n",
      "          [-0.7262, -0.8892, -1.0652,  ...,  0.2218,  0.3092,  0.3765]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.4584, -1.4995, -1.5322,  ...,  0.3602,  0.3642,  0.3596],\n",
      "          [-1.3918, -1.4630, -1.5105,  ...,  0.2558,  0.2572,  0.2791],\n",
      "          [-1.2315, -1.3701, -1.4989,  ...,  0.2024,  0.1897,  0.2186]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ..., -0.6701, -0.7077, -1.0312],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.8743, -0.8681, -0.7936],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.9350, -0.9785, -0.8438],\n",
      "          ...,\n",
      "          [-0.4152, -0.3552, -0.2978,  ..., -0.2384, -0.2526, -0.3211],\n",
      "          [-0.3712, -0.3125, -0.2599,  ..., -0.1410, -0.1673, -0.2974],\n",
      "          [-0.4470, -0.3815, -0.3039,  ..., -0.0637, -0.1124, -0.3054]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -0.1879, -0.2392, -0.5745],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.4028, -0.3979, -0.3345],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.5022, -0.5507, -0.4188],\n",
      "          ...,\n",
      "          [-0.2600, -0.1986, -0.1400,  ..., -0.2193, -0.2338, -0.3039],\n",
      "          [-0.2150, -0.1550, -0.1012,  ..., -0.1198, -0.1466, -0.2796],\n",
      "          [-0.2763, -0.2093, -0.1300,  ..., -0.0407, -0.0905, -0.2878]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ..., -0.0785, -0.0654, -0.3849],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.3109, -0.2648, -0.1560],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.3988, -0.4130, -0.2596],\n",
      "          ...,\n",
      "          [ 0.1787,  0.2398,  0.2983,  ...,  0.0039, -0.0106, -0.0803],\n",
      "          [ 0.2173,  0.2771,  0.3306,  ...,  0.1030,  0.0763, -0.0561],\n",
      "          [ 0.1078,  0.1745,  0.2534,  ...,  0.1817,  0.1322, -0.0643]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6483,  1.6446,  1.6255,  ...,  0.8700,  0.9073,  0.9292],\n",
      "          [ 1.6251,  1.6222,  1.6129,  ...,  0.9378,  0.9429,  0.9450],\n",
      "          [ 1.5921,  1.5934,  1.6043,  ...,  1.0893,  1.0636,  1.0543],\n",
      "          ...,\n",
      "          [-0.2142,  0.1894,  0.1018,  ..., -0.4285, -0.4844, -0.4446],\n",
      "          [ 0.1447,  0.1539, -0.0981,  ..., -0.6031, -0.7433, -0.6180],\n",
      "          [ 0.5388, -0.0132, -0.4709,  ..., -0.4748, -0.7887, -0.8639]],\n",
      "\n",
      "         [[ 1.7796,  1.7758,  1.7562,  ...,  1.0014,  1.0395,  1.0619],\n",
      "          [ 1.7558,  1.7529,  1.7434,  ...,  1.0707,  1.0759,  1.0780],\n",
      "          [ 1.7220,  1.7234,  1.7345,  ...,  1.2256,  1.1993,  1.1898],\n",
      "          ...,\n",
      "          [-0.1232,  0.2893,  0.1997,  ..., -0.1836, -0.2270, -0.1825],\n",
      "          [ 0.1699,  0.1793, -0.0783,  ..., -0.2570, -0.3866, -0.2547],\n",
      "          [ 0.4927, -0.0716, -0.5395,  ..., -0.0516, -0.3658, -0.4423]],\n",
      "\n",
      "         [[ 2.1856,  2.1819,  2.1624,  ...,  1.3586,  1.3966,  1.4188],\n",
      "          [ 2.1619,  2.1590,  2.1496,  ...,  1.4276,  1.4328,  1.4349],\n",
      "          [ 2.1283,  2.1297,  2.1408,  ...,  1.5693,  1.5432,  1.5337],\n",
      "          ...,\n",
      "          [-0.8296, -0.4073, -0.4964,  ..., -1.2911, -1.3856, -1.3733],\n",
      "          [-0.5461, -0.5367, -0.7932,  ..., -1.1477, -1.3254, -1.2123],\n",
      "          [-0.2284, -0.7903, -1.2561,  ..., -0.8273, -1.1607, -1.2678]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 1.9235,  1.9235,  1.9235,  ..., -1.6127, -1.6188, -1.6291],\n",
      "          [ 1.9235,  1.9235,  1.9235,  ..., -1.7705, -1.7872, -1.8060],\n",
      "          [ 1.9235,  1.9235,  1.9235,  ..., -1.9251, -1.9503, -1.9699]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.3761,  2.3760,  2.3761,  ..., -1.5018, -1.5080, -1.5185],\n",
      "          [ 2.3760,  2.3761,  2.3761,  ..., -1.6631, -1.6801, -1.6993],\n",
      "          [ 2.3761,  2.3761,  2.3761,  ..., -1.8211, -1.8469, -1.8669]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.5877,  2.5877,  2.5877,  ..., -1.2031, -1.2094, -1.2198],\n",
      "          [ 2.5877,  2.5877,  2.5877,  ..., -1.3637, -1.3807, -1.3998],\n",
      "          [ 2.5877,  2.5877,  2.5877,  ..., -1.5210, -1.5467, -1.5667]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[ 0.5315,  0.5211,  0.4643,  ..., -1.2511, -1.2384, -1.2089],\n",
      "          [ 0.4496,  0.4459,  0.4128,  ..., -1.1382, -1.1157, -1.1115],\n",
      "          [ 0.3338,  0.3358,  0.3023,  ..., -0.9400, -0.8924, -0.8702],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 1.4457,  1.4419,  1.4094,  ...,  0.3945,  0.4003,  0.3852],\n",
      "          [ 1.3944,  1.3907,  1.3595,  ...,  0.4577,  0.4649,  0.4700],\n",
      "          [ 1.2886,  1.2906,  1.2644,  ...,  0.5884,  0.6315,  0.6566],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.2727,  2.2725,  2.2528,  ...,  1.7420,  1.7362,  1.7362],\n",
      "          [ 2.2379,  2.2341,  2.2058,  ...,  1.7883,  1.7880,  1.7907],\n",
      "          [ 2.1450,  2.1470,  2.1289,  ...,  1.8691,  1.8852,  1.9030],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0924,  0.0961,  0.1095,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.1120,  0.1157,  0.1291,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.1254,  0.1291,  0.1426,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.2273, -1.2328, -1.1582,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.4032, -1.2182, -1.0692,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.5057, -1.1812, -1.0174,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 0.4865,  0.4903,  0.5041,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.5066,  0.5103,  0.5241,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.5203,  0.5241,  0.5378,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.1778, -1.1762, -1.0667,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.3556, -1.1386, -0.9675,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.4297, -1.0956, -0.9156,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.3863,  1.3901,  1.4038,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4063,  1.4100,  1.4237,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4200,  1.4237,  1.4374,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.5379, -1.5387, -1.4407,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.6751, -1.4599, -1.3072,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.7252, -1.3961, -1.2367,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-0.4750, -0.7658, -0.6750,  ...,  1.2539,  1.2618,  1.2720],\n",
      "          [-1.0305, -1.1912, -1.2023,  ...,  1.2117,  1.2499,  1.2716],\n",
      "          [-1.5013, -1.4061, -1.4192,  ...,  1.1713,  1.2415,  1.2716]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-0.7892, -1.0971, -1.0390,  ...,  0.7111,  0.7191,  0.7296],\n",
      "          [-1.2911, -1.4825, -1.5221,  ...,  0.6680,  0.7070,  0.7291],\n",
      "          [-1.7557, -1.6676, -1.7258,  ...,  0.6266,  0.6984,  0.7291]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.0229, -1.3270, -1.2585,  ...,  0.0238,  0.0318,  0.0423],\n",
      "          [-1.5017, -1.6758, -1.7001,  ..., -0.0191,  0.0198,  0.0418],\n",
      "          [-1.7914, -1.8005, -1.8031,  ..., -0.0603,  0.0112,  0.0418]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6281, -0.6244, -0.6048,  ..., -0.6121, -0.4792, -0.5772],\n",
      "          [-0.6281, -0.6244, -0.6048,  ..., -0.7829, -0.6028, -0.5619],\n",
      "          [-0.6281, -0.6244, -0.6048,  ..., -1.2452, -1.1548, -0.9996],\n",
      "          ...,\n",
      "          [-0.3737, -0.2288, -0.3522,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.0890, -0.0136, -0.1177,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.1802,  0.0599, -0.0589,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-0.4951, -0.4913, -0.4713,  ..., -0.6460, -0.4446, -0.4970],\n",
      "          [-0.4951, -0.4913, -0.4713,  ..., -0.7668, -0.5434, -0.4579],\n",
      "          [-0.4951, -0.4913, -0.4713,  ..., -1.1491, -1.0297, -0.8682],\n",
      "          ...,\n",
      "          [-1.1000, -0.8037, -0.6908,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.9294, -0.7060, -0.5390,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.7382, -0.6766, -0.5506,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 0.2522,  0.2559,  0.2759,  ...,  0.3360,  0.2383, -0.0150],\n",
      "          [ 0.2522,  0.2559,  0.2759,  ...,  0.0357,  0.0989,  0.0670],\n",
      "          [ 0.2522,  0.2559,  0.2759,  ..., -0.6126, -0.4748, -0.2891],\n",
      "          ...,\n",
      "          [-1.2389, -0.9501, -0.8664,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.0563, -0.8541, -0.7214,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.8475, -0.8214, -0.7168,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-1.1234, -1.1039, -1.0843,  ..., -0.9979, -1.0045, -1.0048],\n",
      "          [-1.1234, -1.1039, -1.0843,  ..., -0.9877, -0.9982, -1.0045],\n",
      "          [-1.1234, -1.1039, -1.0843,  ..., -0.9855, -0.9877, -0.9979],\n",
      "          ...,\n",
      "          [-1.2392, -1.3029, -1.3096,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.0547, -1.1447, -1.1882,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.8212, -0.9302, -0.9892,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-0.5289, -0.5089, -0.4888,  ..., -0.3130, -0.3198, -0.3200],\n",
      "          [-0.5289, -0.5089, -0.4888,  ..., -0.3025, -0.3133, -0.3198],\n",
      "          [-0.5289, -0.5089, -0.4888,  ..., -0.3003, -0.3025, -0.3130],\n",
      "          ...,\n",
      "          [-0.8048, -0.8699, -0.8768,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.6161, -0.7081, -0.7526,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.3775, -0.4888, -0.5492,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 0.3406,  0.3605,  0.3804,  ...,  0.4509,  0.4442,  0.4439],\n",
      "          [ 0.3406,  0.3605,  0.3804,  ...,  0.4614,  0.4506,  0.4442],\n",
      "          [ 0.3406,  0.3605,  0.3804,  ...,  0.4636,  0.4614,  0.4509],\n",
      "          ...,\n",
      "          [-0.3175, -0.3824, -0.3892,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.1297, -0.2213, -0.2656,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.1079, -0.0030, -0.0631,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-0.7848, -0.5785, -0.6197,  ..., -1.2207, -0.8788, -0.3039],\n",
      "          [-0.7136, -0.5976, -0.7926,  ..., -1.1539, -0.9504, -0.6695],\n",
      "          [-0.5507, -0.5987, -0.9031,  ..., -1.3491, -1.0872, -0.9108],\n",
      "          ...,\n",
      "          [-1.5788, -1.6103, -1.8242,  ..., -1.7889, -1.7719, -1.7429],\n",
      "          [-1.2705, -1.3163, -1.4655,  ..., -1.9099, -1.9294, -1.9594],\n",
      "          [-1.1613, -1.2347, -1.3622,  ..., -1.9977, -2.0609, -2.1069]],\n",
      "\n",
      "         [[ 0.6187,  0.7518,  0.5601,  ..., -0.6078, -0.1715,  0.4478],\n",
      "          [ 0.6697,  0.6827,  0.3721,  ..., -0.5487, -0.2511,  0.0703],\n",
      "          [ 0.7569,  0.6238,  0.1933,  ..., -0.7558, -0.4143, -0.1969],\n",
      "          ...,\n",
      "          [-1.5721, -1.6019, -1.8238,  ..., -1.8556, -1.8383, -1.8087],\n",
      "          [-1.2844, -1.3304, -1.4841,  ..., -1.7730, -1.7930, -1.8237],\n",
      "          [-1.1803, -1.2553, -1.3799,  ..., -1.7335, -1.7669, -1.8220]],\n",
      "\n",
      "         [[ 1.4770,  1.5058,  1.1861,  ...,  0.0844,  0.5958,  1.2579],\n",
      "          [ 1.5495,  1.4924,  1.0272,  ...,  0.1254,  0.4802,  0.8654],\n",
      "          [ 1.7215,  1.4920,  0.8948,  ..., -0.1264,  0.2703,  0.5280],\n",
      "          ...,\n",
      "          [-1.4359, -1.4843, -1.7277,  ..., -1.6526, -1.6353, -1.6058],\n",
      "          [-1.1904, -1.2640, -1.4245,  ..., -1.6363, -1.6347, -1.6593],\n",
      "          [-1.1248, -1.2018, -1.3374,  ..., -1.6406, -1.6591, -1.7099]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.5617, -1.0575, -0.5590,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.5129, -0.9497, -0.3832,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.3315, -1.0158, -0.6807,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.0932, -0.5750, -0.0556,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.1045, -0.5258,  0.0641,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.9666, -0.6402, -0.2839,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-0.0843,  0.4228,  0.8951,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.0102,  0.5789,  1.1165,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.2148,  0.5254,  0.8139,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ..., -0.3113,  0.2054,  0.3544],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.0240,  0.2483,  0.3077],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.1304,  0.2004,  0.2314],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -0.1888,  0.3394,  0.4918],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.1050,  0.3833,  0.4440],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.2628,  0.3343,  0.3661],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  0.0118,  0.5253,  0.6770],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.3043,  0.5690,  0.6294],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.4614,  0.5202,  0.5518],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.1247, -1.1247, -1.1247,  ...,  1.6495,  1.6495,  1.6495],\n",
      "          [-1.1247, -1.1247, -1.1247,  ...,  1.6495,  1.6495,  1.6495],\n",
      "          [-1.1247, -1.1247, -1.1247,  ...,  1.6495,  1.6495,  1.6495],\n",
      "          ...,\n",
      "          [-0.4796, -0.3686, -0.3526,  ...,  1.4979,  1.3781,  1.3186],\n",
      "          [-0.2034, -0.2487, -0.3151,  ...,  1.7934,  1.6439,  1.6180],\n",
      "          [ 0.1079, -0.1345, -0.3031,  ...,  1.9625,  1.7444,  1.7144]],\n",
      "\n",
      "         [[-0.1450, -0.1450, -0.1450,  ...,  1.8859,  1.8859,  1.8859],\n",
      "          [-0.1450, -0.1450, -0.1450,  ...,  1.8859,  1.8859,  1.8859],\n",
      "          [-0.1450, -0.1450, -0.1450,  ...,  1.8859,  1.8859,  1.8859],\n",
      "          ...,\n",
      "          [-0.2033, -0.0898, -0.0734,  ...,  1.7308,  1.6083,  1.5475],\n",
      "          [ 0.0791,  0.0328, -0.0351,  ...,  2.0330,  1.8800,  1.8536],\n",
      "          [ 0.3973,  0.1495, -0.0229,  ...,  2.2058,  1.9829,  1.9521]],\n",
      "\n",
      "         [[ 1.1062,  1.1062,  1.1062,  ...,  2.2566,  2.2566,  2.2566],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  2.2566,  2.2566,  2.2566],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  2.2566,  2.2566,  2.2566],\n",
      "          ...,\n",
      "          [ 0.1767,  0.2897,  0.3060,  ...,  1.9976,  1.8757,  1.8151],\n",
      "          [ 0.4578,  0.4117,  0.3441,  ...,  2.2984,  2.1462,  2.1199],\n",
      "          [ 0.7746,  0.5280,  0.3563,  ...,  2.4705,  2.2486,  2.2180]]],\n",
      "\n",
      "\n",
      "        [[[-0.4397, -0.4397, -0.4397,  ..., -0.3027, -0.3027, -0.3027],\n",
      "          [-0.4360, -0.4360, -0.4360,  ..., -0.2990, -0.2990, -0.2990],\n",
      "          [-0.4164, -0.4164, -0.4164,  ..., -0.2794, -0.2794, -0.2794],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 0.1527,  0.1527,  0.1527,  ...,  0.2402,  0.2402,  0.2402],\n",
      "          [ 0.1564,  0.1564,  0.1564,  ...,  0.2439,  0.2439,  0.2439],\n",
      "          [ 0.1764,  0.1764,  0.1764,  ...,  0.2640,  0.2640,  0.2640],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.3328,  1.3328,  1.3328,  ...,  1.2282,  1.2282,  1.2282],\n",
      "          [ 1.3365,  1.3365,  1.3365,  ...,  1.2320,  1.2320,  1.2320],\n",
      "          [ 1.3565,  1.3565,  1.3565,  ...,  1.2519,  1.2519,  1.2519],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6919,  0.7162,  0.7549,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.6964,  0.7321,  0.7665,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.7150,  0.7383,  0.7752,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.0115, -0.9814, -0.9570,  ..., -0.4345, -0.3676, -0.2778],\n",
      "          [-1.0218, -1.1023, -1.0930,  ..., -0.4937, -0.4433, -0.3492],\n",
      "          [-0.9190, -1.0510, -1.0700,  ..., -0.5066, -0.4703, -0.3761]],\n",
      "\n",
      "         [[ 1.0644,  1.0893,  1.1289,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.0690,  1.1055,  1.1406,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.0880,  1.1118,  1.1496,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-0.7121, -0.6812, -0.6563,  ..., -0.1222, -0.0538,  0.0381],\n",
      "          [-0.7226, -0.8049, -0.7953,  ..., -0.1827, -0.1312, -0.0349],\n",
      "          [-0.6175, -0.7524, -0.7718,  ..., -0.1959, -0.1587, -0.0624]],\n",
      "\n",
      "         [[ 1.4387,  1.4635,  1.5029,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4433,  1.4797,  1.5147,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4623,  1.4859,  1.5236,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-0.4518, -0.4211, -0.3963,  ...,  0.2052,  0.2733,  0.3647],\n",
      "          [-0.4623, -0.5442, -0.5347,  ...,  0.1450,  0.1962,  0.2920],\n",
      "          [-0.3576, -0.4920, -0.5113,  ...,  0.1318,  0.1688,  0.2647]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -1.6453, -1.8769, -2.0091],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -1.6373, -1.8733, -1.9907],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -1.6264, -1.8598, -1.9772],\n",
      "          ...,\n",
      "          [-2.0323, -2.0286, -2.0130,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.0323, -2.0286, -2.0152,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.0164, -2.0195, -2.0311,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ..., -1.5701, -1.8206, -1.9595],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -1.5619, -1.8169, -1.9407],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -1.5508, -1.8031, -1.9269],\n",
      "          ...,\n",
      "          [-1.9482, -1.9444, -1.9284,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.9482, -1.9444, -1.9307,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.9319, -1.9351, -1.9469,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ..., -1.3757, -1.5841, -1.7112],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.3676, -1.5804, -1.6924],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.3565, -1.5667, -1.6787],\n",
      "          ...,\n",
      "          [-1.7173, -1.7136, -1.6976,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.7173, -1.7136, -1.6999,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.7011, -1.7043, -1.7161,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-1.5365, -1.5967, -1.6880,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.7477, -1.7184, -1.7104,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.8089, -1.7376, -1.6890,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-2.1167, -2.0934, -2.0543,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.1167, -2.0934, -2.0543,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.1167, -2.0934, -2.0543,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-1.4414, -1.5029, -1.5963,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.6573, -1.6273, -1.6191,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.7198, -1.6469, -1.5972,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.3704, -1.3742, -1.3942,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.3577, -1.3713, -1.3854,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.3542, -1.3704, -1.3830,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[-1.2476, -1.3089, -1.4018,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.4625, -1.4327, -1.4246,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.5248, -1.4522, -1.4028,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-0.3471, -0.3690, -0.3690,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.3737, -0.4026, -0.4026,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.4078, -0.4101, -0.4101,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  1.9590,  1.9262,  1.9223],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.9567,  1.9101,  1.9027],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.9358,  1.8844,  1.8771],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.1497,  2.1162,  2.1122],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.1473,  2.0997,  2.0922],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.1259,  2.0734,  2.0659],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.4495,  2.4162,  2.4122],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.4471,  2.3997,  2.3923],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.4259,  2.3736,  2.3661],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.5001, -1.4990, -1.4933,  ..., -1.3746, -1.4053, -1.4121],\n",
      "          [-1.4760, -1.4635, -1.4622,  ..., -1.3558, -1.3571, -1.3605],\n",
      "          [-1.4500, -1.4487, -1.4400,  ..., -1.2996, -1.3153, -1.3282],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.5808, -1.7149, -1.8184],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.5537, -1.6968, -1.8140],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.6398, -1.6015, -1.6025]],\n",
      "\n",
      "         [[-1.1415, -1.1404, -1.1346,  ..., -1.0658, -1.0716, -1.0716],\n",
      "          [-1.1169, -1.1041, -1.1028,  ..., -1.0540, -1.0553, -1.0518],\n",
      "          [-1.0903, -1.0890, -1.0801,  ..., -1.0428, -1.0442, -1.0324],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.5217, -1.6588, -1.7645],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.4939, -1.6402, -1.7601],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.5820, -1.5428, -1.5438]],\n",
      "\n",
      "         [[-0.3391, -0.3379, -0.3321,  ..., -0.3857, -0.3914, -0.3914],\n",
      "          [-0.3145, -0.3018, -0.3005,  ..., -0.3702, -0.3715, -0.3715],\n",
      "          [-0.2881, -0.2868, -0.2779,  ..., -0.3391, -0.3454, -0.3454],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.2055, -1.3420, -1.4473],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.1779, -1.3235, -1.4429],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.2656, -1.2266, -1.2276]]],\n",
      "\n",
      "\n",
      "        [[[-2.1008, -2.1008, -2.1008,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1008, -2.1008, -2.1008,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1069, -2.1069, -2.1069,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-2.0182, -2.0182, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0182, -2.0182, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0245, -2.0245, -2.0245,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-1.7870, -1.7870, -1.7870,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.7870, -1.7870, -1.7870,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.7932, -1.7932, -1.7932,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  0.3762,  0.3823,  0.3823],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.3762,  0.3823,  0.3823],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.3762,  0.3823,  0.3823],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.7540, -0.7614, -0.7866],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.7319, -0.7239, -0.7406],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.6998, -0.6819, -0.6830]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  0.7066,  0.7129,  0.7129],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.7066,  0.7129,  0.7129],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.7066,  0.7129,  0.7129],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.9328, -0.9452, -0.9723],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.9164, -0.9082, -0.9253],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.8836, -0.8652, -0.8664]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  0.9606,  0.9668,  0.9668],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.9606,  0.9668,  0.9668],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.9606,  0.9668,  0.9668],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.1596, -1.1719, -1.1990],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.1433, -1.1351, -1.1521],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.1106, -1.0923, -1.0935]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1301, -0.1256, -0.1070,  ..., -0.1486, -0.1486, -0.1486],\n",
      "          [-0.1023, -0.0891, -0.0814,  ..., -0.1486, -0.1486, -0.1486],\n",
      "          [-0.0446, -0.0422, -0.0336,  ..., -0.1424, -0.1424, -0.1424],\n",
      "          ...,\n",
      "          [-0.8375, -0.8771, -0.8935,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.7867, -0.9507, -1.0487,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.7318, -0.9668, -1.1487,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 0.8193,  0.8239,  0.8429,  ...,  0.7654,  0.7654,  0.7654],\n",
      "          [ 0.8477,  0.8612,  0.8691,  ...,  0.7654,  0.7654,  0.7654],\n",
      "          [ 0.9067,  0.9091,  0.9180,  ...,  0.7717,  0.7717,  0.7717],\n",
      "          ...,\n",
      "          [-0.4453, -0.4859, -0.5026,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.4260, -0.5936, -0.6938,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.3736, -0.6138, -0.7998,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.8371,  1.8348,  1.8283,  ...,  1.6988,  1.6988,  1.6988],\n",
      "          [ 1.8330,  1.8465,  1.8544,  ...,  1.6988,  1.6988,  1.6988],\n",
      "          [ 1.8918,  1.8942,  1.9030,  ...,  1.7050,  1.7050,  1.7050],\n",
      "          ...,\n",
      "          [-0.1751, -0.2155, -0.2321,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.1496, -0.3165, -0.4162,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.0974, -0.3366, -0.5217,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  0.0695,  0.0601,  0.0947],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.0825,  0.1178,  0.1937],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.1294,  0.2024,  0.3036],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  0.5157,  0.5335,  0.5764],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.5289,  0.5925,  0.6776],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.5768,  0.6790,  0.7900],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  0.9447,  0.9488,  0.9878],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.9579,  1.0075,  1.0885],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.0057,  1.0937,  1.2004],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-2.0139, -1.9980, -1.9919,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.0139, -1.9980, -1.9932,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.0083, -1.9980, -1.9980,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.3033, -1.2922, -1.3641],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.3744, -1.3941, -1.4956],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.5199, -1.6025, -1.7339]],\n",
      "\n",
      "         [[-1.6843, -1.6681, -1.6618,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.6843, -1.6681, -1.6632,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.6785, -1.6681, -1.6681,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.5180, -1.5068, -1.5802],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.5907, -1.6109, -1.7146],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.7394, -1.8239, -1.9583]],\n",
      "\n",
      "         [[ 0.7240,  0.7402,  0.7464,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.7240,  0.7402,  0.7451,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.7298,  0.7402,  0.7402,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.2890, -1.2778, -1.3509],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.3614, -1.3815, -1.4848],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.5095, -1.5936, -1.7274]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.0531, -2.0359, -2.0346,  ..., -0.5668, -0.2395, -0.0657],\n",
      "          [-2.1096, -2.0795, -1.9820,  ..., -0.4904, -0.2396, -0.0201],\n",
      "          [-2.0356, -2.0388, -1.9771,  ..., -0.6167, -0.4882, -0.2925],\n",
      "          ...,\n",
      "          [-0.7118, -0.6886, -0.3097,  ..., -0.6779, -0.6882, -0.8022],\n",
      "          [-0.9911, -0.7823, -0.4892,  ..., -0.5279, -0.5913, -0.7472],\n",
      "          [-0.9395, -0.5900, -0.6114,  ..., -0.5722, -0.6525, -0.8324]],\n",
      "\n",
      "         [[-1.9181, -1.8993, -1.8980,  ..., -1.1561, -1.0348, -0.9968],\n",
      "          [-1.9875, -1.9440, -1.8442,  ..., -1.0510, -0.9954, -0.9215],\n",
      "          [-1.8991, -1.9024, -1.8393,  ..., -1.1415, -1.1973, -1.1404],\n",
      "          ...,\n",
      "          [-0.5982, -0.5745, -0.1871,  ..., -0.9187, -0.9292, -1.0458],\n",
      "          [-0.8837, -0.6703, -0.3707,  ..., -0.7877, -0.8426, -1.0021],\n",
      "          [-0.8310, -0.4737, -0.4955,  ..., -0.8566, -0.9378, -1.1217]],\n",
      "\n",
      "         [[-1.8033, -1.7877, -1.7893,  ..., -1.6161, -1.2134, -0.8708],\n",
      "          [-1.8044, -1.7970, -1.7358,  ..., -1.4752, -1.0680, -0.7032],\n",
      "          [-1.7680, -1.7761, -1.7309,  ..., -1.4463, -1.1443, -0.7827],\n",
      "          ...,\n",
      "          [-0.5127, -0.4892, -0.1035,  ..., -0.6115, -0.5945, -0.7031],\n",
      "          [-0.7970, -0.5845, -0.2862,  ..., -0.4700, -0.5021, -0.6534],\n",
      "          [-0.7446, -0.3888, -0.4106,  ..., -0.5268, -0.5807, -0.7563]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.7655, -1.7654, -1.7737,  ..., -1.6091, -1.6152, -1.6152],\n",
      "          [-1.7184, -1.7812, -1.8158,  ..., -1.6651, -1.6617, -1.6617],\n",
      "          [-1.6823, -1.7932, -1.8529,  ..., -1.7208, -1.7204, -1.7204]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.5592, -1.5591, -1.5675,  ..., -1.2354, -1.2416, -1.2416],\n",
      "          [-1.4772, -1.5414, -1.5768,  ..., -1.2652, -1.2617, -1.2617],\n",
      "          [-1.4328, -1.5462, -1.6072,  ..., -1.3146, -1.3142, -1.3142]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.1433, -1.1432, -1.1516,  ..., -0.5720, -0.5782, -0.5782],\n",
      "          [-1.0878, -1.1517, -1.1870,  ..., -0.6251, -0.6118, -0.6118],\n",
      "          [-1.0473, -1.1603, -1.2210,  ..., -0.7015, -0.6747, -0.6678]]],\n",
      "\n",
      "\n",
      "        [[[-0.1242, -0.1055, -0.0911,  ..., -0.9898, -1.0117, -1.0282],\n",
      "          [-0.0458, -0.0385, -0.0116,  ..., -0.8863, -0.8568, -0.8267],\n",
      "          [-0.0886, -0.0852, -0.0727,  ..., -0.4669, -0.4347, -0.4037],\n",
      "          ...,\n",
      "          [-2.0844, -2.0947, -2.0802,  ..., -1.9980, -1.9737, -1.9585],\n",
      "          [-2.0983, -2.1142, -2.1116,  ..., -2.0397, -2.0249, -2.0179],\n",
      "          [-2.1020, -2.1179, -2.1179,  ..., -2.0812, -2.0802, -2.0800]],\n",
      "\n",
      "         [[ 1.3343,  1.3531,  1.3669,  ...,  0.7595,  0.7371,  0.7202],\n",
      "          [ 1.4382,  1.4411,  1.4519,  ...,  0.7902,  0.8234,  0.8549],\n",
      "          [ 1.4344,  1.4331,  1.4282,  ...,  1.0728,  1.1145,  1.1660],\n",
      "          ...,\n",
      "          [-2.0015, -2.0120, -1.9972,  ..., -1.9132, -1.8882, -1.8727],\n",
      "          [-2.0157, -2.0320, -2.0293,  ..., -1.9558, -1.9407, -1.9334],\n",
      "          [-2.0195, -2.0357, -2.0357,  ..., -1.9982, -1.9972, -1.9969]],\n",
      "\n",
      "         [[ 2.4569,  2.4757,  2.4778,  ...,  2.2308,  2.2084,  2.1916],\n",
      "          [ 2.5715,  2.5737,  2.5815,  ...,  2.2066,  2.2425,  2.2747],\n",
      "          [ 2.6151,  2.6114,  2.5977,  ...,  2.3683,  2.4187,  2.4666],\n",
      "          ...,\n",
      "          [-1.7355, -1.7459, -1.7313,  ..., -1.4957, -1.4709, -1.4554],\n",
      "          [-1.7497, -1.7659, -1.7632,  ..., -1.5506, -1.5355, -1.5283],\n",
      "          [-1.7534, -1.7696, -1.7696,  ..., -1.5928, -1.5918, -1.5916]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[ 0.3664,  0.3664,  0.3664,  ...,  0.7134,  0.7273,  0.7309],\n",
      "          [ 0.3860,  0.3860,  0.3860,  ...,  0.8226,  0.8435,  0.8471],\n",
      "          [ 0.4056,  0.4056,  0.4056,  ...,  0.9890,  1.0147,  1.0184],\n",
      "          ...,\n",
      "          [ 0.7762,  0.7762,  0.7823,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.7762,  0.7762,  0.7823,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.7762,  0.7762,  0.7823,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 0.6441,  0.6441,  0.6441,  ...,  0.9113,  0.9255,  0.9292],\n",
      "          [ 0.6641,  0.6641,  0.6641,  ...,  1.0154,  1.0368,  1.0405],\n",
      "          [ 0.6841,  0.6841,  0.6841,  ...,  1.1581,  1.1843,  1.1881],\n",
      "          ...,\n",
      "          [ 1.0280,  1.0280,  1.0343,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.0280,  1.0280,  1.0343,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.0280,  1.0280,  1.0343,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.0552,  1.0552,  1.0552,  ...,  1.2166,  1.2307,  1.2345],\n",
      "          [ 1.0751,  1.0751,  1.0751,  ...,  1.3203,  1.3415,  1.3453],\n",
      "          [ 1.0950,  1.0950,  1.0950,  ...,  1.4561,  1.4822,  1.4859],\n",
      "          ...,\n",
      "          [ 1.4548,  1.4548,  1.4610,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4548,  1.4548,  1.4610,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4548,  1.4548,  1.4610,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6221,  0.6221,  0.6221,  ...,  1.5125,  1.5125,  1.5125],\n",
      "          [ 0.6221,  0.6221,  0.6221,  ...,  1.5125,  1.5125,  1.5125],\n",
      "          [ 0.6282,  0.6282,  0.6282,  ...,  1.5125,  1.5125,  1.5125],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.7454, -1.9141, -1.9408],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.8826, -0.8667, -1.0338],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.3297, -0.2237, -0.5678]],\n",
      "\n",
      "         [[ 1.4132,  1.4132,  1.4132,  ...,  2.0434,  2.0434,  2.0434],\n",
      "          [ 1.4132,  1.4132,  1.4132,  ...,  2.0434,  2.0434,  2.0434],\n",
      "          [ 1.4194,  1.4194,  1.4194,  ...,  2.0434,  2.0434,  2.0434],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.6302, -1.7937, -1.8196],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.7440, -0.7216, -0.8796],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.1730, -0.0642, -0.3997]],\n",
      "\n",
      "         [[ 2.4134,  2.4134,  2.4134,  ...,  2.6226,  2.6226,  2.6226],\n",
      "          [ 2.4134,  2.4134,  2.4134,  ...,  2.6226,  2.6226,  2.6226],\n",
      "          [ 2.4196,  2.4196,  2.4196,  ...,  2.6226,  2.6226,  2.6226],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.5573, -1.7492, -1.8028],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.7092, -0.7319, -0.9284],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.1628, -0.0820, -0.4683]]],\n",
      "\n",
      "\n",
      "        [[[-1.9810, -1.9046, -1.8489,  ..., -1.8292, -1.7387, -1.7081],\n",
      "          [-1.8155, -1.7615, -1.7632,  ..., -1.8292, -1.7387, -1.7081],\n",
      "          [-1.8305, -1.7629, -1.7585,  ..., -1.8292, -1.7387, -1.7081],\n",
      "          ...,\n",
      "          [-1.8451, -1.7765, -1.7705,  ..., -1.7488, -1.8012, -1.8977],\n",
      "          [-1.8265, -1.7717, -1.7753,  ..., -1.6617, -1.7061, -1.8136],\n",
      "          [-1.8231, -1.7751, -1.7925,  ..., -1.6722, -1.7206, -1.8194]],\n",
      "\n",
      "         [[-2.0268, -2.0012, -1.9645,  ..., -1.7931, -1.7006, -1.6693],\n",
      "          [-1.9047, -1.8602, -1.8707,  ..., -1.7931, -1.7006, -1.6693],\n",
      "          [-1.8544, -1.8230, -1.8349,  ..., -1.7931, -1.7006, -1.6693],\n",
      "          ...,\n",
      "          [-1.7744, -1.7042, -1.6981,  ..., -1.6933, -1.7469, -1.8456],\n",
      "          [-1.7553, -1.6993, -1.7030,  ..., -1.6043, -1.6498, -1.7596],\n",
      "          [-1.7519, -1.7028, -1.7206,  ..., -1.6151, -1.6646, -1.7655]],\n",
      "\n",
      "         [[-1.7871, -1.7535, -1.7585,  ..., -1.4409, -1.3214, -1.2828],\n",
      "          [-1.5682, -1.5712, -1.6600,  ..., -1.4409, -1.3214, -1.2828],\n",
      "          [-1.5035, -1.5080, -1.5978,  ..., -1.4409, -1.3214, -1.2828],\n",
      "          ...,\n",
      "          [-1.4173, -1.3475, -1.3413,  ..., -1.3764, -1.4298, -1.5281],\n",
      "          [-1.3859, -1.3301, -1.3338,  ..., -1.2878, -1.3331, -1.4424],\n",
      "          [-1.3824, -1.3336, -1.3513,  ..., -1.2986, -1.3478, -1.4483]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-0.1486, -0.1486, -0.1424,  ..., -0.0059, -0.0125, -0.0128],\n",
      "          [-0.1486, -0.1486, -0.1424,  ..., -0.0116, -0.0221, -0.0284],\n",
      "          [-0.1486, -0.1486, -0.1424,  ..., -0.0216, -0.0238, -0.0340],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.0692, -2.0762, -2.0775],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.0837, -2.0731, -2.0577],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.0575, -2.0384, -2.0188]],\n",
      "\n",
      "         [[ 0.4678,  0.4678,  0.4740,  ...,  0.6161,  0.6094,  0.6091],\n",
      "          [ 0.4678,  0.4678,  0.4740,  ...,  0.6429,  0.6320,  0.6256],\n",
      "          [ 0.4678,  0.4678,  0.4740,  ...,  0.6451,  0.6429,  0.6324],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0035, -2.0106, -2.0120],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0182, -2.0074, -1.9917],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.9915, -1.9719, -1.9519]],\n",
      "\n",
      "         [[ 1.5071,  1.5071,  1.5133,  ...,  1.4793,  1.4725,  1.4722],\n",
      "          [ 1.5071,  1.5071,  1.5133,  ...,  1.4971,  1.4864,  1.4800],\n",
      "          [ 1.5071,  1.5071,  1.5133,  ...,  1.5268,  1.5245,  1.5141],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.7894]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3312,  1.1502,  1.1056,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.3648,  1.3978,  1.2511,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.2773,  1.5340,  1.4502,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 1.4379,  1.2528,  1.2259,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.4722,  1.5060,  1.3748,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.3828,  1.6452,  1.5783,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.4969,  1.3201,  1.3145,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.5310,  1.5721,  1.4626,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4420,  1.7107,  1.6653,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.5676, -1.4202, -1.4088,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.6172, -1.4487, -1.1563,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.5072, -1.3572, -0.8676,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 0.8545,  0.8521,  0.8435,  ...,  1.4269,  1.4183,  1.4159],\n",
      "          [ 0.9058,  0.9022,  0.8839,  ...,  1.4183,  1.4106,  1.4098],\n",
      "          [ 0.9291,  0.9254,  0.9058,  ...,  1.4159,  1.4098,  1.4098]],\n",
      "\n",
      "         [[-1.4731, -1.3225, -1.3108,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.5238, -1.3516, -1.0526,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.4114, -1.2580, -0.7575,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 1.0030,  1.0006,  0.9917,  ...,  1.5882,  1.5794,  1.5770],\n",
      "          [ 1.0555,  1.0518,  1.0331,  ...,  1.5794,  1.5715,  1.5707],\n",
      "          [ 1.0793,  1.0755,  1.0555,  ...,  1.5770,  1.5707,  1.5707]],\n",
      "\n",
      "         [[-1.2443, -1.0944, -1.0827,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.2948, -1.1234, -0.8257,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.1829, -1.0302, -0.5319,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 1.2208,  1.2184,  1.2096,  ...,  1.8034,  1.7946,  1.7922],\n",
      "          [ 1.2731,  1.2693,  1.2507,  ...,  1.7946,  1.7868,  1.7860],\n",
      "          [ 1.2967,  1.2930,  1.2731,  ...,  1.7922,  1.7860,  1.7860]]],\n",
      "\n",
      "\n",
      "        [[[-2.0764, -1.9533, -1.8113,  ...,  2.0675,  1.9791,  1.9409],\n",
      "          [-2.0817, -1.9886, -1.8844,  ...,  1.8593,  1.7023,  1.5863],\n",
      "          [-2.0980, -2.0496, -1.9853,  ...,  1.5146,  1.1528,  0.8763],\n",
      "          ...,\n",
      "          [-1.7246, -1.7195, -1.6465,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.6389, -1.5696, -1.5435,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.5846, -1.5202, -1.5593,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-0.8903, -0.7645, -0.6193,  ...,  2.2235,  2.0424,  1.9260],\n",
      "          [-0.8958, -0.8006, -0.6940,  ...,  2.2250,  2.0095,  1.8557],\n",
      "          [-0.9187, -0.8692, -0.8034,  ...,  2.1035,  1.7392,  1.4684],\n",
      "          ...,\n",
      "          [-1.6688, -1.6772, -1.5888,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.5986, -1.5239, -1.4835,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.5430, -1.4734, -1.4996,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 0.0504,  0.1757,  0.3327,  ...,  2.6264,  2.4829,  2.3799],\n",
      "          [ 0.0450,  0.1398,  0.2583,  ...,  2.5632,  2.3950,  2.2661],\n",
      "          [ 0.0222,  0.0715,  0.1450,  ...,  2.3555,  2.0544,  1.8202],\n",
      "          ...,\n",
      "          [-1.5678, -1.5980, -1.5874,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.4913, -1.4356, -1.4825,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.4359, -1.3853, -1.4985,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-2.1179, -2.1179, -2.1179,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  1.0502,  1.0502,  1.0661],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.0502,  1.0502,  1.0661],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.0502,  1.0502,  1.0661],\n",
      "          ...,\n",
      "          [-1.7807, -1.8974, -1.9449,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.9903, -2.0717, -2.0860,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.1121, -2.1169, -2.1057,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.2731,  1.2731,  1.2894],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.2731,  1.2731,  1.2894],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.2731,  1.2731,  1.2894],\n",
      "          ...,\n",
      "          [-1.6209, -1.7429, -1.8013,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.8352, -1.9243, -1.9508,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0086, -2.0070, -1.9652,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  1.5420,  1.5420,  1.5581],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.5420,  1.5420,  1.5581],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.5420,  1.5420,  1.5581],\n",
      "          ...,\n",
      "          [-1.3749, -1.5080, -1.5741,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.5874, -1.6761, -1.7051,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.7600, -1.7585, -1.7169,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-0.9037, -0.7837, -0.7869,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.9433, -1.1563, -1.2281,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.1383, -1.4218, -1.6322,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-2.1155, -2.0754, -2.0321,  ..., -2.0802, -2.0810, -2.0746],\n",
      "          [-2.0200, -1.9634, -1.9308,  ..., -2.0452, -2.0731, -1.9634],\n",
      "          [-1.8615, -1.9632, -1.9953,  ..., -1.9904, -2.0543, -1.8496]],\n",
      "\n",
      "         [[-0.8255, -0.6498, -0.5545,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.8182, -0.9685, -0.9613,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.8845, -1.1304, -1.2678,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.6137, -1.5796, -1.5353,  ..., -1.8221, -1.8230, -1.8338],\n",
      "          [-1.4465, -1.3880, -1.3654,  ..., -1.7863, -1.8148, -1.7027],\n",
      "          [-1.2357, -1.3701, -1.4098,  ..., -1.7303, -1.7956, -1.5863]],\n",
      "\n",
      "         [[-0.3633, -0.3330, -0.4311,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.3739, -0.6967, -0.8504,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.5288, -0.9069, -1.1989,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.3270, -1.2918, -1.2428,  ..., -1.4349, -1.4358, -1.4465],\n",
      "          [-1.1481, -1.0899, -1.0674,  ..., -1.3993, -1.4277, -1.3161],\n",
      "          [-0.9209, -1.0466, -1.1115,  ..., -1.3436, -1.4086, -1.2002]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0711,  1.0636,  1.1023,  ...,  0.9234,  0.8838,  0.8753],\n",
      "          [ 1.1759,  1.1783,  1.2081,  ...,  0.8826,  0.8373,  0.8141],\n",
      "          [ 1.3719,  1.3573,  1.3783,  ...,  0.8082,  0.7652,  0.7419],\n",
      "          ...,\n",
      "          [ 1.6895,  1.6801,  1.6627,  ..., -1.9853, -1.9479, -1.9882],\n",
      "          [ 1.6838,  1.6801,  1.6606,  ..., -1.9870, -1.9540, -1.9944],\n",
      "          [ 1.6827,  1.6642,  1.6446,  ..., -1.9870, -1.9540, -2.0091]],\n",
      "\n",
      "         [[ 1.5921,  1.5735,  1.5786,  ...,  1.5287,  1.4882,  1.4795],\n",
      "          [ 1.6918,  1.6883,  1.6945,  ...,  1.4869,  1.4407,  1.4169],\n",
      "          [ 1.8646,  1.8470,  1.8506,  ...,  1.4109,  1.3669,  1.3431],\n",
      "          ...,\n",
      "          [ 2.0842,  2.0747,  2.0569,  ..., -1.9001, -1.8619, -1.9032],\n",
      "          [ 2.0784,  2.0747,  2.0547,  ..., -1.9019, -1.8681, -1.9094],\n",
      "          [ 2.0773,  2.0584,  2.0384,  ..., -1.9019, -1.8681, -1.9245]],\n",
      "\n",
      "         [[ 2.1384,  2.1228,  2.1213,  ...,  2.1674,  2.1395,  2.1309],\n",
      "          [ 2.2301,  2.2208,  2.2068,  ...,  2.1258,  2.0922,  2.0686],\n",
      "          [ 2.3748,  2.3560,  2.3586,  ...,  2.0502,  2.0188,  1.9951],\n",
      "          ...,\n",
      "          [ 2.4541,  2.4445,  2.4268,  ..., -1.6819, -1.6040, -1.6376],\n",
      "          [ 2.4483,  2.4445,  2.4246,  ..., -1.6837, -1.6102, -1.6438],\n",
      "          [ 2.4471,  2.4284,  2.4084,  ..., -1.6837, -1.6102, -1.6589]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[ 2.2489,  2.2489,  2.2489,  ..., -1.4500, -1.4500, -1.4500],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.4464, -1.4464, -1.4464],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.4268, -1.4268, -1.4268],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.1771, -0.4241, -0.4632],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.0054, -0.2664, -0.2669],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.1141, -0.1711, -0.1595]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  0.5553,  0.5553,  0.5553],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.5591,  0.5591,  0.5591],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.5791,  0.5791,  0.5791],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.4800, -0.6277, -0.6234],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.3999, -0.5863, -0.5306],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.3646, -0.5641, -0.4888]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  1.7685,  1.7685,  1.7685],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.7685,  1.7685,  1.7685],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.7748,  1.7748,  1.7748],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.5005, -0.6394, -0.6304],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.4299, -0.5939, -0.5490],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.4134, -0.5859, -0.4932]]],\n",
      "\n",
      "\n",
      "        [[[-1.5647, -1.3784, -1.4526,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.4880, -1.4701, -1.4848,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.3761, -1.3851, -1.3274,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.3860, -1.1490, -0.8385,  ..., -1.7575, -1.6920, -1.6787],\n",
      "          [-1.3324, -1.2424, -1.2226,  ..., -1.7979, -1.7908, -1.7681],\n",
      "          [-0.9745, -1.3797, -1.5413,  ..., -1.6785, -1.7929, -1.8528]],\n",
      "\n",
      "         [[ 0.0442,  0.1159, -0.1730,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.0568, -0.0351, -0.2590,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.0078, -0.1047, -0.2039,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-0.7510, -0.5063, -0.1778,  ..., -1.4172, -1.3502, -1.3203],\n",
      "          [-0.7038, -0.6080, -0.5740,  ..., -1.4233, -1.4112, -1.3845],\n",
      "          [-0.3566, -0.7556, -0.9139,  ..., -1.2789, -1.3896, -1.4357]],\n",
      "\n",
      "         [[-1.5562, -1.3501, -1.3604,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.5099, -1.4444, -1.4165,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.4749, -1.4046, -1.2775,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.3098, -1.1083, -0.8362,  ..., -1.6480, -1.6114, -1.6350],\n",
      "          [-1.1288, -1.0575, -1.1049,  ..., -1.7882, -1.7807, -1.7818],\n",
      "          [-0.6828, -1.1333, -1.3516,  ..., -1.7755, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6997,  1.6841,  1.6728,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.6926,  1.6838,  1.6863,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.6606,  1.6655,  1.6777,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-0.5415, -0.8061, -0.9977,  ...,  0.3209,  0.4027,  0.5591],\n",
      "          [-0.3091, -0.5946, -0.8211,  ...,  0.2834,  0.3674,  0.4485],\n",
      "          [-0.1855, -0.4123, -0.6080,  ...,  0.4704,  0.3676,  0.1006]],\n",
      "\n",
      "         [[ 1.9196,  1.8961,  1.8571,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.9124,  1.8959,  1.8709,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.8796,  1.8772,  1.8621,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-0.6692, -0.9397, -1.1356,  ...,  0.1293,  0.2085,  0.3684],\n",
      "          [-0.4316, -0.7235, -0.9550,  ...,  0.0866,  0.1724,  0.2553],\n",
      "          [-0.3215, -0.5499, -0.7372,  ...,  0.2777,  0.1727, -0.1003]],\n",
      "\n",
      "         [[ 2.2205,  2.1971,  2.1582,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.2133,  2.1968,  2.1720,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.1806,  2.1782,  2.1610,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-0.6133, -0.8827, -1.0777,  ..., -0.1943, -0.1280,  0.0312],\n",
      "          [-0.3643, -0.6549, -0.8854,  ..., -0.2467, -0.1639, -0.0814],\n",
      "          [-0.2224, -0.4567, -0.6686,  ..., -0.0590, -0.1636, -0.4354]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.7191, -1.6084, -1.0705,  ...,  0.2270,  0.6194,  0.3902],\n",
      "          [-1.3534, -1.3192, -1.0135,  ..., -0.3726, -0.1100, -0.1961],\n",
      "          [-1.1670, -1.0304, -0.8916,  ..., -0.8662, -0.8960, -0.7934]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.7868, -1.6760, -1.1413,  ...,  0.0639,  0.4651,  0.2307],\n",
      "          [-1.3942, -1.3630, -1.0705,  ..., -0.5490, -0.2806, -0.3686],\n",
      "          [-1.1874, -1.0480, -0.9134,  ..., -1.0537, -1.0842, -0.9792]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.7951, -1.7058, -1.1876,  ..., -0.1897,  0.2097, -0.0236],\n",
      "          [-1.4856, -1.4291, -1.0911,  ..., -0.8300, -0.5726, -0.6602],\n",
      "          [-1.2934, -1.1408, -0.9345,  ..., -1.3488, -1.3800, -1.2755]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6495,  1.6495,  1.6495,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.6495,  1.6495,  1.6495,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.6557,  1.6557,  1.6557,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.0084,  2.0084,  2.0084,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.0084,  2.0084,  2.0084,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.0147,  2.0147,  2.0147,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.3263,  2.3263,  2.3263,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.3263,  2.3263,  2.3263,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.3325,  2.3325,  2.3325,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-1.6769, -1.6589, -1.4825,  ..., -1.5424, -1.4491, -1.4104],\n",
      "          [-1.7059, -1.5869, -1.4635,  ..., -1.3103, -1.4462, -1.5501],\n",
      "          [-1.6582, -1.6128, -1.4909,  ..., -1.2276, -1.4441, -1.5412],\n",
      "          ...,\n",
      "          [-0.6667, -0.7921, -0.9574,  ..., -0.5082, -0.8294, -0.7211],\n",
      "          [-0.7097, -0.8764, -1.0272,  ..., -0.3873, -0.7881, -0.9258],\n",
      "          [-0.5995, -0.8594, -1.0976,  ..., -0.0921, -0.3810, -0.7846]],\n",
      "\n",
      "         [[-1.1635, -1.1454, -0.9660,  ..., -0.7488, -0.6529, -0.6134],\n",
      "          [-1.1769, -1.0582, -0.9441,  ..., -0.5435, -0.6775, -0.7837],\n",
      "          [-1.1223, -1.0817, -0.9633,  ..., -0.5078, -0.7291, -0.8284],\n",
      "          ...,\n",
      "          [-0.4675, -0.6878, -0.9804,  ..., -0.1400, -0.4011, -0.2463],\n",
      "          [-0.5899, -0.8478, -1.1380,  ..., -0.0829, -0.4549, -0.5429],\n",
      "          [-0.5511, -0.8811, -1.2832,  ...,  0.1762, -0.0864, -0.4614]],\n",
      "\n",
      "         [[-1.3930, -1.3672, -1.1594,  ..., -0.9871, -0.8984, -0.8590],\n",
      "          [-1.4656, -1.3308, -1.1656,  ..., -0.7759, -0.9191, -1.0248],\n",
      "          [-1.4686, -1.3836, -1.2111,  ..., -0.7302, -0.9506, -1.0494],\n",
      "          ...,\n",
      "          [-0.3378, -0.5285, -0.8148,  ..., -0.0292, -0.3140, -0.1707],\n",
      "          [-0.5286, -0.7861, -1.0426,  ...,  0.1087, -0.2767, -0.3808],\n",
      "          [-0.5332, -0.8589, -1.2436,  ...,  0.3860,  0.1178, -0.2720]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.0583,  2.0909,  1.9978,  ..., -0.3920, -0.3724, -0.3528],\n",
      "          [ 1.9808,  2.0563,  2.0400,  ..., -0.3505, -0.3267, -0.3063],\n",
      "          [ 2.0209,  2.0715,  2.1114,  ..., -0.2987, -0.2574, -0.2342],\n",
      "          ...,\n",
      "          [ 0.2351,  0.2281,  0.2272,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.2514,  0.2543,  0.2710,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.3590,  0.3740,  0.3754,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.3212,  2.3546,  2.2656,  ...,  0.6741,  0.6941,  0.7141],\n",
      "          [ 2.2345,  2.3117,  2.3013,  ...,  0.7165,  0.7408,  0.7617],\n",
      "          [ 2.2297,  2.2872,  2.3320,  ...,  0.7694,  0.8117,  0.8354],\n",
      "          ...,\n",
      "          [ 0.3698,  0.3627,  0.3618,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.3865,  0.3895,  0.4065,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.4965,  0.5118,  0.5133,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6342,  2.6253,  2.5226,  ...,  2.1134,  2.1333,  2.1532],\n",
      "          [ 2.5551,  2.6245,  2.5618,  ...,  2.1556,  2.1798,  2.2005],\n",
      "          [ 2.5689,  2.6027,  2.6043,  ...,  2.2083,  2.2503,  2.2740],\n",
      "          ...,\n",
      "          [ 0.3812,  0.3741,  0.3732,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.3979,  0.4008,  0.4178,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.5073,  0.5226,  0.5240,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2000,  2.1966,  2.1780,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2281,  2.2281,  2.2233,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.1906,  2.1963,  2.1963,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-0.3409, -0.4551, -0.4918,  ..., -0.6639, -0.7001, -0.6708],\n",
      "          [-0.3125, -0.4588, -0.4949,  ..., -0.5520, -0.5291, -0.4852],\n",
      "          [-0.3397, -0.4058, -0.3500,  ..., -0.5215, -0.4828, -0.4581]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4248,  2.4248,  2.4248,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.3740,  2.3798,  2.3798,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-0.1477, -0.2646, -0.3020,  ..., -0.3464, -0.3973, -0.3909],\n",
      "          [-0.1512, -0.3008, -0.3377,  ..., -0.2410, -0.2296, -0.1947],\n",
      "          [-0.1828, -0.2504, -0.1934,  ..., -0.2216, -0.1887, -0.1638]],\n",
      "\n",
      "         [[ 2.5703,  2.5668,  2.5416,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.5628,  2.5620,  2.5493,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.4985,  2.5019,  2.4931,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-0.1103, -0.2267, -0.2639,  ..., -0.1943, -0.2481, -0.2299],\n",
      "          [-0.1474, -0.2964, -0.3331,  ..., -0.1470, -0.1384, -0.1001],\n",
      "          [-0.1864, -0.2536, -0.1969,  ..., -0.1482, -0.1213, -0.0965]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.2315, -0.2893, -0.3251],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.1035,  0.0541,  0.0266],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.2813,  0.2838,  0.2821]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.0329, -0.0262, -0.0629],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.3753,  0.3248,  0.2967],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.5571,  0.5596,  0.5579]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.3072,  0.2484,  0.2119],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.6482,  0.5979,  0.5699],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.8291,  0.8316,  0.8299]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.8610, -1.8610, -1.8610,  ..., -1.0623, -1.0562, -1.0562],\n",
      "          [-1.8610, -1.8610, -1.8610,  ..., -1.0623, -1.0562, -1.0562],\n",
      "          [-1.8671, -1.8671, -1.8671,  ..., -1.0623, -1.0562, -1.0562],\n",
      "          ...,\n",
      "          [-0.5256, -0.8616, -0.8543,  ..., -1.4481, -1.6004, -1.7444],\n",
      "          [-0.6753, -0.9593, -1.2019,  ..., -1.4313, -1.5129, -1.5759],\n",
      "          [-0.9325, -0.9910, -1.4126,  ..., -1.4710, -1.5824, -1.5991]],\n",
      "\n",
      "         [[-1.5105, -1.5105, -1.5105,  ..., -0.1862, -0.1800, -0.1800],\n",
      "          [-1.5105, -1.5105, -1.5105,  ..., -0.1862, -0.1800, -0.1800],\n",
      "          [-1.5105, -1.5105, -1.5105,  ..., -0.1862, -0.1800, -0.1800],\n",
      "          ...,\n",
      "          [ 0.0186, -0.3249, -0.3175,  ..., -1.0386, -1.1965, -1.3658],\n",
      "          [-0.1545, -0.4448, -0.6929,  ..., -1.0627, -1.1717, -1.2425],\n",
      "          [-0.4375, -0.4938, -0.9120,  ..., -1.1384, -1.2604, -1.2777]],\n",
      "\n",
      "         [[ 0.3742,  0.3742,  0.3742,  ...,  1.7623,  1.7685,  1.7685],\n",
      "          [ 0.3742,  0.3742,  0.3742,  ...,  1.7623,  1.7685,  1.7685],\n",
      "          [ 0.3804,  0.3804,  0.3804,  ...,  1.7623,  1.7685,  1.7685],\n",
      "          ...,\n",
      "          [-0.6394, -0.9889, -1.0089,  ..., -1.1611, -1.2802, -1.3985],\n",
      "          [-0.7134, -1.0040, -1.2568,  ..., -1.0971, -1.1514, -1.1884],\n",
      "          [-0.8993, -0.9657, -1.4202,  ..., -1.1078, -1.1695, -1.1744]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2318,  2.2318,  2.2318,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2318,  2.2318,  2.2318,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2318,  2.2318,  2.2318,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4111,  2.4111,  2.4111,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4111,  2.4111,  2.4111,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4111,  2.4111,  2.4111,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6226,  2.6226,  2.6226,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6226,  2.6226,  2.6226,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6226,  2.6226,  2.6226,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1574,  0.2373,  0.4028,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.0731,  0.1943,  0.4019,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.0537,  0.1988,  0.4254,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 0.4422,  0.4814,  0.5083,  ...,  0.6979,  0.7236,  0.7273],\n",
      "          [ 0.4630,  0.4993,  0.5156,  ...,  0.6035,  0.6090,  0.6223],\n",
      "          [ 0.5340,  0.5661,  0.5613,  ...,  0.5617,  0.5435,  0.5560]],\n",
      "\n",
      "         [[-0.0072,  0.0782,  0.2799,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.0934,  0.0342,  0.2790,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.1132,  0.0389,  0.3030,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 0.5353,  0.5753,  0.6028,  ...,  0.8079,  0.8342,  0.8379],\n",
      "          [ 0.5503,  0.5874,  0.6041,  ...,  0.7115,  0.7171,  0.7307],\n",
      "          [ 0.6229,  0.6556,  0.6508,  ...,  0.6687,  0.6501,  0.6629]],\n",
      "\n",
      "         [[-0.0987, -0.0062,  0.2157,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.1845, -0.0500,  0.2149,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.2042, -0.0453,  0.2388,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 0.8647,  0.9046,  0.9319,  ...,  1.1137,  1.1398,  1.1436],\n",
      "          [ 0.8921,  0.9290,  0.9456,  ...,  1.0177,  1.0233,  1.0368],\n",
      "          [ 0.9643,  0.9969,  0.9921,  ...,  0.9751,  0.9566,  0.9693]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[-0.9400, -0.9877, -0.9510,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.9400, -0.9877, -0.9510,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.9400, -0.9877, -0.9510,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.2799,  1.2607,  1.2329],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.2704,  1.2630,  1.2434],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.2565,  1.2434,  1.2091]],\n",
      "\n",
      "         [[-0.9190, -0.9678, -0.9303,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.9190, -0.9678, -0.9303,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.9190, -0.9678, -0.9303,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.2453,  1.2258,  1.1973],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.2356,  1.2281,  1.2081],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.2214,  1.2081,  1.1730]],\n",
      "\n",
      "         [[-0.7450, -0.7936, -0.7562,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.7450, -0.7936, -0.7562,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.7450, -0.7936, -0.7562,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.4272,  1.4077,  1.3793],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.4175,  1.4100,  1.3901],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.4033,  1.3901,  1.3551]]],\n",
      "\n",
      "\n",
      "        [[[-1.7312, -1.7708, -1.6141,  ...,  0.1896,  0.1549,  0.1439],\n",
      "          [-1.7285, -1.7577, -1.6783,  ..., -0.0930,  0.0222,  0.0035],\n",
      "          [-1.6103, -1.6880, -1.6480,  ..., -0.2036, -0.1548, -0.2473],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.5246, -0.5251, -0.5298],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.4663, -0.4173, -0.3954],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.3568, -0.2618, -0.2133]],\n",
      "\n",
      "         [[-1.6404, -1.6808, -1.5207,  ...,  0.3233,  0.2878,  0.2765],\n",
      "          [-1.6376, -1.6674, -1.5862,  ...,  0.0344,  0.1521,  0.1330],\n",
      "          [-1.5168, -1.5962, -1.5553,  ..., -0.0787, -0.0287, -0.1233],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.4068, -0.4074, -0.4121],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.3473, -0.2972, -0.2747],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.2353, -0.1382, -0.0886]],\n",
      "\n",
      "         [[-1.4109, -1.4511, -1.2917,  ...,  0.5440,  0.5087,  0.4975],\n",
      "          [-1.4081, -1.4378, -1.3570,  ...,  0.2565,  0.3737,  0.3546],\n",
      "          [-1.2878, -1.3668, -1.3262,  ...,  0.1439,  0.1936,  0.0994],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.1828, -0.1834, -0.1881],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.1235, -0.0736, -0.0513],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.0121,  0.0847,  0.1340]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8379,  1.8379,  1.8440,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.8379,  1.8379,  1.8440,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.8379,  1.8379,  1.8440,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-0.6371, -0.6171, -0.5632,  ..., -1.4522, -1.4356, -1.4408],\n",
      "          [-0.6351, -0.6265, -0.6033,  ..., -1.5269, -1.4962, -1.5097],\n",
      "          [-0.5349, -0.5710, -0.6064,  ..., -1.6035, -1.4497, -1.3787]],\n",
      "\n",
      "         [[ 2.0259,  2.0259,  2.0322,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.0259,  2.0259,  2.0322,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.0259,  2.0259,  2.0322,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-0.2942, -0.2738, -0.2187,  ..., -1.3552, -1.3382, -1.3435],\n",
      "          [-0.2647, -0.2559, -0.2322,  ..., -1.4315, -1.4001, -1.4139],\n",
      "          [-0.1548, -0.1917, -0.2278,  ..., -1.5099, -1.3526, -1.2801]],\n",
      "\n",
      "         [[ 2.3088,  2.3088,  2.3151,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.3088,  2.3088,  2.3151,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.3088,  2.3088,  2.3151,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 0.0750,  0.0952,  0.1501,  ..., -1.1618, -1.1449, -1.1501],\n",
      "          [ 0.0844,  0.0932,  0.1168,  ..., -1.2378, -1.2065, -1.2203],\n",
      "          [ 0.1901,  0.1534,  0.1174,  ..., -1.3158, -1.1592, -1.0870]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.0562, -1.0562, -1.0562,  ..., -1.1809, -1.1623, -1.1430],\n",
      "          [-1.0562, -1.0562, -1.0562,  ..., -1.1650, -1.1560, -1.1393],\n",
      "          [-1.0501, -1.0501, -1.0501,  ..., -1.1589, -1.1393, -1.1255],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-0.1800, -0.1800, -0.1800,  ..., -0.3075, -0.2885, -0.2688],\n",
      "          [-0.1800, -0.1800, -0.1800,  ..., -0.2913, -0.2821, -0.2650],\n",
      "          [-0.1737, -0.1737, -0.1737,  ..., -0.2850, -0.2650, -0.2508],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 0.8274,  0.8274,  0.8274,  ...,  0.7701,  0.7890,  0.8087],\n",
      "          [ 0.8274,  0.8274,  0.8274,  ...,  0.7863,  0.7954,  0.8124],\n",
      "          [ 0.8336,  0.8336,  0.8336,  ...,  0.7925,  0.8124,  0.8266],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3137,  0.2291,  0.1010,  ..., -0.7794, -1.1381, -1.1882],\n",
      "          [ 0.4673,  0.0613, -0.4302,  ..., -1.2348, -1.2045, -0.9232],\n",
      "          [-0.2527, -0.7099, -1.2237,  ..., -1.5872, -1.0900, -0.5640],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.0706, -0.7731, -0.4507],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.5988,  0.6865,  0.7899],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.5220,  1.4375,  1.2841]],\n",
      "\n",
      "         [[ 0.6065,  0.5200,  0.3890,  ..., -0.6736, -1.0341, -1.0852],\n",
      "          [ 0.7360,  0.3209, -0.1816,  ..., -1.1391, -1.1019, -0.8143],\n",
      "          [-0.0539, -0.5213, -1.0466,  ..., -1.4994, -0.9848, -0.4471],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.0175, -0.7134, -0.3838],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.6891,  0.7788,  0.8845],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.6329,  1.5465,  1.3897]],\n",
      "\n",
      "         [[ 0.8123,  0.7262,  0.5958,  ..., -0.3948, -0.7998, -0.8582],\n",
      "          [ 0.9936,  0.5803,  0.0800,  ..., -0.8583, -0.8674, -0.5885],\n",
      "          [ 0.2333, -0.2320, -0.7550,  ..., -1.2170, -0.7508, -0.2229],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.9476, -0.6449, -0.3167],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.7514,  0.8407,  0.9459],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.6910,  1.6050,  1.4489]]],\n",
      "\n",
      "\n",
      "        [[[-0.0116, -0.0116, -0.0116,  ..., -1.2561, -1.2296, -1.2353],\n",
      "          [-0.0116, -0.0116, -0.0116,  ..., -1.1620, -1.1870, -1.1153],\n",
      "          [-0.0054, -0.0068, -0.0116,  ..., -1.1479, -1.0674, -1.0617],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.3103, -1.3081, -1.3081],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.3094, -1.3094, -1.2969],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.3448, -1.3324, -1.3278]],\n",
      "\n",
      "         [[ 0.7479,  0.7479,  0.7479,  ..., -0.4006, -0.3755, -0.3818],\n",
      "          [ 0.7479,  0.7479,  0.7479,  ..., -0.2919, -0.3391, -0.2717],\n",
      "          [ 0.7542,  0.7528,  0.7479,  ..., -0.3163, -0.2192, -0.2094],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.1051, -1.1028, -1.1028],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.1041, -1.1041, -1.0913],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.1404, -1.1276, -1.1229]],\n",
      "\n",
      "         [[ 1.5942,  1.5942,  1.5942,  ...,  0.7306,  0.7681,  0.7621],\n",
      "          [ 1.5942,  1.5942,  1.5942,  ...,  0.7707,  0.7345,  0.8045],\n",
      "          [ 1.6005,  1.5991,  1.5942,  ...,  0.6668,  0.7585,  0.7670],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.9477, -0.9454, -0.9454],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.9467, -0.9467, -0.9340],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.9828, -0.9701, -0.9654]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.8481, -0.7894, -1.3375,  ..., -1.7326, -1.6015, -1.7377],\n",
      "          [-0.5232, -0.8847, -1.3194,  ..., -1.7606, -1.5648, -1.6224],\n",
      "          [-0.3463, -0.6805, -0.7479,  ..., -1.8432, -1.5788, -1.4901],\n",
      "          ...,\n",
      "          [ 0.7619,  0.5541,  0.6623,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.0234,  0.9910,  0.8436,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.2172,  1.1001,  0.8662,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-0.6875, -0.6713, -1.2792,  ..., -1.7201, -1.5213, -1.6472],\n",
      "          [-0.3554, -0.7687, -1.2607,  ..., -1.7619, -1.5128, -1.5386],\n",
      "          [-0.1745, -0.5599, -0.6764,  ..., -1.8727, -1.5557, -1.4427],\n",
      "          ...,\n",
      "          [ 0.8096,  0.6033,  0.7366,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.0706,  1.0451,  0.9219,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.2688,  1.1565,  0.9449,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[-0.7573, -0.7213, -1.3127,  ..., -1.6409, -1.4903, -1.6268],\n",
      "          [-0.4266, -0.8182, -1.2943,  ..., -1.6811, -1.4818, -1.5187],\n",
      "          [-0.2466, -0.6104, -0.7126,  ..., -1.7483, -1.5027, -1.4166],\n",
      "          ...,\n",
      "          [ 1.0096,  0.8018,  0.9256,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.2881,  1.2589,  1.1226,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4854,  1.3699,  1.1455,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2318,  2.2318,  2.2318,  ..., -1.6898, -1.6898, -1.6898],\n",
      "          [ 2.2318,  2.2318,  2.2318,  ..., -1.6898, -1.6898, -1.6898],\n",
      "          [ 2.2318,  2.2318,  2.2318,  ..., -1.6898, -1.6898, -1.6898],\n",
      "          ...,\n",
      "          [-1.4031, -1.3742, -1.3473,  ...,  1.1335,  1.1874,  1.1945],\n",
      "          [-1.3840, -1.3636, -1.3473,  ...,  1.0522,  1.2148,  1.1749],\n",
      "          [-1.3792, -1.3448, -1.3371,  ...,  1.0838,  1.3345,  1.2432]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -1.8431, -1.8431, -1.8431],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.8431, -1.8431, -1.8431],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.8431, -1.8431, -1.8431],\n",
      "          ...,\n",
      "          [-1.5501, -1.5205, -1.4930,  ...,  1.0432,  1.0983,  1.1055],\n",
      "          [-1.5305, -1.5097, -1.4930,  ...,  0.9600,  1.1263,  1.0854],\n",
      "          [-1.5256, -1.4905, -1.4825,  ...,  0.9924,  1.2486,  1.1553]],\n",
      "\n",
      "         [[ 2.3611,  2.3611,  2.3611,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.3611,  2.3611,  2.3611,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.3611,  2.3611,  2.3611,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [-1.7741, -1.7447, -1.7173,  ...,  0.8076,  0.8625,  0.8697],\n",
      "          [-1.7546, -1.7339, -1.7173,  ...,  0.7248,  0.8903,  0.8497],\n",
      "          [-1.7498, -1.7148, -1.7069,  ...,  0.7570,  1.0122,  0.9192]]],\n",
      "\n",
      "\n",
      "        [[[-0.5082, -0.5082, -0.5082,  ..., -0.2794, -0.2856, -0.2856],\n",
      "          [-0.5082, -0.5082, -0.5082,  ..., -0.2794, -0.2856, -0.2856],\n",
      "          [-0.5082, -0.5082, -0.5082,  ..., -0.2794, -0.2856, -0.2856],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-0.1099, -0.1099, -0.1099,  ...,  0.0364,  0.0301,  0.0301],\n",
      "          [-0.1099, -0.1099, -0.1099,  ...,  0.0364,  0.0301,  0.0301],\n",
      "          [-0.1099, -0.1099, -0.1099,  ...,  0.0364,  0.0301,  0.0301],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 0.5136,  0.5136,  0.5136,  ...,  0.5722,  0.5659,  0.5659],\n",
      "          [ 0.5136,  0.5136,  0.5136,  ...,  0.5722,  0.5659,  0.5659],\n",
      "          [ 0.5136,  0.5136,  0.5136,  ...,  0.5722,  0.5659,  0.5659],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.1760, -1.1760, -1.1760,  ..., -1.0835, -1.0902, -1.0904],\n",
      "          [-1.1760, -1.1760, -1.1760,  ..., -1.0733, -1.0839, -1.0902],\n",
      "          [-1.1699, -1.1699, -1.1699,  ..., -1.0711, -1.0733, -1.0835],\n",
      "          ...,\n",
      "          [-1.9543, -1.7177, -1.5153,  ..., -1.5019, -1.3506, -1.2845],\n",
      "          [-1.6079, -1.5237, -1.4050,  ..., -1.4867, -1.3435, -1.2876],\n",
      "          [-1.4287, -1.4913, -1.4639,  ..., -1.4819, -1.3894, -1.3756]],\n",
      "\n",
      "         [[-0.6352, -0.6352, -0.6352,  ..., -0.4355, -0.4423, -0.4426],\n",
      "          [-0.6352, -0.6352, -0.6352,  ..., -0.4251, -0.4359, -0.4423],\n",
      "          [-0.6289, -0.6289, -0.6289,  ..., -0.4228, -0.4251, -0.4355],\n",
      "          ...,\n",
      "          [-1.5884, -1.3540, -1.1808,  ..., -1.2009, -1.0587, -0.9911],\n",
      "          [-1.2342, -1.1497, -1.0504,  ..., -1.1854, -1.0515, -0.9943],\n",
      "          [-1.0510, -1.1150, -1.1058,  ..., -1.1805, -1.0984, -1.0843]],\n",
      "\n",
      "         [[ 0.3045,  0.3045,  0.3045,  ...,  0.5555,  0.5488,  0.5485],\n",
      "          [ 0.3045,  0.3045,  0.3045,  ...,  0.5659,  0.5552,  0.5488],\n",
      "          [ 0.3107,  0.3107,  0.3107,  ...,  0.5681,  0.5659,  0.5555],\n",
      "          ...,\n",
      "          [-1.5857, -1.3524, -1.1613,  ..., -1.0842, -0.9364, -0.8690],\n",
      "          [-1.2331, -1.1490, -1.0314,  ..., -1.0961, -0.9565, -0.8996],\n",
      "          [-1.0507, -1.1144, -1.0866,  ..., -1.0986, -1.0107, -0.9967]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ..., -1.7542, -1.7693, -1.7925],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.7641, -1.7773, -1.7906],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.7492, -1.7157, -1.6658],\n",
      "          ...,\n",
      "          [-2.0837, -2.0837, -2.0837,  ..., -2.0323, -2.0323, -2.0323],\n",
      "          [-2.0837, -2.0837, -2.0837,  ..., -2.0323, -2.0323, -2.0323],\n",
      "          [-2.0837, -2.0837, -2.0837,  ..., -2.0323, -2.0323, -2.0323]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -1.9077, -1.9419, -1.9808],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.9107, -1.9477, -1.9637],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.8626, -1.8598, -1.8174],\n",
      "          ...,\n",
      "          [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
      "          [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
      "          [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0182]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ..., -1.6301, -1.6588, -1.6975],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.6190, -1.6579, -1.6730],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.5624, -1.5508, -1.5062],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  0.2865,  0.2798,  0.2796],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.2967,  0.2861,  0.2832],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.2967,  0.2967,  0.2967],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.1401,  0.0677, -0.0140],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.3898,  0.4210,  0.0963],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.4369,  0.6408,  0.2044]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  0.9825,  0.9758,  0.9755],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.9930,  0.9822,  0.9792],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.9930,  0.9930,  0.9930],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.2525, -0.3265, -0.4101],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.0028,  0.0347, -0.2973],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.0509,  0.2593, -0.1868]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  1.6013,  1.5945,  1.5942],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.6117,  1.6009,  1.5980],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.6117,  1.6117,  1.6117],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.5172, -0.5909, -0.6740],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.2630, -0.2313, -0.5617],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.2151, -0.0076, -0.4517]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[ 0.1988,  0.2610,  0.3134,  ..., -0.2837, -0.5008, -0.9241],\n",
      "          [ 0.2252,  0.2755,  0.3053,  ..., -0.2967, -0.4177, -0.4828],\n",
      "          [ 0.2816,  0.2928,  0.2945,  ..., -0.2299, -0.0540,  0.3093],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -1.9995, -2.0053, -1.9450],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.0383, -2.0217, -1.9515],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.0331, -1.9941, -1.9197]],\n",
      "\n",
      "         [[ 0.3327,  0.3962,  0.4498,  ..., -0.1606, -0.3825, -0.8152],\n",
      "          [ 0.3597,  0.4112,  0.4416,  ..., -0.1738, -0.2975, -0.3641],\n",
      "          [ 0.4173,  0.4288,  0.4305,  ..., -0.1056,  0.0742,  0.4456],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -1.9147, -1.9206, -1.8589],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -1.9543, -1.9374, -1.8656],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -1.9490, -1.9091, -1.8331]],\n",
      "\n",
      "         [[ 0.5535,  0.6167,  0.6701,  ...,  0.0623, -0.1585, -0.5894],\n",
      "          [ 0.5803,  0.6316,  0.6619,  ...,  0.0492, -0.0740, -0.1402],\n",
      "          [ 0.6377,  0.6492,  0.6508,  ...,  0.1171,  0.2961,  0.6659],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.6840, -1.6898, -1.6285],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.7234, -1.7065, -1.6351],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.7181, -1.6784, -1.6028]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9554,  1.9727,  1.9623,  ...,  2.0182,  2.0219,  2.0214],\n",
      "          [ 1.8979,  1.9349,  1.9554,  ...,  1.9873,  1.9549,  1.9468],\n",
      "          [ 1.8518,  1.8990,  1.9407,  ...,  1.9722,  1.9270,  1.9130],\n",
      "          ...,\n",
      "          [-0.8661, -0.8088, -0.7957,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.8174, -0.7937, -0.8626,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.8469, -0.8514, -0.9664,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.1460,  2.1637,  2.1531,  ...,  2.1927,  2.2103,  2.2135],\n",
      "          [ 2.0872,  2.1251,  2.1460,  ...,  2.1611,  2.1418,  2.1372],\n",
      "          [ 2.0401,  2.0883,  2.1310,  ...,  2.1537,  2.1209,  2.1089],\n",
      "          ...,\n",
      "          [-0.4638, -0.4110, -0.4039,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.4270, -0.4156, -0.4923,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.4726, -0.4818, -0.6126,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.2542,  2.2718,  2.2612,  ...,  2.4276,  2.4575,  2.4607],\n",
      "          [ 2.1956,  2.2333,  2.2542,  ...,  2.3914,  2.3877,  2.3848],\n",
      "          [ 2.1487,  2.1967,  2.2414,  ...,  2.3624,  2.3450,  2.3379],\n",
      "          ...,\n",
      "          [-1.5894, -1.5130, -1.4383,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.4534, -1.4075, -1.4208,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.4208, -1.4098, -1.4550,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-0.5047, -0.4519, -0.4010,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.5072, -0.4890, -0.4508,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.5086, -0.5156, -0.5125,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 0.7366,  0.7554,  0.7750,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.8192,  0.8205,  0.8241,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.9250,  0.9104,  0.8695,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.1696,  1.2474,  1.3174,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.2747,  1.3166,  1.3401,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4170,  1.4110,  1.4078,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.7591,  0.7591,  0.7591,  ...,  0.4679,  0.4679,  0.4679],\n",
      "          [ 0.7554,  0.7554,  0.7554,  ...,  0.4643,  0.4643,  0.4643],\n",
      "          [ 0.7358,  0.7358,  0.7358,  ...,  0.4447,  0.4447,  0.4447],\n",
      "          ...,\n",
      "          [ 0.0373, -0.0186, -0.0271,  ..., -0.1846, -0.1694, -0.1657],\n",
      "          [-0.0691, -0.0466, -0.1100,  ..., -0.1534, -0.1290, -0.1128],\n",
      "          [-0.0719,  0.0354, -0.0820,  ..., -0.1016, -0.0578, -0.0348]],\n",
      "\n",
      "         [[ 1.0805,  1.0805,  1.0805,  ...,  0.7829,  0.7829,  0.7829],\n",
      "          [ 1.0768,  1.0768,  1.0768,  ...,  0.7792,  0.7792,  0.7792],\n",
      "          [ 1.0568,  1.0568,  1.0568,  ...,  0.7592,  0.7592,  0.7592],\n",
      "          ...,\n",
      "          [ 0.5002,  0.4430,  0.4344,  ...,  0.2909,  0.3065,  0.3102],\n",
      "          [ 0.3914,  0.4145,  0.3496,  ...,  0.3228,  0.3477,  0.3643],\n",
      "          [ 0.3886,  0.4983,  0.3783,  ...,  0.3757,  0.4205,  0.4440]],\n",
      "\n",
      "         [[ 1.4548,  1.4548,  1.4548,  ...,  1.1759,  1.1759,  1.1759],\n",
      "          [ 1.4511,  1.4511,  1.4511,  ...,  1.1722,  1.1722,  1.1722],\n",
      "          [ 1.4312,  1.4312,  1.4312,  ...,  1.1523,  1.1523,  1.1523],\n",
      "          ...,\n",
      "          [ 0.6854,  0.6284,  0.6198,  ...,  0.4770,  0.4925,  0.4962],\n",
      "          [ 0.5770,  0.6000,  0.5354,  ...,  0.5087,  0.5336,  0.5500],\n",
      "          [ 0.5742,  0.6835,  0.5640,  ...,  0.5614,  0.6060,  0.6294]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ..., -0.7430, -0.9143, -1.2262],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.7546, -0.9651, -1.2917],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.6282, -1.0336, -1.4276],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.7698, -1.7960, -1.8043],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.8389, -1.8358, -1.8079],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.8867, -1.8669, -1.8428]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -0.5068, -0.6687, -0.9840],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.5081, -0.7142, -1.0473],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.3727, -0.7721, -1.1724],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.5223, -1.5491, -1.5576],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.5929, -1.5897, -1.5612],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.6418, -1.6215, -1.5969]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ..., -0.8595, -1.1053, -1.4696],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.9098, -1.1744, -1.5371],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.8201, -1.2961, -1.7081],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.6593, -1.6860, -1.6944],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.7297, -1.7265, -1.6981],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.7783, -1.7581, -1.7336]]],\n",
      "\n",
      "\n",
      "        [[[-0.2868, -0.2904, -0.3100,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.3100, -0.3129, -0.3283,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.3430, -0.3430, -0.3409,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 0.9042,  0.9005,  0.8805,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.8805,  0.8775,  0.8618,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.8467,  0.8467,  0.8489,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.0810,  2.0773,  2.0574,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.0574,  2.0544,  2.0388,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.0238,  2.0238,  2.0260,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-0.9266, -0.8301, -0.7459,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.8654, -0.7886, -0.7297,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.7753, -0.7113, -0.6853,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 0.5646,  0.5289,  0.2982,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.5457,  0.5463,  0.3591,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.5082,  0.5362,  0.3758,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 0.1451,  0.2549,  0.3886,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.2112,  0.2974,  0.4052,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.3165,  0.3813,  0.4505,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 1.3711,  1.3304,  1.1130,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.3386,  1.3373,  1.1554,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.2968,  1.3254,  1.1676,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.0487,  1.1849,  1.3187,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.1053,  1.2001,  1.3304,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.1722,  1.2681,  1.3535,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.2694,  2.2651,  2.0798,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.2765,  2.2923,  2.1432,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.2453,  2.2812,  2.1578,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-1.2274, -1.2274, -1.2274,  ..., -1.4610, -1.4672, -1.4672],\n",
      "          [-1.2274, -1.2274, -1.2274,  ..., -1.4610, -1.4672, -1.4672],\n",
      "          [-1.2274, -1.2274, -1.2274,  ..., -1.4610, -1.4672, -1.4672],\n",
      "          ...,\n",
      "          [-0.8874, -0.7357, -0.5265,  ...,  1.1135,  1.0514,  0.9890],\n",
      "          [-0.9204, -0.7716, -0.5682,  ...,  1.1688,  1.1406,  1.0869],\n",
      "          [-0.9448, -0.8081, -0.5995,  ...,  1.2239,  1.1793,  1.1359]],\n",
      "\n",
      "         [[-1.6155, -1.6155, -1.6155,  ..., -1.7318, -1.7381, -1.7381],\n",
      "          [-1.6155, -1.6155, -1.6155,  ..., -1.7318, -1.7381, -1.7381],\n",
      "          [-1.6155, -1.6155, -1.6155,  ..., -1.7318, -1.7381, -1.7381],\n",
      "          ...,\n",
      "          [-1.6718, -1.5480, -1.4080,  ..., -0.3088, -0.3763, -0.4401],\n",
      "          [-1.7056, -1.5847, -1.4506,  ..., -0.2537, -0.3163, -0.3801],\n",
      "          [-1.7305, -1.6221, -1.4825,  ..., -0.2437, -0.2922, -0.3374]],\n",
      "\n",
      "         [[-1.7696, -1.7696, -1.7696,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.7696, -1.7696, -1.7696,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.7696, -1.7696, -1.7696,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [-1.7886, -1.7210, -1.6936,  ..., -1.7243, -1.7698, -1.8028],\n",
      "          [-1.7980, -1.7517, -1.7087,  ..., -1.7012, -1.7224, -1.7736],\n",
      "          [-1.8031, -1.7746, -1.7330,  ..., -1.6837, -1.7228, -1.7370]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.8697,  1.8819,  1.8689,  ...,  1.0844,  1.0844,  1.0844],\n",
      "          [ 1.8073,  1.8219,  1.8206,  ...,  1.0844,  1.0844,  1.0844],\n",
      "          [ 1.7417,  1.7693,  1.7919,  ...,  1.0844,  1.0844,  1.0844],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.3095, -0.2383,  0.0664],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.1672,  0.0581,  0.3321],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.0102,  0.2744,  0.4565]],\n",
      "\n",
      "         [[ 2.1109,  2.1310,  2.1452,  ...,  1.4657,  1.4657,  1.4657],\n",
      "          [ 2.0472,  2.0680,  2.0909,  ...,  1.4657,  1.4657,  1.4657],\n",
      "          [ 1.9801,  2.0083,  2.0394,  ...,  1.4657,  1.4657,  1.4657],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.6946, -0.6218, -0.3104],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.5491, -0.3189, -0.0387],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.3678, -0.0977,  0.0884]],\n",
      "\n",
      "         [[ 2.5329,  2.5529,  2.5670,  ...,  2.0125,  2.0125,  2.0125],\n",
      "          [ 2.4694,  2.4902,  2.5130,  ...,  2.0125,  2.0125,  2.0125],\n",
      "          [ 2.3964,  2.4259,  2.4617,  ...,  2.0125,  2.0125,  2.0125],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.0146, -0.9421, -0.6321],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.8822, -0.6530, -0.3741],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.7017, -0.4328, -0.2475]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  1.9456,  1.8994,  1.8176],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.7955,  1.8469,  1.9430],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.8814,  1.8910,  2.0219],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.1495,  0.0630, -0.0216],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.3748,  0.7758,  0.5286],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.7165,  0.8505,  0.6767]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.2060,  2.1588,  2.0751],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.0525,  2.1051,  2.2034],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.1404,  2.1502,  2.2841],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.0234,  0.1938,  0.1074],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.4989,  0.9089,  0.6561],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.8445,  0.9815,  0.8037]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.4707,  2.4237,  2.3404],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.3179,  2.3703,  2.4681],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.4054,  2.4152,  2.5484],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.2338,  0.4501,  0.3640],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.7948,  1.2030,  0.9513],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.1501,  1.2865,  1.1095]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  1.7446,  1.7447,  1.7461],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.6174,  1.6267,  1.6471],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.4807,  1.5151,  1.5427],\n",
      "          ...,\n",
      "          [ 0.3152,  0.1245, -0.1906,  ..., -1.0538, -0.9696, -0.9493],\n",
      "          [-0.2837, -0.4232, -0.6385,  ..., -0.8558, -0.8412, -0.7625],\n",
      "          [-0.6980, -0.7638, -0.9030,  ..., -0.7178, -0.7186, -0.5653]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.9854,  1.9869,  1.9883],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.8983,  1.9226,  1.9434],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.8071,  1.8569,  1.8892],\n",
      "          ...,\n",
      "          [ 0.2354,  0.0404, -0.2817,  ..., -0.9362, -0.8468, -0.8285],\n",
      "          [-0.3707, -0.5132, -0.7333,  ..., -0.7870, -0.7602, -0.6776],\n",
      "          [-0.7942, -0.8615, -1.0038,  ..., -0.7056, -0.6671, -0.5148]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.3574,  2.3584,  2.3598],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.2875,  2.3068,  2.3275],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.1844,  2.2291,  2.2598],\n",
      "          ...,\n",
      "          [ 0.2661,  0.0720, -0.2487,  ..., -0.9538, -0.8313, -0.8056],\n",
      "          [-0.3833, -0.5253, -0.7444,  ..., -0.8301, -0.7649, -0.6752],\n",
      "          [-0.8125, -0.8795, -1.0211,  ..., -0.7588, -0.7049, -0.5042]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 0.1699,  0.1167,  0.1602,  ...,  0.2771,  0.2868,  0.2106],\n",
      "          [ 0.0513, -0.0328,  0.0189,  ...,  0.1426,  0.1475,  0.0643],\n",
      "          [ 0.0143, -0.1138, -0.0943,  ...,  0.1344,  0.1450,  0.0766]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 0.2857,  0.2313,  0.2757,  ...,  0.3777,  0.3877,  0.3098],\n",
      "          [ 0.1645,  0.0784,  0.1313,  ...,  0.2402,  0.2452,  0.1602],\n",
      "          [ 0.1266, -0.0044,  0.0156,  ...,  0.2319,  0.2427,  0.1728]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 0.7506,  0.6965,  0.7408,  ...,  0.8249,  0.8347,  0.7572],\n",
      "          [ 0.6300,  0.5443,  0.5970,  ...,  0.6879,  0.6929,  0.6083],\n",
      "          [ 0.5922,  0.4619,  0.4817,  ...,  0.6797,  0.6904,  0.6208]]],\n",
      "\n",
      "\n",
      "        [[[-0.9841, -0.9657, -0.9461,  ..., -0.6961, -0.7225, -0.7296],\n",
      "          [-0.9461, -0.9432, -0.9265,  ..., -0.6844, -0.7027, -0.7063],\n",
      "          [-0.9069, -0.9069, -0.9030,  ..., -0.6501, -0.6587, -0.6611],\n",
      "          ...,\n",
      "          [-2.1008, -2.1008, -2.1069,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.1008, -2.1008, -2.1069,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.1008, -2.1008, -2.1069,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-0.5965, -0.5776, -0.5576,  ..., -0.0395, -0.0389, -0.0387],\n",
      "          [-0.5576, -0.5547, -0.5376,  ..., -0.0275, -0.0187, -0.0149],\n",
      "          [-0.5176, -0.5189, -0.5198,  ...,  0.0076,  0.0263,  0.0314],\n",
      "          ...,\n",
      "          [-2.0182, -2.0182, -2.0245,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0182, -2.0182, -2.0245,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0182, -2.0182, -2.0245,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 0.0816,  0.1003,  0.1202,  ...,  0.9498,  0.9367,  0.9332],\n",
      "          [ 0.1202,  0.1232,  0.1402,  ...,  0.9617,  0.9568,  0.9568],\n",
      "          [ 0.1601,  0.1627,  0.1765,  ...,  0.9967,  1.0016,  1.0029],\n",
      "          ...,\n",
      "          [-1.7870, -1.7870, -1.7932,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.7870, -1.7870, -1.7932,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.7870, -1.7870, -1.7932,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1975,  2.1975,  2.1975,  ...,  0.5059,  0.4872,  0.4827],\n",
      "          [ 2.1975,  2.1975,  2.1975,  ...,  0.4667,  0.4577,  0.4444],\n",
      "          [ 2.1975,  2.1975,  2.1975,  ...,  0.4337,  0.4141,  0.4104],\n",
      "          ...,\n",
      "          [-1.9919, -1.9932, -2.0020,  ..., -2.0506, -2.0702, -2.0739],\n",
      "          [-1.9855, -1.9980, -1.9993,  ..., -1.9233, -1.9275, -1.9283],\n",
      "          [-1.9810, -1.9821, -1.9878,  ..., -1.7896, -1.7840, -1.7840]],\n",
      "\n",
      "         [[ 2.3760,  2.3761,  2.3761,  ...,  1.1893,  1.1703,  1.1657],\n",
      "          [ 2.3761,  2.3761,  2.3761,  ...,  1.1493,  1.1401,  1.1265],\n",
      "          [ 2.3761,  2.3761,  2.3761,  ...,  1.1155,  1.0955,  1.0918],\n",
      "          ...,\n",
      "          [-1.9244, -1.9258, -1.9347,  ..., -1.9669, -1.9869, -1.9907],\n",
      "          [-1.9179, -1.9307, -1.9320,  ..., -1.8230, -1.8273, -1.8281],\n",
      "          [-1.9133, -1.9144, -1.9202,  ..., -1.6826, -1.6768, -1.6768]],\n",
      "\n",
      "         [[ 2.5877,  2.5877,  2.5877,  ...,  1.8943,  1.8753,  1.8707],\n",
      "          [ 2.5877,  2.5877,  2.5877,  ...,  1.8582,  1.8490,  1.8355],\n",
      "          [ 2.5877,  2.5877,  2.5877,  ...,  1.8383,  1.8183,  1.8146],\n",
      "          ...,\n",
      "          [-1.7285, -1.7298, -1.7387,  ..., -1.7584, -1.7783, -1.7820],\n",
      "          [-1.7220, -1.7347, -1.7361,  ..., -1.6687, -1.6729, -1.6737],\n",
      "          [-1.7174, -1.7185, -1.7243,  ..., -1.5401, -1.5343, -1.5343]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  0.8389,  0.5065,  0.2369],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.2935,  0.2908,  0.3596],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.3527, -0.3018, -0.0116],\n",
      "          ...,\n",
      "          [-0.9639, -1.0754, -0.9737,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.1463, -1.2684, -1.2892,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.4004, -1.4497, -1.6202,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.0509,  0.7173,  0.4568],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.4908,  0.4931,  0.5634],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.1849, -0.1328,  0.1639],\n",
      "          ...,\n",
      "          [-0.7509, -0.8649, -0.7609,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.9373, -1.0622, -1.0835,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.1972, -1.2475, -1.4219,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  0.7182,  0.3084, -0.0105],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.1729,  0.1255,  0.1880],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.4282, -0.3921, -0.0989],\n",
      "          ...,\n",
      "          [-0.7221, -0.8382, -0.7569,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.9201, -1.0503, -1.0956,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.1788, -1.2364, -1.4374,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  0.1817,  0.1631,  0.1597],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.1608,  0.1531,  0.1523],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.1325,  0.1217,  0.1193],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  0.9280,  0.9089,  0.9055],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.9117,  0.9025,  0.9017],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.8992,  0.8841,  0.8817],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  1.4947,  1.4757,  1.4746],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.4819,  1.4768,  1.5014],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.4889,  1.4858,  1.4834],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7306,  0.7041,  0.6676,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.8942,  1.0555,  1.0358,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.1626,  1.3810,  1.2441,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 1.1138,  1.1603,  1.2329,  ...,  1.7422,  1.7035,  1.6345],\n",
      "          [ 1.2199,  1.2731,  1.3084,  ...,  1.7561,  1.7600,  1.7232],\n",
      "          [ 1.3365,  1.3734,  1.3764,  ...,  1.7515,  1.7819,  1.7535]],\n",
      "\n",
      "         [[ 1.0503,  1.0243,  0.9870,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.2022,  1.3798,  1.3583,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.4631,  1.6863,  1.5423,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 1.2856,  1.3331,  1.4074,  ...,  1.9281,  1.8885,  1.8180],\n",
      "          [ 1.3941,  1.4485,  1.4846,  ...,  1.9423,  1.9462,  1.9086],\n",
      "          [ 1.5133,  1.5510,  1.5541,  ...,  1.9376,  1.9687,  1.9396]],\n",
      "\n",
      "         [[ 1.4258,  1.4153,  1.3907,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.5685,  1.7499,  1.7477,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.7946,  2.0243,  1.9163,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 1.5893,  1.6366,  1.7105,  ...,  2.1766,  2.1372,  2.0670],\n",
      "          [ 1.6973,  1.7515,  1.7874,  ...,  2.1908,  2.1947,  2.1572],\n",
      "          [ 1.8159,  1.8535,  1.8566,  ...,  2.1860,  2.2170,  2.1881]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-3.5737e-01, -3.2024e-01, -1.6647e-01,  ..., -2.6843e-01,\n",
      "           -2.6843e-01, -2.6843e-01],\n",
      "          [-5.6174e-01, -1.9119e-01,  2.0503e-01,  ..., -2.7577e-01,\n",
      "           -2.7577e-01, -2.7577e-01],\n",
      "          [-3.0679e-01, -1.5988e-03,  4.3290e-01,  ..., -3.0880e-01,\n",
      "           -3.0880e-01, -3.0880e-01],\n",
      "          ...,\n",
      "          [ 1.2275e+00,  1.2262e+00,  1.2214e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 1.1945e+00,  1.1974e+00,  1.2080e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 1.1565e+00,  1.1715e+00,  1.1782e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[ 2.0286e-01,  2.3528e-01,  3.6775e-01,  ...,  5.5532e-01,\n",
      "            5.5532e-01,  5.5532e-01],\n",
      "          [ 8.1390e-03,  3.5926e-01,  7.5317e-01,  ...,  5.4782e-01,\n",
      "            5.4782e-01,  5.4782e-01],\n",
      "          [ 2.6396e-01,  5.5800e-01,  9.6843e-01,  ...,  5.1406e-01,\n",
      "            5.1406e-01,  5.1406e-01],\n",
      "          ...,\n",
      "          [ 1.5945e+00,  1.5931e+00,  1.5882e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 1.5470e+00,  1.5499e+00,  1.5607e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 1.5044e+00,  1.5197e+00,  1.5265e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 1.5659e+00,  1.5592e+00,  1.6396e+00,  ...,  1.8557e+00,\n",
      "            1.8557e+00,  1.8557e+00],\n",
      "          [ 1.2560e+00,  1.5928e+00,  1.9442e+00,  ...,  1.8445e+00,\n",
      "            1.8445e+00,  1.8445e+00],\n",
      "          [ 1.3140e+00,  1.6372e+00,  2.0415e+00,  ...,  1.7972e+00,\n",
      "            1.7972e+00,  1.7972e+00],\n",
      "          ...,\n",
      "          [ 2.0885e+00,  2.0872e+00,  2.0823e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.0686e+00,  2.0715e+00,  2.0823e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.0336e+00,  2.0489e+00,  2.0557e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2044e+00,\n",
      "            2.1843e+00,  2.1929e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2157e+00,\n",
      "            2.1885e+00,  2.1418e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2030e+00,\n",
      "            2.1888e+00,  2.1168e+00],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.2731e+00,\n",
      "            2.2400e+00,  2.2488e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.2870e+00,\n",
      "            2.2481e+00,  2.2003e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.2868e+00,\n",
      "            2.2634e+00,  2.1885e+00],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6010e+00,\n",
      "            2.5743e+00,  2.5830e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6050e+00,\n",
      "            2.5711e+00,  2.5235e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.5686e+00,\n",
      "            2.5453e+00,  2.4707e+00],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  1.6570e+00,\n",
      "            1.6572e+00,  1.6673e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  1.6449e+00,\n",
      "            1.5262e+00,  1.3959e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  1.4412e+00,\n",
      "            1.2008e+00,  1.0187e+00],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  1.9176e+00,\n",
      "            1.9578e+00,  1.9938e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  1.9336e+00,\n",
      "            1.8540e+00,  1.7671e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  1.7699e+00,\n",
      "            1.5820e+00,  1.4165e+00],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.3350e+00,\n",
      "            2.3963e+00,  2.4652e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.3603e+00,\n",
      "            2.3182e+00,  2.2334e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.2014e+00,\n",
      "            2.0413e+00,  1.9092e+00],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  6.2896e-01,\n",
      "            3.3635e-01,  7.5372e-02],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  7.7994e-01,\n",
      "            4.6959e-01,  1.9123e-01],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  9.8858e-01,\n",
      "            7.1458e-01,  4.9222e-01],\n",
      "          ...,\n",
      "          [-1.9870e+00, -1.9931e+00, -2.0213e+00,  ..., -1.5014e+00,\n",
      "           -1.5162e+00, -1.5242e+00],\n",
      "          [-1.9684e+00, -1.9854e+00, -2.0078e+00,  ..., -1.4866e+00,\n",
      "           -1.5014e+00, -1.5051e+00],\n",
      "          [-1.9650e+00, -1.9846e+00, -2.0041e+00,  ..., -1.4786e+00,\n",
      "           -1.4977e+00, -1.5014e+00]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  9.4718e-01,\n",
      "            6.0882e-01,  3.3041e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  1.1068e+00,\n",
      "            7.7836e-01,  4.8100e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  1.3792e+00,\n",
      "            1.0902e+00,  8.4410e-01],\n",
      "          ...,\n",
      "          [-1.9019e+00, -1.9081e+00, -1.9369e+00,  ..., -1.4930e+00,\n",
      "           -1.5081e+00, -1.5163e+00],\n",
      "          [-1.8829e+00, -1.9002e+00, -1.9232e+00,  ..., -1.4779e+00,\n",
      "           -1.4930e+00, -1.4967e+00],\n",
      "          [-1.8794e+00, -1.8994e+00, -1.9194e+00,  ..., -1.4697e+00,\n",
      "           -1.4892e+00, -1.4930e+00]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  1.1766e-01,\n",
      "           -1.3293e-01, -3.8646e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  3.5438e-01,\n",
      "            8.4575e-02, -1.7162e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  7.3453e-01,\n",
      "            5.0439e-01,  3.0769e-01],\n",
      "          ...,\n",
      "          [-1.6712e+00, -1.6774e+00, -1.7061e+00,  ..., -1.6065e+00,\n",
      "           -1.6215e+00, -1.6297e+00],\n",
      "          [-1.6523e+00, -1.6695e+00, -1.6924e+00,  ..., -1.5977e+00,\n",
      "           -1.6127e+00, -1.6165e+00],\n",
      "          [-1.6488e+00, -1.6687e+00, -1.6887e+00,  ..., -1.5895e+00,\n",
      "           -1.6090e+00, -1.6127e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.3899e+00, -1.3903e+00, -1.4112e+00,  ...,  1.7213e+00,\n",
      "            1.8817e+00,  1.9972e+00],\n",
      "          [-1.5241e+00, -1.4737e+00, -1.4278e+00,  ...,  1.6295e+00,\n",
      "            1.5689e+00,  1.6186e+00],\n",
      "          [-1.6347e+00, -1.5578e+00, -1.4965e+00,  ...,  6.7290e-01,\n",
      "            6.7806e-01,  8.0964e-01],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[-1.1514e+00, -1.1518e+00, -1.1728e+00,  ...,  2.0467e+00,\n",
      "            2.2107e+00,  2.3288e+00],\n",
      "          [-1.2886e+00, -1.2371e+00, -1.1839e+00,  ...,  1.9529e+00,\n",
      "            1.8909e+00,  1.9418e+00],\n",
      "          [-1.4013e+00, -1.3168e+00, -1.2501e+00,  ...,  9.7495e-01,\n",
      "            9.8022e-01,  1.1147e+00],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[-6.9769e-01, -7.0729e-01, -7.5451e-01,  ...,  2.2424e+00,\n",
      "            2.4057e+00,  2.5232e+00],\n",
      "          [-8.4353e-01, -8.1765e-01, -7.7719e-01,  ...,  2.1490e+00,\n",
      "            2.0873e+00,  2.1379e+00],\n",
      "          [-9.8198e-01, -9.0942e-01, -8.5553e-01,  ...,  1.1754e+00,\n",
      "            1.1807e+00,  1.3146e+00],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]]], device='cuda:0')\n",
      "tensor([[[[-6.9655e-01, -6.9655e-01, -6.9655e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [-6.9655e-01, -6.9655e-01, -6.9655e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [-7.0267e-01, -7.0267e-01, -7.0267e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          ...,\n",
      "          [-1.6305e+00, -1.6438e+00, -1.6706e+00,  ..., -1.7452e+00,\n",
      "           -1.7139e+00, -1.7288e+00],\n",
      "          [-1.8231e+00, -1.8696e+00, -1.9383e+00,  ..., -1.7632e+00,\n",
      "           -1.6890e+00, -1.6788e+00],\n",
      "          [-2.0180e+00, -1.9815e+00, -1.9317e+00,  ..., -1.8880e+00,\n",
      "           -1.8530e+00, -1.8783e+00]],\n",
      "\n",
      "         [[-3.2003e-01, -3.2003e-01, -3.2003e-01,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [-3.2003e-01, -3.2003e-01, -3.2003e-01,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [-3.2628e-01, -3.2628e-01, -3.2628e-01,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          ...,\n",
      "          [-1.5200e+00, -1.5336e+00, -1.5609e+00,  ..., -1.6372e+00,\n",
      "           -1.6052e+00, -1.6205e+00],\n",
      "          [-1.7168e+00, -1.7644e+00, -1.8346e+00,  ..., -1.6556e+00,\n",
      "           -1.5797e+00, -1.5693e+00],\n",
      "          [-1.9160e+00, -1.8788e+00, -1.8279e+00,  ..., -1.7832e+00,\n",
      "           -1.7474e+00, -1.7733e+00]],\n",
      "\n",
      "         [[ 2.3477e-01,  2.3477e-01,  2.3477e-01,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.3477e-01,  2.3477e-01,  2.3477e-01,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.2855e-01,  2.2855e-01,  2.2855e-01,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          ...,\n",
      "          [-1.2213e+00, -1.2348e+00, -1.2620e+00,  ..., -1.3728e+00,\n",
      "           -1.3410e+00, -1.3562e+00],\n",
      "          [-1.4036e+00, -1.4509e+00, -1.5208e+00,  ..., -1.3911e+00,\n",
      "           -1.3156e+00, -1.3052e+00],\n",
      "          [-1.5981e+00, -1.5611e+00, -1.5104e+00,  ..., -1.5182e+00,\n",
      "           -1.4825e+00, -1.5083e+00]]],\n",
      "\n",
      "\n",
      "        [[[-8.8370e-01, -8.8370e-01, -8.8938e-01,  ..., -1.5724e+00,\n",
      "           -1.5858e+00, -1.5895e+00],\n",
      "          [-8.6046e-01, -8.6046e-01, -8.6046e-01,  ..., -1.5992e+00,\n",
      "           -1.6139e+00, -1.6176e+00],\n",
      "          [-8.1520e-01, -8.1520e-01, -8.1520e-01,  ..., -1.5503e+00,\n",
      "           -1.5651e+00, -1.5731e+00],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[ 1.1890e-01,  1.1890e-01,  1.2470e-01,  ..., -9.4938e-02,\n",
      "           -1.0869e-01, -1.1244e-01],\n",
      "          [ 1.4641e-01,  1.4641e-01,  1.4641e-01,  ..., -1.2236e-01,\n",
      "           -1.3746e-01, -1.4121e-01],\n",
      "          [ 2.0643e-01,  2.0643e-01,  2.0643e-01,  ..., -7.2429e-02,\n",
      "           -8.7524e-02, -9.5742e-02],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 2.1707e+00,  2.1707e+00,  2.1707e+00,  ...,  1.9578e+00,\n",
      "            1.9441e+00,  1.9403e+00],\n",
      "          [ 2.1868e+00,  2.1868e+00,  2.1868e+00,  ...,  1.9305e+00,\n",
      "            1.9154e+00,  1.9117e+00],\n",
      "          [ 2.2055e+00,  2.2055e+00,  2.2055e+00,  ...,  1.9677e+00,\n",
      "            1.9527e+00,  1.9445e+00],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.0435e+00,\n",
      "           -1.0322e+00, -1.0390e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.1378e+00,\n",
      "           -1.0836e+00, -1.0383e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.3269e+00,\n",
      "           -1.1911e+00, -9.1174e-01],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.7304e+00,\n",
      "           -1.7897e+00, -1.8138e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.1919e+00,\n",
      "           -1.5332e+00, -1.6901e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -6.8038e-01,\n",
      "           -1.2575e+00, -1.5901e+00]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -6.8767e-01,\n",
      "           -6.8196e-01, -7.0402e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -8.0236e-01,\n",
      "           -7.5288e-01, -7.0813e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -9.8824e-01,\n",
      "           -8.6703e-01, -6.0371e-01],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -1.5848e+00,\n",
      "           -1.6414e+00, -1.6660e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -1.0840e+00,\n",
      "           -1.4267e+00, -1.5871e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -5.8281e-01,\n",
      "           -1.1723e+00, -1.5124e+00]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -7.7399e-01,\n",
      "           -7.5478e-01, -7.7621e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -9.4383e-01,\n",
      "           -8.7011e-01, -8.1196e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -1.2160e+00,\n",
      "           -1.0866e+00, -7.9541e-01],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -1.5091e+00,\n",
      "           -1.6110e+00, -1.6430e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -8.3570e-01,\n",
      "           -1.2243e+00, -1.3915e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -2.4551e-01,\n",
      "           -8.5998e-01, -1.2025e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.0836e-01,\n",
      "           -1.7731e-01, -2.2413e-01],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  1.0080e-01,\n",
      "            4.8551e-02, -2.7866e-01],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.3877e-01,\n",
      "            4.4971e-02, -2.4205e-01],\n",
      "          ...,\n",
      "          [-1.7163e+00, -1.7544e+00, -1.8148e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [-1.7585e+00, -1.7897e+00, -1.8464e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [-1.8879e+00, -1.9046e+00, -1.9084e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.7244e-01,\n",
      "           -1.2183e-01, -1.6970e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  1.6249e-01,\n",
      "            1.0907e-01, -2.2544e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -8.2432e-02,\n",
      "            1.0541e-01, -1.8802e-01],\n",
      "          ...,\n",
      "          [-1.6426e+00, -1.6816e+00, -1.7434e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [-1.6858e+00, -1.7176e+00, -1.7757e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [-1.8181e+00, -1.8352e+00, -1.8390e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  4.4117e-01,\n",
      "            4.8649e-02,  9.9037e-04],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  3.3170e-01,\n",
      "            2.7852e-01, -5.4505e-02],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  8.7869e-02,\n",
      "            2.7488e-01, -1.7247e-02],\n",
      "          ...,\n",
      "          [-1.3085e+00, -1.3474e+00, -1.4088e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [-1.3516e+00, -1.3832e+00, -1.4410e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [-1.4833e+00, -1.5002e+00, -1.5041e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          ...,\n",
      "          [-1.1466e+00, -1.2357e+00, -1.2808e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [-1.1614e+00, -1.2715e+00, -1.3327e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [-1.3572e+00, -1.4491e+00, -1.4795e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          ...,\n",
      "          [-8.3264e-01, -9.2375e-01, -9.6984e-01,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [-8.4774e-01, -9.6028e-01, -1.0229e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [-1.0479e+00, -1.1419e+00, -1.1730e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          ...,\n",
      "          [-6.0672e-01, -6.9742e-01, -7.4331e-01,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [-6.2175e-01, -7.3379e-01, -7.9613e-01,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [-8.2103e-01, -9.1458e-01, -9.4553e-01,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8113e-01,  2.3666e-01, -4.6318e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 1.0627e+00,  5.6142e-01, -1.4760e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 1.1619e+00,  9.2698e-01,  5.7182e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          ...,\n",
      "          [-1.4325e+00, -1.4059e+00, -1.3789e+00,  ..., -2.5123e-01,\n",
      "           -1.9015e-01, -1.1553e-01],\n",
      "          [-1.3617e+00, -1.3604e+00, -1.3777e+00,  ..., -6.9996e-01,\n",
      "           -1.3754e-01,  3.1557e-01],\n",
      "          [-1.2848e+00, -1.3101e+00, -1.3664e+00,  ..., -7.0755e-01,\n",
      "            4.3230e-02,  4.6610e-01]],\n",
      "\n",
      "         [[ 5.2013e-01,  3.1487e-01, -3.2369e-01,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 1.1463e+00,  6.7885e-01,  2.2438e-03,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 1.3195e+00,  1.0933e+00,  7.5111e-01,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          ...,\n",
      "          [-9.4983e-01, -9.2268e-01, -8.9955e-01,  ..., -2.4992e-01,\n",
      "           -2.0517e-01, -1.4532e-01],\n",
      "          [-8.7748e-01, -8.7614e-01, -8.9383e-01,  ..., -7.2635e-01,\n",
      "           -1.6710e-01,  2.9451e-01],\n",
      "          [-7.9888e-01, -8.2469e-01, -8.8231e-01,  ..., -7.3894e-01,\n",
      "            1.6096e-02,  4.4841e-01]],\n",
      "\n",
      "         [[ 7.7846e-01,  5.4494e-01, -1.4191e-01,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 1.4725e+00,  9.6609e-01,  2.7283e-01,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 1.7059e+00,  1.4750e+00,  1.1223e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          ...,\n",
      "          [-5.3167e-01, -5.0464e-01, -4.8160e-01,  ..., -1.3117e-01,\n",
      "           -9.5410e-02, -4.4010e-02],\n",
      "          [-4.5964e-01, -4.5831e-01, -4.7591e-01,  ..., -6.1428e-01,\n",
      "           -6.5342e-02,  3.9342e-01],\n",
      "          [-3.8139e-01, -4.0708e-01, -4.6444e-01,  ..., -6.2922e-01,\n",
      "            1.1624e-01,  5.4663e-01]]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.3052, -1.2453, -1.1386,  ..., -1.6915, -1.5929, -1.5532],\n",
      "          [-1.2687, -1.2564, -1.2041,  ..., -1.7092, -1.5716, -1.5308],\n",
      "          [-1.2287, -1.1964, -1.1080,  ..., -1.6522, -1.4852, -1.4550]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.1173, -1.0674, -1.0121,  ..., -1.4485, -1.3414, -1.3009],\n",
      "          [-1.0801, -1.0758, -1.0652,  ..., -1.4754, -1.3226, -1.2779],\n",
      "          [-1.0241, -1.0136, -0.9632,  ..., -1.4196, -1.2351, -1.2005]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.0059, -0.9474, -0.8458,  ..., -1.5037, -1.4095, -1.3807],\n",
      "          [-0.9750, -0.9692, -0.9390,  ..., -1.5129, -1.3849, -1.3463],\n",
      "          [-0.9644, -0.9089, -0.8463,  ..., -1.4525, -1.2962, -1.2692]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4508,  0.4511,  0.4577,  ...,  0.7762,  0.7762,  0.7762],\n",
      "          [ 0.4511,  0.4574,  0.4679,  ...,  0.7762,  0.7762,  0.7762],\n",
      "          [ 0.4577,  0.4679,  0.4701,  ...,  0.7823,  0.7823,  0.7823],\n",
      "          ...,\n",
      "          [-1.3771, -1.3462, -1.3530,  ..., -0.6529, -0.6750, -0.6885],\n",
      "          [-1.3681, -1.3232, -1.2817,  ..., -0.4043, -0.4723, -0.5180],\n",
      "          [-1.3802, -1.3485, -1.2777,  ..., -0.3813, -0.4046, -0.4114]],\n",
      "\n",
      "         [[ 0.9055,  0.9057,  0.9125,  ...,  1.2031,  1.2031,  1.2031],\n",
      "          [ 0.9057,  0.9122,  0.9230,  ...,  1.2031,  1.2031,  1.2031],\n",
      "          [ 0.9188,  0.9292,  0.9315,  ...,  1.2093,  1.2093,  1.2093],\n",
      "          ...,\n",
      "          [-1.2959, -1.2643, -1.2712,  ..., -0.5443, -0.5668, -0.5807],\n",
      "          [-1.2867, -1.2408, -1.1983,  ..., -0.2839, -0.3533, -0.4001],\n",
      "          [-1.2991, -1.2667, -1.1942,  ..., -0.2604, -0.2842, -0.2911]],\n",
      "\n",
      "         [[ 1.7511,  1.7514,  1.7581,  ...,  2.0125,  2.0125,  2.0125],\n",
      "          [ 1.7514,  1.7578,  1.7685,  ...,  2.0088,  2.0088,  2.0088],\n",
      "          [ 1.7457,  1.7561,  1.7583,  ...,  2.0013,  2.0013,  2.0013],\n",
      "          ...,\n",
      "          [-0.9807, -0.9493, -0.9562,  ..., -0.4404, -0.4628, -0.4766],\n",
      "          [-0.9716, -0.9259, -0.8836,  ..., -0.1998, -0.2690, -0.3155],\n",
      "          [-0.9839, -0.9517, -0.8795,  ..., -0.1972, -0.2325, -0.2394]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1462,  2.1462,  2.1462,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.1498,  2.1498,  2.1498,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.1633,  2.1633,  2.1633,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.5330, -1.5722, -1.5694],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.6434, -1.6589, -1.5875],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.5927, -1.5855, -1.4694]],\n",
      "\n",
      "         [[ 1.6408,  1.6408,  1.6408,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.6445,  1.6445,  1.6445,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.6708,  1.6708,  1.6708,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.6315, -1.6716, -1.6688],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.6569, -1.6835, -1.6135],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.5863, -1.5928, -1.4778]],\n",
      "\n",
      "         [[-0.4275, -0.4275, -0.4275,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.4163, -0.4163, -0.4163,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.3690, -0.3690, -0.3690,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.4618, -1.4929, -1.4877],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.4759, -1.4672, -1.3878],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.4094, -1.3747, -1.2490]]],\n",
      "\n",
      "\n",
      "        [[[-0.1486, -0.1486, -0.1424,  ..., -0.9375, -0.9644, -0.9718],\n",
      "          [-0.1486, -0.1478, -0.1401,  ..., -0.9534, -0.9746, -0.9803],\n",
      "          [-0.1424, -0.1401, -0.1314,  ..., -0.9534, -0.9534, -0.9534],\n",
      "          ...,\n",
      "          [-0.0192, -0.1158, -0.2707,  ..., -0.7225, -0.6156, -0.5248],\n",
      "          [ 0.1804, -0.1924, -0.5608,  ..., -0.4265, -0.2856, -0.0971],\n",
      "          [ 0.0686, -0.2140, -0.5293,  ..., -0.3569, -0.1921,  0.0670]],\n",
      "\n",
      "         [[ 0.8179,  0.8179,  0.8242,  ...,  0.4315,  0.4453,  0.4490],\n",
      "          [ 0.8179,  0.8187,  0.8266,  ...,  0.4153,  0.4261,  0.4290],\n",
      "          [ 0.8242,  0.8266,  0.8354,  ...,  0.4153,  0.4153,  0.4153],\n",
      "          ...,\n",
      "          [ 1.1149,  1.0425,  0.9609,  ...,  0.9127,  1.1073,  1.2532],\n",
      "          [ 1.2990,  0.9494,  0.6666,  ...,  1.2028,  1.4468,  1.6909],\n",
      "          [ 1.1661,  0.9273,  0.6988,  ...,  1.2739,  1.5170,  1.8261]],\n",
      "\n",
      "         [[ 2.1868,  2.1868,  2.1931,  ...,  2.1034,  2.1159,  2.1159],\n",
      "          [ 2.1868,  2.1876,  2.1955,  ...,  2.0824,  2.0981,  2.0997],\n",
      "          [ 2.1931,  2.1955,  2.2043,  ...,  2.0648,  2.0824,  2.0872],\n",
      "          ...,\n",
      "          [-0.3771, -0.4554, -0.5608,  ..., -0.1215, -0.0326,  0.0503],\n",
      "          [-0.1752, -0.5307, -0.8458,  ...,  0.1673,  0.2907,  0.4789],\n",
      "          [-0.2601, -0.5203, -0.7930,  ...,  0.2381,  0.3732,  0.6297]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-0.5501, -0.5901, -0.6180,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.5373, -0.6069, -0.6489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.4689, -0.5764, -0.6297,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-0.7481, -0.7890, -0.8175,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.7349, -0.8061, -0.8491,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.6650, -0.7749, -0.8294,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-0.0694, -0.1101, -0.1384,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.0563, -0.1272, -0.1699,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.0134, -0.0961, -0.1504,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2082,  0.8221,  0.5916,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.3437,  1.0289,  0.7119,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.3938,  1.2773,  1.0052,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 0.8516,  0.7138,  0.7935,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.7760,  0.7602,  0.7273,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.7228,  0.8546,  0.6571,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 1.3647,  0.9700,  0.7342,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.5031,  1.1813,  0.8572,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.5544,  1.4352,  1.1571,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 1.0001,  0.8592,  0.9407,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.9228,  0.9066,  0.8730,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.8684,  1.0031,  0.8012,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.5808,  1.1879,  0.9532,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.7187,  1.3983,  1.0756,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.7697,  1.6511,  1.3742,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 1.2178,  1.0776,  1.1587,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.1409,  1.1248,  1.0914,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.0868,  1.2209,  1.0199,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7077,  0.7077,  0.7077,  ...,  1.2716,  1.2581,  1.2544],\n",
      "          [ 0.7077,  0.7077,  0.7077,  ...,  1.2496,  1.2378,  1.2349],\n",
      "          [ 0.7077,  0.7077,  0.7077,  ...,  1.2192,  1.2105,  1.2092],\n",
      "          ...,\n",
      "          [-1.8773, -1.8547, -1.8943,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.8598, -1.8512, -1.9026,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.9052, -1.8637, -1.8969,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 1.5532,  1.5532,  1.5532,  ...,  1.9371,  1.9234,  1.9196],\n",
      "          [ 1.5532,  1.5532,  1.5532,  ...,  1.9147,  1.9026,  1.8996],\n",
      "          [ 1.5532,  1.5532,  1.5532,  ...,  1.8836,  1.8747,  1.8733],\n",
      "          ...,\n",
      "          [-1.6672, -1.6441, -1.6846,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.6356, -1.6268, -1.6793,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.6783, -1.6358, -1.6698,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.2043,  2.2043,  2.2043,  ...,  2.4645,  2.4508,  2.4470],\n",
      "          [ 2.2043,  2.2043,  2.2043,  ...,  2.4421,  2.4300,  2.4271],\n",
      "          [ 2.2043,  2.2043,  2.2043,  ...,  2.4112,  2.4023,  2.4010],\n",
      "          ...,\n",
      "          [-1.7388, -1.7159, -1.7522,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.7609, -1.7522, -1.7884,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.8019, -1.7978, -1.7932,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  1.1700,  1.1700,  1.1700],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.1664,  1.1664,  1.1664],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.1468,  1.1468,  1.1468],\n",
      "          ...,\n",
      "          [-1.4843, -1.4869, -1.5149,  ..., -1.4975, -1.4757, -1.4562],\n",
      "          [-1.5766, -1.5458, -1.5286,  ..., -1.5479, -1.5389, -1.5222],\n",
      "          [-1.6960, -1.6353, -1.5720,  ..., -1.6066, -1.6005, -1.5994]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.4482,  1.4482,  1.4482],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.4444,  1.4444,  1.4444],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.4244,  1.4244,  1.4244],\n",
      "          ...,\n",
      "          [-1.2659, -1.2743, -1.3029,  ..., -1.2789, -1.2567, -1.2366],\n",
      "          [-1.3460, -1.3145, -1.3018,  ..., -1.3304, -1.3212, -1.3042],\n",
      "          [-1.4643, -1.4022, -1.3380,  ..., -1.3905, -1.3842, -1.3830]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  1.8383,  1.8383,  1.8383],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.8345,  1.8345,  1.8345],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.8146,  1.8146,  1.8146],\n",
      "          ...,\n",
      "          [-1.3384, -1.3353, -1.3557,  ..., -0.8767, -0.8546, -0.8346],\n",
      "          [-1.4726, -1.4413, -1.4113,  ..., -0.9280, -0.9188, -0.9019],\n",
      "          [-1.6317, -1.5398, -1.4745,  ..., -0.9878, -0.9815, -0.9804]]],\n",
      "\n",
      "\n",
      "        [[[-0.1657, -0.1657, -0.1596,  ..., -0.2452, -0.2513, -0.2513],\n",
      "          [-0.1620, -0.1620, -0.1572,  ..., -0.2452, -0.2513, -0.2513],\n",
      "          [-0.1481, -0.1424, -0.1424,  ..., -0.2452, -0.2513, -0.2513],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.0157,  2.0290,  2.0781],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.0451,  2.0928,  2.0736],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.1850,  2.1852,  2.0097]],\n",
      "\n",
      "         [[ 0.8179,  0.8179,  0.8242,  ...,  0.8942,  0.8880,  0.8880],\n",
      "          [ 0.8217,  0.8217,  0.8266,  ...,  0.8942,  0.8880,  0.8880],\n",
      "          [ 0.8359,  0.8417,  0.8417,  ...,  0.8942,  0.8880,  0.8880],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.1727,  2.1587,  2.2014],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.2027,  2.2239,  2.1969],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.3457,  2.3184,  2.1315]],\n",
      "\n",
      "         [[ 2.2043,  2.2043,  2.2105,  ...,  2.2105,  2.2043,  2.2043],\n",
      "          [ 2.2080,  2.2080,  2.2129,  ...,  2.2105,  2.2043,  2.2043],\n",
      "          [ 2.2221,  2.2279,  2.2279,  ...,  2.2105,  2.2043,  2.2043],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.3043,  2.2842,  2.3267],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.3342,  2.3491,  2.3222],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.4766,  2.4432,  2.2571]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2318,  2.2318,  2.2318],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2318,  2.2318,  2.2318],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2257,  2.2257,  2.2257],\n",
      "          ...,\n",
      "          [-0.8495, -0.8004, -0.8035,  ..., -0.8042, -0.7565, -0.6680],\n",
      "          [-0.9262, -0.8997, -0.9532,  ..., -0.8459, -0.8030, -0.6963],\n",
      "          [-0.9498, -0.9324, -1.0267,  ..., -0.8976, -0.8492, -0.7357]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-0.7565, -0.7063, -0.7157,  ..., -0.7452, -0.7239, -0.6247],\n",
      "          [-0.8350, -0.8078, -0.8737,  ..., -0.7878, -0.7715, -0.6536],\n",
      "          [-0.8288, -0.8412, -0.9386,  ..., -0.8407, -0.8187, -0.6939]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6338,  2.6338,  2.6338],\n",
      "          ...,\n",
      "          [-0.4333, -0.3938, -0.4032,  ..., -0.6292, -0.6068, -0.5528],\n",
      "          [-0.5047, -0.4812, -0.5419,  ..., -0.6716, -0.6541, -0.5816],\n",
      "          [-0.5134, -0.5107, -0.6072,  ..., -0.7243, -0.7012, -0.6217]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.6898, -1.6898, -1.6898,  ..., -1.6384, -1.6384, -1.6384],\n",
      "          [-1.6898, -1.6898, -1.6898,  ..., -1.6384, -1.6384, -1.6384],\n",
      "          [-1.6898, -1.6898, -1.6898,  ..., -1.6384, -1.6384, -1.6384],\n",
      "          ...,\n",
      "          [-1.2507, -1.2507, -1.2507,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.2445, -1.2445, -1.2445,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.2445, -1.2445, -1.2445,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-0.8452, -0.8452, -0.8452,  ..., -0.7227, -0.7227, -0.7227],\n",
      "          [-0.8452, -0.8452, -0.8452,  ..., -0.7227, -0.7227, -0.7227],\n",
      "          [-0.8452, -0.8452, -0.8452,  ..., -0.7227, -0.7227, -0.7227],\n",
      "          ...,\n",
      "          [-0.0812, -0.0812, -0.0812,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.0749, -0.0749, -0.0749,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.0749, -0.0749, -0.0749,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 0.3045,  0.3045,  0.3045,  ...,  0.4439,  0.4439,  0.4439],\n",
      "          [ 0.3045,  0.3045,  0.3045,  ...,  0.4439,  0.4439,  0.4439],\n",
      "          [ 0.3045,  0.3045,  0.3045,  ...,  0.4439,  0.4439,  0.4439],\n",
      "          ...,\n",
      "          [ 1.2743,  1.2743,  1.2743,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.2805,  1.2805,  1.2805,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.2805,  1.2805,  1.2805,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7928,  1.0114,  1.1785,  ..., -0.9347, -0.9337, -1.0937],\n",
      "          [ 0.6535,  0.9879,  0.9446,  ..., -0.7846, -0.6322, -0.9991],\n",
      "          [ 0.2469,  0.6625,  0.6234,  ..., -1.0679, -0.9260, -0.9344],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.9951, -2.0288, -1.8844],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.9148, -1.9572, -1.8978],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.8341, -1.8782, -1.9104]],\n",
      "\n",
      "         [[ 1.6300,  1.8577,  1.9963,  ..., -0.0779,  0.1038,  0.0555],\n",
      "          [ 1.5659,  1.8970,  1.8447,  ...,  0.0651,  0.4055,  0.1485],\n",
      "          [ 1.2447,  1.7021,  1.6679,  ..., -0.2307,  0.0931,  0.1951],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.8857, -1.9682, -1.8479],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.7742, -1.8793, -1.8480],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.6798, -1.7841, -1.8562]],\n",
      "\n",
      "         [[ 0.3973,  0.7817,  1.2236,  ..., -0.8713, -0.8354, -0.9400],\n",
      "          [ 0.2120,  0.7118,  0.9366,  ..., -0.6915, -0.4957, -0.8311],\n",
      "          [-0.2678,  0.3058,  0.4981,  ..., -0.9365, -0.7221, -0.6982],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.6509, -1.6515, -1.4970],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.5730, -1.5816, -1.5234],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.5035, -1.5274, -1.5420]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1300, -0.0983, -0.4270,  ...,  0.2937,  0.2020,  0.1482],\n",
      "          [ 0.1993,  0.1207, -0.4391,  ...,  0.6339,  0.5342,  0.5975],\n",
      "          [ 0.4907,  0.5345, -0.1695,  ...,  1.0292,  0.9519,  1.0321],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.3772, -0.3776, -0.4935],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.4099, -0.3771, -0.3790],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.1744, -0.2444, -0.3077]],\n",
      "\n",
      "         [[ 0.7150,  0.4747,  0.1131,  ...,  0.8561,  0.7564,  0.7348],\n",
      "          [ 0.7528,  0.6655,  0.0933,  ...,  1.2040,  1.1024,  1.2025],\n",
      "          [ 1.0372,  1.0570,  0.3226,  ...,  1.6171,  1.5465,  1.6227],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.5775, -0.5716, -0.6902],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.6109, -0.5712, -0.5731],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.3702, -0.4355, -0.5003]],\n",
      "\n",
      "         [[ 0.0975, -0.1488, -0.5342,  ...,  0.1351,  0.0936,  0.1110],\n",
      "          [ 0.1354,  0.0519, -0.5178,  ...,  0.4459,  0.3918,  0.5146],\n",
      "          [ 0.4315,  0.4630, -0.2634,  ...,  0.7995,  0.7611,  0.8591],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.6827, -0.6955, -0.8135],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.7159, -0.6950, -0.6969],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.4763, -0.5599, -0.6244]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.0318,  1.0000,  1.3755,  ...,  0.7762,  0.7762,  0.7762],\n",
      "          [ 1.1416,  1.0353,  1.2739,  ...,  0.7762,  0.7762,  0.7762],\n",
      "          [ 1.4042,  1.1497,  1.2552,  ...,  0.7762,  0.7762,  0.7762],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.7134,  0.6930,  0.6266],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.7298,  0.7288,  0.7295],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.7086,  0.8010,  0.8964]],\n",
      "\n",
      "         [[-0.2400, -0.0622,  0.6873,  ...,  1.6758,  1.6758,  1.6758],\n",
      "          [-0.1241, -0.0204,  0.5929,  ...,  1.6758,  1.6758,  1.6758],\n",
      "          [ 0.1707,  0.1182,  0.5864,  ...,  1.6758,  1.6758,  1.6758],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.7299,  0.7091,  0.6412],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.7530,  0.7520,  0.7527],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.7313,  0.8258,  0.9233]],\n",
      "\n",
      "         [[-0.8371, -0.5570,  0.3268,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.5442, -0.3468,  0.3964,  ...,  2.6363,  2.6363,  2.6363],\n",
      "          [ 0.0125,  0.0309,  0.6218,  ...,  2.6226,  2.6226,  2.6226],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.1070,  1.0863,  1.0187],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.1025,  1.0966,  1.0973],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.0727,  1.1663,  1.2635]]],\n",
      "\n",
      "\n",
      "        [[[-0.8508, -0.7820, -0.8936,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.6882, -0.6683, -0.8556,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.6753, -0.6669, -0.8627,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 1.2667,  1.3951,  1.5555,  ...,  1.2993,  1.2836,  1.2883],\n",
      "          [ 1.4896,  1.5969,  1.6928,  ...,  1.4002,  1.3886,  1.4003],\n",
      "          [ 1.5493,  1.6259,  1.6464,  ...,  1.3682,  1.3871,  1.4246]],\n",
      "\n",
      "         [[-0.7404, -0.6700, -0.7841,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.5741, -0.5538, -0.7452,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.5609, -0.5524, -0.7525,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 1.4244,  1.5557,  1.7197,  ...,  1.4577,  1.4417,  1.4465],\n",
      "          [ 1.6523,  1.7620,  1.8600,  ...,  1.5609,  1.5490,  1.5610],\n",
      "          [ 1.7134,  1.7916,  1.8126,  ...,  1.5282,  1.5475,  1.5858]],\n",
      "\n",
      "         [[-0.5149, -0.4448, -0.5583,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.3494, -0.3291, -0.5197,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.3362, -0.3277, -0.5270,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 1.6403,  1.7710,  1.9343,  ...,  1.6735,  1.6576,  1.6623],\n",
      "          [ 1.8672,  1.9764,  2.0740,  ...,  1.7762,  1.7644,  1.7763],\n",
      "          [ 1.9280,  2.0059,  2.0268,  ...,  1.7436,  1.7628,  1.8010]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7236,  0.7077,  0.7016,  ...,  0.2282,  0.2282,  0.2282],\n",
      "          [ 0.7236,  0.7077,  0.7016,  ...,  0.2282,  0.2282,  0.2282],\n",
      "          [ 0.7236,  0.7077,  0.7016,  ...,  0.2343,  0.2343,  0.2343],\n",
      "          ...,\n",
      "          [ 0.9303,  0.9462,  0.9523,  ...,  1.1055,  1.0575,  1.1072],\n",
      "          [ 0.8785,  0.8511,  0.8265,  ...,  1.0161,  0.9861,  1.0455],\n",
      "          [ 0.7469,  0.6862,  0.6225,  ...,  1.0107,  1.0226,  1.0930]],\n",
      "\n",
      "         [[ 0.7817,  0.7654,  0.7592,  ...,  0.3978,  0.3978,  0.3978],\n",
      "          [ 0.7817,  0.7654,  0.7592,  ...,  0.3978,  0.3978,  0.3978],\n",
      "          [ 0.7817,  0.7654,  0.7592,  ...,  0.4040,  0.4040,  0.4040],\n",
      "          ...,\n",
      "          [ 0.8880,  0.9042,  0.9105,  ...,  1.0195,  0.9705,  1.0213],\n",
      "          [ 0.8350,  0.8070,  0.7818,  ...,  0.9682,  0.9375,  0.9983],\n",
      "          [ 0.7005,  0.6384,  0.5733,  ...,  0.9701,  0.9823,  1.0543]],\n",
      "\n",
      "         [[ 1.5581,  1.5420,  1.5357,  ...,  1.3328,  1.3328,  1.3328],\n",
      "          [ 1.5581,  1.5420,  1.5357,  ...,  1.3328,  1.3328,  1.3328],\n",
      "          [ 1.5581,  1.5420,  1.5357,  ...,  1.3390,  1.3390,  1.3390],\n",
      "          ...,\n",
      "          [ 0.6182,  0.6344,  0.6406,  ...,  0.8936,  0.8448,  0.8954],\n",
      "          [ 0.5381,  0.5103,  0.4852,  ...,  0.8686,  0.8381,  0.8986],\n",
      "          [ 0.3967,  0.3349,  0.2701,  ...,  0.8743,  0.8864,  0.9581]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[ 2.2489,  2.2489,  2.2489,  ...,  0.7032,  0.7099,  0.7101],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.7248,  0.7354,  0.7417],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.7126,  0.7126,  0.7228],\n",
      "          ...,\n",
      "          [ 1.2310,  1.1401,  1.1038,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.0722,  1.0245,  1.0498,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.0738,  0.9500,  0.9067,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  0.8484,  0.8552,  0.8554],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.8704,  0.8813,  0.8877],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.8579,  0.8579,  0.8684],\n",
      "          ...,\n",
      "          [ 1.3880,  1.2950,  1.2579,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.2256,  1.1768,  1.2027,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.2272,  1.1006,  1.0564,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  1.0668,  1.0736,  1.0739],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.0888,  1.0996,  1.1060],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.0764,  1.0764,  1.0868],\n",
      "          ...,\n",
      "          [ 1.6040,  1.5115,  1.4746,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4424,  1.3938,  1.4196,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4440,  1.3180,  1.2739,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-0.3428, -0.2191, -0.1365,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.6023, -0.5326, -0.5431,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.5587, -0.7168, -1.0237,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-0.1972, -0.0756, -0.0048,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.5238, -0.4541, -0.4744,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.4954, -0.6721, -0.9979,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-0.0364,  0.0821,  0.1263,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.4138, -0.3503, -0.4058,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.4253, -0.6088, -0.9671,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.2258, -1.1981, -1.1760,  ...,  0.5798,  0.6110,  0.6559],\n",
      "          [-1.2252, -1.1895, -1.1626,  ...,  0.5401,  0.5564,  0.5927],\n",
      "          [-1.2091, -1.1733, -1.1589,  ...,  0.5149,  0.5340,  0.5695]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.1237, -1.0954, -1.0728,  ...,  0.7222,  0.7542,  0.8000],\n",
      "          [-1.1231, -1.0866, -1.0591,  ...,  0.6816,  0.6983,  0.7354],\n",
      "          [-1.1066, -1.0701, -1.0553,  ...,  0.6558,  0.6754,  0.7116]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-0.8964, -0.8683, -0.8458,  ...,  0.9412,  0.9730,  1.0186],\n",
      "          [-0.8959, -0.8595, -0.8321,  ...,  0.9008,  0.9174,  0.9543],\n",
      "          [-0.8795, -0.8431, -0.8284,  ...,  0.8751,  0.8946,  0.9307]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  1.8681,  1.8991,  1.9039],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.8195,  1.8404,  1.8599],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.7560,  1.7816,  1.8012],\n",
      "          ...,\n",
      "          [-0.8488, -0.9680, -1.0817,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.0117, -1.0222, -0.9698,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.8788, -0.8785, -0.8278,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.1480,  2.1622,  2.1671],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.1371,  2.1585,  2.1785],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.1059,  2.1322,  2.1522],\n",
      "          ...,\n",
      "          [-1.3402, -1.4429, -1.5124,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.4825, -1.4917, -1.4247,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.3467, -1.3464, -1.2883,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.4060,  2.4259,  2.4308],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.3847,  2.4060,  2.4259],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.3661,  2.3923,  2.4122],\n",
      "          ...,\n",
      "          [-1.4212, -1.5303, -1.5998,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.5226, -1.5325, -1.4661,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.3799, -1.3796, -1.3218,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-0.9400, -1.0021, -1.0672,  ..., -1.1051, -1.1051, -1.1051],\n",
      "          [-0.9507, -1.0052, -1.0549,  ..., -1.0599, -1.0586, -1.0552],\n",
      "          [-0.9840, -1.0231, -1.0601,  ..., -0.9803, -0.9694, -0.9579],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.2247,  1.1013,  1.0020],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.1001,  0.9251,  0.7729],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.0114,  0.7916,  0.6061]],\n",
      "\n",
      "         [[-0.2036, -0.2822, -0.3488,  ..., -0.3000, -0.3000, -0.3000],\n",
      "          [-0.2185, -0.2750, -0.3288,  ..., -0.2538, -0.2525, -0.2490],\n",
      "          [-0.2175, -0.2599, -0.3065,  ..., -0.1725, -0.1613, -0.1495],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.2239,  1.0978,  0.9963],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.0966,  0.9176,  0.7621],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.0059,  0.7811,  0.5915]],\n",
      "\n",
      "         [[ 0.6517,  0.6110,  0.5846,  ...,  0.7776,  0.7776,  0.7776],\n",
      "          [ 0.6708,  0.6227,  0.6120,  ...,  0.8235,  0.8249,  0.8283],\n",
      "          [ 0.7050,  0.6815,  0.6717,  ...,  0.9046,  0.9157,  0.9274],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.2838,  1.1583,  1.0572],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.1845,  1.0063,  0.8515],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.1016,  0.8779,  0.6891]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4122,  1.4125,  1.4135,  ...,  1.1933,  1.1872,  1.1872],\n",
      "          [ 1.4551,  1.4587,  1.4722,  ...,  1.1920,  1.1872,  1.1872],\n",
      "          [ 1.5077,  1.5100,  1.5208,  ...,  1.1872,  1.1824,  1.1811],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.1159,  2.1162,  2.1172,  ...,  1.9621,  1.9559,  1.9559],\n",
      "          [ 2.1597,  2.1635,  2.1772,  ...,  1.9608,  1.9559,  1.9559],\n",
      "          [ 2.2135,  2.2159,  2.2270,  ...,  1.9559,  1.9510,  1.9496],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.3811,  2.3813,  2.3823,  ...,  2.2130,  2.2068,  2.2068],\n",
      "          [ 2.4246,  2.4284,  2.4421,  ...,  2.2440,  2.2391,  2.2391],\n",
      "          [ 2.4782,  2.4806,  2.4916,  ...,  2.2516,  2.2467,  2.2454],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.6850,  1.6848,  1.6781,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.7046,  1.7009,  1.6875,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.7180,  1.7157,  1.7070,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 1.8521,  1.8518,  1.8450,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.8721,  1.8683,  1.8546,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.8859,  1.8834,  1.8746,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.0661,  2.0658,  2.0591,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.0860,  2.0823,  2.0686,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.0997,  2.0973,  2.0885,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-0.9692, -0.9337, -0.9385,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.8878, -0.9152, -0.9485,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.7930, -0.8651, -0.9224,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-0.8614, -0.8251, -0.8300,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.7782, -0.8061, -0.8402,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.6812, -0.7549, -0.8135,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-0.6354, -0.5992, -0.6041,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.5525, -0.5803, -0.6143,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.4560, -0.5294, -0.5877,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-1.9087, -1.9087, -1.9087,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.8390, -1.8390, -1.8390,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.7338, -1.7338, -1.7338,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.8678, -1.8158, -1.7216],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.9361, -1.9230, -1.8442],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.9226, -1.9496, -1.8818]],\n",
      "\n",
      "         [[-1.3492, -1.3492, -1.3492,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.2854, -1.2854, -1.2854,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.2054, -1.2054, -1.2054,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.7526, -1.6993, -1.6030],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.7570, -1.7289, -1.6483],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.7102, -1.7121, -1.6393]],\n",
      "\n",
      "         [[-0.7898, -0.7898, -0.7898,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.7226, -0.7226, -0.7226,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.6168, -0.6168, -0.6168,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.7947, -1.7169],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.7849, -1.8044, -1.7362],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.7241, -1.7721, -1.7073]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0912,  0.0912,  0.0851,  ..., -0.7410, -0.7477, -0.7479],\n",
      "          [ 0.0912,  0.0912,  0.0864,  ..., -0.7308, -0.7414, -0.7477],\n",
      "          [ 0.0973,  0.0960,  0.0912,  ..., -0.7286, -0.7308, -0.7410],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.2634, -1.4092, -1.4028],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.2292, -1.5001, -1.4935],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.2934, -1.5388, -1.4619]],\n",
      "\n",
      "         [[ 1.0280,  1.0280,  1.0218,  ...,  0.1772,  0.1704,  0.1702],\n",
      "          [ 1.0280,  1.0280,  1.0231,  ...,  0.1877,  0.1769,  0.1704],\n",
      "          [ 1.0343,  1.0329,  1.0280,  ...,  0.1899,  0.1877,  0.1772],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.9305, -1.0773, -1.0603],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.8995, -1.1765, -1.1663],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.9652, -1.2161, -1.1375]],\n",
      "\n",
      "         [[ 1.8731,  1.8731,  1.8669,  ...,  1.2527,  1.2459,  1.2457],\n",
      "          [ 1.8731,  1.8731,  1.8682,  ...,  1.2631,  1.2523,  1.2459],\n",
      "          [ 1.8793,  1.8780,  1.8731,  ...,  1.2653,  1.2631,  1.2527],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.8905, -1.0433, -1.0576],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.8476, -1.1234, -1.1236],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.9130, -1.1628, -1.0845]]],\n",
      "\n",
      "\n",
      "        [[[-0.5914, -0.5948, -0.6077,  ..., -0.6440, -0.6440, -0.6440],\n",
      "          [-0.5488, -0.5522, -0.5570,  ..., -0.6244, -0.6244, -0.6244],\n",
      "          [-0.5090, -0.5192, -0.5192,  ..., -0.5987, -0.5987, -0.5987],\n",
      "          ...,\n",
      "          [-0.7377, -0.7503, -0.7650,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.7455, -0.7650, -0.7894,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.7650, -0.7880, -0.8205,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 0.3477,  0.3443,  0.3310,  ...,  0.4165,  0.4165,  0.4165],\n",
      "          [ 0.3912,  0.3878,  0.3828,  ...,  0.4365,  0.4365,  0.4365],\n",
      "          [ 0.4320,  0.4215,  0.4215,  ...,  0.4628,  0.4628,  0.4628],\n",
      "          ...,\n",
      "          [-0.5722, -0.5850, -0.6001,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.5801, -0.6001, -0.6251,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.6001, -0.6236, -0.6569,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.3353,  1.3318,  1.3187,  ...,  1.4386,  1.4386,  1.4386],\n",
      "          [ 1.3786,  1.3751,  1.3702,  ...,  1.4585,  1.4585,  1.4585],\n",
      "          [ 1.4192,  1.4088,  1.4088,  ...,  1.4847,  1.4847,  1.4847],\n",
      "          ...,\n",
      "          [-0.2603, -0.2731, -0.2881,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.2682, -0.2881, -0.3129,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.2881, -0.3115, -0.3446,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-2.0996, -2.0837, -2.0775,  ..., -0.9701, -0.7560, -0.6571],\n",
      "          [-2.0996, -2.0837, -2.0775,  ..., -0.9485, -0.7737, -0.7352],\n",
      "          [-2.0996, -2.0837, -2.0775,  ..., -0.9852, -0.8421, -0.8372],\n",
      "          ...,\n",
      "          [-1.6360, -1.6065, -1.6274,  ..., -1.5406, -1.5406, -1.5565],\n",
      "          [-1.6494, -1.6184, -1.6335,  ..., -1.5528, -1.5634, -1.5696],\n",
      "          [-1.6531, -1.6213, -1.6335,  ..., -1.5630, -1.5696, -1.5699]],\n",
      "\n",
      "         [[-2.0170, -2.0007, -1.9944,  ..., -0.5105, -0.2135, -0.0896],\n",
      "          [-2.0170, -2.0007, -1.9944,  ..., -0.4988, -0.2380, -0.1882],\n",
      "          [-2.0170, -2.0007, -1.9944,  ..., -0.5426, -0.3250, -0.3125],\n",
      "          ...,\n",
      "          [-1.5430, -1.5129, -1.5343,  ..., -1.5680, -1.5680, -1.5843],\n",
      "          [-1.5568, -1.5251, -1.5405,  ..., -1.5854, -1.5913, -1.5978],\n",
      "          [-1.5605, -1.5280, -1.5405,  ..., -1.5752, -1.5815, -1.5818]],\n",
      "\n",
      "         [[-1.7509, -1.7347, -1.7285,  ..., -1.6359, -1.7140, -1.7221],\n",
      "          [-1.7509, -1.7347, -1.7285,  ..., -1.5717, -1.6924, -1.7514],\n",
      "          [-1.7509, -1.7347, -1.7285,  ..., -1.5502, -1.6687, -1.7498],\n",
      "          ...,\n",
      "          [-1.3488, -1.3188, -1.3401,  ..., -1.6302, -1.6302, -1.6463],\n",
      "          [-1.3625, -1.3309, -1.3463,  ..., -1.6204, -1.6409, -1.6473],\n",
      "          [-1.3662, -1.3339, -1.3463,  ..., -1.5911, -1.5988, -1.5990]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[ 2.1242,  2.1095,  2.1095,  ...,  1.5786,  1.5972,  1.6313],\n",
      "          [ 2.0703,  2.0695,  2.0667,  ...,  1.6253,  1.6345,  1.6486],\n",
      "          [ 2.0434,  2.0397,  2.0263,  ...,  1.6131,  1.6313,  1.6373],\n",
      "          ...,\n",
      "          [-0.4245, -0.7072, -1.2029,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.7839, -0.7730, -1.1371,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.6354, -1.0044, -1.3108,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.3186,  2.3035,  2.3035,  ...,  1.9834,  1.9899,  1.9946],\n",
      "          [ 2.2635,  2.2627,  2.2598,  ...,  2.0359,  2.0297,  2.0424],\n",
      "          [ 2.2360,  2.2322,  2.2185,  ...,  2.0349,  2.0309,  2.0309],\n",
      "          ...,\n",
      "          [-0.2470, -0.5360, -1.0468,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.5744, -0.5662, -0.9505,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.3988, -0.7798, -1.1068,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6177,  2.6027,  2.5964,  ...,  2.2952,  2.3079,  2.3125],\n",
      "          [ 2.5628,  2.5620,  2.5529,  ...,  2.3525,  2.3541,  2.3676],\n",
      "          [ 2.5354,  2.5317,  2.5118,  ...,  2.3826,  2.3874,  2.3898],\n",
      "          ...,\n",
      "          [-0.8428, -1.1144, -1.5784,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.3615, -1.3440, -1.6820,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.3339, -1.6363, -1.7659,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  1.7681,  0.9792,  0.6791],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.6765,  0.5902,  0.0713],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.2681, -0.0920, -0.7609],\n",
      "          ...,\n",
      "          [ 0.1809,  0.1091,  0.0276,  ...,  0.1571,  0.1072,  0.1925],\n",
      "          [ 0.4136,  0.3320,  0.0796,  ...,  0.5591,  0.5789,  0.4666],\n",
      "          [ 0.3553,  0.2906,  0.0230,  ...,  0.6423,  0.5009,  0.5449]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.9433,  1.1305,  0.7750],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.8497,  0.7329,  0.1535],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.4321,  0.0354, -0.6972],\n",
      "          ...,\n",
      "          [ 0.3845,  0.3110,  0.2277,  ...,  0.4508,  0.4114,  0.5013],\n",
      "          [ 0.6086,  0.5251,  0.2671,  ...,  0.8698,  0.8964,  0.7816],\n",
      "          [ 0.5452,  0.4790,  0.2055,  ...,  0.9549,  0.8166,  0.8616]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.0174,  1.1809,  0.8356],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.9242,  0.7850,  0.2170],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.5085,  0.0906, -0.6300],\n",
      "          ...,\n",
      "          [ 0.6324,  0.5593,  0.4683,  ...,  0.6656,  0.6458,  0.7387],\n",
      "          [ 0.9078,  0.8247,  0.5651,  ...,  1.0610,  1.1030,  0.9904],\n",
      "          [ 0.8845,  0.8186,  0.5348,  ...,  1.1430,  1.0177,  1.0626]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-2.0019, -1.8817, -1.7025,  ..., -1.4188, -1.5631, -1.6338],\n",
      "          [-1.7731, -1.4708, -1.1727,  ..., -0.9789, -0.9617, -0.9467],\n",
      "          [-1.4944, -1.1773, -0.5854,  ..., -0.3865, -0.1051, -0.4886]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.9167, -1.7879, -1.6008,  ..., -1.1922, -1.3046, -1.3545],\n",
      "          [-1.6832, -1.3742, -1.0632,  ..., -0.7799, -0.7282, -0.6920],\n",
      "          [-1.3983, -1.0741, -0.4628,  ..., -0.1793,  0.1536, -0.2150]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.7013, -1.6060, -1.4232,  ..., -1.4550, -1.5617, -1.7089],\n",
      "          [-1.4541, -1.1592, -0.8898,  ..., -1.0553, -1.1520, -1.2498],\n",
      "          [-1.1699, -0.8545, -0.2920,  ..., -0.4888, -0.3995, -0.9055]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.5504, -1.3617, -1.3602,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.7314, -1.5532, -1.5084,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.8616, -1.7059, -1.6321,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 1.2357,  1.2032,  1.2551,  ...,  1.2188,  1.2288,  1.2048],\n",
      "          [ 1.3506,  1.3416,  1.3235,  ...,  1.1711,  1.1993,  1.2579],\n",
      "          [ 1.2800,  1.2911,  1.2537,  ...,  1.1693,  1.2592,  1.3917]],\n",
      "\n",
      "         [[-1.0529, -0.8600, -0.8710,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.2312, -1.0595, -1.0235,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.3384, -1.2106, -1.1419,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 1.4102,  1.3770,  1.4300,  ...,  1.3930,  1.4033,  1.3787],\n",
      "          [ 1.5277,  1.5186,  1.5000,  ...,  1.3442,  1.3731,  1.4330],\n",
      "          [ 1.4556,  1.4669,  1.4286,  ...,  1.3423,  1.4342,  1.5698]],\n",
      "\n",
      "         [[-0.5123, -0.3202, -0.3240,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.6820, -0.5077, -0.4571,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.7484, -0.6107, -0.5401,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 1.7133,  1.6802,  1.7331,  ...,  1.6962,  1.7064,  1.6819],\n",
      "          [ 1.8303,  1.8212,  1.8027,  ...,  1.6476,  1.6763,  1.7360],\n",
      "          [ 1.7585,  1.7698,  1.7316,  ...,  1.6457,  1.7372,  1.8721]]],\n",
      "\n",
      "\n",
      "        [[[-1.7835, -1.7954, -1.8865,  ...,  0.8563,  0.9494,  0.8912],\n",
      "          [-1.5680, -1.5074, -1.6210,  ...,  1.1085,  0.8666,  0.8680],\n",
      "          [-1.0205, -1.0660, -1.3872,  ...,  1.5143,  0.8818,  0.3498],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.5827, -1.5455, -1.3498],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.5267, -1.4977, -1.4289],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.5356, -1.5291, -1.5740]],\n",
      "\n",
      "         [[-1.7114, -1.7235, -1.8166,  ...,  0.9699,  1.0651,  1.0067],\n",
      "          [-1.4910, -1.4290, -1.5453,  ...,  1.2276,  0.9833,  0.9984],\n",
      "          [-0.9313, -0.9778, -1.3062,  ...,  1.6488,  1.0110,  0.4696],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.6111, -1.5731, -1.3730],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.5538, -1.5242, -1.4539],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.5629, -1.5563, -1.6022]],\n",
      "\n",
      "         [[-1.5687, -1.5808, -1.6672,  ...,  1.3795,  1.4743,  1.4127],\n",
      "          [-1.3493, -1.2876, -1.3971,  ...,  1.6361,  1.3841,  1.3585],\n",
      "          [-0.7921, -0.8384, -1.1591,  ...,  2.0367,  1.3754,  0.8291],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.5560, -1.5182, -1.3190],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.4990, -1.4695, -1.3995],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.5081, -1.5015, -1.5472]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0331,  1.0379,  1.0575,  ...,  1.3234,  1.3210,  1.2910],\n",
      "          [ 1.0416,  1.0620,  1.0844,  ...,  1.3205,  1.2932,  1.2875],\n",
      "          [ 1.0926,  1.1101,  1.1431,  ...,  1.3880,  1.3793,  1.3780],\n",
      "          ...,\n",
      "          [-0.8593, -1.2943, -1.9135,  ..., -2.0694, -2.0263, -1.7587],\n",
      "          [-1.1635, -1.4764, -2.0329,  ..., -2.0930, -2.0583, -1.8910],\n",
      "          [-1.3656, -1.6380, -2.1135,  ..., -2.1052, -2.0891, -2.0426]],\n",
      "\n",
      "         [[ 1.7295,  1.7495,  1.7696,  ...,  1.7275,  1.7270,  1.7270],\n",
      "          [ 1.7220,  1.7429,  1.7658,  ...,  1.7320,  1.7258,  1.7258],\n",
      "          [ 1.6878,  1.7058,  1.7395,  ...,  1.8286,  1.8197,  1.8183],\n",
      "          ...,\n",
      "          [-0.5277, -0.9748, -1.6167,  ..., -1.7766, -1.7369, -1.4634],\n",
      "          [-0.8186, -1.1423, -1.7299,  ..., -1.8442, -1.8235, -1.6524],\n",
      "          [-1.0216, -1.3142, -1.8471,  ..., -1.8814, -1.8917, -1.8512]],\n",
      "\n",
      "         [[ 2.3101,  2.3300,  2.3499,  ...,  2.1686,  2.1682,  2.1682],\n",
      "          [ 2.3026,  2.3233,  2.3462,  ...,  2.1806,  2.1744,  2.1744],\n",
      "          [ 2.2686,  2.2864,  2.3200,  ...,  2.3041,  2.2952,  2.2939],\n",
      "          ...,\n",
      "          [-0.7871, -1.1990, -1.7460,  ..., -1.7880, -1.7634, -1.5036],\n",
      "          [-1.1816, -1.4243, -1.7996,  ..., -1.8004, -1.7849, -1.6258],\n",
      "          [-1.4174, -1.5775, -1.8044,  ..., -1.8044, -1.8035, -1.7940]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.6384, -1.6384, -1.6384,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.6384, -1.6384, -1.6384,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.6384, -1.6384, -1.6384,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.6727, -1.6727, -1.6727,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.6727, -1.6727, -1.6727,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.6727, -1.6727, -1.6727,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-2.0182, -2.0182, -2.0182,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0182, -2.0182, -2.0182,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0182, -2.0182, -2.0182,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[-1.4036, -1.4036, -1.4036,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.4036, -1.4036, -1.4036,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.4036, -1.4036, -1.4036,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.4036, -1.4036, -1.4036,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.4036, -1.4036, -1.4036,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.4036, -1.4036, -1.4036,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-0.1141, -0.2889, -0.5626,  ..., -1.6168, -1.8229, -1.9547],\n",
      "          [ 0.1752,  0.0942, -0.1047,  ..., -1.3412, -1.4774, -1.6918],\n",
      "          [ 0.1987,  0.4450,  0.5843,  ..., -1.1776, -1.3633, -1.4680],\n",
      "          ...,\n",
      "          [-0.2273, -0.9263, -1.6416,  ..., -1.1511, -1.5462, -1.6655],\n",
      "          [-0.4260, -0.6252, -1.0147,  ..., -1.2479, -1.6771, -1.8689],\n",
      "          [-0.5509, -0.1480, -0.3285,  ..., -1.1741, -1.5192, -1.7118]],\n",
      "\n",
      "         [[-0.3513, -0.4914, -0.7167,  ..., -1.6994, -1.8954, -2.0113],\n",
      "          [-0.0370, -0.0922, -0.2188,  ..., -1.4292, -1.5422, -1.7577],\n",
      "          [ 0.0220,  0.3281,  0.5283,  ..., -1.2598, -1.4305, -1.5235],\n",
      "          ...,\n",
      "          [ 0.1251, -0.5822, -1.2832,  ..., -0.8385, -1.1686, -1.2442],\n",
      "          [-0.0772, -0.2557, -0.6113,  ..., -0.9197, -1.2966, -1.4348],\n",
      "          [-0.2049,  0.2345,  0.0975,  ..., -0.8337, -1.1336, -1.2742]],\n",
      "\n",
      "         [[-0.1461, -0.3445, -0.6242,  ..., -1.4527, -1.6219, -1.7431],\n",
      "          [ 0.2041,  0.1002, -0.1101,  ..., -1.1942, -1.2973, -1.4848],\n",
      "          [ 0.2823,  0.5318,  0.6453,  ..., -1.0516, -1.2030, -1.2953],\n",
      "          ...,\n",
      "          [ 0.0534, -0.6139, -1.3083,  ..., -0.7631, -1.0843, -1.1663],\n",
      "          [-0.1504, -0.3182, -0.6504,  ..., -0.8265, -1.2059, -1.3618],\n",
      "          [-0.2781,  0.1631,  0.0528,  ..., -0.7360, -1.0420, -1.2019]]],\n",
      "\n",
      "\n",
      "        [[[-0.9626, -0.4027,  0.6001,  ..., -0.9589, -0.7263, -0.4883],\n",
      "          [-0.5871, -0.2184,  0.5709,  ..., -0.7176, -0.3634, -0.1632],\n",
      "          [-0.1063,  0.0658,  0.6048,  ..., -0.2886,  0.0224,  0.2338],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.0292, -1.6091, -1.5579],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.0036, -1.1687, -0.8972],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.1473, -0.8883, -0.4835]],\n",
      "\n",
      "         [[-0.8797, -0.1647,  1.0076,  ..., -0.3727, -0.1445,  0.0527],\n",
      "          [-0.4630,  0.0267,  0.9707,  ..., -0.1389,  0.1681,  0.3510],\n",
      "          [ 0.1130,  0.3539,  1.0066,  ...,  0.2703,  0.5238,  0.6740],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.1522, -1.7693, -1.7568],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.1276, -1.3328, -1.0746],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.2873, -1.0383, -0.6589]],\n",
      "\n",
      "         [[-0.9246, -1.1109, -1.0892,  ..., -1.8044, -1.7888, -1.6990],\n",
      "          [-0.6813, -0.9888, -1.0891,  ..., -1.7097, -1.4439, -1.2271],\n",
      "          [-0.3884, -0.7850, -1.0023,  ..., -1.3122, -0.9015, -0.6363],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.2762, -1.7315, -1.7125],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.4335, -1.5216, -1.2419],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.6781, -1.3864, -0.9540]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.8524, -1.8762, -1.8163,  ..., -2.0948, -2.1179, -2.1179],\n",
      "          [-1.7966, -1.5487, -1.3736,  ..., -2.1068, -2.0998, -2.0686],\n",
      "          [-1.5183, -1.2680, -1.1341,  ..., -2.0457, -1.9667, -1.7862],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-0.8739, -0.9458, -0.9829,  ..., -0.8302, -0.8460, -0.8418],\n",
      "          [-0.8167, -0.6064, -0.5156,  ..., -0.8742, -0.8343, -0.7493],\n",
      "          [-0.5306, -0.2939, -0.2152,  ..., -0.8234, -0.7103, -0.4978],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[-1.8038, -1.7837, -1.6859,  ..., -1.7601, -1.7701, -1.7488],\n",
      "          [-1.6920, -1.4712, -1.2013,  ..., -1.7897, -1.7453, -1.6374],\n",
      "          [-1.4702, -1.1585, -0.9319,  ..., -1.7233, -1.5769, -1.3647],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4619,  0.4117,  0.3869,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.4312,  0.3966,  0.3847,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.4491,  0.4104,  0.3973,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-0.5282, -0.4960, -0.4639,  ..., -0.6136, -0.6366, -0.7132],\n",
      "          [-0.4881, -0.4768, -0.4530,  ..., -0.5986, -0.6040, -0.6596],\n",
      "          [-0.4103, -0.4169, -0.4518,  ..., -0.4992, -0.4822, -0.5450]],\n",
      "\n",
      "         [[ 0.7092,  0.7091,  0.7776,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.6781,  0.6966,  0.7753,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.6916,  0.7215,  0.7882,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-0.3755, -0.3426, -0.3098,  ..., -0.4453, -0.4688, -0.5472],\n",
      "          [-0.3345, -0.3230, -0.2987,  ..., -0.4300, -0.4355, -0.4923],\n",
      "          [-0.2550, -0.2617, -0.2974,  ..., -0.3283, -0.3110, -0.3751]],\n",
      "\n",
      "         [[ 0.9320,  1.0029,  1.1968,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.9016,  0.9963,  1.1945,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 0.9343,  1.0427,  1.2073,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-0.2039, -0.1712, -0.1384,  ..., -0.5667, -0.5981, -0.6876],\n",
      "          [-0.1631, -0.1516, -0.1274,  ..., -0.5692, -0.5774, -0.6339],\n",
      "          [-0.0839, -0.0906, -0.1262,  ..., -0.4707, -0.4534, -0.5173]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ..., -1.1748, -1.1614, -1.1577],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.1552, -1.1418, -1.1381],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.1440, -1.1283, -1.1247],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.7282, -1.6835, -1.6649],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.8966, -1.8427, -1.8033],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.9508, -1.9163, -1.9065]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -0.7915, -0.7777, -0.7740],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.7715, -0.7577, -0.7540],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.7599, -0.7439, -0.7402],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.4273, -1.3815, -1.3625],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.5856, -1.5305, -1.4902],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.6373, -1.6021, -1.5920]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ..., -0.1126, -0.0989, -0.0951],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.0926, -0.0790, -0.0752],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.0812, -0.0653, -0.0615],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.9895, -0.9440, -0.9251],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.1883, -1.1334, -1.0933],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.2509, -1.2159, -1.2058]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[ 0.5083,  0.5083,  0.5083,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.6098,  0.6098,  0.6098,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.7150,  0.7150,  0.7150,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 1.1881,  1.1881,  1.1881,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.2318,  1.2318,  1.2318,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.2731,  1.2731,  1.2731,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.7723,  1.7723,  1.7723,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.8246,  1.8246,  1.8246,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.8320,  1.8320,  1.8320,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-0.1828, -0.1828, -0.1828,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.1828, -0.1828, -0.1828,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.1828, -0.1828, -0.1828,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.5659, -1.6680, -1.7059,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.7647, -1.8448, -1.8710,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.8304, -1.9268, -1.9744,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 0.6604,  0.6604,  0.6604,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.6604,  0.6604,  0.6604,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.6604,  0.6604,  0.6604,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.3226, -1.3907, -1.4031,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.5478, -1.6130, -1.5920,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.6355, -1.7193, -1.7014,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.7860,  1.7860,  1.7860,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.7860,  1.7860,  1.7860,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.7860,  1.7860,  1.7860,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.3235, -1.4026, -1.4787,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.4556, -1.5289, -1.5680,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.4494, -1.5773, -1.6376,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9064,  1.9064,  1.9186,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.9064,  1.9080,  1.9234,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.9186,  1.9234,  1.9407,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.3936,  2.3936,  2.3873,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.3936,  2.3928,  2.3849,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.3936,  2.3911,  2.3823,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6276,  2.6276,  2.6276,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ..., -0.4499, -0.3978, -0.3700],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.4225, -0.3785, -0.3394],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.4338, -0.3969, -0.3634],\n",
      "          ...,\n",
      "          [-2.0726, -2.0763, -2.0959,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.0540, -2.0702, -2.0898,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.0495, -2.0543, -2.0795,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -0.3130, -0.2597, -0.2313],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.2849, -0.2400, -0.2000],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.2965, -0.2588, -0.2245],\n",
      "          ...,\n",
      "          [-1.9719, -1.9794, -2.0172,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.9539, -1.9840, -2.0132,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.9646, -1.9707, -2.0028,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  0.2592,  0.3122,  0.3405],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.2871,  0.3319,  0.3717],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.2756,  0.3132,  0.3473],\n",
      "          ...,\n",
      "          [-0.9492, -0.9093, -0.8633,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.8914, -0.8740, -0.8270,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.8622, -0.8279, -0.8060,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-0.1143, -0.1143, -0.1143,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.1106, -0.1106, -0.1106,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.0911, -0.0911, -0.0911,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 0.5378,  0.5378,  0.5378,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.5416,  0.5416,  0.5416,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.5616,  0.5616,  0.5616,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.0300,  2.0300,  2.0300,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.0337,  2.0337,  2.0337,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.0536,  2.0536,  2.0536,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  0.4056,  0.3994,  0.3994],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.4079,  0.4002,  0.3994],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.4166,  0.4079,  0.4056],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.2853,  1.4123,  1.4535],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.2810,  1.3386,  1.3780],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.3053,  1.3080,  1.3253]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.0868,  1.0805,  1.0805],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.0892,  1.0813,  1.0805],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.0980,  1.0892,  1.0868],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.3918,  0.5154,  0.5575],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.4350,  0.5141,  0.5603],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.5043,  0.5032,  0.5064]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.2628,  2.2566,  2.2566],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.2652,  2.2574,  2.2566],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.2740,  2.2652,  2.2628],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.1509,  0.0245,  0.0738],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.1055,  0.0158,  0.0946],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.0226,  0.0335,  0.0765]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.7020e+00,  1.6336e+00,  1.5537e+00,  ..., -1.6392e+00,\n",
      "           -1.6521e+00, -1.6555e+00],\n",
      "          [ 1.7780e+00,  1.6785e+00,  1.5858e+00,  ..., -1.6507e+00,\n",
      "           -1.6555e+00, -1.6555e+00],\n",
      "          [ 1.8261e+00,  1.7292e+00,  1.6202e+00,  ..., -1.6555e+00,\n",
      "           -1.6555e+00, -1.6555e+00],\n",
      "          ...,\n",
      "          [-1.2077e+00, -1.0668e+00, -9.6163e-01,  ..., -1.3439e+00,\n",
      "           -1.5557e+00, -1.5918e+00],\n",
      "          [-1.3739e+00, -1.1928e+00, -1.0524e+00,  ..., -1.4846e+00,\n",
      "           -1.5807e+00, -1.6957e+00],\n",
      "          [-1.3799e+00, -1.2980e+00, -1.2624e+00,  ..., -1.6173e+00,\n",
      "           -1.5579e+00, -1.6813e+00]],\n",
      "\n",
      "         [[ 1.8181e+00,  1.7518e+00,  1.6828e+00,  ..., -3.0252e-01,\n",
      "           -3.0252e-01, -3.0252e-01],\n",
      "          [ 1.9196e+00,  1.8180e+00,  1.7219e+00,  ..., -3.0252e-01,\n",
      "           -3.0252e-01, -3.0252e-01],\n",
      "          [ 2.0151e+00,  1.9147e+00,  1.7943e+00,  ..., -3.0252e-01,\n",
      "           -3.0252e-01, -3.0252e-01],\n",
      "          ...,\n",
      "          [ 2.4332e-01,  3.9955e-01,  5.4273e-01,  ...,  1.0362e-01,\n",
      "           -4.3844e-04,  2.9484e-02],\n",
      "          [ 4.7349e-02,  2.6476e-01,  4.4671e-01,  ..., -9.8601e-02,\n",
      "           -1.0217e-01, -1.5729e-01],\n",
      "          [ 3.4311e-02,  1.5105e-01,  2.0196e-01,  ..., -2.7474e-01,\n",
      "           -1.1459e-01, -1.5871e-01]],\n",
      "\n",
      "         [[ 2.2240e+00,  2.1654e+00,  2.1304e+00,  ...,  1.3502e+00,\n",
      "            1.3502e+00,  1.3502e+00],\n",
      "          [ 2.3213e+00,  2.2276e+00,  2.1668e+00,  ...,  1.3502e+00,\n",
      "            1.3502e+00,  1.3502e+00],\n",
      "          [ 2.3964e+00,  2.3053e+00,  2.2279e+00,  ...,  1.3502e+00,\n",
      "            1.3502e+00,  1.3502e+00],\n",
      "          ...,\n",
      "          [ 8.1305e-01,  9.6724e-01,  1.1009e+00,  ...,  6.1670e-01,\n",
      "            4.6482e-01,  4.6695e-01],\n",
      "          [ 6.0327e-01,  8.0406e-01,  9.8289e-01,  ...,  4.1893e-01,\n",
      "            3.6122e-01,  2.7977e-01],\n",
      "          [ 5.8629e-01,  6.8606e-01,  7.3088e-01,  ...,  2.3584e-01,\n",
      "            3.4246e-01,  2.7461e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2147e+00,  2.2147e+00,  2.2147e+00,  ...,  2.1633e+00,\n",
      "            2.1633e+00,  2.1633e+00],\n",
      "          [ 2.2183e+00,  2.2183e+00,  2.2183e+00,  ...,  2.1706e+00,\n",
      "            2.1706e+00,  2.1706e+00],\n",
      "          [ 2.2257e+00,  2.2257e+00,  2.2257e+00,  ...,  2.1914e+00,\n",
      "            2.1914e+00,  2.1914e+00],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -2.8684e-02,\n",
      "           -2.3879e-02, -1.2345e-02],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -2.0034e-02,\n",
      "           -1.5229e-02, -1.1821e-02],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.7675e-02,\n",
      "           -1.1559e-02, -1.1559e-02]],\n",
      "\n",
      "         [[ 2.2360e+00,  2.2360e+00,  2.2360e+00,  ...,  1.8508e+00,\n",
      "            1.8508e+00,  1.8508e+00],\n",
      "          [ 2.2322e+00,  2.2322e+00,  2.2322e+00,  ...,  1.8471e+00,\n",
      "            1.8471e+00,  1.8471e+00],\n",
      "          [ 2.2122e+00,  2.2122e+00,  2.2122e+00,  ...,  1.8271e+00,\n",
      "            1.8271e+00,  1.8271e+00],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -4.9510e-01,\n",
      "           -4.9019e-01, -4.7839e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -4.8625e-01,\n",
      "           -4.8134e-01, -4.7786e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -4.8384e-01,\n",
      "           -4.7759e-01, -4.7759e-01]],\n",
      "\n",
      "         [[ 1.9428e+00,  1.9428e+00,  1.9428e+00,  ...,  1.6814e+00,\n",
      "            1.6814e+00,  1.6814e+00],\n",
      "          [ 1.9428e+00,  1.9428e+00,  1.9428e+00,  ...,  1.6814e+00,\n",
      "            1.6814e+00,  1.6814e+00],\n",
      "          [ 1.9366e+00,  1.9366e+00,  1.9366e+00,  ...,  1.6752e+00,\n",
      "            1.6752e+00,  1.6752e+00],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -7.5869e-01,\n",
      "           -7.5380e-01, -7.4206e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -7.4989e-01,\n",
      "           -7.4500e-01, -7.4153e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -7.4749e-01,\n",
      "           -7.4126e-01, -7.4126e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1179e+00, -2.1179e+00, -2.1179e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [-2.1179e+00, -2.1179e+00, -2.1179e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [-2.1179e+00, -2.1179e+00, -2.1179e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          ...,\n",
      "          [-1.8207e+00, -1.7948e+00, -1.7277e+00,  ..., -1.7297e+00,\n",
      "           -1.7227e+00, -1.7297e+00],\n",
      "          [-1.7815e+00, -1.7612e+00, -1.7191e+00,  ..., -1.7251e+00,\n",
      "           -1.6760e+00, -1.6577e+00],\n",
      "          [-1.7435e+00, -1.7421e+00, -1.7224e+00,  ..., -1.6465e+00,\n",
      "           -1.5584e+00, -1.5283e+00]],\n",
      "\n",
      "         [[-2.0357e+00, -2.0357e+00, -2.0357e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [-2.0357e+00, -2.0357e+00, -2.0357e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [-2.0357e+00, -2.0357e+00, -2.0357e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          ...,\n",
      "          [-1.6973e+00, -1.6791e+00, -1.6278e+00,  ..., -1.6163e+00,\n",
      "           -1.6092e+00, -1.6163e+00],\n",
      "          [-1.6568e+00, -1.6368e+00, -1.6079e+00,  ..., -1.5854e+00,\n",
      "           -1.5352e+00, -1.5165e+00],\n",
      "          [-1.6180e+00, -1.6165e+00, -1.6088e+00,  ..., -1.5013e+00,\n",
      "           -1.4112e+00, -1.3804e+00]],\n",
      "\n",
      "         [[-1.7696e+00, -1.7696e+00, -1.7696e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [-1.7696e+00, -1.7696e+00, -1.7696e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [-1.7696e+00, -1.7696e+00, -1.7696e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          ...,\n",
      "          [-1.4836e+00, -1.4409e+00, -1.3568e+00,  ..., -1.5724e+00,\n",
      "           -1.5653e+00, -1.5724e+00],\n",
      "          [-1.4701e+00, -1.4223e+00, -1.3700e+00,  ..., -1.5478e+00,\n",
      "           -1.4978e+00, -1.4792e+00],\n",
      "          [-1.4407e+00, -1.4300e+00, -1.3898e+00,  ..., -1.4641e+00,\n",
      "           -1.3744e+00, -1.3438e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0362e-01,  6.4163e-01,  6.6854e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 5.6527e-01,  5.8012e-01,  6.0126e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 6.6356e-01,  6.2669e-01,  6.0572e-01,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -2.0213e+00,\n",
      "           -2.0126e+00, -2.0103e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -2.0065e+00,\n",
      "           -1.9882e+00, -1.9846e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -2.0041e+00,\n",
      "           -1.9721e+00, -1.9650e+00]],\n",
      "\n",
      "         [[ 1.2192e+00,  1.2581e+00,  1.2856e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 1.1800e+00,  1.1952e+00,  1.2168e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 1.2805e+00,  1.2428e+00,  1.2214e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -1.9369e+00,\n",
      "           -1.9281e+00, -1.9257e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -1.9218e+00,\n",
      "           -1.9032e+00, -1.8994e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -1.9194e+00,\n",
      "           -1.8866e+00, -1.8794e+00]],\n",
      "\n",
      "         [[ 2.2552e+00,  2.2939e+00,  2.3213e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.2162e+00,  2.2313e+00,  2.2528e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.3038e+00,  2.2663e+00,  2.2449e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -1.6712e+00,\n",
      "           -1.6624e+00, -1.6600e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -1.6562e+00,\n",
      "           -1.6376e+00, -1.6339e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -1.6538e+00,\n",
      "           -1.6212e+00, -1.6140e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.2458e+00,\n",
      "           -1.1813e+00, -1.1449e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.0793e+00,\n",
      "           -1.0209e+00, -1.0373e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -7.0756e-01,\n",
      "           -9.0939e-01, -1.4417e+00],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -1.3655e-02,\n",
      "           -3.4289e-02, -2.0176e-02],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  5.4599e-03,\n",
      "           -1.5531e-02, -1.1316e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  1.7213e-01,\n",
      "           -1.4496e-01, -7.7870e-01],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -1.0662e+00,\n",
      "           -1.2389e+00, -1.3492e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -9.4677e-01,\n",
      "           -1.0916e+00, -1.2704e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -6.7252e-01,\n",
      "           -1.0341e+00, -1.6736e+00],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]]], device='cuda:0')\n",
      "tensor([[[[-1.7914, -1.7764, -1.7754,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.7925, -1.7889, -1.7741,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.7921, -1.7841, -1.7693,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-0.6288, -0.7221, -0.8050,  ..., -0.2834, -0.2698, -0.2570],\n",
      "          [-0.5537, -0.6370, -0.7149,  ..., -0.4425, -0.4767, -0.4791],\n",
      "          [-0.6221, -0.6640, -0.6942,  ..., -0.5524, -0.6692, -0.7458]],\n",
      "\n",
      "         [[-1.4393, -1.4240, -1.4230,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.4405, -1.4367, -1.4216,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.4400, -1.4318, -1.4167,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-0.7147, -0.8100, -0.8948,  ..., -0.4003, -0.3600, -0.3338],\n",
      "          [-0.5116, -0.5967, -0.6764,  ..., -0.5004, -0.5216, -0.5216],\n",
      "          [-0.5103, -0.5532, -0.5840,  ..., -0.5724, -0.6797, -0.7581]],\n",
      "\n",
      "         [[-0.0453, -0.0605, -0.0615,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.0441, -0.0478, -0.0602,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.0437, -0.0429, -0.0553,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-0.2304, -0.3253, -0.4097,  ...,  0.2582,  0.3072,  0.3356],\n",
      "          [ 0.0639, -0.0208, -0.1001,  ...,  0.2085,  0.2001,  0.2009],\n",
      "          [ 0.1288,  0.0861,  0.0554,  ...,  0.1778,  0.0833,  0.0053]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ..., -1.4077, -1.4258, -1.4463],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.3779, -1.3779, -1.4029],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.3622, -1.3644, -1.3701],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  0.0559,  0.0629,  0.0513],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.0864,  0.0864,  0.0864],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.1024,  0.1001,  0.0943],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  0.9178,  0.8996,  0.8834],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.9529,  0.9373,  0.9230],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.9864,  0.9666,  0.9560],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.6529, -0.8128, -1.0187],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.6520, -0.8244, -0.7989],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.6996, -0.7976, -0.7961]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.1428, -0.2839, -0.4604],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.0931, -0.2519, -0.2153],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.1481, -0.2295, -0.1977]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.2870,  0.1376, -0.0499],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.3313,  0.1669,  0.1998],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.3051,  0.2179,  0.2344]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  1.9777,  0.3542, -0.5718],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.9783,  0.3758, -0.5554],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.9408,  0.3992, -0.5587],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.3727,  0.7466, -0.1925],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.3733,  0.7688, -0.1757],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.3349,  0.7926, -0.1791],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.4088,  0.8361, -0.0590],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.4094,  0.8581, -0.0423],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.3712,  0.8819, -0.0457],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8648,  0.6183,  0.5976,  ..., -1.3091, -0.7393, -0.5402],\n",
      "          [ 0.4237,  0.5685,  0.8522,  ..., -1.5668, -0.9362, -0.4542],\n",
      "          [ 0.1357,  0.2658,  0.6124,  ..., -1.6933, -1.1165, -0.6331],\n",
      "          ...,\n",
      "          [-1.7877, -1.8804, -1.9281,  ..., -1.8817, -1.8623, -1.8194],\n",
      "          [-1.8043, -1.8451, -1.9256,  ..., -1.8480, -1.8684, -1.7597],\n",
      "          [-1.8552, -1.8381, -1.9213,  ..., -1.8383, -1.9004, -1.7372]],\n",
      "\n",
      "         [[ 1.0673,  0.8153,  0.7942,  ..., -1.3206, -0.6911, -0.4301],\n",
      "          [ 0.6399,  0.7844,  1.0745,  ..., -1.5912, -0.9052, -0.3921],\n",
      "          [ 0.3786,  0.5012,  0.8555,  ..., -1.7294, -1.1007, -0.6003],\n",
      "          ...,\n",
      "          [-1.7857, -1.8805, -1.9230,  ..., -1.7943, -1.7744, -1.7305],\n",
      "          [-1.8027, -1.8444, -1.9204,  ..., -1.7598, -1.7806, -1.6695],\n",
      "          [-1.8547, -1.8372, -1.9160,  ..., -1.7499, -1.8134, -1.6465]],\n",
      "\n",
      "         [[ 1.5389,  1.2904,  1.2813,  ..., -1.4761, -0.9780, -0.7911],\n",
      "          [ 0.9853,  1.1650,  1.4600,  ..., -1.6852, -1.1582, -0.6985],\n",
      "          [ 0.5518,  0.7050,  1.0640,  ..., -1.7660, -1.2957, -0.8473],\n",
      "          ...,\n",
      "          [-1.6141, -1.7071, -1.7445,  ..., -1.7692, -1.7522, -1.7097],\n",
      "          [-1.6247, -1.6663, -1.7419,  ..., -1.7389, -1.7596, -1.6490],\n",
      "          [-1.6765, -1.6591, -1.7376,  ..., -1.7186, -1.7888, -1.6261]]],\n",
      "\n",
      "\n",
      "        [[[-0.4262, -0.5155, -0.6521,  ..., -1.7196, -1.7253, -1.7400],\n",
      "          [-0.4032, -0.4952, -0.6218,  ..., -1.7461, -1.7448, -1.7414],\n",
      "          [-0.3646, -0.4605, -0.5718,  ..., -1.7705, -1.7548, -1.7363],\n",
      "          ...,\n",
      "          [-1.8737, -1.9063, -1.9611,  ..., -1.6467, -1.5589, -1.4769],\n",
      "          [-1.9063, -1.9303, -1.9723,  ..., -1.6568, -1.5711, -1.4767],\n",
      "          [-1.9295, -1.9528, -1.9862,  ..., -1.6568, -1.5461, -1.4415]],\n",
      "\n",
      "         [[-0.4813, -0.5726, -0.7122,  ..., -1.7861, -1.7919, -1.8070],\n",
      "          [-0.4579, -0.5518, -0.6813,  ..., -1.8132, -1.8119, -1.8084],\n",
      "          [-0.4184, -0.5164, -0.6302,  ..., -1.8381, -1.8221, -1.8031],\n",
      "          ...,\n",
      "          [-1.8036, -1.8369, -1.8929,  ..., -1.6065, -1.5168, -1.4330],\n",
      "          [-1.8369, -1.8614, -1.9044,  ..., -1.6168, -1.5293, -1.4327],\n",
      "          [-1.8606, -1.8844, -1.9186,  ..., -1.6168, -1.5037, -1.3967]],\n",
      "\n",
      "         [[-0.4313, -0.5222, -0.6611,  ..., -1.7128, -1.7185, -1.7336],\n",
      "          [-0.4079, -0.5014, -0.6304,  ..., -1.7398, -1.7385, -1.7350],\n",
      "          [-0.3686, -0.4661, -0.5794,  ..., -1.7646, -1.7486, -1.7297],\n",
      "          ...,\n",
      "          [-1.6082, -1.6414, -1.6971,  ..., -1.4643, -1.3749, -1.2915],\n",
      "          [-1.6414, -1.6658, -1.7086,  ..., -1.4745, -1.3874, -1.2913],\n",
      "          [-1.6650, -1.6887, -1.7227,  ..., -1.4745, -1.3620, -1.2554]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1063, -0.3639, -0.6321,  ..., -0.7643, -0.8512, -0.8287],\n",
      "          [-0.2492, -0.3222, -0.4322,  ..., -0.7028, -0.7565, -0.7090],\n",
      "          [-0.4649, -0.3966, -0.3597,  ..., -0.5907, -0.6439, -0.5909],\n",
      "          ...,\n",
      "          [-0.9142, -0.9196, -0.9511,  ..., -0.2342, -0.2342, -0.2342],\n",
      "          [-0.9465, -1.0183, -1.1039,  ..., -0.2207, -0.2207, -0.2207],\n",
      "          [-0.9594, -1.0562, -1.1361,  ..., -0.2171, -0.2171, -0.2171]],\n",
      "\n",
      "         [[-0.0667, -0.3301, -0.5917,  ..., -0.8269, -0.9158, -0.8928],\n",
      "          [-0.2128, -0.2874, -0.3874,  ..., -0.7641, -0.8190, -0.7705],\n",
      "          [-0.4334, -0.3635, -0.3133,  ..., -0.6494, -0.7038, -0.6497],\n",
      "          ...,\n",
      "          [-0.9627, -0.9634, -0.9779,  ..., -0.2850, -0.2850, -0.2850],\n",
      "          [-0.9938, -1.0400, -1.1216,  ..., -0.2713, -0.2713, -0.2713],\n",
      "          [-0.9763, -1.0728, -1.1546,  ..., -0.2675, -0.2675, -0.2675]],\n",
      "\n",
      "         [[ 0.0512, -0.2110, -0.4777,  ..., -0.6359, -0.7244, -0.7015],\n",
      "          [-0.0942, -0.1685, -0.2742,  ..., -0.5734, -0.6280, -0.5797],\n",
      "          [-0.3138, -0.2443, -0.2005,  ..., -0.4592, -0.5134, -0.4595],\n",
      "          ...,\n",
      "          [-0.8931, -0.8962, -0.9194,  ..., -0.0441, -0.0441, -0.0441],\n",
      "          [-0.9250, -0.9845, -1.0687,  ..., -0.0304, -0.0304, -0.0304],\n",
      "          [-0.9228, -1.0201, -1.1015,  ..., -0.0267, -0.0267, -0.0267]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5878,  0.5881,  0.5947,  ...,  2.2147,  2.2147,  2.2147],\n",
      "          [ 0.5881,  0.5944,  0.6049,  ...,  2.2147,  2.2147,  2.2147],\n",
      "          [ 0.5947,  0.6049,  0.6071,  ...,  2.2085,  2.2085,  2.2085],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.8602, -0.8494, -0.8470],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.7711, -0.7634, -0.7501],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.7222, -0.7036, -0.6991]],\n",
      "\n",
      "         [[ 1.4482,  1.4484,  1.4552,  ...,  2.3936,  2.3936,  2.3936],\n",
      "          [ 1.4484,  1.4549,  1.4657,  ...,  2.3936,  2.3936,  2.3936],\n",
      "          [ 1.4552,  1.4657,  1.4679,  ...,  2.3873,  2.3873,  2.3873],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.5924, -0.5813, -0.5789],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.5013, -0.4934, -0.4798],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.4513, -0.4323, -0.4277]],\n",
      "\n",
      "         [[ 2.6400,  2.6328,  2.6122,  ...,  2.6051,  2.6051,  2.6051],\n",
      "          [ 2.6328,  2.6333,  2.6226,  ...,  2.6051,  2.6051,  2.6051],\n",
      "          [ 2.6122,  2.6226,  2.6248,  ...,  2.5989,  2.5989,  2.5989],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.1061, -0.0950, -0.0926],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.0154, -0.0075,  0.0060],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.0343,  0.0533,  0.0579]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 0.6795,  0.6809,  0.6857,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.6609,  0.6734,  0.6734,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.6723,  0.6734,  0.6791,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 0.8942,  0.8955,  0.9005,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.8752,  0.8880,  0.8880,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.8868,  0.8880,  0.8938,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 1.3042,  1.3055,  1.3104,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.2852,  1.2980,  1.2980,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.2968,  1.2980,  1.3037,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.5273, -1.6455, -1.5170],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.5483, -1.5013, -1.2237],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.6189, -1.3410, -0.9740]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.3794, -1.5002, -1.3689],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.4009, -1.3528, -1.0690],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.4731, -1.1889, -0.8138]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.3428, -1.4631, -1.3323],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.3642, -1.3163, -1.0337],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.4360, -1.1532, -0.7797]]],\n",
      "\n",
      "\n",
      "        [[[-2.1179, -2.1179, -2.1179,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 0.0445,  0.2478,  0.1845,  ..., -2.0000, -1.9895, -2.0443],\n",
      "          [ 0.0035,  0.1687,  0.1177,  ..., -1.9242, -1.8513, -1.9758],\n",
      "          [ 0.0050,  0.0359,  0.0453,  ..., -1.8062, -1.6523, -1.8074]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 0.1750,  0.3828,  0.3181,  ..., -1.9152, -1.9044, -1.9604],\n",
      "          [ 0.1330,  0.3019,  0.2498,  ..., -1.8377, -1.7632, -1.8905],\n",
      "          [ 0.1346,  0.1661,  0.1758,  ..., -1.7171, -1.5597, -1.7183]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 0.3964,  0.6033,  0.5389,  ..., -1.6845, -1.6737, -1.7295],\n",
      "          [ 0.3546,  0.5228,  0.4710,  ..., -1.6073, -1.5331, -1.6599],\n",
      "          [ 0.3562,  0.3876,  0.3972,  ..., -1.4872, -1.3306, -1.4884]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[-0.4911, -0.4911, -0.4911,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.4911, -0.4911, -0.4911,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.4911, -0.4911, -0.4911,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-2.0262, -2.0238, -2.0152,  ..., -1.5051, -1.5209, -1.5185],\n",
      "          [-2.0448, -2.0315, -2.0190,  ..., -1.5247, -1.5251, -1.5185],\n",
      "          [-2.0482, -2.0323, -2.0200,  ..., -1.5340, -1.5384, -1.5197]],\n",
      "\n",
      "         [[ 0.3277,  0.3277,  0.3277,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.3277,  0.3277,  0.3277,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.3277,  0.3277,  0.3277,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.9307, -1.9307, -1.9307,  ..., -1.4442, -1.5017, -1.5105],\n",
      "          [-1.9434, -1.9307, -1.9258,  ..., -1.4642, -1.5059, -1.5105],\n",
      "          [-1.9469, -1.9307, -1.9244,  ..., -1.4738, -1.5195, -1.5117]],\n",
      "\n",
      "         [[ 1.4374,  1.4374,  1.4374,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4374,  1.4374,  1.4374,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4374,  1.4374,  1.4374,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.6650, -1.6650, -1.6650,  ..., -1.1284, -1.1719, -1.1770],\n",
      "          [-1.6777, -1.6650, -1.6601,  ..., -1.1484, -1.1762, -1.1770],\n",
      "          [-1.6812, -1.6650, -1.6588,  ..., -1.1579, -1.1897, -1.1781]]],\n",
      "\n",
      "\n",
      "        [[[-0.4375, -0.5811, -0.7778,  ...,  1.1504,  0.8286,  0.6685],\n",
      "          [-0.2846, -0.4877, -0.7530,  ...,  1.0566,  0.9390,  0.8366],\n",
      "          [-0.1709, -0.3744, -0.6420,  ...,  1.0130,  1.1925,  1.1827],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-0.2828, -0.4296, -0.6307,  ...,  0.9967,  0.6467,  0.4477],\n",
      "          [-0.1265, -0.3341, -0.6053,  ...,  0.9008,  0.7467,  0.6183],\n",
      "          [-0.0103, -0.2183, -0.4919,  ...,  0.8544,  1.0046,  0.9780],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[-0.1116, -0.2578, -0.4580,  ...,  0.9680,  0.7381,  0.6118],\n",
      "          [ 0.0440, -0.1627, -0.4327,  ...,  0.8651,  0.8234,  0.7736],\n",
      "          [ 0.1597, -0.0474, -0.3198,  ...,  0.7808,  1.0631,  1.0938],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-0.7726, -0.5599, -0.3041,  ...,  0.1526,  0.3340,  0.3363],\n",
      "          [-0.5674, -0.4317, -0.3143,  ...,  0.2225,  0.2472,  0.1521],\n",
      "          [-0.5514, -0.4705, -0.4752,  ...,  0.2431,  0.2278,  0.1515],\n",
      "          ...,\n",
      "          [ 0.1344,  0.2139,  0.2409,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.1761,  0.2155,  0.2219,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.1475,  0.1861,  0.2456,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 0.6790,  0.7513,  0.8265,  ..., -0.1910, -0.1108, -0.1595],\n",
      "          [ 0.8877,  0.9164,  0.8614,  ..., -0.2244, -0.2943, -0.4461],\n",
      "          [ 0.8855,  0.8867,  0.7674,  ..., -0.3210, -0.4516, -0.6123],\n",
      "          ...,\n",
      "          [ 2.1373,  2.1875,  2.1885,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.1565,  2.1627,  2.1499,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.0370,  2.0707,  2.1000,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[-1.7807, -1.6052, -1.3296,  ..., -1.3000, -1.1814, -1.2215],\n",
      "          [-1.5563, -1.4153, -1.3493,  ..., -1.2474, -1.2954, -1.4282],\n",
      "          [-1.4759, -1.4238, -1.5205,  ..., -1.2370, -1.3518, -1.4953],\n",
      "          ...,\n",
      "          [-1.8044, -1.7924, -1.7017,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.8044, -1.7652, -1.5347,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.8044, -1.7319, -1.3320,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.9363, -0.9360, -0.9294,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.9360, -0.9297, -0.9192,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.9294, -0.9192, -0.9170,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 0.9625,  0.8116,  0.2958,  ...,  1.8573,  0.0911, -0.8422],\n",
      "          [-0.3345, -0.1876, -0.4949,  ...,  1.3141, -0.2146, -1.0922],\n",
      "          [-1.0426, -0.8392, -0.9595,  ...,  0.7926, -0.4846, -1.2788]],\n",
      "\n",
      "         [[ 0.0126,  0.0129,  0.0197,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.0129,  0.0193,  0.0301,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.0197,  0.0301,  0.0323,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 0.9384,  0.7842,  0.2568,  ...,  2.0057,  0.2013, -0.7804],\n",
      "          [-0.4013, -0.2512, -0.5653,  ...,  1.4494, -0.1407, -1.0563],\n",
      "          [-1.1290, -0.9211, -1.0441,  ...,  0.9160, -0.4247, -1.2479]],\n",
      "\n",
      "         [[ 1.4897,  1.4899,  1.4967,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4899,  1.4963,  1.5071,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.4967,  1.5071,  1.5093,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 1.2959,  1.1423,  0.6173,  ...,  2.2427,  0.3990, -0.6000],\n",
      "          [-0.0379,  0.1116, -0.2109,  ...,  1.6576,  0.0389, -0.8814],\n",
      "          [-0.7647, -0.5877, -0.7110,  ...,  1.1180, -0.2492, -1.0724]]],\n",
      "\n",
      "\n",
      "        [[[-0.6838, -0.8976, -1.2121,  ..., -0.8633, -0.8155, -0.7713],\n",
      "          [-0.6027, -0.9378, -1.3214,  ..., -0.9472, -0.8767, -0.8059],\n",
      "          [-0.6787, -0.7162, -0.8654,  ..., -0.9826, -0.8018, -0.6182],\n",
      "          ...,\n",
      "          [-1.4511, -1.7076, -1.8485,  ..., -0.5296, -0.5695, -0.8280],\n",
      "          [-1.5094, -1.7146, -1.8754,  ..., -0.7240, -0.8176, -1.0265],\n",
      "          [-1.6431, -1.6321, -1.7639,  ..., -0.9665, -1.0294, -1.1156]],\n",
      "\n",
      "         [[ 0.8269,  0.7650,  0.6137,  ...,  0.1994,  0.3600,  0.4599],\n",
      "          [ 0.9768,  0.7311,  0.4588,  ...,  0.0965,  0.2686,  0.4305],\n",
      "          [ 1.0269,  0.9984,  0.8323,  ...,  0.0781,  0.3652,  0.6042],\n",
      "          ...,\n",
      "          [ 0.1192, -0.1257, -0.2657,  ...,  1.5953,  1.6092,  1.3968],\n",
      "          [-0.0293, -0.2391, -0.3924,  ...,  1.4113,  1.4126,  1.2417],\n",
      "          [-0.2336, -0.2223, -0.3387,  ...,  1.1751,  1.2114,  1.1888]],\n",
      "\n",
      "         [[-0.8604, -1.0119, -1.3063,  ..., -0.7322, -0.7029, -0.6779],\n",
      "          [-0.7262, -1.0416, -1.4161,  ..., -0.8518, -0.7935, -0.7406],\n",
      "          [-0.6759, -0.7492, -0.9260,  ..., -0.9515, -0.7848, -0.6154],\n",
      "          ...,\n",
      "          [-1.2120, -1.4616, -1.6010,  ..., -0.1584, -0.2038, -0.4621],\n",
      "          [-1.2859, -1.4948, -1.6523,  ..., -0.3858, -0.4873, -0.6908],\n",
      "          [-1.4582, -1.4470, -1.5691,  ..., -0.6712, -0.7173, -0.7856]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.2160, -1.2552, -1.3155,  ..., -0.7770, -0.8201, -0.8592],\n",
      "          [-1.1614, -1.2086, -1.2680,  ..., -0.7685, -0.7782, -0.7865],\n",
      "          [-1.3045, -1.3339, -1.3026,  ..., -0.7185, -0.6765, -0.6401]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.2187, -1.2516, -1.2800,  ..., -0.8400, -0.8840, -0.9240],\n",
      "          [-1.1629, -1.1999, -1.2193,  ..., -0.8312, -0.8411, -0.8497],\n",
      "          [-1.3057, -1.2897, -1.2547,  ..., -0.7801, -0.7372, -0.7000]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-0.8168, -0.8519, -0.8912,  ..., -0.6489, -0.6927, -0.7325],\n",
      "          [-0.7612, -0.8018, -0.8348,  ..., -0.6402, -0.6500, -0.6586],\n",
      "          [-0.9045, -0.9039, -0.8585,  ..., -0.5893, -0.5465, -0.5095]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -4.3968e-01,\n",
      "           -4.3968e-01, -4.3968e-01],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -4.3601e-01,\n",
      "           -4.3601e-01, -4.3601e-01],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -4.2255e-01,\n",
      "           -4.2255e-01, -4.2255e-01],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  1.8768e-01,\n",
      "            1.8768e-01,  1.8768e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  1.8017e-01,\n",
      "            1.8017e-01,  1.8017e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  1.5266e-01,\n",
      "            1.5266e-01,  1.5266e-01],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  9.6680e-01,\n",
      "            9.6680e-01,  9.6680e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  9.7053e-01,\n",
      "            9.7053e-01,  9.7053e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  9.8423e-01,\n",
      "            9.8423e-01,  9.8423e-01],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "        [[[-2.1179e+00, -2.1179e+00, -2.1179e+00,  ..., -2.1008e+00,\n",
      "           -2.1008e+00, -2.1008e+00],\n",
      "          [-2.1179e+00, -2.1179e+00, -2.1179e+00,  ..., -2.1008e+00,\n",
      "           -2.1008e+00, -2.1008e+00],\n",
      "          [-2.1179e+00, -2.1179e+00, -2.1179e+00,  ..., -2.1008e+00,\n",
      "           -2.1008e+00, -2.1008e+00],\n",
      "          ...,\n",
      "          [-3.1675e-01, -3.3370e-01, -1.5878e-01,  ..., -1.9415e+00,\n",
      "           -1.6745e+00, -1.3129e+00],\n",
      "          [-4.1504e-01, -3.4147e-01, -2.1959e-01,  ..., -9.1470e-01,\n",
      "           -5.9414e-01, -2.0761e-01],\n",
      "          [-3.0408e-01, -2.1277e-01, -2.8634e-01,  ..., -1.8480e-01,\n",
      "            1.2702e-01,  1.2465e-01]],\n",
      "\n",
      "         [[-1.1954e+00, -1.1954e+00, -1.1954e+00,  ..., -1.2129e+00,\n",
      "           -1.2129e+00, -1.2129e+00],\n",
      "          [-1.1954e+00, -1.1954e+00, -1.1954e+00,  ..., -1.2129e+00,\n",
      "           -1.2129e+00, -1.2129e+00],\n",
      "          [-1.1891e+00, -1.1891e+00, -1.1891e+00,  ..., -1.2129e+00,\n",
      "           -1.2129e+00, -1.2129e+00],\n",
      "          ...,\n",
      "          [-3.1690e-01, -3.3798e-01, -1.8542e-01,  ..., -1.8554e+00,\n",
      "           -1.5824e+00, -1.2128e+00],\n",
      "          [-4.1739e-01, -3.4298e-01, -2.3875e-01,  ..., -8.0566e-01,\n",
      "           -4.7794e-01, -8.2776e-02],\n",
      "          [-3.0395e-01, -2.1061e-01, -3.0458e-01,  ..., -5.9463e-02,\n",
      "            2.5932e-01,  2.5690e-01]],\n",
      "\n",
      "         [[ 4.3050e-02,  4.3050e-02,  4.3050e-02,  ...,  4.3050e-02,\n",
      "            4.3050e-02,  4.3050e-02],\n",
      "          [ 4.3050e-02,  4.3050e-02,  4.3050e-02,  ...,  4.3050e-02,\n",
      "            4.3050e-02,  4.3050e-02],\n",
      "          [ 4.9275e-02,  4.9275e-02,  4.9275e-02,  ...,  4.3050e-02,\n",
      "            4.3050e-02,  4.3050e-02],\n",
      "          ...,\n",
      "          [-3.7214e-01, -3.8192e-01, -1.7028e-01,  ..., -1.4506e+00,\n",
      "           -1.1789e+00, -8.1088e-01],\n",
      "          [-4.9761e-01, -3.9570e-01, -2.5956e-01,  ..., -4.0556e-01,\n",
      "           -7.9299e-02,  3.1411e-01],\n",
      "          [-3.9392e-01, -2.9175e-01, -3.3497e-01,  ...,  3.3732e-01,\n",
      "            6.5468e-01,  6.5227e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.3251e-02,  1.2570e-01,  2.9957e-01,  ...,  1.1932e-01,\n",
      "            7.1094e-02,  1.8948e-01],\n",
      "          [-1.9248e-02,  2.2603e-02,  3.2115e-01,  ...,  2.8253e-01,\n",
      "            2.6401e-01,  3.0018e-01],\n",
      "          [ 1.0983e-02,  1.3718e-03,  3.4168e-01,  ...,  5.4535e-01,\n",
      "            5.6203e-01,  5.3241e-01],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "         [[ 2.0670e-01,  4.3108e-01,  6.1079e-01,  ...,  6.5777e-01,\n",
      "            5.5532e-01,  6.5322e-01],\n",
      "          [ 2.4984e-01,  2.9852e-01,  6.2535e-01,  ...,  7.5620e-01,\n",
      "            6.7492e-01,  6.9770e-01],\n",
      "          [ 2.6199e-01,  2.5217e-01,  6.0677e-01,  ...,  9.2583e-01,\n",
      "            8.8644e-01,  8.3016e-01],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "         [[ 4.6411e-01,  6.8722e-01,  8.6516e-01,  ...,  8.6258e-01,\n",
      "            7.4244e-01,  8.3902e-01],\n",
      "          [ 5.2324e-01,  5.6877e-01,  8.8339e-01,  ...,  9.9347e-01,\n",
      "            8.9948e-01,  9.1158e-01],\n",
      "          [ 5.4156e-01,  5.3178e-01,  8.8259e-01,  ...,  1.2149e+00,\n",
      "            1.1509e+00,  1.0956e+00],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.0851e+00,\n",
      "           -1.0525e+00, -1.0145e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.1676e+00,\n",
      "           -1.1480e+00, -1.1271e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.1910e+00,\n",
      "           -1.1957e+00, -1.1878e+00],\n",
      "          ...,\n",
      "          [-1.6214e+00, -1.7277e+00, -1.8647e+00,  ..., -1.9816e+00,\n",
      "           -1.9651e+00, -1.9442e+00],\n",
      "          [-1.7867e+00, -1.8491e+00, -1.9092e+00,  ..., -1.9405e+00,\n",
      "           -1.9543e+00, -1.9530e+00],\n",
      "          [-1.9259e+00, -1.9775e+00, -2.0041e+00,  ..., -1.9996e+00,\n",
      "           -2.0078e+00, -2.0115e+00]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -1.8622e-01,\n",
      "           -1.3996e-01, -1.0226e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -2.6733e-01,\n",
      "           -2.2374e-01, -2.1275e-01],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -3.1154e-01,\n",
      "           -2.9475e-01, -2.8082e-01],\n",
      "          ...,\n",
      "          [-1.6373e+00, -1.7295e+00, -1.8394e+00,  ..., -1.8889e+00,\n",
      "           -1.8720e+00, -1.8181e+00],\n",
      "          [-1.8580e+00, -1.8759e+00, -1.8974e+00,  ..., -1.8857e+00,\n",
      "           -1.8998e+00, -1.8915e+00],\n",
      "          [-2.0107e+00, -2.0107e+00, -2.0049e+00,  ..., -1.9986e+00,\n",
      "           -1.9942e+00, -1.9944e+00]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  8.7601e-01,\n",
      "            9.3318e-01,  9.7418e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  7.5898e-01,\n",
      "            8.0042e-01,  8.5031e-01],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  6.7770e-01,\n",
      "            7.1790e-01,  7.3817e-01],\n",
      "          ...,\n",
      "          [-1.2857e+00, -1.3749e+00, -1.4688e+00,  ..., -1.5270e+00,\n",
      "           -1.5368e+00, -1.5044e+00],\n",
      "          [-1.4928e+00, -1.5234e+00, -1.5322e+00,  ..., -1.5615e+00,\n",
      "           -1.6027e+00, -1.6045e+00],\n",
      "          [-1.6402e+00, -1.6344e+00, -1.5965e+00,  ..., -1.6849e+00,\n",
      "           -1.7322e+00, -1.7434e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          ...,\n",
      "          [ 3.8843e-01,  3.8607e-01,  3.7742e-01,  ...,  3.4317e-01,\n",
      "            3.4317e-01,  3.5907e-01],\n",
      "          [ 3.4098e-01,  3.2770e-01,  3.2482e-01,  ...,  3.3094e-01,\n",
      "            3.3094e-01,  3.3434e-01],\n",
      "          [ 3.1381e-01,  2.9791e-01,  2.9791e-01,  ...,  3.3661e-01,\n",
      "            3.3094e-01,  3.3094e-01]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          ...,\n",
      "          [ 4.0401e-01,  4.0160e-01,  3.9276e-01,  ...,  3.2273e-01,\n",
      "            3.2273e-01,  3.3899e-01],\n",
      "          [ 3.8302e-01,  3.6944e-01,  3.6650e-01,  ...,  3.1022e-01,\n",
      "            3.1022e-01,  3.1371e-01],\n",
      "          [ 3.6274e-01,  3.4649e-01,  3.4649e-01,  ...,  3.1603e-01,\n",
      "            3.1022e-01,  3.1022e-01]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          ...,\n",
      "          [ 4.8500e-01,  4.8260e-01,  4.7380e-01,  ...,  3.8665e-01,\n",
      "            3.8665e-01,  4.0284e-01],\n",
      "          [ 4.9150e-01,  4.7798e-01,  4.7505e-01,  ...,  3.7420e-01,\n",
      "            3.7420e-01,  3.7767e-01],\n",
      "          [ 4.7878e-01,  4.6260e-01,  4.6260e-01,  ...,  3.7998e-01,\n",
      "            3.7420e-01,  3.7420e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "            2.2489e+00,  2.2489e+00],\n",
      "          ...,\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.4870e+00,\n",
      "           -1.4341e+00, -1.5227e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.4660e+00,\n",
      "           -1.4475e+00, -1.5800e+00],\n",
      "          [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ..., -1.4806e+00,\n",
      "           -1.5095e+00, -1.6875e+00]],\n",
      "\n",
      "         [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "            2.4286e+00,  2.4286e+00],\n",
      "          ...,\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -1.4532e+00,\n",
      "           -1.4694e+00, -1.5839e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -1.4367e+00,\n",
      "           -1.4929e+00, -1.6816e+00],\n",
      "          [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ..., -1.4739e+00,\n",
      "           -1.5633e+00, -1.8021e+00]],\n",
      "\n",
      "         [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "            2.6400e+00,  2.6400e+00],\n",
      "          ...,\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -1.5754e+00,\n",
      "           -1.5517e+00, -1.6514e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -1.5629e+00,\n",
      "           -1.5716e+00, -1.7355e+00],\n",
      "          [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ..., -1.5895e+00,\n",
      "           -1.6382e+00, -1.7918e+00]]]], device='cuda:0')\n",
      "tensor([[[[-0.7998, -0.3949,  0.1142,  ...,  2.1654,  2.1642,  2.1597],\n",
      "          [-1.1465, -0.8546, -0.2390,  ...,  2.1338,  2.1277,  2.1095],\n",
      "          [-1.5841, -1.4448, -0.8689,  ...,  2.1738,  2.1413,  2.1087],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  1.8343,  2.0080,  2.1336],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.1098,  2.1836,  2.0586],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2035,  2.2434,  2.1578]],\n",
      "\n",
      "         [[ 0.3761,  0.8039,  1.3916,  ...,  2.4186,  2.4248,  2.4248],\n",
      "          [-0.0250,  0.3175,  1.0268,  ...,  2.3698,  2.3761,  2.3726],\n",
      "          [-0.4796, -0.3073,  0.3566,  ...,  2.3868,  2.3836,  2.3602],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.9342,  2.1477,  2.2973],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.2491,  2.3449,  2.2203],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.3475,  2.4147,  2.3342]],\n",
      "\n",
      "         [[-1.4375, -1.0010, -0.3696,  ...,  2.5914,  2.6370,  2.6398],\n",
      "          [-1.6724, -1.3560, -0.6715,  ...,  2.5144,  2.5798,  2.6084],\n",
      "          [-1.8044, -1.7007, -1.2481,  ...,  2.4699,  2.4934,  2.4827],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.6172,  1.8451,  1.9931],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.1091,  2.2152,  2.0928],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.3260,  2.4188,  2.3305]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ..., -1.5242, -1.5592, -1.4598],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.5749, -1.6046, -1.4992],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.6149, -1.6434, -1.5271],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.3949, -0.3797, -0.3602],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.3808, -0.3410, -0.3311],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.2986, -0.2476, -0.2255]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -1.4813, -1.5170, -1.4155],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.5331, -1.5635, -1.4557],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.5740, -1.6031, -1.4842],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.2568, -0.2412, -0.2212],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.2423, -0.2017, -0.1915],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.1583, -0.1062, -0.0836]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ..., -1.3396, -1.3752, -1.2741],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.3912, -1.4214, -1.3142],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.4319, -1.4609, -1.3426],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.1206, -0.1051, -0.0852],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.1062, -0.0657, -0.0556],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.0225,  0.0294,  0.0519]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ..., -2.0939, -2.1005, -2.1008],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.0823, -2.0942, -2.0971],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.0858, -2.0898, -2.0784],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -1.4684, -1.4752, -1.4755],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.4566, -1.4688, -1.4717],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.4415, -1.4455, -1.4513],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ..., -0.7342, -0.7410, -0.7413],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.7225, -0.7346, -0.7375],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.7136, -0.7176, -0.7176],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ..., -0.7144, -0.7905, -0.8409],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.8127, -0.9195, -0.9650],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.8325, -0.8903, -0.8700],\n",
      "          ...,\n",
      "          [-1.6057, -1.5586, -1.4444,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.5035, -1.5681, -1.5660,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.5449, -1.7411, -1.8256,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -1.4562, -1.5340, -1.5855],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.4979, -1.6072, -1.6536],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.4031, -1.4622, -1.4415],\n",
      "          ...,\n",
      "          [-1.4533, -1.4027, -1.2772,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.3551, -1.4203, -1.4103,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.3974, -1.5980, -1.6839,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ..., -1.3508, -1.4282, -1.4795],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.4085, -1.5172, -1.5635],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.3203, -1.3791, -1.3585],\n",
      "          ...,\n",
      "          [-1.6040, -1.5699, -1.4751,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.4655, -1.5378, -1.5677,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.4701, -1.6968, -1.7899,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-1.7879, -1.7818, -1.9072,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.7781, -1.8223, -1.9674,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.8835, -1.9417, -2.0534,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0348, -2.0232, -2.0143,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[-1.5057, -1.5091, -1.6264,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.5054, -1.5169, -1.6148,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.6023, -1.5860, -1.6096,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3954,  0.5087,  0.5031,  ..., -1.3995, -1.0253, -0.9510],\n",
      "          [ 0.4678,  0.4933,  0.4596,  ..., -1.3350, -0.9603, -0.8852],\n",
      "          [ 0.5164,  0.4692,  0.4359,  ..., -1.2688, -0.9020, -0.8014],\n",
      "          ...,\n",
      "          [ 1.7087,  1.7172,  1.6206,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.7146,  1.6997,  1.5774,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.7669,  1.7599,  1.6308,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-0.2516, -0.0957, -0.0678,  ..., -1.5818, -1.2719, -1.2266],\n",
      "          [-0.1776, -0.1116, -0.1122,  ..., -1.5367, -1.2124, -1.1594],\n",
      "          [-0.1279, -0.1361, -0.1365,  ..., -1.4735, -1.1528, -1.0737],\n",
      "          ...,\n",
      "          [ 1.3861,  1.3948,  1.3023,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.3922,  1.3769,  1.2581,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.4456,  1.4384,  1.3069,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[-0.9869, -0.8205, -0.7329,  ..., -1.5995, -1.3637, -1.3625],\n",
      "          [-0.9126, -0.8304, -0.7771,  ..., -1.5468, -1.3010, -1.2955],\n",
      "          [-0.8612, -0.8333, -0.8013,  ..., -1.4937, -1.2416, -1.2103],\n",
      "          ...,\n",
      "          [ 1.2187,  1.2199,  1.0818,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.2375,  1.2021,  1.0378,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.2941,  1.2703,  1.1245,  ...,  2.6400,  2.6400,  2.6400]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1925, -0.0144, -0.1084,  ..., -1.3807, -0.9128, -0.5181],\n",
      "          [ 0.4184,  0.1072, -0.2256,  ..., -1.4700, -1.0753, -0.6852],\n",
      "          [ 1.0191,  0.5356, -0.1076,  ..., -1.0975, -0.8747, -0.6717],\n",
      "          ...,\n",
      "          [-1.9407, -1.7515, -1.6096,  ..., -1.3491, -1.1870, -0.8609],\n",
      "          [-1.5055, -1.6105, -1.5682,  ..., -1.1466, -1.0558, -0.9982],\n",
      "          [-1.1383, -1.4889, -1.4177,  ..., -0.9380, -1.1452, -1.1231]],\n",
      "\n",
      "         [[ 0.2250,  0.0772,  0.0424,  ..., -0.9907, -0.5514, -0.1400],\n",
      "          [ 0.4666,  0.2037, -0.0785,  ..., -1.1071, -0.7226, -0.3364],\n",
      "          [ 1.1200,  0.6521,  0.0463,  ..., -0.7752, -0.5422, -0.3739],\n",
      "          ...,\n",
      "          [-1.7412, -1.5021, -1.3387,  ..., -1.0047, -0.8536, -0.5243],\n",
      "          [-1.2706, -1.3390, -1.2688,  ..., -0.7976, -0.7048, -0.6459],\n",
      "          [-0.8615, -1.2139, -1.1086,  ..., -0.5844, -0.7962, -0.7736]],\n",
      "\n",
      "         [[ 0.1686,  0.0414,  0.0267,  ..., -0.7354, -0.3249,  0.0378],\n",
      "          [ 0.4132,  0.1747, -0.0862,  ..., -0.7881, -0.4624, -0.1039],\n",
      "          [ 1.0783,  0.6500,  0.0738,  ..., -0.3848, -0.2292, -0.0952],\n",
      "          ...,\n",
      "          [-1.4099, -1.2148, -1.0637,  ..., -0.7606, -0.6053, -0.2761],\n",
      "          [-0.9813, -1.0760, -1.0110,  ..., -0.5544, -0.4620, -0.4034],\n",
      "          [-0.5994, -0.9514, -0.8528,  ..., -0.3422, -0.5530, -0.5305]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6734,  0.6734,  0.6734,  ...,  0.7933,  0.7933,  0.7933],\n",
      "          [ 0.6734,  0.6734,  0.6734,  ...,  0.7933,  0.7933,  0.7933],\n",
      "          [ 0.6673,  0.6673,  0.6673,  ...,  0.7872,  0.7872,  0.7872],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 1.0280,  1.0280,  1.0280,  ...,  1.1506,  1.1506,  1.1506],\n",
      "          [ 1.0280,  1.0280,  1.0280,  ...,  1.1506,  1.1506,  1.1506],\n",
      "          [ 1.0218,  1.0218,  1.0218,  ...,  1.1443,  1.1443,  1.1443],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.5245,  1.5245,  1.5245,  ...,  1.6465,  1.6465,  1.6465],\n",
      "          [ 1.5245,  1.5245,  1.5245,  ...,  1.6465,  1.6465,  1.6465],\n",
      "          [ 1.5183,  1.5183,  1.5183,  ...,  1.6403,  1.6403,  1.6403],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  0.8633,  0.6273,  0.1560],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.9119,  0.5039,  0.0043],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.9871,  0.3463, -0.2040],\n",
      "          ...,\n",
      "          [-0.9016, -0.8936, -0.8810,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.8876, -0.8743, -0.8654,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.8530, -0.8485, -0.8299,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.0120,  0.7708,  0.2890],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.0617,  0.6446,  0.1339],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.1386,  0.4835, -0.0790],\n",
      "          ...,\n",
      "          [-0.7923, -0.7841, -0.7712,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.7780, -0.7644, -0.7552,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.7426, -0.7380, -0.7189,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  1.2298,  0.9896,  0.5099],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.2792,  0.8640,  0.3555],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.3558,  0.7036,  0.1435],\n",
      "          ...,\n",
      "          [-0.5665, -0.5583, -0.5455,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.5523, -0.5388, -0.5296,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.5171, -0.5125, -0.4935,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.1780,  2.1782,  2.1796,  ..., -0.7777, -0.6855, -0.4368],\n",
      "          [ 2.1464,  2.1535,  2.1731,  ..., -0.8128, -0.7962, -0.6746],\n",
      "          [ 2.1596,  2.1792,  2.1988,  ..., -0.7614, -0.8476, -0.9189],\n",
      "          ...,\n",
      "          [ 0.3147,  0.4056,  0.3973,  ..., -1.2959, -1.2850, -1.2678],\n",
      "          [ 0.3440,  0.3773,  0.3491,  ..., -1.3193, -1.3228, -1.3069],\n",
      "          [ 0.3641,  0.3486,  0.3007,  ..., -1.3400, -1.3461, -1.3449]],\n",
      "\n",
      "         [[ 2.4261,  2.4263,  2.4278,  ..., -0.4443, -0.3437, -0.0895],\n",
      "          [ 2.3863,  2.3936,  2.4136,  ..., -0.4802, -0.4570, -0.3326],\n",
      "          [ 2.3598,  2.3798,  2.3998,  ..., -0.4316, -0.5108, -0.5824],\n",
      "          ...,\n",
      "          [ 0.4337,  0.5266,  0.5181,  ..., -1.0728, -1.0617, -1.0441],\n",
      "          [ 0.4636,  0.4977,  0.4689,  ..., -1.0968, -1.1003, -1.0841],\n",
      "          [ 0.4842,  0.4683,  0.4194,  ..., -1.1178, -1.1241, -1.1229]],\n",
      "\n",
      "         [[ 2.6201,  2.6203,  2.6218,  ..., -1.1243, -1.0574, -0.8080],\n",
      "          [ 2.5805,  2.5877,  2.6076,  ..., -1.1484, -1.1672, -1.0498],\n",
      "          [ 2.5603,  2.5802,  2.6002,  ..., -1.0881, -1.2061, -1.2917],\n",
      "          ...,\n",
      "          [ 0.5842,  0.6767,  0.6683,  ..., -0.6715, -0.6604, -0.6429],\n",
      "          [ 0.6140,  0.6480,  0.6193,  ..., -0.6954, -0.6989, -0.6828],\n",
      "          [ 0.6346,  0.6187,  0.5700,  ..., -0.7164, -0.7226, -0.7214]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ..., -1.4455, -1.7746, -1.9148],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.4829, -1.8635, -2.0320],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.4728, -1.8586, -2.0396],\n",
      "          ...,\n",
      "          [-1.0186, -1.0748, -1.0682,  ..., -0.8972, -1.0126, -1.4041],\n",
      "          [-0.8682, -1.0643, -1.0847,  ..., -1.1406, -1.1316, -1.3150],\n",
      "          [-0.8006, -0.9879, -1.0319,  ..., -1.5844, -1.3460, -1.0455]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -1.1907, -1.4869, -1.6192],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.2290, -1.5905, -1.7553],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.2249, -1.5869, -1.7631],\n",
      "          ...,\n",
      "          [ 0.7279,  0.6751,  0.6630,  ...,  0.1638,  0.0187, -0.4181],\n",
      "          [ 0.8897,  0.7154,  0.6747,  ..., -0.0748, -0.0682, -0.2627],\n",
      "          [ 0.9591,  0.7964,  0.7373,  ..., -0.5065, -0.2512,  0.0560]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ..., -1.2919, -1.5995, -1.7335],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.2976, -1.6575, -1.7985],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.2810, -1.6463, -1.7919],\n",
      "          ...,\n",
      "          [-0.6578, -0.6706, -0.6241,  ..., -1.1367, -1.2656, -1.6656],\n",
      "          [-0.5709, -0.7213, -0.6758,  ..., -1.3114, -1.3035, -1.4937],\n",
      "          [-0.5135, -0.6638, -0.6547,  ..., -1.6963, -1.4421, -1.1363]]],\n",
      "\n",
      "\n",
      "        [[[-1.9135, -1.9107, -1.8974,  ..., -2.0706, -2.1074, -2.1154],\n",
      "          [-1.9415, -1.8974, -1.8634,  ..., -2.0531, -2.0592, -2.0717],\n",
      "          [-2.0136, -1.9652, -1.9083,  ..., -2.0323, -2.0336, -2.0323],\n",
      "          ...,\n",
      "          [-0.9754, -0.3756,  1.0574,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.4458, -0.9940,  0.1587,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.5438, -1.2913, -0.4560,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-1.7067, -1.7398, -1.7577,  ..., -1.9524, -2.0037, -2.0307],\n",
      "          [-1.7353, -1.7227, -1.7067,  ..., -1.9358, -1.9544, -1.9710],\n",
      "          [-1.8090, -1.7920, -1.7527,  ..., -1.9194, -1.9283, -1.9307],\n",
      "          ...,\n",
      "          [-0.3987,  0.1770,  1.6047,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.8622, -0.4506,  0.6996,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.9589, -0.7147,  0.0759,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[-1.5953, -1.5711, -1.5302,  ..., -1.7638, -1.7216, -1.7136],\n",
      "          [-1.6296, -1.5900, -1.5280,  ..., -1.7473, -1.6725, -1.6541],\n",
      "          [-1.7161, -1.6665, -1.5861,  ..., -1.7310, -1.6464, -1.6140],\n",
      "          ...,\n",
      "          [-0.5686,  0.0198,  1.4694,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.0358, -0.6053,  0.5675,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.1332, -0.8851, -0.0662,  ...,  2.6400,  2.6400,  2.6400]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[ 2.2318,  2.2318,  2.2318,  ...,  2.2318,  2.2318,  2.2318],\n",
      "          [ 2.2318,  2.2318,  2.2318,  ...,  2.2318,  2.2318,  2.2318],\n",
      "          [ 2.2318,  2.2318,  2.2318,  ...,  2.2318,  2.2318,  2.2318],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4111,  2.4111,  2.4111,  ...,  2.4111,  2.4111,  2.4111],\n",
      "          [ 2.4111,  2.4111,  2.4111,  ...,  2.4111,  2.4111,  2.4111],\n",
      "          [ 2.4111,  2.4111,  2.4111,  ...,  2.4111,  2.4111,  2.4111],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6226,  2.6226,  2.6226,  ...,  2.6226,  2.6226,  2.6226],\n",
      "          [ 2.6226,  2.6226,  2.6226,  ...,  2.6226,  2.6226,  2.6226],\n",
      "          [ 2.6226,  2.6226,  2.6226,  ...,  2.6226,  2.6226,  2.6226],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-1.8978, -1.9503, -1.9502,  ..., -1.5528, -1.5528, -1.5528],\n",
      "          [-1.8789, -1.9377, -1.9135,  ..., -1.5491, -1.5491, -1.5491],\n",
      "          [-1.8499, -1.8584, -1.8008,  ..., -1.5295, -1.5295, -1.5295],\n",
      "          ...,\n",
      "          [ 1.2858,  1.2973,  1.3061,  ..., -0.1635, -0.1509, -0.1429],\n",
      "          [ 1.2596,  1.2659,  1.2826,  ..., -0.1987, -0.1791, -0.1630],\n",
      "          [ 1.2409,  1.2559,  1.2630,  ..., -0.2379, -0.2058, -0.1976]],\n",
      "\n",
      "         [[-0.9775, -1.0793, -1.1016,  ..., -0.7227, -0.7227, -0.7227],\n",
      "          [-1.0063, -1.0604, -1.0866,  ..., -0.7189, -0.7189, -0.7189],\n",
      "          [-1.0053, -1.0351, -1.0146,  ..., -0.6989, -0.6989, -0.6989],\n",
      "          ...,\n",
      "          [ 1.6716,  1.6834,  1.6923,  ...,  0.2774,  0.2903,  0.2985],\n",
      "          [ 1.6448,  1.6512,  1.6683,  ...,  0.2414,  0.2615,  0.2780],\n",
      "          [ 1.6257,  1.6410,  1.6483,  ...,  0.2014,  0.2342,  0.2426]],\n",
      "\n",
      "         [[-0.0865, -0.1830, -0.2420,  ...,  0.2348,  0.2348,  0.2348],\n",
      "          [-0.1033, -0.2010, -0.2306,  ...,  0.2385,  0.2385,  0.2385],\n",
      "          [-0.1063, -0.1585, -0.1636,  ...,  0.2584,  0.2584,  0.2584],\n",
      "          ...,\n",
      "          [ 2.0258,  2.0375,  2.0464,  ...,  0.7424,  0.7552,  0.7634],\n",
      "          [ 1.9991,  2.0055,  2.0225,  ...,  0.7066,  0.7265,  0.7430],\n",
      "          [ 1.9801,  1.9954,  2.0026,  ...,  0.6668,  0.6994,  0.7078]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-0.9929, -1.0032, -1.0283,  ..., -1.9958, -1.9907, -1.9711],\n",
      "          [-0.8156, -0.8858, -0.9534,  ..., -1.9785, -1.9711, -1.9515],\n",
      "          [-0.7246, -0.8349, -0.9470,  ..., -1.9748, -1.9675, -1.9331]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.4033, -1.3901, -1.3699,  ..., -1.9985, -1.9932, -1.9732],\n",
      "          [-1.2146, -1.2625, -1.2792,  ..., -1.9807, -1.9732, -1.9532],\n",
      "          [-1.1015, -1.1836, -1.2258,  ..., -1.9769, -1.9694, -1.9343]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.5857, -1.6998, -1.8044,  ..., -1.8044, -1.8044, -1.7940],\n",
      "          [-1.5317, -1.7164, -1.8044,  ..., -1.7996, -1.7937, -1.7746],\n",
      "          [-1.5207, -1.7096, -1.8044,  ..., -1.7982, -1.7907, -1.7558]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0509, -0.0079,  0.0361,  ...,  1.4111,  1.6654,  1.6902],\n",
      "          [ 0.0361, -0.0079,  0.0375,  ...,  0.9231,  1.1821,  1.1620],\n",
      "          [ 0.0305, -0.0066,  0.0484,  ...,  0.1874,  0.4830,  0.4046],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.9118, -1.1245, -1.3038],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.9074, -1.1583, -1.2559],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.0421, -1.0647, -0.8456]],\n",
      "\n",
      "         [[ 0.5166,  0.4965,  0.5628,  ...,  1.7834,  2.0247,  2.0197],\n",
      "          [ 0.5016,  0.4965,  0.5642,  ...,  1.2930,  1.5329,  1.5100],\n",
      "          [ 0.4957,  0.4979,  0.5753,  ...,  0.5764,  0.8382,  0.7482],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.0501, -1.2941, -1.4731],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.0193, -1.2998, -1.3908],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.1569, -1.1873, -0.9929]],\n",
      "\n",
      "         [[ 1.4698,  1.4698,  1.5681,  ...,  2.0612,  2.3076,  2.3177],\n",
      "          [ 1.4548,  1.4698,  1.5694,  ...,  1.5706,  1.8173,  1.7952],\n",
      "          [ 1.4490,  1.4711,  1.5806,  ...,  0.8608,  1.1351,  1.0492],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.3545, -1.6102, -1.7076],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.5597, -1.7767, -1.8042],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.7331, -1.8036, -1.7293]]],\n",
      "\n",
      "\n",
      "        [[[-2.0678, -2.0678, -2.0678,  ..., -0.1077,  0.2581,  0.6317],\n",
      "          [-2.0873, -2.0873, -2.0873,  ...,  0.0722,  0.1013,  0.1413],\n",
      "          [-2.1069, -2.1069, -2.1069,  ...,  0.0913, -0.3846, -0.7994],\n",
      "          ...,\n",
      "          [ 0.5626,  0.5104,  0.2557,  ..., -0.6003, -0.7204, -0.6637],\n",
      "          [-0.0682, -0.3330, -0.6445,  ..., -0.8677, -1.0976, -1.1764],\n",
      "          [-0.6932, -0.9166, -1.1960,  ..., -0.9573, -1.1952, -1.3684]],\n",
      "\n",
      "         [[-1.9844, -1.9844, -1.9844,  ..., -0.6993, -0.4570, -0.1313],\n",
      "          [-2.0045, -2.0045, -2.0045,  ..., -0.4832, -0.5765, -0.6042],\n",
      "          [-2.0245, -2.0245, -2.0245,  ..., -0.3957, -1.0066, -1.4823],\n",
      "          ...,\n",
      "          [ 0.2519,  0.3336,  0.2791,  ..., -0.2479, -0.4858, -0.4978],\n",
      "          [-0.4437, -0.5411, -0.6470,  ..., -0.5649, -0.9101, -1.0619],\n",
      "          [-1.0932, -1.1377, -1.2107,  ..., -0.7142, -1.0568, -1.2832]],\n",
      "\n",
      "         [[-1.7534, -1.7534, -1.7534,  ..., -1.6238, -1.1757, -0.7153],\n",
      "          [-1.7733, -1.7733, -1.7733,  ..., -1.1168, -0.9774, -0.8566],\n",
      "          [-1.7932, -1.7932, -1.7932,  ..., -0.6460, -1.0162, -1.3689],\n",
      "          ...,\n",
      "          [ 0.5539,  0.6316,  0.5534,  ..., -0.8682, -0.8909, -0.7468],\n",
      "          [-0.0943, -0.2272, -0.3470,  ..., -1.0122, -1.0794, -1.0631],\n",
      "          [-0.7281, -0.7941, -0.9035,  ..., -1.0046, -1.0363, -1.1076]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.3315, -0.0088,  0.4671,  ..., -1.3764, -1.9301, -2.0047],\n",
      "          [ 0.0279,  0.1702,  0.5006,  ..., -1.1190, -1.7397, -1.9976],\n",
      "          [ 0.3594,  0.3537,  0.5216,  ..., -0.8083, -1.4561, -1.9069],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-0.5246, -0.1944,  0.2801,  ..., -0.8087, -1.4729, -1.6021],\n",
      "          [-0.1534, -0.0050,  0.3249,  ..., -0.5432, -1.2548, -1.5929],\n",
      "          [ 0.1993,  0.1934,  0.3485,  ..., -0.2189, -0.9727, -1.4895],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[-0.7183, -0.3901,  0.0750,  ..., -0.0219, -0.8032, -1.0169],\n",
      "          [-0.3562, -0.2144,  0.0960,  ...,  0.2604, -0.5721, -0.9699],\n",
      "          [-0.0450, -0.0509,  0.0952,  ...,  0.6230, -0.2309, -0.8195],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  0.4153,  0.4019,  0.3982],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.3934,  0.3815,  0.3786],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.3630,  0.3543,  0.3530],\n",
      "          ...,\n",
      "          [-0.2121, -0.2300, -0.2450,  ..., -0.6109, -0.6048, -0.5946],\n",
      "          [-0.3531, -0.3776, -0.4091,  ..., -0.8142, -0.8176, -0.8142],\n",
      "          [-0.5894, -0.5000, -0.4166,  ..., -0.8548, -0.8916, -0.9131]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  0.6591,  0.6454,  0.6416],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.6367,  0.6245,  0.6216],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.6056,  0.5967,  0.5953],\n",
      "          ...,\n",
      "          [-0.1574, -0.1757, -0.1910,  ..., -0.5126, -0.5064, -0.4959],\n",
      "          [-0.3015, -0.3266, -0.3588,  ..., -0.7204, -0.7239, -0.7205],\n",
      "          [-0.5432, -0.4517, -0.3665,  ..., -0.7619, -0.7995, -0.8216]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  1.1573,  1.1436,  1.1398],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.1350,  1.1229,  1.1199],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.1040,  1.0951,  1.0938],\n",
      "          ...,\n",
      "          [ 0.0830,  0.0647,  0.0495,  ..., -0.2010, -0.1947, -0.1843],\n",
      "          [-0.0605, -0.0855, -0.1175,  ..., -0.4078, -0.4114, -0.4079],\n",
      "          [-0.3011, -0.2100, -0.1252,  ..., -0.4491, -0.4866, -0.5085]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9303,  0.9303,  0.9303,  ...,  1.2043,  1.2043,  1.2043],\n",
      "          [ 0.9266,  0.9266,  0.9279,  ...,  1.2043,  1.2043,  1.2043],\n",
      "          [ 0.9075,  0.9132,  0.9171,  ...,  1.1982,  1.1982,  1.1982],\n",
      "          ...,\n",
      "          [-1.6983, -1.7177, -1.7412,  ..., -0.5877, -0.5963, -0.5987],\n",
      "          [-1.6857, -1.6729, -1.6483,  ..., -0.6159, -0.6236, -0.6244],\n",
      "          [-1.7295, -1.6003, -1.5043,  ..., -0.6378, -0.6440, -0.6587]],\n",
      "\n",
      "         [[ 1.1155,  1.1155,  1.1155,  ...,  1.3606,  1.3606,  1.3606],\n",
      "          [ 1.1118,  1.1118,  1.1131,  ...,  1.3606,  1.3606,  1.3606],\n",
      "          [ 1.0922,  1.0980,  1.1021,  ...,  1.3544,  1.3544,  1.3544],\n",
      "          ...,\n",
      "          [-1.7643, -1.7842, -1.8081,  ..., -0.1037, -0.1125, -0.1149],\n",
      "          [-1.7514, -1.7443, -1.7407,  ..., -0.1325, -0.1404, -0.1412],\n",
      "          [-1.8287, -1.6972, -1.6010,  ..., -0.1550, -0.1612, -0.1763]],\n",
      "\n",
      "         [[ 1.5594,  1.5594,  1.5594,  ...,  1.7860,  1.7860,  1.7860],\n",
      "          [ 1.5557,  1.5557,  1.5570,  ...,  1.7860,  1.7860,  1.7860],\n",
      "          [ 1.5362,  1.5420,  1.5460,  ...,  1.7797,  1.7797,  1.7797],\n",
      "          ...,\n",
      "          [-1.6438, -1.6588, -1.6650,  ...,  0.1713,  0.1625,  0.1601],\n",
      "          [-1.6434, -1.6318, -1.6116,  ...,  0.1426,  0.1347,  0.1339],\n",
      "          [-1.7041, -1.5730, -1.4762,  ...,  0.1202,  0.1140,  0.0990]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2450,  0.6914,  1.1023,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.3571,  0.7067,  1.0110,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.1298,  0.3789,  0.5461,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-0.9119, -0.9710, -0.8065,  ..., -0.6546, -0.7353, -0.9458],\n",
      "          [-0.7377, -0.8681, -0.8663,  ..., -0.6825, -0.8425, -1.1029],\n",
      "          [-0.9630, -0.9189, -1.0079,  ..., -0.7851, -0.9446, -1.1008]],\n",
      "\n",
      "         [[ 0.9052,  1.3297,  1.7349,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.0722,  1.4035,  1.6595,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.9395,  1.1547,  1.2318,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 0.8087,  0.9027,  1.1815,  ...,  0.8027,  0.7897,  0.6227],\n",
      "          [ 1.0965,  1.0777,  1.1758,  ...,  1.0926,  1.0068,  0.8197],\n",
      "          [ 0.9355,  1.1113,  1.0737,  ...,  1.1809,  1.1279,  1.0221]],\n",
      "\n",
      "         [[-0.8464, -0.1886,  0.5733,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.6158, -0.0794,  0.5621,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.6282, -0.1920,  0.2576,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 0.6543,  0.6716,  0.8713,  ...,  0.5204,  0.8222,  0.8787],\n",
      "          [ 1.3231,  1.1926,  1.1631,  ...,  1.0851,  1.3834,  1.4621],\n",
      "          [ 1.3777,  1.4148,  1.2380,  ...,  1.3357,  1.7017,  1.8910]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0110,  0.9915,  0.9780,  ...,  1.4098,  1.4098,  1.4098],\n",
      "          [ 0.9523,  0.9327,  0.9180,  ...,  1.4098,  1.4098,  1.4098],\n",
      "          [ 0.8936,  0.8740,  0.8545,  ...,  1.4098,  1.4098,  1.4098],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.5049, -0.4717, -0.4565],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.3785, -0.3663, -0.3913],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.1754, -0.1461, -0.1631]],\n",
      "\n",
      "         [[ 1.1631,  1.1431,  1.1293,  ...,  1.6057,  1.6057,  1.6057],\n",
      "          [ 1.1030,  1.0830,  1.0679,  ...,  1.6057,  1.6057,  1.6057],\n",
      "          [ 1.0430,  1.0230,  1.0030,  ...,  1.6057,  1.6057,  1.6057],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.3867, -0.3528, -0.3372],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.2575, -0.2450, -0.2705],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.0498, -0.0199, -0.0373]],\n",
      "\n",
      "         [[ 1.5893,  1.5693,  1.5557,  ...,  2.0300,  2.0300,  2.0300],\n",
      "          [ 1.5295,  1.5096,  1.4946,  ...,  2.0300,  2.0300,  2.0300],\n",
      "          [ 1.4698,  1.4498,  1.4299,  ...,  2.0300,  2.0300,  2.0300],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.1628, -0.1290, -0.1135],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.0341, -0.0217, -0.0471],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  0.1726,  0.2024,  0.1851]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6256,  0.7101,  0.8210,  ..., -2.0837, -2.0837, -2.0837],\n",
      "          [ 0.6010,  0.6665,  0.7702,  ..., -2.0873, -2.0873, -2.0873],\n",
      "          [ 0.5548,  0.6049,  0.7006,  ..., -2.1008, -2.1008, -2.1008],\n",
      "          ...,\n",
      "          [ 1.8555,  1.7740,  1.5641,  ...,  1.8604,  1.8872,  1.9032],\n",
      "          [ 1.8370,  1.9374,  1.6910,  ...,  1.9320,  1.9587,  1.9798],\n",
      "          [ 1.8570,  2.0423,  1.6580,  ...,  2.0164,  1.9690,  1.9306]],\n",
      "\n",
      "         [[ 0.8754,  0.9705,  1.0563,  ..., -1.2829, -1.2829, -1.2829],\n",
      "          [ 0.8499,  0.9230,  1.0043,  ..., -1.2792, -1.2792, -1.2792],\n",
      "          [ 0.8017,  0.8492,  0.9332,  ..., -1.2654, -1.2654, -1.2654],\n",
      "          ...,\n",
      "          [ 2.0614,  1.9780,  1.7635,  ...,  2.0139,  2.0413,  2.0576],\n",
      "          [ 2.0425,  2.1452,  1.8932,  ...,  2.0871,  2.1143,  2.1360],\n",
      "          [ 2.0630,  2.2523,  1.8595,  ...,  2.1734,  2.1249,  2.0857]],\n",
      "\n",
      "         [[ 1.4734,  1.5233,  1.6224,  ..., -0.1487, -0.1487, -0.1487],\n",
      "          [ 1.4489,  1.4848,  1.5707,  ..., -0.1487, -0.1487, -0.1487],\n",
      "          [ 1.4038,  1.4436,  1.4999,  ..., -0.1487, -0.1487, -0.1487],\n",
      "          ...,\n",
      "          [ 2.2570,  2.1740,  1.9604,  ...,  2.1923,  2.2196,  2.2358],\n",
      "          [ 2.2382,  2.3404,  2.0896,  ...,  2.2652,  2.2923,  2.3138],\n",
      "          [ 2.2586,  2.4471,  2.0560,  ...,  2.3511,  2.3028,  2.2638]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[ 2.2489,  2.2489,  2.2489,  ...,  0.5556,  0.6068,  0.3778],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.2806,  0.5066,  0.4280],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.0691,  0.4257,  0.8321],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.0118, -1.0797, -1.0618],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.8002, -0.9281, -0.9596],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.5506, -0.8529, -1.1393]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.7629,  1.8542,  1.6436],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  1.3507,  1.6011,  1.5329],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.8102,  1.2977,  1.6942],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.7259, -0.7501, -0.7222],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.6097, -0.6618, -0.6407],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.4209, -0.6196, -0.8452]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ..., -0.4493, -0.5824, -0.9254],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.5117, -0.3544, -0.4668],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.5696,  0.0242,  0.5090],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.5157, -1.7667, -1.8040],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.0027, -1.4897, -1.7878],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.5550, -1.3197, -1.7810]]],\n",
      "\n",
      "\n",
      "        [[[-0.7822, -0.7822, -0.7761,  ..., -0.3320, -0.3506, -0.3541],\n",
      "          [-0.7858, -0.7851, -0.7761,  ..., -0.3516, -0.3577, -0.3577],\n",
      "          [-0.7993, -0.7956, -0.7761,  ..., -0.3734, -0.3773, -0.3773],\n",
      "          ...,\n",
      "          [-0.9608, -0.9986, -1.0106,  ..., -0.8959, -0.8873, -0.8792],\n",
      "          [-0.9884, -1.0525, -1.0672,  ..., -0.9020, -0.8886, -0.8849],\n",
      "          [-1.0232, -1.0794, -1.0941,  ..., -0.9020, -0.9011, -0.8861]],\n",
      "\n",
      "         [[-0.2850, -0.2850, -0.2788,  ...,  0.4203,  0.4012,  0.3978],\n",
      "          [-0.2888, -0.2880, -0.2788,  ...,  0.4003,  0.3940,  0.3940],\n",
      "          [-0.3025, -0.2988, -0.2788,  ...,  0.3780,  0.3740,  0.3740],\n",
      "          ...,\n",
      "          [-1.2029, -1.2416, -1.2539,  ..., -1.1078, -1.0990, -1.0908],\n",
      "          [-1.2311, -1.2967, -1.3117,  ..., -1.1078, -1.0941, -1.0903],\n",
      "          [-1.2667, -1.3242, -1.3392,  ..., -1.1078, -1.1069, -1.0915]],\n",
      "\n",
      "         [[ 1.4200,  1.4200,  1.4262,  ...,  2.1744,  2.1555,  2.1520],\n",
      "          [ 1.4162,  1.4170,  1.4262,  ...,  2.1545,  2.1482,  2.1482],\n",
      "          [ 1.4025,  1.4063,  1.4262,  ...,  2.1323,  2.1283,  2.1283],\n",
      "          ...,\n",
      "          [-0.9405, -0.9790, -0.9912,  ..., -0.8682, -0.8594, -0.8513],\n",
      "          [-0.9686, -1.0338, -1.0488,  ..., -0.8807, -0.8670, -0.8633],\n",
      "          [-1.0040, -1.0612, -1.0762,  ..., -0.8807, -0.8797, -0.8644]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9230,  0.9261,  0.9368,  ...,  0.8601,  0.8628,  0.8849],\n",
      "          [ 1.0756,  1.0677,  1.0379,  ...,  0.9019,  0.9295,  0.9853],\n",
      "          [ 1.1627,  1.1408,  1.1025,  ...,  0.8559,  0.9155,  0.9812],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 1.3356,  1.3388,  1.3497,  ...,  1.2364,  1.2391,  1.2617],\n",
      "          [ 1.4917,  1.4836,  1.4531,  ...,  1.2791,  1.3073,  1.3644],\n",
      "          [ 1.5807,  1.5583,  1.5192,  ...,  1.2321,  1.2930,  1.3602],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.6391,  1.6423,  1.6531,  ...,  1.5926,  1.5952,  1.6328],\n",
      "          [ 1.7944,  1.7864,  1.7560,  ...,  1.6351,  1.6632,  1.7200],\n",
      "          [ 1.8831,  1.8608,  1.8218,  ...,  1.5883,  1.6489,  1.7158],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.3534, -1.3534, -1.3534],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.3473, -1.3473, -1.3473],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.3473, -1.3473, -1.3473]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.0791, -1.0791, -1.0791],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.0728, -1.0728, -1.0728],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.0728, -1.0728, -1.0728]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.6778, -0.6778, -0.6778],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.6715, -0.6715, -0.6715],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.6715, -0.6715, -0.6715]]],\n",
      "\n",
      "\n",
      "        [[[-0.7455, -0.7455, -0.7455,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.7063, -0.7063, -0.7063,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.6672, -0.6672, -0.6672,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.4984, -1.5002, -1.5002],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.5441, -1.5666, -1.5724],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.6050, -1.6433, -1.6802]],\n",
      "\n",
      "         [[ 0.2777,  0.2777,  0.2777,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.3177,  0.3177,  0.3177,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 0.3640,  0.3640,  0.3640,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.6475, -1.6493, -1.6493],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.6942, -1.7172, -1.7231],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.7565, -1.7956, -1.8333]],\n",
      "\n",
      "         [[ 1.4922,  1.4922,  1.4922,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.5320,  1.5320,  1.5320,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.5594,  1.5594,  1.5594,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.5873, -1.5891, -1.5891],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.6213, -1.6442, -1.6501],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.6833, -1.7223, -1.7598]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  0.1352,  0.1548,  0.1744],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.1157,  0.1352,  0.1548],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  0.0961,  0.1157,  0.1352],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  0.6529,  0.6729,  0.6929],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.6329,  0.6529,  0.6729],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  0.6128,  0.6329,  0.6529],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  1.2731,  1.2930,  1.3129],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.2531,  1.2731,  1.2930],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  1.2394,  1.2594,  1.2793],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.5125,  1.5125,  1.5187,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.5125,  1.5125,  1.5173,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.5064,  1.5077,  1.5125,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.0775, -2.0775, -2.0775],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.0971, -2.0971, -2.0971],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.1008, -2.1008, -2.1008]],\n",
      "\n",
      "         [[ 1.6758,  1.6758,  1.6820,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.6758,  1.6758,  1.6807,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.6695,  1.6709,  1.6758,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -1.9944, -1.9944, -1.9944],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0145, -2.0145, -2.0145],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0182, -2.0182, -2.0182]],\n",
      "\n",
      "         [[ 1.8905,  1.8905,  1.8968,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.8905,  1.8905,  1.8954,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.8843,  1.8857,  1.8905,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.7634, -1.7634, -1.7634],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.7833, -1.7833, -1.7833],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.7870, -1.7870, -1.7870]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3939,  1.3939,  1.3873,  ...,  1.6096,  1.6349,  1.6692],\n",
      "          [ 1.4098,  1.4090,  1.3952,  ...,  1.7118,  1.7327,  1.7523],\n",
      "          [ 1.4159,  1.4109,  1.3866,  ...,  1.7909,  1.8170,  1.8322],\n",
      "          ...,\n",
      "          [-0.5515, -0.7411, -0.3976,  ..., -1.0011, -0.9190, -0.8771],\n",
      "          [-0.4512, -0.3959, -0.0432,  ..., -1.0354, -0.9542, -0.8820],\n",
      "          [-0.5269, -0.1337,  0.1773,  ..., -1.1089, -1.0601, -0.9852]],\n",
      "\n",
      "         [[ 1.3269,  1.3269,  1.3264,  ...,  1.7362,  1.7621,  1.7519],\n",
      "          [ 1.3431,  1.3431,  1.3369,  ...,  1.7896,  1.8096,  1.8296],\n",
      "          [ 1.3494,  1.3480,  1.3369,  ...,  1.8593,  1.8771,  1.8913],\n",
      "          ...,\n",
      "          [-0.9070, -1.1009, -0.7434,  ..., -1.0453, -0.9614, -0.9186],\n",
      "          [-0.8045, -0.7480, -0.3811,  ..., -1.0718, -1.0036, -0.9297],\n",
      "          [-0.8819, -0.4799, -0.1558,  ..., -1.1429, -1.1119, -1.0353]],\n",
      "\n",
      "         [[ 1.2643,  1.2643,  1.2639,  ...,  1.5627,  1.5768,  1.5817],\n",
      "          [ 1.2805,  1.2805,  1.2743,  ...,  1.6156,  1.6328,  1.6528],\n",
      "          [ 1.2867,  1.2854,  1.2743,  ...,  1.6550,  1.6602,  1.6744],\n",
      "          ...,\n",
      "          [-0.8168, -1.0381, -0.7221,  ..., -1.4123, -1.3287, -1.2861],\n",
      "          [-0.7032, -0.6868, -0.3614,  ..., -1.3975, -1.3247, -1.2512],\n",
      "          [-0.7802, -0.4130, -0.1162,  ..., -1.4622, -1.4250, -1.3488]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.2261, -0.9962, -0.5829,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.1303, -0.8772, -0.4778,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-1.0859, -0.7855, -0.3509,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-1.7925, -1.7925, -1.7986,  ..., -1.6316, -1.6237, -1.6181],\n",
      "          [-1.7925, -1.7925, -1.7986,  ..., -1.5464, -1.5198, -1.5198],\n",
      "          [-1.7925, -1.7925, -1.7986,  ..., -1.5161, -1.4605, -1.4537]],\n",
      "\n",
      "         [[-1.1765, -0.9415, -0.5189,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.0785, -0.8199, -0.4115,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-1.0332, -0.7261, -0.2818,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-1.8081, -1.8081, -1.8019,  ..., -1.6086, -1.6055, -1.6010],\n",
      "          [-1.8081, -1.8081, -1.8019,  ..., -1.5215, -1.4942, -1.4942],\n",
      "          [-1.8081, -1.8081, -1.8019,  ..., -1.4905, -1.4337, -1.4267]],\n",
      "\n",
      "         [[-1.0362, -0.8023, -0.3816,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.9387, -0.6812, -0.2746,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.8935, -0.5878, -0.1455,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.5779, -1.5779, -1.5779,  ..., -1.4046, -1.4236, -1.4239],\n",
      "          [-1.5779, -1.5779, -1.5779,  ..., -1.3099, -1.3102, -1.3177],\n",
      "          [-1.5779, -1.5779, -1.5779,  ..., -1.2791, -1.2245, -1.2481]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ..., -1.4035, -0.6232, -0.0192],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -1.1220, -0.4263, -0.0617],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.8209, -0.1831, -0.0101],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -0.6947,  0.1501,  0.8203],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.4258,  0.3431,  0.7276],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.1570,  0.5488,  0.7474],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ..., -1.5283, -0.8654, -0.3157],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.4279, -0.7285, -0.3927],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.1405, -0.5086, -0.3547],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1346,  1.1346,  1.1346,  ...,  1.0375,  1.0318,  1.0318],\n",
      "          [ 1.1187,  1.1187,  1.1187,  ...,  1.0086,  1.0086,  1.0086],\n",
      "          [ 1.1126,  1.1126,  1.1126,  ...,  0.9756,  0.9804,  0.9817],\n",
      "          ...,\n",
      "          [-0.3427, -0.2436, -0.2045,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.4588, -0.3841, -0.4018,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-0.3806, -0.3686, -0.4884,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 1.4819,  1.4819,  1.4819,  ...,  1.4002,  1.3944,  1.3944],\n",
      "          [ 1.4657,  1.4657,  1.4657,  ...,  1.3706,  1.3706,  1.3706],\n",
      "          [ 1.4594,  1.4594,  1.4594,  ...,  1.3369,  1.3418,  1.3431],\n",
      "          ...,\n",
      "          [-0.3960, -0.2947, -0.2546,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.5147, -0.4383, -0.4564,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-0.4347, -0.4225, -0.5449,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.2553,  2.2553,  2.2553,  ...,  2.0345,  2.0287,  2.0287],\n",
      "          [ 2.2391,  2.2391,  2.2391,  ...,  2.0051,  2.0051,  2.0051],\n",
      "          [ 2.2329,  2.2329,  2.2329,  ...,  1.9715,  1.9764,  1.9777],\n",
      "          ...,\n",
      "          [-0.3288, -0.2280, -0.1944,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.4470, -0.3710, -0.3953,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-0.3674, -0.3552, -0.4834,  ...,  2.6400,  2.6400,  2.6400]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "predicted = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for data in testloader:\n",
    "        images = data.to(device)\n",
    "        outputs = model(images)\n",
    "        mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dec6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
