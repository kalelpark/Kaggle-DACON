{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import models as tvmodels\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "\n",
    "from albumentations import Compose\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "bs = 32\n",
    "EPOCHS = 10\n",
    "sz = 512\n",
    "SNAPMIX_ALPHA = 5.0                 # 논문을 보면 고정으로 5.0 을 사용하라고 한다.\n",
    "SNAPMIX_PCT = 0.5\n",
    "GRAD_ACCUM_STEPS = 1\n",
    "TIMM_MODEL = 'resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "SEED = 1234\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  CassavaDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transforms = None):\n",
    "        super().__init__()\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def get_img_bgr_to_rgb(self, path):\n",
    "        img_bgr = cv2.imread(path)\n",
    "        img_rgb = img_bgr[:, :, ::-1]\n",
    "        return img_rgb\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.dataframe.iloc[idx, 0])\n",
    "        image = self.get_img_bgr_to_rgb(img_name)\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image = image)['image']\n",
    "        csv_row = self.dataframe.iloc[idx, 1:]\n",
    "        sample = {\n",
    "            'image' : image,\n",
    "            'label' : csv_row.label\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('files/train.csv')\n",
    "def train_transforms():\n",
    "    return Compose([\n",
    "        A.RandomResizedCrop(sz, sz),\n",
    "        # A.Transpose(p = 0.5),\n",
    "        A.HorizontalFlip(p = 0.5),\n",
    "        # A.VerticalFlip(p = 0.5),\n",
    "        # A.ShiftScaleRotate(p = 0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ], p = 1.)\n",
    "\n",
    "def valid_transforms():\n",
    "    return Compose([\n",
    "        A.Resize(sz, sz),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p = 1.0)\n",
    "    ], p = 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        backbone = timm.create_model(TIMM_MODEL, pretrained= True)\n",
    "        n_features = backbone.fc.in_feautres\n",
    "        self.backbone = nn.Sequential(*backbone.children())[:-2]       # 모든 모델은 children 이라는 함수를 가지고 있는데, 이건 layer들을 반환해주는 함수이다.\n",
    "                                                                       # 마지막 2개까지 가져온다는 것이다.\n",
    "        self.classifier = nn.Linear(n_features , 5)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))                       # Adaw\n",
    "    \n",
    "    def forward_features(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feats = self.forward_features(x)\n",
    "        x = self.pool(feats).view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(input, targs):\n",
    "    return accuracy_score(targs.cpu(), input.cpu())\n",
    "\n",
    "def print_scores(scores):\n",
    "    kaggle_metric = np.average(scores)\n",
    "    print(\"Kaggle Metric : %f\" % (kaggle_metric))\n",
    "\n",
    "    return kaggle_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint(model, optimizer, epoch, current_metric, best_metric, fold):\n",
    "    print(\"Metric imporved from %f to %f, Saving Model at Epoch #%d\" % (best_metric, current_metric, epoch))\n",
    "    ckpt = {\n",
    "        'model' : CassavaNet(),\n",
    "        'state_dict' : model.state_dict(),\n",
    "        'metric' : current_metric\n",
    "    }\n",
    "    torch.save(ckpt, 'ckpt_%s-%d-%d.pth' % (TIMM_MODEL, sz, fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits = NUM_FOLDS, shuffle= True, random_state= SEED).split(np.arange(train_df.shape[0]), train_df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def get_spm(input,target,model):\n",
    "    imgsize = (sz, sz)\n",
    "    bs = input.size(0)\n",
    "    with torch.no_grad():\n",
    "        output,fms = model(input)\n",
    "        clsw = model.classifier\n",
    "        weight = clsw.weight.data\n",
    "        bias = clsw.bias.data\n",
    "        weight = weight.view(weight.size(0),weight.size(1),1,1)\n",
    "        fms = F.relu(fms)\n",
    "        poolfea = F.adaptive_avg_pool2d(fms,(1,1)).squeeze()\n",
    "        clslogit = F.softmax(clsw.forward(poolfea))\n",
    "        logitlist = []\n",
    "        for i in range(bs):\n",
    "            logitlist.append(clslogit[i,target[i]])\n",
    "        clslogit = torch.stack(logitlist)\n",
    "\n",
    "        out = F.conv2d(fms, weight, bias=bias)\n",
    "\n",
    "        outmaps = []\n",
    "        for i in range(bs):\n",
    "            evimap = out[i,target[i]]\n",
    "            outmaps.append(evimap)\n",
    "\n",
    "        outmaps = torch.stack(outmaps)\n",
    "        if imgsize is not None:\n",
    "            outmaps = outmaps.view(outmaps.size(0),1,outmaps.size(1),outmaps.size(2))\n",
    "            outmaps = F.interpolate(outmaps,imgsize,mode='bilinear',align_corners=False)\n",
    "\n",
    "        outmaps = outmaps.squeeze()\n",
    "\n",
    "        for i in range(bs):\n",
    "            outmaps[i] -= outmaps[i].min()\n",
    "            outmaps[i] /= outmaps[i].sum()\n",
    "\n",
    "\n",
    "    return outmaps,clslogit\n",
    "\n",
    "\n",
    "def snapmix(input, target, alpha, model=None):\n",
    "\n",
    "    r = np.random.rand(1)\n",
    "    lam_a = torch.ones(input.size(0))\n",
    "    lam_b = 1 - lam_a\n",
    "    target_b = target.clone()\n",
    "\n",
    "    if True:\n",
    "        wfmaps,_ = get_spm(input, target, model)\n",
    "        bs = input.size(0)\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        lam1 = np.random.beta(alpha, alpha)\n",
    "        rand_index = torch.randperm(bs).cuda()\n",
    "        wfmaps_b = wfmaps[rand_index,:,:]\n",
    "        target_b = target[rand_index]\n",
    "\n",
    "        same_label = target == target_b\n",
    "        bbx1, bby1, bbx2, bby2 = rand_bbox(input.size(), lam)\n",
    "        bbx1_1, bby1_1, bbx2_1, bby2_1 = rand_bbox(input.size(), lam1)\n",
    "\n",
    "        area = (bby2-bby1)*(bbx2-bbx1)\n",
    "        area1 = (bby2_1-bby1_1)*(bbx2_1-bbx1_1)\n",
    "\n",
    "        if  area1 > 0 and  area>0:\n",
    "            ncont = input[rand_index, :, bbx1_1:bbx2_1, bby1_1:bby2_1].clone()\n",
    "            ncont = F.interpolate(ncont, size=(bbx2-bbx1,bby2-bby1), mode='bilinear', align_corners=True)\n",
    "            input[:, :, bbx1:bbx2, bby1:bby2] = ncont\n",
    "            lam_a = 1 - wfmaps[:,bbx1:bbx2,bby1:bby2].sum(2).sum(1)/(wfmaps.sum(2).sum(1)+1e-8)\n",
    "            lam_b = wfmaps_b[:,bbx1_1:bbx2_1,bby1_1:bby2_1].sum(2).sum(1)/(wfmaps_b.sum(2).sum(1)+1e-8)\n",
    "            tmp = lam_a.clone()\n",
    "            lam_a[same_label] += lam_b[same_label]\n",
    "            lam_b[same_label] += tmp[same_label]\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (input.size()[-1] * input.size()[-2]))\n",
    "            lam_a[torch.isnan(lam_a)] = lam\n",
    "            lam_b[torch.isnan(lam_b)] = 1-lam\n",
    "\n",
    "    return input,target,target_b,lam_a.cuda(),lam_b.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnapMixLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, criterion, outputs, ya, yb, lam_a, lam_b):\n",
    "        loss_a = criterion(outputs, ya)\n",
    "        loss_b = criterion(outputs, yb)\n",
    "        loss = torch.mean(loss_a * lam_a + loss_b * lam_b)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_num, (train_split, valid_split) in enumerate(folds):\n",
    "    train_set = train_df.iloc[train_split].reset_index(drop = True)\n",
    "    valid_set = train_df.iloc[valid_split].reset_index(drop = True)\n",
    "\n",
    "    train_ds = CassavaDataset(dataframe=train_set,\n",
    "                              root_dir= 'train_images',\n",
    "                              transforms=train_transforms())\n",
    "    valid_ds = CassavaDataset(dataframe=valid_set, \n",
    "                              root_dir='train_images',\n",
    "                              transforms = valid_transforms())\n",
    "    \n",
    "    train_dl = torch.utils.data.DataLoader(train_ds, batch_size=bs,\n",
    "                                           shuffle = True, drop_last = True, pin_memeory = True)\n",
    "    valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size = bs,\n",
    "                                           shuffle = True, pin_memory = True)\n",
    "    \n",
    "    losses = []\n",
    "    batches = len(train_dl)\n",
    "    val_batches = len(valid_dl)\n",
    "    best_metric = 0\n",
    "\n",
    "    model = CassavaNet().to(device)\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none').to(device)\n",
    "    val_criterion = nn.CrossEntropyLoss().to(device)\n",
    "    snap_mix_criterion = SnapMixLoss().to(device)\n",
    "    param_groups = [\n",
    "        {'params' : model.backbone.parameters(), 'lr' : 1e-2},\n",
    "        {'params': model.classifier.parameters()},\n",
    "    ]\n",
    "    optimizer = torch.optim.SGD(param_groups, lr = 1e-1, momentum=0.9,\n",
    "                                weight_decay = 1e-4, nesterov = True)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1, 20, 40], gamma = 0.1,\n",
    "                                                     last_epoch = -1, verbose = True)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # ---------------------- Training ---------------------\n",
    "        train_loss = 0\n",
    "        progress = tqdm(enumerate(train_dl), desc = \"Loss : \", total = batches)\n",
    "        model.train()\n",
    "        for i, data in progress:\n",
    "            image, label = data.values()\n",
    "            X, y = image.to(device).float(), label.to(device).long()\n",
    "\n",
    "            with autocast:\n",
    "                rand = np.random.rand()\n",
    "                if rand > (1.0 - SNAPMIX_PCT):\n",
    "                    X, ya, yb, lam_a, lam_b = snapmix(X, y, SNAPMIX_ALPHA, model)\n",
    "                    outputs, _ = model(X)\n",
    "                    loss = snap_mix_criterion(criterion, outputs, ya, yb, lam_a, lam_b)\n",
    "                else:\n",
    "                    outputs, _ = model(X)\n",
    "                    loss = torch.mean(criterion(outputs, y))\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            if ((i + 1) % GRAD_ACCUM_STEPS == 0) or ((i +1 ) == len(train_dl)):\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            cur_step = i+1\n",
    "            trn_epoch_result = dict()\n",
    "            trn_epoch_result['Epoch'] = epoch + 1\n",
    "            trn_epoch_result['Train_loss'] = round(train_loss / cur_step, 4)\n",
    "\n",
    "            progress.set_description(str(trn_epoch_result))\n",
    "        \n",
    "        scheduler.step()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # ---------------- Validation Loss ------------------\n",
    "        val_loss = 0\n",
    "        scores = []\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(valid_dl):\n",
    "                image, label = data.values()\n",
    "                X, y = image.to(device), label.to(device)\n",
    "                outputs, _ = model(X)\n",
    "                l = val_criterion(outputs, y)\n",
    "                val_loss += l.item()\n",
    "\n",
    "                preds = F.softmax(outputs).argmax(axis = 1)\n",
    "                scores.append(accuracy_metric(preds, y))\n",
    "        epoch_result = dict()\n",
    "        epoch_result['Epoch'] = epoch + 1\n",
    "        epoch_result['train_loss'] = round(train_loss/batches, 4)\n",
    "        epoch_result['val_loss'] = round(val_loss / val_batches, 4)\n",
    "\n",
    "        print(epoch_result)\n",
    "\n",
    "        current_metric = print_scores(scores)\n",
    "        if current_metric > best_metric:\n",
    "            checkpoint(model, optimizer, epoch + 1 , current_metric, best_metric, fold_num)\n",
    "            best_metric = current_metric\n",
    "    \n",
    "    del model, optimizer, train_dl, valid_dl, scaler, scheduler\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b4505f09541fece67cab37567117394b96a6fcfc274ce6a4d4cf422ca2f442a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
